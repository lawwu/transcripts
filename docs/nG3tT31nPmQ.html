<html><head><title>Lesson 14: Deep Learning Part 2 2018 - Super resolution; Image segmentation with Unet</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 14: Deep Learning Part 2 2018 - Super resolution; Image segmentation with Unet</h2><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ"><img src="https://i.ytimg.com/vi_webp/nG3tT31nPmQ/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=0">0:0</a> <Untitled Chapter 1><br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=133">2:13</a> Style Transfer<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=230">3:50</a> Super Resolution<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=993">16:33</a> Data Augmentation<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1002">16:42</a> Random Dihedral<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1100">18:20</a> Transformations<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1146">19:6</a> Transform Types<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1560">26:0</a> Enhanced Deep Residual Networks<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2092">34:52</a> App Sampling<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2140">35:40</a> Transposed Convolutions<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2625">43:45</a> Pixel Shuffle<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3053">50:53</a> Perceptual Loss<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3500">58:20</a> Progressive Resizing<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3850">64:10</a> What Are the Future Plans for Fast Ai in this Course<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4107">68:27</a> Leverage Your Knowledge about Your Domain<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4526">75:26</a> Reinforcement Learning<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5361">89:21</a> Segmentation<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5824">97:4</a> Transform Type Classification<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6170">102:50</a> Upscaling<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6429">107:9</a> The Dice Metric<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6708">111:48</a> Unit Blocks<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6755">112:35</a> Dynamic Unit<br><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7174">119:34</a> Feature Pyramid Networks<br><br><div style="text-align: left;"><a href="./nG3tT31nPmQ.html">Whisper Transcript</a> | <a href="./transcript_nG3tT31nPmQ.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3" target="_blank">00:00:03.000</a></span> | <span class="t">Welcome to the last lesson, lesson 14.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=8" target="_blank">00:00:08.040</a></span> | <span class="t">We're going to be looking at image segmentation today, amongst other things, but before we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=13" target="_blank">00:00:13.080</a></span> | <span class="t">do, a bit of show and tell from last week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=20" target="_blank">00:00:20.040</a></span> | <span class="t">Elena Harley did something really interesting, which was she tried finding out what would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=24" target="_blank">00:00:24.160</a></span> | <span class="t">happen if you did CycleGAN on just 300 or 400 images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=28" target="_blank">00:00:28.780</a></span> | <span class="t">I really like these projects where people just go to Google image search using the API</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=33" target="_blank">00:00:33.360</a></span> | <span class="t">or one of the libraries out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=35" target="_blank">00:00:35.400</a></span> | <span class="t">Some of our students have created some very good libraries for interacting with Google</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=38" target="_blank">00:00:38.720</a></span> | <span class="t">images API, download a bunch of stuff they're interested in, in this case some photos and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=44" target="_blank">00:00:44.360</a></span> | <span class="t">some stained glass windows, and with 300 or 400 photos of that she trained a model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=51" target="_blank">00:00:51.320</a></span> | <span class="t">She trained actually a few different models, this is what I particularly liked, and as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=54" target="_blank">00:00:54.840</a></span> | <span class="t">you can see, with quite a small number of images she gets some very nice stained glass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=59" target="_blank">00:00:59.760</a></span> | <span class="t">effects.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=60" target="_blank">00:01:00.760</a></span> | <span class="t">So I thought that was an interesting example of using pretty small amounts of data that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=66" target="_blank">00:01:06.440</a></span> | <span class="t">was readily available, which she was able to download pretty quickly, and there's more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=70" target="_blank">00:01:10.960</a></span> | <span class="t">information about that on the forum if you're interested.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=77" target="_blank">00:01:17.160</a></span> | <span class="t">It's interesting to wonder about what kinds of things people will come up with with this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=80" target="_blank">00:01:20.280</a></span> | <span class="t">kind of generative model, it's clearly a great artistic medium, it's clearly a great medium</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=88" target="_blank">00:01:28.120</a></span> | <span class="t">for forgeries and fakeries, I wonder what other kinds of things people will realize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=95" target="_blank">00:01:35.240</a></span> | <span class="t">they can do with these kind of generative models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=98" target="_blank">00:01:38.080</a></span> | <span class="t">I think audio is going to be the next big area, and also very interactive type stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=105" target="_blank">00:01:45.240</a></span> | <span class="t">Nvidia just released a paper showing an interactive photo repair tool where you just brush over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=114" target="_blank">00:01:54.940</a></span> | <span class="t">an object and it replaces it with a deep learning generated replacement very nicely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=121" target="_blank">00:02:01.400</a></span> | <span class="t">Those kinds of interactive tools I think will be very interesting too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=127" target="_blank">00:02:07.000</a></span> | <span class="t">So before we talk about segmentation, we've got some stuff to finish up from last time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=132" target="_blank">00:02:12.240</a></span> | <span class="t">which is that we looked at doing style transfer by actually directly optimizing pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=142" target="_blank">00:02:22.760</a></span> | <span class="t">Like with most of the things in Part 2, it's not so much that I'm wanting you to understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=150" target="_blank">00:02:30.680</a></span> | <span class="t">style transfer per se, but the kind of idea of optimizing your input directly and using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=157" target="_blank">00:02:37.240</a></span> | <span class="t">activations as part of a loss function is really the key kind of takeaway here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=166" target="_blank">00:02:46.920</a></span> | <span class="t">So it's interesting then to kind of see what is effectively the follow-up paper, not from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=172" target="_blank">00:02:52.680</a></span> | <span class="t">the same people, but the paper that kind of came next in the sequence of these kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=177" target="_blank">00:02:57.240</a></span> | <span class="t">vision generative models with this one from Justin Johnson and folks at Stanford.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=185" target="_blank">00:03:05.240</a></span> | <span class="t">And it actually does the same thing, style transfer, but it does it in a different way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=191" target="_blank">00:03:11.200</a></span> | <span class="t">Rather than optimizing the pixels, we're going to go back to something much more familiar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=196" target="_blank">00:03:16.480</a></span> | <span class="t">and optimize some weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=198" target="_blank">00:03:18.760</a></span> | <span class="t">And so specifically we're going to train a model which learns to take a photo and translate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=205" target="_blank">00:03:25.020</a></span> | <span class="t">it into a photo in the style of a particular artwork.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=210" target="_blank">00:03:30.360</a></span> | <span class="t">So each ConvNet will learn to produce one kind of style.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=219" target="_blank">00:03:39.260</a></span> | <span class="t">Now it turns out that getting to that point, there's an intermediate point which is I actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=225" target="_blank">00:03:45.040</a></span> | <span class="t">think kind of more useful and takes us halfway there, which is something called super-resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=232" target="_blank">00:03:52.480</a></span> | <span class="t">So we're actually going to start with super-resolution because then we'll build on top of super-resolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=237" target="_blank">00:03:57.240</a></span> | <span class="t">to finish off the style transfer, ConvNet based style transfer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=242" target="_blank">00:04:02.560</a></span> | <span class="t">And so super-resolution is where we take a low-res image, we're going to take 72x72 and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=249" target="_blank">00:04:09.200</a></span> | <span class="t">upscale it to a larger image, 288x288 in our case, trying to create a higher-res image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=258" target="_blank">00:04:18.160</a></span> | <span class="t">that looks as real as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=264" target="_blank">00:04:24.360</a></span> | <span class="t">And so this is a pretty challenging thing to do because at 72x72 there's not that much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=268" target="_blank">00:04:28.640</a></span> | <span class="t">information about a lot of the details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=271" target="_blank">00:04:31.000</a></span> | <span class="t">And the cool thing is that we're going to do it in a way as we tend to do with vision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=275" target="_blank">00:04:35.680</a></span> | <span class="t">models which is not tied to the input size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=279" target="_blank">00:04:39.160</a></span> | <span class="t">So you could totally then take this model and apply it to a 288x288 image and get something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=285" target="_blank">00:04:45.160</a></span> | <span class="t">that's 4 times bigger on each side, so 16 times bigger than that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=291" target="_blank">00:04:51.840</a></span> | <span class="t">But often it even works better at that level because you're really introducing a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=297" target="_blank">00:04:57.440</a></span> | <span class="t">detail into the finer details and you could really print out a high-resolution print of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=302" target="_blank">00:05:02.080</a></span> | <span class="t">something which earlier on was pretty pixelated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=307" target="_blank">00:05:07.560</a></span> | <span class="t">So this is the notebook called Enhance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=312" target="_blank">00:05:12.520</a></span> | <span class="t">And it is a lot like that kind of CSI style enhancement where we're going to take something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=318" target="_blank">00:05:18.600</a></span> | <span class="t">that appears like the information is just not there and we kind of invent it, but the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=325" target="_blank">00:05:25.760</a></span> | <span class="t">ConvNet is going to learn to invent it in a way that's consistent with the information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=329" target="_blank">00:05:29.320</a></span> | <span class="t">that is there, so hopefully it's kind of inventing the right information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=333" target="_blank">00:05:33.920</a></span> | <span class="t">One of the really nice things about this kind of problem is that we can create our own dataset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=340" target="_blank">00:05:40.440</a></span> | <span class="t">as big as we like without any labeling requirements because we can easily create a low-res image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=347" target="_blank">00:05:47.240</a></span> | <span class="t">from a high-res image just by downsampling our images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=351" target="_blank">00:05:51.200</a></span> | <span class="t">So something I would love some of you to try during the week would be to do other types</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=357" target="_blank">00:05:57.760</a></span> | <span class="t">of image-to-image translation where you can invent kind of labels, invent your dependent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=364" target="_blank">00:06:04.920</a></span> | <span class="t">variable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=365" target="_blank">00:06:05.920</a></span> | <span class="t">For example, de-skewing, so either recognize things that have been rotated by 90 degrees</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=372" target="_blank">00:06:12.720</a></span> | <span class="t">or better still that have been rotated by 5 degrees and straighten them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=378" target="_blank">00:06:18.480</a></span> | <span class="t">Colorization, so make a bunch of images into black and white and learn to put the color</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=384" target="_blank">00:06:24.360</a></span> | <span class="t">back again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=387" target="_blank">00:06:27.480</a></span> | <span class="t">Noise reduction, maybe do a really low-quality JPEG save and learn to put it back to how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=398" target="_blank">00:06:38.080</a></span> | <span class="t">it should have been, and so forth, or maybe take something that's in a 16 color palette</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=405" target="_blank">00:06:45.360</a></span> | <span class="t">and put it back to a higher color palette.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=409" target="_blank">00:06:49.280</a></span> | <span class="t">I think these things are all interesting because they can be used to take pictures that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=416" target="_blank">00:06:56.600</a></span> | <span class="t">may have taken back on crappy old digital cameras before they were high resolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=420" target="_blank">00:07:00.880</a></span> | <span class="t">or you may have scanned in some old photos that have faded or whatever, I think it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=426" target="_blank">00:07:06.120</a></span> | <span class="t">a really useful thing to be able to do, and also it's a good project because it's really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=431" target="_blank">00:07:11.120</a></span> | <span class="t">similar to what we're doing here, but different enough that you'll come across some interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=435" target="_blank">00:07:15.140</a></span> | <span class="t">challenges on the way, I'm sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=439" target="_blank">00:07:19.200</a></span> | <span class="t">So I'm going to use ImageNet again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=442" target="_blank">00:07:22.400</a></span> | <span class="t">You don't need to use all of ImageNet at all, I just happen to have it lying around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=446" target="_blank">00:07:26.360</a></span> | <span class="t">You can download the 1% sample of ImageNet from files.fast.ai.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=449" target="_blank">00:07:29.720</a></span> | <span class="t">You can use any set of pictures you have lying around, honestly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=455" target="_blank">00:07:35.880</a></span> | <span class="t">And in this case, as I said, we don't really have labels per se, so I'm just going to give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=462" target="_blank">00:07:42.160</a></span> | <span class="t">everything a label of 0 just so we can use it with our existing infrastructure more easily.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=470" target="_blank">00:07:50.360</a></span> | <span class="t">Now because I'm in this case pointing at a folder that contains all of ImageNet, I certainly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=474" target="_blank">00:07:54.880</a></span> | <span class="t">don't want to wait for all of ImageNet to finish, to run an epoch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=478" target="_blank">00:07:58.420</a></span> | <span class="t">So here most of the time I would set keep% to 1 or 2%, and then I just generate a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=486" target="_blank">00:08:06.720</a></span> | <span class="t">of random numbers, and then I just keep those which are less than 0.02, and so that lets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=494" target="_blank">00:08:14.000</a></span> | <span class="t">me quickly sub-sample my rows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=501" target="_blank">00:08:21.720</a></span> | <span class="t">So we're going to use VGG16, and VGG16 is something that we haven't really looked at in this class,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=515" target="_blank">00:08:35.960</a></span> | <span class="t">but it's a very simple model where we take our normal, presumably 3-channel input, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=526" target="_blank">00:08:46.240</a></span> | <span class="t">we basically run it through a number of 3x3 convolutions, and then from time to time we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=535" target="_blank">00:08:55.200</a></span> | <span class="t">put it through a 2x2 MaxPool, and then we do a few more 3x3 convolutions, MaxPool, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=548" target="_blank">00:09:08.280</a></span> | <span class="t">on and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=550" target="_blank">00:09:10.160</a></span> | <span class="t">And then this is kind of our backbone, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=561" target="_blank">00:09:21.520</a></span> | <span class="t">And then we don't do an average pooling layer, an adaptive average pooling layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=567" target="_blank">00:09:27.560</a></span> | <span class="t">After a few of these we end up with this 7x7 grid as usual, I think it's about 7x7x512.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=576" target="_blank">00:09:36.760</a></span> | <span class="t">And so rather than average pooling we do something different, which is we flatten the whole thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=582" target="_blank">00:09:42.160</a></span> | <span class="t">So that spits out a very long vector of activations of size 7x7x512 if memory says correctly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=592" target="_blank">00:09:52.900</a></span> | <span class="t">And then that gets fed into two fully connected layers, each one of which has 4096 activations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=604" target="_blank">00:10:04.920</a></span> | <span class="t">and then one more fully connected layer which has however many classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=610" target="_blank">00:10:10.840</a></span> | <span class="t">So if you think about it, the weight matrix here is huge, it's 7x7x512x4096, and it's because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=625" target="_blank">00:10:25.440</a></span> | <span class="t">of that weight matrix really that VGG went out of favor pretty quickly, because it takes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=632" target="_blank">00:10:32.100</a></span> | <span class="t">a lot of memory, it takes a lot of computation, and it's really slow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=636" target="_blank">00:10:36.920</a></span> | <span class="t">And there's a lot of redundant stuff going on here, because really those 512 activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=644" target="_blank">00:10:44.040</a></span> | <span class="t">are not that specific to which of those 7x7 grid cells they're in, but when you have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=651" target="_blank">00:10:51.720</a></span> | <span class="t">entire weight matrix here of every possible combination, it treats all of them uniquely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=660" target="_blank">00:11:00.600</a></span> | <span class="t">And so that can also lead to generalization problems, because there's just a lot of weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=664" target="_blank">00:11:04.560</a></span> | <span class="t">and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=667" target="_blank">00:11:07.800</a></span> | <span class="t">My view is that the approach that's used in every modern network, which is here we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=674" target="_blank">00:11:14.840</a></span> | <span class="t">an adaptive average pooling in Keras that we know as a global average pooling, or in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=681" target="_blank">00:11:21.840</a></span> | <span class="t">fast.ai we generally do a concat pooling, which spits it straight down to a 512-long activation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=692" target="_blank">00:11:32.320</a></span> | <span class="t">I think that's throwing away too much geometry, so to me probably the correct answer is somewhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=699" target="_blank">00:11:39.000</a></span> | <span class="t">in between and would involve some kind of factored convolution or some kind of tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=705" target="_blank">00:11:45.160</a></span> | <span class="t">decomposition which maybe some of us can think about in the coming months.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=711" target="_blank">00:11:51.020</a></span> | <span class="t">So for now we've gone from one extreme, which is the adaptive average pooling, to the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=716" target="_blank">00:11:56.200</a></span> | <span class="t">extreme which is this huge flattened pooling connection layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=720" target="_blank">00:12:00.400</a></span> | <span class="t">So a couple of things which are interesting about VGG that make it still useful today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=728" target="_blank">00:12:08.200</a></span> | <span class="t">The first one is that there's more interesting layers going on here with most modern networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=738" target="_blank">00:12:18.000</a></span> | <span class="t">including the ResNet family.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=740" target="_blank">00:12:20.600</a></span> | <span class="t">The very first layer generally is a 7x7 pond, or something similar, which means we throw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=751" target="_blank">00:12:31.560</a></span> | <span class="t">away half the grid size straight away and so there's little opportunity to use the fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=759" target="_blank">00:12:39.120</a></span> | <span class="t">detail because we never do any computation with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=764" target="_blank">00:12:44.640</a></span> | <span class="t">And so that's a bit of a problem for things like segmentation or super resolution models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=772" target="_blank">00:12:52.080</a></span> | <span class="t">because the fine detail matters, we actually want to restore it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=777" target="_blank">00:12:57.400</a></span> | <span class="t">And then the second problem is that the adaptive average pooling layer entirely throws away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=783" target="_blank">00:13:03.800</a></span> | <span class="t">the geometry in the last few sections, which means that the rest of the model doesn't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=788" target="_blank">00:13:08.800</a></span> | <span class="t">have as much interest in learning the geometry as it otherwise might.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=793" target="_blank">00:13:13.560</a></span> | <span class="t">And so therefore for things which are dependent on position, any kind of localization based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=798" target="_blank">00:13:18.360</a></span> | <span class="t">approach to anything that requires generative modeling is going to be less effective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=802" target="_blank">00:13:22.800</a></span> | <span class="t">So one of the things I'm hoping you're hearing as I describe this is that probably none of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=808" target="_blank">00:13:28.080</a></span> | <span class="t">the existing architectures are actually ideal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=812" target="_blank">00:13:32.340</a></span> | <span class="t">We can invent a new one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=813" target="_blank">00:13:33.520</a></span> | <span class="t">And actually I just tried inventing a new one over the week which was to take the VGG</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=822" target="_blank">00:13:42.360</a></span> | <span class="t">thread and attach it to a ResNet backbone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=827" target="_blank">00:13:47.720</a></span> | <span class="t">And interestingly I found I actually got a slightly better classifier than a normal ResNet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=833" target="_blank">00:13:53.520</a></span> | <span class="t">but it also was something with a little bit more useful information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=837" target="_blank">00:13:57.640</a></span> | <span class="t">It took 5 or 10% longer to train, but nothing worth worrying about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=845" target="_blank">00:14:05.960</a></span> | <span class="t">I think maybe we couldn't in ResNet replace this as we've talked about briefly before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=850" target="_blank">00:14:10.040</a></span> | <span class="t">this very early convolution with something more like an inception stem which does a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=854" target="_blank">00:14:14.760</a></span> | <span class="t">more computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=856" target="_blank">00:14:16.160</a></span> | <span class="t">I think there's definitely room for some nice little tweaks to these architectures so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=862" target="_blank">00:14:22.820</a></span> | <span class="t">we can build some models which are maybe more versatile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=866" target="_blank">00:14:26.360</a></span> | <span class="t">At the moment people tend to build architectures that just do one thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=869" target="_blank">00:14:29.720</a></span> | <span class="t">They don't really think what am I throwing away in terms of opportunity because that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=875" target="_blank">00:14:35.120</a></span> | <span class="t">how publishing works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=876" target="_blank">00:14:36.120</a></span> | <span class="t">You know you publish like I've got the state-of-the-art in this one thing rather than I've created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=880" target="_blank">00:14:40.240</a></span> | <span class="t">something that's good at lots of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=883" target="_blank">00:14:43.480</a></span> | <span class="t">So for these reasons we're going to use VGG today even though it's ancient and it's missing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=889" target="_blank">00:14:49.020</a></span> | <span class="t">lots of great stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=890" target="_blank">00:14:50.760</a></span> | <span class="t">One thing we are going to do though is use a slightly more modern version which is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=895" target="_blank">00:14:55.200</a></span> | <span class="t">version of VGG where batch norm has been added after all the convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=900" target="_blank">00:15:00.400</a></span> | <span class="t">And so in fast.ai actually when you ask for a VGG network you always get the batch norm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=905" target="_blank">00:15:05.200</a></span> | <span class="t">one because that's basically always what you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=909" target="_blank">00:15:09.280</a></span> | <span class="t">So this is actually our VGG with batch norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=912" target="_blank">00:15:12.480</a></span> | <span class="t">There's a 16 and a 19.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=914" target="_blank">00:15:14.160</a></span> | <span class="t">The 19 is way bigger and heavier and doesn't really any better so no one really uses it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=923" target="_blank">00:15:23.480</a></span> | <span class="t">So we're going to go from 72x72, LR is low resolution input, Si is low resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=930" target="_blank">00:15:30.500</a></span> | <span class="t">We're going to initially scale it up by x2 with a batch size of 64 to get a 2x72, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=937" target="_blank">00:15:37.340</a></span> | <span class="t">1x44x144 output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=939" target="_blank">00:15:39.720</a></span> | <span class="t">So that's going to be our stage 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=946" target="_blank">00:15:46.120</a></span> | <span class="t">We'll create our own dataset for this and the dataset, it's very worthwhile looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=952" target="_blank">00:15:52.800</a></span> | <span class="t">inside the fastai.dataset module and seeing what's there because just about anything you'd</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=959" target="_blank">00:15:59.920</a></span> | <span class="t">want we probably have something that's almost what you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=964" target="_blank">00:16:04.120</a></span> | <span class="t">So in this case I want a dataset where my x's are images and my y's are also images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=970" target="_blank">00:16:10.880</a></span> | <span class="t">So there's already a files dataset we can inherit from where the x's are images and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=975" target="_blank">00:16:15.360</a></span> | <span class="t">then I just inherit from that and I just copied and pasted the get x and turned that into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=980" target="_blank">00:16:20.200</a></span> | <span class="t">get y so it just opens an image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=983" target="_blank">00:16:23.520</a></span> | <span class="t">So now I've got something where the x is an image and the y is an image and in both cases</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=987" target="_blank">00:16:27.760</a></span> | <span class="t">what we're passing in is an array of file names.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=991" target="_blank">00:16:31.240</a></span> | <span class="t">I'm going to do some data augmentation, obviously with all of ImageNet we don't really need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=997" target="_blank">00:16:37.320</a></span> | <span class="t">it, but this is mainly here for anybody who's using smaller datasets to make most of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1003" target="_blank">00:16:43.640</a></span> | <span class="t">Random dihedral is referring to every possible 90 degree rotation plus optional left/right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1010" target="_blank">00:16:50.240</a></span> | <span class="t">flipping, so the dihedral group of eight symmetries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1016" target="_blank">00:16:56.560</a></span> | <span class="t">Probably we don't use this transformation for ImageNet pictures because you don't normally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1021" target="_blank">00:17:01.440</a></span> | <span class="t">flip dogs upside down, but in this case we're not trying to classify whether it's a dog</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1027" target="_blank">00:17:07.480</a></span> | <span class="t">or a cat, we're just trying to keep the general structure of it, so actually every possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1033" target="_blank">00:17:13.640</a></span> | <span class="t">flip is a reasonably sensible thing to do for this problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1040" target="_blank">00:17:20.280</a></span> | <span class="t">So create a validation set in the usual way, and you can see I'm kind of using a few more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1046" target="_blank">00:17:26.360</a></span> | <span class="t">slightly lower level functions, generally speaking I just copy and paste them out of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1050" target="_blank">00:17:30.440</a></span> | <span class="t">the fast.ai source code to find the bits I want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1054" target="_blank">00:17:34.600</a></span> | <span class="t">So here's the bit which takes an array of validation set indexes and one or more arrays</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1063" target="_blank">00:17:43.480</a></span> | <span class="t">of variables and simply splits, so in this case this into a training and a validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1070" target="_blank">00:17:50.440</a></span> | <span class="t">set and this into a training and a validation set to give us our x's and y's.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1078" target="_blank">00:17:58.760</a></span> | <span class="t">Now in this case the x and y are the same, our image and our output are the same, we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1085" target="_blank">00:18:05.720</a></span> | <span class="t">going to use transformations to make one of them lower resolution, so that's why these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1090" target="_blank">00:18:10.720</a></span> | <span class="t">are the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1094" target="_blank">00:18:14.760</a></span> | <span class="t">So the next thing that we need to do is to create our transformations as per usual, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1104" target="_blank">00:18:24.880</a></span> | <span class="t">we're going to use this transform y parameter like we did for bounding boxes, but rather</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1110" target="_blank">00:18:30.440</a></span> | <span class="t">than use transform type.coordinate, we're going to use transform type.pixel, and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1118" target="_blank">00:18:38.320</a></span> | <span class="t">that tells our transformations framework that your y values are images with normal pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1127" target="_blank">00:18:47.160</a></span> | <span class="t">in them and so anything you do with the x you also need to do the y, do the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1134" target="_blank">00:18:54.200</a></span> | <span class="t">And you need to make sure any data representation transforms you use have the same parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1139" target="_blank">00:18:59.560</a></span> | <span class="t">as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1146" target="_blank">00:19:06.440</a></span> | <span class="t">So you can see the possible transform types, basically you've got classification, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1149" target="_blank">00:19:09.960</a></span> | <span class="t">we're about to use for segmentation in the second half of today, coordinates, no transformation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1155" target="_blank">00:19:15.040</a></span> | <span class="t">at all, or pixel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1160" target="_blank">00:19:20.480</a></span> | <span class="t">So once we've got a dataset class and some x and y training and validation sets, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1168" target="_blank">00:19:28.840</a></span> | <span class="t">a handy little method called get_datasets, which basically runs that constructor over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1174" target="_blank">00:19:34.760</a></span> | <span class="t">all the different things that you have to return all the datasets that you need in exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1179" target="_blank">00:19:39.560</a></span> | <span class="t">the right format to pass to a model data constructor, in this case the image data constructor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1186" target="_blank">00:19:46.560</a></span> | <span class="t">So we're kind of like going back under the covers of fast.ai a little bit and building</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1191" target="_blank">00:19:51.520</a></span> | <span class="t">it up from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1193" target="_blank">00:19:53.840</a></span> | <span class="t">And in the next few weeks this will all be wrapped up and refactored into something that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1198" target="_blank">00:19:58.400</a></span> | <span class="t">you can do in a single step in fast.ai, but the point of this class is to learn a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1203" target="_blank">00:20:03.000</a></span> | <span class="t">about going under the covers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1208" target="_blank">00:20:08.320</a></span> | <span class="t">So something we've briefly seen before is that when we take images in we transform them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1217" target="_blank">00:20:17.200</a></span> | <span class="t">not just with data augmentation, but we also move the channels dimension up to the start,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1223" target="_blank">00:20:23.800</a></span> | <span class="t">we subtract the mean, divide by the standard deviation, whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1227" target="_blank">00:20:27.800</a></span> | <span class="t">So if we want to be able to display those pictures that have come out of our datasets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1232" target="_blank">00:20:32.640</a></span> | <span class="t">or data loaders, we need to denormalize them, and so the model data objects dataset has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1238" target="_blank">00:20:38.840</a></span> | <span class="t">a denorm function that knows how to do that, so I'm just going to give that a short name</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1243" target="_blank">00:20:43.680</a></span> | <span class="t">for convenience.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1246" target="_blank">00:20:46.160</a></span> | <span class="t">So now I'm going to create a function that can show an image from a dataset, and if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1250" target="_blank">00:20:50.320</a></span> | <span class="t">pass in something saying this is a normalized image, then we'll denormalize it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1255" target="_blank">00:20:55.560</a></span> | <span class="t">So we can go ahead and have a look at that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1259" target="_blank">00:20:59.160</a></span> | <span class="t">You'll see here we've passed in size_low_res as our size for the transforms, and size_high_res</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1267" target="_blank">00:21:07.400</a></span> | <span class="t">as this is something new, the size_y parameter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1270" target="_blank">00:21:10.760</a></span> | <span class="t">So the two bits are going to get different sizes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1274" target="_blank">00:21:14.620</a></span> | <span class="t">And so here you can see the two different resolutions of our x and our y for a whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1280" target="_blank">00:21:20.240</a></span> | <span class="t">bunch of fish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1283" target="_blank">00:21:23.800</a></span> | <span class="t">As per usual, plot.subplots to create our two plots, and then we can just use the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1289" target="_blank">00:21:29.360</a></span> | <span class="t">axes that came back to put stuff next to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1297" target="_blank">00:21:37.980</a></span> | <span class="t">So we can then have a look at a few different versions of the data transformation, and there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1303" target="_blank">00:21:43.640</a></span> | <span class="t">you can see them being flipped in all different directions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1309" target="_blank">00:21:49.480</a></span> | <span class="t">So let's create our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1317" target="_blank">00:21:57.260</a></span> | <span class="t">So we're going to have an image coming in, a small image coming in, and we want to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1327" target="_blank">00:22:07.520</a></span> | <span class="t">a big image coming out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1332" target="_blank">00:22:12.720</a></span> | <span class="t">And so we need to do some computation between those two to calculate what the big image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1338" target="_blank">00:22:18.480</a></span> | <span class="t">would look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1340" target="_blank">00:22:20.000</a></span> | <span class="t">And so essentially there's kind of two ways of doing that computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1343" target="_blank">00:22:23.120</a></span> | <span class="t">We could first of all do some upsampling, and then do a few stride1 kind of layers to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1351" target="_blank">00:22:31.640</a></span> | <span class="t">do lots of computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1354" target="_blank">00:22:34.240</a></span> | <span class="t">Or we could first do lots of stride1 layers to do all the computation, and then at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1359" target="_blank">00:22:39.080</a></span> | <span class="t">end do some upsampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1362" target="_blank">00:22:42.760</a></span> | <span class="t">We're going to pick the second approach, because we want to do lots of computation on something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1368" target="_blank">00:22:48.160</a></span> | <span class="t">smaller because it's much faster to do it that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1373" target="_blank">00:22:53.160</a></span> | <span class="t">And also like all that computation we get to leverage during the upsampling process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1381" target="_blank">00:23:01.760</a></span> | <span class="t">So upsampling, we know a couple of possible ways to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1385" target="_blank">00:23:05.960</a></span> | <span class="t">We can use transposed or fractionally strided convolutions, or we can use nearest neighbor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1394" target="_blank">00:23:14.440</a></span> | <span class="t">upsampling, followed by a 1x1 conv.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1401" target="_blank">00:23:21.920</a></span> | <span class="t">And then in the do lots of computation section, we could just have a whole bunch of 3x3 cons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1410" target="_blank">00:23:30.400</a></span> | <span class="t">But in this case in particular, it seems likely that ResNet blocks are going to be better,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1417" target="_blank">00:23:37.000</a></span> | <span class="t">because really the output and the input are very similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1425" target="_blank">00:23:45.200</a></span> | <span class="t">So we really want a flow-through path that allows as little fussing around as possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1431" target="_blank">00:23:51.040</a></span> | <span class="t">except the minimal amount necessary to do our super-resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1435" target="_blank">00:23:55.760</a></span> | <span class="t">And so if we use ResNet blocks, then they have an identity path already.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1441" target="_blank">00:24:01.920</a></span> | <span class="t">So you could imagine the most simple version where it does a bilinear sampling kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1449" target="_blank">00:24:09.880</a></span> | <span class="t">approach or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1450" target="_blank">00:24:10.880</a></span> | <span class="t">It could basically just go through identity blocks all the way through, and then in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1454" target="_blank">00:24:14.080</a></span> | <span class="t">upsampling blocks just learn to take the averages of the inputs and get something that's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1459" target="_blank">00:24:19.400</a></span> | <span class="t">too terrible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1462" target="_blank">00:24:22.160</a></span> | <span class="t">So that's what we're going to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1463" target="_blank">00:24:23.160</a></span> | <span class="t">We're going to create something with 5 ResNet blocks, and then for each 2x scale-up we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1471" target="_blank">00:24:31.960</a></span> | <span class="t">to do, we'll have one upsampling block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1478" target="_blank">00:24:38.440</a></span> | <span class="t">So they're all going to consist of, obviously as per usual, convolution layers, possibly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1483" target="_blank">00:24:43.600</a></span> | <span class="t">with activation functions after many of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1486" target="_blank">00:24:46.760</a></span> | <span class="t">So I kind of like to put my standard convolution block into a function so I can refactor it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1493" target="_blank">00:24:53.840</a></span> | <span class="t">more easily.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1496" target="_blank">00:24:56.240</a></span> | <span class="t">As per usual I just won't worry about passing in padding and just calculate it directly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1500" target="_blank">00:25:00.560</a></span> | <span class="t">as kernel size over 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1504" target="_blank">00:25:04.340</a></span> | <span class="t">So one interesting thing about our little conv block here is that there's no batch norm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1509" target="_blank">00:25:09.720</a></span> | <span class="t">which is pretty unusual for ResNet-type models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1514" target="_blank">00:25:14.880</a></span> | <span class="t">And the reason there's no batch norm is because I'm stealing ideas from this fantastic recent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1520" target="_blank">00:25:20.560</a></span> | <span class="t">paper which actually won a recent competition in super-resolution performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1527" target="_blank">00:25:27.280</a></span> | <span class="t">And to see how good this paper is, here's kind of a previous state of the art, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1532" target="_blank">00:25:32.800</a></span> | <span class="t">SR ResNet, and what they've done here is they've zoomed way in to an upsampled kind of net</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1541" target="_blank">00:25:41.200</a></span> | <span class="t">or fence, this is the original.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1543" target="_blank">00:25:43.680</a></span> | <span class="t">And you can see in the previous best approach there's a whole lot of distortion and blurring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1549" target="_blank">00:25:49.080</a></span> | <span class="t">going on, whereas in their approach it's nearly perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1555" target="_blank">00:25:55.040</a></span> | <span class="t">So it was a really big step up this paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1559" target="_blank">00:25:59.520</a></span> | <span class="t">They call their model EDSR, Enhanced Deep Residual Networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1563" target="_blank">00:26:03.000</a></span> | <span class="t">And they did two things differently to the previous standard approaches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1570" target="_blank">00:26:10.280</a></span> | <span class="t">One was to take the ResNet block, this is a regular ResNet block, and throw away the batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1575" target="_blank">00:26:15.000</a></span> | <span class="t">norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1577" target="_blank">00:26:17.360</a></span> | <span class="t">So why would they throw away the batch norm?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1579" target="_blank">00:26:19.520</a></span> | <span class="t">Well the reason they would throw away the batch norm is because batch norm changes stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1585" target="_blank">00:26:25.980</a></span> | <span class="t">and we want a nice straight-through path that doesn't change stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1591" target="_blank">00:26:31.360</a></span> | <span class="t">So the idea basically here is if you don't want to fiddle with the input more than you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1596" target="_blank">00:26:36.200</a></span> | <span class="t">have to, then don't force it to have to calculate things like batch norm parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1601" target="_blank">00:26:41.120</a></span> | <span class="t">So throw away the batch norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1602" target="_blank">00:26:42.760</a></span> | <span class="t">And the second trick we'll see shortly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1606" target="_blank">00:26:46.000</a></span> | <span class="t">So here's a conv with no batch norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1609" target="_blank">00:26:49.640</a></span> | <span class="t">And so then we're going to create a residual block containing, as per usual, two convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1618" target="_blank">00:26:58.480</a></span> | <span class="t">And as you see in their approach, they don't even have a value after their second conv.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1623" target="_blank">00:27:03.520</a></span> | <span class="t">So that's why I've only got activation on the first one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1631" target="_blank">00:27:11.760</a></span> | <span class="t">So a couple of interesting things here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1636" target="_blank">00:27:16.460</a></span> | <span class="t">One is that this idea of having some kind of main ResNet path, like conv_relu_conv,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1646" target="_blank">00:27:26.280</a></span> | <span class="t">and then turning that into a relu block by adding it back to the identity, it's something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1650" target="_blank">00:27:30.840</a></span> | <span class="t">we do so often.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1651" target="_blank">00:27:31.840</a></span> | <span class="t">We've kind of factored it out into a tiny little module called res_sequential, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1656" target="_blank">00:27:36.880</a></span> | <span class="t">simply takes a bunch of layers that you want to put into your residual path, turns that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1664" target="_blank">00:27:44.660</a></span> | <span class="t">into a sequential model, runs it, and then adds it back to the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1670" target="_blank">00:27:50.560</a></span> | <span class="t">So with this little module we can now turn anything like conv_activation_conv into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1678" target="_blank">00:27:58.160</a></span> | <span class="t">ResNet block, just by wrapping it in res_sequential.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1684" target="_blank">00:28:04.960</a></span> | <span class="t">But that's not quite all I'm doing, because normally a res block just has that in its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1690" target="_blank">00:28:10.760</a></span> | <span class="t">forward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1691" target="_blank">00:28:11.760</a></span> | <span class="t">But I've also got that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1695" target="_blank">00:28:15.760</a></span> | <span class="t">What's res_scale?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1696" target="_blank">00:28:16.760</a></span> | <span class="t">Res_scale is the number 0.1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1700" target="_blank">00:28:20.040</a></span> | <span class="t">Why is it there?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1702" target="_blank">00:28:22.400</a></span> | <span class="t">I'm not sure anybody quite knows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1705" target="_blank">00:28:25.320</a></span> | <span class="t">But the short answer is that the guy who invented batchnorm also somewhat more recently did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1713" target="_blank">00:28:33.400</a></span> | <span class="t">a paper in which he showed, I think the first time, the ability to train imageNet in under</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1719" target="_blank">00:28:39.800</a></span> | <span class="t">an hour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1721" target="_blank">00:28:41.480</a></span> | <span class="t">And the way he did it was fire up lots and lots of machines and have them work in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1728" target="_blank">00:28:48.500</a></span> | <span class="t">to create really large batch sizes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1731" target="_blank">00:28:51.400</a></span> | <span class="t">Now generally when you increase the batch size by order n, you also increase the learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1736" target="_blank">00:28:56.880</a></span> | <span class="t">rate by order n to go with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1738" target="_blank">00:28:58.960</a></span> | <span class="t">So generally very large batch size training means very high learning rate training as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1744" target="_blank">00:29:04.200</a></span> | <span class="t">well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1745" target="_blank">00:29:05.200</a></span> | <span class="t">And he found that with these very large batch sizes of 8,000 plus, or even up to 32,000,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1753" target="_blank">00:29:13.240</a></span> | <span class="t">that at the start of training his activations would basically go straight to infinity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1758" target="_blank">00:29:18.760</a></span> | <span class="t">And a lot of other people found that, we actually found that when we were competing in Dawnbench</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1762" target="_blank">00:29:22.880</a></span> | <span class="t">both on the Cypher and the imageNet competitions that we really struggled to make the most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1768" target="_blank">00:29:28.920</a></span> | <span class="t">of even the eight GPUs that we were trying to take advantage of because of these challenges</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1774" target="_blank">00:29:34.920</a></span> | <span class="t">with these larger batch sizes and taking advantage of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1778" target="_blank">00:29:38.760</a></span> | <span class="t">So something that Christian found, this researcher, was that in the resNet blocks, if he multiplied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1783" target="_blank">00:29:43.920</a></span> | <span class="t">them by some number smaller than 1, something like 0.1 or 0.2, it really helped stabilize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1790" target="_blank">00:29:50.320</a></span> | <span class="t">training at the start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1793" target="_blank">00:29:53.760</a></span> | <span class="t">And that's kind of weird because mathematically it's kind of identical, because obviously</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1801" target="_blank">00:30:01.000</a></span> | <span class="t">whatever I'm multiplying it by here, I could just scale the weights by the opposite amount</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1807" target="_blank">00:30:07.560</a></span> | <span class="t">here and have the same number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1810" target="_blank">00:30:10.440</a></span> | <span class="t">So it's kind of like we're not dealing with abstract math, we're dealing with real optimization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1821" target="_blank">00:30:21.480</a></span> | <span class="t">problems and different initializations and learning rates and whatever else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1827" target="_blank">00:30:27.920</a></span> | <span class="t">And so the problem of weights disappearing off into infinity I guess generally is really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1835" target="_blank">00:30:35.280</a></span> | <span class="t">about the kind of discrete and finite nature of computers in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1842" target="_blank">00:30:42.040</a></span> | <span class="t">And so often these kind of little tricks can make the difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1846" target="_blank">00:30:46.800</a></span> | <span class="t">So in this case we're just kind of toning things down, at least based on our initialization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1855" target="_blank">00:30:55.040</a></span> | <span class="t">And so there are probably other ways to do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1858" target="_blank">00:30:58.400</a></span> | <span class="t">For example, one approach from some folks at Nvidia called Lars, L-A-R-S, which I briefly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1864" target="_blank">00:31:04.320</a></span> | <span class="t">mentioned last week, is an approach which uses discriminative learning rates calculated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1869" target="_blank">00:31:09.760</a></span> | <span class="t">in real time, basically looking at the ratio between the gradients and the activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1878" target="_blank">00:31:18.200</a></span> | <span class="t">to scale learning rates by layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1880" target="_blank">00:31:20.820</a></span> | <span class="t">And so they found that they didn't need this trick to scale up the batch sizes a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1890" target="_blank">00:31:30.000</a></span> | <span class="t">Maybe a different initialization would be all that's necessary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1895" target="_blank">00:31:35.060</a></span> | <span class="t">The reason I mention this is not so much because I think a lot of you are likely to want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1899" target="_blank">00:31:39.560</a></span> | <span class="t">train on massive clusters of computers, but rather that I think a lot of you want to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1905" target="_blank">00:31:45.200</a></span> | <span class="t">models quickly, and that means using high learning rates and ideally getting super-convergence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1911" target="_blank">00:31:51.800</a></span> | <span class="t">And I think these kinds of tricks, the tricks that we'll need to be able to get super-convergence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1918" target="_blank">00:31:58.880</a></span> | <span class="t">across more different architectures and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1922" target="_blank">00:32:02.640</a></span> | <span class="t">And other than Leslie Smith, no one else is really working on super-convergence other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1930" target="_blank">00:32:10.240</a></span> | <span class="t">than some fast AI students nowadays.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1932" target="_blank">00:32:12.640</a></span> | <span class="t">So these kinds of things about how do we train at very, very high learning rates, we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1937" target="_blank">00:32:17.120</a></span> | <span class="t">to have to be the ones who figure it out as far as I can tell nobody else cares yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1944" target="_blank">00:32:24.840</a></span> | <span class="t">So I think looking at the literature around training ImageNet in one hour, or more recently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1951" target="_blank">00:32:31.160</a></span> | <span class="t">there's now a train ImageNet in 15 minutes, these papers actually have some of the tricks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1957" target="_blank">00:32:37.720</a></span> | <span class="t">to allow us to train things at high learning rates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1960" target="_blank">00:32:40.960</a></span> | <span class="t">And so here's one of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1962" target="_blank">00:32:42.200</a></span> | <span class="t">And so interestingly other than the train ImageNet in one hour paper, the only other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1967" target="_blank">00:32:47.920</a></span> | <span class="t">place I've seen this mentioned was in this EDSR paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1973" target="_blank">00:32:53.280</a></span> | <span class="t">And it's really cool because people who win competitions, I just find them to be very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1980" target="_blank">00:33:00.640</a></span> | <span class="t">pragmatic and well-read.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1983" target="_blank">00:33:03.200</a></span> | <span class="t">They actually have to get things to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1985" target="_blank">00:33:05.420</a></span> | <span class="t">And so this paper describes an approach which actually worked better than anybody else's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1990" target="_blank">00:33:10.480</a></span> | <span class="t">approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1991" target="_blank">00:33:11.480</a></span> | <span class="t">And they did these pragmatic things like throw away batch norm and use this little scaling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=1997" target="_blank">00:33:17.120</a></span> | <span class="t">factor which almost nobody else seems to know about and stuff like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2003" target="_blank">00:33:23.000</a></span> | <span class="t">So that's where the point one comes from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2006" target="_blank">00:33:26.400</a></span> | <span class="t">So basically our super-resolution ResNet is going to do a convolution to go from our three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2012" target="_blank">00:33:32.960</a></span> | <span class="t">channels to 64 channels just to richen up the space a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2016" target="_blank">00:33:36.760</a></span> | <span class="t">Oh sorry, I've got actually 8, not 5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2019" target="_blank">00:33:39.920</a></span> | <span class="t">Eight lots of these res blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2023" target="_blank">00:33:43.560</a></span> | <span class="t">Remember every one of these res blocks is Stripe 1, so the grid size doesn't change,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2028" target="_blank">00:33:48.880</a></span> | <span class="t">the number of filters doesn't change, it's just 64 all the way through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2034" target="_blank">00:33:54.080</a></span> | <span class="t">We'll do one more convolution and then we'll do our up-sampling by however much scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2038" target="_blank">00:33:58.800</a></span> | <span class="t">we asked for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2041" target="_blank">00:34:01.160</a></span> | <span class="t">And then something I've added which is a little idea is just one batch norm here because it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2046" target="_blank">00:34:06.720</a></span> | <span class="t">kind of felt like it might be helpful just to scale the last layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2051" target="_blank">00:34:11.560</a></span> | <span class="t">And then finally a conv to go back to the three channels we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2056" target="_blank">00:34:16.120</a></span> | <span class="t">So you can see that's basically here's lots and lots of computation and then a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2060" target="_blank">00:34:20.960</a></span> | <span class="t">bit of up-sampling just like we kind of described.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2072" target="_blank">00:34:32.200</a></span> | <span class="t">So the only other piece here then is -- and also just to mention as you can see as I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2078" target="_blank">00:34:38.640</a></span> | <span class="t">tending to do now, this whole thing is done by creating just a list of layers and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2084" target="_blank">00:34:44.800</a></span> | <span class="t">at the end turning that into a sequential model, and so my forward function is as simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2089" target="_blank">00:34:49.920</a></span> | <span class="t">as can be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2093" target="_blank">00:34:53.120</a></span> | <span class="t">So here's our up-sampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2095" target="_blank">00:34:55.800</a></span> | <span class="t">And up-sampling is a bit interesting because it is not doing either of these two things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2105" target="_blank">00:35:05.680</a></span> | <span class="t">So let's talk a bit about up-sampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2113" target="_blank">00:35:13.820</a></span> | <span class="t">Here's a picture from the paper, not from the competition-winning paper but from this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2118" target="_blank">00:35:18.040</a></span> | <span class="t">original paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2120" target="_blank">00:35:20.480</a></span> | <span class="t">And so they're saying our approach is so much better, but look at their approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2125" target="_blank">00:35:25.040</a></span> | <span class="t">It's got goddamn artifacts in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2130" target="_blank">00:35:30.000</a></span> | <span class="t">These just pop up everywhere, don't they?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2131" target="_blank">00:35:31.800</a></span> | <span class="t">And so one of the reasons for this is that they use transposed convolutions, and we all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2135" target="_blank">00:35:35.960</a></span> | <span class="t">know don't use transposed convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2140" target="_blank">00:35:40.840</a></span> | <span class="t">So here are transposed convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2142" target="_blank">00:35:42.600</a></span> | <span class="t">This is from this fantastic convolutional arithmetic paper that was shown also in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2147" target="_blank">00:35:47.640</a></span> | <span class="t">Theano docs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2148" target="_blank">00:35:48.720</a></span> | <span class="t">If we're going from the blue is the original image, so a 3x3 image up to a 5x5 image, or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2155" target="_blank">00:35:55.760</a></span> | <span class="t">a 6x6 if we added a layer of padding, then all a transposed convolution does is it uses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2161" target="_blank">00:36:01.520</a></span> | <span class="t">a regular 3x3 conv, but it sticks white 0 pixels between every pair of pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2170" target="_blank">00:36:10.320</a></span> | <span class="t">So that makes the input image bigger and when we run this convolution up over it, it therefore</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2174" target="_blank">00:36:14.680</a></span> | <span class="t">gives us a larger output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2177" target="_blank">00:36:17.240</a></span> | <span class="t">But that's obviously stupid because when we get here, for example, of the 9 pixels coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2183" target="_blank">00:36:23.480</a></span> | <span class="t">in, 8 of them are 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2186" target="_blank">00:36:26.200</a></span> | <span class="t">So we're just wasting a whole lot of computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2188" target="_blank">00:36:28.960</a></span> | <span class="t">And then on the other hand, if we're slightly off over here, then 4 of our 9 are non-zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2195" target="_blank">00:36:35.080</a></span> | <span class="t">But yet we only have one filter, like one kernel to use, so it can't change depending</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2202" target="_blank">00:36:42.600</a></span> | <span class="t">on how many zeros are coming in, so it has to be suitable for both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2208" target="_blank">00:36:48.640</a></span> | <span class="t">And it's just not possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2210" target="_blank">00:36:50.680</a></span> | <span class="t">So we end up with these artifacts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2213" target="_blank">00:36:53.720</a></span> | <span class="t">So one approach we've learned to make it a bit better is to not put white things here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2219" target="_blank">00:36:59.320</a></span> | <span class="t">but instead to copy this pixel's value to each of these three locations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2227" target="_blank">00:37:07.240</a></span> | <span class="t">That's certainly a bit better, but it's still pretty crappy because now still when we get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2231" target="_blank">00:37:11.480</a></span> | <span class="t">to these 9 here, 4 of them are exactly the same number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2237" target="_blank">00:37:17.160</a></span> | <span class="t">And when we move across 1, then now we've got a different situation entirely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2245" target="_blank">00:37:25.200</a></span> | <span class="t">And so depending on where we are, in particular if we're here, there's going to be a lot less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2250" target="_blank">00:37:30.440</a></span> | <span class="t">repetition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2251" target="_blank">00:37:31.480</a></span> | <span class="t">So again we have this problem where there's wasted computation and too much structure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2256" target="_blank">00:37:36.640</a></span> | <span class="t">in the data and it's going to lead to artifacts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2259" target="_blank">00:37:39.480</a></span> | <span class="t">So up-sampling is better than transposed convolutions, it's better to copy them rather than replace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2265" target="_blank">00:37:45.160</a></span> | <span class="t">them with zeros, but it's still not quite good enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2270" target="_blank">00:37:50.220</a></span> | <span class="t">So instead we're going to do the pixel shuffle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2280" target="_blank">00:38:00.640</a></span> | <span class="t">So the pixel shuffle is an operation in this sub-pixel convolutional neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2287" target="_blank">00:38:07.160</a></span> | <span class="t">And it's a little bit mind-bending, but it's kind of fascinating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2292" target="_blank">00:38:12.900</a></span> | <span class="t">And so we start with our input, we go through some convolutions to create some feature maps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2298" target="_blank">00:38:18.200</a></span> | <span class="t">for a while until eventually we get to layer i-1, which has n i-1 feature maps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2307" target="_blank">00:38:27.800</a></span> | <span class="t">We're going to do another 3x3 conv.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2309" target="_blank">00:38:29.960</a></span> | <span class="t">And our goal here is to go from a 7x7 grid cell, we're going to go a 3x3 upscaling, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2316" target="_blank">00:38:36.960</a></span> | <span class="t">we're going to go up to a 21x21 grid cell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2321" target="_blank">00:38:41.400</a></span> | <span class="t">So what's another way we could do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2325" target="_blank">00:38:45.560</a></span> | <span class="t">To make it simpler, let's just pick one face, just one filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2330" target="_blank">00:38:50.700</a></span> | <span class="t">So we'll just take the topmost filter and just do a convolution over that just to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2334" target="_blank">00:38:54.720</a></span> | <span class="t">what happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2336" target="_blank">00:38:56.120</a></span> | <span class="t">And what we're going to do is we're going to use a convolution where the kernel size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2342" target="_blank">00:39:02.840</a></span> | <span class="t">the number of filters is 9 times bigger than we, strictly speaking, need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2352" target="_blank">00:39:12.200</a></span> | <span class="t">So if we needed 64 filters, we're actually going to do 64 times 9 filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2360" target="_blank">00:39:20.600</a></span> | <span class="t">Why is that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2361" target="_blank">00:39:21.840</a></span> | <span class="t">And so here r is the scale factor, so 3, so r squared, 3 squared is 9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2367" target="_blank">00:39:27.980</a></span> | <span class="t">So here are the 9 filters to cover one of these input layers, one of these input slices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2378" target="_blank">00:39:38.120</a></span> | <span class="t">But what we can do is we started with 7x7 and we turned it into 7x7x9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2387" target="_blank">00:39:47.240</a></span> | <span class="t">Well the output that we want is equal to 7x3 by 7x3, so in other words there's an equal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2398" target="_blank">00:39:58.160</a></span> | <span class="t">number of pixels here, or activations here, as there are r activations here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2404" target="_blank">00:40:04.100</a></span> | <span class="t">So we can literally reshuffle these 7x7x9 activations to create this 7x3x7x3 map.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2417" target="_blank">00:40:17.320</a></span> | <span class="t">And so what we're going to do is we're going to take one little tube here, the top left</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2421" target="_blank">00:40:21.920</a></span> | <span class="t">hand of each grid, and we're going to put the purple one up in the top left, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2429" target="_blank">00:40:29.280</a></span> | <span class="t">the blue one, one to the right, and then the light blue one, one to the right of that, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2435" target="_blank">00:40:35.440</a></span> | <span class="t">then the slightly darker blue one in the middle of the far left, the green one in the middle,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2440" target="_blank">00:40:40.920</a></span> | <span class="t">and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2441" target="_blank">00:40:41.920</a></span> | <span class="t">So each of these 9 cells in the top left are going to end up in this little 3x3 section</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2449" target="_blank">00:40:49.320</a></span> | <span class="t">of our grid.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2451" target="_blank">00:40:51.640</a></span> | <span class="t">And then we're going to take 2, 1 and take all of those 9 and move them to these 3x3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2458" target="_blank">00:40:58.760</a></span> | <span class="t">part of the grid, and so on and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2462" target="_blank">00:41:02.160</a></span> | <span class="t">And so we're going to end up having every one of these 7x7x9 activations inside this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2468" target="_blank">00:41:08.000</a></span> | <span class="t">7x3x7x3 image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2473" target="_blank">00:41:13.360</a></span> | <span class="t">So the first thing to realize is, yes of course this works under some definition of works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2479" target="_blank">00:41:19.280</a></span> | <span class="t">because we have a learnable convolution here, and it's going to get some gradients, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2485" target="_blank">00:41:25.440</a></span> | <span class="t">is going to do the best job it can of filling in the correct activation such that this output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2490" target="_blank">00:41:30.880</a></span> | <span class="t">is the thing we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2493" target="_blank">00:41:33.720</a></span> | <span class="t">So the first step is to realize there's nothing particularly magical here, we can create any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2500" target="_blank">00:41:40.360</a></span> | <span class="t">architecture we like, we can move things around anyhow we want to, and our weights in the convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2506" target="_blank">00:41:46.640</a></span> | <span class="t">will do their best to do all we asked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2509" target="_blank">00:41:49.040</a></span> | <span class="t">The real question is, is it a good idea?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2512" target="_blank">00:41:52.760</a></span> | <span class="t">Is this an easier thing for it to do, and a more flexible thing for it to do, than the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2518" target="_blank">00:41:58.680</a></span> | <span class="t">transposed convolution or the upsampling followed by 1x1 conv?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2524" target="_blank">00:42:04.440</a></span> | <span class="t">And the short answer is, yes it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2527" target="_blank">00:42:07.480</a></span> | <span class="t">And the reason it's better in short is that the convolution here is happening in the low</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2533" target="_blank">00:42:13.760</a></span> | <span class="t">resolution 7x7 space, which is quite efficient, whereas if we first of all upsampled and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2541" target="_blank">00:42:21.160</a></span> | <span class="t">did our conv, then our conv would be happening in the 21x21 space, which is a lot of computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2550" target="_blank">00:42:30.960</a></span> | <span class="t">And furthermore as we discussed, there's a lot of replication and redundancy in the nearest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2555" target="_blank">00:42:35.880</a></span> | <span class="t">neighbor upsampled version.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2560" target="_blank">00:42:40.840</a></span> | <span class="t">So they actually show in this paper, in fact I think they have a follow-up technical note</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2565" target="_blank">00:42:45.160</a></span> | <span class="t">where they provide some more mathematical details as to exactly what work is being done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2571" target="_blank">00:42:51.080</a></span> | <span class="t">and show that the work really is more efficient this way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2578" target="_blank">00:42:58.480</a></span> | <span class="t">So that's what we're going to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2580" target="_blank">00:43:00.280</a></span> | <span class="t">So for our upsampling we're going to have two steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2582" target="_blank">00:43:02.880</a></span> | <span class="t">The first will be a 3x3 conv with R^2 times more channels than we originally wanted, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2591" target="_blank">00:43:11.920</a></span> | <span class="t">then a pixel shuffle operation which moves everything in each grid cell into the little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2600" target="_blank">00:43:20.880</a></span> | <span class="t">R/R grids that are located throughout here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2605" target="_blank">00:43:25.880</a></span> | <span class="t">So here it is, it's one line of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2611" target="_blank">00:43:31.200</a></span> | <span class="t">And so here's the conv from number of in to number of filters out times 4, because we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2617" target="_blank">00:43:37.400</a></span> | <span class="t">doing a scale2 upsample, so 2^2 is 4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2623" target="_blank">00:43:43.560</a></span> | <span class="t">So that's our convolution, and then here is our pixel shuffle, it's built into PyTorch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2629" target="_blank">00:43:49.320</a></span> | <span class="t">Pixel shuffle is the thing that moves each thing into its right spot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2634" target="_blank">00:43:54.960</a></span> | <span class="t">So that will increase, will upsample by a scale factor of 2, and so we need to do that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2642" target="_blank">00:44:02.800</a></span> | <span class="t">log base2 scale times, so if scale is 4, then we have to do it 2 times to go 2 times 2 bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2652" target="_blank">00:44:12.200</a></span> | <span class="t">So that's what this upsample here does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2657" target="_blank">00:44:17.840</a></span> | <span class="t">Great, guess what?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2664" target="_blank">00:44:24.240</a></span> | <span class="t">That does not get rid of the checkerboard patterns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2667" target="_blank">00:44:27.440</a></span> | <span class="t">We still have checkerboard patterns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2670" target="_blank">00:44:30.580</a></span> | <span class="t">So I'm sure in great fury and frustration, this same team from Twitter, I think this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2675" target="_blank">00:44:35.040</a></span> | <span class="t">was back when they used to be at a startup called MagicPony that Twitter bought, came</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2679" target="_blank">00:44:39.500</a></span> | <span class="t">back again with another paper saying, okay, this time we've got rid of the checkerboard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2692" target="_blank">00:44:52.760</a></span> | <span class="t">So why do we still have, as you can see here, we still have a checkerboard?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2700" target="_blank">00:45:00.080</a></span> | <span class="t">And so the reason we still have a checkerboard, even after doing this, is that when we randomly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2707" target="_blank">00:45:07.300</a></span> | <span class="t">initialize this convolutional kernel at the start, it means that each of these 9 pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2713" target="_blank">00:45:13.840</a></span> | <span class="t">in this little 3x3 grid over here are going to be totally randomly different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2719" target="_blank">00:45:19.320</a></span> | <span class="t">But then the next set of 3 pixels will be randomly different to each other, but will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2724" target="_blank">00:45:24.840</a></span> | <span class="t">be very similar to the corresponding pixel in the previous 3x3 section.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2729" target="_blank">00:45:29.520</a></span> | <span class="t">So we're going to have repeating 3x3 things all the way across.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2733" target="_blank">00:45:33.880</a></span> | <span class="t">And so then as we try to learn something better, it's starting from this repeating 3x3 starting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2740" target="_blank">00:45:40.720</a></span> | <span class="t">point, which is not what we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2744" target="_blank">00:45:44.300</a></span> | <span class="t">What we actually would want is for these 3x3 pixels to be the same to start with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2751" target="_blank">00:45:51.100</a></span> | <span class="t">So to make these 3x3 pixels the same, we would need to make these 9 channels the same here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2759" target="_blank">00:45:59.440</a></span> | <span class="t">For each filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2761" target="_blank">00:46:01.760</a></span> | <span class="t">And so the solution, and this paper is very simple, is that when we initialize this convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2770" target="_blank">00:46:10.980</a></span> | <span class="t">at the start, when we randomly initialize it, we don't totally randomly initialize it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2775" target="_blank">00:46:15.740</a></span> | <span class="t">We randomly initialize one of the R^2 sets of channels, and then we copy that to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2783" target="_blank">00:46:23.620</a></span> | <span class="t">other R^2, so they're all the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2786" target="_blank">00:46:26.800</a></span> | <span class="t">And that way, initially, each of these 3x3s will be the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2791" target="_blank">00:46:31.900</a></span> | <span class="t">And so that is called IC&R, and that's what we're going to use in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2802" target="_blank">00:46:42.420</a></span> | <span class="t">So before we do, let's take a quick look.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2805" target="_blank">00:46:45.140</a></span> | <span class="t">So we've got this super resolution ResNet, which does lots of computation with lots of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2810" target="_blank">00:46:50.600</a></span> | <span class="t">ResNet blocks, and then it does some up-sampling and gets our final 3 channels out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2817" target="_blank">00:46:57.020</a></span> | <span class="t">And then to make life faster, we're going to run this in parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2823" target="_blank">00:47:03.140</a></span> | <span class="t">One reason we want to run it in parallel is because Dorado told us that he has 6 GPUs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2828" target="_blank">00:47:08.960</a></span> | <span class="t">and this is what his computer looks like right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2833" target="_blank">00:47:13.240</a></span> | <span class="t">And so I'm sure anybody who has more than one GPU has had this experience before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2839" target="_blank">00:47:19.900</a></span> | <span class="t">So how do we get these men working together?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2847" target="_blank">00:47:27.700</a></span> | <span class="t">All you need to do is to take your PyTorch module and wrap it with nn.data_parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2857" target="_blank">00:47:37.220</a></span> | <span class="t">And once you've done that, it copies it to each of your GPUs and will automatically run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2863" target="_blank">00:47:43.580</a></span> | <span class="t">it in parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2865" target="_blank">00:47:45.820</a></span> | <span class="t">It scales pretty well to 2 GPUs, okay to 3 GPUs, better than nothing to 4 GPUs, and beyond</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2874" target="_blank">00:47:54.580</a></span> | <span class="t">that performance starts to go backwards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2880" target="_blank">00:48:00.140</a></span> | <span class="t">By default it will copy it to all of your GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2883" target="_blank">00:48:03.220</a></span> | <span class="t">You can add an array of GPUs, otherwise if you want to avoid getting in trouble, for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2888" target="_blank">00:48:08.940</a></span> | <span class="t">example I have to share our box with Yannette, and if I didn't put this here, then she would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2893" target="_blank">00:48:13.340</a></span> | <span class="t">be yelling at me right now, or maybe boycotting my class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2897" target="_blank">00:48:17.720</a></span> | <span class="t">So this is how you avoid getting into trouble with Yannette.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2902" target="_blank">00:48:22.740</a></span> | <span class="t">So one thing to be aware of here is that once you do this, it actually modifies your module.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2909" target="_blank">00:48:29.460</a></span> | <span class="t">So if you now print out your module, let's say prohibuously it was just an nn.sequential,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2914" target="_blank">00:48:34.140</a></span> | <span class="t">now you'll find it's an nn.sequential embedded inside a module called module.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2923" target="_blank">00:48:43.020</a></span> | <span class="t">And so in other words, if you save something which you had nn.data_parallel, and then try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2929" target="_blank">00:48:49.580</a></span> | <span class="t">to load it back into something that you hadn't, nn.beta_parallel, it'll say it doesn't match</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2934" target="_blank">00:48:54.580</a></span> | <span class="t">up because one of them is embedded inside this module attribute and the other one isn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2940" target="_blank">00:49:00.820</a></span> | <span class="t">It may also depend even on which GPU IDs you had it copied to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2947" target="_blank">00:49:07.020</a></span> | <span class="t">So two possible solutions, one is don't save the module m, but instead save the module attribute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2956" target="_blank">00:49:16.380</a></span> | <span class="t">m.module, because that's actually the non-data parallel bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2961" target="_blank">00:49:21.860</a></span> | <span class="t">Or always put it on the same GPU IDs and use data parallel and load and save that every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2968" target="_blank">00:49:28.540</a></span> | <span class="t">time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2969" target="_blank">00:49:29.540</a></span> | <span class="t">That's what I was using.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2970" target="_blank">00:49:30.540</a></span> | <span class="t">This would be an easy thing for me to fix automatically in fast.ai and I'll do it pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2975" target="_blank">00:49:35.060</a></span> | <span class="t">soon so it'll look for that module attribute and deal with it automatically, but for now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2981" target="_blank">00:49:41.140</a></span> | <span class="t">we have to do it manually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2982" target="_blank">00:49:42.140</a></span> | <span class="t">It's probably useful to know what's going on behind the scenes anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2986" target="_blank">00:49:46.720</a></span> | <span class="t">So we've got our module, I find it'll run like 50% or 60% faster on a 1080ti.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=2994" target="_blank">00:49:54.340</a></span> | <span class="t">If you're running on Volta, it actually parallelizes a bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3000" target="_blank">00:50:00.580</a></span> | <span class="t">There are much faster ways to parallelize, but this is a super easy way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3006" target="_blank">00:50:06.260</a></span> | <span class="t">So we create our learner in the usual way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3008" target="_blank">00:50:08.980</a></span> | <span class="t">We could use mse_loss here, so that's just going to compare the pixels of the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3013" target="_blank">00:50:13.340</a></span> | <span class="t">to the pixels that we expected, and we can run our learning rate finder and we can train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3019" target="_blank">00:50:19.360</a></span> | <span class="t">it for a while, and here's our input and here's our output, and you can see that what we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3027" target="_blank">00:50:27.420</a></span> | <span class="t">managed to do is to train a very advanced residual convolutional network that's learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3032" target="_blank">00:50:32.500</a></span> | <span class="t">to blur things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3036" target="_blank">00:50:36.100</a></span> | <span class="t">Why is that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3037" target="_blank">00:50:37.100</a></span> | <span class="t">Well because it's what we asked for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3038" target="_blank">00:50:38.540</a></span> | <span class="t">We said to minimize mse_loss, an mse_loss between pixels, really the best way to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3045" target="_blank">00:50:45.900</a></span> | <span class="t">that is just average the pixels, i.e. to blur it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3050" target="_blank">00:50:50.400</a></span> | <span class="t">So that's why pixel_loss is no good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3052" target="_blank">00:50:52.620</a></span> | <span class="t">So we want to use our perceptual loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3056" target="_blank">00:50:56.980</a></span> | <span class="t">So let's try perceptual loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3060" target="_blank">00:51:00.120</a></span> | <span class="t">So with perceptual loss, we're basically going to take our VGG network, and just like we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3066" target="_blank">00:51:06.260</a></span> | <span class="t">did last week, we're going to find the block index just before we get a max pool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3074" target="_blank">00:51:14.120</a></span> | <span class="t">So here are the ends of each block of the same grid size, and if we just print them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3080" target="_blank">00:51:20.500</a></span> | <span class="t">out as we'd expect, every one of those is a value module.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3086" target="_blank">00:51:26.040</a></span> | <span class="t">And so in this case, these last two blocks are less interesting to us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3092" target="_blank">00:51:32.440</a></span> | <span class="t">The grid size there is small enough, coarse enough that it's not as useful for super resolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3099" target="_blank">00:51:39.580</a></span> | <span class="t">so we're just going to use the first three.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3102" target="_blank">00:51:42.380</a></span> | <span class="t">And so just to save unnecessary computation, we're just going to use those first 23 layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3107" target="_blank">00:51:47.300</a></span> | <span class="t">for VGG, we'll throw away the rest, we'll stick it on the GPU, we're not going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3114" target="_blank">00:51:54.340</a></span> | <span class="t">training this VGG model at all, we're just using it to compare activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3119" target="_blank">00:51:59.740</a></span> | <span class="t">So we'll stick it in eval mode, and we will set it to not trainable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3127" target="_blank">00:52:07.540</a></span> | <span class="t">Just like last week, we'll use a save_features class to do a forward hook, which saves the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3133" target="_blank">00:52:13.940</a></span> | <span class="t">output activations at each of those layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3137" target="_blank">00:52:17.340</a></span> | <span class="t">And so now we've got everything we need to create our perceptual loss, or as I call it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3141" target="_blank">00:52:21.180</a></span> | <span class="t">here, feature_loss_plus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3144" target="_blank">00:52:24.660</a></span> | <span class="t">And so we're going to pass in a list of layer IDs, the layers where we want the content</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3152" target="_blank">00:52:32.160</a></span> | <span class="t">loss to be calculated, an array of weights, a list of weights for each of those layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3159" target="_blank">00:52:39.580</a></span> | <span class="t">So we can just go through each of those layer IDs and create an object which has got the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3166" target="_blank">00:52:46.180</a></span> | <span class="t">hook function, forward hook function to store the activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3169" target="_blank">00:52:49.860</a></span> | <span class="t">And so in our forward, then we can just go ahead and call the forward pass of our model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3178" target="_blank">00:52:58.220</a></span> | <span class="t">with the target, so the target is the high res image we're trying to create.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3182" target="_blank">00:53:02.620</a></span> | <span class="t">And so the reason we do that is because that's going to then call that hook function and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3186" target="_blank">00:53:06.860</a></span> | <span class="t">store in self.save_features the activations we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3194" target="_blank">00:53:14.060</a></span> | <span class="t">Now we're going to need to do that for our Confinet output as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3200" target="_blank">00:53:20.540</a></span> | <span class="t">So we need to clone these because otherwise the Confinet output is going to go ahead and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3204" target="_blank">00:53:24.780</a></span> | <span class="t">just plobber what we already had.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3207" target="_blank">00:53:27.980</a></span> | <span class="t">So now we can do the same thing for the Confinet output, which is the input to the loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3214" target="_blank">00:53:34.180</a></span> | <span class="t">And so now we've got those two things, we can zip them all together along with the weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3220" target="_blank">00:53:40.500</a></span> | <span class="t">So we've got inputs, targets, weights, and then we can do the L1 loss between the inputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3225" target="_blank">00:53:45.420</a></span> | <span class="t">and the targets and multiply by the layer weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3228" target="_blank">00:53:48.820</a></span> | <span class="t">The only other thing I do is I also grab the pixel loss, but I weight it down quite a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3237" target="_blank">00:53:57.100</a></span> | <span class="t">And most people don't do this, I haven't seen papers that do this, but in my opinion it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3242" target="_blank">00:54:02.260</a></span> | <span class="t">maybe a little bit better because you've got the perceptual content loss activation stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3249" target="_blank">00:54:09.860</a></span> | <span class="t">but at the finest level it also cares about the individual pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3258" target="_blank">00:54:18.660</a></span> | <span class="t">So that's our loss function, we create our super resolution ResNet, telling it how much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3264" target="_blank">00:54:24.060</a></span> | <span class="t">to scale up by.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3268" target="_blank">00:54:28.060</a></span> | <span class="t">And then we're going to do our ICNR initialization of that pixel shuffle convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3278" target="_blank">00:54:38.820</a></span> | <span class="t">So this is very, very boring code, I actually stole it from somebody else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3286" target="_blank">00:54:46.840</a></span> | <span class="t">Literally all it does is just say, okay, you've got some weight tensor x that you want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3293" target="_blank">00:54:53.500</a></span> | <span class="t">initialize, so we're going to treat it as if it had a number of number of features divided</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3301" target="_blank">00:55:01.300</a></span> | <span class="t">by scale squared features in practice, so this might be 2 squared, it could be 4, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3311" target="_blank">00:55:11.020</a></span> | <span class="t">we actually want to keep one set of them and then copy them 4 times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3316" target="_blank">00:55:16.960</a></span> | <span class="t">So we divide it by 4, and we create something of that size, and we initialize that with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3322" target="_blank">00:55:22.620</a></span> | <span class="t">a default timing normal initialization, and then we just make scale squared copies of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3331" target="_blank">00:55:31.460</a></span> | <span class="t">it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3332" target="_blank">00:55:32.460</a></span> | <span class="t">And the rest of it is just moving axes around a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3336" target="_blank">00:55:36.220</a></span> | <span class="t">So that's going to return a new weight matrix where each initialized subkernel is repeated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3345" target="_blank">00:55:45.740</a></span> | <span class="t">R squared or scale squared times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3349" target="_blank">00:55:49.780</a></span> | <span class="t">So that details don't matter very much, all that matters here is that I just looked through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3353" target="_blank">00:55:53.760</a></span> | <span class="t">to find what was the actual layer, the conv layer just before the pixel shuffle, and stored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3360" target="_blank">00:56:00.820</a></span> | <span class="t">it away, and then I called ICNR on its weight matrix to get my new weight matrix, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3367" target="_blank">00:56:07.100</a></span> | <span class="t">I copied that new weight matrix back into that layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3373" target="_blank">00:56:13.140</a></span> | <span class="t">So as you can see, I went to quite a lot of trouble in this exercise to really try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3380" target="_blank">00:56:20.660</a></span> | <span class="t">implement all the best practices, and I kind of tend to do things a bit one extreme or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3385" target="_blank">00:56:25.900</a></span> | <span class="t">the other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3386" target="_blank">00:56:26.900</a></span> | <span class="t">I show you a really hacky version that only slightly works, or I go to the nth degree</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3390" target="_blank">00:56:30.420</a></span> | <span class="t">to make it work really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3392" target="_blank">00:56:32.860</a></span> | <span class="t">So this is a version where I'm claiming that this is pretty much a state-of-the-art implementation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3397" target="_blank">00:56:37.940</a></span> | <span class="t">it's a competition-winning approach, and the reason I'm doing that is because I think this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3406" target="_blank">00:56:46.220</a></span> | <span class="t">is one of those rare papers where they actually get a lot of the details right, and I kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3411" target="_blank">00:56:51.180</a></span> | <span class="t">of want you to get a feel of what it feels like to get all the details right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3416" target="_blank">00:56:56.580</a></span> | <span class="t">And remember, getting the details right is the difference between this hideous blurry</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3422" target="_blank">00:57:02.220</a></span> | <span class="t">mess and this really pretty exquisite result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3434" target="_blank">00:57:14.780</a></span> | <span class="t">So we're going to have to do theta parallel on that again, we're going to set our criterion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3439" target="_blank">00:57:19.260</a></span> | <span class="t">to be feature loss using our VGG model, grab the first few blocks, and these are sets of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3445" target="_blank">00:57:25.500</a></span> | <span class="t">layer weights that I found worked pretty well, do a learning rate finder, fit it for a while,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3454" target="_blank">00:57:34.580</a></span> | <span class="t">and I fit all around for a little while trying to get some of these details right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3460" target="_blank">00:57:40.700</a></span> | <span class="t">But here's my favorite part of the paper, what happens next, now that we've done it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3468" target="_blank">00:57:48.260</a></span> | <span class="t">for scale=2, progressive resizing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3475" target="_blank">00:57:55.180</a></span> | <span class="t">So progressive resizing is the trick that let us get the best single computer result</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3480" target="_blank">00:58:00.540</a></span> | <span class="t">for ImageNet training on Dawnbench.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3482" target="_blank">00:58:02.740</a></span> | <span class="t">This idea is starting small, gradually making bigger, and in two papers that have used this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3487" target="_blank">00:58:07.860</a></span> | <span class="t">idea, one is the progressive resizing of GANs paper which allows training of very high-resolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3495" target="_blank">00:58:15.220</a></span> | <span class="t">GANs, and the other one is the EDSR paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3499" target="_blank">00:58:19.620</a></span> | <span class="t">And the cool thing about progressive resizing is not only are your earlier epochs, assuming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3506" target="_blank">00:58:26.700</a></span> | <span class="t">you've got two by two smaller, four times faster, you can also make the batch size maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3513" target="_blank">00:58:33.000</a></span> | <span class="t">three or four times bigger, but more importantly, they're going to generalize better because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3519" target="_blank">00:58:39.060</a></span> | <span class="t">you're feeding your model different size images during training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3524" target="_blank">00:58:44.980</a></span> | <span class="t">So we were able to train like half as many epochs for ImageNet as most people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3531" target="_blank">00:58:51.000</a></span> | <span class="t">So our epochs were faster and there were fewer of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3534" target="_blank">00:58:54.620</a></span> | <span class="t">So progressive resizing is something that, particularly if you're training from scratch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3541" target="_blank">00:59:01.140</a></span> | <span class="t">I'm not so sure if it's useful for fine-tuning transfer learning, but if you're training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3544" target="_blank">00:59:04.780</a></span> | <span class="t">from scratch, you probably want to do nearly all the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3548" target="_blank">00:59:08.740</a></span> | <span class="t">So the next step is to go all the way back to the top and change to 4-scale 32 batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3556" target="_blank">00:59:16.140</a></span> | <span class="t">size, like restart, so I save the model before I do that, go back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3561" target="_blank">00:59:21.780</a></span> | <span class="t">And that's why there's a little bit of fussing around in here with reloading, because what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3569" target="_blank">00:59:29.340</a></span> | <span class="t">I needed to do now is I needed to load my saved model back in, but there's a slight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3575" target="_blank">00:59:35.580</a></span> | <span class="t">issue, which is I now have one more up-sampling layer than I used to have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3581" target="_blank">00:59:41.500</a></span> | <span class="t">To go from 2x2 to 4x4, my little loop here is now looping through twice, not once, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3594" target="_blank">00:59:54.420</a></span> | <span class="t">therefore it's added an extra conv and an extra pixel shuffle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3598" target="_blank">00:59:58.100</a></span> | <span class="t">So how am I going to load in weights through a different network?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3603" target="_blank">01:00:03.900</a></span> | <span class="t">And the answer is that I use a very handy thing in PyTorch, which is if I call -- this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3611" target="_blank">01:00:11.100</a></span> | <span class="t">is basically what learn.load calls behind the scenes, load state dict.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3619" target="_blank">01:00:19.440</a></span> | <span class="t">If I pass this parameter strict=false, if I pass in this parameter strict=false, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3626" target="_blank">01:00:26.780</a></span> | <span class="t">it says if you can't fill in all of the layers, just fill in the layers you can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3634" target="_blank">01:00:34.500</a></span> | <span class="t">So after loading the model back in this way, we're going to end up with something where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3638" target="_blank">01:00:38.900</a></span> | <span class="t">it's loaded in all the layers that it can, and that one conv layer that's new is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3644" target="_blank">01:00:44.460</a></span> | <span class="t">to be randomly initialized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3646" target="_blank">01:00:46.900</a></span> | <span class="t">And so then I freeze all my layers and then unfreeze that up-sampling part, and then use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3656" target="_blank">01:00:56.600</a></span> | <span class="t">ICNR on my newly added extra layer, and then I can go ahead and load again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3666" target="_blank">01:01:06.980</a></span> | <span class="t">And so then the rest is the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3668" target="_blank">01:01:08.820</a></span> | <span class="t">So if you're trying to replicate this, don't just run this top to bottom, realize it involves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3673" target="_blank">01:01:13.780</a></span> | <span class="t">a bit of jumping around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3681" target="_blank">01:01:21.220</a></span> | <span class="t">The longer you train, the better it gets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3684" target="_blank">01:01:24.460</a></span> | <span class="t">I ended up training it for about 10 hours, but you'll still get very good results much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3688" target="_blank">01:01:28.540</a></span> | <span class="t">more quickly if you're less patient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3692" target="_blank">01:01:32.020</a></span> | <span class="t">And so we can try it out, and here is the result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3695" target="_blank">01:01:35.160</a></span> | <span class="t">Here is my pixelated bird, and look here, it's like totally randomly pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3701" target="_blank">01:01:41.160</a></span> | <span class="t">And here's the up-sampled version, it's like it's literally invented coloration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3708" target="_blank">01:01:48.900</a></span> | <span class="t">But it figured out what kind of bird it is, and it knows what these feathers are meant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3715" target="_blank">01:01:55.300</a></span> | <span class="t">to look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3716" target="_blank">01:01:56.680</a></span> | <span class="t">And so it has imagined a set of feathers which are compatible with these exact pixels, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3723" target="_blank">01:02:03.620</a></span> | <span class="t">is like genius.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3724" target="_blank">01:02:04.920</a></span> | <span class="t">Like same here, there's no way you can tell what these blue dots are meant to represent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3730" target="_blank">01:02:10.940</a></span> | <span class="t">but if you know that this kind of bird has an array of feathers here, you know that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3736" target="_blank">01:02:16.120</a></span> | <span class="t">what they must be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3737" target="_blank">01:02:17.120</a></span> | <span class="t">And then you can figure out where the feathers would have to be such that when they were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3740" target="_blank">01:02:20.320</a></span> | <span class="t">pixelated they'd end up in these spots.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3743" target="_blank">01:02:23.080</a></span> | <span class="t">So it's like literally reverse engineered, given its knowledge of this exact species</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3750" target="_blank">01:02:30.780</a></span> | <span class="t">of bird, how it would have to have looked to create this output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3756" target="_blank">01:02:36.640</a></span> | <span class="t">And so this is like so amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3759" target="_blank">01:02:39.440</a></span> | <span class="t">It also knows from all the kind of signs around it that this area here was almost certainly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3768" target="_blank">01:02:48.100</a></span> | <span class="t">blurred out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3769" target="_blank">01:02:49.580</a></span> | <span class="t">So it's actually reconstructed blurred vegetation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3775" target="_blank">01:02:55.520</a></span> | <span class="t">And if it hadn't done all of those things, it wouldn't have got such a good loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3780" target="_blank">01:03:00.400</a></span> | <span class="t">Because in the end, it had to match the activations saying like there's a feather over here and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3788" target="_blank">01:03:08.440</a></span> | <span class="t">it's kind of fluffy looking and it's in this direction and all that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3797" target="_blank">01:03:17.320</a></span> | <span class="t">Alright, well that brings us to the end of super resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3802" target="_blank">01:03:22.460</a></span> | <span class="t">Don't forget to check out the Ask Jeremy Anything thread and we will do some Ask Jeremy Anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3807" target="_blank">01:03:27.960</a></span> | <span class="t">after the break.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3808" target="_blank">01:03:28.960</a></span> | <span class="t">Let's see you back here at quarter to eight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3827" target="_blank">01:03:47.160</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3834" target="_blank">01:03:54.040</a></span> | <span class="t">So we are going to do Ask Jeremy Anything, Rachel will tell me the most voted up of your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3844" target="_blank">01:04:04.960</a></span> | <span class="t">questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3845" target="_blank">01:04:05.960</a></span> | <span class="t">Yes, Rachel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3846" target="_blank">01:04:06.960</a></span> | <span class="t">What are the future plans for Fast AI in this course?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3855" target="_blank">01:04:15.080</a></span> | <span class="t">Will there be a part three?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3856" target="_blank">01:04:16.560</a></span> | <span class="t">If there is a part three, I would really love to take it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3859" target="_blank">01:04:19.480</a></span> | <span class="t">That's cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3860" target="_blank">01:04:20.480</a></span> | <span class="t">I'm not quite sure, it's always hard to guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3865" target="_blank">01:04:25.400</a></span> | <span class="t">I hope there will be some kind of follow-up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3868" target="_blank">01:04:28.320</a></span> | <span class="t">Last year after part two, one of the students started up a weekly book club going through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3873" target="_blank">01:04:33.700</a></span> | <span class="t">the Ian Goodfellow deep learning book and Ian actually came in and presented quite a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3879" target="_blank">01:04:39.240</a></span> | <span class="t">few of the chapters and other people, like there was somebody, an expert, who presented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3883" target="_blank">01:04:43.040</a></span> | <span class="t">every chapter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3884" target="_blank">01:04:44.040</a></span> | <span class="t">That was like a really cool part three.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3886" target="_blank">01:04:46.440</a></span> | <span class="t">To a large extent it will depend on you, the community, to come up with ideas and to help</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3892" target="_blank">01:04:52.720</a></span> | <span class="t">make them happen and I'm definitely keen to help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3897" target="_blank">01:04:57.360</a></span> | <span class="t">I've got a bunch of ideas, but I'm nervous about saying them because I'm not sure which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3901" target="_blank">01:05:01.160</a></span> | <span class="t">ones will happen and which ones won't, but the more support I have in making things happen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3907" target="_blank">01:05:07.080</a></span> | <span class="t">that you want to happen from you, the more likely they are to happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3913" target="_blank">01:05:13.800</a></span> | <span class="t">What was your experience like starting down the path of entrepreneurship?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3917" target="_blank">01:05:17.440</a></span> | <span class="t">Have you always been an entrepreneur or did you start out at a big company and transition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3921" target="_blank">01:05:21.920</a></span> | <span class="t">to a start-up?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3922" target="_blank">01:05:22.920</a></span> | <span class="t">Did you go from academia to start-ups or start-ups to academia?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3926" target="_blank">01:05:26.800</a></span> | <span class="t">I was definitely not in academia, I'm totally a fake academic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3931" target="_blank">01:05:31.720</a></span> | <span class="t">I started at McKinsey & Company which is a strategy firm when I was 18, which meant I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3938" target="_blank">01:05:38.760</a></span> | <span class="t">couldn't really go to university, so I didn't really turn up and then I spent eight years</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3943" target="_blank">01:05:43.400</a></span> | <span class="t">in business helping really big companies on strategic questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3947" target="_blank">01:05:47.240</a></span> | <span class="t">I always wanted to be an entrepreneur, I planned to already spend two years at McKinsey, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3953" target="_blank">01:05:53.380</a></span> | <span class="t">only thing I really regret in my life was not sticking to that plan and wasting eight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3958" target="_blank">01:05:58.160</a></span> | <span class="t">years instead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3959" target="_blank">01:05:59.160</a></span> | <span class="t">So two years would have been perfect, but then I went into entrepreneurship, started</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3964" target="_blank">01:06:04.480</a></span> | <span class="t">two companies in Australia and the best part about that was that I didn't get any funding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3972" target="_blank">01:06:12.480</a></span> | <span class="t">so all the money that I made was mine, all the decisions were mine and my partners.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3979" target="_blank">01:06:19.540</a></span> | <span class="t">I focused entirely on profit and product and customer and service, whereas I find in San</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3987" target="_blank">01:06:27.400</a></span> | <span class="t">Francisco I'm glad I came here and so the two of us came here for Kaggle, Anthony and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=3998" target="_blank">01:06:38.040</a></span> | <span class="t">I and raised a ridiculous amount of money, $11 million for this really new company.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4007" target="_blank">01:06:47.320</a></span> | <span class="t">That was really interesting but it's also really distracting, trying to worry about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4011" target="_blank">01:06:51.720</a></span> | <span class="t">scaling and VCs wanting to see what your business development plans are and also just not having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4018" target="_blank">01:06:58.760</a></span> | <span class="t">any real need to actually make a profit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4022" target="_blank">01:07:02.840</a></span> | <span class="t">So I had a bit of the same problem at Inletic, where I again raised a lot of money, $15 million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4031" target="_blank">01:07:11.240</a></span> | <span class="t">pretty quickly and a lot of distractions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4037" target="_blank">01:07:17.340</a></span> | <span class="t">So I think trying to bootstrap your own company and focus on making money by selling something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4048" target="_blank">01:07:28.320</a></span> | <span class="t">at a profit and then plowing that back into the company worked really well because within</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4057" target="_blank">01:07:37.000</a></span> | <span class="t">like five years we were making a profit from three months in and within five years we were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4063" target="_blank">01:07:43.280</a></span> | <span class="t">making enough of a profit not just to pay all of us in their own wages but also to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4067" target="_blank">01:07:47.800</a></span> | <span class="t">my bank account growing and after ten years sold it for a big chunk of money, not enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4072" target="_blank">01:07:52.680</a></span> | <span class="t">that a VC would be excited but enough that I didn't have to worry about money again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4079" target="_blank">01:07:59.480</a></span> | <span class="t">So I think bootstrapping a company is something which people in the Bay Area at least don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4085" target="_blank">01:08:05.440</a></span> | <span class="t">seem to appreciate how good an idea that is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4090" target="_blank">01:08:10.920</a></span> | <span class="t">If you are 25 years old today and still know what you know where, which you'd be looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4095" target="_blank">01:08:15.240</a></span> | <span class="t">to use AI, what are you working on right now or looking to work on in the next two years?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4101" target="_blank">01:08:21.600</a></span> | <span class="t">You should ignore the last part of that, I won't even answer it, it doesn't matter where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4104" target="_blank">01:08:24.920</a></span> | <span class="t">I'm looking, what you should do is leverage your knowledge about your domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4112" target="_blank">01:08:32.200</a></span> | <span class="t">So one of the main reasons we do this is to get people who have backgrounds in whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4119" target="_blank">01:08:39.120</a></span> | <span class="t">recruiting, oil field surveys, journalism, activism, whatever, and solve your problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4133" target="_blank">01:08:53.000</a></span> | <span class="t">It will be really obvious to you what your problems are and it will be really obvious</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4136" target="_blank">01:08:56.680</a></span> | <span class="t">to you what data you have and where to find it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4140" target="_blank">01:09:00.000</a></span> | <span class="t">Those are all the bits that for everybody else it's really hard, so people who start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4143" target="_blank">01:09:03.160</a></span> | <span class="t">out with "Oh I know deep learning" now go and find something to apply it to, basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4149" target="_blank">01:09:09.280</a></span> | <span class="t">never succeed, whereas people who are like "Oh I've been spending 25 years doing specialized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4156" target="_blank">01:09:16.240</a></span> | <span class="t">recruiting for legal firms and I know that the key issue is this thing and I know that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4160" target="_blank">01:09:20.840</a></span> | <span class="t">this piece of data totally solves it and so I'm just going to do that now and I already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4165" target="_blank">01:09:25.360</a></span> | <span class="t">know who to call to actually start selling it to, they're the ones who tend to win.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4171" target="_blank">01:09:31.720</a></span> | <span class="t">So if you've done nothing but academic stuff then it's more about your hobbies and interests,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4184" target="_blank">01:09:44.680</a></span> | <span class="t">so everybody has hobbies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4187" target="_blank">01:09:47.720</a></span> | <span class="t">The main thing I would say is please don't focus on building tools for data scientists</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4193" target="_blank">01:09:53.520</a></span> | <span class="t">to use or for software engineers to use because every data scientist knows about the market</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4200" target="_blank">01:10:00.280</a></span> | <span class="t">of data scientists, whereas only you know about the market for analyzing oil survey well logs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4208" target="_blank">01:10:08.920</a></span> | <span class="t">or understanding audiology studies or whatever it is that you do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4219" target="_blank">01:10:19.560</a></span> | <span class="t">Given what you've shown us about applying transfer learning from image recognition to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4223" target="_blank">01:10:23.360</a></span> | <span class="t">NLP, there looks to be a lot of value in paying attention to all of the developments that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4227" target="_blank">01:10:27.920</a></span> | <span class="t">happen across the whole machine learning field and that if you were to focus in one area</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4232" target="_blank">01:10:32.000</a></span> | <span class="t">you might miss out on some great advances in other concentrations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4235" target="_blank">01:10:35.920</a></span> | <span class="t">How do you stay aware of all the advancements across the field while still having time to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4239" target="_blank">01:10:39.720</a></span> | <span class="t">dig in deep to your specific domains?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4242" target="_blank">01:10:42.280</a></span> | <span class="t">Yeah that's awesome, I mean that's kind of the message of this course, one of the key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4246" target="_blank">01:10:46.640</a></span> | <span class="t">messages of this course is like lots of good works being done in different places and people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4252" target="_blank">01:10:52.240</a></span> | <span class="t">are so specialized most people don't know about it, like if I can get state-of-the-art</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4257" target="_blank">01:10:57.000</a></span> | <span class="t">results in NLP within six months of starting to look at NLP, then I think that says more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4262" target="_blank">01:11:02.440</a></span> | <span class="t">about NLP than it does about me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4266" target="_blank">01:11:06.720</a></span> | <span class="t">So yeah it's kind of like the entrepreneurship thing, it's like you pick the areas that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4273" target="_blank">01:11:13.160</a></span> | <span class="t">see that you know about and kind of transfer stuff like oh we could use deep learning to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4277" target="_blank">01:11:17.800</a></span> | <span class="t">solve this problem or in this case like we could use this idea of computer vision to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4284" target="_blank">01:11:24.840</a></span> | <span class="t">solve that problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4287" target="_blank">01:11:27.380</a></span> | <span class="t">So things like transfer learning, I'm sure there's like a thousand things, opportunities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4292" target="_blank">01:11:32.440</a></span> | <span class="t">for you to do in other fields to do what Sebastian and I did in NLP with NLP classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4299" target="_blank">01:11:39.600</a></span> | <span class="t">So the short answer to your question is the way to stay ahead of what's going on would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4303" target="_blank">01:11:43.600</a></span> | <span class="t">be to follow my feed of Twitter favorites and my approach is to follow lots and lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4310" target="_blank">01:11:50.440</a></span> | <span class="t">of people on Twitter and put them into the Twitter favorites for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4315" target="_blank">01:11:55.040</a></span> | <span class="t">Every time I come across something interesting I click favorite and there are two reasons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4319" target="_blank">01:11:59.080</a></span> | <span class="t">I do it, the first is that when the next course comes along I go through my favorites to find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4323" target="_blank">01:12:03.640</a></span> | <span class="t">which things I want to study and the second is so that you can do the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4331" target="_blank">01:12:11.480</a></span> | <span class="t">And then which do you go deep into, it almost doesn't matter, like I find every time I look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4337" target="_blank">01:12:17.040</a></span> | <span class="t">at something it turns out to be super interesting and important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4339" target="_blank">01:12:19.880</a></span> | <span class="t">So just pick something which is like, you feel like solving that problem would be actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4346" target="_blank">01:12:26.400</a></span> | <span class="t">useful for some reason and it doesn't seem to be very popular, which is kind of the opposite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4351" target="_blank">01:12:31.480</a></span> | <span class="t">of what everybody else does, everybody else works on the problems which everybody else</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4356" target="_blank">01:12:36.720</a></span> | <span class="t">is already working on because they're the ones that seem popular and I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4361" target="_blank">01:12:41.360</a></span> | <span class="t">I can't quite understand this kind of thinking but it seems to be very common.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4366" target="_blank">01:12:46.880</a></span> | <span class="t">Is deep learning an overkill to use on tabular data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4370" target="_blank">01:12:50.200</a></span> | <span class="t">When is it better to use deep learning instead of machine learning on tabular data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4379" target="_blank">01:12:59.320</a></span> | <span class="t">Is that a real question or did you just put that there so that I would point out that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4383" target="_blank">01:13:03.280</a></span> | <span class="t">Rachel Thomas just wrote an article?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4390" target="_blank">01:13:10.000</a></span> | <span class="t">Yes, so Rachel's just written about this and Rachel and I spent a long time talking about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4396" target="_blank">01:13:16.520</a></span> | <span class="t">it and the short answer is we think it's great to use deep learning on tabular data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4404" target="_blank">01:13:24.280</a></span> | <span class="t">Actually of all the rich, complex, important and interesting things that appear in Rachel's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4410" target="_blank">01:13:30.520</a></span> | <span class="t">Twitter stream covering everything from the genocide of the Rohingya through to the latest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4417" target="_blank">01:13:37.680</a></span> | <span class="t">ethics violations in AI companies, the one by far that got the most attention and engagement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4424" target="_blank">01:13:44.540</a></span> | <span class="t">from the community was her question about is it called tabular data or structured data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4431" target="_blank">01:13:51.920</a></span> | <span class="t">Ask computer people how to name things and you'll get plenty of interest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4437" target="_blank">01:13:57.200</a></span> | <span class="t">There are some really good links here to stuff from Instacart and Pinterest and other folks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4443" target="_blank">01:14:03.000</a></span> | <span class="t">who have done some good work in this area.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4445" target="_blank">01:14:05.520</a></span> | <span class="t">Many of you that went to the Data Institute conference will have seen Jeremy Stanley's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4449" target="_blank">01:14:09.020</a></span> | <span class="t">presentation about the really cool work they did at Instacart.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4452" target="_blank">01:14:12.400</a></span> | <span class="t">Yes, Rachel?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4453" target="_blank">01:14:13.400</a></span> | <span class="t">I relied heavily on lessons three and four from part one in writing this post, so much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4459" target="_blank">01:14:19.960</a></span> | <span class="t">of it may be familiar to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4463" target="_blank">01:14:23.520</a></span> | <span class="t">Rachel asked me during the post how to tell whether you should use a decision tree ensemble</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4470" target="_blank">01:14:30.600</a></span> | <span class="t">like GVM or random forest or neural net and my answer is I still don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4477" target="_blank">01:14:37.320</a></span> | <span class="t">Nobody I'm aware of has done that research in any particularly meaningful way, so there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4482" target="_blank">01:14:42.480</a></span> | <span class="t">a question to be answered there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4484" target="_blank">01:14:44.680</a></span> | <span class="t">I guess my approach has been to try to make both of those things as accessible as possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4489" target="_blank">01:14:49.920</a></span> | <span class="t">through the fastAI library so you can try them both and see what works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4494" target="_blank">01:14:54.480</a></span> | <span class="t">That was it for the top three questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4509" target="_blank">01:15:09.000</a></span> | <span class="t">Just quickly to go from super resolution to style transfer is kind of --</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4515" target="_blank">01:15:15.600</a></span> | <span class="t">I think I missed the one on reinforcement learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4522" target="_blank">01:15:22.040</a></span> | <span class="t">Reinforcement learning popularity has been on a gradual rise in the recent past.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4526" target="_blank">01:15:26.920</a></span> | <span class="t">What's your take on reinforcement learning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4528" target="_blank">01:15:28.980</a></span> | <span class="t">Would fastAI consider covering some ground and popular RL techniques in the future?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4536" target="_blank">01:15:36.160</a></span> | <span class="t">I'm still not a believer in reinforcement learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4541" target="_blank">01:15:41.520</a></span> | <span class="t">I think it's an interesting problem to solve, but it's not at all clear that we have a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4547" target="_blank">01:15:47.280</a></span> | <span class="t">way of solving this problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4548" target="_blank">01:15:48.480</a></span> | <span class="t">The problem really is the delayed credit problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4553" target="_blank">01:15:53.000</a></span> | <span class="t">I want to learn to play Pong, I move up or down, and three minutes later I find out whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4558" target="_blank">01:15:58.780</a></span> | <span class="t">I won the game of Pong, which actions I took were actually useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4565" target="_blank">01:16:05.520</a></span> | <span class="t">To me the idea of calculating the gradients of the output with respect to those inputs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4573" target="_blank">01:16:13.480</a></span> | <span class="t">the credit is so delayed that those derivatives don't seem very interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4581" target="_blank">01:16:21.720</a></span> | <span class="t">I get this question quite regularly in every one of these four courses so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4585" target="_blank">01:16:25.680</a></span> | <span class="t">I've always said the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4588" target="_blank">01:16:28.360</a></span> | <span class="t">I'm rather pleased that finally recently there's been some results showing that basically random</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4593" target="_blank">01:16:33.520</a></span> | <span class="t">search often does better than reinforcement learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4599" target="_blank">01:16:39.400</a></span> | <span class="t">Basically what's happened is very well-funded companies with vast amounts of computational</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4604" target="_blank">01:16:44.800</a></span> | <span class="t">power throw all of it at reinforcement learning problems and get good results and people then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4611" target="_blank">01:16:51.120</a></span> | <span class="t">say it's because of the reinforcement learning rather than the vast amounts of compute power.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4616" target="_blank">01:16:56.880</a></span> | <span class="t">Or they use extremely thoughtful and clever algorithms like a combination of convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4624" target="_blank">01:17:04.600</a></span> | <span class="t">neural nets and Monte Carlo tree search like they did with the AlphaGo stuff to get great</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4629" target="_blank">01:17:09.920</a></span> | <span class="t">results and people incorrectly say that's because of reinforcement learning but it wasn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4635" target="_blank">01:17:15.800</a></span> | <span class="t">really reinforcement learning at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4639" target="_blank">01:17:19.880</a></span> | <span class="t">I'm very interested in solving these kind of more generic optimization type problems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4647" target="_blank">01:17:27.440</a></span> | <span class="t">rather than just prediction problems and that's what these delayed credit problems look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4653" target="_blank">01:17:33.880</a></span> | <span class="t">But I don't think we've yet got good enough best practices that I have anything I'm ready</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4660" target="_blank">01:17:40.160</a></span> | <span class="t">to teach and say like I'm going to teach you this thing because I think it's still going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4664" target="_blank">01:17:44.080</a></span> | <span class="t">to be useful next year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4666" target="_blank">01:17:46.640</a></span> | <span class="t">So we'll keep watching and see what happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4678" target="_blank">01:17:58.080</a></span> | <span class="t">So we're going to now turn the super resolution network basically into a style transfer network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4685" target="_blank">01:18:05.040</a></span> | <span class="t">and we'll do this pretty quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4687" target="_blank">01:18:07.160</a></span> | <span class="t">We basically already have something, so here's my input image and I'm going to have some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4691" target="_blank">01:18:11.940</a></span> | <span class="t">loss function and I've got some neural net again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4696" target="_blank">01:18:16.960</a></span> | <span class="t">So instead of a neural net that does a whole lot of compute and then does upsampling at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4700" target="_blank">01:18:20.600</a></span> | <span class="t">the end, our input this time is just as big as our output so we're going to do some downsampling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4706" target="_blank">01:18:26.520</a></span> | <span class="t">first and then our compute and then our upsampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4710" target="_blank">01:18:30.400</a></span> | <span class="t">So that's the first change we're going to make is we're going to add some down sampling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4714" target="_blank">01:18:34.200</a></span> | <span class="t">so some stride 2 convolution layers to the front of our network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4717" target="_blank">01:18:37.680</a></span> | <span class="t">The second is rather than just comparing y, c and x to the same thing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4723" target="_blank">01:18:43.160</a></span> | <span class="t">So we're going to basically say our input image should look like itself by the end,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4730" target="_blank">01:18:50.320</a></span> | <span class="t">so specifically we're going to compare it by chucking it through VGG and comparing it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4734" target="_blank">01:18:54.120</a></span> | <span class="t">at one of the activation layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4738" target="_blank">01:18:58.360</a></span> | <span class="t">And then its style should look like some painting which we'll do just like we did with the Gatties</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4744" target="_blank">01:19:04.600</a></span> | <span class="t">approach by looking at the grammatrix correspondence at a number of layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4750" target="_blank">01:19:10.360</a></span> | <span class="t">So that's basically it, and so that ought to be super straightforward, it's really just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4756" target="_blank">01:19:16.600</a></span> | <span class="t">combining two things we've already done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4760" target="_blank">01:19:20.000</a></span> | <span class="t">And so all this code at the start is identical, except we don't have high res and low res,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4764" target="_blank">01:19:24.120</a></span> | <span class="t">we just have one size 256, all this is the same, my model's the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4773" target="_blank">01:19:33.280</a></span> | <span class="t">One thing I did here is I did not do any kind of fancy best practices for this one at all,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4781" target="_blank">01:19:41.760</a></span> | <span class="t">partly because there doesn't seem to be any, like there's been very little follow-up in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4787" target="_blank">01:19:47.360</a></span> | <span class="t">this approach compared to the super resolution stuff, and we'll talk about why in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4795" target="_blank">01:19:55.000</a></span> | <span class="t">So you'll see this is much more normal looking, I've got batch norm layers, I don't have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4803" target="_blank">01:20:03.200</a></span> | <span class="t">scaling factor here, I don't have a pixel shuffle, it's just using a normal upsampling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4809" target="_blank">01:20:09.920</a></span> | <span class="t">followed by one by one conge, blah blah blah, so it's just more normal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4815" target="_blank">01:20:15.880</a></span> | <span class="t">One thing they mentioned in the paper is they had a lot of problems with zero padding creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4822" target="_blank">01:20:22.260</a></span> | <span class="t">artifacts, and the way they solved that was by adding 40 pixels of reflection padding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4827" target="_blank">01:20:27.160</a></span> | <span class="t">at the start, so I did the same thing, and then they used zero padding in their convolutions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4834" target="_blank">01:20:34.120</a></span> | <span class="t">in their res blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4836" target="_blank">01:20:36.400</a></span> | <span class="t">Now if you've got zero padding in your convolution in your res blocks, then that means that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4841" target="_blank">01:20:41.320</a></span> | <span class="t">two parts of your resnet won't add up anymore because you've lost a pixel from each side</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4847" target="_blank">01:20:47.080</a></span> | <span class="t">on each of your two convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4849" target="_blank">01:20:49.080</a></span> | <span class="t">So my res sequential has become res sequential center, and I've removed the last two pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4856" target="_blank">01:20:56.240</a></span> | <span class="t">on each side of those good cells.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4859" target="_blank">01:20:59.000</a></span> | <span class="t">So other than that, this is basically the same as what we had before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4863" target="_blank">01:21:03.720</a></span> | <span class="t">So then we can bring in our starry_night_picture, we can resize it, we can throw it through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4870" target="_blank">01:21:10.680</a></span> | <span class="t">our transformations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4874" target="_blank">01:21:14.060</a></span> | <span class="t">Just to make the method a little bit easier for my brain to handle, I took my transform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4883" target="_blank">01:21:23.540</a></span> | <span class="t">style image, which after transformations is 3x256x256, and I made a mini-batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4889" target="_blank">01:21:29.640</a></span> | <span class="t">My batch size is 24, 24 copies of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4892" target="_blank">01:21:32.680</a></span> | <span class="t">That just makes it a little bit easier to do the batch arithmetic without worrying about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4897" target="_blank">01:21:37.560</a></span> | <span class="t">some of the broadcasting, they're not really 24 copies, I used np.broadcast to basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4905" target="_blank">01:21:45.720</a></span> | <span class="t">fake 24 copies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4912" target="_blank">01:21:52.000</a></span> | <span class="t">So just like before, we create our VGG, grab the last block, this time we're going to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4918" target="_blank">01:21:58.240</a></span> | <span class="t">all of these layers so we keep everything up to the 43rd layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4925" target="_blank">01:22:05.600</a></span> | <span class="t">And so now our combined loss is going to add together a content loss for the 3rd block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4932" target="_blank">01:22:12.040</a></span> | <span class="t">plus the gram loss for all of our blocks with different weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4936" target="_blank">01:22:16.840</a></span> | <span class="t">And so the gram loss, and again, going back to everything being as normal as possible,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4943" target="_blank">01:22:23.520</a></span> | <span class="t">I've gone back to using MSE here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4946" target="_blank">01:22:26.800</a></span> | <span class="t">Basically what happened is I had a lot of trouble getting this to train properly, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4949" target="_blank">01:22:29.480</a></span> | <span class="t">I gradually removed trick after trick and eventually just went okay, I'm just going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4952" target="_blank">01:22:32.480</a></span> | <span class="t">to make it as bland as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4958" target="_blank">01:22:38.440</a></span> | <span class="t">Last week's gram matrix was wrong, by the way, it only worked for a batch size of 1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4964" target="_blank">01:22:44.920</a></span> | <span class="t">and we only had a batch size of 1, so that was fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4968" target="_blank">01:22:48.680</a></span> | <span class="t">I was using matrix multiply, which meant that every batch was being compared to every other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4975" target="_blank">01:22:55.680</a></span> | <span class="t">batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4976" target="_blank">01:22:56.680</a></span> | <span class="t">You actually need to use batch matrix multiply, which does a matrix multiply per batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4983" target="_blank">01:23:03.840</a></span> | <span class="t">So that's something to be aware of there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4986" target="_blank">01:23:06.960</a></span> | <span class="t">So I've got my gram matrices, I do my MSE loss between the gram matrices, I weight them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=4992" target="_blank">01:23:12.760</a></span> | <span class="t">I style weights, so I create that resnet, so I create my style, my combined loss, passing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5000" target="_blank">01:23:20.240</a></span> | <span class="t">in the VGG network, passing in the block IDs, passing in the transformed starry night image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5009" target="_blank">01:23:29.180</a></span> | <span class="t">and so you'll see at the very start here I do a forward pass through my VGG model with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5014" target="_blank">01:23:34.720</a></span> | <span class="t">that starry night image in order that I can save the features for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5020" target="_blank">01:23:40.960</a></span> | <span class="t">Now notice it's really important now that I don't do any data augmentation because I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5026" target="_blank">01:23:46.040</a></span> | <span class="t">saved the style features for a particular non-augmented version, so if I augmented it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5035" target="_blank">01:23:55.240</a></span> | <span class="t">it might make some minor problems, but that's fine because I've got all of ImageNet to deal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5040" target="_blank">01:24:00.960</a></span> | <span class="t">with, I don't really need to do data augmentation anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5044" target="_blank">01:24:04.840</a></span> | <span class="t">Okay, so I've got my loss function and I can go ahead and fit, and there's really nothing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5052" target="_blank">01:24:12.120</a></span> | <span class="t">clever here at all, at the end I have my sumLayers equals false so I can see what each part looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5059" target="_blank">01:24:19.360</a></span> | <span class="t">like and see that they're reasonably balanced, and I can finally pop it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5067" target="_blank">01:24:27.500</a></span> | <span class="t">So I mentioned that should be pretty easy, and yet it took me about four days because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5075" target="_blank">01:24:35.480</a></span> | <span class="t">I just found this incredibly fiddly to actually get it to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5082" target="_blank">01:24:42.680</a></span> | <span class="t">So when I finally got up in the morning I said to Rachel, guess what, they're trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5087" target="_blank">01:24:47.600</a></span> | <span class="t">correctly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5088" target="_blank">01:24:48.600</a></span> | <span class="t">Rachel was like, I never thought that was going to happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5094" target="_blank">01:24:54.980</a></span> | <span class="t">It just looked awful all the time, and it was really about getting the exact right mix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5100" target="_blank">01:25:00.040</a></span> | <span class="t">of content loss versus style loss, the mix of the layers of the style loss, and the worst</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5105" target="_blank">01:25:05.080</a></span> | <span class="t">part was it takes a really long time to train the damn CNN, and I didn't really know how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5112" target="_blank">01:25:12.680</a></span> | <span class="t">long to train it before I decided it wasn't doing well, like should I just train it for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5117" target="_blank">01:25:17.840</a></span> | <span class="t">longer or what?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5122" target="_blank">01:25:22.320</a></span> | <span class="t">And I don't know, all the little details didn't seem to slightly change it, but it would totally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5127" target="_blank">01:25:27.880</a></span> | <span class="t">fall apart all the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5129" target="_blank">01:25:29.840</a></span> | <span class="t">So I kind of mentioned this partly to say just remember the final answer you see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5139" target="_blank">01:25:39.400</a></span> | <span class="t">is after me driving myself crazy all week, nearly always not working until finally at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5145" target="_blank">01:25:45.240</a></span> | <span class="t">the last minute, it finally does, even for things which just seem like they couldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5151" target="_blank">01:25:51.560</a></span> | <span class="t">possibly be difficult because they're just combining two things we already have working.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5156" target="_blank">01:25:56.220</a></span> | <span class="t">The other is to be careful about how we interpret what authors claim.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5171" target="_blank">01:26:11.280</a></span> | <span class="t">It was so fiddly getting this style transfer to work, and after doing it, it left me thinking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5180" target="_blank">01:26:20.640</a></span> | <span class="t">why did I bother? Because now I've got something that takes hours to create a network that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5186" target="_blank">01:26:26.600</a></span> | <span class="t">can turn any kind of photo into one specific style.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5191" target="_blank">01:26:31.640</a></span> | <span class="t">It just seems very unlikely I would want that for anything, like the only reason I could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5196" target="_blank">01:26:36.880</a></span> | <span class="t">think that being useful would be to do some art stuff on a video to turn every frame into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5203" target="_blank">01:26:43.400</a></span> | <span class="t">some style. It's an incredibly niche thing to do, but when I looked at the paper, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5211" target="_blank">01:26:51.480</a></span> | <span class="t">table was saying we're a thousand times faster than the Gatties approach, which is just such</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5219" target="_blank">01:26:59.880</a></span> | <span class="t">an obviously meaningless thing to say and such an incredibly misleading thing to say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5227" target="_blank">01:27:07.040</a></span> | <span class="t">because it ignores all the hours of training for each individual style. I find this frustrating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5234" target="_blank">01:27:14.380</a></span> | <span class="t">because groups like this Stanford group clearly know better, or ought to know better, but still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5241" target="_blank">01:27:21.200</a></span> | <span class="t">I guess the academic community kind of encourages people to make these ridiculously grand claims.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5249" target="_blank">01:27:29.280</a></span> | <span class="t">It also completely ignores this incredibly sensitive, fiddly training process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5260" target="_blank">01:27:40.880</a></span> | <span class="t">This paper was just so well-accepted when it came out. I remember everybody getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5265" target="_blank">01:27:45.800</a></span> | <span class="t">on Twitter and being like, wow, these Stanford people have found this way of doing style</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5270" target="_blank">01:27:50.240</a></span> | <span class="t">transfer a thousand times faster. And clearly, the people saying this were like all top researchers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5278" target="_blank">01:27:58.600</a></span> | <span class="t">in the field, but clearly none of them actually understood it because nobody said, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5285" target="_blank">01:28:05.160</a></span> | <span class="t">I don't see why this is remotely useful and also I tried it and it was incredibly fiddly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5289" target="_blank">01:28:09.400</a></span> | <span class="t">to get it all to work. And so it's not until like, what is this now, like 18 months later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5294" target="_blank">01:28:14.720</a></span> | <span class="t">or something that I'm finally coming back to it and kind of thinking like, wait a minute,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5299" target="_blank">01:28:19.320</a></span> | <span class="t">this is kind of stupid. So this is the answer I think to the question of why haven't people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5306" target="_blank">01:28:26.280</a></span> | <span class="t">done follow-ups on this to like create really amazing best practices and better approaches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5310" target="_blank">01:28:30.440</a></span> | <span class="t">like with a super resolution part of the paper? And I think the answer is because it's done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5316" target="_blank">01:28:36.760</a></span> | <span class="t">So I think this part of the paper is clearly not done, you know, and it's been improved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5324" target="_blank">01:28:44.400</a></span> | <span class="t">and improved and improved and now we have great super resolution and I think we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5329" target="_blank">01:28:49.840</a></span> | <span class="t">derive from that great noise reduction, great colorization, great, you know, slant removal,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5337" target="_blank">01:28:57.880</a></span> | <span class="t">great interactive artifact removal, whatever else. So I think there's a lot of really cool</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5346" target="_blank">01:29:06.280</a></span> | <span class="t">techniques here. It's also leveraging a lot of stuff that we've been learning and getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5350" target="_blank">01:29:10.560</a></span> | <span class="t">better and better at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5352" target="_blank">01:29:12.280</a></span> | <span class="t">Okay, so then finally let's talk about segmentation. This is from the famous CAMVID dataset which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5360" target="_blank">01:29:20.240</a></span> | <span class="t">is a classic example of an academic segmentation dataset. And basically you can see what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5364" target="_blank">01:29:24.760</a></span> | <span class="t">do is we start with a picture, there are actually video frames in this dataset like here, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5370" target="_blank">01:29:30.920</a></span> | <span class="t">we construct, we have some labels where they're not actually colors, each one has an ID and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5380" target="_blank">01:29:40.360</a></span> | <span class="t">the IDs are mapped colors, so like red might be one, purple might be two, like pink might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5385" target="_blank">01:29:45.880</a></span> | <span class="t">be three. And so all the buildings, you know, one class or the cars or another class, all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5394" target="_blank">01:29:54.760</a></span> | <span class="t">the people or another class, all the road is another class. And so what we're actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5399" target="_blank">01:29:59.560</a></span> | <span class="t">doing here is multi-class classification for every pixel, okay? And so you can see sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5407" target="_blank">01:30:07.720</a></span> | <span class="t">that multi-class classification really is quite tricky, you know, like these branches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5413" target="_blank">01:30:13.560</a></span> | <span class="t">Although sometimes the labels are really not that great, you know, this is very coarse,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5419" target="_blank">01:30:19.000</a></span> | <span class="t">as you can see. So here are traffic lights and so forth. So that's what we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5425" target="_blank">01:30:25.920</a></span> | <span class="t">do. We're going to do, this is segmentation. And so it's a lot like bounding boxes, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5432" target="_blank">01:30:32.160</a></span> | <span class="t">But rather than just finding a box around each thing, we're actually going to label</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5438" target="_blank">01:30:38.480</a></span> | <span class="t">every single pixel with its class. And really that's actually a lot easier because it fits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5447" target="_blank">01:30:47.160</a></span> | <span class="t">our CNN style so nicely that we basically, we can create any CNN where the output is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5454" target="_blank">01:30:54.240</a></span> | <span class="t">an n by m grid containing the integers from 0 to c where there are c categories, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5462" target="_blank">01:31:02.240</a></span> | <span class="t">we can use cross-entropy loss with a softmax activation and we're done. So I could actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5467" target="_blank">01:31:07.920</a></span> | <span class="t">stop the class there and you can go and use exactly the approaches you've learned in like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5472" target="_blank">01:31:12.320</a></span> | <span class="t">lessons 1 and 2 and you'll get a perfectly okay result. So the first thing to say is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5478" target="_blank">01:31:18.800</a></span> | <span class="t">like this is not actually a terribly hard thing to do, but we're going to try and do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5482" target="_blank">01:31:22.800</a></span> | <span class="t">it really well. And so let's start by doing it the really simple way. And we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5490" target="_blank">01:31:30.320</a></span> | <span class="t">to use the Kaggle Carvana competition, so you Google Kaggle Carvana to find it. You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5495" target="_blank">01:31:35.240</a></span> | <span class="t">can download it with the Kaggle API as per usual. And basically there's a train folder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5500" target="_blank">01:31:40.880</a></span> | <span class="t">containing a bunch of images which is the independent variable and a train_masks folder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5505" target="_blank">01:31:45.920</a></span> | <span class="t">that contains the dependent variable and they look like this. Here's one of the independent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5510" target="_blank">01:31:50.760</a></span> | <span class="t">variable and here's one of the dependent variable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5519" target="_blank">01:31:59.280</a></span> | <span class="t">So in this case, just like cats and dogs, we're going simple. Rather than doing multi-class</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5524" target="_blank">01:32:04.960</a></span> | <span class="t">classification, we're going to do binary classification, but of course multi-class is just the more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5530" target="_blank">01:32:10.040</a></span> | <span class="t">general version, you know, categorical cross-entropy or binary cross-entropy. So there's no differences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5536" target="_blank">01:32:16.320</a></span> | <span class="t">conceptually. So we've got this is just zeros and ones, whereas this is a regular image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5544" target="_blank">01:32:24.560</a></span> | <span class="t">So in order to do this well, it would really help to know what cars look like because really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5551" target="_blank">01:32:31.400</a></span> | <span class="t">what we just want to do is figure out this is the car and this is its orientation and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5555" target="_blank">01:32:35.560</a></span> | <span class="t">then put white pixels where we expect the car to be based on the picture and our understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5561" target="_blank">01:32:41.440</a></span> | <span class="t">of what cars look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5565" target="_blank">01:32:45.080</a></span> | <span class="t">The original data set came with these CSV files as well. I don't really use them for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5569" target="_blank">01:32:49.640</a></span> | <span class="t">very much other than getting a list of images from them. Each image after the car ID has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5582" target="_blank">01:33:02.760</a></span> | <span class="t">a 01, 02, et cetera of which I've printed out all 16 of them for one car and as you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5588" target="_blank">01:33:08.680</a></span> | <span class="t">can see basically those numbers are the 16 orientations of one car. So there that is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5596" target="_blank">01:33:16.600</a></span> | <span class="t">I don't think anybody in this competition actually used this orientation information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5601" target="_blank">01:33:21.400</a></span> | <span class="t">I believe they all kept the car's images, just treated them separately. These images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5608" target="_blank">01:33:28.160</a></span> | <span class="t">are pretty big, like over 1,000 by 1,000 in size and just opening the JPEGs and resizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5617" target="_blank">01:33:37.160</a></span> | <span class="t">them is slow. So I processed them all. Also OpenCV can't handle GIF files, so I converted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5627" target="_blank">01:33:47.600</a></span> | <span class="t">them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5628" target="_blank">01:33:48.600</a></span> | <span class="t">Yes, Rachel?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5629" target="_blank">01:33:49.600</a></span> | <span class="t">Question, how would somebody get these masks for training initially, Mechanical Turk or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5633" target="_blank">01:33:53.400</a></span> | <span class="t">something?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5634" target="_blank">01:33:54.400</a></span> | <span class="t">Yeah, just a lot of boring work. Probably some tools that help you with a bit of edge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5643" target="_blank">01:34:03.360</a></span> | <span class="t">snapping and stuff so that the human can kind of do it roughly and then just fine-tune the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5647" target="_blank">01:34:07.740</a></span> | <span class="t">bits that gets wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5654" target="_blank">01:34:14.120</a></span> | <span class="t">These kinds of labels are expensive. One of the things I really want to work on is deep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5659" target="_blank">01:34:19.920</a></span> | <span class="t">learning enhanced interactive labeling tools because that's clearly something that would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5667" target="_blank">01:34:27.760</a></span> | <span class="t">help a lot of people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5669" target="_blank">01:34:29.000</a></span> | <span class="t">I've got a little section here that you can run if you want to. You probably want to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5674" target="_blank">01:34:34.280</a></span> | <span class="t">which converts the GIFs into PNGs. So just open it up with a PIL and then save it as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5680" target="_blank">01:34:40.160</a></span> | <span class="t">PNG because OpenCV doesn't have GIF support. And as per usual for this kind of stuff I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5685" target="_blank">01:34:45.960</a></span> | <span class="t">do it with a thread pool so I can take advantage of parallel processing, and then also create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5691" target="_blank">01:34:51.680</a></span> | <span class="t">a separate directory, train-128 and train-masks-128, which contains the 128x128 resized versions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5698" target="_blank">01:34:58.800</a></span> | <span class="t">of them. And this is the kind of stuff that keeps you sane if you do it early in the process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5704" target="_blank">01:35:04.800</a></span> | <span class="t">So anytime you get a new data set, seriously think about creating a smaller version to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5711" target="_blank">01:35:11.880</a></span> | <span class="t">make life fast. Anytime you find yourself waiting on your computer, try and think of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5717" target="_blank">01:35:17.320</a></span> | <span class="t">a way to create a smaller version.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5720" target="_blank">01:35:20.280</a></span> | <span class="t">So after you grab it from Kaggle you probably want to run this stuff, go away, have lunch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5724" target="_blank">01:35:24.080</a></span> | <span class="t">come back, and when you're done you'll have these smaller directories which we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5728" target="_blank">01:35:28.680</a></span> | <span class="t">to use here, 128x128 pixel versions to start with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5734" target="_blank">01:35:34.240</a></span> | <span class="t">So here's a cool trick, if you use the same axis object to plot an image twice, and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5742" target="_blank">01:35:42.280</a></span> | <span class="t">second time you use alpha, which as you might know means transparency in the computer vision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5746" target="_blank">01:35:46.760</a></span> | <span class="t">world, then you can actually plot the mask over the top of the photo. And so here's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5753" target="_blank">01:35:53.240</a></span> | <span class="t">nice way to see all the masks on top of the photos for all of the cars in one group. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5759" target="_blank">01:35:59.520</a></span> | <span class="t">is the same matched files data set we've seen twice already, this is all the same code we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5764" target="_blank">01:36:04.240</a></span> | <span class="t">used to, and here's something important though, if we had something that was in the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5770" target="_blank">01:36:10.520</a></span> | <span class="t">set good at this image, and then the validation had that image, that would kind of be cheating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5777" target="_blank">01:36:17.320</a></span> | <span class="t">because it's the same car.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5779" target="_blank">01:36:19.440</a></span> | <span class="t">So we use a contiguous set of car IDs, and since each set is a set of 16, we make sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5789" target="_blank">01:36:29.320</a></span> | <span class="t">it's evenly divisible by 16, so we make sure that our validation set contains different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5795" target="_blank">01:36:35.160</a></span> | <span class="t">car IDs to our training set. This is the kind of stuff which you've got to be careful of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5801" target="_blank">01:36:41.120</a></span> | <span class="t">On Kaggle it's not so bad, you'll know about it because you'll submit your result and you'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5805" target="_blank">01:36:45.280</a></span> | <span class="t">get a very different result on your leaderboard compared to your validation set, but in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5811" target="_blank">01:36:51.160</a></span> | <span class="t">real world you won't know until you put it in production and send your company bankrupt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5817" target="_blank">01:36:57.000</a></span> | <span class="t">and lose your job, so you might want to think carefully about your validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5824" target="_blank">01:37:04.760</a></span> | <span class="t">So here we're going to use transform_type.classification, it's basically the same as transform_type.pixel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5831" target="_blank">01:37:11.040</a></span> | <span class="t">but if you think about it, with the pixel version if we rotate a little bit, then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5836" target="_blank">01:37:16.040</a></span> | <span class="t">probably want to average the pixels in between the two, but for classification obviously</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5840" target="_blank">01:37:20.720</a></span> | <span class="t">we don't, we use nearest_neighbor, so there's a slight difference there. Also for classification,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5847" target="_blank">01:37:27.240</a></span> | <span class="t">lighting doesn't kick in, normalization doesn't kick in to the dependent variable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5855" target="_blank">01:37:35.440</a></span> | <span class="t">There are already square images, so we don't have to do any cropping. So here you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5863" target="_blank">01:37:43.360</a></span> | <span class="t">different versions of the augmented, you know, they're moving around a bit and they're rotating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5867" target="_blank">01:37:47.560</a></span> | <span class="t">a bit and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5872" target="_blank">01:37:52.040</a></span> | <span class="t">I get a lot of questions during our study group and stuff about how do I debug things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5878" target="_blank">01:37:58.760</a></span> | <span class="t">and fix things that aren't working, and I never have a great answer other than every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5884" target="_blank">01:38:04.760</a></span> | <span class="t">time I fix a problem it's because of stuff like this that I do all the time. I just always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5891" target="_blank">01:38:11.720</a></span> | <span class="t">print out everything as I go and then the one thing that I screw up always turns out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5897" target="_blank">01:38:17.880</a></span> | <span class="t">to be the one thing that I forgot to check along the way. The more of this kind of thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5902" target="_blank">01:38:22.680</a></span> | <span class="t">you can do the better. If you're not looking at all of your intermediate results you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5906" target="_blank">01:38:26.600</a></span> | <span class="t">going to have troubles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5910" target="_blank">01:38:30.800</a></span> | <span class="t">So given that we want something that knows what cars look like, we probably want to start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5916" target="_blank">01:38:36.120</a></span> | <span class="t">with a pre-trained ImageNet network. So we're going to start with ResNet34 and so with ConvNetBuilder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5924" target="_blank">01:38:44.360</a></span> | <span class="t">we can grab our ResNet34 and we can add a custom head. And so the custom head is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5930" target="_blank">01:38:50.640</a></span> | <span class="t">to be something that upsamples a bunch of times. And we're going to do things really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5935" target="_blank">01:38:55.680</a></span> | <span class="t">dumb for now. We're just going to do Conv transpose 2D batch norm value. This is what I'm saying.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5947" target="_blank">01:39:07.480</a></span> | <span class="t">Any of you could have built this without looking at any of this notebook, or at least you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5954" target="_blank">01:39:14.040</a></span> | <span class="t">the information from previous classes. There's nothing new at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5959" target="_blank">01:39:19.800</a></span> | <span class="t">And so at the very end we have a single filter. And now that's going to give us something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5969" target="_blank">01:39:29.040</a></span> | <span class="t">which is batch size by 1, by 128, by 128. But we want something which is batch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5976" target="_blank">01:39:36.200</a></span> | <span class="t">by 128 by 128. So we have to remove that unit axis. So I've got a lambda layer here. Lambda</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5982" target="_blank">01:39:42.560</a></span> | <span class="t">layers are incredibly helpful, because without the lambda layer here, which is simply removing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5988" target="_blank">01:39:48.320</a></span> | <span class="t">that unit axis by just indexing into it at zero, without the lambda layer I would have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=5993" target="_blank">01:39:53.840</a></span> | <span class="t">to have created a custom class with a custom forward method and so forth. But by creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6000" target="_blank">01:40:00.520</a></span> | <span class="t">a lambda layer that does like the one custom bit, I can now just chuck it in the sequential.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6005" target="_blank">01:40:05.280</a></span> | <span class="t">And so that just makes life easier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6007" target="_blank">01:40:07.440</a></span> | <span class="t">So the PyTorch people are kind of snooty about this approach. Lambda layer is actually something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6013" target="_blank">01:40:13.880</a></span> | <span class="t">that's part of the fast AI library, not part of the PyTorch library. And literally people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6018" target="_blank">01:40:18.760</a></span> | <span class="t">on the PyTorch discussion board are like, yes, we could give people this, yes, it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6024" target="_blank">01:40:24.880</a></span> | <span class="t">only a single line of code, but then it would encourage them to use sequential too often.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6030" target="_blank">01:40:30.360</a></span> | <span class="t">So there you go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6037" target="_blank">01:40:37.240</a></span> | <span class="t">So this is our custom head. So we're going to have a Resbit34 that goes down sample and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6041" target="_blank">01:40:41.800</a></span> | <span class="t">then a really simple custom head that very quickly upsamples and that hopefully will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6046" target="_blank">01:40:46.520</a></span> | <span class="t">do something. And we're going to use accuracy with a threshold of 0.5 to print out metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6052" target="_blank">01:40:52.800</a></span> | <span class="t">And so after a few epochs we've got 96% accurate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6056" target="_blank">01:40:56.520</a></span> | <span class="t">So is that good? Is 96% accurate? Good. And hopefully the answer to your question is it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6064" target="_blank">01:41:04.520</a></span> | <span class="t">depends. What's it for? And the answer is Kavana wanted this because they wanted to be able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6071" target="_blank">01:41:11.500</a></span> | <span class="t">to take their car images and cut them out and paste them on exotic Monte Carlo backgrounds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6081" target="_blank">01:41:21.620</a></span> | <span class="t">or whatever. That's Monte Carlo the place, not the simulation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6087" target="_blank">01:41:27.520</a></span> | <span class="t">So to do that, you need a really good mask. You don't want to leave the rearview mirrors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6094" target="_blank">01:41:34.720</a></span> | <span class="t">behind or have one wheel missing or include background or something that would look stupid.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6103" target="_blank">01:41:43.500</a></span> | <span class="t">So you would need something very good. So only having 96% of the pixels correct doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6108" target="_blank">01:41:48.760</a></span> | <span class="t">sound great, but we won't really know until we look at it. So let's look at it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6115" target="_blank">01:41:55.300</a></span> | <span class="t">So there's the correct version that we want to cut out. That's the 96% accurate version.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6123" target="_blank">01:42:03.400</a></span> | <span class="t">So when you look at it, you realize, oh yeah, getting 96% of the pixels accurate is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6129" target="_blank">01:42:09.480</a></span> | <span class="t">easy because all the outside bits are not car and all the inside bits are car and really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6134" target="_blank">01:42:14.000</a></span> | <span class="t">the interesting bit is the edge. So we need to do better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6140" target="_blank">01:42:20.120</a></span> | <span class="t">So let's unfreeze because all we've done so far is train the custom head. And let's do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6145" target="_blank">01:42:25.400</a></span> | <span class="t">more. And so after a bit more we've got 99.1%. So is that good? I don't know. Let's take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6153" target="_blank">01:42:33.080</a></span> | <span class="t">a look. And so actually no, it's totally missed the rearview vision mirror here and missed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6161" target="_blank">01:42:41.920</a></span> | <span class="t">a lot of it here and it's clearly got an edge wrong here and these things are totally going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6166" target="_blank">01:42:46.520</a></span> | <span class="t">to matter when we try to cut it out. So it's still not good enough. So let's try upscaling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6172" target="_blank">01:42:52.400</a></span> | <span class="t">And the nice thing is that when we upscale to 512x512, make sure you decrease the batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6176" target="_blank">01:42:56.360</a></span> | <span class="t">size because you'll run out of memory. Here's the true ones. This is all identical. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6185" target="_blank">01:43:05.960</a></span> | <span class="t">quite a lot more information there for it to go on. So our accuracy increases to 99.4%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6191" target="_blank">01:43:11.560</a></span> | <span class="t">and things keep getting better. But we've still got quite a few little black blocky bits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6197" target="_blank">01:43:17.360</a></span> | <span class="t">So let's go to 124x124 down to batch size of 4. This is pretty high res now. And train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6204" target="_blank">01:43:24.480</a></span> | <span class="t">a bit more, 99.6, 99.8. And so now if we look at the masks, they're actually looking not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6217" target="_blank">01:43:37.080</a></span> | <span class="t">bad. That's looking pretty good. So can we do better? And the answer is yes we can. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6227" target="_blank">01:43:47.680</a></span> | <span class="t">we're moving from the Carvana notebook to the Carvana UNet notebook now. And the UNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6232" target="_blank">01:43:52.080</a></span> | <span class="t">network is quite magnificent. You see, with that previous approach, our pre-trained ImageNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6240" target="_blank">01:44:00.000</a></span> | <span class="t">network was being squished down all the way down to 7x7 and then expanded out all the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6245" target="_blank">01:44:05.360</a></span> | <span class="t">back up to, well it's 224 and then expanded out again all this way, which means it has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6255" target="_blank">01:44:15.640</a></span> | <span class="t">to somehow store all the information about the much bigger version in the small version.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6261" target="_blank">01:44:21.860</a></span> | <span class="t">And actually most of the information about the bigger version was really in the original</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6266" target="_blank">01:44:26.040</a></span> | <span class="t">picture anyway. So it doesn't seem like a great approach, this squishing and unsquishing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6273" target="_blank">01:44:33.360</a></span> | <span class="t">So the UNet idea comes from this fantastic paper where it was literally invented in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6281" target="_blank">01:44:41.280</a></span> | <span class="t">very domain-specific area of biomedical image segmentation. But in fact, basically every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6286" target="_blank">01:44:46.680</a></span> | <span class="t">Kaggle winner in anything even vaguely related to segmentation has ended up using UNet. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6293" target="_blank">01:44:53.960</a></span> | <span class="t">one of these things that like everybody in Kaggle knows is the best practice, but in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6297" target="_blank">01:44:57.880</a></span> | <span class="t">more of academic circles, like even now, this has been around for a couple of years at least,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6303" target="_blank">01:45:03.560</a></span> | <span class="t">a lot of people still don't realize. This is by far the best approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6311" target="_blank">01:45:11.200</a></span> | <span class="t">And here's the basic idea. Here's the downward path where we basically start at 572x532 in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6322" target="_blank">01:45:22.240</a></span> | <span class="t">this case and then kind of half the grid size, half the grid size, half the grid size, half</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6326" target="_blank">01:45:26.420</a></span> | <span class="t">the grid size. And then here's the upward path where we double the grid size, double-double-double-double.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6336" target="_blank">01:45:36.160</a></span> | <span class="t">But the thing that we also do is we take at every point where we've halved the grid size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6344" target="_blank">01:45:44.600</a></span> | <span class="t">we actually copy those activations over to the upward path and concatenate them together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6353" target="_blank">01:45:53.780</a></span> | <span class="t">And so you can see here these red blobs are max pooling operations, the green blobs are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6359" target="_blank">01:45:59.720</a></span> | <span class="t">upward sampling, and then these gray bits here are copying. So we copy and concat. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6368" target="_blank">01:46:08.260</a></span> | <span class="t">basically in other words, the input image after a couple of columns is copied over to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6374" target="_blank">01:46:14.160</a></span> | <span class="t">the output, concatenated together, and so now we get to use all of the information that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6380" target="_blank">01:46:20.600</a></span> | <span class="t">gone through all the down and all the up, plus also a slightly modified version of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6384" target="_blank">01:46:24.840</a></span> | <span class="t">input pixels, and a slightly modified version of one thing down from the input pixels because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6390" target="_blank">01:46:30.640</a></span> | <span class="t">they came out through here. So we have like all of the richness of going all the way down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6396" target="_blank">01:46:36.720</a></span> | <span class="t">and up, but also like a slightly less coarse version and a slightly less coarse version</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6401" target="_blank">01:46:41.960</a></span> | <span class="t">and then this really kind of simple version and they can all be combined together. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6407" target="_blank">01:46:47.320</a></span> | <span class="t">so that's UNET, such a cool idea. So here we are in the Kavana UNET notebook, all this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6415" target="_blank">01:46:55.320</a></span> | <span class="t">is the same code as before. And at the start I've got a simple upsample version just to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6425" target="_blank">01:47:05.320</a></span> | <span class="t">kind of show you again the non-UNET version. This time I'm going to add in something called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6430" target="_blank">01:47:10.120</a></span> | <span class="t">the dice metric. Dice is very similar, as you see, to Jacquard, or A over U. It's just a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6438" target="_blank">01:47:18.360</a></span> | <span class="t">minor difference, it's basically intersection over union with a minor tweak. And the reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6447" target="_blank">01:47:27.800</a></span> | <span class="t">we're going to use dice is that's the metric that the Kaggle competition used. And it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6454" target="_blank">01:47:34.560</a></span> | <span class="t">a little bit harder to get a high dice score than a high accuracy because it's really looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6459" target="_blank">01:47:39.480</a></span> | <span class="t">at like what the overlap of the correct pixels are with your pixels. But it's pretty similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6466" target="_blank">01:47:46.960</a></span> | <span class="t">So in the Kaggle competition, people that were doing okay were getting about 99.6 dice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6473" target="_blank">01:47:53.320</a></span> | <span class="t">and the winners were about 99.7 dice. So here's our standard upsample, this is all as before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6481" target="_blank">01:48:01.440</a></span> | <span class="t">And so now we can check our dice metric. And so you can see on dice metric we're getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6486" target="_blank">01:48:06.960</a></span> | <span class="t">like 9.6.8 at 128x128. And so that's not great. So let's try UNET. And I'm calling it UNET-ish</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6500" target="_blank">01:48:20.000</a></span> | <span class="t">because as per usual I'm creating my own somewhat hacky version, kind of trying to keep things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6506" target="_blank">01:48:26.200</a></span> | <span class="t">similar to what you're used to as possible and doing things that I think make sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6511" target="_blank">01:48:31.840</a></span> | <span class="t">And so there should be plenty of opportunity for you to at least make this more authentically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6516" target="_blank">01:48:36.600</a></span> | <span class="t">UNET by looking at the exact kind of grid sizes. And like see how here the size is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6522" target="_blank">01:48:42.640</a></span> | <span class="t">down a little bit so they're obviously not adding any padding and then they're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6527" target="_blank">01:48:47.960</a></span> | <span class="t">here they've got some cropping going on. There's a few differences. But one of the things is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6534" target="_blank">01:48:54.920</a></span> | <span class="t">because I want to take advantage of transfer learning, that means I can't quite use UNET.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6540" target="_blank">01:49:00.640</a></span> | <span class="t">So here's another big opportunity is what if you create the UNET downpath and then add</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6550" target="_blank">01:49:10.120</a></span> | <span class="t">a classifier on the end and then train that on ImageNet. And you've now got an ImageNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6556" target="_blank">01:49:16.800</a></span> | <span class="t">trained classifier which is specifically designed to be a good backbone for UNET. And then you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6563" target="_blank">01:49:23.560</a></span> | <span class="t">should be able to now come back and get pretty close to winning this old competition. Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6574" target="_blank">01:49:34.040</a></span> | <span class="t">that pre-trained network didn't exist before. But if you think about what YOLOv3 did, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6581" target="_blank">01:49:41.040</a></span> | <span class="t">basically that. They created DarkNet, they pre-trained it on ImageNet and then they used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6585" target="_blank">01:49:45.840</a></span> | <span class="t">it as the basis for their founding boxes. So again, this kind of idea of pre-training things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6595" target="_blank">01:49:55.200</a></span> | <span class="t">which are designed not just for classification but for other things is just something that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6600" target="_blank">01:50:00.960</a></span> | <span class="t">nobody's done yet. But as we've shown, you can train ImageNet for 25 bucks in 3 hours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6615" target="_blank">01:50:15.720</a></span> | <span class="t">So and if people in the community are interested in doing this, hopefully I'll have credits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6621" target="_blank">01:50:21.400</a></span> | <span class="t">I can help you with as well. So if you do the work to get it set up and give me a script,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6625" target="_blank">01:50:25.720</a></span> | <span class="t">I can probably run it for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6630" target="_blank">01:50:30.320</a></span> | <span class="t">So for now though, we don't have that. So we're going to use ResNet. So we're basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6638" target="_blank">01:50:38.800</a></span> | <span class="t">going to start with this, let's see, with getBase. And so base is our base network and that was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6647" target="_blank">01:50:47.760</a></span> | <span class="t">defined back up in this first section. So getBase is going to be something that calls whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6653" target="_blank">01:50:53.920</a></span> | <span class="t">this is and this is ResNet 34. So we're going to grab our ResNet 34 and cutModel is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6659" target="_blank">01:50:59.640</a></span> | <span class="t">first thing that our ConvNet builder does. It basically removes everything from the adaptive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6664" target="_blank">01:51:04.400</a></span> | <span class="t">pulling onwards and so that gives us back the backbone of ResNet 34. So getBase is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6670" target="_blank">01:51:10.860</a></span> | <span class="t">to give us back our ResNet 34 backbone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6677" target="_blank">01:51:17.960</a></span> | <span class="t">And then we're going to take that ResNet 34 backbone and turn it into a unit 34. So what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6685" target="_blank">01:51:25.520</a></span> | <span class="t">that's going to do is it's going to save that ResNet that we passed in and then we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6693" target="_blank">01:51:33.200</a></span> | <span class="t">to use a forward hook, just like before, to save the results at the second, fourth, fifth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6698" target="_blank">01:51:38.440</a></span> | <span class="t">and sixth blocks, which as before is basically before each stride 2 convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6705" target="_blank">01:51:45.600</a></span> | <span class="t">Then we're going to create a bunch of these things we're calling unit blocks. And the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6710" target="_blank">01:51:50.200</a></span> | <span class="t">unit block basically says, so these unit blocks are these things. These are unit blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6717" target="_blank">01:51:57.720</a></span> | <span class="t">So the unit block tells us, we have to tell it, how many things are coming from the kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6724" target="_blank">01:52:04.640</a></span> | <span class="t">of previous layer that we're upsampling, how many are coming across, and then how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6730" target="_blank">01:52:10.400</a></span> | <span class="t">do we want to come at. And so the amount coming across is entirely defined by whatever the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6740" target="_blank">01:52:20.440</a></span> | <span class="t">base network was. Whatever the downward path was, we need that many layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6748" target="_blank">01:52:28.360</a></span> | <span class="t">And so this is a little bit awkward. And actually one of our master's students here, Karim, has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6753" target="_blank">01:52:33.800</a></span> | <span class="t">actually created something called dynamic unit that you'll find in fastai.unit.dynamic_unit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6761" target="_blank">01:52:41.960</a></span> | <span class="t">And it actually calculates this all for you and automatically creates the whole unit from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6766" target="_blank">01:52:46.760</a></span> | <span class="t">your base model. It's got some minor quirks still that I want to fix. By the time the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6772" target="_blank">01:52:52.480</a></span> | <span class="t">video is out, it'll definitely be working and I will at least have a notebook showing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6777" target="_blank">01:52:57.820</a></span> | <span class="t">how to use it and possibly an additional video. But for now, you'll just have to go through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6784" target="_blank">01:53:04.640</a></span> | <span class="t">and do it yourself. You can easily see it just by once you've got a resnet, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6788" target="_blank">01:53:08.960</a></span> | <span class="t">just go type in its name and it'll print out all the layers and you can see how many activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6796" target="_blank">01:53:16.080</a></span> | <span class="t">there are in each block. Or you could even have it printed out for you for each block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6804" target="_blank">01:53:24.720</a></span> | <span class="t">automatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6805" target="_blank">01:53:25.720</a></span> | <span class="t">Anyway, I just did this manually. And so the unit block works like this. So you said, "Okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6815" target="_blank">01:53:35.400</a></span> | <span class="t">I've got this many coming up from the previous layer, I've got this many coming across this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6819" target="_blank">01:53:39.240</a></span> | <span class="t">x." I'm using across from the downward path. This is the amount I want coming out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6825" target="_blank">01:53:45.440</a></span> | <span class="t">Now what I do is I then say, "Okay, we're going to create a certain amount of convolutions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6830" target="_blank">01:53:50.880</a></span> | <span class="t">from the upward path and a certain amount from the cross path and so I'm going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6835" target="_blank">01:53:55.120</a></span> | <span class="t">concatenating them together. So let's divide the number we want out by 2. And so we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6841" target="_blank">01:54:01.660</a></span> | <span class="t">going to have our cross convolution take our cross path and create number out divided by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6848" target="_blank">01:54:08.520</a></span> | <span class="t">2. And then the upward path is going to be a conv transpose 2D because we want to increase</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6856" target="_blank">01:54:16.400</a></span> | <span class="t">up sample. And again, here we've got the number n divided by 2. And then at the end, I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6863" target="_blank">01:54:23.200</a></span> | <span class="t">concatenate those together. So I've got an upward sample, I've got a cross convolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6870" target="_blank">01:54:30.480</a></span> | <span class="t">I concatenate the two together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6873" target="_blank">01:54:33.080</a></span> | <span class="t">And so that's all a unit block is. And so that's actually a pretty easy module to create.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6880" target="_blank">01:54:40.960</a></span> | <span class="t">And so then in my forward path, I need to pass to the forward of the unit block the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6887" target="_blank">01:54:47.800</a></span> | <span class="t">upward path and the cross path. So the upward path is just wherever I'm up to so far. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6895" target="_blank">01:54:55.160</a></span> | <span class="t">then the cross path is whatever the value is of whatever the activations are that I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6901" target="_blank">01:55:01.240</a></span> | <span class="t">stored on the way down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6904" target="_blank">01:55:04.600</a></span> | <span class="t">So as I come up, it's the last set of saved features that I need first. And as I gradually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6909" target="_blank">01:55:09.900</a></span> | <span class="t">keep going up further and further and further, eventually it's the first set of features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6916" target="_blank">01:55:16.700</a></span> | <span class="t">And so there are some more tricks we can do to make this a little bit better, but this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6921" target="_blank">01:55:21.640</a></span> | <span class="t">is a good start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6924" target="_blank">01:55:24.880</a></span> | <span class="t">So the simple upsampling approach looked horrible and had a dice of 968. A unit with everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6935" target="_blank">01:55:35.280</a></span> | <span class="t">else identical, except we've now got these unit blocks, has a dice of 985. So that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6944" target="_blank">01:55:44.600</a></span> | <span class="t">like we've kind of halved the error with everything else exactly the same. And more to the point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6951" target="_blank">01:55:51.720</a></span> | <span class="t">you can look at it. This is actually looking somewhat car-like compared to our non-unet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6957" target="_blank">01:55:57.360</a></span> | <span class="t">equivalent, which is just a blob. Because trying to do this through down and up paths,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6964" target="_blank">01:56:04.920</a></span> | <span class="t">it's just asking too much. Whereas when we actually provide the downward path pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6972" target="_blank">01:56:12.300</a></span> | <span class="t">at every point, it can actually start to create something car-ish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6976" target="_blank">01:56:16.600</a></span> | <span class="t">So at the end of that, we'll go .close to again remove those SFS features that are taking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6984" target="_blank">01:56:24.560</a></span> | <span class="t">up GPU memory, go to a smaller batch size, a higher size, and you can see the dice coefficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=6991" target="_blank">01:56:31.880</a></span> | <span class="t">is really going up. So notice here I'm loading in the 128x128 version of the network. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7002" target="_blank">01:56:42.120</a></span> | <span class="t">doing this progressive resizing trick again. So that gets us 99.3, and then unfreeze to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7008" target="_blank">01:56:48.160</a></span> | <span class="t">get to 99.4. And you can see it's now looking pretty good. Go down to a batch size of 4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7017" target="_blank">01:56:57.200</a></span> | <span class="t">size of 102.4, load in what we just did with the 512, takes us to 99.5, unfreeze, takes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7027" target="_blank">01:57:07.760</a></span> | <span class="t">us to 99. And as you can see, that actually looks good. Accuracy terms, 99.82. You can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7046" target="_blank">01:57:26.360</a></span> | <span class="t">see this is looking like something you could just about use to cut out. I think at this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7053" target="_blank">01:57:33.600</a></span> | <span class="t">point there's a couple of minor tweaks we can do to get up to 99.7, but really the key thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7060" target="_blank">01:57:40.200</a></span> | <span class="t">then I think is just maybe to do a little bit of smoothing maybe, or a little bit of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7065" target="_blank">01:57:45.920</a></span> | <span class="t">post-processing. You can go and have a look at the Carvana winner's blogs and see some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7073" target="_blank">01:57:53.560</a></span> | <span class="t">of these tricks. But as I say, the difference between where we're at 99.6 and what the winner's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7079" target="_blank">01:57:59.840</a></span> | <span class="t">got of 99.7 is not heaps. And so really the unit on its own pretty much solves that problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7095" target="_blank">01:58:15.400</a></span> | <span class="t">Okay so that's it. The last thing I wanted to mention is now to come all the way back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7101" target="_blank">01:58:21.160</a></span> | <span class="t">to bounding boxes. Because you might remember I said our bounding box model was still not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7108" target="_blank">01:58:28.880</a></span> | <span class="t">doing very well on small objects, so hopefully you might be able to guess where I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7114" target="_blank">01:58:34.800</a></span> | <span class="t">to go with this. Which is that for the bounding box model, remember how we had at different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7124" target="_blank">01:58:44.360</a></span> | <span class="t">grid cells, we spat out outputs of our model, and it was those earlier ones with the small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7134" target="_blank">01:58:54.200</a></span> | <span class="t">grid sizes that weren't very good. How do we fix it? Unet it. Let's have an upward path</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7143" target="_blank">01:59:03.520</a></span> | <span class="t">with cross-connections. And so then we're just going to do a unet and then spit them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7150" target="_blank">01:59:10.120</a></span> | <span class="t">out of that. Because now those finer grid cells have all of the information of that path and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7157" target="_blank">01:59:17.960</a></span> | <span class="t">that path and that path and that path to leverage. Now of course, this is deep learning, so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7165" target="_blank">01:59:25.600</a></span> | <span class="t">means you can't write a paper saying we just used unet for bounding boxes. You have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7172" target="_blank">01:59:32.080</a></span> | <span class="t">invent a new word. So this is called feature pyramid networks, or FPMs. And literally this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7182" target="_blank">01:59:42.040</a></span> | <span class="t">is part of the retina net paper, which is used in the retina net paper. It was created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7189" target="_blank">01:59:49.200</a></span> | <span class="t">in earlier papers specifically about FPMs. If memory says correctly, they did briefly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7195" target="_blank">01:59:55.200</a></span> | <span class="t">cite the unet paper, but they kind of made it sound like it was this vaguely slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7201" target="_blank">02:00:01.800</a></span> | <span class="t">connected thing that maybe some people could consider slightly useful. But it really, FPMs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7209" target="_blank">02:00:09.040</a></span> | <span class="t">is units. I don't have an implementation of it to show you, but it'll be a fun thing maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7217" target="_blank">02:00:17.360</a></span> | <span class="t">for some of us to try. I know some of the students have been trying to get it working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7224" target="_blank">02:00:24.400</a></span> | <span class="t">well on the forums. Interesting thing to try. So I think a couple of things to look at after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7232" target="_blank">02:00:32.400</a></span> | <span class="t">this class, as well as the other things I mentioned, would be playing around with FPMs and also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7239" target="_blank">02:00:39.560</a></span> | <span class="t">maybe trying Caram's dynamic unet. They would both be interesting things to look at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7246" target="_blank">02:00:46.360</a></span> | <span class="t">So you guys have all been through 14 lessons of me talking at you now, so I'm sorry about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7253" target="_blank">02:00:53.400</a></span> | <span class="t">that. Thanks for putting up with me. You're going to find it hard to find people who actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7265" target="_blank">02:01:05.880</a></span> | <span class="t">know as much about training neural networks in practice as you do. It'll be really easy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7272" target="_blank">02:01:12.360</a></span> | <span class="t">for you to overestimate how capable all these other people are and underestimate how capable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7279" target="_blank">02:01:19.400</a></span> | <span class="t">you are. The main thing to say is please practice. Please, just because you don't have this constant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7288" target="_blank">02:01:28.920</a></span> | <span class="t">thing getting you to come back here every Monday night now, it's very easy to kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7294" target="_blank">02:01:34.700</a></span> | <span class="t">lose that momentum. So find ways to keep it, organize a study group or a book reading group</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7305" target="_blank">02:01:45.040</a></span> | <span class="t">or get together with some friends and work on a project. Do something more than just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7312" target="_blank">02:01:52.740</a></span> | <span class="t">deciding I want to keep working on X. Unless you're the kind of person who's super motivated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7319" target="_blank">02:01:59.320</a></span> | <span class="t">and you know that whenever you decide to do something, it happens, that's not me. I know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7326" target="_blank">02:02:06.360</a></span> | <span class="t">something to happen. I have to say, "Yes, David, in October I will absolutely teach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7331" target="_blank">02:02:11.360</a></span> | <span class="t">that course." And then it's like, "Okay, I better actually write some material." That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7337" target="_blank">02:02:17.640</a></span> | <span class="t">the only way I can get stuff to happen. We've got a great community there on the forums.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7342" target="_blank">02:02:22.160</a></span> | <span class="t">If people have ideas for ways to make it better, please tell me. If you think you can help</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7347" target="_blank">02:02:27.240</a></span> | <span class="t">with, if you want to create some new forum or moderate it in some different way or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7352" target="_blank">02:02:32.980</a></span> | <span class="t">just let me know. You can always PM me. There's a lot of projects going on through GitHub</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7359" target="_blank">02:02:39.200</a></span> | <span class="t">as well, lots of stuff. I hope to see you all back here at Something Else. Thanks so much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7364" target="_blank">02:02:44.560</a></span> | <span class="t">for joining me on this journey.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nG3tT31nPmQ&t=7365" target="_blank">02:02:45.800</a></span> | <span class="t">[APPLAUSE]</span></div></div></body></html>