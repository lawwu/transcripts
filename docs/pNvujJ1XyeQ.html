<html><head><title>Today Unsupervised Sentence Transformers, Tomorrow Skynet (how TSDAE works)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Today Unsupervised Sentence Transformers, Tomorrow Skynet (how TSDAE works)</h2><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ"><img src="https://i.ytimg.com/vi_webp/pNvujJ1XyeQ/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=0">0:0</a> Why Language Embedding Matters<br><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=312">5:12</a> Supervised Methods<br><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=329">5:29</a> Natural Language Inference<br><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=435">7:15</a> Semantic Textual Similarity<br><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=463">7:43</a> Multilingual Training<br><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=600">10:0</a> TSDAE (Unsupervised)<br><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1130">18:50</a> Data Preparation<br><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1745">29:5</a> Initialize Model<br><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1959">32:39</a> Model Training<br><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2185">36:25</a> NLTK Error<br><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2235">37:15</a> Evaluation<br><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2461">41:1</a> TSDAE vs Supervised Methods<br><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2562">42:42</a> Why TSDAE is Cool<br><br><div style="text-align: left;"><a href="./pNvujJ1XyeQ.html">Whisper Transcript</a> | <a href="./transcript_pNvujJ1XyeQ.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">In this video we're going to have a look at how we can train sentence transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=4" target="_blank">00:00:04.560</a></span> | <span class="t">without needing any label data. So if you're new to sentence transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=11" target="_blank">00:00:11.160</a></span> | <span class="t">sentence embeddings or vectors, a sentence vector as we'll call it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=16" target="_blank">00:00:16.200</a></span> | <span class="t">simply a numerical representation of a sentence or paragraph. If you think about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=23" target="_blank">00:00:23.560</a></span> | <span class="t">language it's a very human centric concept, it's not built for computers so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=31" target="_blank">00:00:31.120</a></span> | <span class="t">computers really struggle to get the meaning or concepts that we as humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=38" target="_blank">00:00:38.240</a></span> | <span class="t">find very easy to communicate using language. Now the modern-ish computers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=45" target="_blank">00:00:45.160</a></span> | <span class="t">appeared during and around World War Two. The first application of NLP came soon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=51" target="_blank">00:00:51.280</a></span> | <span class="t">after in 1954 with the Georgetown machine translation experiment. In that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=57" target="_blank">00:00:57.760</a></span> | <span class="t">first decade of research those involved were pretty optimistic that they were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=63" target="_blank">00:01:03.280</a></span> | <span class="t">going to solve the problem of machine translation in just a few short years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=68" target="_blank">00:01:08.440</a></span> | <span class="t">Obviously they were a little bit optimistic and that's still a problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=74" target="_blank">00:01:14.800</a></span> | <span class="t">that's still not solved, we still haven't solved machine translation and the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=79" target="_blank">00:01:19.480</a></span> | <span class="t">goes for anything in NLP but in the past decade especially there have been a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=87" target="_blank">00:01:27.680</a></span> | <span class="t">of breakthroughs. The the field of NLP has progressed at an incredible rate in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=93" target="_blank">00:01:33.760</a></span> | <span class="t">just the past decade and we now have an incredible ecosystem of language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=103" target="_blank">00:01:43.520</a></span> | <span class="t">and techniques that we can use for a lot of different use cases. Now a lot of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=109" target="_blank">00:01:49.800</a></span> | <span class="t">recent success is in part thanks to the dense vector representations of language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=118" target="_blank">00:01:58.400</a></span> | <span class="t">So those are vectors, so numerical vectors that a machine can understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=125" target="_blank">00:02:05.200</a></span> | <span class="t">but are built in such a way that they actually provide a numerical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=130" target="_blank">00:02:10.120</a></span> | <span class="t">representation of the semantics or the meaning behind whatever is those vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=136" target="_blank">00:02:16.600</a></span> | <span class="t">represent, whether that be tokens, words or sentences, paragraphs and so on. So and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=143" target="_blank">00:02:23.240</a></span> | <span class="t">with those dense vectors we now have a way for computers to comprehend and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=151" target="_blank">00:02:31.240</a></span> | <span class="t">understand to an extent the semantic meaning behind language. To build those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=159" target="_blank">00:02:39.080</a></span> | <span class="t">you know given a lot of data and a lot of compute we tend to use transform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=165" target="_blank">00:02:45.080</a></span> | <span class="t">models. In NLP, transformers are the de facto standard and for building</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=172" target="_blank">00:02:52.560</a></span> | <span class="t">representations of sentences or paragraphs there is a subcategory of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=178" target="_blank">00:02:58.880</a></span> | <span class="t">transformers called sentence transformers. Now the training process to build a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=185" target="_blank">00:03:05.160</a></span> | <span class="t">transformer begins with something called pre-training that produces a generic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=192" target="_blank">00:03:12.920</a></span> | <span class="t">transformer model and then we fine-tune that, so we train that further using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=199" target="_blank">00:03:19.040</a></span> | <span class="t">special methods to build sentence transformers that can produce these very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=205" target="_blank">00:03:25.440</a></span> | <span class="t">information rich and accurate sentence vectors. Now whereas pre-training tends</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=214" target="_blank">00:03:34.200</a></span> | <span class="t">to use unsupervised training methods, fine-tuning tends to be more along the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=220" target="_blank">00:03:40.560</a></span> | <span class="t">lines of supervised training and what that means is that we need a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=226" target="_blank">00:03:46.920</a></span> | <span class="t">labeled data and for some domains and languages there simply is not enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=234" target="_blank">00:03:54.480</a></span> | <span class="t">labeled data out there to actually build a sentence transformer for those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=240" target="_blank">00:04:00.160</a></span> | <span class="t">specific domains or languages. So that means that you can either spend a long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=246" target="_blank">00:04:06.280</a></span> | <span class="t">time gathering data and labeling all the data to get tens of thousands of labeled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=253" target="_blank">00:04:13.120</a></span> | <span class="t">samples or you can go ahead and try fine-tuning model using unsupervised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=260" target="_blank">00:04:20.320</a></span> | <span class="t">training. Now unsupervised training I will tell you straight away is not going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=265" target="_blank">00:04:25.560</a></span> | <span class="t">to get you the performance that you would get from a supervised training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=270" target="_blank">00:04:30.040</a></span> | <span class="t">approach, however if you do not have the labeled data to train using a supervised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=276" target="_blank">00:04:36.000</a></span> | <span class="t">approach, unsupervised training is your best bet and it still works pretty well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=282" target="_blank">00:04:42.080</a></span> | <span class="t">So in this video that's what we're going to cover, we're going to cover how we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=287" target="_blank">00:04:47.560</a></span> | <span class="t">train a sentence transformer or fine-tune sentence transformer using a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=292" target="_blank">00:04:52.400</a></span> | <span class="t">unsupervised training method called transformer based sequential denoising</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=298" target="_blank">00:04:58.920</a></span> | <span class="t">autoencoder. So what we'll do is jump straight into it and take a look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=306" target="_blank">00:05:06.560</a></span> | <span class="t">where we might want to use this training approach and and how we can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=311" target="_blank">00:05:11.200</a></span> | <span class="t">implement it. So the first question we need to ask is do we really need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=318" target="_blank">00:05:18.560</a></span> | <span class="t">resort to unsupervised training? Now what we're going to do here is just have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=324" target="_blank">00:05:24.080</a></span> | <span class="t">look at a few most popular training approaches and what sort of data we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=328" target="_blank">00:05:28.240</a></span> | <span class="t">need for that. So the first one we're looking at here is natural language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=333" target="_blank">00:05:33.760</a></span> | <span class="t">inference or NLI and NLI requires that we have pairs of sentences that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=343" target="_blank">00:05:43.600</a></span> | <span class="t">labeled as either contradictory, neutral, which means they're not necessarily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=350" target="_blank">00:05:50.600</a></span> | <span class="t">related, or as entailing or as inferring each other. So you have you have pairs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=359" target="_blank">00:05:59.560</a></span> | <span class="t">that entail each other, so they are both very similar, pairs that are neutral and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=371" target="_blank">00:06:11.400</a></span> | <span class="t">also pairs that are contradictory. And this is the traditional NLI data. Now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=382" target="_blank">00:06:22.640</a></span> | <span class="t">using another version of fine-tuning with with NLI called multiple negatives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=393" target="_blank">00:06:33.480</a></span> | <span class="t">ranking loss, you can get by with only entailment pairs, so pairs that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=404" target="_blank">00:06:44.720</a></span> | <span class="t">related to each other or positive pairs. And it can also use contradictory pairs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=411" target="_blank">00:06:51.640</a></span> | <span class="t">to improve the performance of training as well, but you don't need it. So if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=417" target="_blank">00:06:57.040</a></span> | <span class="t">have positive pairs of related sentences, you can go ahead and actually try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=424" target="_blank">00:07:04.560</a></span> | <span class="t">training or fine-tuning using NLI with with multiple negative ranking loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=431" target="_blank">00:07:11.800</a></span> | <span class="t">If you don't have that, fine. Another option is that you have a semantic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=438" target="_blank">00:07:18.240</a></span> | <span class="t">textual similarity, DSL or STS, and what this is is you have, so you have sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=445" target="_blank">00:07:25.480</a></span> | <span class="t">A here, sentence B here, and then you have a score from from 0 to 1 that tells you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=453" target="_blank">00:07:33.680</a></span> | <span class="t">the similarity between those two scores. And you would train this using something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=460" target="_blank">00:07:40.400</a></span> | <span class="t">like cosine similarity loss. Now if that's not an option and your focus or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=467" target="_blank">00:07:47.400</a></span> | <span class="t">use case is on building a sentence transformer for another language where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=473" target="_blank">00:07:53.760</a></span> | <span class="t">there is no current sentence transformer, you can use multilingual parallel data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=480" target="_blank">00:08:00.760</a></span> | <span class="t">So what I mean by that is, so parallel data just means translation pairs. So if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=486" target="_blank">00:08:06.600</a></span> | <span class="t">you have, for example, a English sentence and then you have another language here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=493" target="_blank">00:08:13.560</a></span> | <span class="t">so it can it can be anything, I'm just going to put XX, and that XX is your target</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=499" target="_blank">00:08:19.040</a></span> | <span class="t">language, you can fine-tune a model using something called multilingual knowledge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=509" target="_blank">00:08:29.080</a></span> | <span class="t">distillation. And what that does is takes a monolingual model, for example in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=518" target="_blank">00:08:38.600</a></span> | <span class="t">English, and using those translation pairs it distills the knowledge, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=524" target="_blank">00:08:44.320</a></span> | <span class="t">semantic similarity knowledge, from that monolingual English model into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=530" target="_blank">00:08:50.040</a></span> | <span class="t">multilingual model which can handle both English and your target language. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=535" target="_blank">00:08:55.880</a></span> | <span class="t">they're three options that are quite popular, very common, that you can go for. And as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=544" target="_blank">00:09:04.600</a></span> | <span class="t">they're supervised methods, the chances are they're probably going to outperform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=549" target="_blank">00:09:09.320</a></span> | <span class="t">anything you do with unsupervised training, at least for now. So if none of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=556" target="_blank">00:09:16.320</a></span> | <span class="t">those sound like something you can do, the datasets, or if it sounds like you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=561" target="_blank">00:09:21.800</a></span> | <span class="t">probably can't get data that seems like that and it doesn't match your use case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=566" target="_blank">00:09:26.200</a></span> | <span class="t">then we would have to move on to unsupervised training. So like I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=573" target="_blank">00:09:33.800</a></span> | <span class="t">written here, you want to go for unsupervised if you have little to no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=577" target="_blank">00:09:37.440</a></span> | <span class="t">data in your unique domain or your low resource language. And with low</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=584" target="_blank">00:09:44.080</a></span> | <span class="t">resource language you also have no translation data. So from a source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=588" target="_blank">00:09:48.640</a></span> | <span class="t">language like English, or you can use other languages as well, just as long as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=593" target="_blank">00:09:53.000</a></span> | <span class="t">there's a monolingual model in that source language, to your target language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=599" target="_blank">00:09:59.000</a></span> | <span class="t">So if we can't do that, we move on to unsupervised learning. And one of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=606" target="_blank">00:10:06.280</a></span> | <span class="t">the best approaches at the moment is this transformer-based and sequential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=610" target="_blank">00:10:10.920</a></span> | <span class="t">denoising autoencoder. Now there are other approaches as well, but we're not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=616" target="_blank">00:10:16.440</a></span> | <span class="t">going to cover those. And I think for now this is probably your best bet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=621" target="_blank">00:10:21.720</a></span> | <span class="t">although there is other methods being researched that do look quite promising</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=626" target="_blank">00:10:26.160</a></span> | <span class="t">as well. So the way that TSD works is, if you have, let's say you have a sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=635" target="_blank">00:10:35.000</a></span> | <span class="t">here, what you do is you take your sentence and you corrupt that data. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=643" target="_blank">00:10:43.880</a></span> | <span class="t">we have this, and what we're going to do is it's just kind of remove parts of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=649" target="_blank">00:10:49.600</a></span> | <span class="t">that or modify it in a different way and do some other things to it. So it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=654" target="_blank">00:10:54.600</a></span> | <span class="t">slightly different, but not too different that it should not be similar. And we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=661" target="_blank">00:11:01.760</a></span> | <span class="t">take both of these, so we take the modified input and we feed it into our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=668" target="_blank">00:11:08.240</a></span> | <span class="t">encoder model, so our transformer. Our transformer outputs a set of tokens and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=677" target="_blank">00:11:17.040</a></span> | <span class="t">we use some sort of pooling method to convert those into a single sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=683" target="_blank">00:11:23.920</a></span> | <span class="t">vector. So with that sentence vector, we process that through another model here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=691" target="_blank">00:11:31.080</a></span> | <span class="t">which is a decoder model. So it goes into decoder model, and what that decoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=696" target="_blank">00:11:36.640</a></span> | <span class="t">model must do is actually optimize to produce a sentence here, to produce the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=706" target="_blank">00:11:46.640</a></span> | <span class="t">same text. So it has to try and predict this original sentence. And these weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=716" target="_blank">00:11:56.600</a></span> | <span class="t">in the decoder and encoder are optimized in order for the decoder to be able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=724" target="_blank">00:12:04.640</a></span> | <span class="t">actually do that. And that is TSDAE. It's not particularly complex</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=732" target="_blank">00:12:12.980</a></span> | <span class="t">when you sort of look at a very high level, and it's certainly a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=738" target="_blank">00:12:18.200</a></span> | <span class="t">intelligent way of building a sentence transformer without any labeled data. Now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=746" target="_blank">00:12:26.040</a></span> | <span class="t">let's have a look at a little graphic here to compare TSDAE to MLM. Now MLM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=755" target="_blank">00:12:35.120</a></span> | <span class="t">is master language modeling and that is a pre-training approach that a few of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=759" target="_blank">00:12:39.880</a></span> | <span class="t">you will probably be familiar with, and that's why I wanted to include this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=762" target="_blank">00:12:42.920</a></span> | <span class="t">comparison in here. So with MLM, which is the bottom down here, we take some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=775" target="_blank">00:12:55.760</a></span> | <span class="t">input text and we mask one of the tokens in that text. We pass it through an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=782" target="_blank">00:13:02.040</a></span> | <span class="t">encoder which outputs all these token vectors, and basically these token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=786" target="_blank">00:13:06.720</a></span> | <span class="t">vectors for every word almost, every word or subword here, will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=792" target="_blank">00:13:12.440</a></span> | <span class="t">represented by one of these token vectors or token embeddings. All those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=797" target="_blank">00:13:17.600</a></span> | <span class="t">pass into the decoder and the decoder attempts to predict which word or token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=807" target="_blank">00:13:27.040</a></span> | <span class="t">is behind that masked token here. So it's trying to optimize for that mask to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=813" target="_blank">00:13:33.560</a></span> | <span class="t">become an elephant. And that's how you use a pre-trainer transformer, or one of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=818" target="_blank">00:13:38.640</a></span> | <span class="t">ways that you can pre-train transformer. TSDAE is different for quite a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=825" target="_blank">00:13:45.800</a></span> | <span class="t">reasons, but I think the main reasons you can think of is, one, we are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=835" target="_blank">00:13:55.040</a></span> | <span class="t">necessarily masking the input, and it was found that the best way or the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=840" target="_blank">00:14:00.640</a></span> | <span class="t">approach is to actually delete the token. So you see here we should have that mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=846" target="_blank">00:14:06.920</a></span> | <span class="t">here, but it's not there anymore, we just removed it. So one, we delete rather than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=853" target="_blank">00:14:13.640</a></span> | <span class="t">mask, though in the TSDAE paper they did test both. We have an encoder as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=863" target="_blank">00:14:23.160</a></span> | <span class="t">before, but that is followed by this pooling step. And this pooling step takes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=871" target="_blank">00:14:31.040</a></span> | <span class="t">the token vectors that we see down here, and it converts them into a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=877" target="_blank">00:14:37.800</a></span> | <span class="t">sentence vector. So that sentence vector is passed on to the decoder, so if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=884" target="_blank">00:14:44.000</a></span> | <span class="t">compare both of these steps here, these two, the decoder in Masked Language Modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=889" target="_blank">00:14:49.800</a></span> | <span class="t">is getting a lot more information. It's getting token level information, whereas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=894" target="_blank">00:14:54.800</a></span> | <span class="t">the decoder in TSDAE is dealing with a lot less data and it's dealing with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=900" target="_blank">00:15:00.280</a></span> | <span class="t">sentence level information rather than token level information. And it is then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=906" target="_blank">00:15:06.400</a></span> | <span class="t">optimizing for the same thing to try and predict that we should have this text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=912" target="_blank">00:15:12.520</a></span> | <span class="t">here with elephant rather than the missing or corrupted text that was input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=918" target="_blank">00:15:18.920</a></span> | <span class="t">into the encoder initially. So that's the main difference between both of those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=925" target="_blank">00:15:25.320</a></span> | <span class="t">Now in the TSDAE paper from Wang, Reimers, and Gurevich, they tested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=936" target="_blank">00:15:36.680</a></span> | <span class="t">different approaches to fine-tuning. So the first of those is the noise type. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=945" target="_blank">00:15:45.200</a></span> | <span class="t">when we take that original text and we corrupt it, what is the best approach in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=951" target="_blank">00:15:51.480</a></span> | <span class="t">you know, how do we corrupt it? And they found that deleting tokens, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=957" target="_blank">00:15:57.880</a></span> | <span class="t">this box here, produced the best results. Other options, you can swap tokens, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=966" target="_blank">00:16:06.000</a></span> | <span class="t">swap one word for another, you can mask as we saw with Masked Language Modeling, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=970" target="_blank">00:16:10.680</a></span> | <span class="t">place those tokens, you can add new tokens, you do different things, right? But by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=977" target="_blank">00:16:17.840</a></span> | <span class="t">far, the best here was to just delete the token. Now there's also, you know, how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=985" target="_blank">00:16:25.180</a></span> | <span class="t">many tokens do you delete? So going through each token, you assign a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=989" target="_blank">00:16:29.680</a></span> | <span class="t">probability of that token being deleted and that's what we see here with this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=993" target="_blank">00:16:33.720</a></span> | <span class="t">noise ratio. So again, best best approach there is 0.6. Okay, so we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1001" target="_blank">00:16:41.840</a></span> | <span class="t">through each token and assigning probability of 60% that that token will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1006" target="_blank">00:16:46.560</a></span> | <span class="t">be deleted. So you are removing quite a lot of data. And then we have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1012" target="_blank">00:16:52.080</a></span> | <span class="t">pooling method, so the little circle after the encoder. And the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1019" target="_blank">00:16:59.200</a></span> | <span class="t">best or the highest performing approach here was using mean pooling, okay?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1026" target="_blank">00:17:06.840</a></span> | <span class="t">But to mean pool, you have another step of actually taking the average across all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1032" target="_blank">00:17:12.120</a></span> | <span class="t">those word vectors or token vectors, whereas with CLS pooling, you don't do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1039" target="_blank">00:17:19.080</a></span> | <span class="t">that. You just take the CLS token, which is a classified token from BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1047" target="_blank">00:17:27.000</a></span> | <span class="t">So if you've seen it before, it looks like this. Okay, and then you have your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1052" target="_blank">00:17:32.760</a></span> | <span class="t">other tokens following it. So that is the approach that they stuck with. They</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1058" target="_blank">00:17:38.400</a></span> | <span class="t">went and used deletion only in encrypting that data, a ratio of 0.6%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1066" target="_blank">00:17:46.320</a></span> | <span class="t">with a probability of 60%. And at the end, they used CLS pooling. You can use mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1074" target="_blank">00:17:54.960</a></span> | <span class="t">pooling as well, or even max. It's up to you, but later on we're going to stick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1080" target="_blank">00:18:00.040</a></span> | <span class="t">with CLS to follow along with the paper. It's just a actually quick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1085" target="_blank">00:18:05.760</a></span> | <span class="t">explanation of CLS and mean pooling if it's new to you. So we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1092" target="_blank">00:18:12.360</a></span> | <span class="t">our encoder. We output loads of token vectors. CLS pooling, we just take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1097" target="_blank">00:18:17.240</a></span> | <span class="t">that single vector, and that is our sentence vector. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1104" target="_blank">00:18:24.960</a></span> | <span class="t">not really doing anything there. We're just kind of extracting that vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1108" target="_blank">00:18:28.040</a></span> | <span class="t">Whereas with mean pooling, we're taking an average over all of the output token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1114" target="_blank">00:18:34.080</a></span> | <span class="t">vectors to create our sentence vector. So that's it for the visual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1120" target="_blank">00:18:40.880</a></span> | <span class="t">explanation. So let's jump into how to actually build or fine-tune a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1128" target="_blank">00:18:48.080</a></span> | <span class="t">using this approach. Okay, so we have here, I'm just loading a data set. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1136" target="_blank">00:18:56.560</a></span> | <span class="t">using HoganFace for data sets here. If you haven't used it before, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1141" target="_blank">00:19:01.880</a></span> | <span class="t">would want to pip install datasets. And what we're doing is getting the Oscar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1148" target="_blank">00:19:08.320</a></span> | <span class="t">dataset, Oscar corpus, which is basically a massive multilingual corpus. It has a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1153" target="_blank">00:19:13.720</a></span> | <span class="t">lot of different languages in there. I'm sure not every single language, but if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1160" target="_blank">00:19:20.160</a></span> | <span class="t">you can think of a language, it's probably in there. And we're taking the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1165" target="_blank">00:19:25.560</a></span> | <span class="t">English portion of that, just so I can actually read and understand things. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1173" target="_blank">00:19:33.760</a></span> | <span class="t">we're taking the training data. Okay, and this is important. So the Oscar dataset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1180" target="_blank">00:19:40.760</a></span> | <span class="t">or at least for English, the size of that is quite massive. It's 1.8 terabytes of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1189" target="_blank">00:19:49.560</a></span> | <span class="t">data. If you don't include the streaming true, all that's going to download to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1194" target="_blank">00:19:54.480</a></span> | <span class="t">your computer. And I assume you probably, a lot of us probably don't even have that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1199" target="_blank">00:19:59.840</a></span> | <span class="t">much memory available on our machines anyway, so it won't work. So you need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1207" target="_blank">00:20:07.920</a></span> | <span class="t">add streaming equals true, because what that will do is, as we request a sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1212" target="_blank">00:20:12.440</a></span> | <span class="t">from the dataset, it will download it and pull it through for us, one at a time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1216" target="_blank">00:20:16.280</a></span> | <span class="t">not the full thing. So it's obviously a lot more efficient. It's not going to break</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1221" target="_blank">00:20:21.840</a></span> | <span class="t">our computer or anything. Now, because we're streaming it, we have to kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1226" target="_blank">00:20:26.560</a></span> | <span class="t">iterate through it. So if I want to show you part of that, so I'm going to go four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1230" target="_blank">00:20:30.800</a></span> | <span class="t">row in Oscar, print that row, and just break. Okay, so we're just going to print</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1237" target="_blank">00:20:37.160</a></span> | <span class="t">the first item there. So we have these two features, ID, which is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1244" target="_blank">00:20:44.960</a></span> | <span class="t">an index ID value, and we also have text. Now in here, we can see quite a lot. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1252" target="_blank">00:20:52.760</a></span> | <span class="t">there's this text, and it's pretty long. So there's multiple paragraphs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1259" target="_blank">00:20:59.040</a></span> | <span class="t">in there, multiple sentences. And when we're training with TSDAE, we only want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1265" target="_blank">00:21:05.800</a></span> | <span class="t">small-ish sentences. We just want one sentence for each sample. So we need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1272" target="_blank">00:21:12.280</a></span> | <span class="t">split that. We need to split that up into just sentences. So to do that, I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1279" target="_blank">00:21:19.200</a></span> | <span class="t">to import RE, because I want to split for just periods here, full stops, periods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1288" target="_blank">00:21:28.120</a></span> | <span class="t">And I also want to split on newline characters, and I want to remove spaces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1294" target="_blank">00:21:34.120</a></span> | <span class="t">at the same time. So I just want to remove anything that indicates that this is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1297" target="_blank">00:21:37.560</a></span> | <span class="t">new sentence or paragraph, and split based on that character. So I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1304" target="_blank">00:21:44.320</a></span> | <span class="t">create a regex, re.compile, and that is going to be any full stop followed by a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1314" target="_blank">00:21:54.760</a></span> | <span class="t">space. That's an optional thing, so it doesn't have to be a space. And also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1321" target="_blank">00:22:01.560</a></span> | <span class="t">optionally, followed by a newline character. Okay, so this is just going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1325" target="_blank">00:22:05.800</a></span> | <span class="t">match any full stop for sure. And it will also allow for there to be a space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1331" target="_blank">00:22:11.720</a></span> | <span class="t">included in that, and they'll also allow for that to include a newline</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1337" target="_blank">00:22:17.200</a></span> | <span class="t">character as well. So that's going to capture everything for us. And let's see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1342" target="_blank">00:22:22.960</a></span> | <span class="t">what that looks like. So we write splitter.split, and we'll go row. So the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1350" target="_blank">00:22:30.960</a></span> | <span class="t">row it will just pull through text, and yeah. Okay, so now we see that we have all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1360" target="_blank">00:22:40.200</a></span> | <span class="t">these nice sentences rather than just one massive paragraph. You see some here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1366" target="_blank">00:22:46.440</a></span> | <span class="t">are not very long, and what we'll do is we'll remove them later on, because they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1372" target="_blank">00:22:52.600</a></span> | <span class="t">aren't really sentences. So let's do that. I'm gonna create a number here which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1384" target="_blank">00:23:04.360</a></span> | <span class="t">going to count number of sentences we manage to capture. So in reality, or at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1392" target="_blank">00:23:12.360</a></span> | <span class="t">least in the TSDA paper, they found that 10k is pretty much all you need, and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1400" target="_blank">00:23:20.840</a></span> | <span class="t">can sort of go up to 100k as well if you want. So we're going to go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1407" target="_blank">00:23:27.520</a></span> | <span class="t">up to 100k. We probably don't necessarily need to. Probably 10k, maybe even lower.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1412" target="_blank">00:23:32.480</a></span> | <span class="t">English is probably a reasonably easy one for this to figure out, so you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1417" target="_blank">00:23:37.160</a></span> | <span class="t">could possibly go even lower and still get decent results. So that's one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1423" target="_blank">00:23:43.360</a></span> | <span class="t">thing about TSDA is that you need very little data, which is pretty cool,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1428" target="_blank">00:23:48.080</a></span> | <span class="t">especially when it's not labeled. So we have sentences. I'm gonna create a list,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1433" target="_blank">00:23:53.280</a></span> | <span class="t">and we're going to just iterate through. So for row in OSCQR, we need to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1441" target="_blank">00:24:01.200</a></span> | <span class="t">our new sentences. So new sentences equals splitter.split, and that will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1448" target="_blank">00:24:08.360</a></span> | <span class="t">row text like we did before. And we also want to say we want to remove a sentence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1460" target="_blank">00:24:20.200</a></span> | <span class="t">so say line for line and sentence. If, sorry, in new sentences, new sentences, if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1472" target="_blank">00:24:32.640</a></span> | <span class="t">that line or length of that line is less than, no, greater than 10. Okay, so we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1484" target="_blank">00:24:44.160</a></span> | <span class="t">saying we only want to include strings that have a character length of greater</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1489" target="_blank">00:24:49.920</a></span> | <span class="t">than 10, and we can maybe even increase that because if we look at this, this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1494" target="_blank">00:24:54.320</a></span> | <span class="t">definitely more than 10. So let's just go with 20 for now and see how that goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1502" target="_blank">00:25:02.240</a></span> | <span class="t">Now, they're our new sentences from a single sample, and we want to extend our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1510" target="_blank">00:25:10.160</a></span> | <span class="t">sentences list with those new sentences. So we just write send new sentences. Okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1520" target="_blank">00:25:20.560</a></span> | <span class="t">and like I said, OSCQR is a massive data set. If we run through this for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1528" target="_blank">00:25:28.280</a></span> | <span class="t">whole data set, we're going to end up with a lot of sentences, and we don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1532" target="_blank">00:25:32.800</a></span> | <span class="t">need that many. We're only 10 to 100,000 sentences. So what I'm going to say is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1539" target="_blank">00:25:39.000</a></span> | <span class="t">number of sentences is going to be equal to the length of new sentences. So the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1547" target="_blank">00:25:47.720</a></span> | <span class="t">number of new sentences that we've just added, we're going to add that on to new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1552" target="_blank">00:25:52.440</a></span> | <span class="t">num, number of sentences. So once that exceeds 100k, then we want to break. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1569" target="_blank">00:26:09.280</a></span> | <span class="t">we want to stop its num sentence. Okay, and with that, we should be able to run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1577" target="_blank">00:26:17.760</a></span> | <span class="t">that. It should be quite quick. Okay, pretty nice and easy there, and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1588" target="_blank">00:26:28.160</a></span> | <span class="t">next step, as we usually would with PyTorch, is we want to put this data into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1596" target="_blank">00:26:36.440</a></span> | <span class="t">a data set object, and then we want to load that data set object into a data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1601" target="_blank">00:26:41.520</a></span> | <span class="t">loader. Now, because we're doing this thing where we corrupt our data by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1607" target="_blank">00:26:47.400</a></span> | <span class="t">adding noise to it, we either need to do that manually when we're building out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1612" target="_blank">00:26:52.680</a></span> | <span class="t">our data set object, or what we can do is just use the SentenceTransformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1619" target="_blank">00:26:59.000</a></span> | <span class="t">denoising autoencoder data set object. So to use that, we just write from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1625" target="_blank">00:27:05.040</a></span> | <span class="t">SentenceTransformers.datasets import denoising autoencoder data set, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1636" target="_blank">00:27:16.200</a></span> | <span class="t">we're also going to create a data loader now as well. So as we usually would in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1641" target="_blank">00:27:21.600</a></span> | <span class="t">PyTorch, we'll just import that as well. So it's from torch.data or utils.data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1650" target="_blank">00:27:30.280</a></span> | <span class="t">import data loader, and we want to create a data set. So data set is equal to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1661" target="_blank">00:27:41.080</a></span> | <span class="t">denoising autoencoder data set, and we just pass our data into that. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1668" target="_blank">00:27:48.640</a></span> | <span class="t">sentences, and that is all we need for our data set. So from now we can create our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1679" target="_blank">00:27:59.920</a></span> | <span class="t">data loader. So it's loader equals data loader, and we pass in our data set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1692" target="_blank">00:28:12.400</a></span> | <span class="t">and we also want to say, okay, what is the batch size, and do we want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1697" target="_blank">00:28:17.200</a></span> | <span class="t">to shuffle the data. So for the batch size, we're going to put 8. We do want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1703" target="_blank">00:28:23.480</a></span> | <span class="t">shuffle data. Shuffle is true, and we also want to drop the last batch, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1711" target="_blank">00:28:31.800</a></span> | <span class="t">this will not be the same batch size as the rest of our batches, or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1718" target="_blank">00:28:38.080</a></span> | <span class="t">most likely will not be. So we'll just drop it. It's easier. So we run that. So we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1724" target="_blank">00:28:44.720</a></span> | <span class="t">now have that. Our data is prepared for fine-tuning, and we now need to move on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1733" target="_blank">00:28:53.200</a></span> | <span class="t">to the final preparation before we actually fine-tune the model, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1739" target="_blank">00:28:59.800</a></span> | <span class="t">setting up the loss function and the actual training function itself. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1746" target="_blank">00:29:06.240</a></span> | <span class="t">before we actually even do the loss function, we need to define the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1750" target="_blank">00:29:10.600</a></span> | <span class="t">that we're going to be training. So we're going to be using vert-based encase from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1755" target="_blank">00:29:15.760</a></span> | <span class="t">hood-and-face transformers library, and to initialize that, or we will initialize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1761" target="_blank">00:29:21.080</a></span> | <span class="t">that through sentence transformers. So from sentence transformers, import from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1769" target="_blank">00:29:29.120</a></span> | <span class="t">sentence transformer, and we also want models. Now the vert model is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1780" target="_blank">00:29:40.400</a></span> | <span class="t">to be models.transformer, and then in here we just pass the name vert-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1787" target="_blank">00:29:47.120</a></span> | <span class="t">encase, so this will just download models directly from hood-and-face models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1793" target="_blank">00:29:53.160</a></span> | <span class="t">repository as we would with the transformers library. So we want to write</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1798" target="_blank">00:29:58.640</a></span> | <span class="t">vert-based encase, and then we also need a pooling layer. So write pooling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1806" target="_blank">00:30:06.560</a></span> | <span class="t">equals models.pooling, and as we saw before when we were working through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1815" target="_blank">00:30:15.160</a></span> | <span class="t">everything, we want to use pooling using the CLS or classifier token. So to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1823" target="_blank">00:30:23.200</a></span> | <span class="t">that, we will need to pass CLS in there. But before we do that, we also actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1829" target="_blank">00:30:29.840</a></span> | <span class="t">need to tell the pooling layer what number, what dimensionality to expect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1839" target="_blank">00:30:39.000</a></span> | <span class="t">from that vector. And to get that, I'll show you, we can just write vert equals get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1847" target="_blank">00:30:47.120</a></span> | <span class="t">word embedding dimension, and we'll see 768. But we will once it's actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1853" target="_blank">00:30:53.240</a></span> | <span class="t">defined, so let me put that in there. So I'll add that in there. Okay, run this, you'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1861" target="_blank">00:31:01.400</a></span> | <span class="t">see in a sec. Okay, that's just initializing everything, and we have that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1867" target="_blank">00:31:07.120</a></span> | <span class="t">768. Now what we have here are two separate layers, and we need to combine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1873" target="_blank">00:31:13.040</a></span> | <span class="t">them both or merge them both into a single sentence transform model. So to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1878" target="_blank">00:31:18.640</a></span> | <span class="t">that, we want to write model equals, this is where sentence transformer part comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1883" target="_blank">00:31:23.080</a></span> | <span class="t">in, we have modules, and that will be vert followed by the pooling layer. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1891" target="_blank">00:31:31.240</a></span> | <span class="t">we can also print out the description of that model as well. So we see we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1897" target="_blank">00:31:37.420</a></span> | <span class="t">have transformer using vert model, and we also see the pooling. We have the word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1905" target="_blank">00:31:45.680</a></span> | <span class="t">embedding dimension, and we also have the pooling mode CLS token is true, whereas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1911" target="_blank">00:31:51.600</a></span> | <span class="t">the rest of them are false, because we're not using those pooling methods. Now with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1915" target="_blank">00:31:55.840</a></span> | <span class="t">model defined, we can define our loss function. So write from sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1921" target="_blank">00:32:01.520</a></span> | <span class="t">transformers.losses, and we're going to import the denoising auto encode loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1928" target="_blank">00:32:08.760</a></span> | <span class="t">and we'll use that to define our loss function. So we just write denoising</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1935" target="_blank">00:32:15.480</a></span> | <span class="t">auto encode loss, and we pass in our model, so it knows what to actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1945" target="_blank">00:32:25.080</a></span> | <span class="t">optimize. And we also need to make sure that we tie the encoder and decoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1953" target="_blank">00:32:33.880</a></span> | <span class="t">weights, so we have true in there. Okay, because we have that encode decoder, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1961" target="_blank">00:32:41.000</a></span> | <span class="t">we're tying those weights together because the performance is there. We can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1963" target="_blank">00:32:43.880</a></span> | <span class="t">also set faults, but the performance will not be as good. So that is everything. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1974" target="_blank">00:32:54.200</a></span> | <span class="t">can go ahead and actually move on to the training function, so model.fit. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1979" target="_blank">00:32:59.800</a></span> | <span class="t">what we're going to be doing here is we write model.fit, and I'll just add a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1988" target="_blank">00:33:08.920</a></span> | <span class="t">points here. So we're going to be using an atom optimizer. We are going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=1994" target="_blank">00:33:14.000</a></span> | <span class="t">using a learning rate, so LR of 3e to -5, and that learning rate is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2002" target="_blank">00:33:22.960</a></span> | <span class="t">constant, so we're going to be using a constant learning rate. So if you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2009" target="_blank">00:33:29.000</a></span> | <span class="t">watched the last videos, we have tended to use a warm-up before we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2015" target="_blank">00:33:35.200</a></span> | <span class="t">actually move on to that learning rate, so we warm up to that learning rate. With</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2019" target="_blank">00:33:39.400</a></span> | <span class="t">this, we're just going to use constant learning rate all the way through, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2022" target="_blank">00:33:42.560</a></span> | <span class="t">there's also no weight decay in there. So model.fit, we need to say what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2030" target="_blank">00:33:50.600</a></span> | <span class="t">are our training objectives, so we just write train objectives, and then in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2040" target="_blank">00:34:00.600</a></span> | <span class="t">there we pass a list, and in here we need pairs of data loaders and the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2047" target="_blank">00:34:07.400</a></span> | <span class="t">functions we're going to use to optimize with that data. In our case, we just have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2051" target="_blank">00:34:11.680</a></span> | <span class="t">one of these, so it's just load up the data and also loss. We're going to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2058" target="_blank">00:34:18.000</a></span> | <span class="t">for one epoch, so epoch equals 1. We are going to be using the atom optimizer. The</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2066" target="_blank">00:34:26.700</a></span> | <span class="t">default optimizer here is a atom W or atom weight decay optimizer from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2074" target="_blank">00:34:34.640</a></span> | <span class="t">Transformers library, so if we want to use atom, we just set the weight decay to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2080" target="_blank">00:34:40.520</a></span> | <span class="t">zero. So we write weight decay equals zero. We also need to set scheduler, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2089" target="_blank">00:34:49.160</a></span> | <span class="t">this is why I mentioned before, so scheduler equals constant learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2097" target="_blank">00:34:57.200</a></span> | <span class="t">Okay, so we're not doing any warm-up, we're just going with a constant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2101" target="_blank">00:35:01.720</a></span> | <span class="t">learning rate all the way through, and then we want to pass our optimizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2106" target="_blank">00:35:06.440</a></span> | <span class="t">parameters. So here we're just passing the learning rate, nothing more, so that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2112" target="_blank">00:35:12.840</a></span> | <span class="t">3e to the minus 5, and while training we're probably going to want to see the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2119" target="_blank">00:35:19.720</a></span> | <span class="t">progress bar, so I'm going to set that equal to true as well. Now after that, after we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2129" target="_blank">00:35:29.520</a></span> | <span class="t">finish training, you're probably going to want to save the model, so you can save</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2134" target="_blank">00:35:34.680</a></span> | <span class="t">that as wherever you would like. So I'm going to write TSDAE, but I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2144" target="_blank">00:35:44.840</a></span> | <span class="t">start running that, and now I'm going to stop it, because it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2150" target="_blank">00:35:50.000</a></span> | <span class="t">take long, to be fair. With 100,000 samples, this took 20 minutes on a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2155" target="_blank">00:35:55.480</a></span> | <span class="t">reasonably good GPU, so that's a RTX 3090, so it's obviously a decent GPU, but it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2162" target="_blank">00:36:02.920</a></span> | <span class="t">nothing like Tesla or anything like that. So this is really quick, I was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2169" target="_blank">00:36:09.800</a></span> | <span class="t">pretty impressed. Okay, so you can see that this is training, so what I'm going to do is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2174" target="_blank">00:36:14.040</a></span> | <span class="t">pause that, or stop that, and I'm going to switch over to the other notebook where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2178" target="_blank">00:36:18.080</a></span> | <span class="t">I have that training, and the evaluation I performed afterwards, we'll just run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2183" target="_blank">00:36:23.240</a></span> | <span class="t">through it really quickly. Okay, so we're here now, yep, you can see everything is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2190" target="_blank">00:36:30.920</a></span> | <span class="t">the same as before, model save, I've saved it there, and oh, there was one thing I did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2198" target="_blank">00:36:38.680</a></span> | <span class="t">want to mention. So if you do get an error with NLTK, you just need to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2205" target="_blank">00:36:45.320</a></span> | <span class="t">this. You just need to either pip install NLTK, if you haven't already got it installed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2210" target="_blank">00:36:50.320</a></span> | <span class="t">and then you just run this, input NLTK, and that's going to download this PUNT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2214" target="_blank">00:36:54.760</a></span> | <span class="t">tokenizer, which is used in the denoising process, so where we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2222" target="_blank">00:37:02.360</a></span> | <span class="t">adding noise and denoising and whatever else, it uses that tokenizer, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2227" target="_blank">00:37:07.120</a></span> | <span class="t">that's why we need that in there. So if you do get that error, just run that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2235" target="_blank">00:37:15.120</a></span> | <span class="t">So after that, we train the model, and we want to evaluate the performance of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2241" target="_blank">00:37:21.080</a></span> | <span class="t">the model because we want to see that it has actually worked. So one benchmark that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2248" target="_blank">00:37:28.200</a></span> | <span class="t">you've probably seen me use a few times already is the Semantic Textual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2252" target="_blank">00:37:32.480</a></span> | <span class="t">Similarity Benchmark, or STSB, which, again, we can use Hugging Face datasets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2258" target="_blank">00:37:38.040</a></span> | <span class="t">to pull that, so it's from the Glue dataset, it's the STSB part of that, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2263" target="_blank">00:37:43.760</a></span> | <span class="t">we're going to take the validation split, so we're not taking the training data, though we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2269" target="_blank">00:37:49.460</a></span> | <span class="t">can if we want because we haven't trained it on that, just in case. And that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2274" target="_blank">00:37:54.880</a></span> | <span class="t">contains one sentence, two sentences, and a label. This label is a score, so if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2281" target="_blank">00:38:01.040</a></span> | <span class="t">remember earlier we were talking about STS data that we can train using cosine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2287" target="_blank">00:38:07.820</a></span> | <span class="t">similarity loss, this is the data that we would use. So we have that label</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2293" target="_blank">00:38:13.680</a></span> | <span class="t">score, and in this dataset, it ranges from 0 to 5, we want to normalize that from 0</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2300" target="_blank">00:38:20.400</a></span> | <span class="t">to 1. So that's what I'm doing here, I'm using the datasets map function and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2306" target="_blank">00:38:26.480</a></span> | <span class="t">then a lambda in here, and we're just dividing all those by 5, mapping them all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2312" target="_blank">00:38:32.960</a></span> | <span class="t">from 0 to 1. Then we are reformatting that benchmark data, the STSB data, using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2322" target="_blank">00:38:42.500</a></span> | <span class="t">the Sentence Transformers input example class, so we need this because we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2327" target="_blank">00:38:47.480</a></span> | <span class="t">using the evaluators from the Sentence Transformers library later. So all we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2333" target="_blank">00:38:53.120</a></span> | <span class="t">there is we loop through, create a list, and we append input example objects that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2339" target="_blank">00:38:59.600</a></span> | <span class="t">contain the two sentences and the label, so the score. And then we initialize a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2346" target="_blank">00:39:06.920</a></span> | <span class="t">similarity evaluator, so we can see this is called Embedding Similarity Evaluator,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2353" target="_blank">00:39:13.320</a></span> | <span class="t">so that's for this type of data, the STS data, and we're just passing all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2359" target="_blank">00:39:19.700</a></span> | <span class="t">samples we have there, and you can write to CSV if you want, but I'm not doing that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2363" target="_blank">00:39:23.240</a></span> | <span class="t">because I just want to see the score in here, I don't really, I don't want to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2368" target="_blank">00:39:28.120</a></span> | <span class="t">all the detail, so I just want to have a look at the overall score. And then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2373" target="_blank">00:39:33.100</a></span> | <span class="t">just evaluate the model, so you just pass the model to your evaluator, and using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2379" target="_blank">00:39:39.000</a></span> | <span class="t">the model that we trained with TSDAE, we get 0.75, which is the Spearman's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2388" target="_blank">00:39:48.040</a></span> | <span class="t">coefficients, so basically saying how, where our model is scoring high, does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2396" target="_blank">00:39:56.720</a></span> | <span class="t">that correlate to where the true scores are high, or the true labels are high, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2402" target="_blank">00:40:02.120</a></span> | <span class="t">0.75 means yes, there is correlation there, it's pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2409" target="_blank">00:40:09.360</a></span> | <span class="t">strong, right, it's not the strongest, as we'll see in a minute, but it's pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2413" target="_blank">00:40:13.600</a></span> | <span class="t">strong. So that's a good score, and we can see that it is working. Now, if we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2422" target="_blank">00:40:22.440</a></span> | <span class="t">compare that to an untrained model, so what we had before, before we actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2426" target="_blank">00:40:26.120</a></span> | <span class="t">fine-tuned it with TSDAE, so we scroll down, I've just reinitialized something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2433" target="_blank">00:40:33.920</a></span> | <span class="t">here, the same model as before, and evaluated it, scroll down a little bit to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2438" target="_blank">00:40:38.480</a></span> | <span class="t">find the score, and you see that it's like 0.32, which is obviously way lower,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2444" target="_blank">00:40:44.040</a></span> | <span class="t">and yeah, there's some correlation there, but it's not great. So TSDAE is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2452" target="_blank">00:40:52.760</a></span> | <span class="t">giving us pretty good results, I think, like it is really not bad. Now, something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2461" target="_blank">00:41:01.560</a></span> | <span class="t">we mentioned earlier is, yes, TSDAE works, it's an unsupervised method, but the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2467" target="_blank">00:41:07.120</a></span> | <span class="t">unsupervised method is, or cannot really be compared to supervised methods in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2474" target="_blank">00:41:14.720</a></span> | <span class="t">terms of the performance that you'll get from your Sentence Transformer, and so I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2479" target="_blank">00:41:19.760</a></span> | <span class="t">wanted to show you that here. So first thing I've done, it is taking the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2484" target="_blank">00:41:24.400</a></span> | <span class="t">original SBIRT, so the first one, and okay, we get 0.8, or 0.81 if you want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2493" target="_blank">00:41:33.920</a></span> | <span class="t">round up. So it's about 7% better than the other, than the unsupervised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2503" target="_blank">00:41:43.080</a></span> | <span class="t">method, which is a fair bit, but it's not massive, so at least our unsupervised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2509" target="_blank">00:41:49.400</a></span> | <span class="t">model is up there in like a good area of performance. It's not the best, but it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2515" target="_blank">00:41:55.880</a></span> | <span class="t">does work. And as well, in the paper they did do better than this, I think they got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2522" target="_blank">00:42:02.400</a></span> | <span class="t">to, I think, 78 maybe? So they also did better than what I got here anyway, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2530" target="_blank">00:42:10.480</a></span> | <span class="t">you can probably do better. And then I wanted to look at a more advanced model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2536" target="_blank">00:42:16.280</a></span> | <span class="t">one of the more recent models at least, like MPNet. So the MPNet model scored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2544" target="_blank">00:42:24.440</a></span> | <span class="t">pretty much 89, or 0.89. So we get okay result, or I think pretty good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2552" target="_blank">00:42:32.760</a></span> | <span class="t">result TSA, but obviously I can't compare it to those unsupervised models. Now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2560" target="_blank">00:42:40.020</a></span> | <span class="t">that's it for this video. I think, at least for me, this unsupervised approach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2567" target="_blank">00:42:47.480</a></span> | <span class="t">to training is actually one of the coolest things, or at least one of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2574" target="_blank">00:42:54.120</a></span> | <span class="t">coolest approaches to training and building models that I've seen in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2578" target="_blank">00:42:58.000</a></span> | <span class="t">sentence transformers. Possibly only really paralleled with multilingual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2584" target="_blank">00:43:04.760</a></span> | <span class="t">knowledge of distillation for training multilingual models. Both of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2589" target="_blank">00:43:09.280</a></span> | <span class="t">together, for me, I think are really incredible. I know this isn't like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2594" target="_blank">00:43:14.200</a></span> | <span class="t">best performance. When you think about all of the low resource languages out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2600" target="_blank">00:43:20.120</a></span> | <span class="t">there that don't really have that much data, they just have unstructured text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2604" target="_blank">00:43:24.560</a></span> | <span class="t">states like this, or the domains, very specific domains, where they just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2611" target="_blank">00:43:31.840</a></span> | <span class="t">have loads of text data, but they don't have label data, and they can't afford to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2615" target="_blank">00:43:35.880</a></span> | <span class="t">pay someone to go and create all that data, or don't have the time to even. I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2620" target="_blank">00:43:40.400</a></span> | <span class="t">think this is a really cool method to actually be able to use. I mean you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2628" target="_blank">00:43:48.560</a></span> | <span class="t">don't really need anything. So for that reason, I think this is really cool, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2635" target="_blank">00:43:55.360</a></span> | <span class="t">is definitely one of the most interesting ways of training, in my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2643" target="_blank">00:44:03.240</a></span> | <span class="t">opinion. Just training something without label data that actually works pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2649" target="_blank">00:44:09.320</a></span> | <span class="t">well. So yeah, that's it for this video. I hope it's been useful, and thank you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pNvujJ1XyeQ&t=2657" target="_blank">00:44:17.560</a></span> | <span class="t">very much for watching, and I'll see you in the next one.</span></div></div></body></html>