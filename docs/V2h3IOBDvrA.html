<html><head><title>Lesson 4: Practical Deep Learning for Coders</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 4: Practical Deep Learning for Coders</h2><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA"><img src="https://i.ytimg.com/vi_webp/V2h3IOBDvrA/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./V2h3IOBDvrA.html">Whisper Transcript</a> | <a href="./transcript_V2h3IOBDvrA.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">I guess I noticed during the week from some of the questions I've been seeing that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6" target="_blank">00:00:06.460</a></span> | <span class="t">idea of what a convolution is, is still a little counter-intuitive or surprising to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=14" target="_blank">00:00:14.020</a></span> | <span class="t">some people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=15" target="_blank">00:00:15.860</a></span> | <span class="t">I feel like the only way I know to teach things effectively is by creating a spreadsheet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=20" target="_blank">00:00:20.740</a></span> | <span class="t">so here we are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=23" target="_blank">00:00:23.420</a></span> | <span class="t">This is the famous number 7 from lesson 0, and I just copied and pasted the numbers into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=30" target="_blank">00:00:30.700</a></span> | <span class="t">a spreadsheet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=31" target="_blank">00:00:31.700</a></span> | <span class="t">They're not exactly 0, they're actually floats, just rounded off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=39" target="_blank">00:00:39.060</a></span> | <span class="t">And as you can see, I'm just using conditional coloring, you can see the shape of our little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=44" target="_blank">00:00:44.700</a></span> | <span class="t">number 7 here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=47" target="_blank">00:00:47.140</a></span> | <span class="t">So I wanted to show you exactly what a convolution does, and specifically what a convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=52" target="_blank">00:00:52.420</a></span> | <span class="t">does in a deep learning neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=57" target="_blank">00:00:57.660</a></span> | <span class="t">So we are generally using modern convolutions, and that means a 3x3 convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=64" target="_blank">00:01:04.700</a></span> | <span class="t">So here is a 3x3 convolution, and I have just randomly generated 9 random numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=73" target="_blank">00:01:13.740</a></span> | <span class="t">So that is a filter, there's one filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=77" target="_blank">00:01:17.540</a></span> | <span class="t">Here is my second filter, it is 9 more random numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=83" target="_blank">00:01:23.500</a></span> | <span class="t">So this is what we do in Keras when we ask for a convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=90" target="_blank">00:01:30.020</a></span> | <span class="t">We tell it, the first thing we pass it is how many filters do we want, and that's how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=95" target="_blank">00:01:35.540</a></span> | <span class="t">many of these random matrices do we want it to build for us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=100" target="_blank">00:01:40.880</a></span> | <span class="t">So in this case, it's as if I passed convolution2D, the first parameter would be 2, and the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=106" target="_blank">00:01:46.700</a></span> | <span class="t">parameter would be 3,3, because it's a 3x3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=110" target="_blank">00:01:50.900</a></span> | <span class="t">And what happens to this little random matrix?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=115" target="_blank">00:01:55.140</a></span> | <span class="t">In order to calculate the very first item, it takes the sum of the blue stuff, those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=126" target="_blank">00:02:06.380</a></span> | <span class="t">9, times the red stuff, those 9, all added together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=133" target="_blank">00:02:13.460</a></span> | <span class="t">So let's go down here into where it gets a bit darker, how does this get calculated?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=137" target="_blank">00:02:17.980</a></span> | <span class="t">This is equal to these 9 times these 9, when I say times, I mean element-wise times, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=145" target="_blank">00:02:25.100</a></span> | <span class="t">the top left by the top left, the middle by the middle, and so forth, and add them all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=149" target="_blank">00:02:29.460</a></span> | <span class="t">together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=152" target="_blank">00:02:32.940</a></span> | <span class="t">That's all a convolution is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=153" target="_blank">00:02:33.940</a></span> | <span class="t">So it's just as you go through, we take the corresponding 3x3 area in the image, and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=162" target="_blank">00:02:42.420</a></span> | <span class="t">multiply each of those 9 things by each of these 9 things, and then we add those 9 products</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=167" target="_blank">00:02:47.940</a></span> | <span class="t">together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=170" target="_blank">00:02:50.660</a></span> | <span class="t">That's it, that's a convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=172" target="_blank">00:02:52.900</a></span> | <span class="t">So there's really nothing particularly weird or confusing about it, and I'll make this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=179" target="_blank">00:02:59.160</a></span> | <span class="t">available in class so you can have a look.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=181" target="_blank">00:03:01.820</a></span> | <span class="t">You can see that when I get to the top left corner, I can't move further left and up because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=189" target="_blank">00:03:09.940</a></span> | <span class="t">I've reached the edge, and this is why when you do a 3x3 convolution without zero padding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=197" target="_blank">00:03:17.020</a></span> | <span class="t">you lose one pixel on each edge because you can't push this 3x3 any further.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=204" target="_blank">00:03:24.580</a></span> | <span class="t">So if we go down to the bottom left, you can see again the same thing, it kind of gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=209" target="_blank">00:03:29.940</a></span> | <span class="t">stuck in the corner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=211" target="_blank">00:03:31.380</a></span> | <span class="t">So that's why you can see that my result is one row less than my starting point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=219" target="_blank">00:03:39.220</a></span> | <span class="t">So I did this for two different filters, so here's my second filter, and you can see when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=224" target="_blank">00:03:44.580</a></span> | <span class="t">I calculate this one, it's exactly the same thing, it's these 9 times each of these 9</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=234" target="_blank">00:03:54.580</a></span> | <span class="t">added together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=235" target="_blank">00:03:55.580</a></span> | <span class="t">These are just 9 other random numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=239" target="_blank">00:03:59.220</a></span> | <span class="t">So that's how we start with our first, in this case I've created two convolutional filters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=246" target="_blank">00:04:06.340</a></span> | <span class="t">and this is the output of those two convolutional filters, they're just random at this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=251" target="_blank">00:04:11.300</a></span> | <span class="t">So my second layer, now my second layer is no longer enough just to have a 3x3 matrix,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=257" target="_blank">00:04:17.260</a></span> | <span class="t">and I need a 3x3x2 tensor because to calculate my top left of my second convolutional layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=269" target="_blank">00:04:29.440</a></span> | <span class="t">I need these 9 by these 9 added together, plus these 9 by these 9 added together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=281" target="_blank">00:04:41.300</a></span> | <span class="t">Because at this point, my previous layer is no longer just one thing, but it's two things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=287" target="_blank">00:04:47.380</a></span> | <span class="t">Now indeed, if our original picture was a 3-channel color picture, our very first convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=294" target="_blank">00:04:54.900</a></span> | <span class="t">layer would have had to have been 3x3x3 tensors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=301" target="_blank">00:05:01.020</a></span> | <span class="t">So all of the convolutional layers from now on are going to be 3x3x number of filters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=308" target="_blank">00:05:08.780</a></span> | <span class="t">in the previous layer convolution matrices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=313" target="_blank">00:05:13.900</a></span> | <span class="t">So here is my first, I've just drawn it like this, 3x3x2 tensor, and you can see it's taking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=321" target="_blank">00:05:21.580</a></span> | <span class="t">9 from here, 9 from here and adding those two together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=326" target="_blank">00:05:26.860</a></span> | <span class="t">And so then for my second filter in my second layer, it's exactly the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=333" target="_blank">00:05:33.140</a></span> | <span class="t">I've created two more random matrices, or one more random 3x3x2 tensor, and here again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=340" target="_blank">00:05:40.360</a></span> | <span class="t">I have those 9 by these 9 sum plus those 9 by those 9 sum, and that gives me that one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=353" target="_blank">00:05:53.980</a></span> | <span class="t">So that gives me my first two layers of my convolutional neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=359" target="_blank">00:05:59.420</a></span> | <span class="t">Then I do max pooling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=362" target="_blank">00:06:02.980</a></span> | <span class="t">Max pooling is slightly more awkward to do in Excel, but that's fine, we can still handle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=367" target="_blank">00:06:07.940</a></span> | <span class="t">it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=369" target="_blank">00:06:09.800</a></span> | <span class="t">So here's max pooling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=371" target="_blank">00:06:11.140</a></span> | <span class="t">So max pooling, because I'm going to do 2x2 max pooling, it's going to decrease the resolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=376" target="_blank">00:06:16.780</a></span> | <span class="t">of my image by 2 on each axis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=380" target="_blank">00:06:20.320</a></span> | <span class="t">So how do we calculate that number?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=384" target="_blank">00:06:24.120</a></span> | <span class="t">That number is simply the maximum of those 4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=389" target="_blank">00:06:29.260</a></span> | <span class="t">And then that number is the maximum of those 4, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=394" target="_blank">00:06:34.860</a></span> | <span class="t">So with max pooling, we had two filters in the previous layer, so we still have two filters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=403" target="_blank">00:06:43.060</a></span> | <span class="t">but now our filters have half the resolution in each of the x and y axes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=411" target="_blank">00:06:51.820</a></span> | <span class="t">And so then I thought, okay, we've done two convolutional layers, how did you go from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=419" target="_blank">00:06:59.860</a></span> | <span class="t">one matrix to two matrices in the second layer?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=425" target="_blank">00:07:05.300</a></span> | <span class="t">How did I go from one matrix to two matrices, as in how did I go from just this one thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=430" target="_blank">00:07:10.940</a></span> | <span class="t">to these two things?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=434" target="_blank">00:07:14.260</a></span> | <span class="t">So the answer to that is I just created two random 3x3 filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=439" target="_blank">00:07:19.180</a></span> | <span class="t">This is my first random 3x3 filter, this is my second random 3x3 filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=444" target="_blank">00:07:24.980</a></span> | <span class="t">So each output then was simply equal to each corresponding 9-element section, multiplied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=454" target="_blank">00:07:34.100</a></span> | <span class="t">by each other, and added together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=455" target="_blank">00:07:35.640</a></span> | <span class="t">So because I had two random 3x3 matrices, I ended up with two outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=462" target="_blank">00:07:42.540</a></span> | <span class="t">Two filters means two sets of outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=468" target="_blank">00:07:48.780</a></span> | <span class="t">Alright, so now that we've got our max pooling layer, let's use a dense layer to turn it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=479" target="_blank">00:07:59.820</a></span> | <span class="t">into our output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=483" target="_blank">00:08:03.140</a></span> | <span class="t">So a dense layer means that every single one of our activations from our max pooling layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=491" target="_blank">00:08:11.060</a></span> | <span class="t">needs a random weight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=493" target="_blank">00:08:13.460</a></span> | <span class="t">So these are a whole bunch of random numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=497" target="_blank">00:08:17.540</a></span> | <span class="t">So what I do is I take every one of those random numbers and multiply each one by a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=504" target="_blank">00:08:24.140</a></span> | <span class="t">corresponding input and add them all together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=513" target="_blank">00:08:33.780</a></span> | <span class="t">So I've got the sum product of this and this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=516" target="_blank">00:08:36.860</a></span> | <span class="t">In MNIST we would have 10 activations because we need an activation for 0, 1, 2, 3, so forth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=523" target="_blank">00:08:43.540</a></span> | <span class="t">up to 9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=524" target="_blank">00:08:44.620</a></span> | <span class="t">So for MNIST we would need 10 sets of these dense weight matrices so that we could calculate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=532" target="_blank">00:08:52.860</a></span> | <span class="t">the 10 outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=536" target="_blank">00:08:56.600</a></span> | <span class="t">If we were only calculating one output, this would be a perfectly reasonable way to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=542" target="_blank">00:09:02.540</a></span> | <span class="t">it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=543" target="_blank">00:09:03.540</a></span> | <span class="t">So for one output, it's just the sum product of everything from our final layer with a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=550" target="_blank">00:09:10.900</a></span> | <span class="t">weight for everything in that final layer, add it together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=557" target="_blank">00:09:17.740</a></span> | <span class="t">So that's all a dense layer is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=564" target="_blank">00:09:24.260</a></span> | <span class="t">Both dense layers and convolutional layers couldn't be easier mathematically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=573" target="_blank">00:09:33.140</a></span> | <span class="t">I think the surprising thing is when you say rather than using random weights, let's calculate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=581" target="_blank">00:09:41.980</a></span> | <span class="t">the derivative of what happens if we were to change that weight up by a bit or down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=587" target="_blank">00:09:47.940</a></span> | <span class="t">by a bit, and how would it impact our loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=591" target="_blank">00:09:51.100</a></span> | <span class="t">In this case, I haven't actually got as far as calculating a loss function, but we could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=596" target="_blank">00:09:56.100</a></span> | <span class="t">add over here a sigmoid loss, for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=601" target="_blank">00:10:01.980</a></span> | <span class="t">And so we can calculate the derivative of the loss with respect to every single weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=605" target="_blank">00:10:05.940</a></span> | <span class="t">in the dense layer, and every single weight in all of our filters in that layer, and every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=613" target="_blank">00:10:13.500</a></span> | <span class="t">single weight in all of our filters in this layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=618" target="_blank">00:10:18.100</a></span> | <span class="t">And then with all of those derivatives, we can calculate how to optimize all of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=621" target="_blank">00:10:21.420</a></span> | <span class="t">weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=622" target="_blank">00:10:22.860</a></span> | <span class="t">And the surprising thing is that when we optimize all of these weights, we end up with these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=627" target="_blank">00:10:27.720</a></span> | <span class="t">incredibly powerful models, like those visualizations that we saw.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=632" target="_blank">00:10:32.540</a></span> | <span class="t">So I'm not quite sure where the disconnect between the incredibly simple math and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=639" target="_blank">00:10:39.140</a></span> | <span class="t">outcome is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=640" target="_blank">00:10:40.260</a></span> | <span class="t">I think it might be that it's so easy, it's hard to believe that's all it is, but I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=645" target="_blank">00:10:45.820</a></span> | <span class="t">not skipping over anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=648" target="_blank">00:10:48.140</a></span> | <span class="t">That really is it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=649" target="_blank">00:10:49.540</a></span> | <span class="t">And so to help you really understand this, I'm going to talk more about SGD.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=655" target="_blank">00:10:55.240</a></span> | <span class="t">Why would you use a sigmoid function here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=660" target="_blank">00:11:00.900</a></span> | <span class="t">So the loss function we generally use is the softmax, so e^xi divided by the sum of e^xi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=668" target="_blank">00:11:08.220</a></span> | <span class="t">If it's just binary, that's just the equivalent of having just 1/1 + e^xi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=676" target="_blank">00:11:16.020</a></span> | <span class="t">So softmax in the binary case simplifies into a sigmoid function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=685" target="_blank">00:11:25.540</a></span> | <span class="t">Thank you for clarifying that question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=688" target="_blank">00:11:28.820</a></span> | <span class="t">So I think this is super fun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=691" target="_blank">00:11:31.300</a></span> | <span class="t">We're going to talk about not just SGD, but every variant of SGD, including one invented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=698" target="_blank">00:11:38.080</a></span> | <span class="t">just a week ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=700" target="_blank">00:11:40.820</a></span> | <span class="t">So we've already talked about SGD.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=706" target="_blank">00:11:46.900</a></span> | <span class="t">SGD happens for all layers at once, yes we calculate the derivative of all the weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=713" target="_blank">00:11:53.080</a></span> | <span class="t">with respect to the loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=715" target="_blank">00:11:55.180</a></span> | <span class="t">And when to have a max pool after convolution versus when not to?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=719" target="_blank">00:11:59.860</a></span> | <span class="t">When to have a max pool after a convolution, who knows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=726" target="_blank">00:12:06.540</a></span> | <span class="t">This is a very controversial question, and indeed some people now say never use max pool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=733" target="_blank">00:12:13.180</a></span> | <span class="t">Instead of using max pool when you're doing the convolutions, don't do a convolution over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=740" target="_blank">00:12:20.540</a></span> | <span class="t">every set of 9 pixels, but instead skip a pixel each time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=748" target="_blank">00:12:28.740</a></span> | <span class="t">And so that's another way of downsampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=753" target="_blank">00:12:33.100</a></span> | <span class="t">Jeffrey Hinton, who is kind of the father of deep learning, has gone as far as saying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=757" target="_blank">00:12:37.980</a></span> | <span class="t">that the extremely great success of max pooling has been the greatest problem deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=767" target="_blank">00:12:47.780</a></span> | <span class="t">has faced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=768" target="_blank">00:12:48.780</a></span> | <span class="t">Because to him, it really stops us from going further.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=776" target="_blank">00:12:56.060</a></span> | <span class="t">I don't know if that's true or not, I assume it is because he's Jeffrey Hinton and I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=784" target="_blank">00:13:04.220</a></span> | <span class="t">not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=785" target="_blank">00:13:05.220</a></span> | <span class="t">For now, we use max pooling every time we're doing fine-tuning because we need to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=791" target="_blank">00:13:11.500</a></span> | <span class="t">sure that our architecture is identical to the original VGG's authors' architecture and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=796" target="_blank">00:13:16.140</a></span> | <span class="t">so we have to put max pooling wherever they do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=800" target="_blank">00:13:20.420</a></span> | <span class="t">Why do we want max pooling or downsampling or anything like that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=803" target="_blank">00:13:23.580</a></span> | <span class="t">Are we just trying to look at bigger features at the input?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=806" target="_blank">00:13:26.840</a></span> | <span class="t">Why use max pooling at all?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=811" target="_blank">00:13:31.260</a></span> | <span class="t">There's a couple of reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=812" target="_blank">00:13:32.660</a></span> | <span class="t">The first is that max pooling helps with translation invariance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=817" target="_blank">00:13:37.780</a></span> | <span class="t">So it basically says if this feature is here, or here, or here, or here, I don't care.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=822" target="_blank">00:13:42.580</a></span> | <span class="t">It's kind of roughly in the right spot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=824" target="_blank">00:13:44.660</a></span> | <span class="t">And so that seems to work well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=826" target="_blank">00:13:46.260</a></span> | <span class="t">And the second is exactly what you said.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=827" target="_blank">00:13:47.860</a></span> | <span class="t">Every time we max pool, we end up with a smaller grid, which means that our 3x3 convolutions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=833" target="_blank">00:13:53.560</a></span> | <span class="t">are effectively covering a larger part of the original image, which means that our convolutions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=838" target="_blank">00:13:58.280</a></span> | <span class="t">can find larger and more complex features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=842" target="_blank">00:14:02.580</a></span> | <span class="t">I think they would be the two main reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=848" target="_blank">00:14:08.260</a></span> | <span class="t">Is Jeffrey Hinton cool with the idea of doing the skipping index page time?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=863" target="_blank">00:14:23.980</a></span> | <span class="t">You can learn all about the things that he thinks we ought to have but don't yet have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=885" target="_blank">00:14:45.780</a></span> | <span class="t">He did point out that -- I can't remember what it was, but one of the key pieces of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=892" target="_blank">00:14:52.420</a></span> | <span class="t">deep learning that he invented took like 17 years from conception to working, so he is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=898" target="_blank">00:14:58.660</a></span> | <span class="t">somebody who sticks with these things and makes it work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=901" target="_blank">00:15:01.240</a></span> | <span class="t">Is max pooling unique to image processing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=904" target="_blank">00:15:04.900</a></span> | <span class="t">Max pooling is not unique to image processing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=908" target="_blank">00:15:08.020</a></span> | <span class="t">It's likely to be useful for any kind of convolutional neural network, and a convolutional neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=912" target="_blank">00:15:12.580</a></span> | <span class="t">network can be used for any kind of data that has some kind of consistent ordering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=917" target="_blank">00:15:17.580</a></span> | <span class="t">So things like speech, or any kind of audio, or some kind of consistent time series, all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=924" target="_blank">00:15:24.860</a></span> | <span class="t">of these things have some kind of ordering to them and therefore you can use CNN and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=928" target="_blank">00:15:28.740</a></span> | <span class="t">therefore you can use max pooling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=931" target="_blank">00:15:31.760</a></span> | <span class="t">And as we look at NLP, we will be looking more at convolutional neural networks for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=937" target="_blank">00:15:37.280</a></span> | <span class="t">other data types.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=938" target="_blank">00:15:38.740</a></span> | <span class="t">And interestingly, the author of Keras last week, or maybe the week before, made the contention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=946" target="_blank">00:15:46.620</a></span> | <span class="t">that perhaps it will turn out that CNNs are the architecture that will be used for every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=952" target="_blank">00:15:52.540</a></span> | <span class="t">type of ordered data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=956" target="_blank">00:15:56.060</a></span> | <span class="t">And this was just after one of the leading NLP researchers released a paper basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=961" target="_blank">00:16:01.020</a></span> | <span class="t">showing a state-of-the-art result in NLP using convolutional neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=967" target="_blank">00:16:07.540</a></span> | <span class="t">So although we'll start learning about recurrent neural networks next week, I have to be open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=973" target="_blank">00:16:13.580</a></span> | <span class="t">to the possibilities that they'll become redundant by the end of the year, but they're still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=980" target="_blank">00:16:20.420</a></span> | <span class="t">interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=981" target="_blank">00:16:21.420</a></span> | <span class="t">So SGD.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=984" target="_blank">00:16:24.220</a></span> | <span class="t">So we looked at the SGD intro notebook, but I think things are a little more clear sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=989" target="_blank">00:16:29.220</a></span> | <span class="t">when you can see it all in front of you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=990" target="_blank">00:16:30.660</a></span> | <span class="t">So here is basically the identical thing that we saw in the SGD notebook in Excel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=996" target="_blank">00:16:36.700</a></span> | <span class="t">So we are going to start by creating a line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1001" target="_blank">00:16:41.980</a></span> | <span class="t">We create 29 random numbers, and then we say okay, let's create something that is equal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1015" target="_blank">00:16:55.700</a></span> | <span class="t">to 2 times x plus 30.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1020" target="_blank">00:17:00.780</a></span> | <span class="t">And so here is 2 times x plus 30.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1023" target="_blank">00:17:03.860</a></span> | <span class="t">So that's my input data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1027" target="_blank">00:17:07.560</a></span> | <span class="t">So I am trying to create something that can find the parameters of a line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1033" target="_blank">00:17:13.060</a></span> | <span class="t">Now the important thing, and this is the leap, which requires not thinking too hard lest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1042" target="_blank">00:17:22.060</a></span> | <span class="t">you realize how surprising and amazing this is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1045" target="_blank">00:17:25.440</a></span> | <span class="t">Everything we learn about how to fit a line is identical to how to fit filters and weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1052" target="_blank">00:17:32.300</a></span> | <span class="t">in a convolutional neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1054" target="_blank">00:17:34.180</a></span> | <span class="t">And so everything we learn about calculating the slope and the intercept, we will then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1059" target="_blank">00:17:39.020</a></span> | <span class="t">use to let computers see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1063" target="_blank">00:17:43.220</a></span> | <span class="t">And so the answer to any question which is basically why is why not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1070" target="_blank">00:17:50.020</a></span> | <span class="t">This is a function that takes some inputs and calculates an output, this is a function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1073" target="_blank">00:17:53.780</a></span> | <span class="t">that takes some inputs and calculates an output, so why not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1078" target="_blank">00:17:58.900</a></span> | <span class="t">The only reason it wouldn't work would be because it was too slow, for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1082" target="_blank">00:18:02.740</a></span> | <span class="t">And we know it's not too slow because we tried it and it works pretty well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1086" target="_blank">00:18:06.500</a></span> | <span class="t">So everything we're about to learn works for any kind of function which kind of has the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1095" target="_blank">00:18:15.620</a></span> | <span class="t">appropriate types of gradients, and we can talk more about that later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1101" target="_blank">00:18:21.100</a></span> | <span class="t">But neural nets have the appropriate kinds of gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1103" target="_blank">00:18:23.900</a></span> | <span class="t">So SGD, we start with a guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1107" target="_blank">00:18:27.460</a></span> | <span class="t">What do we think the parameters of our function are, in this case the intercept and the slope.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1111" target="_blank">00:18:31.340</a></span> | <span class="t">And with Keras, they will be randomized using the chloro-initialization procedure, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1117" target="_blank">00:18:37.540</a></span> | <span class="t">is 6 divided by n_in plus n_out, random numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1121" target="_blank">00:18:41.940</a></span> | <span class="t">And I'm just going to say let's assume they're both 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1127" target="_blank">00:18:47.540</a></span> | <span class="t">We are going to use very, very small mini-batches here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1131" target="_blank">00:18:51.000</a></span> | <span class="t">Mini-batches are going to be of size 1, because it's easier to do in Excel and it's easier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1136" target="_blank">00:18:56.660</a></span> | <span class="t">to see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1137" target="_blank">00:18:57.660</a></span> | <span class="t">But everything we're going to see would work equally well for a mini-batch of size 4 or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1141" target="_blank">00:19:01.420</a></span> | <span class="t">64 or 128 or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1144" target="_blank">00:19:04.460</a></span> | <span class="t">So here's our first row, our first mini-batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1147" target="_blank">00:19:07.500</a></span> | <span class="t">Our input is 14 and our desired output is 58.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1151" target="_blank">00:19:11.500</a></span> | <span class="t">And so our guesses to our parameters are 1 and 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1154" target="_blank">00:19:14.900</a></span> | <span class="t">And therefore our predicted y value is equal to 1 plus 1 times 14, which is normally 15.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1167" target="_blank">00:19:27.260</a></span> | <span class="t">Therefore if we're doing root mean squared error, our error squared is prediction minus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1171" target="_blank">00:19:31.980</a></span> | <span class="t">actual squared.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1175" target="_blank">00:19:35.140</a></span> | <span class="t">So the next thing we do is we want to calculate the derivative with respect to each of our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1179" target="_blank">00:19:39.180</a></span> | <span class="t">two inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1182" target="_blank">00:19:42.140</a></span> | <span class="t">One really easy way to do that is to add a tiny amount to each of the two inputs and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1188" target="_blank">00:19:48.020</a></span> | <span class="t">see how the output varies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1190" target="_blank">00:19:50.380</a></span> | <span class="t">So let's start by doing that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1191" target="_blank">00:19:51.860</a></span> | <span class="t">So let's add 0.01 to our intercept and calculate the line and then calculate the loss squared.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1204" target="_blank">00:20:04.420</a></span> | <span class="t">So this is the error if b is increased by 0.01.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1210" target="_blank">00:20:10.180</a></span> | <span class="t">And then let's calculate the difference between that error and the actual error and then divide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1214" target="_blank">00:20:14.380</a></span> | <span class="t">that by our change, which is 0.01.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1218" target="_blank">00:20:18.380</a></span> | <span class="t">And that gives us our estimated gradient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1221" target="_blank">00:20:21.140</a></span> | <span class="t">I'm using dE for the error, dB, I should have probably been dL for the loss, dB.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1226" target="_blank">00:20:26.820</a></span> | <span class="t">The change in loss with respect to b is -85.99.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1232" target="_blank">00:20:32.140</a></span> | <span class="t">We can do the same thing for a.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1233" target="_blank">00:20:33.980</a></span> | <span class="t">So we can add 0.01 to a, and then calculate our line, subtract our actual, take the square,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1243" target="_blank">00:20:43.860</a></span> | <span class="t">and so there is our value of estimated dL/dA, subtract it from the actual loss divided by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1252" target="_blank">00:20:52.240</a></span> | <span class="t">0.01.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1254" target="_blank">00:20:54.140</a></span> | <span class="t">And so there are two estimates of the derivative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1256" target="_blank">00:20:56.420</a></span> | <span class="t">This approach to estimating the derivative is called finite differencing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1259" target="_blank">00:20:59.900</a></span> | <span class="t">And any time you calculate a derivative by hand, you should always use finite differencing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1264" target="_blank">00:21:04.980</a></span> | <span class="t">to make sure your calculation is correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1267" target="_blank">00:21:07.620</a></span> | <span class="t">You're not very likely to ever have to do that, however, because all of the libraries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1271" target="_blank">00:21:11.580</a></span> | <span class="t">do derivatives for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1273" target="_blank">00:21:13.900</a></span> | <span class="t">They do them analytically, not using finite derivatives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1277" target="_blank">00:21:17.700</a></span> | <span class="t">And so here are the derivatives calculated analytically, which you can do by going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1283" target="_blank">00:21:23.420</a></span> | <span class="t">Wolfram Alpha and typing in your formula and getting the derivative back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1287" target="_blank">00:21:27.180</a></span> | <span class="t">So this is the analytical derivative of the loss with respect to b, and the analytical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1290" target="_blank">00:21:30.980</a></span> | <span class="t">derivative of the loss with respect to a.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1294" target="_blank">00:21:34.340</a></span> | <span class="t">And so you can see that our analytical and our finite difference are very similar for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1298" target="_blank">00:21:38.740</a></span> | <span class="t">b and they are very similar for a.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1303" target="_blank">00:21:43.580</a></span> | <span class="t">So that makes me feel comfortable that we got the calculation correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1307" target="_blank">00:21:47.100</a></span> | <span class="t">So all SGD does is it says, okay, this tells us if we change our weights by a little bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1315" target="_blank">00:21:55.780</a></span> | <span class="t">this is the change in our loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1318" target="_blank">00:21:58.680</a></span> | <span class="t">We know that increasing our value of b by a bit will decrease the loss function, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1323" target="_blank">00:22:03.780</a></span> | <span class="t">we know that increasing our value of a by a little bit will decrease the loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1329" target="_blank">00:22:09.540</a></span> | <span class="t">So therefore let's decrease both of them by a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1332" target="_blank">00:22:12.700</a></span> | <span class="t">And the way we do that is to multiply the derivative times a learning rate, that's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1337" target="_blank">00:22:17.580</a></span> | <span class="t">value of a little bit, and subtract that from our previous guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1343" target="_blank">00:22:23.020</a></span> | <span class="t">So we do that for a, and we do that for b, and here are our new guesses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1347" target="_blank">00:22:27.900</a></span> | <span class="t">Now we're at 1.12 and 1.01, and so let's copy them over here, 1.12 and 1.01.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1358" target="_blank">00:22:38.460</a></span> | <span class="t">And then we do the same thing, and that gives us a new a and a b.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1364" target="_blank">00:22:44.020</a></span> | <span class="t">And we keep doing that again and again and again until we've gone through the whole dataset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1369" target="_blank">00:22:49.700</a></span> | <span class="t">at the end of which we have a guess of a of 2.61 and a guess of b of 1.07.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1375" target="_blank">00:22:55.980</a></span> | <span class="t">So that's one epoch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1378" target="_blank">00:22:58.340</a></span> | <span class="t">Now in real life, we would be having shuffle=true, which means that these would be randomized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1385" target="_blank">00:23:05.060</a></span> | <span class="t">So this isn't quite perfect, but apart from that, this is SGD with a mini-batch size of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1391" target="_blank">00:23:11.220</a></span> | <span class="t">1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1392" target="_blank">00:23:12.660</a></span> | <span class="t">So at the end of the epoch, we say this is our new slope, so let's copy 2.61 over here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1404" target="_blank">00:23:24.500</a></span> | <span class="t">and this is our new intercept.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1407" target="_blank">00:23:27.940</a></span> | <span class="t">So let's copy 1.06 over here, and so now it starts again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1417" target="_blank">00:23:37.700</a></span> | <span class="t">So we can keep doing that again and again and again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1420" target="_blank">00:23:40.700</a></span> | <span class="t">Copy the stuff from the bottom, stick it back at the top, and each one of these is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1424" target="_blank">00:23:44.220</a></span> | <span class="t">to be an epoch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1425" target="_blank">00:23:45.360</a></span> | <span class="t">So I recorded a macro with me copying this to the bottom and pasting it at the top, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1430" target="_blank">00:23:50.820</a></span> | <span class="t">added something that says for i = 1 to 5 around it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1434" target="_blank">00:23:54.540</a></span> | <span class="t">And so now if I click Run, it will copy and paste it 5 times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1441" target="_blank">00:24:01.860</a></span> | <span class="t">And so you can see it's gradually getting closer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1444" target="_blank">00:24:04.060</a></span> | <span class="t">And we know that our goal is that it should be a = 2 and b = 30.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1451" target="_blank">00:24:11.860</a></span> | <span class="t">So we've got as far as a = 2.5 and b = 1.3, so they're better than our starting point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1460" target="_blank">00:24:20.140</a></span> | <span class="t">And you can see our gradually improving loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1465" target="_blank">00:24:25.140</a></span> | <span class="t">But it's going to take a long time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1467" target="_blank">00:24:27.260</a></span> | <span class="t">Yes, Rachel?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1468" target="_blank">00:24:28.260</a></span> | <span class="t">Question - Can we still do analytic derivatives when we are using nonlinear activation functions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1474" target="_blank">00:24:34.300</a></span> | <span class="t">Answer - Yes, we can use analytical derivatives as long as we're using a function that has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1480" target="_blank">00:24:40.300</a></span> | <span class="t">an analytical derivative, which is pretty much every useful function you can think of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1487" target="_blank">00:24:47.220</a></span> | <span class="t">except ones that you can't have something that has an if-then statement in it, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1491" target="_blank">00:24:51.420</a></span> | <span class="t">it jumps from here to here, but even those you can approximate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1495" target="_blank">00:24:55.140</a></span> | <span class="t">So a good example would be ReLU, which is max of (0, x) strictly speaking doesn't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1506" target="_blank">00:25:06.500</a></span> | <span class="t">have a derivative at every point, or at least not a well-defined one, because this is what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1520" target="_blank">00:25:20.220</a></span> | <span class="t">ReLU looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1523" target="_blank">00:25:23.100</a></span> | <span class="t">And so its derivative here is 0, and its derivative here is 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1532" target="_blank">00:25:32.260</a></span> | <span class="t">What is its derivative exactly here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1535" target="_blank">00:25:35.860</a></span> | <span class="t">Who knows?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1536" target="_blank">00:25:36.860</a></span> | <span class="t">But the thing is, mathematicians care about that kind of thing, we don't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1541" target="_blank">00:25:41.620</a></span> | <span class="t">Like in real life, this is a computer, and computers are never exactly anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1547" target="_blank">00:25:47.020</a></span> | <span class="t">We can either assume that it's like an infinite amount to this side, or an infinite amount</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1550" target="_blank">00:25:50.460</a></span> | <span class="t">to this side, and who cares?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1552" target="_blank">00:25:52.820</a></span> | <span class="t">So as long as it has a derivative that you can calculate in a meaningful way in practice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1559" target="_blank">00:25:59.820</a></span> | <span class="t">on a computer, then it'll be fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1566" target="_blank">00:26:06.660</a></span> | <span class="t">So one thing you might have noticed about this is that it's going to take an awfully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1569" target="_blank">00:26:09.180</a></span> | <span class="t">long time to get anywhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1572" target="_blank">00:26:12.060</a></span> | <span class="t">And so you might think, okay, let's increase the learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1575" target="_blank">00:26:15.260</a></span> | <span class="t">Fine, let's increase the learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1577" target="_blank">00:26:17.780</a></span> | <span class="t">So let's get rid of one of these zeroes, oh dear, something went crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1583" target="_blank">00:26:23.940</a></span> | <span class="t">What went crazy?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1584" target="_blank">00:26:24.940</a></span> | <span class="t">I'll tell you what went crazy, our a's and b's started to go out into like 11 million,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1589" target="_blank">00:26:29.700</a></span> | <span class="t">which is not the correct answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1592" target="_blank">00:26:32.740</a></span> | <span class="t">So how did it go ahead and do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1594" target="_blank">00:26:34.660</a></span> | <span class="t">Well here's the problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1596" target="_blank">00:26:36.260</a></span> | <span class="t">Let's say this was the shape of our loss function, and this was our initial guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1603" target="_blank">00:26:43.220</a></span> | <span class="t">And we figured out the derivative is going this way, actually the derivative is positive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1608" target="_blank">00:26:48.220</a></span> | <span class="t">so we want to go the opposite direction, and so we step a little bit over here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1614" target="_blank">00:26:54.180</a></span> | <span class="t">And then that leads us to here, and we step a little bit further, and this looks good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1620" target="_blank">00:27:00.900</a></span> | <span class="t">But then we increase the learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1623" target="_blank">00:27:03.420</a></span> | <span class="t">So rather than stepping a little bit, we stepped a long way, and that put us here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1630" target="_blank">00:27:10.280</a></span> | <span class="t">And then we stepped a long way again, and that put us here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1635" target="_blank">00:27:15.140</a></span> | <span class="t">If your learning rate is too high, you're going to get worse and worse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1639" target="_blank">00:27:19.500</a></span> | <span class="t">And that's what happened.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1641" target="_blank">00:27:21.620</a></span> | <span class="t">So getting your learning rate right is critical to getting your thing to train it all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1650" target="_blank">00:27:30.260</a></span> | <span class="t">Exploding gradients, yeah, or you can even have gradients that do the opposite.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1655" target="_blank">00:27:35.540</a></span> | <span class="t">Exploding gradients are something a little bit different, but it's a similar idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1660" target="_blank">00:27:40.320</a></span> | <span class="t">So it looks like 0.001 is the best we can do, and that's a bit sad because this is really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1666" target="_blank">00:27:46.500</a></span> | <span class="t">slow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1667" target="_blank">00:27:47.500</a></span> | <span class="t">So let's try and improve it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1669" target="_blank">00:27:49.580</a></span> | <span class="t">So one thing we could do is say, well, given that every time we've been -- actually let</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1677" target="_blank">00:27:57.100</a></span> | <span class="t">me do this in a few more dimensions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1681" target="_blank">00:28:01.080</a></span> | <span class="t">So let's say we had a 3-dimensional set of axes now, and we kind of had a loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1688" target="_blank">00:28:08.260</a></span> | <span class="t">that looks like this kind of valley.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1692" target="_blank">00:28:12.140</a></span> | <span class="t">And let's say our initial guess was somewhere over here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1695" target="_blank">00:28:15.580</a></span> | <span class="t">So over here, the gradient is pointing in this direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1700" target="_blank">00:28:20.960</a></span> | <span class="t">So we might make a step and end up there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1705" target="_blank">00:28:25.260</a></span> | <span class="t">And then we might make another step which would put us there, and another step that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1709" target="_blank">00:28:29.060</a></span> | <span class="t">would put us there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1710" target="_blank">00:28:30.420</a></span> | <span class="t">And this is actually the most common thing that happens in neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1715" target="_blank">00:28:35.180</a></span> | <span class="t">Something that's kind of flat in one dimension like this is called a saddle point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1721" target="_blank">00:28:41.100</a></span> | <span class="t">And it's actually been proved that the vast majority of the space of a loss function in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1726" target="_blank">00:28:46.140</a></span> | <span class="t">a neural network is pretty much all saddle points.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1729" target="_blank">00:28:49.580</a></span> | <span class="t">So when you look at this, it's pretty obvious what should be done, which is if we go to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1739" target="_blank">00:28:59.420</a></span> | <span class="t">here and then we go to here, we can say on average, we're kind of obviously heading in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1745" target="_blank">00:29:05.580</a></span> | <span class="t">this direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1746" target="_blank">00:29:06.580</a></span> | <span class="t">Especially when we do it again, we're obviously heading in this direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1749" target="_blank">00:29:09.620</a></span> | <span class="t">So let's take the average of how we've been going so far and do a bit of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1755" target="_blank">00:29:15.060</a></span> | <span class="t">And that's exactly what momentum does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1758" target="_blank">00:29:18.260</a></span> | <span class="t">If ReLU isn't the cost function, why are we concerned with its differentiability?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1767" target="_blank">00:29:27.900</a></span> | <span class="t">We care about the derivative of the output with respect to the inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1774" target="_blank">00:29:34.100</a></span> | <span class="t">The inputs are the filters, and remember the loss function consists of a function of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1780" target="_blank">00:29:40.020</a></span> | <span class="t">function of a function of a function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1781" target="_blank">00:29:41.940</a></span> | <span class="t">So it is categorical cross-entropy loss applied to softmax, applied to ReLU, applied to dense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1793" target="_blank">00:29:53.420</a></span> | <span class="t">layer, applied to max pooling, applied to ReLU, applied to convolutions, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1799" target="_blank">00:29:59.160</a></span> | <span class="t">So in other words, to calculate the derivative of the loss with respect to the inputs, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1803" target="_blank">00:30:03.660</a></span> | <span class="t">have to calculate the derivative through that whole function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1807" target="_blank">00:30:07.180</a></span> | <span class="t">And this is what's called backpropagation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1809" target="_blank">00:30:09.560</a></span> | <span class="t">Backpropagation is easy to calculate that derivative because we know that from the chain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1814" target="_blank">00:30:14.740</a></span> | <span class="t">rule, the derivative of a function of a function is simply equal to the product of the derivatives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1821" target="_blank">00:30:21.140</a></span> | <span class="t">of those functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1822" target="_blank">00:30:22.440</a></span> | <span class="t">So in practice, all we do is we calculate the derivative of every layer with respect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1827" target="_blank">00:30:27.060</a></span> | <span class="t">to its inputs, and then we just multiply them all together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1830" target="_blank">00:30:30.660</a></span> | <span class="t">And so that's why we need to know the derivative of the activation layers as well as the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1837" target="_blank">00:30:37.500</a></span> | <span class="t">layer and everything else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1843" target="_blank">00:30:43.700</a></span> | <span class="t">So here's the trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1845" target="_blank">00:30:45.820</a></span> | <span class="t">What we're going to do is we're going to say, every time we take a step, we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1856" target="_blank">00:30:56.900</a></span> | <span class="t">also calculate the average of the last few steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1860" target="_blank">00:31:00.920</a></span> | <span class="t">So after these two steps, the average is this direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1864" target="_blank">00:31:04.700</a></span> | <span class="t">So the next step, we're going to take our gradient step as usual, and we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1868" target="_blank">00:31:08.940</a></span> | <span class="t">add on our average of the last few steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1874" target="_blank">00:31:14.700</a></span> | <span class="t">And that means that we end up actually going to here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1877" target="_blank">00:31:17.700</a></span> | <span class="t">And then we do the same thing again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1879" target="_blank">00:31:19.300</a></span> | <span class="t">So we find the average of the last few steps, and it's now even further in this direction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1884" target="_blank">00:31:24.420</a></span> | <span class="t">and so this is the surface of the loss function with respect to some of the parameters, in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1893" target="_blank">00:31:33.980</a></span> | <span class="t">this case just a couple of parameters, it's just an example of what a loss function might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1897" target="_blank">00:31:37.980</a></span> | <span class="t">look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1898" target="_blank">00:31:38.980</a></span> | <span class="t">So this is the loss, and this is some weight number 1, and this is some weight number 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1911" target="_blank">00:31:51.660</a></span> | <span class="t">So we're trying to get our little, if you can imagine this is like gravity, we're trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1915" target="_blank">00:31:55.820</a></span> | <span class="t">to get this little ball to travel down this valley as far down to the bottom as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1920" target="_blank">00:32:00.980</a></span> | <span class="t">And so the trick is that we're going to keep taking a step, not just the gradient step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1927" target="_blank">00:32:07.940</a></span> | <span class="t">but also the average of the last few steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1931" target="_blank">00:32:11.660</a></span> | <span class="t">And so in practice, this is going to end up kind of going "donk, donk, donk, donk, donk."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1940" target="_blank">00:32:20.180</a></span> | <span class="t">That's the idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1941" target="_blank">00:32:21.900</a></span> | <span class="t">So to do that in Excel is pretty straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1946" target="_blank">00:32:26.600</a></span> | <span class="t">To make things simpler, I have removed the finite-differencing base derivatives here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1950" target="_blank">00:32:30.980</a></span> | <span class="t">so we just have the analytical derivatives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1952" target="_blank">00:32:32.580</a></span> | <span class="t">But other than that, this is identical to the previous spreadsheet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1957" target="_blank">00:32:37.460</a></span> | <span class="t">Same data, same predictions, same derivatives, except we've done one extra thing, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1963" target="_blank">00:32:43.900</a></span> | <span class="t">that when we calculate our new B, we say it's our previous B minus our learning rate times,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1972" target="_blank">00:32:52.860</a></span> | <span class="t">and we're not going times our gradient, but times this cell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1977" target="_blank">00:32:57.340</a></span> | <span class="t">And what is that cell?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1979" target="_blank">00:32:59.220</a></span> | <span class="t">That cell is equal to our gradient times 0.1 plus the thing just above it times 0.9, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1991" target="_blank">00:33:11.980</a></span> | <span class="t">the thing just above it is equal to its gradient times 0.1 plus the thing just above it times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=1998" target="_blank">00:33:18.460</a></span> | <span class="t">0.9, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2000" target="_blank">00:33:20.740</a></span> | <span class="t">So in other words, this column is keeping track of an average derivative of the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2007" target="_blank">00:33:27.820</a></span> | <span class="t">few steps that we've taken, which is exactly what we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2011" target="_blank">00:33:31.620</a></span> | <span class="t">And we do that for both of our two parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2015" target="_blank">00:33:35.260</a></span> | <span class="t">So this 0.9 is our momentum parameter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2020" target="_blank">00:33:40.540</a></span> | <span class="t">So in Keras, when you use momentum, you can say momentum = and you say how much momentum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2026" target="_blank">00:33:46.060</a></span> | <span class="t">you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2027" target="_blank">00:33:47.060</a></span> | <span class="t">Where did that beta come from?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2029" target="_blank">00:33:49.820</a></span> | <span class="t">You just pick it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2031" target="_blank">00:33:51.120</a></span> | <span class="t">So you just pick what that parameter, what do you want?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2033" target="_blank">00:33:53.020</a></span> | <span class="t">Just like your learning rate, you pick it, your momentum factor, you pick it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2037" target="_blank">00:33:57.520</a></span> | <span class="t">It's something you get to choose.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2039" target="_blank">00:33:59.100</a></span> | <span class="t">And you choose it by trying a few and find out what works best.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2043" target="_blank">00:34:03.360</a></span> | <span class="t">So let's try running this, and you can see it is still not exactly zipping along.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2055" target="_blank">00:34:15.540</a></span> | <span class="t">Why is it not exactly zipping along?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2057" target="_blank">00:34:17.340</a></span> | <span class="t">Well the reason when we look at it is that we know that the constant term needs to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2062" target="_blank">00:34:22.180</a></span> | <span class="t">all the way up to 30, and it's still way down at 1.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2068" target="_blank">00:34:28.800</a></span> | <span class="t">It's not moving fast enough, whereas the slope term moved very quickly to where we want it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2075" target="_blank">00:34:35.740</a></span> | <span class="t">to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2076" target="_blank">00:34:36.740</a></span> | <span class="t">So what we really want is we need different learning rates for different parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2082" target="_blank">00:34:42.620</a></span> | <span class="t">And doing this is called dynamic learning rates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2085" target="_blank">00:34:45.580</a></span> | <span class="t">And the first really effective dynamic learning rate approaches have just appeared in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2091" target="_blank">00:34:51.340</a></span> | <span class="t">last 3 years or so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2095" target="_blank">00:34:55.100</a></span> | <span class="t">And one very popular one is called Adagrad, and it's very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2099" target="_blank">00:34:59.860</a></span> | <span class="t">All of these dynamic learning rate approaches have the same insight, which is this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2105" target="_blank">00:35:05.340</a></span> | <span class="t">If the parameter that I'm changing, if the derivative of that parameter is consistently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2112" target="_blank">00:35:12.660</a></span> | <span class="t">of a very low magnitude, then if the derivative of this mini-batch is higher than that, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2120" target="_blank">00:35:20.460</a></span> | <span class="t">what I really care about is the relative difference between how much this variable tends to change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2126" target="_blank">00:35:26.520</a></span> | <span class="t">and how much it's going to change this time around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2130" target="_blank">00:35:30.100</a></span> | <span class="t">So in other words, we don't just care about what's the gradient, but is the magnitude</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2135" target="_blank">00:35:35.980</a></span> | <span class="t">of the gradient a lot more or a lot less than it has tended to be recently?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2141" target="_blank">00:35:41.300</a></span> | <span class="t">So the easy way to calculate the overall amount of change of the gradient recently is to keep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2147" target="_blank">00:35:47.760</a></span> | <span class="t">track of the square of the gradient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2151" target="_blank">00:35:51.380</a></span> | <span class="t">So what we do with Adagrad is you can see at the bottom of my epoch here, I have got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2159" target="_blank">00:35:59.000</a></span> | <span class="t">a sum of squares of all of my gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2162" target="_blank">00:36:02.980</a></span> | <span class="t">And then I have taken the square root, so I've got the roots and the squares, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2166" target="_blank">00:36:06.880</a></span> | <span class="t">I've just divided it by the count to get the average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2169" target="_blank">00:36:09.260</a></span> | <span class="t">So this is the average of the roots and the squares of my gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2173" target="_blank">00:36:13.120</a></span> | <span class="t">So this number here will be high if the magnitudes of my gradients is high.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2178" target="_blank">00:36:18.260</a></span> | <span class="t">And because it's squared, it will be particularly high if sometimes they're really high.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2184" target="_blank">00:36:24.620</a></span> | <span class="t">So why is it okay to just use a mini-batch since the surface is going to depend on what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2190" target="_blank">00:36:30.180</a></span> | <span class="t">points are in your mini-batch?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2192" target="_blank">00:36:32.860</a></span> | <span class="t">It's not ideal to just use a mini-batch, and we will learn about a better approach to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2197" target="_blank">00:36:37.120</a></span> | <span class="t">in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2198" target="_blank">00:36:38.120</a></span> | <span class="t">But for now, let's look at this, and in fact, there are two approaches related to Adagrad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2203" target="_blank">00:36:43.680</a></span> | <span class="t">and Adadelta, and one of them actually does this for all of the gradients so far, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2211" target="_blank">00:36:51.280</a></span> | <span class="t">one of them uses a slightly more sophisticated approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2214" target="_blank">00:36:54.640</a></span> | <span class="t">This approach of doing it on a mini-batch-by-min-batch basis is slightly different either, but it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2219" target="_blank">00:36:59.620</a></span> | <span class="t">similar enough to explain the concept.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2222" target="_blank">00:37:02.280</a></span> | <span class="t">Does this mean for a CNN, would dynamic learning rates mean that each filter would have its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2234" target="_blank">00:37:14.080</a></span> | <span class="t">own learning rate?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2236" target="_blank">00:37:16.560</a></span> | <span class="t">It would mean that every parameter has its own learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2240" target="_blank">00:37:20.320</a></span> | <span class="t">So this is one parameter, that's a parameter, that's a parameter, that's a parameter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2244" target="_blank">00:37:24.900</a></span> | <span class="t">And then in our dense layer, that's a parameter, that's a parameter, that's a parameter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2253" target="_blank">00:37:33.900</a></span> | <span class="t">So when you go model.summary in Keras, it shows you for every layer how many parameters there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2260" target="_blank">00:37:40.080</a></span> | <span class="t">are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2261" target="_blank">00:37:41.080</a></span> | <span class="t">So anytime you're unclear on how many parameters there are, you can go back and have a look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2264" target="_blank">00:37:44.900</a></span> | <span class="t">at these spreadsheets, and you can also look at the Keras model.summary and make sure you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2270" target="_blank">00:37:50.320</a></span> | <span class="t">understand how they turn out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2273" target="_blank">00:37:53.280</a></span> | <span class="t">So for the first layer, it's going to be the size of your filter times the number of your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2279" target="_blank">00:37:59.160</a></span> | <span class="t">filters, if it's just a grayscale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2282" target="_blank">00:38:02.840</a></span> | <span class="t">And then after that, the number of parameters will be equal to the size of your filter times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2288" target="_blank">00:38:08.440</a></span> | <span class="t">the number of filters coming in times the number of filters coming out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2294" target="_blank">00:38:14.700</a></span> | <span class="t">And then of course your dense layers will be every input goes to every output, so number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2299" target="_blank">00:38:19.000</a></span> | <span class="t">of inputs times the number of outputs, a parameter to the function that is calculating whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2306" target="_blank">00:38:26.580</a></span> | <span class="t">it's a cat or a dog.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2311" target="_blank">00:38:31.480</a></span> | <span class="t">So what we do now is we say this number here, 1857, this is saying that the derivative of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2320" target="_blank">00:38:40.440</a></span> | <span class="t">the loss with respect to the slope varies a lot, whereas the derivative of the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2327" target="_blank">00:38:47.040</a></span> | <span class="t">with respect to the intercept doesn't vary much at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2330" target="_blank">00:38:50.660</a></span> | <span class="t">So at the end of every epoch, I copy that up to here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2336" target="_blank">00:38:56.720</a></span> | <span class="t">And then I take my learning rate and I divide it by that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2341" target="_blank">00:39:01.820</a></span> | <span class="t">And so now for each of my parameters, I now have this adjusted learning rate, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2348" target="_blank">00:39:08.240</a></span> | <span class="t">the learning rate divided by the recent sum of squares average gradient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2355" target="_blank">00:39:15.100</a></span> | <span class="t">And so you can see that now one of my learning rates is 100 times faster than the other one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2360" target="_blank">00:39:20.860</a></span> | <span class="t">And so let's see what happens when I run this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2363" target="_blank">00:39:23.820</a></span> | <span class="t">Question - Is there a relationship with normalizing the input data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2369" target="_blank">00:39:29.760</a></span> | <span class="t">Answer - No, there's not really a relationship with normalizing the input data because it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2378" target="_blank">00:39:38.480</a></span> | <span class="t">can help, but still if your inputs are very different scales, it's still a lot more work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2387" target="_blank">00:39:47.720</a></span> | <span class="t">for it to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2390" target="_blank">00:39:50.840</a></span> | <span class="t">So yes it helps, but it doesn't help so much that it makes it useless, and in fact it turns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2395" target="_blank">00:39:55.380</a></span> | <span class="t">out that even with dynamic learning rates, not just normalized inputs, but batch normalized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2402" target="_blank">00:40:02.840</a></span> | <span class="t">activations is extremely helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2407" target="_blank">00:40:07.320</a></span> | <span class="t">And so the thing about when you're using Adagrad or any kind of dynamic learning rates is generally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2412" target="_blank">00:40:12.120</a></span> | <span class="t">you'll set the learning rate quite a lot higher, because remember you're dividing it by this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2415" target="_blank">00:40:15.760</a></span> | <span class="t">recent average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2416" target="_blank">00:40:16.760</a></span> | <span class="t">So if I set it to 0.1, oh, too far, so that's no good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2424" target="_blank">00:40:24.400</a></span> | <span class="t">So let's try 0.05, run that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2433" target="_blank">00:40:33.080</a></span> | <span class="t">So you can see after just 5 steps, I'm already halfway there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2437" target="_blank">00:40:37.560</a></span> | <span class="t">Another 5 steps, getting very close, and another 5 steps, and it's exploded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2447" target="_blank">00:40:47.160</a></span> | <span class="t">Now why did that happen?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2449" target="_blank">00:40:49.680</a></span> | <span class="t">Because as we get closer and closer to where we want to be, you can see that you need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2457" target="_blank">00:40:57.880</a></span> | <span class="t">take smaller and smaller steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2460" target="_blank">00:41:00.760</a></span> | <span class="t">And by keeping the learning rates the same, it meant that eventually we went too far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2467" target="_blank">00:41:07.920</a></span> | <span class="t">So this is still something you have to be very careful of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2474" target="_blank">00:41:14.000</a></span> | <span class="t">As more elegant, in my opinion, approach to the same thing that Adagrad is doing is something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2480" target="_blank">00:41:20.400</a></span> | <span class="t">called RMSprop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2481" target="_blank">00:41:21.960</a></span> | <span class="t">And RMSprop was first introduced in Jeffrey Hinton's Coursera course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2486" target="_blank">00:41:26.840</a></span> | <span class="t">So if you go to the Coursera course in one of those classes he introduces RMSprop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2499" target="_blank">00:41:39.680</a></span> | <span class="t">So it's quite funny nowadays because this comes up in academic papers a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2503" target="_blank">00:41:43.560</a></span> | <span class="t">When people cite it, they have to cite Coursera course, chapter 6, at minute 14 and 30 seconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2510" target="_blank">00:41:50.920</a></span> | <span class="t">But Hinton has asked that this be the official way that he decided, so there you go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2516" target="_blank">00:41:56.240</a></span> | <span class="t">You see how cool he is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2519" target="_blank">00:41:59.280</a></span> | <span class="t">So here's what RMSprop does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2520" target="_blank">00:42:00.920</a></span> | <span class="t">What RMSprop does is exactly the same thing as momentum, but instead of keeping track</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2526" target="_blank">00:42:06.920</a></span> | <span class="t">of the weighted running average of the gradients, we keep track of the weighted running average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2532" target="_blank">00:42:12.960</a></span> | <span class="t">of the square of the gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2534" target="_blank">00:42:14.960</a></span> | <span class="t">So here it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2537" target="_blank">00:42:17.920</a></span> | <span class="t">Everything here is the same as momentum so far, except that I take my gradient squared,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2547" target="_blank">00:42:27.160</a></span> | <span class="t">multiply it by 0.1, and add it to my previous cell times 0.9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2555" target="_blank">00:42:35.600</a></span> | <span class="t">So this is keeping track of the recent running average of the squares of the gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2561" target="_blank">00:42:41.920</a></span> | <span class="t">And when I have that, I do exactly the same thing with it that I did in Adagrad, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2565" target="_blank">00:42:45.920</a></span> | <span class="t">is to divide the learning rate by it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2568" target="_blank">00:42:48.180</a></span> | <span class="t">So I take my previous guess as to b and then I subtract from it my derivative times the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2576" target="_blank">00:42:56.760</a></span> | <span class="t">learning rate divided by the square root of the recent weighted average of the square gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2585" target="_blank">00:43:05.120</a></span> | <span class="t">So it's doing basically the same thing as Adagrad, but in a way that's doing it kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2589" target="_blank">00:43:09.400</a></span> | <span class="t">of continuously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2590" target="_blank">00:43:10.400</a></span> | <span class="t">So these are all different types of learning rate optimization?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2596" target="_blank">00:43:16.080</a></span> | <span class="t">These last two are different types of dynamic learning rate approaches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2603" target="_blank">00:43:23.540</a></span> | <span class="t">So let's try this one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2604" target="_blank">00:43:24.540</a></span> | <span class="t">If we run it for a few steps, and again you have to guess what learning rate to start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2609" target="_blank">00:43:29.300</a></span> | <span class="t">with, say 0.1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2629" target="_blank">00:43:49.720</a></span> | <span class="t">So as you can see, this is going pretty well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2631" target="_blank">00:43:51.820</a></span> | <span class="t">And I'll show you something really nice about RMSprop, which is what happens as we get very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2636" target="_blank">00:43:56.360</a></span> | <span class="t">close.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2637" target="_blank">00:43:57.360</a></span> | <span class="t">We know the right answer is 2 and 30.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2639" target="_blank">00:43:59.160</a></span> | <span class="t">Is it about to explode?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2641" target="_blank">00:44:01.480</a></span> | <span class="t">No, it doesn't explode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2643" target="_blank">00:44:03.840</a></span> | <span class="t">And the reason it doesn't explode is because it's recalculating that running average every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2649" target="_blank">00:44:09.120</a></span> | <span class="t">single minibatch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2650" target="_blank">00:44:10.880</a></span> | <span class="t">And so rather than waiting until the end of the epoch by which stage it's gone so far</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2654" target="_blank">00:44:14.720</a></span> | <span class="t">that it can't come back again, it just jumps a little bit too far and then it recalculates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2660" target="_blank">00:44:20.000</a></span> | <span class="t">the dynamic learning rates and tries again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2663" target="_blank">00:44:23.040</a></span> | <span class="t">So what happens with RMSprop is if your learning rate is too high, then it doesn't explode,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2667" target="_blank">00:44:27.600</a></span> | <span class="t">it just ends up going around the right answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2671" target="_blank">00:44:31.360</a></span> | <span class="t">And so when you use RMSprop, as soon as you see your validation scores flatten out, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2678" target="_blank">00:44:38.320</a></span> | <span class="t">know this is what's going on, and so therefore you should probably divide your learning rate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2682" target="_blank">00:44:42.320</a></span> | <span class="t">by 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2683" target="_blank">00:44:43.320</a></span> | <span class="t">And you see me doing this all the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2684" target="_blank">00:44:44.640</a></span> | <span class="t">When I'm running Keras stuff, you'll keep seeing me run a few steps, divide the learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2689" target="_blank">00:44:49.000</a></span> | <span class="t">rate by 10, run a few steps, and you don't see that my loss function explodes, you just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2693" target="_blank">00:44:53.720</a></span> | <span class="t">see that it flattens out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2694" target="_blank">00:44:54.720</a></span> | <span class="t">So do you want your learning rate to get smaller and smaller?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2698" target="_blank">00:44:58.440</a></span> | <span class="t">Yeah, you do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2700" target="_blank">00:45:00.880</a></span> | <span class="t">Your very first learning rate often has to start small, and we'll talk about that in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2705" target="_blank">00:45:05.200</a></span> | <span class="t">a moment, but once you've kind of got started, you generally have to gradually decrease the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2710" target="_blank">00:45:10.760</a></span> | <span class="t">learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2711" target="_blank">00:45:11.760</a></span> | <span class="t">That's called learning rate annealing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2712" target="_blank">00:45:12.760</a></span> | <span class="t">And can you repeat what you said earlier that something does the same thing as Adagrad,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2718" target="_blank">00:45:18.120</a></span> | <span class="t">but...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2719" target="_blank">00:45:19.120</a></span> | <span class="t">So RMSprop, which we're looking at now, does exactly the same thing as Adagrad, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2725" target="_blank">00:45:25.000</a></span> | <span class="t">divide the learning rate by the root-summer-squared of the gradients, but rather than doing it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2733" target="_blank">00:45:33.200</a></span> | <span class="t">since the beginning of time, or every minibatch, or epoch, RMSprop does it continuously using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2741" target="_blank">00:45:41.440</a></span> | <span class="t">the same technique that we learned from momentum, which is take the squared of this gradient,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2748" target="_blank">00:45:48.640</a></span> | <span class="t">multiply it by 0.1, and add it to 0.9 times the last calculation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2756" target="_blank">00:45:56.040</a></span> | <span class="t">That's called a moving average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2760" target="_blank">00:46:00.560</a></span> | <span class="t">It's a weighted moving average, where we're weighting it such that the more recent squared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2766" target="_blank">00:46:06.440</a></span> | <span class="t">gradients are weighted higher.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2769" target="_blank">00:46:09.160</a></span> | <span class="t">I think it's actually an exponentially weighted moving average, to be more precise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2775" target="_blank">00:46:15.360</a></span> | <span class="t">So there's something pretty obvious we could do here, which is momentum seems like a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2778" target="_blank">00:46:18.840</a></span> | <span class="t">idea, RMSprop seems like a good idea, why not do both?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2785" target="_blank">00:46:25.500</a></span> | <span class="t">And that is called Adam.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2788" target="_blank">00:46:28.140</a></span> | <span class="t">And so Adam was invented last year, 18 months ago, and hopefully one of the things you see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2795" target="_blank">00:46:35.000</a></span> | <span class="t">from these spreadsheets is that these recently invented things are still at the ridiculously</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2801" target="_blank">00:46:41.520</a></span> | <span class="t">extremely simple end of the spectrum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2804" target="_blank">00:46:44.080</a></span> | <span class="t">So the stuff that people are discovering in deep learning is a long, long, long way away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2809" target="_blank">00:46:49.480</a></span> | <span class="t">from being incredibly complex or sophisticated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2813" target="_blank">00:46:53.180</a></span> | <span class="t">And so hopefully you'll find this very encouraging, which is if you want to play at the state-of-the-art</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2818" target="_blank">00:46:58.040</a></span> | <span class="t">of deep learning, that's not at all hard to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2822" target="_blank">00:47:02.840</a></span> | <span class="t">So let's look at Adam, which I remember it coming out 12-18 months ago, and everybody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2829" target="_blank">00:47:09.080</a></span> | <span class="t">was so excited because suddenly it became so much easier and faster to train neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2834" target="_blank">00:47:14.240</a></span> | <span class="t">nets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2835" target="_blank">00:47:15.440</a></span> | <span class="t">But once I actually tried to create an Excel spreadsheet out of it, I realized, oh my god,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2839" target="_blank">00:47:19.200</a></span> | <span class="t">it's just RMSprop to plus momentum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2842" target="_blank">00:47:22.600</a></span> | <span class="t">And so literally all I did was I copied my momentum page and then I copied across my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2847" target="_blank">00:47:27.280</a></span> | <span class="t">RMSprop columns and combined them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2850" target="_blank">00:47:30.920</a></span> | <span class="t">So you can see here I have my exponentially weighted moving average of the gradients,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2858" target="_blank">00:47:38.120</a></span> | <span class="t">that's what these two columns are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2862" target="_blank">00:47:42.240</a></span> | <span class="t">Here is my exponentially weighted moving average of the squares of the gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2868" target="_blank">00:47:48.040</a></span> | <span class="t">And so then when I calculate my new parameters, I take my old parameter and I subtract not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2878" target="_blank">00:47:58.240</a></span> | <span class="t">my derivative times the learning rate, but my momentum factor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2883" target="_blank">00:48:03.480</a></span> | <span class="t">So in other words, the recent weighted moving average of the gradients multiplied by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2890" target="_blank">00:48:10.560</a></span> | <span class="t">learning rate divided by the recent moving average of the squares of the derivatives,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2896" target="_blank">00:48:16.720</a></span> | <span class="t">or the root of them anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2898" target="_blank">00:48:18.760</a></span> | <span class="t">So it's literally just combining momentum plus RMSprop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2906" target="_blank">00:48:26.560</a></span> | <span class="t">And so let's see how that goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2908" target="_blank">00:48:28.200</a></span> | <span class="t">Let's run 5 epochs, and we can use a pretty high learning rate now because it's really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2914" target="_blank">00:48:34.640</a></span> | <span class="t">handling a lot of stuff for us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2916" target="_blank">00:48:36.840</a></span> | <span class="t">And 5 epochs, we're almost perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2920" target="_blank">00:48:40.600</a></span> | <span class="t">And so another 5 epochs does exactly the same thing that RMSprop does, which is it goes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2926" target="_blank">00:48:46.560</a></span> | <span class="t">too far and tries to come back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2929" target="_blank">00:48:49.240</a></span> | <span class="t">So we need to do the same thing when we use atom, and atom is what I use all the time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2933" target="_blank">00:48:53.160</a></span> | <span class="t">now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2935" target="_blank">00:48:55.040</a></span> | <span class="t">I just divide by 10 every time I see it flatten out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2941" target="_blank">00:49:01.240</a></span> | <span class="t">So a week ago, somebody came out with something that they called not atom, but Eve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2948" target="_blank">00:49:08.800</a></span> | <span class="t">And Eve is an addition to atom which attempts to deal with this learning rate annealing automatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2959" target="_blank">00:49:19.280</a></span> | <span class="t">And so all of this is exactly the same as my atom page.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2965" target="_blank">00:49:25.200</a></span> | <span class="t">But at the bottom, I've added some extra stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2967" target="_blank">00:49:27.680</a></span> | <span class="t">I have kept track of the root means grid error, this is just my loss function, and then I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2974" target="_blank">00:49:34.800</a></span> | <span class="t">copy across my loss function from my previous epoch and from the epoch before that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2982" target="_blank">00:49:42.600</a></span> | <span class="t">And what Eve does is it says how much has the loss function changed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2988" target="_blank">00:49:48.120</a></span> | <span class="t">And so it's got this ratio between the previous loss function and the loss function before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2994" target="_blank">00:49:54.640</a></span> | <span class="t">that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=2995" target="_blank">00:49:55.640</a></span> | <span class="t">So you can see it's the absolute value of the last one minus the one before divided</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3000" target="_blank">00:50:00.320</a></span> | <span class="t">by whichever one is smaller.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3002" target="_blank">00:50:02.880</a></span> | <span class="t">And what it says is, let's then adjust the learning rate such that instead of just using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3010" target="_blank">00:50:10.760</a></span> | <span class="t">the learning rate that we're given, let's adjust the learning rate that we're given.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3027" target="_blank">00:50:27.800</a></span> | <span class="t">We take the exponentially weighted moving average of these ratios, so you can see another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3034" target="_blank">00:50:34.400</a></span> | <span class="t">of these betas appearing here, so this thing here is equal to our last ratio times 0.9</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3044" target="_blank">00:50:44.960</a></span> | <span class="t">plus our new ratio times 0.1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3050" target="_blank">00:50:50.160</a></span> | <span class="t">And so then for our learning rate, we divide the learning rate from atom by this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3060" target="_blank">00:51:00.560</a></span> | <span class="t">So what that says is if the learning rate is moving around a lot, if it's very bumpy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3071" target="_blank">00:51:11.880</a></span> | <span class="t">we should probably decrease the learning rate because it's going all over the place.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3076" target="_blank">00:51:16.800</a></span> | <span class="t">Remember how we saw before, if we've kind of gone past where we want to get to, it just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3080" target="_blank">00:51:20.640</a></span> | <span class="t">jumps up and down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3082" target="_blank">00:51:22.920</a></span> | <span class="t">On the other hand, if the loss function is staying pretty constant, then we probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3087" target="_blank">00:51:27.900</a></span> | <span class="t">want to increase the learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3090" target="_blank">00:51:30.640</a></span> | <span class="t">So that all seems like a good idea, and so again let's try it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3101" target="_blank">00:51:41.040</a></span> | <span class="t">Not bad, so after 5 epochs it's gone a little bit too far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3106" target="_blank">00:51:46.280</a></span> | <span class="t">After a week of playing with it, I used this on State Farm a lot during the week, I grabbed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3110" target="_blank">00:51:50.200</a></span> | <span class="t">a Keras implementation which somebody wrote a day after the paper came out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3116" target="_blank">00:51:56.600</a></span> | <span class="t">The problem is that because it can both decrease and increase the learning rate, sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3124" target="_blank">00:52:04.840</a></span> | <span class="t">as it gets down to the flat bottom point where it's pretty much optimal, it will often be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3131" target="_blank">00:52:11.800</a></span> | <span class="t">the case that the loss gets pretty constant at that point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3138" target="_blank">00:52:18.740</a></span> | <span class="t">And so therefore, Eve will try to increase the learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3142" target="_blank">00:52:22.200</a></span> | <span class="t">And so what I tend to find happens that it would very quickly get pretty close to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3146" target="_blank">00:52:26.640</a></span> | <span class="t">answer, and then suddenly it would jump to somewhere really awful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3149" target="_blank">00:52:29.480</a></span> | <span class="t">And then it would start to get to the answer again and jump somewhere really awful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3167" target="_blank">00:52:47.680</a></span> | <span class="t">We have not done any such thing, no.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3169" target="_blank">00:52:49.440</a></span> | <span class="t">We have always run for a specific number of epochs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3173" target="_blank">00:52:53.680</a></span> | <span class="t">We have not defined any kind of stopping criterion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3179" target="_blank">00:52:59.500</a></span> | <span class="t">It is possible to define such a stopping criterion, but nobody's really come up with one that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3184" target="_blank">00:53:04.400</a></span> | <span class="t">remotely reliable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3186" target="_blank">00:53:06.240</a></span> | <span class="t">And the reason why is that when you look at the graph of loss over time, it doesn't tend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3194" target="_blank">00:53:14.120</a></span> | <span class="t">to look like that, but it tends to look like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3199" target="_blank">00:53:19.880</a></span> | <span class="t">And so in practice, it's very hard to know when to stop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3205" target="_blank">00:53:25.520</a></span> | <span class="t">It's kind of still a human judgment thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3207" target="_blank">00:53:27.200</a></span> | <span class="t">Oh yeah, that's definitely true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3211" target="_blank">00:53:31.080</a></span> | <span class="t">And particularly with a type of architecture called ResNet that we'll look at next week,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3216" target="_blank">00:53:36.520</a></span> | <span class="t">the authors showed that it tends to go like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3225" target="_blank">00:53:45.200</a></span> | <span class="t">So in practice, you have to run your training for as long as you have patience for, at whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3229" target="_blank">00:53:49.840</a></span> | <span class="t">the best learning rate you can come up with is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3233" target="_blank">00:53:53.400</a></span> | <span class="t">So something I actually came up with 6 or 12 months ago, but we've kind of restimulated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3241" target="_blank">00:54:01.000</a></span> | <span class="t">my interest after I read this Adam paper, is something which dynamically updates learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3247" target="_blank">00:54:07.640</a></span> | <span class="t">rates in such a way that they only go down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3252" target="_blank">00:54:12.380</a></span> | <span class="t">And rather than using the loss function, which as I just said is incredibly bumpy, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3257" target="_blank">00:54:17.080</a></span> | <span class="t">something else which is less bumpy, which is the average sum of squareds gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3264" target="_blank">00:54:24.400</a></span> | <span class="t">So I actually created a little spreadsheet of my idea, and I helped to prototype it in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3268" target="_blank">00:54:28.520</a></span> | <span class="t">Python maybe this week or the next week after, we'll see how it goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3272" target="_blank">00:54:32.240</a></span> | <span class="t">And the idea is basically this, keep track of the sum of the squares of the derivatives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3280" target="_blank">00:54:40.840</a></span> | <span class="t">and compare the sum of the squares of the derivatives from the last epoch to the sum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3285" target="_blank">00:54:45.000</a></span> | <span class="t">of the squares of the derivatives of this epoch and look at the ratio of the two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3289" target="_blank">00:54:49.920</a></span> | <span class="t">The derivatives should keep going down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3293" target="_blank">00:54:53.600</a></span> | <span class="t">If they ever go up by too much, that would strongly suggest that you've kind of jumped</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3298" target="_blank">00:54:58.800</a></span> | <span class="t">out of the good part of the function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3301" target="_blank">00:55:01.720</a></span> | <span class="t">So anytime they go up too much, you should decrease the learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3307" target="_blank">00:55:07.320</a></span> | <span class="t">So I literally added two lines of code to my incredibly simple VBA, Adam with a kneeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3314" target="_blank">00:55:14.680</a></span> | <span class="t">here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3315" target="_blank">00:55:15.680</a></span> | <span class="t">If the gradient ratio is greater than 2, so if it doubles, divide the learning rate by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3322" target="_blank">00:55:22.160</a></span> | <span class="t">4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3323" target="_blank">00:55:23.160</a></span> | <span class="t">Here's what happens when I run that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3332" target="_blank">00:55:32.880</a></span> | <span class="t">That's 5 steps, another 5 steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3339" target="_blank">00:55:39.240</a></span> | <span class="t">You can see it's automatically changing it, so I don't have to do anything, I just keep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3343" target="_blank">00:55:43.640</a></span> | <span class="t">running it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3347" target="_blank">00:55:47.440</a></span> | <span class="t">So I'm pretty interested in this idea, I think it's going to work super well because it allows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3352" target="_blank">00:55:52.160</a></span> | <span class="t">me to focus on just running stuff without ever worrying about setting learning rates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3357" target="_blank">00:55:57.780</a></span> | <span class="t">So I'm hopeful that this approach to automatic learning rate and kneeling is something that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3362" target="_blank">00:56:02.560</a></span> | <span class="t">we can have in our toolbox by the end of this course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3368" target="_blank">00:56:08.240</a></span> | <span class="t">One thing that happened to me today is I tried a lot of different learning rates, I didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3381" target="_blank">00:56:21.400</a></span> | <span class="t">get anywhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3382" target="_blank">00:56:22.400</a></span> | <span class="t">But I was working with the whole dataset, trying to understand if I tried with the sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3390" target="_blank">00:56:30.000</a></span> | <span class="t">and I find something, would that apply to the whole dataset or how do I go about investigating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3395" target="_blank">00:56:35.760</a></span> | <span class="t">this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3396" target="_blank">00:56:36.760</a></span> | <span class="t">I'll hold that thought for 5 seconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3398" target="_blank">00:56:38.680</a></span> | <span class="t">Was there another question at the back before we answered that one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3403" target="_blank">00:56:43.160</a></span> | <span class="t">So here is the answer to that question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3408" target="_blank">00:56:48.720</a></span> | <span class="t">The question was, "It takes a long time to figure out the optimal learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3414" target="_blank">00:56:54.960</a></span> | <span class="t">Can we calculate it using just a sample?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3418" target="_blank">00:56:58.760</a></span> | <span class="t">And to answer that question, I'm going to show you how I entered statefum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3422" target="_blank">00:57:02.720</a></span> | <span class="t">Indeed, when I started entering statefum, I started by using a sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3431" target="_blank">00:57:11.880</a></span> | <span class="t">And so step 1 was to think, "What insights can we gain from using a sample which can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3439" target="_blank">00:57:19.920</a></span> | <span class="t">still apply when we move to the whole dataset?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3443" target="_blank">00:57:23.040</a></span> | <span class="t">Because running stuff in a sample took 10 or 20 seconds, and running stuff in the full</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3447" target="_blank">00:57:27.840</a></span> | <span class="t">dataset took 2 to 10 minutes per epoch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3453" target="_blank">00:57:33.560</a></span> | <span class="t">So after I created my sample, which I just created randomly, I first of all wanted to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3463" target="_blank">00:57:43.280</a></span> | <span class="t">find out what does it take to create a better-than-random model here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3471" target="_blank">00:57:51.880</a></span> | <span class="t">So I always start with the simplest possible model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3475" target="_blank">00:57:55.600</a></span> | <span class="t">And so the simplest possible model has a single dense layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3482" target="_blank">00:58:02.040</a></span> | <span class="t">Now here's a handy trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3483" target="_blank">00:58:03.960</a></span> | <span class="t">Rather than worrying about calculating the average and the standard deviation of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3487" target="_blank">00:58:07.080</a></span> | <span class="t">input and subtracting it all out in order to normalize your input layer, you can just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3492" target="_blank">00:58:12.440</a></span> | <span class="t">start with a batch-norm layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3495" target="_blank">00:58:15.640</a></span> | <span class="t">And so if you start with a batch-norm layer, it's going to do that for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3498" target="_blank">00:58:18.700</a></span> | <span class="t">So anytime you create a Keras model from scratch, I would recommend making your first layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3503" target="_blank">00:58:23.600</a></span> | <span class="t">a batch-norm layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3504" target="_blank">00:58:24.980</a></span> | <span class="t">So this is going to normalize the data for me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3509" target="_blank">00:58:29.300</a></span> | <span class="t">So that's a cool little trick which I haven't actually seen anybody use elsewhere, but I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3512" target="_blank">00:58:32.800</a></span> | <span class="t">think it's a good default starting point all the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3518" target="_blank">00:58:38.440</a></span> | <span class="t">If I'm going to use a dense layer, then obviously I have to flatten everything into a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3524" target="_blank">00:58:44.000</a></span> | <span class="t">vector first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3525" target="_blank">00:58:45.580</a></span> | <span class="t">So this is really a most minimal model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3533" target="_blank">00:58:53.800</a></span> | <span class="t">So I tried fitting it, compiled it, fit it, and nothing happened.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3540" target="_blank">00:59:00.940</a></span> | <span class="t">Not only did nothing happen to my validation, but really nothing happened by training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3545" target="_blank">00:59:05.960</a></span> | <span class="t">It's only taking 7 seconds per epoch to find this out, so that's okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3552" target="_blank">00:59:12.720</a></span> | <span class="t">So what might be going on?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3553" target="_blank">00:59:13.760</a></span> | <span class="t">So I look at model.summary, and I see that there's 1.5 million parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3558" target="_blank">00:59:18.720</a></span> | <span class="t">And that makes me think, okay, it's probably not underfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3561" target="_blank">00:59:21.620</a></span> | <span class="t">It's probably unlikely that with 1.5 million parameters, there's really nothing useful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3566" target="_blank">00:59:26.240</a></span> | <span class="t">that can do whatsoever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3567" target="_blank">00:59:27.240</a></span> | <span class="t">It's only a linear model, true, but I still think it should be able to do something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3571" target="_blank">00:59:31.800</a></span> | <span class="t">So that makes me think that what must be going on is it must be doing that thing where it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3575" target="_blank">00:59:35.840</a></span> | <span class="t">jumps too far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3578" target="_blank">00:59:38.800</a></span> | <span class="t">And it's particularly easy to jump too far at the very start of training, and let me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3585" target="_blank">00:59:45.520</a></span> | <span class="t">explain why.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3589" target="_blank">00:59:49.440</a></span> | <span class="t">It turns out that there are often reasonably good answers that are way too easy to find.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3599" target="_blank">00:59:59.920</a></span> | <span class="t">So one reasonably good answer would be always predict 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3606" target="_blank">01:00:06.560</a></span> | <span class="t">Because there are 10 output classes in the state fun competition, there's one of 10 different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3613" target="_blank">01:00:13.000</a></span> | <span class="t">types of distracted driving, and you are scored based on the cross-entropy loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3621" target="_blank">01:00:21.600</a></span> | <span class="t">And what that's looking at is how accurate are each of your 10 predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3625" target="_blank">01:00:25.960</a></span> | <span class="t">So rather than trying to predict something well, what if we just always predict 0.01?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3635" target="_blank">01:00:35.120</a></span> | <span class="t">Nine times out of 10, you're going to be right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3637" target="_blank">01:00:37.440</a></span> | <span class="t">Because 9 out of the 10 categories, it's not that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3641" target="_blank">01:00:41.380</a></span> | <span class="t">It's only one of the 10 categories.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3643" target="_blank">01:00:43.160</a></span> | <span class="t">So actually always predicting 0.01 would be pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3647" target="_blank">01:00:47.500</a></span> | <span class="t">Now it turns out it's not possible to do that because we have a softmax layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3651" target="_blank">01:00:51.440</a></span> | <span class="t">And a softmax layer, remember, is e^x_i divided by sum_of, e^x_i.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3656" target="_blank">01:00:56.660</a></span> | <span class="t">And so in a softmax layer, everything has to add to 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3662" target="_blank">01:01:02.240</a></span> | <span class="t">So therefore if it makes one of the classes really high, and all of the other ones really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3668" target="_blank">01:01:08.560</a></span> | <span class="t">low, then 9 times out of 10 it is going to be right, 9 times out of 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3674" target="_blank">01:01:14.960</a></span> | <span class="t">So in other words, it's a pretty good answer for it to always predict some random class,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3681" target="_blank">01:01:21.720</a></span> | <span class="t">class 8, close to 100% certainty.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3686" target="_blank">01:01:26.400</a></span> | <span class="t">And that's what happened.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3687" target="_blank">01:01:27.400</a></span> | <span class="t">So anybody who tried this, and I saw a lot of people on the forums this week saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3691" target="_blank">01:01:31.320</a></span> | <span class="t">"I tried to train it and nothing happened."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3695" target="_blank">01:01:35.360</a></span> | <span class="t">And the folks who got the interesting insight were the ones who then went on to say, "And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3699" target="_blank">01:01:39.520</a></span> | <span class="t">then I looked at my predictions and it kept predicting the same class with great confidence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3704" target="_blank">01:01:44.980</a></span> | <span class="t">again and again and again."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3706" target="_blank">01:01:46.800</a></span> | <span class="t">Okay, that's why I did that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3709" target="_blank">01:01:49.760</a></span> | <span class="t">Our next step then is to try decreasing the learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3724" target="_blank">01:02:04.220</a></span> | <span class="t">So here is exactly the same model, but I'm now using a much lower learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3733" target="_blank">01:02:13.400</a></span> | <span class="t">And when I run that, it's actually moving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3738" target="_blank">01:02:18.360</a></span> | <span class="t">So it's only 12 seconds of compute time to figure out that I'm going to have to start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3742" target="_blank">01:02:22.800</a></span> | <span class="t">with a low learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3744" target="_blank">01:02:24.600</a></span> | <span class="t">Once we've got to a point where the accuracy is reasonably better than random, we're well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3752" target="_blank">01:02:32.800</a></span> | <span class="t">away from that part of the loss function now that says always predict everything as the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3757" target="_blank">01:02:37.880</a></span> | <span class="t">same class, and therefore we can now increase the learning rate back up again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3763" target="_blank">01:02:43.100</a></span> | <span class="t">So generally speaking, for these harder problems, you'll need to start at an epoch or two at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3767" target="_blank">01:02:47.480</a></span> | <span class="t">a low learning rate, and then you can increase it back up again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3773" target="_blank">01:02:53.160</a></span> | <span class="t">So you can see now I can put it back up to 0.01 and very quickly increase my accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3780" target="_blank">01:03:00.920</a></span> | <span class="t">So you can see here my accuracy on my validation set is 0.5 using a linear model, and this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3787" target="_blank">01:03:07.800</a></span> | <span class="t">is a good starting point because it says to me anytime that my validation accuracy is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3793" target="_blank">01:03:13.200</a></span> | <span class="t">worse than about 0.5, this is really no better than even a linear model, so this is not worth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3798" target="_blank">01:03:18.280</a></span> | <span class="t">spending more time on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3801" target="_blank">01:03:21.240</a></span> | <span class="t">One obvious question would be, how do you decide how big a sample to use?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3805" target="_blank">01:03:25.920</a></span> | <span class="t">And what I did was I tried a few different sizes of sample for my validation set, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3811" target="_blank">01:03:31.040</a></span> | <span class="t">I then said, okay, evaluate the model, in other words, calculate the loss function, on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3817" target="_blank">01:03:37.680</a></span> | <span class="t">validation set, but for a whole bunch of randomly sampled batches, so do it 10 times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3826" target="_blank">01:03:46.320</a></span> | <span class="t">And so then I looked and I saw how the accuracy changed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3829" target="_blank">01:03:49.760</a></span> | <span class="t">With the validation set at 1000 images, my accuracy changed from 0.48 or 0.47 to 0.51,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3838" target="_blank">01:03:58.880</a></span> | <span class="t">so it's not changing too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3841" target="_blank">01:04:01.280</a></span> | <span class="t">It's small enough that I think I can make useful insights using a sample size of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3846" target="_blank">01:04:06.880</a></span> | <span class="t">size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3850" target="_blank">01:04:10.000</a></span> | <span class="t">So what else can we learn from a sample?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3858" target="_blank">01:04:18.800</a></span> | <span class="t">One is, are there other architectures that work well?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3862" target="_blank">01:04:22.200</a></span> | <span class="t">So the obvious thing to do with a computer vision problem is to try a convolutional neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3866" target="_blank">01:04:26.440</a></span> | <span class="t">network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3868" target="_blank">01:04:28.880</a></span> | <span class="t">And here's one of the most simple convolutional neural networks, two convolutional layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3875" target="_blank">01:04:35.520</a></span> | <span class="t">each one with a max pooling layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3877" target="_blank">01:04:37.600</a></span> | <span class="t">And then one dense layer followed by my dense output layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3883" target="_blank">01:04:43.640</a></span> | <span class="t">So again I tried that and found that it very quickly got to an accuracy of 100% on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3891" target="_blank">01:04:51.920</a></span> | <span class="t">training set, but only 24% on the validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3896" target="_blank">01:04:56.240</a></span> | <span class="t">And that's because I was very careful to make sure my validation set included different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3900" target="_blank">01:05:00.760</a></span> | <span class="t">drivers to my training set, because on Kaggle it told us that the test set has different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3906" target="_blank">01:05:06.600</a></span> | <span class="t">drivers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3907" target="_blank">01:05:07.600</a></span> | <span class="t">So it's much harder to recognize what a driver is doing if we've never seen that driver before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3913" target="_blank">01:05:13.360</a></span> | <span class="t">So I could see that convolutional neural networks clearly are a great way to model this kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3919" target="_blank">01:05:19.600</a></span> | <span class="t">of data, but I've got to have to think very carefully about overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3924" target="_blank">01:05:24.200</a></span> | <span class="t">So step 1 to avoiding overfitting is data augmentation, as we learned in our data augmentation class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3931" target="_blank">01:05:31.700</a></span> | <span class="t">So here's the exact same model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3934" target="_blank">01:05:34.520</a></span> | <span class="t">And I tried every type of data augmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3938" target="_blank">01:05:38.980</a></span> | <span class="t">So I tried shifting it left and right a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3941" target="_blank">01:05:41.640</a></span> | <span class="t">I tried shifting it up and down a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3944" target="_blank">01:05:44.320</a></span> | <span class="t">I tried shearing it a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3947" target="_blank">01:05:47.040</a></span> | <span class="t">I tried rotating it a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3950" target="_blank">01:05:50.880</a></span> | <span class="t">I tried shifting the channels, so the colors a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3955" target="_blank">01:05:55.600</a></span> | <span class="t">And for each of those, I tried four different levels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3958" target="_blank">01:05:58.680</a></span> | <span class="t">And I found in each case what was the best.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3963" target="_blank">01:06:03.040</a></span> | <span class="t">And then I combined them all together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3966" target="_blank">01:06:06.200</a></span> | <span class="t">So here are my best data augmentation amounts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3971" target="_blank">01:06:11.200</a></span> | <span class="t">So on 1560 images, so a very small set, this is just my sample, I then ran my very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3978" target="_blank">01:06:18.160</a></span> | <span class="t">two convolutional layer model with this data augmentation at these optimized parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3985" target="_blank">01:06:25.520</a></span> | <span class="t">And it didn't look very good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3987" target="_blank">01:06:27.280</a></span> | <span class="t">After 5 epochs, I only had 0.1 accuracy on my validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3992" target="_blank">01:06:32.160</a></span> | <span class="t">But I can see that my training set is continuing to improve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=3996" target="_blank">01:06:36.200</a></span> | <span class="t">And so that makes me think, okay, don't give up yet, try deducing the learning rate and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4000" target="_blank">01:06:40.160</a></span> | <span class="t">do a few more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4001" target="_blank">01:06:41.640</a></span> | <span class="t">And lo and behold, it started improving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4003" target="_blank">01:06:43.240</a></span> | <span class="t">So this is where you've got to be careful not to jump to conclusions too soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4009" target="_blank">01:06:49.400</a></span> | <span class="t">So I ran a few more, and it's improving well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4012" target="_blank">01:06:52.080</a></span> | <span class="t">So I ran a few more, another 25.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4016" target="_blank">01:06:56.120</a></span> | <span class="t">And look at what happened.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4017" target="_blank">01:06:57.240</a></span> | <span class="t">It kept getting better and better and better until we were getting 67% accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4030" target="_blank">01:07:10.880</a></span> | <span class="t">So this 1.15 validation loss is well within the top 50% in this competition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4039" target="_blank">01:07:19.620</a></span> | <span class="t">So using an incredibly simple model, on just a sample, we can get in the top half of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4044" target="_blank">01:07:24.840</a></span> | <span class="t">Kaggle competition simply by using the right kind of data augmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4050" target="_blank">01:07:30.360</a></span> | <span class="t">So I think this is a really interesting insight about the power of this incredibly useful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4055" target="_blank">01:07:35.560</a></span> | <span class="t">tool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4056" target="_blank">01:07:36.560</a></span> | <span class="t">Okay, let's have a five minute break, and we'll do your question first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4073" target="_blank">01:07:53.040</a></span> | <span class="t">It's unlikely that there's going to be a class imbalance in my sample unless there was an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4078" target="_blank">01:07:58.800</a></span> | <span class="t">equivalent class imbalance in the real data, because I've got a thousand examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4085" target="_blank">01:08:05.000</a></span> | <span class="t">And so statistically speaking, that's unlikely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4087" target="_blank">01:08:07.800</a></span> | <span class="t">If there was a class imbalance in my original data, then I want my sample to have that class</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4091" target="_blank">01:08:11.400</a></span> | <span class="t">imbalance too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4094" target="_blank">01:08:14.960</a></span> | <span class="t">So at this point, I felt pretty good that I knew that we should be using a convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4104" target="_blank">01:08:24.160</a></span> | <span class="t">neural network, which is obviously a very strong hypothesis to start with anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4109" target="_blank">01:08:29.920</a></span> | <span class="t">And also I felt pretty confident when you knew what kind of learning rate to start with,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4116" target="_blank">01:08:36.680</a></span> | <span class="t">and then how to change it, and also what data augmentation to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4124" target="_blank">01:08:44.240</a></span> | <span class="t">The next thing I wanted to wonder about was how else do I handle overfitting, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4129" target="_blank">01:08:49.480</a></span> | <span class="t">although I'm getting some pretty good results, I'm still overfitting hugely, 0.6 versus 0.9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4137" target="_blank">01:08:57.560</a></span> | <span class="t">So the next thing in our list of ways to avoid overfitting, and I hope you guys all remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4143" target="_blank">01:09:03.040</a></span> | <span class="t">that we have that list in lesson 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4146" target="_blank">01:09:06.680</a></span> | <span class="t">The five steps, let's go and have a look at it now to remind ourselves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4154" target="_blank">01:09:14.000</a></span> | <span class="t">Approaches to reducing overfitting, these are the five steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4158" target="_blank">01:09:18.160</a></span> | <span class="t">We can't add more data, we've tried using data augmentation, we're already using batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4163" target="_blank">01:09:23.640</a></span> | <span class="t">norm and convnets, so the next step is to add regularization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4168" target="_blank">01:09:28.600</a></span> | <span class="t">And dropout is our favored regularization technique.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4172" target="_blank">01:09:32.180</a></span> | <span class="t">So I was thinking, okay, before we do that, I'll just mention one more thing about this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4178" target="_blank">01:09:38.600</a></span> | <span class="t">data augmentation approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4182" target="_blank">01:09:42.200</a></span> | <span class="t">I have literally never seen anybody write down a process as to how to figure out what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4190" target="_blank">01:09:50.640</a></span> | <span class="t">kind of data augmentation to use and the amount.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4193" target="_blank">01:09:53.900</a></span> | <span class="t">The only posts I've seen on it always rely on intuition, which is basically like, look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4200" target="_blank">01:10:00.680</a></span> | <span class="t">at the images and think about how much they seem like they should be able to move around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4204" target="_blank">01:10:04.240</a></span> | <span class="t">or rotate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4206" target="_blank">01:10:06.240</a></span> | <span class="t">I really tried this week to come up with a rigorous, repeatable process that you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4212" target="_blank">01:10:12.060</a></span> | <span class="t">use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4215" target="_blank">01:10:15.560</a></span> | <span class="t">And that process is go through each data augmentation type one at a time, try 3 or 4 different levels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4221" target="_blank">01:10:21.420</a></span> | <span class="t">of it on a sample with a big enough validation set that it's pretty stable to find the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4229" target="_blank">01:10:29.560</a></span> | <span class="t">value of each of the data augmentation parameters, and then try combining them all together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4240" target="_blank">01:10:40.640</a></span> | <span class="t">So I hope you kind of come away with this as a practical message which probably your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4249" target="_blank">01:10:49.920</a></span> | <span class="t">colleagues, even if some of them claim to be deep learning experts, I doubt that they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4253" target="_blank">01:10:53.520</a></span> | <span class="t">doing this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4254" target="_blank">01:10:54.800</a></span> | <span class="t">So this is something you can hopefully get people into the practice of doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4260" target="_blank">01:11:00.800</a></span> | <span class="t">Regularization however, we cannot do on a sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4264" target="_blank">01:11:04.600</a></span> | <span class="t">And the reason why is that step 1, add more data, well that step is very correlated with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4274" target="_blank">01:11:14.960</a></span> | <span class="t">add regularization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4276" target="_blank">01:11:16.120</a></span> | <span class="t">As we add more data, we need less regularization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4280" target="_blank">01:11:20.000</a></span> | <span class="t">So as we move from a sample to the full dataset, we're going to need less regularization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4285" target="_blank">01:11:25.920</a></span> | <span class="t">So to figure out how much regularization to use, we have to use the whole dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4290" target="_blank">01:11:30.360</a></span> | <span class="t">So at this point I changed it to use the whole dataset, not the sample, and I started using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4298" target="_blank">01:11:38.360</a></span> | <span class="t">Dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4299" target="_blank">01:11:39.360</a></span> | <span class="t">So you can see that I started with my data augmentation amounts that you've already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4303" target="_blank">01:11:43.600</a></span> | <span class="t">seen, and I started adding in some Dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4309" target="_blank">01:11:49.200</a></span> | <span class="t">And ran it for a few epochs to see what would happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4313" target="_blank">01:11:53.480</a></span> | <span class="t">And you can see it's worked pretty well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4317" target="_blank">01:11:57.220</a></span> | <span class="t">So we're getting up into the 75% now, and before we were in the 64%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4322" target="_blank">01:12:02.360</a></span> | <span class="t">So once we add clipping, which is very important for getting the best cross-entropy loss function,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4330" target="_blank">01:12:10.800</a></span> | <span class="t">I haven't checked where that would get us on the Kaggle leaderboard, but I'm pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4336" target="_blank">01:12:16.560</a></span> | <span class="t">sure it would be at least in the top third based on this accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4341" target="_blank">01:12:21.640</a></span> | <span class="t">So I ran a few more epochs with an even lower learning rate and got 0.78, 0.79.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4355" target="_blank">01:12:35.000</a></span> | <span class="t">So this is going to be well up into the top third, maybe even the top third of the leaderboard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4363" target="_blank">01:12:43.280</a></span> | <span class="t">So I got to this point by just trying out a couple of different levels of Dropout, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4369" target="_blank">01:12:49.320</a></span> | <span class="t">I'll just put them in my dense layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4371" target="_blank">01:12:51.880</a></span> | <span class="t">There's no rule of thumb here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4374" target="_blank">01:12:54.200</a></span> | <span class="t">A lot of people put small amounts of Dropout in their convolutional layers as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4379" target="_blank">01:12:59.640</a></span> | <span class="t">All I can say is to try things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4383" target="_blank">01:13:03.160</a></span> | <span class="t">But what VGG does is to put 50% Dropout after each of its dense layers, and that doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4389" target="_blank">01:13:09.680</a></span> | <span class="t">seem like a bad rule of thumb, so that's what I was doing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4392" target="_blank">01:13:12.440</a></span> | <span class="t">And then trying around a few different sizes of dense layers to try and find something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4396" target="_blank">01:13:16.320</a></span> | <span class="t">reasonable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4397" target="_blank">01:13:17.320</a></span> | <span class="t">I didn't spend a heap of time on this, so there's probably better architectures, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4401" target="_blank">01:13:21.160</a></span> | <span class="t">as you can see this is still a pretty good one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4404" target="_blank">01:13:24.080</a></span> | <span class="t">So that was my step 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4406" target="_blank">01:13:26.040</a></span> | <span class="t">Now so far we have not used a pre-trained network at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4415" target="_blank">01:13:35.080</a></span> | <span class="t">So this is getting into the top third of the leaderboard without even using any ImageNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4420" target="_blank">01:13:40.320</a></span> | <span class="t">features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4421" target="_blank">01:13:41.320</a></span> | <span class="t">So that's pretty damn cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4424" target="_blank">01:13:44.120</a></span> | <span class="t">But we're pretty sure that ImageNet features would be helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4427" target="_blank">01:13:47.640</a></span> | <span class="t">So that was the next step, was to use ImageNet features, so VGG features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4432" target="_blank">01:13:52.560</a></span> | <span class="t">Specifically, I was reasonably confident that all of the convolutional layers of VGG are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4439" target="_blank">01:13:59.680</a></span> | <span class="t">probably pretty much good enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4441" target="_blank">01:14:01.520</a></span> | <span class="t">I didn't expect I would have to fine-tune them much, if at all, because the convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4446" target="_blank">01:14:06.120</a></span> | <span class="t">layers are the things which really look at the shape and structure of things rather than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4451" target="_blank">01:14:11.280</a></span> | <span class="t">how they fit together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4452" target="_blank">01:14:12.960</a></span> | <span class="t">And these are photos of the real world, just like ImageNet are photos of the real world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4458" target="_blank">01:14:18.580</a></span> | <span class="t">So I really felt like most of the time, if not all of it, was likely to be spent on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4463" target="_blank">01:14:23.480</a></span> | <span class="t">dense layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4465" target="_blank">01:14:25.200</a></span> | <span class="t">So therefore, because calculating the convolutional layers takes nearly all the time, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4470" target="_blank">01:14:30.560</a></span> | <span class="t">that's where all the computation is, I pre-computed the output of the convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4477" target="_blank">01:14:37.240</a></span> | <span class="t">And we've done this before, you might remember.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4481" target="_blank">01:14:41.020</a></span> | <span class="t">When we looked at dropout, we did exactly this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4490" target="_blank">01:14:50.840</a></span> | <span class="t">We figured out what was the last convolutional layer's ID.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4495" target="_blank">01:14:55.240</a></span> | <span class="t">We grabbed all of the layers up to that ID, we built a model out of them, and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4502" target="_blank">01:15:02.240</a></span> | <span class="t">calculated the output of that model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4505" target="_blank">01:15:05.640</a></span> | <span class="t">And that told us the value of those features, those activations from VGG's last convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4512" target="_blank">01:15:12.440</a></span> | <span class="t">layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4513" target="_blank">01:15:13.560</a></span> | <span class="t">So I did exactly the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4514" target="_blank">01:15:14.960</a></span> | <span class="t">I basically copied and pasted that code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4518" target="_blank">01:15:18.540</a></span> | <span class="t">So I said okay, grab VGG 16, find the last convolutional layer, build a model that contains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4524" target="_blank">01:15:24.000</a></span> | <span class="t">everything up to and including that layer, predict the output of that model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4534" target="_blank">01:15:34.320</a></span> | <span class="t">So predicting the output means calculate the activations of that last convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4542" target="_blank">01:15:42.080</a></span> | <span class="t">And since that takes some time, then save that so I never have to do it again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4549" target="_blank">01:15:49.640</a></span> | <span class="t">So then in the future I can just load that array.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4554" target="_blank">01:15:54.920</a></span> | <span class="t">So this array, I'm not going to calculate those, I'm simply going to load them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4567" target="_blank">01:16:07.840</a></span> | <span class="t">And so have a think about what would you expect the shape of this to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4573" target="_blank">01:16:13.560</a></span> | <span class="t">And you can figure out what you would expect the shape to be by looking at model.summary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4581" target="_blank">01:16:21.420</a></span> | <span class="t">and finding the last convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4584" target="_blank">01:16:24.760</a></span> | <span class="t">Here it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4585" target="_blank">01:16:25.760</a></span> | <span class="t">And we can see it is 512 filters by 14x14.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4591" target="_blank">01:16:31.440</a></span> | <span class="t">So let's have a look, just one moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4596" target="_blank">01:16:36.440</a></span> | <span class="t">We'll find our conv_val_feet.shape, 512x14x14 as expected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4614" target="_blank">01:16:54.080</a></span> | <span class="t">Is there a reason you chose to leave out the max_pooling and flatten layers?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4620" target="_blank">01:17:00.560</a></span> | <span class="t">So why did I leave out the max_pooling and flatten layers?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4625" target="_blank">01:17:05.440</a></span> | <span class="t">Probably because it takes zero time to calculate them and the max_pooling layer loses information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4633" target="_blank">01:17:13.560</a></span> | <span class="t">So I thought given that I might want to play around with other types of pooling or other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4639" target="_blank">01:17:19.360</a></span> | <span class="t">types of convolutions or whatever, I thought pre-calculating this layer is the last one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4644" target="_blank">01:17:24.680</a></span> | <span class="t">that takes a lot of computation time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4648" target="_blank">01:17:28.360</a></span> | <span class="t">Having said that, the first thing I did with it in my new model was to max_pool_it and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4653" target="_blank">01:17:33.800</a></span> | <span class="t">flatten it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4660" target="_blank">01:17:40.640</a></span> | <span class="t">So now that I have the output of VGG for the last conv layer, I can now build a model that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4668" target="_blank">01:17:48.360</a></span> | <span class="t">has dense layers on top of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4671" target="_blank">01:17:51.500</a></span> | <span class="t">And so the input to this model will be the output of those conv layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4674" target="_blank">01:17:54.740</a></span> | <span class="t">And the nice thing is it won't take long to run this, even on the whole dataset, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4678" target="_blank">01:17:58.240</a></span> | <span class="t">the dense layers don't take much computation time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4681" target="_blank">01:18:01.560</a></span> | <span class="t">So here's my model, and by making p a parameter, I could try a wide range of dropout amounts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4691" target="_blank">01:18:11.160</a></span> | <span class="t">and I fit it, and one epoch takes 5 seconds on the entire dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4697" target="_blank">01:18:17.520</a></span> | <span class="t">So this is a super good way to play around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4700" target="_blank">01:18:20.360</a></span> | <span class="t">And you can see 1 epoch gets me 0.65, 3 epochs get me 0.75.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4715" target="_blank">01:18:35.280</a></span> | <span class="t">So this is pretty cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4716" target="_blank">01:18:36.280</a></span> | <span class="t">I have something that in 15 seconds can get me 0.75 accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4719" target="_blank">01:18:39.960</a></span> | <span class="t">And notice here, I'm not using any data augmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4725" target="_blank">01:18:45.080</a></span> | <span class="t">Why aren't I using data augmentation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4727" target="_blank">01:18:47.140</a></span> | <span class="t">Because you can't pre-compute the output of convolutional layers if you're using data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4731" target="_blank">01:18:51.520</a></span> | <span class="t">augmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4732" target="_blank">01:18:52.520</a></span> | <span class="t">Because with data augmentation, your convolutional layers give you a different output every time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4740" target="_blank">01:19:00.180</a></span> | <span class="t">So that's just a bit of a bummer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4745" target="_blank">01:19:05.040</a></span> | <span class="t">You can't use data augmentation if you are pre-computing the output of a layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4750" target="_blank">01:19:10.840</a></span> | <span class="t">Because think about it, every time it sees the same cat photo, it's rotating it by a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4757" target="_blank">01:19:17.520</a></span> | <span class="t">different amount, or moving it by a different amount.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4762" target="_blank">01:19:22.240</a></span> | <span class="t">So it gives a different output of the convolutional layer, so you can't pre-compute it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4771" target="_blank">01:19:31.520</a></span> | <span class="t">There is something you can do, which I've played with a little bit, which is you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4775" target="_blank">01:19:35.680</a></span> | <span class="t">pre-compute something that's 10 times bigger than your dataset, consisting of 10 different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4783" target="_blank">01:19:43.720</a></span> | <span class="t">data-augmented versions of it, which is why I actually had this -- where is it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4793" target="_blank">01:19:53.400</a></span> | <span class="t">Which is what I was doing here when I brought in this data generator with augmentations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4797" target="_blank">01:19:57.520</a></span> | <span class="t">and I created something called data-augmented convolutional features, in which I predicted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4803" target="_blank">01:20:03.960</a></span> | <span class="t">5 times the amount of data, or calculated 5 times the amount of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4809" target="_blank">01:20:09.800</a></span> | <span class="t">And so that basically gave me a dataset 5 times bigger, and that actually worked pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4814" target="_blank">01:20:14.680</a></span> | <span class="t">well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4816" target="_blank">01:20:16.260</a></span> | <span class="t">It's not as good as having a whole new sample every time, but it's kind of a compromise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4822" target="_blank">01:20:22.200</a></span> | <span class="t">So once I played around with these dense layers, I then did some more fine-tuning and found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4830" target="_blank">01:20:30.420</a></span> | <span class="t">out that -- so if I went basically here, I then tried saying, okay, let's go through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4836" target="_blank">01:20:36.400</a></span> | <span class="t">all of my layers in my model from 16 onwards and set them to trainable and see what happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4844" target="_blank">01:20:44.120</a></span> | <span class="t">So I tried retraining, fine-tuning some of the convolutional layers as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4848" target="_blank">01:20:48.520</a></span> | <span class="t">It basically didn't help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4850" target="_blank">01:20:50.400</a></span> | <span class="t">So I experimented with my hypothesis, and I found it was correct, which is it seems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4854" target="_blank">01:20:54.960</a></span> | <span class="t">that for this particular model, coming up with the right set of dense layers is what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4861" target="_blank">01:21:01.400</a></span> | <span class="t">it's all about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4862" target="_blank">01:21:02.400</a></span> | <span class="t">Yes, Rachel?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4863" target="_blank">01:21:03.400</a></span> | <span class="t">Question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4864" target="_blank">01:21:04.400</a></span> | <span class="t">If we want rotational invariance, should we keep the max pooling, or can another layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4869" target="_blank">01:21:09.800</a></span> | <span class="t">do it as well?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4875" target="_blank">01:21:15.120</a></span> | <span class="t">Max pooling doesn't really have anything to do with rotational invariance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4879" target="_blank">01:21:19.080</a></span> | <span class="t">Max pooling does translation invariance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4887" target="_blank">01:21:27.280</a></span> | <span class="t">So I'm going to show you one more cool trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4889" target="_blank">01:21:29.200</a></span> | <span class="t">I'm going to show you a little bit of State Farm every week from now on because there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4893" target="_blank">01:21:33.200</a></span> | <span class="t">so many cool things to try, and I want to keep reviewing CNNs because convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4898" target="_blank">01:21:38.560</a></span> | <span class="t">neural nets really are becoming what deep learning is all about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4903" target="_blank">01:21:43.520</a></span> | <span class="t">I'm going to show you one really cool trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4905" target="_blank">01:21:45.720</a></span> | <span class="t">It's actually a combination of two tricks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4907" target="_blank">01:21:47.640</a></span> | <span class="t">The two tricks are called pseudo-labeling and knowledge distillation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4913" target="_blank">01:21:53.680</a></span> | <span class="t">So if you Google for pseudo-labeling semi-supervised learning, you can see the original paper that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4922" target="_blank">01:22:02.480</a></span> | <span class="t">came out with pseudo-labeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4924" target="_blank">01:22:04.760</a></span> | <span class="t">I guess that's 2013.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4929" target="_blank">01:22:09.600</a></span> | <span class="t">And then knowledge distillation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4933" target="_blank">01:22:13.160</a></span> | <span class="t">This is a Jeffrey Hinton paper, Distilling the Knowledge in a Neural Network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4937" target="_blank">01:22:17.560</a></span> | <span class="t">This is from 2015.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4940" target="_blank">01:22:20.040</a></span> | <span class="t">So these are a couple of really cool techniques which Hinton and Jeff Dean, that's not bad,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4949" target="_blank">01:22:29.240</a></span> | <span class="t">we're going to combine them together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4952" target="_blank">01:22:32.440</a></span> | <span class="t">And they're kind of crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4954" target="_blank">01:22:34.680</a></span> | <span class="t">What we're going to do is we are going to use the test set to give us more information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4960" target="_blank">01:22:40.400</a></span> | <span class="t">Because in State Farm, the test set has 80,000 images in it, and the training set has 20,000</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4967" target="_blank">01:22:47.960</a></span> | <span class="t">images in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4974" target="_blank">01:22:54.920</a></span> | <span class="t">What could we do with those 80,000 images which we don't have labels for?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4981" target="_blank">01:23:01.760</a></span> | <span class="t">It seems a shame to waste them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4983" target="_blank">01:23:03.880</a></span> | <span class="t">It seems like we should be able to do something with them, and there's a great little picture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4986" target="_blank">01:23:06.880</a></span> | <span class="t">here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4987" target="_blank">01:23:07.880</a></span> | <span class="t">Imagine we only had two points, and we knew their labels, white and black.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4994" target="_blank">01:23:14.400</a></span> | <span class="t">And then somebody said, "How would you label this?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=4997" target="_blank">01:23:17.960</a></span> | <span class="t">And then they told you that there's a whole lot of other unlabeled data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5004" target="_blank">01:23:24.000</a></span> | <span class="t">Notice this is all gray, it's not labeled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5007" target="_blank">01:23:27.880</a></span> | <span class="t">But it's helped us, hasn't it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5009" target="_blank">01:23:29.720</a></span> | <span class="t">It's helped us because it's told us how the data is structured.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5014" target="_blank">01:23:34.840</a></span> | <span class="t">This is what semi-supervised learning is all about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5016" target="_blank">01:23:36.920</a></span> | <span class="t">It's all about using the unlabeled data to try and understand something about the structure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5021" target="_blank">01:23:41.120</a></span> | <span class="t">of it and use that to help you, just like in this picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5027" target="_blank">01:23:47.680</a></span> | <span class="t">Pseudo-labeling and knowledge distillation are a way to do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5031" target="_blank">01:23:51.920</a></span> | <span class="t">And what we do is -- and I'm not going to do it on the test set, I'm going to do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5035" target="_blank">01:23:55.880</a></span> | <span class="t">on the validation set because it's a little bit easier to see the impact of it, and maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5040" target="_blank">01:24:00.920</a></span> | <span class="t">next week we'll look at the test set to see, because that's going to be much cooler when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5044" target="_blank">01:24:04.680</a></span> | <span class="t">you do it on the test set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5046" target="_blank">01:24:06.720</a></span> | <span class="t">It's this simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5047" target="_blank">01:24:07.720</a></span> | <span class="t">What we do is we take our model, some model we've already built, and we predict the outputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5054" target="_blank">01:24:14.360</a></span> | <span class="t">from that model for our unlabeled set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5057" target="_blank">01:24:17.600</a></span> | <span class="t">In this case, I'm using the validation set, as if it was unlabeled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5061" target="_blank">01:24:21.000</a></span> | <span class="t">So I'm ignoring labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5063" target="_blank">01:24:23.800</a></span> | <span class="t">And those things we call the pseudo-labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5066" target="_blank">01:24:26.440</a></span> | <span class="t">So now that we have predictions for the test set or the validation set, it's not that they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5072" target="_blank">01:24:32.160</a></span> | <span class="t">true, but we can pretend they're true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5075" target="_blank">01:24:35.520</a></span> | <span class="t">We can say there's some label, they're not correct labels, but they're labels nonetheless.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5080" target="_blank">01:24:40.080</a></span> | <span class="t">So what we then do is we take our training labels and we concatenate them with our validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5087" target="_blank">01:24:47.040</a></span> | <span class="t">or test set pseudo-labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5089" target="_blank">01:24:49.800</a></span> | <span class="t">And so we now have a bunch of labels for all of our data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5093" target="_blank">01:24:53.840</a></span> | <span class="t">And so we can now also concatenate our convolutional features with the convolutional features of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5099" target="_blank">01:24:59.960</a></span> | <span class="t">the validation set or test set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5103" target="_blank">01:25:03.960</a></span> | <span class="t">And we now use these to train a model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5109" target="_blank">01:25:09.420</a></span> | <span class="t">So the model we use is exactly the same model we had before, and we train it in exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5115" target="_blank">01:25:15.120</a></span> | <span class="t">the same way as before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5117" target="_blank">01:25:17.640</a></span> | <span class="t">And our loss goes up from 0.75 to 0.82.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5122" target="_blank">01:25:22.340</a></span> | <span class="t">So our error has dropped by like 25%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5127" target="_blank">01:25:27.240</a></span> | <span class="t">And the reason why is just because we use this additional unlabeled data to try to figure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5134" target="_blank">01:25:34.740</a></span> | <span class="t">out the structure of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5136" target="_blank">01:25:36.240</a></span> | <span class="t">Question about model choice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5139" target="_blank">01:25:39.840</a></span> | <span class="t">How do you learn how to design a model and when to stop messing with them?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5143" target="_blank">01:25:43.240</a></span> | <span class="t">It seems like you've taken a few initial ideas, tweaked them to get higher accuracy, but unless</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5148" target="_blank">01:25:48.120</a></span> | <span class="t">your initial guesses are amazing, there should be plenty of architectures that would also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5151" target="_blank">01:25:51.880</a></span> | <span class="t">work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5153" target="_blank">01:25:53.880</a></span> | <span class="t">So if and when you figure out how to find an architecture and stop messing with it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5159" target="_blank">01:25:59.560</a></span> | <span class="t">please tell me, because I don't sleep.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5167" target="_blank">01:26:07.040</a></span> | <span class="t">We all want to know this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5168" target="_blank">01:26:08.680</a></span> | <span class="t">I look back at these models I'm showing you and I'm thinking, I bet there's something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5174" target="_blank">01:26:14.920</a></span> | <span class="t">twice as good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5177" target="_blank">01:26:17.160</a></span> | <span class="t">I don't know what it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5179" target="_blank">01:26:19.360</a></span> | <span class="t">There are all kinds of ways of optimizing other hyperparameters of deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5186" target="_blank">01:26:26.020</a></span> | <span class="t">For example, there's something called spearmint, which is a Bayesian optimization hyperparameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5196" target="_blank">01:26:36.120</a></span> | <span class="t">tuning thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5199" target="_blank">01:26:39.360</a></span> | <span class="t">In fact, just last week a new paper came out for hyperparameter tuning, but this is all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5203" target="_blank">01:26:43.840</a></span> | <span class="t">about tuning things like the learning rate and stuff like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5210" target="_blank">01:26:50.280</a></span> | <span class="t">Coming up with architectures, there are some people who have tried to come up with some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5223" target="_blank">01:27:03.840</a></span> | <span class="t">kind of more general architectures, and we're going to look at one next week called ResNets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5229" target="_blank">01:27:09.840</a></span> | <span class="t">which seem to be pretty encouraging in that direction, but even then, ResNet, which we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5239" target="_blank">01:27:19.360</a></span> | <span class="t">going to learn about next week, is an architecture which won ImageNet in 2015.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5247" target="_blank">01:27:27.400</a></span> | <span class="t">The author of ResNet, Kaiming He from Microsoft, said, "The reason ResNet is so great is it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5255" target="_blank">01:27:35.960</a></span> | <span class="t">lets us build very, very, very deep networks."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5260" target="_blank">01:27:40.080</a></span> | <span class="t">Indeed he showed a network with over a thousand layers, and it was totally state-of-the-art.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5265" target="_blank">01:27:45.680</a></span> | <span class="t">Somebody else came along a few months ago and built wide ResNets with like 50 layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5274" target="_blank">01:27:54.520</a></span> | <span class="t">and easily beat Kaiming He's best results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5277" target="_blank">01:27:57.880</a></span> | <span class="t">So the very author of the ImageNet winner completely got wrong the reason why his invention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5283" target="_blank">01:28:03.480</a></span> | <span class="t">was good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5286" target="_blank">01:28:06.000</a></span> | <span class="t">The idea that any of us have any idea how to create optimal architectures is totally,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5290" target="_blank">01:28:10.960</a></span> | <span class="t">totally wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5291" target="_blank">01:28:11.960</a></span> | <span class="t">We don't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5292" target="_blank">01:28:12.960</a></span> | <span class="t">So that's why I'm trying to show you what we know so far, which is like the processes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5298" target="_blank">01:28:18.000</a></span> | <span class="t">you can use to build them without waiting forever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5301" target="_blank">01:28:21.320</a></span> | <span class="t">So in this case, doing your data augmentation on the small sample in a rigorous way, figuring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5307" target="_blank">01:28:27.000</a></span> | <span class="t">out that probably the dense layers are where the action is at and pre-computing the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5311" target="_blank">01:28:31.320</a></span> | <span class="t">to them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5312" target="_blank">01:28:32.560</a></span> | <span class="t">These are the kinds of things that can keep you sane.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5316" target="_blank">01:28:36.240</a></span> | <span class="t">I'm showing you the outcome of my last weeks kind of playing with this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5321" target="_blank">01:28:41.500</a></span> | <span class="t">I can tell you that during this time I continually fell into the trap of running stuff on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5327" target="_blank">01:28:47.520</a></span> | <span class="t">whole network and all the way through and fiddling around with hyperparameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5333" target="_blank">01:28:53.240</a></span> | <span class="t">And I have to stop myself and have a cup of tea and say, "Okay, is this really a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5336" target="_blank">01:28:56.760</a></span> | <span class="t">idea?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5337" target="_blank">01:28:57.760</a></span> | <span class="t">This is really a good use of time."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5339" target="_blank">01:28:59.080</a></span> | <span class="t">So we all do it, but not you anymore because you've been to this class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5345" target="_blank">01:29:05.560</a></span> | <span class="t">Green box, back there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5349" target="_blank">01:29:09.520</a></span> | <span class="t">Can you run us through this one more time?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5353" target="_blank">01:29:13.080</a></span> | <span class="t">I'm just a little confused because it feels like maybe we're using our validation set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5358" target="_blank">01:29:18.440</a></span> | <span class="t">as part of our training program and I'm confused how it's not true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5362" target="_blank">01:29:22.000</a></span> | <span class="t">But look, we're not using the validation labels, nowhere here does it say "val_labels".</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5370" target="_blank">01:29:30.160</a></span> | <span class="t">So yeah, we are absolutely using our validation set but we're using the validation set's inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5377" target="_blank">01:29:37.320</a></span> | <span class="t">And for our test set we have the inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5381" target="_blank">01:29:41.320</a></span> | <span class="t">So next week I will show you this page again, and this time I'm going to use the test set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5386" target="_blank">01:29:46.680</a></span> | <span class="t">I just didn't have enough time to do it this time around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5389" target="_blank">01:29:49.560</a></span> | <span class="t">And hopefully we're going to see some great results, and when we do it on the test set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5392" target="_blank">01:29:52.840</a></span> | <span class="t">then you'll be really convinced that it's not using the labels because we don't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5395" target="_blank">01:29:55.720</a></span> | <span class="t">any labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5396" target="_blank">01:29:56.720</a></span> | <span class="t">But you can see here, all it's doing is it's creating pseudo-labels by calculating what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5402" target="_blank">01:30:02.280</a></span> | <span class="t">it thinks it ought to be based on the model that we just built with that 75% accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5410" target="_blank">01:30:10.520</a></span> | <span class="t">And so then it's able to use the input data for the validation set in an intelligent way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5416" target="_blank">01:30:16.280</a></span> | <span class="t">and therefore improve the accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5422" target="_blank">01:30:22.340</a></span> | <span class="t">What do you mean the same?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5431" target="_blank">01:30:31.480</a></span> | <span class="t">Yeah, it's using bn_model, and bn_model is the thing that we just fitted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5446" target="_blank">01:30:46.120</a></span> | <span class="t">By using the training labels, so this is bn_model, the thing with this 0.755 accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5452" target="_blank">01:30:52.520</a></span> | <span class="t">So if we were to look at - I know we haven't gone through this - can you move a bit closer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5457" target="_blank">01:30:57.280</a></span> | <span class="t">to the mic?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5458" target="_blank">01:30:58.280</a></span> | <span class="t">Sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5459" target="_blank">01:30:59.280</a></span> | <span class="t">And this is supervised and unsupervised learning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5461" target="_blank">01:31:01.800</a></span> | <span class="t">And in this case semi-supervised learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5463" target="_blank">01:31:03.340</a></span> | <span class="t">Semi-supervised learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5464" target="_blank">01:31:04.340</a></span> | <span class="t">Right, and semi-supervised works because you're giving it a model which already knows about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5469" target="_blank">01:31:09.360</a></span> | <span class="t">a bunch of labels but unsupervised wouldn't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5472" target="_blank">01:31:12.400</a></span> | <span class="t">Unsupervised has nothing, that's right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5477" target="_blank">01:31:17.520</a></span> | <span class="t">I wasn't particularly thinking about doing this, but unsupervised learning is where you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5483" target="_blank">01:31:23.040</a></span> | <span class="t">trying to build a model when you have no labels at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5487" target="_blank">01:31:27.320</a></span> | <span class="t">How many people here would be interested in hearing about unsupervised learning during</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5491" target="_blank">01:31:31.240</a></span> | <span class="t">this class?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5492" target="_blank">01:31:32.240</a></span> | <span class="t">Okay, enough people, I should do that, I will add it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5502" target="_blank">01:31:42.240</a></span> | <span class="t">During the week, perhaps we can create a forum thread about unsupervised learning and I can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5506" target="_blank">01:31:46.520</a></span> | <span class="t">learn about what you're interested in doing with it because many things that people think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5511" target="_blank">01:31:51.280</a></span> | <span class="t">of as unsupervised problems actually aren't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5515" target="_blank">01:31:55.120</a></span> | <span class="t">Okay, so pseudo-labeling is insane and awesome, and we need the green box back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5522" target="_blank">01:32:02.840</a></span> | <span class="t">Okay, and there are a number of questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5531" target="_blank">01:32:11.640</a></span> | <span class="t">Earlier you talked about learning about the structure of the data that you can learn from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5534" target="_blank">01:32:14.800</a></span> | <span class="t">the validation set, can you say more about that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5538" target="_blank">01:32:18.320</a></span> | <span class="t">I don't know, not really.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5540" target="_blank">01:32:20.640</a></span> | <span class="t">Other than that picture I showed you before with the two little spirally things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5545" target="_blank">01:32:25.520</a></span> | <span class="t">And that picture was kind of showing how they clustered in a way that was higher dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5549" target="_blank">01:32:29.120</a></span> | <span class="t">than what you can see when you just had to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5551" target="_blank">01:32:31.420</a></span> | <span class="t">So think about that Matt Zyler paper we saw, or the Jason Yersinski visualization tool</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5556" target="_blank">01:32:36.560</a></span> | <span class="t">box we saw.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5558" target="_blank">01:32:38.500</a></span> | <span class="t">The layers learn shapes and textures and concepts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5566" target="_blank">01:32:46.300</a></span> | <span class="t">In that 80,000 test images of people driving in different distracted ways, there are lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5572" target="_blank">01:32:52.960</a></span> | <span class="t">of concepts there to learn about ways in which people drive in distracted ways, even although</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5578" target="_blank">01:32:58.540</a></span> | <span class="t">they're not labeled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5580" target="_blank">01:33:00.080</a></span> | <span class="t">So what we're doing is we're trying to learn better convolutional or dense features, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5588" target="_blank">01:33:08.920</a></span> | <span class="t">what I mean by learning more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5590" target="_blank">01:33:10.660</a></span> | <span class="t">So the structure of the data here is basically like what do these pictures tend to look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5596" target="_blank">01:33:16.400</a></span> | <span class="t">More importantly, in what ways do they differ?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5599" target="_blank">01:33:19.360</a></span> | <span class="t">Because it's the ways that they differ that therefore must be related to how they're labeled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5605" target="_blank">01:33:25.920</a></span> | <span class="t">Can you use your updated model to make new labels for the validation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5612" target="_blank">01:33:32.520</a></span> | <span class="t">Yes, you can absolutely do pseudo-labeling on pseudo-labeling, and you should.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5618" target="_blank">01:33:38.200</a></span> | <span class="t">And if I don't get sick of running this code, I will try it next week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5624" target="_blank">01:33:44.600</a></span> | <span class="t">Could that introduce bias towards your validation set?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5629" target="_blank">01:33:49.480</a></span> | <span class="t">No because we don't have any validation labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5633" target="_blank">01:33:53.080</a></span> | <span class="t">One of the tricky parameters in pseudo-labeling is in each batch, how much do I make it a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5641" target="_blank">01:34:01.280</a></span> | <span class="t">mix of training versus pseudo?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5645" target="_blank">01:34:05.120</a></span> | <span class="t">One of the big things that stopped me from getting the test set in this week is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5650" target="_blank">01:34:10.440</a></span> | <span class="t">Keras doesn't have a way of creating batches which have like 80% of this set and 20% of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5659" target="_blank">01:34:19.040</a></span> | <span class="t">that set, which is really what I want -- because if I just pseudo-labeled the whole test set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5664" target="_blank">01:34:24.440</a></span> | <span class="t">and then concatenated it, then 80% of my batches are going to be pseudo-labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5671" target="_blank">01:34:31.080</a></span> | <span class="t">And generally speaking, the rule of thumb I've read is that somewhere around a quarter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5675" target="_blank">01:34:35.240</a></span> | <span class="t">to a third of your mini-batches should be pseudo-labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5679" target="_blank">01:34:39.040</a></span> | <span class="t">So I need to write some code basically to get Keras to generate batches which are a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5685" target="_blank">01:34:45.640</a></span> | <span class="t">mix from two different places before I can do this properly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5689" target="_blank">01:34:49.440</a></span> | <span class="t">There are two questions and I think you're asking the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5693" target="_blank">01:34:53.240</a></span> | <span class="t">Are your pseudo-labels only as good as the initial model you're beginning from, so do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5697" target="_blank">01:34:57.320</a></span> | <span class="t">you need to have kind of a particular accuracy in your model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5700" target="_blank">01:35:00.880</a></span> | <span class="t">Yeah, your pseudo-labels are indeed as good as your model you're starting from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5705" target="_blank">01:35:05.880</a></span> | <span class="t">People have not studied this enough to know how sensitive it is to those initial labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5713" target="_blank">01:35:13.080</a></span> | <span class="t">No, this is too new, you know, and just try it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5725" target="_blank">01:35:25.360</a></span> | <span class="t">My guess is that pseudo-labels will be useful regardless of what accuracy level you're at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5730" target="_blank">01:35:30.720</a></span> | <span class="t">because it will make it better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5732" target="_blank">01:35:32.280</a></span> | <span class="t">As long as you are in a semi-supervised learning context, i.e. you have a lot of unlabeled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5736" target="_blank">01:35:36.840</a></span> | <span class="t">data that you want to take advantage of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5740" target="_blank">01:35:40.560</a></span> | <span class="t">I really want to move on because I told you I wanted to get us down the path to NLP this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5747" target="_blank">01:35:47.560</a></span> | <span class="t">week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5749" target="_blank">01:35:49.040</a></span> | <span class="t">And it turns out that the path to NLP, strange as it sounds, starts with collaborative filtering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5756" target="_blank">01:35:56.140</a></span> | <span class="t">You will learn why next week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5758" target="_blank">01:35:58.380</a></span> | <span class="t">This week we are going to learn about collaborative filtering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5761" target="_blank">01:36:01.740</a></span> | <span class="t">And so collaborative filtering is a way of doing recommender systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5766" target="_blank">01:36:06.560</a></span> | <span class="t">And I sent you guys an email today with a link to more information about collaborative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5771" target="_blank">01:36:11.300</a></span> | <span class="t">filtering and recommender systems, so please read those links if you haven't already just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5777" target="_blank">01:36:17.720</a></span> | <span class="t">to get a sense of what the problem we're solving here is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5782" target="_blank">01:36:22.520</a></span> | <span class="t">In short, what we're trying to do is to learn to predict who is going to like what and how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5794" target="_blank">01:36:34.800</a></span> | <span class="t">much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5796" target="_blank">01:36:36.200</a></span> | <span class="t">For example, the $1 million Netflix price, at what rating level will this person give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5804" target="_blank">01:36:44.120</a></span> | <span class="t">this movie?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5806" target="_blank">01:36:46.880</a></span> | <span class="t">If you're writing Amazon's recommender system to figure out what to show you on their homepage,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5812" target="_blank">01:36:52.080</a></span> | <span class="t">which products is his person likely to rate highly?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5817" target="_blank">01:36:57.960</a></span> | <span class="t">If you're trying to figure out what stuff to show at a news speed, which articles is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5822" target="_blank">01:37:02.840</a></span> | <span class="t">his person likely to enjoy reading?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5826" target="_blank">01:37:06.840</a></span> | <span class="t">There's a lot of different ways of doing this, but broadly speaking there are two main classifications</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5830" target="_blank">01:37:10.920</a></span> | <span class="t">of recommender system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5833" target="_blank">01:37:13.000</a></span> | <span class="t">One is based on metadata, which is for example, this guy filled out a survey in which they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5839" target="_blank">01:37:19.800</a></span> | <span class="t">said they liked action movies and sci-fi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5843" target="_blank">01:37:23.200</a></span> | <span class="t">And we also have taken all of our movies and put them into genres, and here are all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5848" target="_blank">01:37:28.080</a></span> | <span class="t">our action sci-fi movies, so we'll use them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5851" target="_blank">01:37:31.880</a></span> | <span class="t">Broadly speaking, that would be a metadata-based approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5856" target="_blank">01:37:36.000</a></span> | <span class="t">A collaborative filtering-based approach is very different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5859" target="_blank">01:37:39.040</a></span> | <span class="t">It says, "Let's find other people like you and find out what they liked and assume that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5866" target="_blank">01:37:46.720</a></span> | <span class="t">you will like the same stuff."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5869" target="_blank">01:37:49.520</a></span> | <span class="t">And specifically when we say people like you, we mean people who rated the same movies you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5874" target="_blank">01:37:54.840</a></span> | <span class="t">watched in a similar way, and that's called collaborative filtering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5880" target="_blank">01:38:00.060</a></span> | <span class="t">It turns out that in a large enough dataset, collaborative filtering is so much better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5885" target="_blank">01:38:05.680</a></span> | <span class="t">than the metadata-based approaches that adding metadata doesn't even improve it at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5891" target="_blank">01:38:11.280</a></span> | <span class="t">So when people in the Netflix prize actually went out to IMDB and sucked in additional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5897" target="_blank">01:38:17.280</a></span> | <span class="t">data and tried to use that to make it better, at a certain point it didn't help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5903" target="_blank">01:38:23.860</a></span> | <span class="t">Once their collaborative filtering models were good enough, it didn't help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5906" target="_blank">01:38:26.440</a></span> | <span class="t">And that's because it's something I learned about 20 years ago when I used to do a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5909" target="_blank">01:38:29.960</a></span> | <span class="t">of surveys in consulting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5911" target="_blank">01:38:31.720</a></span> | <span class="t">It turns out that asking people about their behavior is crap compared to actually looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5916" target="_blank">01:38:36.680</a></span> | <span class="t">at people's behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5918" target="_blank">01:38:38.960</a></span> | <span class="t">So let me show you what collaborative filtering looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5922" target="_blank">01:38:42.040</a></span> | <span class="t">What we're going to do is use a dataset called MovieLens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5925" target="_blank">01:38:45.560</a></span> | <span class="t">So you guys hopefully will be able to play around with this this week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5930" target="_blank">01:38:50.440</a></span> | <span class="t">Unfortunately Rachel and I could not find any Kaggle competitions that were about recommender</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5936" target="_blank">01:38:56.280</a></span> | <span class="t">systems and where the competitions were still open for entries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5940" target="_blank">01:39:00.120</a></span> | <span class="t">However, there is something called MovieLens which is a widely studied dataset in academia.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5954" target="_blank">01:39:14.520</a></span> | <span class="t">Perhaps surprisingly, approaching or beating an academic state of the art is way easier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5960" target="_blank">01:39:20.960</a></span> | <span class="t">than winning a Kaggle competition, because in Kaggle competitions lots and lots and lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5965" target="_blank">01:39:25.120</a></span> | <span class="t">of people look at that data and they try lots and lots and lots of things and they use a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5968" target="_blank">01:39:28.840</a></span> | <span class="t">really pragmatic approach, whereas academics state of the arts are done by academics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5975" target="_blank">01:39:35.440</a></span> | <span class="t">So with that said, the MovieLens benchmarks are going to be much easier to beat than any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5982" target="_blank">01:39:42.060</a></span> | <span class="t">Kaggle competition, but it's still interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5986" target="_blank">01:39:46.520</a></span> | <span class="t">So you can download MovieLens dataset from the MovieLens dataset website, and you'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5992" target="_blank">01:39:52.120</a></span> | <span class="t">see that there's one here recommended for new research with 20 million items in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=5997" target="_blank">01:39:57.920</a></span> | <span class="t">Also conveniently, they have a small one with only 100,000 ratings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6001" target="_blank">01:40:01.480</a></span> | <span class="t">So you don't have to build a sample, they have already built a sample for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6005" target="_blank">01:40:05.240</a></span> | <span class="t">So I am of course going to use a sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6009" target="_blank">01:40:09.080</a></span> | <span class="t">So what I do is I read in ratings.csv.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6014" target="_blank">01:40:14.280</a></span> | <span class="t">And as you'll see here, I've started using pandas, pd is pd for pandas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6019" target="_blank">01:40:19.480</a></span> | <span class="t">How many people here have tried pandas?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6022" target="_blank">01:40:22.240</a></span> | <span class="t">Awesome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6023" target="_blank">01:40:23.520</a></span> | <span class="t">So those of you that don't, hopefully the peer group pressure is kicking in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6027" target="_blank">01:40:27.440</a></span> | <span class="t">So pandas is a great way of dealing with structured data and you should use it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6032" target="_blank">01:40:32.040</a></span> | <span class="t">Reading a CSV file is this easy, showing the first few items is this easy, finding out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6037" target="_blank">01:40:37.640</a></span> | <span class="t">how big it is, finding out how many users and movies there are, are all this easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6046" target="_blank">01:40:46.360</a></span> | <span class="t">I wanted to play with this in Excel, because that's the only way I know how to teach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6052" target="_blank">01:40:52.160</a></span> | <span class="t">What I did was I grabbed the user ID by rating and grabbed the top 15 most busiest movie-watching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6063" target="_blank">01:41:03.120</a></span> | <span class="t">users, and then I grabbed the 15 most watched movies, and then I created a cross-tab of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6071" target="_blank">01:41:11.600</a></span> | <span class="t">the two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6073" target="_blank">01:41:13.280</a></span> | <span class="t">And then I copied that into Excel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6076" target="_blank">01:41:16.320</a></span> | <span class="t">Here is the table I downloaded from MovieLens for the 15 busiest movie-watching users and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6087" target="_blank">01:41:27.400</a></span> | <span class="t">the 15 most widely watched movies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6090" target="_blank">01:41:30.560</a></span> | <span class="t">And here are the ratings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6091" target="_blank">01:41:31.560</a></span> | <span class="t">Here's the rating of user 14 for movie 27.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6095" target="_blank">01:41:35.440</a></span> | <span class="t">Look at these guys.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6096" target="_blank">01:41:36.440</a></span> | <span class="t">These three users have watched every single one of these movies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6100" target="_blank">01:41:40.240</a></span> | <span class="t">I'm probably one of them, I love movies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6105" target="_blank">01:41:45.640</a></span> | <span class="t">And these have been watched by every single one of these users.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6109" target="_blank">01:41:49.660</a></span> | <span class="t">So user 14 kind of liked movie 27, loved movie 49, hated movie 51.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6118" target="_blank">01:41:58.080</a></span> | <span class="t">So let's have a look, is there anybody else here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6125" target="_blank">01:42:05.200</a></span> | <span class="t">So this guy really liked movie 49, didn't much like movie 57, so they may feel the same way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6130" target="_blank">01:42:10.960</a></span> | <span class="t">about movie 27 as that user.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6133" target="_blank">01:42:13.800</a></span> | <span class="t">That's the basic essence of collaborative filtering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6135" target="_blank">01:42:15.680</a></span> | <span class="t">We're going to try and automate it a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6138" target="_blank">01:42:18.560</a></span> | <span class="t">And the way we're going to automate it is we're going to say let's pretend for each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6141" target="_blank">01:42:21.800</a></span> | <span class="t">movie we had like five characteristics, which is like is it sci-fi, is it action, is it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6149" target="_blank">01:42:29.480</a></span> | <span class="t">dialogue-heavy, is it new, and does it have Bruce Willis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6158" target="_blank">01:42:38.360</a></span> | <span class="t">And then we could have those five things for every user as well, which is this user somebody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6172" target="_blank">01:42:52.160</a></span> | <span class="t">who likes sci-fi, action, dialogue, new movies, and Bruce Willis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6176" target="_blank">01:42:56.960</a></span> | <span class="t">And so what we could then do is multiply those matrix product or dot product, that set of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6187" target="_blank">01:43:07.280</a></span> | <span class="t">user features with that set of movie features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6191" target="_blank">01:43:11.400</a></span> | <span class="t">If this person likes sci-fi and it's sci-fi and they like action and it is action and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6195" target="_blank">01:43:15.160</a></span> | <span class="t">so forth, then a high number will appear in here for this matrix product of these two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6200" target="_blank">01:43:20.680</a></span> | <span class="t">vectors, this dot product of these two vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6205" target="_blank">01:43:25.640</a></span> | <span class="t">And so this would be a cool way to build up a collaborative filtering system if only we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6213" target="_blank">01:43:33.040</a></span> | <span class="t">could create these five items for every movie and for every user.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6220" target="_blank">01:43:40.940</a></span> | <span class="t">Now because we don't actually know what five things are most important for users and what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6225" target="_blank">01:43:45.680</a></span> | <span class="t">five things are most important for movies, we're instead going to learn them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6230" target="_blank">01:43:50.560</a></span> | <span class="t">And the way we learn them is the way we learn everything, which is we start by randomizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6235" target="_blank">01:43:55.560</a></span> | <span class="t">them and then we use gradient descent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6239" target="_blank">01:43:59.380</a></span> | <span class="t">So here are five random numbers for every movie, and here are five random numbers for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6246" target="_blank">01:44:06.360</a></span> | <span class="t">every user, and in the middle is the dot product of that movie with that user.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6254" target="_blank">01:44:14.800</a></span> | <span class="t">Once we have a good set of movie factors and user factors for each one, then each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6262" target="_blank">01:44:22.120</a></span> | <span class="t">ratings will be similar to each of the observed ratings, and therefore this sum of squared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6268" target="_blank">01:44:28.820</a></span> | <span class="t">errors will be low.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6274" target="_blank">01:44:34.160</a></span> | <span class="t">Currently it is high.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6276" target="_blank">01:44:36.840</a></span> | <span class="t">So we start with our random numbers, we start with a loss function of 40.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6283" target="_blank">01:44:43.640</a></span> | <span class="t">So we now want to use gradient descent, and it turns out that every copy of Excel has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6289" target="_blank">01:44:49.400</a></span> | <span class="t">a gradient descent solver in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6291" target="_blank">01:44:51.680</a></span> | <span class="t">So we're going to go ahead and use it, it's called solver.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6295" target="_blank">01:44:55.380</a></span> | <span class="t">And so we have to tell it what thing to minimize, so it's saying minimize this, and which things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6301" target="_blank">01:45:01.720</a></span> | <span class="t">do we want to change, which is all of our factors, and then we set it to a minimum and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6307" target="_blank">01:45:07.400</a></span> | <span class="t">we say solve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6309" target="_blank">01:45:09.500</a></span> | <span class="t">And then we can see in the bottom left, it is trying to make this better and better and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6313" target="_blank">01:45:13.760</a></span> | <span class="t">better using gradient descent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6316" target="_blank">01:45:16.800</a></span> | <span class="t">Notice I'm not saying stochastic gradient descent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6320" target="_blank">01:45:20.300</a></span> | <span class="t">Stochastic gradient descent means it's doing it mini-batch at a mini-batch time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6324" target="_blank">01:45:24.620</a></span> | <span class="t">Gradient descent means it's doing the whole data set each time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6328" target="_blank">01:45:28.040</a></span> | <span class="t">Excel uses gradient descent, not stochastic gradient descent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6331" target="_blank">01:45:31.480</a></span> | <span class="t">They give the same answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6334" target="_blank">01:45:34.420</a></span> | <span class="t">You might also wonder why is it so slow?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6337" target="_blank">01:45:37.000</a></span> | <span class="t">It's so slow because it doesn't know how to create analytical derivatives, so it's having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6341" target="_blank">01:45:41.080</a></span> | <span class="t">to calculate the derivatives with finite difference, which is slow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6345" target="_blank">01:45:45.400</a></span> | <span class="t">So here we've got a solution, it's got it down to 5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6350" target="_blank">01:45:50.600</a></span> | <span class="t">That's pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6351" target="_blank">01:45:51.600</a></span> | <span class="t">So we can see here that it predicted 5.14 and it was actually 5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6358" target="_blank">01:45:58.440</a></span> | <span class="t">It predicted 3.05 and it was actually 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6361" target="_blank">01:46:01.600</a></span> | <span class="t">So it's done a really, really good job.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6365" target="_blank">01:46:05.980</a></span> | <span class="t">It's a little bit too easy because there are 5 times that many user factors and 5 times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6376" target="_blank">01:46:16.040</a></span> | <span class="t">that many user factors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6377" target="_blank">01:46:17.520</a></span> | <span class="t">We've got nearly as many factors as we have things to calculate, so it's kind of over-specified.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6383" target="_blank">01:46:23.600</a></span> | <span class="t">But the idea is there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6386" target="_blank">01:46:26.520</a></span> | <span class="t">There's one piece missing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6388" target="_blank">01:46:28.280</a></span> | <span class="t">The piece we're missing is that some users probably just like movies more than others,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6395" target="_blank">01:46:35.460</a></span> | <span class="t">and some movies are probably just more like than others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6399" target="_blank">01:46:39.440</a></span> | <span class="t">And this dot product does not allow us in any way to say this is an enthusiastic user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6406" target="_blank">01:46:46.440</a></span> | <span class="t">or this is a popular movie.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6408" target="_blank">01:46:48.920</a></span> | <span class="t">To do that, we have to add bias terms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6412" target="_blank">01:46:52.560</a></span> | <span class="t">So here is exactly the same spreadsheet, but I've added one more row to the movies part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6422" target="_blank">01:47:02.280</a></span> | <span class="t">and one more column to the users part for our biases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6427" target="_blank">01:47:07.280</a></span> | <span class="t">And I've updated the formula so that as well as the matrix multiplication, it also is adding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6435" target="_blank">01:47:15.020</a></span> | <span class="t">the user bias and the movie bias.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6438" target="_blank">01:47:18.080</a></span> | <span class="t">So this is saying this is a very popular movie, and here we are, this is a very enthusiastic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6448" target="_blank">01:47:28.640</a></span> | <span class="t">user for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6450" target="_blank">01:47:30.760</a></span> | <span class="t">And so now that we have a collaborative filtering plus bias, we can do gradient descent on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6459" target="_blank">01:47:39.120</a></span> | <span class="t">So previously our gradient descent loss function was 5.6.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6465" target="_blank">01:47:45.540</a></span> | <span class="t">We would expect it to be better with bias because we can really better specify what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6469" target="_blank">01:47:49.080</a></span> | <span class="t">going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6470" target="_blank">01:47:50.080</a></span> | <span class="t">Let's try it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6472" target="_blank">01:47:52.120</a></span> | <span class="t">So again we run solver, solve, and we let that zip along, and we see what happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6479" target="_blank">01:47:59.760</a></span> | <span class="t">So these things we're calculating are called latent factors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6486" target="_blank">01:48:06.440</a></span> | <span class="t">A latent factor is some factor that is influencing outcome, but we don't quite know what it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6493" target="_blank">01:48:13.400</a></span> | <span class="t">We're just assuming it's there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6495" target="_blank">01:48:15.680</a></span> | <span class="t">And in fact what happens is when people do collaborative filtering, they then go back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6499" target="_blank">01:48:19.400</a></span> | <span class="t">and they draw graphs where they say here are the movies that are scored highly on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6504" target="_blank">01:48:24.860</a></span> | <span class="t">latent factor and low on this latent factor, and so they'll discover the Bruce Willis factor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6511" target="_blank">01:48:31.680</a></span> | <span class="t">and the sci-fi factor and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6514" target="_blank">01:48:34.400</a></span> | <span class="t">And so if you look at the Netflix prize visualizations, you'll see these graphs people do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6519" target="_blank">01:48:39.980</a></span> | <span class="t">And the way they do them is they literally do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6522" target="_blank">01:48:42.440</a></span> | <span class="t">Not in Excel, because they're not that cool, but they calculate these latent factors and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6528" target="_blank">01:48:48.480</a></span> | <span class="t">then they draw pictures of them and then they actually write the name of the movie on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6532" target="_blank">01:48:52.760</a></span> | <span class="t">graph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6533" target="_blank">01:48:53.760</a></span> | <span class="t">So 4.6, even better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6538" target="_blank">01:48:58.960</a></span> | <span class="t">So you can see that, oh that's interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6545" target="_blank">01:49:05.400</a></span> | <span class="t">In fact I also have an error here, because any time that my writing is empty, I really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6553" target="_blank">01:49:13.800</a></span> | <span class="t">want to be setting this to empty as well, which means my parenthesis was in the wrong</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6558" target="_blank">01:49:18.720</a></span> | <span class="t">place.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6561" target="_blank">01:49:21.280</a></span> | <span class="t">So I'm going to recalculate this with my error fixed up and see if we get a better answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6570" target="_blank">01:49:30.480</a></span> | <span class="t">They're randomly generated and then optimized with gradient descent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6599" target="_blank">01:49:59.480</a></span> | <span class="t">For some reason, this seems crazier than what we were doing at CNN's, because movies I understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6611" target="_blank">01:50:11.200</a></span> | <span class="t">more than features of images that I just don't intuitively understand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6617" target="_blank">01:50:17.080</a></span> | <span class="t">So we can look at some pictures next week, but during the week, Google for Netflix prize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6625" target="_blank">01:50:25.040</a></span> | <span class="t">visualizations and you will see these pictures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6629" target="_blank">01:50:29.960</a></span> | <span class="t">It really does work the way I described.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6632" target="_blank">01:50:32.840</a></span> | <span class="t">It figures out what are the most interesting dimensions on which we can rate a movie.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6641" target="_blank">01:50:41.000</a></span> | <span class="t">Things like level of action and sci-fi and dialogue driven are very important features,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6646" target="_blank">01:50:46.760</a></span> | <span class="t">it turns out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6649" target="_blank">01:50:49.960</a></span> | <span class="t">But rather than pre-specifying those features, we have definitely learned from this class</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6656" target="_blank">01:50:56.160</a></span> | <span class="t">that calculating features using gradient descent is going to give us better features than trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6661" target="_blank">01:51:01.240</a></span> | <span class="t">to engineer them by hand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6668" target="_blank">01:51:08.600</a></span> | <span class="t">Interesting that it feels crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6671" target="_blank">01:51:11.040</a></span> | <span class="t">Tell me next week if you find some particularly interesting things, or if it still seems crazy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6675" target="_blank">01:51:15.680</a></span> | <span class="t">and we can try to decresify it a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6680" target="_blank">01:51:20.360</a></span> | <span class="t">So let's do this in Keras.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6684" target="_blank">01:51:24.760</a></span> | <span class="t">Now there's really only one main new concept we have to learn, which is we started out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6691" target="_blank">01:51:31.000</a></span> | <span class="t">with data not in a crosstab form, but in this form.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6696" target="_blank">01:51:36.440</a></span> | <span class="t">We have user ID, movie ID, rating triplets, and I crosstab them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6707" target="_blank">01:51:47.920</a></span> | <span class="t">So the rows and the columns above the random numbers, are they the variations and the features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6715" target="_blank">01:51:55.700</a></span> | <span class="t">in the movies and the variations and features in the users?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6719" target="_blank">01:51:59.520</a></span> | <span class="t">Each of these rows is one feature of a movie, and each of these columns is one feature of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6725" target="_blank">01:52:05.200</a></span> | <span class="t">a user.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6726" target="_blank">01:52:06.360</a></span> | <span class="t">And so one of these sets of 5 is one set of features for a user.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6731" target="_blank">01:52:11.680</a></span> | <span class="t">This is this user's latent factors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6734" target="_blank">01:52:14.240</a></span> | <span class="t">I think it's interesting and crazy because you're basically taking random data and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6739" target="_blank">01:52:19.520</a></span> | <span class="t">can generate those features out of people that you don't know in movies that you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6744" target="_blank">01:52:24.720</a></span> | <span class="t">not looking at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6746" target="_blank">01:52:26.360</a></span> | <span class="t">Yeah, this is the thing I just did at the start of class, which is there's nothing mathematically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6753" target="_blank">01:52:33.400</a></span> | <span class="t">complicated about gradient descent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6758" target="_blank">01:52:38.500</a></span> | <span class="t">The hard part is unlearning the idea that this should be hard, you know, gradient descent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6766" target="_blank">01:52:46.000</a></span> | <span class="t">just figures it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6768" target="_blank">01:52:48.280</a></span> | <span class="t">Did you have a question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6769" target="_blank">01:52:49.280</a></span> | <span class="t">I have one question behind you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6770" target="_blank">01:52:50.840</a></span> | <span class="t">I just wanted to point out that this you can think of as a smaller, more concise way to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6779" target="_blank">01:52:59.800</a></span> | <span class="t">represent the movies and the users.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6783" target="_blank">01:53:03.740</a></span> | <span class="t">In math, there's a concept of a matrix factorization, an SVD for example, which is where you basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6790" target="_blank">01:53:10.360</a></span> | <span class="t">take a big matrix and turn it into a small narrow one and a small thin one and multiply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6795" target="_blank">01:53:15.520</a></span> | <span class="t">the two together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6796" target="_blank">01:53:16.520</a></span> | <span class="t">This is exactly what we're doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6797" target="_blank">01:53:17.920</a></span> | <span class="t">Instead of having how user 14 rated every single movie, we just have 5 numbers that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6803" target="_blank">01:53:23.240</a></span> | <span class="t">represent it, which is pretty cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6808" target="_blank">01:53:28.760</a></span> | <span class="t">So earlier, did you say that both the user features were random as well as the?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6815" target="_blank">01:53:35.200</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6816" target="_blank">01:53:36.200</a></span> | <span class="t">I guess I'm in trouble relating to, I thought, you know, usually we run something like gradient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6824" target="_blank">01:53:44.760</a></span> | <span class="t">descent on, something has like inputs that you know and here, what are the, what do you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6832" target="_blank">01:53:52.360</a></span> | <span class="t">know?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6833" target="_blank">01:53:53.360</a></span> | <span class="t">What we know, that's what we know, the resulting ratings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6837" target="_blank">01:53:57.160</a></span> | <span class="t">So can you perhaps come up with the wrong, like you flip the feature for a movie and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6846" target="_blank">01:54:06.800</a></span> | <span class="t">a user because if you're doing a multiplication, how do you know which value goes which?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6856" target="_blank">01:54:16.240</a></span> | <span class="t">If one of the numbers was in the wrong spot, our loss function would be less good and therefore</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6863" target="_blank">01:54:23.480</a></span> | <span class="t">there would be a gradient from that weight to say you should make this weight a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6869" target="_blank">01:54:29.000</a></span> | <span class="t">higher or a little lower.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6871" target="_blank">01:54:31.680</a></span> | <span class="t">So all the gradient descent is doing is saying okay, for every weight, if we make it a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6876" target="_blank">01:54:36.160</a></span> | <span class="t">higher, does it get better or if we make it a little bit lower, does it get better?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6879" target="_blank">01:54:39.760</a></span> | <span class="t">And then we keep making them a little bit higher and lower until we can't go any better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6887" target="_blank">01:54:47.520</a></span> | <span class="t">And we had to decide how to combine the weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6890" target="_blank">01:54:50.720</a></span> | <span class="t">So this was our architecture, our architecture was let's take a dot product of some assumed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6898" target="_blank">01:54:58.200</a></span> | <span class="t">user feature and some assumed movie feature and let's add in the second case some assumed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6904" target="_blank">01:55:04.400</a></span> | <span class="t">bias term.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6906" target="_blank">01:55:06.320</a></span> | <span class="t">So we had to build an architecture and we built the architecture using common sense,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6911" target="_blank">01:55:11.000</a></span> | <span class="t">which is to say this seems like a reasonable way of thinking about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6913" target="_blank">01:55:13.600</a></span> | <span class="t">I'm going to show you a better architecture in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6915" target="_blank">01:55:15.920</a></span> | <span class="t">In fact, we're running out of time, so let me jump into the better architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6921" target="_blank">01:55:21.600</a></span> | <span class="t">So I wanted to point out that there is something new we're going to have to learn here, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6925" target="_blank">01:55:25.560</a></span> | <span class="t">is how do you start with a numeric user_id and look up to find what is their 5-element</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6933" target="_blank">01:55:33.040</a></span> | <span class="t">latent factor matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6935" target="_blank">01:55:35.960</a></span> | <span class="t">Now remember, when we have user_id's like 1, 2 and 3, one way to specify them is using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6943" target="_blank">01:55:43.240</a></span> | <span class="t">one hot encoding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6952" target="_blank">01:55:52.600</a></span> | <span class="t">So one way to handle this situation would be if this was our user matrix, it was one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6961" target="_blank">01:56:01.720</a></span> | <span class="t">hot encoded, and then we had a factor matrix containing a whole bunch of random numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6972" target="_blank">01:56:12.360</a></span> | <span class="t">-- one way to do it would be to take a dot product or a matrix product of this and this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6989" target="_blank">01:56:29.200</a></span> | <span class="t">And what that would do would be for this one here, it would basically say let's multiply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=6994" target="_blank">01:56:34.480</a></span> | <span class="t">that by this, it would grab the first column of the matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7002" target="_blank">01:56:42.360</a></span> | <span class="t">And this here would grab the second column of the matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7006" target="_blank">01:56:46.040</a></span> | <span class="t">And this here would grab the third column of the matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7009" target="_blank">01:56:49.080</a></span> | <span class="t">So one way to do this in Keras would be to represent our user_id's as one hot encodings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7016" target="_blank">01:56:56.720</a></span> | <span class="t">and to create a user factor matrix just as a regular matrix like this and then take a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7024" target="_blank">01:57:04.680</a></span> | <span class="t">matrix product.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7027" target="_blank">01:57:07.800</a></span> | <span class="t">That's horribly slow because if we have 10,000 users, then this thing is 10,000 wide and that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7036" target="_blank">01:57:16.040</a></span> | <span class="t">a really big matrix multiplication when all we're actually doing is saying for user_id</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7040" target="_blank">01:57:20.280</a></span> | <span class="t">number 1, take the first column.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7042" target="_blank">01:57:22.520</a></span> | <span class="t">For user_id number 2, take the second column, for user_id number 3, take the third column.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7047" target="_blank">01:57:27.120</a></span> | <span class="t">And so Keras has something which does this for us and it's called an embedding layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7052" target="_blank">01:57:32.280</a></span> | <span class="t">And embedding is literally something which takes an integer as an input and looks up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7056" target="_blank">01:57:36.600</a></span> | <span class="t">and grabs the corresponding column as output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7059" target="_blank">01:57:39.920</a></span> | <span class="t">So it's doing exactly what we're seeing in this spreadsheet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7063" target="_blank">01:57:43.160</a></span> | <span class="t">Question 2 - How do you deal with missing values, so if a user has not rated a particular movie?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7072" target="_blank">01:57:52.400</a></span> | <span class="t">That's no problem, so missing values are just ignored, so if it's missing, I just set the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7076" target="_blank">01:57:56.520</a></span> | <span class="t">loss to 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7077" target="_blank">01:57:57.520</a></span> | <span class="t">Question 3 - How do you break up the training and test set?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7082" target="_blank">01:58:02.000</a></span> | <span class="t">I broke up the training and test set randomly by grabbing random numbers and saying are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7089" target="_blank">01:58:09.280</a></span> | <span class="t">they greater or less than 0.8 and then split my ratings into two groups based on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7094" target="_blank">01:58:14.160</a></span> | <span class="t">Question 4 - And you're choosing those from the ratings so that you have some ratings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7098" target="_blank">01:58:18.640</a></span> | <span class="t">from all users and you have some ratings for all movies?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7101" target="_blank">01:58:21.400</a></span> | <span class="t">I just grabbed them at random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7105" target="_blank">01:58:25.960</a></span> | <span class="t">So here it is, here's our dot product.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7110" target="_blank">01:58:30.480</a></span> | <span class="t">In Keras, there's one other thing, I'm going to stop using the sequential model in Keras</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7118" target="_blank">01:58:38.200</a></span> | <span class="t">and start using the functional model in Keras.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7120" target="_blank">01:58:40.760</a></span> | <span class="t">I'll talk more about this next week, but you can read about it learning the week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7124" target="_blank">01:58:44.080</a></span> | <span class="t">There are two ways of creating models in Keras, the sequential and the functional.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7128" target="_blank">01:58:48.320</a></span> | <span class="t">They do similar things, but the functional is much more flexible and it's going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7133" target="_blank">01:58:53.000</a></span> | <span class="t">what we're going to need to use now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7134" target="_blank">01:58:54.880</a></span> | <span class="t">So this is going to look slightly unfamiliar, but the ideas are the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7139" target="_blank">01:58:59.460</a></span> | <span class="t">So we create an input layer for a user, and then we say now create an embedding layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7147" target="_blank">01:59:07.480</a></span> | <span class="t">for n users, which is 671, and we want to create how many latent factors?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7154" target="_blank">01:59:14.480</a></span> | <span class="t">I decided not to create 5, but to create 50.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7159" target="_blank">01:59:19.360</a></span> | <span class="t">And then I create a movie input, and then I create a movie embedding with 50 factors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7166" target="_blank">01:59:26.840</a></span> | <span class="t">and then I say take the dot product of those, and that's our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7174" target="_blank">01:59:34.540</a></span> | <span class="t">So now please compile the model, and now train it, taking the userID and movieID as input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7182" target="_blank">01:59:42.120</a></span> | <span class="t">the rating as the target, and run it for 6 epochs, and I get a 1.27 loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7189" target="_blank">01:59:49.600</a></span> | <span class="t">This is with an RMSE loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7193" target="_blank">01:59:53.720</a></span> | <span class="t">Notice that I'm not doing anything else clever, it's just that simple dot product.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7196" target="_blank">01:59:56.840</a></span> | <span class="t">That gets me to 1.27.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7199" target="_blank">01:59:59.840</a></span> | <span class="t">Here's how I add the bias, I use exactly the same kind of embedding inputs as before, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7204" target="_blank">02:00:04.960</a></span> | <span class="t">I've encapsulated them in a function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7207" target="_blank">02:00:07.760</a></span> | <span class="t">So my user and movie embeddings are the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7211" target="_blank">02:00:11.120</a></span> | <span class="t">And then I create bias by simply creating an embedding with just a single output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7218" target="_blank">02:00:18.400</a></span> | <span class="t">And so then my new model is do a dot product, and then add the user bias, and add the movie</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7226" target="_blank">02:00:26.720</a></span> | <span class="t">bias, and try fitting that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7230" target="_blank">02:00:30.640</a></span> | <span class="t">And it takes me to a validation loss of 1.1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7234" target="_blank">02:00:34.200</a></span> | <span class="t">How is that going?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7235" target="_blank">02:00:35.200</a></span> | <span class="t">Well, there are lots of sites on the internet where you can find out benchmarks for movie</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7241" target="_blank">02:00:41.080</a></span> | <span class="t">lens, and on the 100,000 dataset, we're generally looking for RMSE of about 0.89.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7247" target="_blank">02:00:47.120</a></span> | <span class="t">There's some more, the best one here is 0.9, here we are, 0.89, and this one, RMSE, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7260" target="_blank">02:01:00.560</a></span> | <span class="t">on the 1,000,000 dataset, let's go to the 100,000, 100,000, RMSE, 1.9, 0.89.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7270" target="_blank">02:01:10.360</a></span> | <span class="t">So kind of high 0.89s, low 0.9s would be state-of-the-art according to these benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7276" target="_blank">02:01:16.600</a></span> | <span class="t">So, we're on the right track, but we're not there yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7281" target="_blank">02:01:21.000</a></span> | <span class="t">So let's try something better, let's create a neural net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7283" target="_blank">02:01:23.760</a></span> | <span class="t">And a neural net does the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7285" target="_blank">02:01:25.960</a></span> | <span class="t">We create a movie embedding and a user embedding, again with 50 factors, and this time we don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7291" target="_blank">02:01:31.600</a></span> | <span class="t">take a dot product, we just concatenate the two vectors together, stick one on the end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7295" target="_blank">02:01:35.680</a></span> | <span class="t">or the other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7297" target="_blank">02:01:37.820</a></span> | <span class="t">And because we now have one big vector, we can create a neural net, create a dense layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7303" target="_blank">02:01:43.480</a></span> | <span class="t">add dropout, create an activation, compile it, and fit it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7311" target="_blank">02:01:51.120</a></span> | <span class="t">And after 5 epochs, we get something way better than state-of-the-art.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7317" target="_blank">02:01:57.280</a></span> | <span class="t">So we couldn't find anything better than about 0.89.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7320" target="_blank">02:02:00.680</a></span> | <span class="t">And so this whole notebook took me like half an hour to write, and so I don't claim to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7326" target="_blank">02:02:06.080</a></span> | <span class="t">be a collaborative filtering expert, but I think it's pretty cool that these things that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7330" target="_blank">02:02:10.360</a></span> | <span class="t">were written by people that write collaborative filtering software for a living, that's what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7335" target="_blank">02:02:15.680</a></span> | <span class="t">these websites basically are coming from, places that use LensKit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7341" target="_blank">02:02:21.100</a></span> | <span class="t">So LensKit is a piece of software for recommender systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7346" target="_blank">02:02:26.000</a></span> | <span class="t">We have just killed their benchmark, and it took us 10 seconds to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7352" target="_blank">02:02:32.400</a></span> | <span class="t">So I think that's pretty neat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7353" target="_blank">02:02:33.720</a></span> | <span class="t">And we're right on time, so we're going to take one last question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7356" target="_blank">02:02:36.480</a></span> | <span class="t">So in the neural net, why is it that there are a number of factors so low?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7366" target="_blank">02:02:46.960</a></span> | <span class="t">Oh, actually I thought it was an equal, not a comma, never mind, we're good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7370" target="_blank">02:02:50.760</a></span> | <span class="t">Alright, so now you can go home.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7373" target="_blank">02:02:53.240</a></span> | <span class="t">So that was a very, very quick introduction to embeddings, like as per usual in this class,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7379" target="_blank">02:02:59.200</a></span> | <span class="t">I kind of stick the new stuff in at the end and say go study it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7384" target="_blank">02:03:04.160</a></span> | <span class="t">So your job this week is to keep improving state farm, hopefully win the new fisheries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7389" target="_blank">02:03:09.960</a></span> | <span class="t">competition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7390" target="_blank">02:03:10.960</a></span> | <span class="t">By the way, in the last half hour, I just created this little notebook in which I basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7395" target="_blank">02:03:15.880</a></span> | <span class="t">copied the Dogs and Cats Redux competition into something which does the same thing with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7402" target="_blank">02:03:22.960</a></span> | <span class="t">the fish data, and I quickly submitted a result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7407" target="_blank">02:03:27.880</a></span> | <span class="t">So we currently have one of us in 18th place, yay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7411" target="_blank">02:03:31.960</a></span> | <span class="t">So hopefully you can beat that tomorrow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7414" target="_blank">02:03:34.760</a></span> | <span class="t">But most importantly, download the movie lens data and have a play with that and we'll talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7419" target="_blank">02:03:39.440</a></span> | <span class="t">more about embeddings next week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7420" target="_blank">02:03:40.840</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7421" target="_blank">02:03:41.840</a></span> | <span class="t">[Applause]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7421" target="_blank">02:03:41.840</a></span> | <span class="t">(audience applauds)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V2h3IOBDvrA&t=7424" target="_blank">02:03:44.840</a></span> | <span class="t">(audience applauds)</span></div></div></body></html>