<html><head><title>AGI Will Not Be A Chatbot - Autonomy, Acceleration, and Arguments Behind the Scenes</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>AGI Will Not Be A Chatbot - Autonomy, Acceleration, and Arguments Behind the Scenes</h2><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4"><img src="https://i.ytimg.com/vi/2bn3S4vOVN4/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./2bn3S4vOVN4.html">Whisper Transcript</a> | <a href="./transcript_2bn3S4vOVN4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">In the last 48 hours there have been a flurry of articles and interviews revealing key details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=6" target="_blank">00:00:06.740</a></span> | <span class="t">about our march to artificial general intelligence. I'm going to extract out the most interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=12" target="_blank">00:00:12.320</a></span> | <span class="t">parts and link them to a series of other recent developments. And if there's one theme it's that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=18" target="_blank">00:00:18.040</a></span> | <span class="t">the AGI these companies are creating is not just a clever chatbot and is coming much sooner than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=24" target="_blank">00:00:24.420</a></span> | <span class="t">you might think. If AGI is a lot more than just a clever personal assistant what actually is it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=29" target="_blank">00:00:29.600</a></span> | <span class="t">Well let's turn to this bombshell article in Wired. They say OpenAI doesn't claim to know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=35" target="_blank">00:00:35.260</a></span> | <span class="t">what AGI really is. The determination would come from the board but it's not clear how the board</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=40" target="_blank">00:00:40.320</a></span> | <span class="t">would define it. Sam Altman who is on the board of OpenAI said I would happily tell you but I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=45" target="_blank">00:00:45.120</a></span> | <span class="t">like to keep confidential conversations private. And then said but we don't know what it's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=49" target="_blank">00:00:49.900</a></span> | <span class="t">to be like at that point. Not being able to define AGI continues on their website where they first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=55" target="_blank">00:00:55.740</a></span> | <span class="t">say that AGI is AI systems that are generally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=59" target="_blank">00:00:59.200</a></span> | <span class="t">smarter than humans. Elsewhere they say their definition of AGI is highly autonomous systems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=65" target="_blank">00:01:05.140</a></span> | <span class="t">that outperform humans at most economically valuable work. And back to the just released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=70" target="_blank">00:01:10.660</a></span> | <span class="t">article it seems that confusion continues with Microsoft. It says Microsoft wasn't even bothered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=76" target="_blank">00:01:16.240</a></span> | <span class="t">by the clause that demands reconsideration if OpenAI achieves AGI. Whatever that is. At that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=83" target="_blank">00:01:23.380</a></span> | <span class="t">point says Nadella the CEO of Microsoft all bets are off. It might be the last invention of humanity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=88" target="_blank">00:01:28.800</a></span> | <span class="t">he notes. So we might have bigger issues to consider once machines are smarter than we are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=94" target="_blank">00:01:34.320</a></span> | <span class="t">OpenAI even have a legal disclaimer that says you as an investor stand to lose all of your money. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=100" target="_blank">00:01:40.240</a></span> | <span class="t">are not here to make your return. We're here to achieve a technical mission. Oh and by the way we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=106" target="_blank">00:01:46.080</a></span> | <span class="t">don't really know what role money will play in a post AGI world. In their restructuring documents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=111" target="_blank">00:01:51.760</a></span> | <span class="t">they have a clause to the effect that if the company does manage to create AGI all financial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=116" target="_blank">00:01:56.640</a></span> | <span class="t">arrangements will be reconsidered. So if you're not sure what role money will play in a post AGI world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=118" target="_blank">00:01:58.400</a></span> | <span class="t">then you can go back to the article and see what the clause says. But not clearly defining AGI seems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=121" target="_blank">00:02:01.200</a></span> | <span class="t">to play into the hands of Microsoft who can always say well we haven't reached it yet. I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=125" target="_blank">00:02:05.680</a></span> | <span class="t">don't think Microsoft is going to lightly allow all of their trillion dollar financial arrangements to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=131" target="_blank">00:02:11.040</a></span> | <span class="t">be reconsidered. And again we have this the company's financial documents stipulate a kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=136" target="_blank">00:02:16.000</a></span> | <span class="t">of exit contingency for when AI wipes away our whole economic system. But then apparently the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=141" target="_blank">00:02:21.840</a></span> | <span class="t">company's leadership says this it would be hard they say to work at OpenAI if the individual didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=148" target="_blank">00:02:28.000</a></span> | <span class="t">believe that AGI was truly coming and furthermore that its arrival would mark one of the greatest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=153" target="_blank">00:02:33.920</a></span> | <span class="t">moments in human history. Why would a non-believer want to work here they wondered. Three more quick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=160" target="_blank">00:02:40.080</a></span> | <span class="t">insights from Wired before we move on. First that Sam Altman was planning to run for governor of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=165" target="_blank">00:02:45.920</a></span> | <span class="t">California before he planned to build AGI. Second that in a 2015 interview with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=172" target="_blank">00:02:52.720</a></span> | <span class="t">same journalist at Wired Sam Altman was a bit more clear about what he thought the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=177" target="_blank">00:02:57.600</a></span> | <span class="t">job impacts of AGI would be. He predicted the challenge of massive automation and job elimination</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=184" target="_blank">00:03:04.320</a></span> | <span class="t">that's going to happen. This chimes in with a quote from the new book The Coming Wave that I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=189" target="_blank">00:03:09.120</a></span> | <span class="t">got early access to written by Mustafa Suleiman the head of another AGI lab. He said these tools</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=195" target="_blank">00:03:15.440</a></span> | <span class="t">are only temporarily augmenting human intelligence but they are fundamentally labor replacing. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=202" target="_blank">00:03:22.240</a></span> | <span class="t">finally from Wired was this quote that I found really interesting. Sam Altman's original vision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=207" target="_blank">00:03:27.200</a></span> | <span class="t">was not to make a single entity that is a million times more powerful than any human. He wanted lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=213" target="_blank">00:03:33.920</a></span> | <span class="t">of little AIs not one super intelligent AI. But Sam Altman is now talking about making a super</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=220" target="_blank">00:03:40.320</a></span> | <span class="t">intelligence within the next 10 years that's as productive as one of today's largest corporations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=226" target="_blank">00:03:46.480</a></span> | <span class="t">Which don't forget have millions of human employees. This fits in with his view that AGI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=232" target="_blank">00:03:52.560</a></span> | <span class="t">is only going to get built exactly once. Once you've got it you could then use it to build a new entity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=236" target="_blank">00:03:56.800</a></span> | <span class="t">And if you think the timeline of within the next 10 years sounds wild wait till you hear some of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=244" target="_blank">00:04:04.880</a></span> | <span class="t">quotes towards the end of the video. And the key thing to remember is that it's not about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=249" target="_blank">00:04:09.360</a></span> | <span class="t">models just getting more smart. It's about them being more capable. More able to match</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=254" target="_blank">00:04:14.320</a></span> | <span class="t">a goal with a set of actions. As the chief scientist at OpenAI Ilya Sutskova said the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=259" target="_blank">00:04:19.920</a></span> | <span class="t">upshot is "Eventually AI systems will become very very very capable and powerful. We will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=266" target="_blank">00:04:26.400</a></span> | <span class="t">not be able to understand them, they'll be much smarter than us." Notice the words capable and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=271" target="_blank">00:04:31.600</a></span> | <span class="t">powerful there. And his vision by the way is that we imprint on them like a parent to a child so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=277" target="_blank">00:04:37.520</a></span> | <span class="t">they eventually feel towards us the way we feel towards our babies. Now I don't know about you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=282" target="_blank">00:04:42.320</a></span> | <span class="t">but it's challenging for me to imagine the human race as a baby in the arms of an AGI or super</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=288" target="_blank">00:04:48.960</a></span> | <span class="t">intelligence. But some of you may be thinking is a super intelligence just a really smart chatbot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=294" target="_blank">00:04:54.000</a></span> | <span class="t">that sits on a web page somewhere? Well, not really. It's just a super intelligent AI that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=296" target="_blank">00:04:56.000</a></span> | <span class="t">able to do anything. And it's not just a simple AI. It's a super intelligent AI that's able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=296" target="_blank">00:04:56.960</a></span> | <span class="t">do anything. And it's not just a super intelligent AI that's able to do anything. Well, no. For many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=299" target="_blank">00:04:59.120</a></span> | <span class="t">reasons. Starting with the fact that we're building autonomy into them. I've already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=303" target="_blank">00:05:03.200</a></span> | <span class="t">discussed on the channel how OpenAI are working on autonomy. And here's Google DeepMind recruiting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=309" target="_blank">00:05:09.120</a></span> | <span class="t">for the same purpose. And what kind of tasks are we talking about? What about commissioning from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=313" target="_blank">00:05:13.920</a></span> | <span class="t">a factory? The purpose of the modern Turing test is to measure what an AI can do, not what it can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=319" target="_blank">00:05:19.920</a></span> | <span class="t">say. Capabilities, practical creation of real things in the real world, or the use of digital</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=325" target="_blank">00:05:25.600</a></span> | <span class="t">tools. Invent a new product from scratch to get that manufactured by commissioning it in a factory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=332" target="_blank">00:05:32.480</a></span> | <span class="t">negotiate over the blueprints of the product, actually get it drop shipped and sell the new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=337" target="_blank">00:05:37.840</a></span> | <span class="t">product. His company, Inflection AI, want their PI, personal intelligence, to be your digital</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=343" target="_blank">00:05:43.680</a></span> | <span class="t">chief of staff, booking flights, bargaining with other AIs and maybe even making a million dollars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=349" target="_blank">00:05:49.840</a></span> | <span class="t">This is particularly interesting to me because Suleiman says that they are not working on autonomy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=355" target="_blank">00:05:55.200</a></span> | <span class="t">I do. I think that we may be working on those capabilities, but they won't necessarily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=359" target="_blank">00:05:59.440</a></span> | <span class="t">represent an existential threat. I think what I'm saying is they indicate the beginning of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=364" target="_blank">00:06:04.480</a></span> | <span class="t">a trajectory towards a greater threat, right? At Inflection, we're actually not working on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=370" target="_blank">00:06:10.000</a></span> | <span class="t">either of those capabilities, recursive self-improvement and autonomy. And I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=374" target="_blank">00:06:14.960</a></span> | <span class="t">chosen a product direction, which I think can enable us to be extremely successful without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=379" target="_blank">00:06:19.760</a></span> | <span class="t">needing to work on that. I mean, we're not an AGI company. We're not trying to build a super</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=384" target="_blank">00:06:24.240</a></span> | <span class="t">intelligence. But it's a very, very important thing. And I think that's what we're trying to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=384" target="_blank">00:06:24.800</a></span> | <span class="t">But aside from autonomy, what else might AGI or super intelligence entail? Well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=390" target="_blank">00:06:30.320</a></span> | <span class="t">how about matching or exceeding the problem solving ability of the best human mathematicians</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=395" target="_blank">00:06:35.920</a></span> | <span class="t">within a decade? Wait, scrap that. 2026. Terence Tao, who I believe is recorded as the highest IQ</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=402" target="_blank">00:06:42.960</a></span> | <span class="t">human around, said this: "When integrated with tools, I expect, say, a 2026 level AI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=409" target="_blank">00:06:49.760</a></span> | <span class="t">when used properly, will be a trustworthy co-author in mathematical research. And,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=414" target="_blank">00:06:54.400</a></span> | <span class="t">in many other fields as well." What else? Well, how about self-improving capabilities?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=419" target="_blank">00:06:59.920</a></span> | <span class="t">This is from the AI power paradox in Foreign Affairs. "Soon, AI developers will likely succeed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=426" target="_blank">00:07:06.480</a></span> | <span class="t">in creating systems with self-improving capabilities, a critical juncture in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=430" target="_blank">00:07:10.960</a></span> | <span class="t">trajectory of this technology that should give everyone pause." OpenAI agrees, saying it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=436" target="_blank">00:07:16.160</a></span> | <span class="t">possible that AGI capable enough to accelerate its own progress could cause major changes to happen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=442" target="_blank">00:07:22.800</a></span> | <span class="t">surprisingly quickly. And, in fact, this is a very important point. OpenAI agrees, saying it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=444" target="_blank">00:07:24.000</a></span> | <span class="t">possible that AGI could be a key part of the future of AI. And back to Suleiman in Foreign</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=446" target="_blank">00:07:26.160</a></span> | <span class="t">Affairs. With each new order of magnitude, unexpected capabilities emerge. Few predicted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=451" target="_blank">00:07:31.520</a></span> | <span class="t">that training on raw text would enable large language models to produce coherent novel and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=456" target="_blank">00:07:36.080</a></span> | <span class="t">even creative sentences. Fewer still expected language models to be able to compose music or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=460" target="_blank">00:07:40.640</a></span> | <span class="t">solve scientific problems, as some now can. An order of magnitude, don't forget, means being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=465" target="_blank">00:07:45.920</a></span> | <span class="t">10 times bigger. But how about 1000 times bigger than GPT-4 in 3 years? Right, so if everybody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=473" target="_blank">00:07:53.600</a></span> | <span class="t">gets that power, that starts to look like, you know, individuals having the power of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=477" target="_blank">00:07:57.760</a></span> | <span class="t">organisations or even states. I'm talking about models that are like two or three orders of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=482" target="_blank">00:08:02.240</a></span> | <span class="t">magnitude, maybe four orders of magnitude on from where we are. And we're not far away from that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=486" target="_blank">00:08:06.240</a></span> | <span class="t">We're going to be training models that are 1000x larger than they currently are in the next three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=491" target="_blank">00:08:11.200</a></span> | <span class="t">years. Even at inflection with the compute that we have, we'll be 100x larger than the current</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=496" target="_blank">00:08:16.160</a></span> | <span class="t">frontier models in the next 18 months. You can start to see why AGI means so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=501" target="_blank">00:08:21.040</a></span> | <span class="t">much more than just a chatbot. And here's another example. OpenAI agrees, saying it's possible that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=503" target="_blank">00:08:23.200</a></span> | <span class="t">we can do this. This again came from Suleiman's book released two days ago. He talks about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=508" target="_blank">00:08:28.160</a></span> | <span class="t">WannaCry ransomware attack that caused billions of dollars of damage back in 2017. And he said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=514" target="_blank">00:08:34.160</a></span> | <span class="t">"Imagine WannaCry being able to patch its own vulnerabilities, learning to detect and stop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=520" target="_blank">00:08:40.640</a></span> | <span class="t">further attempts to shut it down. A weapon like this is on the horizon, if not already in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=526" target="_blank">00:08:46.880</a></span> | <span class="t">development." Let's move on though from Suleiman to Demis Hassabis, head of Google DeepMind. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=532" target="_blank">00:08:52.800</a></span> | <span class="t">this article yesterday in Time magazine, which was fascinating. Apparently, Hassabis warned Elon Musk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=538" target="_blank">00:08:58.800</a></span> | <span class="t">about the risks from artificial intelligence back in 2012, saying that machines could become super</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=544" target="_blank">00:09:04.400</a></span> | <span class="t">intelligent and surpass us mere mortals. Maybe that's why he's glad that ChatGPT moved the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=550" target="_blank">00:09:10.160</a></span> | <span class="t">Overton window, the window of what it's permissible to discuss in public. In 2012, it was probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=556" target="_blank">00:09:16.560</a></span> | <span class="t">embarrassing to talk about artificial intelligence, let alone AGI. We also learned that Musk tried to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=562" target="_blank">00:09:22.400</a></span> | <span class="t">stop DeepMind being sold to Google. Musk put together financing to stop the deal and had an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=568" target="_blank">00:09:28.160</a></span> | <span class="t">hour-long Skype call with Hassabis saying the future of AI should not be controlled by Larry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=574" target="_blank">00:09:34.000</a></span> | <span class="t">That's Larry Page, one of the co-founders of Google. Obviously that didn't happen and we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=578" target="_blank">00:09:38.800</a></span> | <span class="t">soon set to see Gemini from Google DeepMind. That's their rival to GPT-4. I've got a whole video series</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=585" target="_blank">00:09:45.680</a></span> | <span class="t">on it, so do check that out. But the revelation from today was that Hassabis said this, "Gemini represents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=592" target="_blank">00:09:52.000</a></span> | <span class="t">a combination of scaling and innovation. It's very promising early results." And as a Londoner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=598" target="_blank">00:09:58.000</a></span> | <span class="t">like me, Hassabis will be prone to understatement. So a British person saying "very promising early</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=603" target="_blank">00:10:03.920</a></span> | <span class="t">results" means it might shock a few people. Now do you remember from earlier in the video where I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=608" target="_blank">00:10:08.800</a></span> | <span class="t">quoted Altman back in 2015 saying this, "AI is about making humans better, not a single entity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=615" target="_blank">00:10:15.360</a></span> | <span class="t">that is a million times more powerful." Well for Musk, who remember co-founded OpenAI, that was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=620" target="_blank">00:10:20.720</a></span> | <span class="t">apparently the answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=621" target="_blank">00:10:21.600</a></span> | <span class="t">And that's the reason why he's so proud of his idea of the AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=623" target="_blank">00:10:23.760</a></span> | <span class="t">That's his attempt to tie the bots closer to humans, making them an extension of the will of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=629" target="_blank">00:10:29.840</a></span> | <span class="t">individuals, rather than systems that could go rogue and develop their own goals and intentions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=634" target="_blank">00:10:34.480</a></span> | <span class="t">Another idea for Musk would be to build a sustainable human colony on Mars before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=639" target="_blank">00:10:39.920</a></span> | <span class="t">anything went wrong. Speaking of going wrong, we also have this from Demis Hassabis in Time Magazine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=646" target="_blank">00:10:46.080</a></span> | <span class="t">He was asked, "Are there any capabilities that, if Gemini remember that's their version of GPT-4 or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=651" target="_blank">00:10:51.200</a></span> | <span class="t">5, exhibited them in your testing phase, you'd decide, 'No, we cannot release this'?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=656" target="_blank">00:10:56.000</a></span> | <span class="t">He said, "Yeah, I mean it's probably several generations down the line."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=660" target="_blank">00:11:00.080</a></span> | <span class="t">And then for anyone who's watched my SmartGPT series, they'd know that I would agree with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=664" target="_blank">00:11:04.720</a></span> | <span class="t">next part. I think the most pressing thing that needs to happen in the research area of AI is to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=669" target="_blank">00:11:09.760</a></span> | <span class="t">come up with the right evaluation benchmarks for capabilities. Because we'd all love a set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=675" target="_blank">00:11:15.200</a></span> | <span class="t">of maybe even hundreds of tests where if your system passed it, that could get a kite mark and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=680" target="_blank">00:11:20.800</a></span> | <span class="t">you'd say, "Right, this is safe to deploy." The problem is, we don't have those types of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=685" target="_blank">00:11:25.360</a></span> | <span class="t">benchmarks currently. For example, is this system capable of deception? Can it replicate itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=690" target="_blank">00:11:30.880</a></span> | <span class="t">across data centers? This is the kind of level we're talking about. These are the sorts of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=695" target="_blank">00:11:35.280</a></span> | <span class="t">things you might want to test for. But we need practical, pragmatic tests for them. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=700" target="_blank">00:11:40.800</a></span> | <span class="t">that's the most pressing thing for the field to do as a whole. Our current evals and benchmarks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=705" target="_blank">00:11:45.360</a></span> | <span class="t">are just not up to the task. But apparently, we have plenty of time to do this. At least,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=710" target="_blank">00:11:50.400</a></span> | <span class="t">according to Suleiman, who don't forget, along with Hassabis, was the co-founder of DeepMind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=715" target="_blank">00:11:55.520</a></span> | <span class="t">Many of us more or less expected, or more or less sure was coming, which was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=720" target="_blank">00:12:00.320</a></span> | <span class="t">there'd be a breakthrough at some company like DeepMind where the people building the technology</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=728" target="_blank">00:12:08.400</a></span> | <span class="t">would recognize that they had finally gotten into the end zone or close enough to it so that they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=734" target="_blank">00:12:14.720</a></span> | <span class="t">now in the presence of something that's fundamentally different than anything that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=738" target="_blank">00:12:18.400</a></span> | <span class="t">come before. And there'd be this question, "What's the best way to do this?" And I think that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=740" target="_blank">00:12:20.000</a></span> | <span class="t">the question, "Okay, is this safe to work with, safe to create an API for?" The idea was that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=747" target="_blank">00:12:27.120</a></span> | <span class="t">you'd have this digital oracle in a box, would already have been air gapped from the internet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=753" target="_blank">00:12:33.760</a></span> | <span class="t">and incapable of doing anything until we let it out. And then the question would be,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=757" target="_blank">00:12:37.920</a></span> | <span class="t">"Have we done enough safety testing to let it out?" But now it's pretty clear that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=762" target="_blank">00:12:42.640</a></span> | <span class="t">everything is already more or less out and we're building our most powerful models already in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=769" target="_blank">00:12:49.600</a></span> | <span class="t">wild. They're open source versions of the next best model. And is containment even a dream at this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=776" target="_blank">00:12:56.240</a></span> | <span class="t">point? It's definitely not too late. We're a long, long way away. This is really just the beginning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=781" target="_blank">00:13:01.760</a></span> | <span class="t">We have plenty of time to address this. The more that these models and these ideas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=788" target="_blank">00:13:08.640</a></span> | <span class="t">happen in the open, the more they can be scrutinized and they can be pressure tested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=794" target="_blank">00:13:14.320</a></span> | <span class="t">and held accountable. So I think it's great that they're happening in open source at the moment. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=799" target="_blank">00:13:19.200</a></span> | <span class="t">have to be humble about the practical reality about how these things emerge. The initial framing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=806" target="_blank">00:13:26.560</a></span> | <span class="t">that it was going to be possible to invent this oracle AI that stays in a box and we'll just probe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=812" target="_blank">00:13:32.000</a></span> | <span class="t">it and poke it and test it until we can prove that it's going to be safe, that we'll stay in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=816" target="_blank">00:13:36.240</a></span> | <span class="t">bunker and keep it hidden from everybody. I mean, this is a complete nonsense and it's attached to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=820" target="_blank">00:13:40.480</a></span> | <span class="t">the super intelligence framing. It was just a completely wrong metaphor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=824" target="_blank">00:13:44.800</a></span> | <span class="t">He might want to tell that to Hassabis who said this recently, "If a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=828" target="_blank">00:13:48.800</a></span> | <span class="t">system didn't pass the evals, that means you wouldn't release it until you sorted that out."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=833" target="_blank">00:13:53.440</a></span> | <span class="t">And perhaps you would do that in something like a hardened simulator or hardened sandbox with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=838" target="_blank">00:13:58.640</a></span> | <span class="t">cybersecurity things around it. So these are the types of ideas we have, but they need to be made</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=843" target="_blank">00:14:03.520</a></span> | <span class="t">a little bit more concrete. I think that's the most pressing thing to be done in time for those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=848" target="_blank">00:14:08.320</a></span> | <span class="t">types of systems when they arrive. And here's the key moment, because I think we've got a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=852" target="_blank">00:14:12.960</a></span> | <span class="t">couple of years probably or more. That's not actually a lot of time if you think about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=858" target="_blank">00:14:18.400</a></span> | <span class="t">research that has to be done. I think I am much closer to Hassabis than Suleiman on this one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=864" target="_blank">00:14:24.000</a></span> | <span class="t">Personally, I'd love a button where you could click at the exact moment where you want AI to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=869" target="_blank">00:14:29.040</a></span> | <span class="t">stop. For me, that would be after it cures Alzheimer's, but before it creates rabies 2.0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=874" target="_blank">00:14:34.560</a></span> | <span class="t">It would be after it solves mathematics, but before it gets too good at warfare.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=879" target="_blank">00:14:39.600</a></span> | <span class="t">Maybe such a button could be devised at Bletchley Park in November, which was the place where the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=885" target="_blank">00:14:45.200</a></span> | <span class="t">Enigma was cracked in World War II. They are both very good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=888" target="_blank">00:14:48.000</a></span> | <span class="t">They are being advised by some of the top minds in AI, so there is a chance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=892" target="_blank">00:14:52.560</a></span> | <span class="t">And apparently they want 10 times as many people to join them in the next few weeks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=897" target="_blank">00:14:57.440</a></span> | <span class="t">But anyway, at the very least, I hope I've persuaded you that AGI is going to mean a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2bn3S4vOVN4&t=903" target="_blank">00:15:03.520</a></span> | <span class="t">more than just clever chatbots. Thank you so much for watching to the end and have a wonderful day.</span></div></div></body></html>