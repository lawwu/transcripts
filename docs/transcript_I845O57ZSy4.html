<html><head><title>John Carmack: Doom, Quake, VR, AGI, Programming, Video Games, and Rockets | Lex Fridman Podcast #309</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>John Carmack: Doom, Quake, VR, AGI, Programming, Video Games, and Rockets | Lex Fridman Podcast #309</h2><a href="https://www.youtube.com/watch?v=I845O57ZSy4" target="_blank"><img src="https://i.ytimg.com/vi_webp/I845O57ZSy4/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=0 target="_blank"">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=117 target="_blank"">1:57</a> Programming languages<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=1981 target="_blank"">33:1</a> Modern programming<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=2583 target="_blank"">43:3</a> Day in the life<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=3053 target="_blank"">50:53</a> Hard work<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=3246 target="_blank"">54:6</a> Pizza and Diet Coke<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=3410 target="_blank"">56:50</a> Setup<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=4928 target="_blank"">82:8</a> id Software<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=6898 target="_blank"">114:58</a> Commander Keen<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=7304 target="_blank"">121:44</a> Hacker ethic<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=7764 target="_blank"">129:24</a> Wolfenstein 3D<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=8961 target="_blank"">149:21</a> Doom<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=9822 target="_blank"">163:42</a> Quake<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=11282 target="_blank"">188:2</a> John Romero<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=11749 target="_blank"">195:49</a> Metaverse<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=13451 target="_blank"">224:11</a> Elon Musk<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=13806 target="_blank"">230:6</a> Mars<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=14349 target="_blank"">239:9</a> Nuclear energy<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=14567 target="_blank"">242:47</a> AGI<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=17399 target="_blank"">289:59</a> Andrej Karpathy<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=17577 target="_blank"">292:57</a> Martial arts<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=18117 target="_blank"">301:57</a> Advice for young people<br><a href="https://www.youtube.com/watch?v=I845O57ZSy4&t=18657 target="_blank"">310:57</a> Meaning of life<br><h3>Transcript</h3><div class='max-width'><p>I remember the reaction where he had drawn these characters and he was slowly moving around. And people had no experience with 3D navigation. It was all still keyboard. We didn't even have mice set up at that time. But slowly moving, going up, picked up a key, go to a wall.</p><p>The wall disappears in a little animation. And there's a monster right there. And he practically fell out of his chair. It was just like, ah! And games just didn't do that. The games were the god's eye view. You were a little invested in your little guy. You can be happy or sad when things happen.</p><p>But you just did not get that kind of startle reaction. - You weren't inside the game. - Something in the back of your brain, some reptile brain thing is just going, oh shit, something just happened. And that was one of those early points where it's like, yeah, this is gonna make a difference.</p><p>This is going to be powerful and it's gonna matter. - The following is a conversation with John Carmack, widely considered to be one of the greatest programmers ever. He was the co-founder of id Software and the lead programmer on several games that revolutionized the technology, the experience, and the role of gaming in our society, including Commander Keen, Wolfenstein 3D, Doom, and Quake.</p><p>He spent many years as the CTO of Oculus VR, helping to create portals into virtual worlds and to define the technological path to the metaverse and meta. And now he has been shifting some of his attention to the problem of artificial general intelligence. This was the longest conversation on this podcast at over five hours.</p><p>And still I could talk to John many, many more times. And we hope to do just that. This is the Lux Readment Podcast. To support it, please check out our sponsors in the description. And now, dear friends, here's John Carmack. What was the first program you've ever written? Do you remember?</p><p>- Yeah, I do. So I remember being in a radio shack, going up to the TRS-80 computers and learning just enough to be able to do 10 print John Carmack. And it's kind of interesting how, of course, I've, you know, Carnegan and Richie kind of standardized "Hello, World" as the first thing that you do in every computer programming language in every computer, but not having any interaction with the cultures of Unix or any other standardized things.</p><p>It was just like, well, what am I gonna say? I'm gonna say my name. And then you learn how to do GOTO 10 and have it scroll all off the screen. And that was definitely the first thing that I wound up doing on a computer. - Can I ask you a programming advice?</p><p>I was always told in the beginning that you're not allowed to use GOTO statements. That's really bad programming. Is this correct or not? Jumping around code. Can we look at the philosophy and the technical aspects of the GOTO statement that seems so convenient, but it's supposed to be bad programming?</p><p>- Back in the day in basic programming languages, you didn't have proper loops. You didn't have for a while and repeats. You know, that was the land of Pascal for people that kind of generally had access to it back then. So you had no choice but to use GOTOs.</p><p>And as you made what were big programs back then, which were a thousand line basic program is a really big program. They did tend to sort of degenerate into madness. You didn't have good editors or code exploration tools. So you would wind up fixing things in one place, add a little patch.</p><p>And there's reasons why structured programming generally helps understanding, but GOTOs aren't poisonous. Sometimes they're the right thing to do. Usually it's because there's a language feature missing like nested breaks or something where it can sometimes be better to do a GOTO cleanup or GOTO error rather than having multiple flags, multiple if statements littered throughout things.</p><p>But it is rare. I mean, if you grep through all of my code right now, I don't think any of my current code bases would actually have a GOTO, but deep within sort of the technical underpinnings of a major game engine, you're gonna have some GOTOs in a couple of places probably.</p><p>- Yeah, the infrastructure on top of, like the closer you get to the machine code, the more GOTOs you're gonna see, the more of these like hacks you're going to see because the set of features available to you in low level programming languages is limited. So print John Carmack, when is the first time, if we could talk about love, that you fell in love with programming?</p><p>You said like, this is really something special. - It really was something that was one of those love at first sight things where just really from the time that I understood what a computer was, even, I mean, I remember looking through old encyclopedias at the black and white photos of the IBM mainframes at the reel to reel tape decks.</p><p>And for people nowadays, it can be a little hard to understand what the world was like then from information gathering, where I would go to the libraries and there would be a couple books on the shelf about computers and they would be very out of date even at that point, just not a lot of information, but I would grab everything that I could find and devour everything.</p><p>Whenever Time or Newsweek had some article about computers, I would like cut it out with scissors and put it somewhere. It just, it felt like this magical thing to me, this idea that the computer would just do exactly what you told it to. I mean, and there's a little bit of the genie monkey's paw sort of issues there where you'd better be really, really careful with what you're telling it to do, but it wasn't gonna backtalk you.</p><p>It wasn't gonna have a different point of view. It was gonna carry out what you told it to do. And if you had the right commands, you could make it do these pretty magical things. - And so what kind of programs did you write at first? So beyond the print, John Carmack.</p><p>- So I can remember as going through the learning process where you find at the start, you're just learning how to do the most basic possible things. And I can remember stuff like a Superman comic that Radio Shack commissioned to have, it's like Superman had lost some of his super brain and kids had to use Radio Shack TRS-80 computers to do calculations for it, to help him kind of complete his heroics.</p><p>And I'd find little things like that and then get a few basic books to be able to kind of work my way up. And again, it was so precious back then. I had a couple books that would teach me important things about it. I had one book that I could start to learn a little bit of assembly language from, and I'd have a few books on basic and some things that I could get from the libraries.</p><p>But my goals in the early days was almost always making games of various kinds. I loved the arcade games and the early Atari 2600 games, and being able to do some of those things myself on the computers was very much what I aspired to. And it was a whole journey where if you learn normal basic, you can't do any kind of an action game.</p><p>You can write an adventure game. You can write things where you say, "What do you do here? I get sword, attack troll," that type of thing. And that can be done in the context of basic, but to do things that had moving graphics, they were only the most limited things you could possibly do.</p><p>You could maybe do Breakout or Pong or that sort of thing in low-resolution graphics. And in fact, one of my first sort of major technical hacks that I was kind of fond of was on the Apple II computers, they had a mode called low-resolution graphics, where, of course, all graphics were low-resolution back then, but regular low-resolution graphics, it was a grid of 40 by 40 pixels normally, but they could have 16 different colors.</p><p>And I wanted to make a game kind of like the arcade game Vanguard, just a scrolling game, and I wanted to just kind of have it scroll vertically up. And I could move a little ship around. You could manage to do that in basic, but there's no way you could redraw the whole screen.</p><p>And I remember at the time just coming up with what felt like a brainstorm to me, where I knew enough about the way the hardware was controlled, where the text screen and the low-resolution graphics screen were basically the same thing. And all those computers could scroll their text screen reasonably.</p><p>You could do a listing, and it would scroll things up. And I figured out that I could kind of tweak just a couple things that I barely understood to put it into a graphics mode, and I could draw graphics, and then I could just do a line feed at the very bottom of the screen, and then the system would scroll it all up using an assembly language routine that I didn't know how to write back then.</p><p>So that was like this first great hack that sort of had analogs later on in my career for a lot of different things. So I found out that I could draw a screen, I could do a line feed at the bottom, it would scroll it up once, I could draw a couple more lines of stuff at the bottom.</p><p>And that was my first way to kind of scroll the screen, which was interesting in that that played a big part later on in the id software days as well. - So do efficient drawing, where you don't have to draw the whole screen, but you draw from the bottom using the thing that was designed in the hardware for text output.</p><p>- Yeah, where so much of until recently, game design was limited by what you could actually get the computer to do, where it's easy to say like, "Okay, I wanna scroll the screen." You just redraw the entire screen at a slight offset. And nowadays that works just fine. Computers are ludicrously fast.</p><p>But up until a decade ago or so, there were all these things everybody wanted to do, but if they knew enough programming to be able to make it happen, it would happen too slow to be a good experience, either just ridiculously slow or just slow enough that it wasn't fun to experience it like that.</p><p>So, so much of kind of the first couple decades of the programming work that I did was largely figuring out how to do something that everybody knows how they want it to happen. It just has to happen two to 10 times faster than sort of the straightforward way of doing things would make it happen.</p><p>And it's different now because at this point, lots of things you can just do in the most naive possible way, and it still works out. You don't have nearly the creative limitations or the incentives for optimizing on that level. And there's a lot of pros and cons to that, but I do generally, I'm not gonna do the angry old man shaking my fist at the clouds bit, where back in my day, programmers had to do real programming.</p><p>It's amazing that you can just kind of pick an idea and go do it right now. And you don't have to be some assembly language wizard or deep GPU arcanist to be able to figure out how to make your wishes happen. - Well, there's still, see, that's true, but let me put on my old man with a fist hat and say that probably the thing that will define the future still requires you to operate it at the limits of the current system.</p><p>So we'll probably talk about this, but if you talk about building the metaverse and building a VR experience that's compelling, it probably requires you to not to go to assembly or maybe not literally, but sort of spiritually to go to the limits of what the system is capable of.</p><p>- Yeah, and that really was why virtual reality was specifically interesting to me, where it had all the ties to, you could say that even back in the early days, I have some old magazine articles that's talking about doom as a virtual reality experience back when just seeing anything in 3D.</p><p>So you could say that we've been trying to build those virtual experiences from the very beginning. And in the modern era of virtual reality, especially on the mobile side of things, when it's standalone, you're basically using a cell phone chip to be able to produce these very immersive experiences.</p><p>It does require work. It's not at the level of what an old school console game programmer would have operated at, where you're looking at hardware registers and you're scheduling all the DMA accesses, but it is still definitely a different level than what a web developer or even a PC Steam game developer usually has to work at.</p><p>And again, it's great. There's opportunities for people that wanna operate at either end of that spectrum there and still provide a lot of value to the world. - Let me ask you sort of a big question about preference. What would you say is the best programming language? Your favorite, but also the best.</p><p>You've seen throughout your career, you're considered by many to be the greatest programmer ever. I mean, it's so difficult to place that label on anyone, but if you put it on anyone, it's you. So let me ask you these kind of ridiculous questions of what's the best band of all time, but in your case, what's the best programming language?</p><p>- Everything has all the caveats about it. But so what I use, so nowadays I do program a reasonable amount of Python for AI/ML sorts of work. I'm not a native Python programmer. It's something I came to very late in my career. I understand what it's good for. - But you don't dream in Python.</p><p>- I do not. And it has some of those things where there's some amazing stats when you say, if you just start, if you make a loop, you know, a triply nested loop and start doing operations in Python, you can be thousands to potentially a million times slower than a proper GPU tensor operation.</p><p>And these are staggering numbers. You know, you can be as much slower as we've almost gotten faster in our pace of progress and all this other miraculous stuff. - So your intuition's about inefficiencies within the Python sort of- - It keeps hitting me upside the face where it's gotten to the point now I understand.</p><p>It's like, okay, you just can't do a loop if you care about performance in Python. You have to figure out how you can reformat this into some big vector operation or something that's going to be done completely within a C++ library. But the other hand is it's amazingly convenient.</p><p>And you just see stuff that people are able to cobble together by, you just import a few different things and you can do stuff that nobody on earth could do 10 years ago. And you can do it in a little cookbook thing that you copy pasted out of a website.</p><p>So that is really great. When I'm sitting down to do what I consider kind of serious programming, it's still in C++ and it's really kind of a C-flavored C++ at that where I'm not big into the modern template metaprogramming sorts of things. I see a lot of train wrecks coming from some of that over abstraction.</p><p>I spent a few years really going kind of deep into the kind of the historical Lisp work and Haskell and some of the functional programming sides of things. And there is a lot of value there in the way you think about things. And I changed a lot of the way I write my C and C++ code based on what I learned about the value that comes out of not having this random mutable state that you kind of lose track of.</p><p>Because something that many people don't really appreciate till they've been at it for a long time is that it's not the writing of the program initially, it's the whole lifespan of the program. And that's when it's not necessarily just how fast you wrote it or how fast it operates, but it's how can it bend and adapt as situations change.</p><p>And then the thing that I've really been learning in my time at Meta with the Oculus and VR work is it's also how well it hands off between a continuous kind of revolving door of programmers taking over maintenance and different things, and how you get people up to speed in different areas.</p><p>And there's all these other different aspects of it. - Is C++ a good language for handover between engineers? - Probably not the best. And there's some really interesting aspects to this where in some cases, languages that are not generally thought well of for many reasons, like C is derided pretty broadly, that yes, obviously all of these security flaws that happen with the memory and unsafeness and buffer overruns and the things that you've got there, but there is this underappreciated aspect to the language is so simple, anyone can go and if you know C, you can generally jump in someplace and not have to learn what paradigms they're using because there just aren't that many available.</p><p>I think there's, and there's some really, really well-written C code. Like it's, I find it great that if I'm messing around with something in OpenBSD say, I mean, I can be walking around in the kernel and I'm like, I understand everything that's going on here. It's not hard for me to figure out what's, what I need to do to make whatever change that I need to.</p><p>While you can have more significant languages, like it's a downside of Lisp where I don't regret the time that I spent with Lisp. I think that it did help, help my thinking about programming in some ways. But the people that are the biggest defenders of Lisp are saying how malleable of a language it is, that if you write a huge Lisp program, you've basically invented your own kind of language and structure because it's not the primitives of the language you're using very much.</p><p>It's all of the things you've built on top of that. And then a language like Racket, kind of one of the more modern Lisp versions, it's essentially touted as a language for building other languages. And I understand the value of that for a tiny little project, but the idea of that for one of these long-term supported by lots of people kind of horrifies me where all of those abstractions that you're like, okay, you can't touch this code till you educate yourself on all of these things that we've built on top of that.</p><p>And it was interesting to see how when Google made Go, a lot of the criticisms of that are, it's like, wow, this is not a state-of-the-art language. This language is just so simple and almost crude. And you could see the programming language people just looking down at it. But it does seem to be quite popular as basically saying, this is the good things about C.</p><p>Everybody can just jump right in and use it. You don't need to restructure your brain to write good code in it. So I wish that I had more opportunity for doing some work in Go. Rust is the other modern language that everybody talks about that I'm not fit to pass judgment on.</p><p>I've done a little bit beyond "Hello, World." I wrote some video decompression work in Rust just as an exercise, but that was a few years ago, and I haven't really used it since. The best programming language is the one that works generally that you're currently using, because that's another trap is in almost every case I've seen when people mixed languages on a project, that's a mistake.</p><p>I would rather stay just in one language so that everybody can work across the entire thing. And we have -- Like, at Meta, we have a lot of projects that use kind of React frameworks. So you've got JavaScript here, and then you have C++ for real work, and then you may have Java interfacing with some other part of the Android system.</p><p>And those are all kind of horrible things. And that was one thing that I remember talking with Boz at Facebook about it, where, like, man, I wish we could have just said, "We're only hiring C++ programmers." And he just thought, from the Facebook Meta perspective, "Well, we just wouldn't be able to find enough." You know, with the thousands of programmers they've got there, it is not necessarily a dying breed, but you can sure find a lot more Java or JavaScript programmers.</p><p>And I kind of mentioned that to Elon one time, and he was kind of flabbergasted about that. It's like, "Well, you just go out and you find those programmers, and you don't hire the other programmers that don't do the languages that you want to use." But right now, I guess, yeah, they're using JavaScript on a bunch of the SpaceX work for the UI side of things.</p><p>When you go find UI programmers, they're JavaScript programmers. -I wonder if that's because there's a lot of JavaScript programmers, because I do think that great programmers are rare. That it's not, you know, if you just look at statistics of how many people are using different programming languages, that doesn't tell you the story of what the great programmers are using.</p><p>And so you have to really look at what you were speaking to, which is the fundamentals of a language. What does it encourage you? How does it encourage you to think? What kind of systems does it encourage you to build? There is something about C++ that has elements of creativity, but forces you to be an adult about your programming.</p><p>-It expects you to be an adult. It does not force you to. -And so it brings out people that are willing to be creative in terms of building large systems and coming up with interesting solutions, but at the same time have sort of the good software engineering practices that amend themselves to real-world systems.</p><p>Let me ask you about this other language, JavaScript. So if we, you know, aliens visit in thousands of years and humans are long gone, something tells me that most of the systems they find will be running JavaScript. I kind of think that if we're living in a simulation, it's written in JavaScript.</p><p>You know, for the longest time, even still, JavaScript didn't get any respect, and yet it runs so much of the world and an increasing number of the world. Is it possible that everything will be written in JavaScript one day? -So the engineering under JavaScript is really pretty phenomenal. The systems that make JavaScript run as fast as it does right now are kind of miracles of modern engineering in many ways.</p><p>It does feel like it is not an optimal language for all the things that it's being used for or an optimal distribution system to build huge apps in something like this without type systems and so on, but I think for a lot of people, it does reasonably the necessary things.</p><p>It's still a C-flavored language. It's still a braces and semicolon language. It's not hard for people to be trained in JavaScript and then understand the roots of where it came from. I think garbage collection is unequivocally a good thing for most programs to be written in. It's funny that I still -- Just this morning, I was seeing a Twitter thread of a bunch of really senior game dev people arguing about the virtues and costs of garbage collection, and you will run into some people that are top-notch programmers that just say, "No, this is literally not a good thing." -Oh, because it makes you lazy?</p><p>-Yes, that it makes you not think about things, and I do disagree. I think that there is so much objective data on the vulnerabilities that have happened in C and C++ programs, sometimes written by the best programmers in the world. It's like nobody is good enough to avoid ever shooting themselves in the foot with that.</p><p>You write enough C code, you're going to shoot yourself in the foot. And garbage collection is a very great thing for the vast majority of programs. It's only when you get into the tightest of real-time things that you start saying it's like, "No, the garbage collection has more costs than it has benefits for me there," but that's not 99-plus percent of all the software in the world.</p><p>So JavaScript is not terrible in those ways, and so much of programming is not the language itself. It's the infrastructure around everyone that surrounds it, all the libraries that you can get and the different ways you can deploy it, the portability that it gives you. And JavaScript is really strong on a lot of those things, where for a long time, and it still does if I look at it, the web stack about everything that has to go when you do something really trivial in JavaScript and it shows up on a web browser to kind of X-ray through that and see everything that has to happen for your one little JavaScript statement to turn into something visible in your web browser, it's very, very disquieting, just the depth of that stack and the fact that so few people can even comprehend all of the levels that are going on there.</p><p>But it's, again, I have to caution myself to not be the in-the-good-old-days-old-man about it because clearly there's enormous value here. The world does run on JavaScript to a pretty good approximation there, and it's not falling apart. There's a bunch of scary stuff where you look at console logs and you just see all of these bad things that are happening, but it's still kind of limping along and nobody really notices.</p><p>But so much of my systems design and systems analysis goes around you should understand what the speed of light is, like what would be the best you could possibly do here. And it sounds horrible, but in a lot of cases, you can be 1,000 times off your speed of light velocity for something and it still be okay.</p><p>And in fact, it can even sometimes still be the optimal thing in a larger system standpoint where there's a lot of things that you don't want to have to parachute in someone like me to go in and say, "Make this web page run 1,000 times faster. Make this web app into a hardcore native application that starts up in 37 milliseconds and everything responds in less than one frame latency." That's just not necessary.</p><p>And if somebody wants to go pay me millions of dollars to do software like that, when they can take somebody right out of a boot camp and say, "Spin up an application for this," often being efficient is not really the best metric. And it's like that applies in a lot of areas where it's kind of interesting how a lot of our appliances and everything are all built around energy efficiency, sometimes at the expense of robustness in some other ways or higher costs in other ways, where there's interesting things where energy or electricity could become much cheaper in a future world, and that could change our engineering trade-offs for the way we build certain things, where you could throw away efficiency and actually get more benefits that actually matter.</p><p>I mean, that's one of my, you know, one of the directions I was considering swerving into was nuclear energy when I was kind of like, "What do I want to do next?" It was either going to be cost-effective nuclear fission or artificial general intelligence. And one of my pet ideas there is, like, you know, people don't understand how cheap nuclear fuel is, and there would be ways that you could be a quarter the efficiency or less, but if it wound up making your plant 10 times cheaper, that could be a radical innovation in something like that.</p><p>So there's, like, some of these thoughts around, like, direct fission energy conversion, you know, fission fragment conversion, that, you know, maybe you build something that doesn't require all the steam turbines and everything, even if it winds up being less efficient. So that applies a lot in programming, where it's always good to know what you could do if you really sat down and took it far, because sometimes there's discontinuities, like around user reaction times.</p><p>There are some points where the difference between operating in 1 second and 750 milliseconds is not that huge. You'll see it in web page statistics, but most of the usability stuff, not that great. But if you get down to 50 milliseconds, then all of a sudden this just feels amazing.</p><p>You know, it's just like doing your bidding instantly rather than you're giving it a command, twiddling your thumbs, waiting for it to respond. So sometimes it's important to really crunch hard to get over some threshold, but there are broad basins in the value metric for lots of work where it just doesn't pay to even go that extra mile.</p><p>And there are craftsmen that just don't want to buy that, and more power to them. You know, if somebody just wants to say, no, I'm going to be, my pride is in my work, I'm never going to do something that's not as good as I could possibly make it, I respect that, and sometimes I am that person, but I try to focus more on the larger value picture, and you do pick your battles, and you deploy your resources into play that's going to give you sort of the best user value in the end.</p><p>- Well, if you look at the evolution of life on Earth as a kind of programming effort, it seems like efficiency isn't the thing that's being optimized for. Like natural selection is very inefficient, but it kind of adapts, and through the process of adaptations, building more and more complex systems that are more and more intelligent, the final result is kind of pretty interesting.</p><p>And so I think of JavaScript the same way. It's like this giant mess that things naturally die off if they don't work, and if they become useful to people, they kind of naturally live, and then you build this community, large community of people that are generating code, and some code is sticky, some is not, and nobody knows the inefficiencies or the efficiencies or the breaking points, like how reliable this code is, and you kind of just run it, assume it works, and then get unpleasantly surprised, and then that's very kind of the evolutionary process.</p><p>- So that's a really good analogy, and we can go a lot of places with that, where in the earliest days of programming, when you had finite, you could count the bytes that you had to work on this, you had all the kind of hackers playing code golf to be one less instruction than the other person's multiply routine to kind of get through, and it was so perfectly crafted.</p><p>It was a crystal piece of artwork when you had a program, because there just were not that many, you couldn't afford to be lazy in different ways, and in many ways, I see that as akin to the symbolic AI work where again, if you did not have the resources to just say, well, we're gonna do billions and billions of programmable weights here, you have to turn it down into something that is symbolic and crafted like that, but that's definitely not the way DNA and life and biological evolution and things work.</p><p>On the one hand, it's almost humbling how little programming code is in our bodies. We've got a couple of billion base pairs, and it's like this all fits on a thumb drive for years now, and then our brains are even a smaller section of that. You've got maybe 50 megabytes, and this is not like Shannon limit, perfectly information dense conveyances here.</p><p>It's like, these are messy codes. They're broken up into amino acids. A lot of them don't do important things or they do things in very awkward ways, but it is this process of just accumulation on top of things, and you need scale. Both you need scale for sort of the population for that to work out, and in the early days, in the '50s and '60s, the kind of ancient era of computers where you could count when they said, like when the internet started, even in the '70s, there were like 18 hosts or something on it.</p><p>It was this small, finite number, and you were still optimizing everything to be as good as you possibly could be, but now it's billions and billions of devices and everything going on, and you can have this very much natural evolution going on where lots of things are tried, lots of things are blowing up.</p><p>Venture capitalists lose their money when a startup invested in the wrong tech stack and things completely failed or failed to scale, but good things do come out of it, and it's interesting to see the mimetic evolution of the way different things happen, like mentioning "Hello, World!" at the beginning.</p><p>It's funny how some little thing like that where every programmer knows "Hello, World!" now, and that was a completely arbitrary sort of decision that just came out of the dominance of Unix and C and early examples of things like that. So millions of experiments are going on all the time, but some things do kind of rise to the top and win the fitness war for whether it's Mindspace or programming techniques or anything.</p><p>Like there's a site on Stack Exchange called Code Golf where people compete to write the shortest possible program for a particular task in all the different kinds of languages, and it's really interesting to see folks kind of, their masters of their craft really play with the limits of programming languages.</p><p>It's really beautiful to see, and across all the different programming languages, you get to see some of these weird programming languages and mainstream ones, difference between Python 2 and 3. You get to see the difference between C and C++ and Java, and you get to see JavaScript, all of that, and it's kind of inspiring to see how much depth of possibility there is within programming languages that Code Golf kind of tasks reveal.</p><p>Most of us, if you do any kind of programming, you kind of do boring, kind of very vanilla type of code. That's the way to build large systems, but it's nice to see that the possibility of creative genius is still within those languages. It's laden within those languages. So given that you are, once again, one of the greatest programmers ever, what do you think makes a good programmer?</p><p>Maybe a good modern programmer. - So I just gave a long rant/lecture at Meta to the TPM organization, and my biggest point was everything that we're doing really should flow from user value. All the good things that we're doing. It's like we're not technical people. It's like you shouldn't be taking pride just in the specific thing.</p><p>Like, Code Golf is the sort of thing, it's a fun puzzle game, but that really should not be a major motivator for you. It's like we're solving problems for people or we're providing entertainment to people. We're doing something of value to people that's displacing something else in their life.</p><p>So we want to be providing a net value over what they could be doing, but instead they're choosing to use our products. And that's where, I mean, it sounds trite or corny, but I fundamentally do think that's how you make the world a better place. If you have given more value to people than it took you and your team to create, then the world's a better place.</p><p>People have, they've gone from something of lesser value, chosen to use your product, and their life feels better for that. And if you've produced that economically, that's a really good thing. On the other hand, if you spent ridiculous amounts of money, you've just kind of shoveled a lot of cash into a wood chipper there, and you should maybe not feel so good about what you're doing.</p><p>So being proud about like a specific architecture or a specific technology or a specific code sequence that you've done, it's great to get a little smile, like a tiny little dopamine hit for that, but the top level metric should be that you're building things of value. Now you can get into the argument about how you, you know, what is user value?</p><p>How do you actually quantify that? And there can be big arguments about that, but it's easy to be able to say, okay, this pissed off user there is not getting value from what you're doing. This user over there with the big smile on their face, I am the moment of delight when something happened.</p><p>There's a value that's happened there. I mean, if you, you have to at least accept that there is a concept of user value, even if you have trouble exactly quantifying it, you can usually make relative arguments about it. Well, this was better than this. We've improved things. So, you know, being a servant to the user is your job when you're a developer.</p><p>You want to be producing something that, you know, other people are going to find valuable. And if you are technically inclined, then finding the right levers to be able to pull, to be able to make a design that's going to produce the most value for the least amount of effort.</p><p>And it always has to be kind of divide. There's a ratio there where you, it's a problem at the big tech companies, you know, whether it's, you know, MetaGoogle, Apple, Microsoft, Amazon, companies that have almost infinite money. I mean, I know their CFO will complain that it's not infinite money, but for most developer standpoints, it really does feel like it.</p><p>And it's almost counterintuitive that if you're working hard as a developer on something, there's always this thought, if only I had more resources, more people, more RAM, more megahertz, then my product will be better. And that sense that at certain points, it's certainly true that if you are really hamstrung by this, removing an obstacle will make a better product, make more value.</p><p>But if you're not making your core design decisions in this fiercely competitive way, where you're saying feature A or feature B, you can't just say, let's do both, because then you're not making a value judgment about them. You're just saying, well, they both seem good. I don't want to necessarily have to pick out which one is better or how much better and tell team B that, sorry, we're not gonna do this because A is more important.</p><p>But that notion of always having to really critically value what you're doing, your time, the resources you expend, even the opportunity cost of doing something else, that's, you know, super important. - Well, let me ask you about this, the big debates that you're mentioning of how to measure value.</p><p>Is it possible to measure it kind of numerically, or can you do the sort of Johnny Ive, the designer route of imagining sort of somebody using a thing and imagining a smile on their face, imagining the experience of love and joy that you have when you use the thing?</p><p>That's from a design perspective. Or if you're building more like a lower level thing for like Linux, you imagine a developer that might come across this and use it and become happy and better off because of it. So where do you land on those things? Is it measurable? So I imagine like Meta and Google will probably try to measure the thing.</p><p>They'll try to, it's like you try to optimize engagement or something, let's measure engagement. And then I think there is a kind of, I mean, I admire the designer ethic of like, think of a future that's immeasurable. And you try to make somebody in that future that's different from today happy.</p><p>- So I do usually favor, if you can get any kind of a metric that's good, by all means, listen to the data. But you can go too far there where we've had problems where it's like, hey, we had a performance regression because our fancy new telemetry system is doing a bazillion file writes to kind of archive this stuff because we needed to collect information to determine if we were doing, if our plans were good.</p><p>So when information is available, you should never ignore it. I mean, all the- - From actual users using the thing, human beings using the thing, large number of human beings, and you get to see sort of- - So there's the zero to one problem of when you're doing something really new, you do kind of have to make a guess.</p><p>But one of the points that I've been making at Meta is we have more than enough users now that anything somebody wants to try in VR, we have users that will be interested in that. You do not get to make a completely green field, blue sky pitch and say, I'm going to do this because I think it might be interesting.</p><p>I challenge everyone. There are going to be people, whether it's working in VR on your, like on your desktop replacement or communicating with people in different ways or playing the games, there are going to be probably millions of people, or at least if you pick some tiny niche that we're not in right now, there's still going to be thousands of people out there that have the headsets that would be your target market.</p><p>And I tell people, pay attention to them. Don't invent fictional users. Don't make an Alice, Bob, Charlie that fits whatever matrix of tendencies that you want to break the market down to because it's a mistake to think about imaginary users when you've got real users that you could be working with.</p><p>But on the other hand, there is value to having a kind of wholeness of vision for a product. And companies like Meta have, they understand the trade-offs where you can have a company like SpaceX or Apple in the Steve Jobs era where you have a very powerful leading personality that can micromanage at a very low level and can say, it's like, no, that handle needs to be different or that icon needs to change the tint there.</p><p>And they clearly get a lot of value out of it. They also burn through a lot of employees that have horror stories to tell about working there afterwards. My position is that you're at your best when you've got a leader that is at their limit of what they can kind of comprehend of everything below them.</p><p>And they can have an informed opinion about everything that's going on. And you take somebody, you've got to believe that somebody that has 30, 40 years of experience, you would hope that they've got wisdom that the just out of bootcamp person contributing doesn't have. And that if they're like, well, that's wrong there, you probably shouldn't do it that way or even just don't do it that way, do it another way.</p><p>So there's value there, but it can't go beyond a certain level. I mean, I have Steve Jobs stories of him saying things that are just wrong right in front of me about technical things because he was not operating at that level. But when it does work and you do get that kind of passionate leader that's thinking about the entire product and just really deeply cares about not letting anything slip through the cracks, I think that's got a lot of value.</p><p>But the other side of that is the people saying that, well, we want to have these independent teams that are bubbling up the ideas because it's almost it's anti-capitalist or anti-free market to say, it's like I want my great leader to go ahead and dictate all these points there where clearly free markets bring up things that you don't expect.</p><p>Like in VR, we saw a bunch of things, like it didn't turn out at all the way the early people thought were gonna be the key applications and things that would not have been approved by the dark cabal making the decisions about what gets into the store turn out to in some cases be extremely successful.</p><p>So yeah, I definitely kind of wanted to be there as a point where I did make a pitch. It's like, hey, make me VR dictator and I'll go in and get shit done. And that's just, it's not in the culture at Meta, and they understand the trade-offs and that's just not the way, that's not the company that they want, the team that they wanna do.</p><p>- It's fascinating 'cause VR, and we'll talk about it more, it's still unclear to me in what way VR will change the world, because it does seem clear that VR will somehow fundamentally transform this world, and it's unclear to me how yet. - Let me know when you wanna get into that.</p><p>- We will, but hold on a second. So stick to you being the best programmer ever. Okay, in the early days when you didn't have adult responsibilities of leading teams and all that kind of stuff, and you can focus on just being a programmer, what did a productive day in the life of John Carmack look like?</p><p>How many hours of the keyboard, how much sleep, what was the source of calories that fueled the brain? What was it like? What times you wake up? - So I was able to be remarkably consistent about what was good working conditions for me for a very long time. I was never one of the programmers that would do all-nighters going through, work for 20 hours straight.</p><p>It's like my brain generally starts turning to mush after 12 hours or so. But the hard work is really important, and I would work for decades. I would work 60 hours a week. I would work a 10-hour day, six days a week, and try to be productive at that.</p><p>Now, my schedule shifted around a fair amount when I was young without any kids and any other responsibilities. I was on one of those cycling schedules where I'd kind of get in an hour later each day and roll around through the entire time. And I'd wind up kind of pulling in at two or three in the afternoon sometimes, and then working again past midnight or two in the morning.</p><p>And that was, when it was just me trying to make things happen, and I was usually isolated off in my office, people generally didn't bother me much at it, and I could get a lot of programming work done that way. I did settle into a more normal schedule when I was taking kids to school and things like that.</p><p>- So kids were the forcing function that got you to wake up at the same time each day. - It's not clear to me that there was much of a difference in the productivity with that, where I kind of feel, if I just get up when I feel like it, it's usually a little later each day, but I just recently made the focusing decision to try to push my schedule back a little bit earlier to getting up at eight in the morning and trying to shift things around.</p><p>Like I'm often doing experiments with myself about what should I be doing to be more productive. And one of the things that I did realize was happening in recent months, where I would go for a walk or a run, I cover like four miles a day, and I would usually do that just as the sun's going down at here in Texas now, and it's still really damn hot, but I'd go out at 8.30 or something and cover the time there, and then the showering.</p><p>And it was putting a hole in my day where I would have still a couple hours after that. And sometimes my best hours were at night when nobody else is around, nobody's bothering me, but that hole in the day was a problem. So just a couple of weeks ago, I made the change to go ahead and say, all right, I'm gonna get up a little earlier.</p><p>I'm gonna do a walk or get out there first so I can have more uninterrupted time. So I'm still playing with factors like this as I kind of optimize my work efforts, but it's always been, it was 60 hours a week for a very long time. To some degree, I had a little thing in the back of my head where I was almost jealous of some of the programmers that would do these marathon sessions.</p><p>And I had like Dave Taylor, one of the guys that he had, he would be one of those people that would fall asleep under his desk sometimes and all the kind of classic hacker tropes about things. And a part of me was like, always a little bothered that that wasn't me, that I wouldn't go program 20 hours straight because I'm falling apart and not being very effective after 12 hours.</p><p>I mean, yeah, 12 hour programming, that's fine when you're doing that, but you're not doing smart work much after, at least I'm not, but there's a range of people. I mean, that's something that a lot of people don't really get in their gut, where there are people that work on four hours of sleep and are smart and can continue to do good work, but then there's a lot of people that just fall apart.</p><p>So I do tell people that I always try to get eight hours of sleep. It's not this, push yourself harder, get up earlier. I just do worse work where, you know, there's, you can work 100 hours a week and still get eight hours of sleep if you just kind of prioritize things correctly.</p><p>But I do believe in working hard, working a lot. There was a comment that a game dev made that I know there's a backlash against really hard work in a lot of cases, and I get into online arguments about this all the time, but he was basically saying, yeah, 40 hours a week, that's kind of a part-time job.</p><p>And if you were really in it, you're doing what you think is important, what you're passionate about, working more gets more done. And it's just really not possible to argue with that if you've been around the people that work with that level of intensity and just say, it's like, no, they should just stop.</p><p>And we had, I kind of came back around to that a couple of years ago where I was using the fictional example of, all right, some people say, they'll say with a straight face, they think, no, you are less productive if you work more than 40 hours a week.</p><p>And they're generally misinterpreting things where your marginal productivity for an hour after eight hours is less than in one of your peak hours, but you're not literally getting less done. There is a point where you start breaking things and getting worse behavior and everything out of it where you're literally going backwards, but it's not at eight or 10 or 12 hours.</p><p>And the fictional example I would use was, imagine there's an asteroid coming to impact, to crash into earth, destroy all of human life. Do you want Elon Musk or the people working at SpaceX that are building the interceptor that's going to deflect the asteroid, do you want them to clock out at five?</p><p>Because dammit, they're just gonna go do worse work if they work another couple hours. And it seems absurd. And that's a hypothetical though, and everyone can dismiss that. But then when coronavirus was hitting and you have all of these medical personnel that are clearly pushing themselves really, really hard, and I'd say, it's like, okay, do you want all of these scientists working on treatments and vaccines and caring for all of these people?</p><p>Are they really screwing everything up by working more than eight hours a day? And of course people say I'm just an asshole to say something like that, but it's, I know, it's the truth, working longer gets more done. - Well, so that's kind of the layer one, but I'd like to also say that, at least I believe depending on the person, depending on the task, working more and harder will make you better for the next week in those peak hours.</p><p>So there's something about a deep dedication to a thing that kind of gets deep in you. So the hard work isn't just about the raw hours of productivity, it's the thing it does to you in the weeks and months after too. - You're tempering yourself in some ways. - And I think, it's like your zero dreams of sushi.</p><p>If you really dedicate yourself completely to making the sushi, to really putting in the long hours day after day after day, you become a true craftsman of the thing you're doing. Now there's of course discussions about are you sacrificing a lot of personal relationships, are you sacrificing a lot of other possible things you could do with that time, but if you're talking about purely being a master or a craftsman of your art, that more hours isn't just about doing more, it's about becoming better at the thing you're doing.</p><p>- Yeah, and I don't gainsay anybody that wants to work the minimum amount, they've got other priorities in their life. My only argument that I'm making, it's not that everybody should work hard, it's that if you want to accomplish something, working longer and harder is the path to getting it accomplished.</p><p>- Well let me ask you about this then, the mythical work-life balance. For an engineer it seems like that's one of the professions for a programmer where working hard does lead to greater productivity in it, but it also raises the question of personal relationships and all that kind of stuff, family and how are you able to find work-life balance?</p><p>Is there advice you can give, maybe even outside of yourself, have you been able to arrive at any wisdom on this part in your years of life? - I do think that there's a wide range of people where different people have different needs, it's not a one size fits all, I am certainly what works for me.</p><p>I can tell enough that I'm different than a typical average person in the way things impact me, the things that I want to do, my goals are different and sort of the levers to impact things are different where I have literally never felt burnout and I know there's lots of brilliant smart people that do world-leading work that get burned out and it's never hit me.</p><p>I've never been at a point where I'm like, I just don't care about this, I don't want to do this anymore, but I've always had the flexibility to work on lots of interesting things. I can always just turn my gaze to something else and have a great time working on that and so much of the ability to actually work hard is the ability to have multiple things to choose from and to use your time on the most appropriate thing.</p><p>Like there are time periods where it's the best time for me to read a new research paper that I need to really be thinking hard about it, then there's a time that maybe I should just scan and organize my old notes because I'm just not on top of things and then there's the time that, all right, let's go bang out a few hundred lines of code for something.</p><p>So switching between them has been real valuable. - So you always have kind of joy in your heart for all the things you're doing and that is a kind of work-life balance as a first sort of step. - Yeah, I do. - So you're always happy. - I do.</p><p>- Well, happy, you know. - Yeah, I mean, it's like a lot of people would say that often I look like kind of a grim person with just sitting there with a neutral expression or even like knitted brows and a frown on my face as I'm staring at something.</p><p>- That's what happiness looks like for you. - Yeah, it's kind of true where that's like, okay, I'm pushing through this, I'm making progress here. I know that doesn't work for everyone. I know it doesn't work for most people, but what I am always trying to do in those cases is I don't wanna let somebody that might be a person like that be told by someone else that no, don't even try that out as an option where work-life balance versus kind of your life's work where there's a small subset of the people that can be very happy being obsessive about things.</p><p>And obsession can often get things done that just practical, prudent, pedestrian work won't or at least won't for a very long time. - There's legends of your nutritional intake in the early days. What can you say about sort of as a, being a programmer is a kind of athlete.</p><p>So what was the nutrition that fueled? - I have never been that great on really paying attention to it where I'm good enough that I don't eat a lot. I've never been like a big heavy guy, but it was interesting where one of the things that I can remember being an unhappy teenager, not having enough money.</p><p>And like one of the things that bothered me about not having enough money is I couldn't buy pizza whenever I wanted to. So I got rich and then I bought a whole lot of pizza. - So that was defining, like that's what being rich felt like. - A lot of the little things, like I could buy all the pizza and comic books and video games that I wanted to.</p><p>And it really didn't take that much, but the pizza was one of those things. And it's absolutely true that for a long time it did software. I had a pizza delivered every single day. You know, the delivery guy knew me by name. And I didn't find out until years later that apparently I was such a good customer that they just never raised the price on me.</p><p>And I was using this six-year-old price for the pizzas that they were still kind of sending my way every day. - So you were doing eating once a day or were you- - It would be spread out. You know, you have a few pieces of pizza, you have some more later on and I'd maybe have something at home.</p><p>It was one of the nice things that Facebook Meta is they feed you quite well. You get a different, I guess now it's DoorDash, sorts of things delivered, but they take care of making sure that everybody does get well fed. And I probably had better food those six years that I was working in the Meta office there than I used to before.</p><p>But it's worked out okay for me. My health has always been good. I get a pretty good amount of exercise and I don't eat to excess and I avoid a lot of other kind of not so good for you things. So I'm still doing quite well at my age.</p><p>- Did you have a kind of, I don't know, spiritual experience with food or coffee or any of that kind of stuff? I mean, you know, the programming experience, you know, with music or like I listen to brown noise on a program or like creating an environment and the things you take into your body, just everything you construct can become a kind of ritual that empowers the whole process of the program.</p><p>Did you have that relationship with pizza or? - It would really be with Diet Coke. I mean, there still is that sense of, you know, drop the can down, crack open the can of Diet Coke. All right, now I mean business. We're getting to work here. - Still to this day is Diet Coke is still part of it.</p><p>- Yeah, probably eight or nine a day. - Nice, okay. What about your setup? How many screens? What kind of keyboard? Is there something interesting? What kind of IDE, Emacs Vim or something modern? Linux, what operating system, laptop, or any interesting thing that brings you joy? - So I kind of migrated cultures where early on through all of game dev, there was sort of one culture there, which was really quite distinct from the more the Silicon Valley venture, you know, culture for things.</p><p>It's they're different groups and they have pretty different mores and the way they think about things where, and I still do think a lot of the big companies can learn things from the hardcore game development side of things where it still boggles my mind how I am, how hostile to debuggers and IDEs that so much of the kind of big money, get billions of dollars, Silicon Valley venture backed funds are.</p><p>- Oh, that's interesting. Sorry, so you're saying like big companies at Google and Meta are hostile to- - They are not big on debuggers and IDEs. Like so much of it is like Emacs Vim for things. And we just assume that debuggers don't work most of the time. I have for the systems and a lot of this comes from a sort of Linux bias on a lot of things where I did come up through the personal computers and then the DOS and then I am, you know, Windows and it was Borland tools and then Visual Studio and- - Do you appreciate the buggers?</p><p>- Very much so. I mean, a debugger is how you get a view into a system that's too complicated to understand. I mean, anybody that thinks just read the code and think about it, that's an insane statement in the, you can't even read all the code on a big system.</p><p>You have to do experiments on the system and doing that by adding log statements, recompiling and rerunning it is an incredibly inefficient way of doing it. I mean, yes, you can always get things done even if you're working with stone knives and, you know, and bearskins, that is the mark of a good programmer is that given any tools, you will figure out a way to get it done.</p><p>But it's amazing what you can do with sometimes much, much better tools where instead of just going through this iterative compile run debug cycle, you have the old Lisp direction of like, you've got a REPL and you're working interactively and doing amazing things there. But in many cases, a debugger as a very powerful user interface that can stop, examine all the different things in your program, set all of these different break points.</p><p>And of course you can do that with GDB or whatever there, but this is one of the user interface fundamental principles where when something is complicated to do, you won't use it very often. There's people that will break out GDB when they're at their wits end and they just have beat their head against a problem for so long.</p><p>But for somebody that kind of grew up in game dev, it's like they were running into the debugger anyways before they even knew there was a problem. And you would just stop and see, you know, what was happening. And sometimes you could fix things even before you, you know, even before you did one compile cycle, you could be in the debugger and you would say, well, I'm just going to change this right here.</p><p>And yep, that did the job and fix it and go on. - And for people who don't know, GDB is a sort of popular, I guess, Linux debugger, primarily for C++? - They handle most of the languages, but it's, you know, it's based on C as the original kind of Unix heritage.</p><p>- But, and it's kind of like command line. It's not user-friendly. It's not, it doesn't allow for clean visualizations. And you're exactly right. So you're using this kind of debugger, usually when you're at wits end and there's a problem that you can't figure out why, by just looking at the codes, you have to find it.</p><p>That's how I guess normal programmers use it. But you're saying there should be tools that kind of visualize and help you as part of the programming process, just the normal programming process to understand the code deeper. - Yeah, when I'm working on like my C/C++ code, I'm always running it from the debugger.</p><p>You know, just I type in the code, I run it. Many times, the first thing I do after writing code is set a break point and step through the function. Now, other people will say, it's like, oh, I do that in my head. Well, your head is a faulty interpreter of all those things there.</p><p>And I've written brand new code. I want to step in there and I'm going to single step through that, examine lots of things and see if it's actually doing what I expected it to. - It is a kind of companion, the debugger. Like you're now coding in an interactive way with another being.</p><p>A debugger is a kind of dumb being, but it's a reliable being. That is an interesting question of what role does AI play in that kind of, with codecs and these kind of ability to generate code. That might be, you might start having tools that understand the code in interesting, deep ways that can work with you.</p><p>- There's a whole spectrum there from static code analyzers and various kind of dynamic tools there up to AI that can conceivably grok these programs that literally no human can understand. They're too big, too intertwined and too interconnected, but it's not beyond the possibility of understanding. It's just beyond what we can hold in our heads as kind of mutable state while we're working on things.</p><p>And I'm a big proponent again of things like static analyzers and some of that stuff where you'll find some people that don't like being scolded by a program for how they've written something where it's like, oh, I know better. And sometimes you do, but that was something that I was, it was very, very valuable for me when, and not too many people get an opportunity like this to have.</p><p>This is almost one of those spiritual experiences as a programmer and awakening to, the id Software code bases were a couple million lines of code. And at one point I had used a few of the different analysis tools, but I made a point to really go through and scrub the code base using every tool that I could find.</p><p>And it was eyeopening where we had a reputation for having some of the most robust, strongest code, you know, where there were some, you know, great things that I remember hearing from Microsoft telling us about crashes on Xbox. And we had this tiny number that they said were probably literally hardware errors.</p><p>And then you have other significant titles that just have millions of faults that are getting recorded all the time. So I was proud of our code on a lot of levels, but when I took this code analysis squeegee through everything, it was shocking how many errors there were in there.</p><p>Things that you can say, okay, this was a copy paste, not changing something right here. Lots of things that were, you know, the most common problem was something in a printf format string that was the wrong data type that could cause crashes there. And, you know, you really want the warnings for things like that.</p><p>Then the next most common was missing a check for null that could actually happen, that could blow things up. And those are obviously like top C, C++ things. Everybody has those problems. But the long tail of all of the different little things that could go wrong there, and we had good programmers and my own code, stuff that I'd be looking at, it's like, oh, I wrote that code.</p><p>That's definitely wrong. We've been using this for a year. And it's this submarine, you know, this mine sitting there waiting for us to step on. And it was humbling. It was, and I reached the conclusion that anything that can be syntactically allowed in your language, if it's going to show up eventually in a large enough code base, you're not going to, good intentions aren't going to keep it from happening.</p><p>You need automated tools and guardrails for things. And those start with things like static types and, or, you know, even type hints in the more dynamic languages. But the people that rebel against that, that basically say, that slows me down doing that. There's something to that. I get that.</p><p>And, you know, I've cobbled things together in a notebook. I am like, wow, this is great that it just happened. But yeah, that's kind of sketchy, but it's working fine. I don't care. It does come back to that value analysis, where sometimes it's right to not care. But when you do care, if it's going to be something that's going to live for years and it's going to have other people working on it, and it's going to be deployed to millions of people, then you want to use all of these tools.</p><p>You want to be told, it's like, no, you've screwed up here, here, and here. And that does require kind of an ego check about things, where you have to be open to the fact that everything that you're doing is just littered with flaws. It's not that, oh, you occasionally have a bad day.</p><p>It's just, whatever stream of code you output, there is going to be a statistical regularity of things that you just make mistakes on. And I do think there's the whole argument about test-driven design and unit testing versus kind of analysis and different things. I am more in favor of the analysis and the stuff that just like, you can't run your program until you fix this rather than you can run it and hopefully a unit test will catch it in some way.</p><p>Yeah, in my private code, I have asserts everywhere. Yeah. Just there's something pleasant to me, pleasurable to me, about sort of the dictatorial rule of like, this should be true at this point. And too many times I've made mistakes that shouldn't have been made. And I would assume I wouldn't be the kind of person that would make that mistake, but I keep making that mistake.</p><p>Therefore, an assert really catches me, really helps all the time. So my code, I would say like 10 to 20% of my private code, just for personal use is probably asserts. And they're active comments. That's one of those things that in theory, they don't make any difference to the program.</p><p>And if it was all operating the way you expected it would be, then they will never fire. But even if you have it right and you wrote the code right initially, then circumstances change. The world outside your program changes. And in fact, that's one of the things where I'm kind of fond in a lot of cases of static array size declarations, where I went through this period where it's like, okay, now we have general collection classes.</p><p>We should just make everything variable. Because I had this history of in the early days, you get Doom, which had some fixed limits on it. Then everybody started making crazier and crazier things. And they kept bumping up the different limits, this many lines, this many sectors. And it seemed like a good idea.</p><p>Well, we should just make this completely generic. It can go kind of go up to whatever. And there's cases where that's the right thing to do. But it also, the other aspect of the world changing around you is it's good to be informed when the world has changed more than you thought it would.</p><p>And if you've got a continuously growing collection, you're never going to find out. You might have this quadratic slowdown on something where you thought, oh, I'm only ever going to have a handful of these. But something changes, and there's a new design style. And all of a sudden, you've got 10,000 of them.</p><p>So I kind of like, in many cases, picking a number, some nice round power of two number, and setting it up in there, and having an assert saying, it's like, hey, you hit this limit. You should probably think, are the choices that you've made around all of this still relevant if somebody's using 10 times more than you thought they would?</p><p>- Yeah, this code was originally written with this kind of worldview, with this kind of set of constraints. You were thinking of the world in this way. If something breaks, that means you got to rethink the initial stuff. And it's nice for it to do that. Is there any stuff like a keyboard or monitors?</p><p>- I'm fairly pedestrian on a lot of that, where I did move to triple monitors like in the last several years ago. I had been dual monitor for a very long time. And it was one of those things where, probably years later than I should have, I'm just like, well, the video cards now generally have three output ports.</p><p>I should just put the third monitor up there. That's been a pure win. I've been very happy with that. But no, I don't have fancy keyboard or mouse or anything really going on with that. - So, one of the key things is an IDE that has helpful debuggers, has helpful tools.</p><p>So it's not the Emacs Vim route and then Diacoke. - Yeah. So I did spend, I spent one of my week-long retreats where I'm like, okay, I'm going to make myself use, it was actually classic VI, which I know people will say, you should never have done that. You should have just used Vim directly.</p><p>But I gave it the good try. It's like, okay, I'm being in kind of classic Unix developer mode here. And I worked for a week on it. I used Anki to like teach myself the different little key combinations for things like that. And in the end it was just like, all right, this was kind of like my civil war reenactment phase.</p><p>You know, it's like, I'm going out there, doing it like they used to in the old days. And it was kind of fun in that regard. - So many people right now, they're screaming as they're listening to this. - So again, the out is that this was not modern Vim, but still, yes, I was very happy to get back to my visual studio at the end.</p><p>- Yeah, I'm actually, I struggle with this a lot because so you said Kinesis keyboard and I use Emacs primarily. And I feel like I can, exactly as you said, I can understand the code, I can navigate the code. There's a lot of stuff you could build within Emacs with using Lisp.</p><p>You can customize a lot of things for yourself to help you introspect the code, like to help you understand the code and visualize different aspects of the code. You can even run debuggers, but it's work. And the world moves past you and the better and better ideas are constantly being built.</p><p>And that puts a kind of, I need to take the same kind of retreat as you're talking about, but now I'm still fighting the civil war. I need to kind of move into the 21st century. - And it does seem like the world is, or a large chunk of the world is moving towards visual studio code, which is kind of interesting to me.</p><p>Again, it's the JavaScript ecosystem on the one hand, and IDs are one of those things that you want to be infinitely fast. You want them to just kind of immediately respond. And like, I mean, heck, I've got, there's someone I know, an old school game dev guy that still uses Visual Studio 6.</p><p>And on a modern computer, everything is just absolutely instant on something like that because it was made to work on a computer that's 10,000 or 100,000 times slower. So just everything happens immediately. And all the modern systems just feel, you know, they feel so crufty when it's like, oh, why is this refreshing the screen and moving around and updating over here and something blinks down there and you should update this.</p><p>And there's, you know, there are things that we've lost with that incredible flexibility, but lots of people get tons of value from it. And I am super happy that that seems to be winning over even a lot of the old Vim and Emacs people that they're kind of like, hey, Visual Studio code's maybe, you know, not so bad.</p><p>I am, that may be the final peacekeeping solution where everybody is reasonably happy with something like that. - So can you explain what a .plan file is and what role that played in your life? Does it still continue to play a role? - Back in the early, early days of id Software, one of our big things that was unique with what we did is I had adopted Nextstations or kind of next step systems from Steve Jobs' out in the woods away from Apple company.</p><p>And they were basically, it was kind of interesting because I did not really have a background with the Unix system. So many of the people, they get immersed in that in college and, you know, and that's, you know, that sets a lot of cultural expectations for them. And I didn't have any of that, but I knew that my background was, I was a huge Apple II fan boy.</p><p>I was always a little suspicious of the Mac. I was not really what kind of I wanted to go with. But when Steve Jobs left Apple and started Next, this computer did just seem like one of those amazing things from the future where it had all of this cool stuff in it.</p><p>And we were still back in those days working on DOS, everything blew up. You had reset buttons because your computer would just freeze if you're doing development work, literally dozens of times a day, your computer was just rebooting constantly. And so this idea of, yes, any of the Unix workstations would have given a stable development platform where you don't crash and reboot all the time.</p><p>But Next also had this really amazing graphical interface and it was great for building tools. And it used Objective-C as the kind of an interesting- - Oh, wow. - Yeah, dead end for things like that. - So Next was Unix based, it said Objective-C. So it has a lot of the elements- - That became Mac.</p><p>I mean, the kind of reverse acquisition of Apple by Next, where that took over and became what the modern Mac system is. - And define some of the developer, like the tools and the whole community. - Yeah, you've still got, if you're programming on Apple stuff now, there's still all these NS somethings, which was originally Next Step objects of different kinds of things.</p><p>But one of the aspects of those Unix systems was they had this notion of a .plan file, where a .file is an invisible file, usually in your home directory or something. And there was a trivial server running on most Unix systems at the time, that when somebody ran a trivial little command called finger, you could do a finger and then somebody's address, it could be anywhere on the internet if you were connected correctly.</p><p>Then all that server would do was read the .plan file in that user's home directory and then just spit it out to you. And originally the idea was that could be whether you're on vacation, what your current project was, it's supposed to be like the plan of what you're doing.</p><p>And people would use it for various purposes, but all it did was dump that file over to the terminal of whoever issued the finger command. And at one point I started just keeping a list of what I was doing in there, which would be what I was working on in the day.</p><p>And I would have this little syntax I kind of got to myself about, here's something that I'm working on, I put a star when I finish it, I could have a few other little bits of punctuation. And at the time it started off as being just like my to-do list.</p><p>And it would be these trivial, obscure little things like I fixed something with collision detection code, made fireball do something different and just little one-liners that people that were following the games could kind of decipher. But I did wind up starting to write much more in-depth things. I would have little notes of thoughts and insights and then I would eventually start having little essays I would sometimes dump into the .plan files interspersed with the work logs of things that I was doing.</p><p>So in some ways it was like a super early proto blog where I was just kind of dumping out what I was working on, but it was interesting enough that there were a lot of people that were interested in this. So most of the people didn't have Unix workstation, so there were the websites back in the day that would follow the Doom and Quake development that would basically make a little service that would go grab all the changes and then people could just get it with a web browser.</p><p>And there was a period where like all of the little kind of Dallas gaming diaspora of people that were at all in that orbit, there were a couple dozen .plan files going on, which was, and this was some years before blogging really became kind of a thing. And it was kind of a premonition of sort of the way things would go.</p><p>And there was, it's all been collected, it's available online in different places and it's kind of fun to go back and look through what I was thinking, what I was doing in the different areas. - Have you had a chance to look back? Is there some interesting, very low level specific to do items, maybe things you've never completed, all that kind of stuff and high level philosophical essay type of stuff?</p><p>- Yeah, there's some good stuff on both where a lot of it was low level nitpicky details about game dev and I've learned enough things where there's no project that I worked on that I couldn't go back and do a better job on now. I mean, you just, you learn things, hopefully if you're doing it right, you learn things as you get older and you should be able to do a better job at all of the early things.</p><p>And there's stuff in Wolfenstein, Doom, Quake, that's like, oh, clearly I could go back and do a better job at this, whether it's something in the rendering engine side or how I implemented the monster behaviors or managed resources or anything like that. - Do you see the flaws in your thinking now?</p><p>- Yeah. - Like looking back? - Yeah, I do. I mean, sometimes I'll get the, I'll look at it and say, yeah, I had a pretty clear view of I was doing good work there and I haven't really hit the point where there was another programmer, Graham Devine, who was, he had worked at Id and Seventh Guest and he made some comment one time where he said he looked back at some of his old notes and he was like, wow, I was really smart back then.</p><p>And I don't hit that so much where, I mean, I look at it and I always know that, yeah, there's all the, with aging, you get certain changes in how you're able to work problems, but all of the problems that I've worked, I'm sure that I could do a better job on all of them.</p><p>- Oh, wow. So you can still step right in. If you could travel back in time and talk to that guy, you would teach him a few things. - Yeah, absolutely. (laughing) - That's awesome. What about the high level philosophical stuff? Is there some insights that stand out that you remember?</p><p>- There's things that I was understanding about development and I'm in the industry and so on that were in a more primitive stage where I definitely learned a lot more in the later years about business and organization and team structure. There were, I mean, there were definitely things that I was not the best person or even a very good person about managing like how a team should operate internally, how people should work together.</p><p>I was just, you know, just get out of my way and let me work on the code and do this. And more and more, I've learned how, in the larger scheme of things, how sometimes relatively unimportant some of those things are, where it is this user value generation that's the overarching importance for all of that.</p><p>And I didn't necessarily have my eye on that ball correctly through a lot of my earlier years. And there's things that, you know, I could have gotten more out of people handling things in different ways. I could have made, you know, in some ways more successful products by following things in different ways.</p><p>There's mistakes that we've made that we couldn't really have known how things would have worked out, but it was interesting to see in later years, companies like Activision showing that, hey, you really can just do the same game, make it better every year. And you can look at that from a negative standpoint and say, it's like, oh, that's just being derivative and all that.</p><p>But if you step back again and say, it's like, no, are the people buying it still enjoying it? Are they enjoying it more than what they might have bought otherwise? And you can say, no, that's actually a great value creation engine to do that if you're in a position where you can.</p><p>I, you know, don't be forced into reinventing everything just because you think that you need to. I'm, you know, lots of things about business and team stuff that could be done better. But the technical work, the kind of technical visionary type stuff that I laid out, I still feel pretty good about.</p><p>There are some classic old ones about my defending of OpenGL versus D3D, which turned out to be one of the more probably important momentous things there, where it never-- it was always a rearguard action on Windows, where Microsoft was just not going to let that win. But when I look back on it now, that fight to keep OpenGL relevant for a number of years there meant that OpenGL was there when mobile started happening.</p><p>And OpenGL ES was the thing that drove all of the acceleration of the mobile industry. And it's really only in the last few years, as Apple's moved to Metal and some of the other companies have moved to Vulkan, that that's moved away. But really stepping back and looking at it, it's like, yeah, I sold tens of millions of games for different things.</p><p>But billions and billions of devices wound up with an appropriate, capable graphics API due in no small part to me thinking that that was really important, that we not just give up and use Microsoft's, at that time, really terrible API. The thing about Microsoft is the APIs don't stay terrible.</p><p>They were terrible at the start. But a few versions on, they were actually quite good. And there was a completely fair argument to be made that by the time DX9 was out, it was probably a better programming environment than OpenGL. But it was still a wonderful, good thing that we had an open standard that could show up on Linux and Android and iOS, eventually WebGL still to this day.</p><p>So that would be on my greatest hits list of things that I kind of pushed with-- - In terms of impact it had on billions of devices, yes. So let's talk about it. Can you tell the origin story of id Software? Again, one of the greatest game developer companies ever.</p><p>It created Wolfenstein 3D, games that define my life also in many ways. As a thing that made me realize what computers are capable of in terms of graphics, in terms of performance. It just unlocks something deep in me and understanding what these machines are all about. Those games can do that.</p><p>So Wolfenstein 3D, Doom, Quake, and just all the incredible engineering innovation that went into that. So how did it all start? - So I'll caveat up front that I usually don't consider myself the historian of the software side of things. I usually do kind of point people at John Romero for stories about the early days where I've never been-- like I've commented that I'm a remarkably unsentimental person in some ways where I don't really spend a lot of time unless I'm explicitly prodded to go back and think about the early days of things.</p><p>And I didn't necessarily make the effort to archive everything exactly in my brain. And the more that I work on machine learning and AI and the aspects of memory and how when you go back and polish certain things, it's not necessarily exactly the way it happened. But having said all of that, from my view, the way everything happened that led up to that was after I was an adult and kind of taking a few college classes and deciding to drop out, I was doing-- I was hardscrabble contract programming work, really struggling to kind of keep groceries and pay my rent and things.</p><p>And the company that I was doing the most work for was a company called Softdisk Publishing, which had the Sounds Bizarre Now business model of monthly subscription software. Before, there was an internet that people could connect to and get software. You would pay a certain amount. And every month, they would send you a disk that had some random software on it.</p><p>And people that were into computers thought this was kind of cool. And they had different ones for the Apple II, the 2GS, the PC, the Mac, the Amiga, lots of different things here. So quirky little business. But I was doing a lot of contract programming for them where I'd write tiny little games and sell them for $300, $500.</p><p>And one of the things that I was doing, again, to keep my head above water here, was I decided that I could make one program and I could port it to multiple systems. So I would write a game like Dark Designs or Catacombs. And I would develop it on the Apple II, the 2GS, and the IBM PC, which apparently was the thing that really kind of piqued the attention of the people working down there.</p><p>Like, Jay Wilber was my primary editor. And Tom Hall was a secondary editor. And they kept asking me, it's like, hey, you should come down and work for us here. And I pushed it off a couple of times because I was really enjoying my freedom of kind of being off on my own, even if I was barely getting by.</p><p>I loved it. I was doing nothing but programming all day. But I did have enough close scrapes with, like, damn, I'm just really out of money, that maybe I should get an actual job rather than contracting these kind of one-at-a-time things. And Jay Wilber was great. He was like FedExing me the checks when I would need them to kind of get over whatever hump I was at.</p><p>So I finally took them up on their offer to come down to Shreveport, Louisiana. I was in Kansas City at the time. Drove down through the Ozarks and everything down to Louisiana and saw the Softdisk offices, went through, talked to a bunch of people, met the people I had been working with remotely at that time.</p><p>But the most important thing for me was I met two programmers there, John Romero and Lane Roth, that for the first time ever, I had met programmers that knew more cool stuff than I did, where the world was just different back then. I was in Kansas City. It was one of those smartest kid in the school, does all the computer stuff.</p><p>The teachers don't have anything to teach him. But all I had to learn from was these few books at the library. It was not much at all. And there were some aspects of programming that were kind of black magic to me. It's like, oh, he knows how to format a track on a low level drive programming interface.</p><p>And I was still not at all sure I was going to take the job. But I met these awesome programmers that were doing cool stuff. And Romero had worked at Origin Systems. And he had done so many different games ahead of time that I did kind of quickly decide, yeah, I'll go take the job down there.</p><p>And I settled down there, moved in, and started working on more little projects. And the first kind of big change that happened down there was the company wanted to make a gaming-focused, a PC gaming focused subscription. Just like all their others, the same formula that they used for everything.</p><p>Pay a monthly fee, and you'll get a disc with one or two games just every month. And no choice in what you get, but we think it'll be fun. And that was the model they were comfortable with. And they said, all right, we're going to start this gamers edge department.</p><p>And all of us that were interested in that, like me, Romero, Tom Hall was kind of helping us from his side of things. Jay would peek in. And we had a few other programmers working with us at the time. And we were going to just start making games, just the same model.</p><p>And we dived in, and it was fantastic. So you had to make new games-- Every month. --every month. Yeah. And this, in retrospect, looking back at it, that sense that I had done all this contract programming, and John Romero had done far more of this, where he had done-- one of his teaching himself efforts was he made a game for every letter of the alphabet.</p><p>It's that sense of, I'm just going to go make 26 different games, give them a different theme. And you learn so much when you go through and you crank these things out on a biweekly, monthly basis, something like that. From start to finish. So it's not just an idea.</p><p>It's not just from the very beginning to the very end. It's done. It has to be done. There's no delaying. It's done. And you've got deadlines. And that kind of rapid iteration, pressure cooker environment was super important for all of us developing the skills that brought us to where we eventually went to.</p><p>I mean, people would say, like, in the history of the Beatles, it wasn't them being the Beatles. It was them playing all of these other early works, that that opportunity to craft all of their skills before they were famous, that was very critical to their later successes. And I think there's a lot of that here, where we did these games that nobody remembers, lots of little things that contributed to building up the skill set for the things that eventually did make us famous.</p><p>And Dostoevsky wrote The Gambler. I had to write it in a month just to make money. And nobody remembers that probably, because he had to figure out-- because it's literally-- he didn't have enough time to write it fast enough. So he had to come up with hacks to actually literally write it fast enough within a month.</p><p>It comes down to that point where pressure and limitation of resources is surprisingly important. And it's counterintuitive in a lot of ways, where you just think that if you've got all the time in the world, and you've got all the resources in the world, of course you're going to get something better.</p><p>But sometimes it really does work out that the innovations, mother necessity, where you can-- or resource constraints, and you have to do things. When you don't have a choice, it's surprising what you can do. Is there any good games written in that time? Would you say-- Some of them are still fun to go back and play, where you get the-- they were all about-- the more modern term is game feel, about how just the exact feel that things-- it's not the grand strategy of the design, but how running, and jumping, and shooting, and those things I feel in the moment.</p><p>And some of those are still-- if you sat down on them, you kind of go, it's a little bit different. It doesn't have the same movement feel, but you move over, and you're like, bang, jump, bang. It's like, hey, that's kind of cool still. So you can get lost in the rhythm of the game.</p><p>Is that what you mean by feel? Just like there's something about it that pulls you in? Nowadays, again, people talk about compulsion loops and things, where it's that sense of exactly what you're doing, what your fingers are doing on the keyboard, what your eyes are seeing. And there are going to be these sequences of things.</p><p>Grab the loot, shoot the monster, jump over the obstacle, get to the end of the level. These are eternal aspects of game design in a lot of ways. But there are better and worse ways to do all of them. And we did so many of these games that we got a lot of practice with it.</p><p>So one of the kind of weird things that was happening at this time is John Romero was getting some strange fan mail. And back in the days, this was before email. So we literally got letters sometimes. And telling him, it's like, oh, I want to talk to you about your games.</p><p>I want to reach out, different things. And eventually, it turned out that these were all coming from Scott Miller at Apogee Software. And he was reaching out through-- he didn't think he could contact John directly, that he would get intercepted. So he was trying to get him to contact him through back channel fan mail.</p><p>Because he basically was saying, hey, I'm making all this money on shareware games. I want you to make shareware games. Because he had seen some of the games that Romero had done. And we looked at Scott Miller's games. And we didn't think they were very good. We're like, that can't be making the kind of money that he's saying he's making $10,000 or something off of this game.</p><p>And we really thought that he was full of shit, that it was a lie trying to get him into this. So that was kind of going on at one level. And it was funny the moment when Romero realized that he had some of these letters pinned up on his wall of all of his fans.</p><p>And then we noticed that they all had the same return address with different names on them, which was a little bit of a two-edged sword there. Trying to figure out the puzzle laid out before him. Yeah, what happened after I kind of coincident with that was I was working on a lot of the new technologies, where I was now full on the IBM PC for the first time, where I was really a long holdout on Apple II forever.</p><p>And I loved my Apple II. It was the computer I always wished I had when I was growing up. And when I finally did have one, I was kind of clinging on to that well past its sort of good use by date. Was it the best computer ever made, you would say?</p><p>I wouldn't make judgments like that about it. But it was positioned in such a way, especially in the school systems, that it impacted a whole lot of American programmers, at least, where there was programs that the Apple IIs got into the schools. And they had enough capability that lots of interesting things happened with them.</p><p>In Europe, it was different. You had your Amigas and Ataris. And you know, acorns in the UK and things that had different things. But in the United States, it was probably the Apple II made the most impact for a lot of programmers of my generation. But so I was really digging into the IBM.</p><p>And this was even more so with the Total Focus, because I had moved to another city where I didn't know anybody that I wasn't working with. I had a little apartment. And then at Softdisk, again, the things that drew me to it, I had a couple programmers that knew more than I did.</p><p>And they had a library. They had a set of books and a set of magazines. They had a couple years of magazines, the old Dr. Dobbs Journal and all of these magazines that had information about things. And so I was just in total immersion mode. It was eat, breathe, sleep, computer programming, particularly the IBM, for everything that I was doing.</p><p>And I was digging into a lot of these low-level hardware details that people weren't usually paying attention to, the way the IBM EGA cards worked, which was fun for me. I hadn't had experience with things at that level. And back then, you could get hardware documentation just down at the register levels.</p><p>This is where the CRTC register is. This is how the color registers work and how the different things are applied. And they were designed for a certain reason. They were designed for an application. They had an intended use in mind. But I was starting to look at other ways that they could perhaps be exploited that they weren't initially intended for.</p><p>Because you comment on, first of all, what operating system was there? What instruction set was it? Like, what are we talking about? So this was DOS and x86, so 16-bit 8086. The 286s were there. And 386s existed. They were rare. We had a couple for our development systems. But we were still targeting the more broad-- it was all DOS 16-bit.</p><p>None of this was kind of DOS extenders and things. How different is it from the systems of today? Is it kind of a precursor that's similar? Very little. If you open up command.exe or com on Windows, you see some of the remnants of all of that. But it was a different world.</p><p>It was the 640k is enough world. And nothing was protected. It crashed all the time. You had TSRs or terminate and stay resident hacks on top of things that would cause configuration problems. All the hardware was manually configured in your auto exec. So it was a very different world.</p><p>But the code is still the same, similar. You could still write it. My earliest code there was written in Pascal. That was what I had learned at an earlier point. So between BASIC and C++, there was Pascal. So when BASIC assembly language-- Some of my-- Take a step back.</p><p>Yeah, my intermediate stuff was-- well, you had to for performance. BASIC was just too slow. So most of the work that I was doing as a contract programmer in my teenage years was assembly language. Wait, you wrote games in assembly? Yeah, complete games in assembly language. And it's thousands and thousands of lines of three-letter acronyms for the instructions.</p><p>You don't earn the once again greatest programmer ever label without being able to write a game in assembly. OK. That's good. Everybody serious wrote their games in assembly language. It was kind of a-- Everybody serious. See what he said? Everybody serious. It was an outlier to use Pascal a little bit, where there was one famous program called Wizardry.</p><p>It was like one of the great early role-playing games that was written in Pascal. But it was almost nothing used Pascal there. But I did learn Pascal. And I remember doing all of my-- like to this day, I sketch in data structures. When I'm thinking about something, I'll open up a file, and I'll start writing struct definitions for how data is going to be laid out.</p><p>And Pascal was kind of formative to that, because I remember designing my RPGs in Pascal record structures and things like that. And so I had gotten a Pascal compiler for the Apple IIGS that I could work on. And the first IBM game that I developed, I did in Pascal.</p><p>And that's actually kind of an interesting story, again, talking about the constraints and resources, where I had an Apple IIGS. I didn't have an IBM PC. I wanted to port my applications to IBM, because I thought I could make more money on it. So what I wound up doing is I rented a PC for a week and bought a copy of Turbo Pascal.</p><p>And so I had a hard one week. And this was cutting into what minimal profit margin I had there. But I had this computer for a week. I had to get my program ported before I had to return the PC. And that was kind of the first thing that I had done on the IBM PC and what led me to taking the job at Softdisk.</p><p>And Turbo Pascal, how is that different from regular Pascal? Is it a different compiler or something like that? So it was a product of Borland, which before Microsoft kind of killed them, they were the hot stuff developer tools company. You had Borland, Turbo Pascal, and Turbo C, and Turbo Prolog.</p><p>I mean, all the different things. But what they did was they took a supremely pragmatic approach of making something useful. It was one of these great examples where Pascal was an academic language. And you had things like the UCSDP system that Wizardry was actually written in, that they did manage to make a game with that.</p><p>But it was not a super practical system. While Turbo Pascal was-- it was called Turbo because it was blazingly fast to compile. I mean, really ridiculously 10 to 20 times faster than most other compilers at the time. But it also had very pragmatic access to, look, you can just poke at the hardware in these different ways.</p><p>And we have libraries that let you do things. And it was a pretty good-- it was a perfectly good way to write games. And this is one of those things where people have talked about different paths that computer development could have taken, where C took over the world for reasons that came out of Unix and eventually Linux.</p><p>And that was not a foregone conclusion at all. And people can make real reasoned rational arguments that the world might have been better if it had gone a Pascal route. I'm somewhat agnostic on that, where I do know from experience it was perfectly good enough to do that. And it had some fundamental improvements, like it had range-checked arrays as an option there, which could avoid many of C's real hazards that happened in a security space.</p><p>But C1, they were basically operating in about the same level of abstraction. It was a systems programming language. But you said Pascal had more emphasis on data structures. Actually, in the tree of languages, did Pascal come before C? Did it inspire a lot of-- They were pretty contemporaneous. So Pascal's lineage went to Modula 2 and eventually Oberon, which was another Nicholas word, kind of experimental language.</p><p>But they were all good enough at that level. Now, some of the classic academic-oriented Pascals were just missing fundamental things, like, oh, you can't access this core system thing, because we're just using it to teach students. But Turbo Pascal showed that only modest changes to it really did make it a completely capable language.</p><p>And it had some reasons why you could implement it as a single-pass compiler. So it could be way, way faster, although less scope for optimizations if you do it that way. And it did have some range-checking options. It had a little bit better typing capability. You'd have properly typed enums, sorts of things, and other stuff that C lacked.</p><p>But C was also clearly good enough. And it wound up with a huge inertia from the Unix ecosystem and everything that came with that. And Pascal didn't have garbage collection? No, it was not garbage collected. It was the same kind of thing as C. Same manual. So you could still have your use-after-freeze and all those other problems.</p><p>But just getting rid of array overruns, at least if you were compiled with that debugging option, certainly would have avoided a lot of problems and could have a lot of benefits. But so anyways, that was the next thing. I had to learn C, because C was where it seemed like most of the things were going.</p><p>So I abandoned Pascal, and I started working in C. I started hacking on these hardware things, dealing with the graphics controllers and the EGA systems. And what we most wanted to do-- so at that time, we were sitting in our darkened office, playing all the different console video games.</p><p>We were figuring out, what games do we want to make for our gamers edge product there? And so we had one of the first Super Nintendos sitting there. And we had an older Nintendo. And we were looking at all those games. And the core thing that those consoles did that you just didn't get on the PC games was this ability to have a massive scrolling world, where most of the games that you would make on the PC and earlier personal computers would be a static screen.</p><p>You move little things around on it, and you interact like that. Maybe you go to additional screens as you move. But arcade games and consoles had this wonderful ability to just have a big world that you're slowly moving your window through. And that was, for those types of games, that kind of action exploration adventure games, that was a super, super important thing.</p><p>And PC games just didn't do that. And what I had come across was a couple different techniques for implementing that on the PC. And they're not hard, complicated things. When I explain them now, they're pretty straightforward. But just nobody was doing-- You sound like Einstein describing his five papers.</p><p>It's pretty straightforward. I understand. But they're nevertheless revolutionary. So side-scrolling is a game changer. Yeah, and scrolling is-- It's a genius invention. --whether it's side or vertical. And some of the consoles had different limitations about you could do one but not the other. And there were similar things going on as advancements, even in the console space, where you'd have-- like the original Mario game was just horizontal scrolling.</p><p>And then later Mario games added vertical aspects to it and different things that you were doing to explore, kind of expand the capabilities there. And so much of the early game design for decades was removing limitations, letting you do things that you envisioned as a designer, you wanted the player to experience, but the hardware just couldn't really-- or you didn't know how to make it happen.</p><p>It felt impossible. You can imagine that you want to create this big world through which you can side-scroll, like through which you can walk. And then you ask yourself a question, how do I actually build that in a way that's-- like the latency is low enough, the hardware can actually deliver that in such a way that it's a compelling experience.</p><p>Yeah, and we knew what we wanted to do because we were playing all of these console games, playing all these Nintendo games and arcade games. Clearly, there is a whole world of awesome things there that we just couldn't do on the PC, at least initially. Because every programmer can tell, it's like if you want to scroll, you can just redraw the whole screen.</p><p>But then it turns out, well, you're going five frames per second. That's not an interactive, fun experience. You want to be going 30 or 60 frames per second or something. And it just didn't feel like that was possible. It felt like the PCs had to get five times faster for you to make a playable game there.</p><p>And interestingly, I wound up with two completely different solutions for the scrolling problem. And this is a theme that runs through everything, where all of these big technical advancements, it turns out there's always a couple different ways of doing them. And it's not like you found the one true way of doing it.</p><p>And we'll see this as we go into 3D games and things later. But so the scrolling, the first set of scrolling tricks that I got was, the hardware had this ability to-- you could shift inside the window of memory. So the EGA cards at the time had 256 kilobytes of memory.</p><p>And it was awkwardly set up in this planar format, where instead of having 256 or 24 million colors, you had 16 colors, which is four bits. So you had four bit planes, 64k a piece. Of course, 64k is a nice round number for 16-bit addressing. So your graphics card had a 16-bit window that you could look at.</p><p>And you could tell it to start the video scan out anywhere inside there. So there were a couple games that had taken this approach. If you could make a 2 by 2 screen or a 1 by 4 screen, and you could do scrolling really easily like that. You could just lay it all out and just pan around there.</p><p>But you just couldn't make it any bigger, because that's all the memory that was there. The first insight to the scrolling that I had was, well, if we make a screen that's just one tile larger-- we usually had tiles that were 16 pixels by 16 pixels, the little classic Mario block that you run into.</p><p>Lots of art gets drawn that way. And your screen is a certain number of tiles. But if you had one little buffer region outside of that, you could easily pan around inside that 16-pixel region. That could be perfectly smooth. But then what happens if you get to the edge and you want to keep going?</p><p>The first way we did scrolling was what I called adaptive tile refresh, which was really just a matter of you get to the edge, and then you go back to the original point, and then only change the tiles that have actually-- that are different between where it was. In most of the games at the time, if you think about your classic Super Mario Brothers game, you've got big fields of blue sky, long rows of the same brick texture.</p><p>And there's a lot of commonality. It's kind of like a data compression thing. If you take the screen and you set it down on top of each other, in general, only about 10% of the tiles were actually different there. So this was a way to go ahead and say, well, I'm going to move it back, and then I'm only going to change those 10%, 20%, whatever percent tiles there.</p><p>And that meant that it was essentially five times faster than if you were redrawing all of the tiles. And that worked well enough for us to do a bunch of these games for Gamer's Edge. We had a lot of these scrolling games, like Slordax and Shadow Knights and things like that, that we were cranking out at this high rate that had this scrolling effect on it.</p><p>And it worked well enough. There were design challenges there where, if you made-- the worst case, if you made a checkerboard over the entire screen, you scroll over one, and every single tile changes, and your frame rate's now five frames per second because it had to redraw everything. So the designers had a little bit that they had to worry about.</p><p>They had to make these relatively plain-looking levels. But it was still pretty magical. It was something that we hadn't seen before. And the first thing that we wound up doing with that was I had just gotten this working, and Tom Hall was sitting there with me. And we were looking over at our Super Nintendo on the side there with Super Mario 3 running.</p><p>And we had the technology. We had the tools set up there. And we stayed up all night. And we basically cloned the first level of Super Mario Brothers. Performance-wise as well? Yeah. And we had our little character running and jumping in there. It was close to pixel accurate as far as all the backgrounds and everything.</p><p>But the gaming was just stuff that we cobbled together from previous games that I had written. I just really kit bashed the whole thing together to make this demo. And that was one of the rare cases when I said I don't usually do these all-night programming things. There's probably only two memorable ones that I can think about.</p><p>One was the all-nighter to go ahead and get our Dangerous Dave and Copyright Infringement, is how we titled it. Because we had a game called Dangerous Dave, which was running around with a shotgun shooting things. And we were just taking our most beloved game at the time there, Super Mario 3, and sort of sticking Dave inside that with this new scrolling technology that was going perfectly smooth for them as it ran.</p><p>And Tom and I just kind of blearily the next morning kind of left. And we left a disk on the desk for John Romero and Jay Wilbur to see and just said, run this. And we eventually made it back in later in the day. And it was like they grabbed us and pulled us into the room.</p><p>And that was the point where they were like, we got to do something with this. We're going to make a company. We're going to go make our own games, where this was something that we were able to just kind of hit them with a hammer of an experience. Like, wow, this is just so much cooler than what we thought was possible there.</p><p>And initially, we tried to get Nintendo to let us make Super Mario 3 on the PC. That's really what we wanted to do. We were like, hey, we can finish this. It's line of sight for this will be great. And we sent something to Nintendo. And we heard that it did get looked at in Japan.</p><p>And they just weren't interested in that. But that's another one of those, life could have gone a very different way, where we could have been like Nintendo's house PC team at that point. And define the direction of Wolfenstein and Doom and Quake could have been a Nintendo creation. Yeah.</p><p>So at the same time that we were just doing our first scrolling demos, we reached out to Scott Miller at Apogee and said, it's like, hey, we do want to make some games. These things that you think you want, those are nothing. What do you see what we can actually do now?</p><p>This is going to be amazing. And he just popped right up and sent a check to us, where at that point, we still thought he might be a fraud, that he was just lying about all of this. But he was totally correct on how much money he was making with his shareware titles.</p><p>And this was his kind of real brainstorm about this, where shareware was this idea that software doesn't have a fixed price. If you use it, you send, out of the goodness of your heart, some money to the creator. And there were a couple utilities that did make some significant success like that.</p><p>But for the most part, it didn't really work. There wasn't much software in a pure shareware model that was successful. The Apogee innovation was to take something, call it shareware, split it into three pieces. You always made a trilogy. And you would put the first piece out. But then you buy the whole trilogy for some shareware amount, which in reality, it meant that the first part was a demo, where you kind of like, the demo went everywhere for free.</p><p>And you paid money to get the whole set. But it was still played as shareware. And we were happy to have the first one go everywhere. And it wasn't a crippled demo, where the first episode of all of these trilogies, it was a real complete game. And probably 20 times as many people played that part of it, thought they had a great game, had fond memories of it, but never paid us a dime.</p><p>But enough people were happy with that, where it was really quite successful. And these early games that we didn't think very much of compared to commercial quality games, but they were doing really good business, some fairly crude things. And people-- it was good business. People enjoyed it. And it wasn't like you were taking a crap shoot on what you were getting.</p><p>You just played a third of the experience. And you loved it enough to handwrite out a check and put it in an envelope and address it and send it out to Apogee to get the rest of them. So it was a really pretty feel-good business prospect there, because everybody was happy.</p><p>They knew what they were getting when they sent it in. And they would send in fan mail. If you're going to the trouble of addressing a letter and filling out an envelope, you write something in it. And there were just the literal bags of fan mail for the Shareware games.</p><p>So people loved them. - I should mention that for you, the definition of wealth is being able to have pizza whenever you want. For me, there was a dream, 'cause I would play Shareware games over and over, the part that's free, over and over. And it was very deeply fulfilling experience.</p><p>But I dreamed of a time when I could actually afford the full experience. And this is kind of this dreamland beyond the horizon, when you could find out what else is there. In some sense, even just playing the Shareware was, it's the limitation of that. Life is limited. Eventually we all die.</p><p>In that way, Shareware was somehow really fulfilling to have this kind of mysterious thing beyond what's free, always there. It's kind of, I don't know. That was, maybe it's because a part of my childhood is playing Shareware games. That was a really fulfilling experience. It's so interesting how that model still brought joy to so many people, the 20X people that played it.</p><p>- I felt very good about that. I would run into people that would say, "Oh, I loved that game that you had early on, Commander Keen, whatever." And no, they meant just the first episode that they got to see everywhere. - That's me, I played the crap out of Commander Keen.</p><p>That was all good. - Yeah, yeah. - But so we were in this position where Scott Miller was just fronting us cash and saying, "Yeah, make a game." But we did not properly pull the trigger and say, "All right, we're quitting our jobs." We were like, "We're gonna do both.</p><p>We're gonna keep working at Softdisk, working on this. And then we're going to go ahead and make a new game for Apogee at the same time." And this eventually did lead to some legal problems. And we had trouble, it all got worked out in the end, but it was not a good call at the time there.</p><p>- And your legal mind at the time was not stellar. You were not thinking in legal terms. - No, I definitely wasn't, none of us were. And in hindsight, yeah, it's like, how did we think we were gonna get away with like even using our work computers to write software for our breakaway new company?</p><p>It was not a good plan. - How did Commander Keen come to be? - So the design process, we would start from, we had some idea of what we wanted to do. We wanted to do a Mario-like game. It was gonna be a side scroller. It was gonna use the technology.</p><p>We had some sense of what it would have to look like because of the limitations of this adaptive tile refresh technology. It had to have fields of relatively constant tiles. You couldn't just paint up a background and then move that around. The early design or all the design for Commander Keen really came from Tom Hall, where he was kind of the main creative mind for the early id software stuff, where we had an interesting division of things where Tom was all creative and design.</p><p>I was all programming. John Romero was an interesting bridge where he was both a very good programmer and also a very good designer and artist and kind of straddled between the areas. But Commander Keen was very much Tom Hall's baby. And he came up with all the design and backstory for the different things of kind of a mad scientist little kid with, you know, building a rocket ship and a zap gun and visiting alien worlds and doing all of this, the background that we lay the game inside of.</p><p>And there's not a whole lot to any of these things. You know, design for us was always just what we needed to do to make the game that was gonna be so much fun to play. And we laid out our first trilogy of games, you know, the shareware formula.</p><p>It was gonna be three pieces. We make Commander Keen 1, 2, and 3. And we just really started busting on all that work. And it went together really quickly. It was like three months or something that while we were still making games every month for Gamers Edge, we were sharing technology between that.</p><p>I'd write a bunch of code for this, and we'd just kind of use it for both. Again, not a particularly good idea there that had consequences for us. But in three months, we got our first game out, and all of a sudden, it was three times as successful as the most successful thing Apogee had had before.</p><p>And we were making like $30,000 a month immediately from the Commander Keen stuff. And that was, again, a surprise to us. It was more than we thought that was gonna make. And we said, "Well, we're gonna certainly roll into another set of titles from this." And in that three months, I had come up with a much better way of doing the scrolling technology that was not the adaptive tile refresh, which in some ways was even simpler.</p><p>And these things, so many of the great ideas of technology are things that are back-of-the-envelope designs. I make this comment about modern machine learning where all the things that are really important practically in the last decade are, each of them fits on the back of an envelope. There are these simple little things.</p><p>They're not super dense, hard-to-understand technologies. And so the second scrolling trick was just a matter of like, "Okay, we know we've got this 64K window." And the question was always like, "Well, you could make a two-by-two, but you can't go off the edge." But I finally asked, "Well, what actually happens if you just go off the edge?" If you take your start and you say, it's like, "Okay, I can move over.</p><p>I'm scrolling. I can move over. I can move down. I'm scrolling." I get to what should be the bottom of the memory window. It's like, "Well, what if I just keep going?" And I say, "I'm going to start at, you know, what happens if I start at FFFE at the very end of the 64K block?" And it turns out it just wraps back around to the top of the block.</p><p>And I'm like, "Oh, well, this makes everything easy. You can just scroll the screen everywhere, and all you have to draw is just one new line of tiles, whichever thing you expose. It might be unaligned off various parts of the screen memory, but it just works." That no longer had the problem of you had to have fields of the similar colors because it doesn't matter what you're doing.</p><p>You could be having a completely unique world, and you're just drawing the new strip as it comes on. - But it might be, like you said, unaligned, so it can be all over the place. - Yeah, and it turns out it doesn't matter. I would have two page-flipped screens.</p><p>As long as they didn't overlap, they moved in series through this two-dimensional window of graphics, and that was one of those, like, "Well, this is so simple. This just works. It's faster. It seemed like there was no downside." Funny thing was, it turned out, after we shipped titles with this, there were what they called "super VGA cards," the cards that would allow higher resolutions and different features that the standard ones didn't.</p><p>And on some of those cards, this was a weird compatibility quirk, again, because nobody thought this was not what it was designed to do. And some of those cards had more memory. They had more than just 256K in four planes. They had 512K or a megabyte. And on some of those cards, I scroll my window down, and then it goes into uninitialized memory that actually exists there, rather than wrapping back around to the top.</p><p>And then I was in the tough position of, "Do I have to track every single one of these?" And it was a madhouse back then with -- There were 20 different video card vendors with all slightly different implementations of their nonstandard functionality. So either I needed to natively program all of the VGA cards there to map in that memory and keep scrolling down through all of that, or I kind of punted and took the easy solution of, when you finally did run to the edge of the screen, I accepted a hitch and just copied the whole screen up there.</p><p>So on some of those cards, it was a compatibility mode. In the normal ones, when it all worked fine, everything was just beautifully smooth. But if you had one of those cards where it did not wrap the way I wanted it to, you'd be scrolling around, scrolling around, and then eventually you'd have a little hitch where 200 milliseconds or something that was not super smooth.</p><p>- Yeah, it froze a little bit. And so it's the binary thing. Is it one of the standard screens or is it one of the weird ones, the super VGA ones? - Yeah. - Okay. - And so we would default to -- And I think that was one of those that changed over the kind of course of deployment, where early on, we would have a normal mode, and then you would enable the compatibility flag if your screen did this crazy flickery thing when you got to a certain point in the game.</p><p>And then later, I think it probably got enabled by default as just more and more of the cards kind of did not do exactly the right thing. And that's the two-edged sword of doing unconventional things with technology, where you can find something that nobody thought about doing that kind of scrolling trick when they set up those cards.</p><p>But the fact that nobody thought that was the primary reason when I was relying on that, then I wound up being broken on some of the later cards. - Let me take a bit of a tangent, but ask you about the hacker ethic, 'cause you mentioned shareware. It's an interesting world, the world of people that make money, the business and the people that build systems, the engineers.</p><p>And what is the hacker ethic? You've been a man of the people and you've embodied at least the part of that ethic. What does it mean? What did it mean to you at the time? What does it mean to you today? - So, Stephen Levy's book "Hackers" was a really formative book for me as a teenager.</p><p>I mean, I read it several times and there was all of the great lore of the early MIT era of hackers and you ending up at the end with, it kind of went through the early MIT hackers and then the Silicon Valley hardware hackers and then the game hackers in part three.</p><p>And at that time as a teenager, I really was kind of bitter in some ways, like I thought I was born too late. I thought I missed the window there. And I really thought I belonged in that third section of that book with the game hackers. And they were talking about the Williams at Sierra and origin systems with Richard Garriott.</p><p>And it's like, I really wanted to be there. And I knew that was now a few years in the past. It was, you know, it was not to be. But the early days, especially the early MIT hacker days, talking a lot about this sense of the hacker ethic, that there was this sense that it was about sharing information, being good, not keeping it to yourself, and that it's not a zero-sum game, that you can share something with another programmer and it doesn't take it away from you.</p><p>You know, you then have somebody else doing something. And I also think that there's an aspect of it where it's this ability to take joy in other people's accomplishments, where it's not the cutthroat bit of like, I have to be first, I have to be recognized as the one that did this in some way, but being able to see somebody else do something and say, holy shit, that's amazing, you know, and just taking joy in the ability of something amazing that somebody else does.</p><p>And the big thing that I was able to do through id Software was this ability to eventually release the source code for most of our, like, all of our really seminal game titles. And that was a, it was a stepping stone process where we were kind of surprised early on where people were able to hack the existing games.</p><p>And of course, I had experience with that. I remember hacking my copies of Ultima, so I'd give myself, you know, 999 gold and raise my levels and, you know, break out the sector editor. And so I was familiar with all of that. So it was just, it was with a smile when I started to see people doing that to our games.</p><p>I am, you know, making level editors for Commander Keen or hacking up Wolfenstein 3D. But I made the pitch internally that we should actually release our own tools for like what we did, what we used to create the games. And that was, you know, that was a little bit debatable about, well, you know, will this let other, will it give people a leg up?</p><p>It's always like, what's that going to mean for the competition? But the really hard pitch was to actually release the full source code for the games. And it was a balancing act with the other people inside the company where it's interesting how the programmers generally did get, certainly the people that I worked closely with, they did kind of get that hacker ethic bit where you wanted to share your code.</p><p>You were proud of it. You wanted other people to take it and do cool things with it. But interestingly, the broader game industry is a little more hesitant to embrace that than like the group of people that we happen to have at id Software where it was always a little interesting to me seeing how a lot of people in the game modding community were very possessive of their code.</p><p>They did not want to share their code. They wanted it to be theirs. It was their, you know, claim to fame. And that was much more like what we tended to see with artists where, you know, the artists understand something about credit and, you know, wanting it to be known as their work.</p><p>And a lot of the game programmers felt a little bit more like artists than like hacker programmers in that it was about building something that maybe felt more like art to them than the more tool-based and exploration-based kind of hacking culture side of things. - Yeah, it's so interesting that this kind of fear that credit will not be sufficiently attributed to you.</p><p>- And that's one of the things that I do bump into a lot because I try not to go... I mean, it's easy for me to say because so much credit is heaped on me for the id Software side of things. But when people come up and they want to pick a fight and say, "No, it's like that wasn't where first-person gaming came from." And you can point to, you know, you can point to some of like things on obscure titles that I was never aware of, or like the old Play-Doh systems, or, you know, each personal computer had something that was 3D-ish and moving around.</p><p>And I'm, you know, and I'm happy to say it's like, no, I mean, I saw Battlezone and Star Wars in the arcades. I had seen 3D graphics. I had seen all these things there. I'm standing on the shoulders of lots of other people, but sometimes these examples they pull out, it's like, "No, I didn't know that existed." I mean, I had never heard of that before then.</p><p>And that didn't contribute to what I made, but there's plenty of stuff that did. And, you know, I think there's good cases to be made that obviously Doom and Quake and Wolfenstein were formative examples for what, everything that came after that. But I don't feel the need to go fight and say, claim primacy or initial invention of anything like that.</p><p>But a lot of people do want to. - I think when you fight for the credit in that way, and it does go against the hacker ethic, you destroy something fundamental about the culture, about the community that builds cool stuff. I think credit ultimately, so I had this sort of, there's a famous wrestler in freestyle wrestling called Buvae Sarasatev.</p><p>And he always preached that you should just focus on the art of the wrestling and let people write your story however they want. The highest form of the art is just focusing on the art. And that is something about the hacker ethic is just focus on building cool stuff, sharing it with other cool people, and credit will get assigned correctly in the long arc of history.</p><p>- Yeah, and I generally think that's true. And you've got, there's some things, there's a graphics technique that got labeled CarMax reverse. I am literally named it. And it turned out that I wasn't the first person to figure that out. Most scientific things or mathematical things, you wind up, it's like, oh, this other person had actually done that somewhat before.</p><p>And then there's things that get attributed to me, like the inverse square root hack that I actually didn't do. I flat out, that wasn't me. And it's weird how the mimetic power of the internet, I cannot convince people of that. - You're like the Mark Twain of programming. Everything just gets attributed to you now, even though you've never sought the credit of things.</p><p>I mean, but part of the fact of the humility behind that is what attracts the attributions. Let's talk about a game, I mean, one of the greatest games ever made. I know you could talk about doing Quake and so on, but to me, Wolfenstein 3D was like, whoa. It blew my mind that a world like this could exist.</p><p>So how did Wolfenstein 3D come to be in terms of the programming, in terms of the design, in terms of some of the memorable technical challenges? And also actually just something you haven't mentioned, how did these ideas come to be inside your mind, the adaptive side-scrolling, the solutions to these technical challenges?</p><p>- So I usually can introspectively pull back pretty detailed accounts of how technology solutions and design choices on my part came to be, where technically we had done two games, 3D games like that before, where Hover Tank was the first one which had flat shaded walls, but did have the scaled enemies inside it.</p><p>And then Catacombs 3D, which had textured walls, scaled enemies, and some more functionality like the disappearing walls and some other stuff. But what's really interesting from a game development standpoint is those games, Catacombs 3D, Hover Tank, and Wolfenstein, they literally used the same code for a lot of the character behavior that a 2D game that I had made earlier called Catacombs did, where it was an overhead view game, kind of like Gauntlet.</p><p>You're running around and you can open up doors, pick up items, basic game stuff. And the thought was that this exact same game experience just presented in a different perspective. It could be literally the same game, just with a different view into it, would have a dramatically different impact on the players.</p><p>- So it wasn't a true 3D, you're saying that you could kind of fake it, you can like scale enemies, meaning things that are farther away, you can make them smaller. - So from the game was a 2D map, like all of our games use the same tool for creation.</p><p>We use the same map editor for creating Keen as Wolfenstein and Hover Tank and Catacombs and all this stuff. So the game was a 2D grid made out of blocks. And you could say, well, these are walls, these are where the enemies start, then they start moving around. And these early games like Catacombs, you played it strictly in a 2D view.</p><p>It was a scrolling 2D view, and that was kind of using an adaptive tile refresh at the time to be able to do something like that. And then the thought that these early games, all it did was take the same basic enemy logic, but instead of seeing it from the God's eye view on top, you were inside it and turning from side to side, yawing your view and moving forwards and backwards and side to side.</p><p>And it's a striking thing where you always talk about wanting to isolate and factor changes in values. And this was one of those most pure cases there where the rest of the game changed very little. It was our normal kind of change the colors on something and draw a different picture for it, but it's kind of the same thing.</p><p>But the perspective changed in a really fundamental way, and it was dramatically different. I can remember the reactions where the artist, Adrian, that had been drawing the pictures for it, we had a cool big troll thing in Catacombs 3D, and we had these walls that you could get a key and you could make the blocks disappear.</p><p>Yeah, really simple stuff. Blocks could either be there or not there. So our idea of a door was being able to make a set of blocks just disappear. And I remember the reaction where he had drawn these characters, and he was slowly moving around. And people had no experience with 3D navigation.</p><p>It was all still keyboard. We didn't even have mice set up at that time. But slowly moving, going up, picked up a key, go to a wall. The wall disappears in a little animation, and there's a monster right there. And he practically fell out of his chair. It was just like, ah!</p><p>And games just didn't do that. The games were the god's eye view. You were a little invested in your little guy. You can be happy or sad when things happen, but you just did not get that kind of startle reaction. You weren't inside the game. Something in the back of your brain, some reptile brain thing is just going, oh shit, something just happened.</p><p>And that was one of those early points where it's like, yeah, this is going to make a difference. This is going to be powerful, and it's going to matter. Were you able to imagine that in the idea stage or no? So not that exact thing. So we had cases like the arcade games Battlezone and Star Wars that you could kind of see a 3D world and things coming at you, and you get some sense of it.</p><p>But nothing had done the kind of worlds that we were doing and the sort of action-based things. 3D at the time was really largely about the simulation thoughts. And this is something that really might have trended differently if not for the id software approach in the games, where there were flight simulators, there were driving simulators, you had like hard drive-in and Microsoft Flight Simulator.</p><p>And these were doing 3D and general purpose 3D in ways that were more flexible than what we were doing with our games. But they were looked at as simulations. They weren't trying to necessarily be fast or responsive or letting you do kind of exciting maneuvers, because they were trying to simulate reality, and they were taking their cues from the big systems, the Evans and Sutherlands and the Silicon Graphics that were doing things.</p><p>But we were taking our cues from the console and arcade games. We wanted things that were sort of quarter eaters, that were doing fast-paced things, that could smack you around rather than just smoothly gliding you from place to place. So-- Quarter eaters. Yeah. And you know, a funny thing is, so much that that built into us that Wolfenstein still had lives.</p><p>And you had like one of the biggest power-ups in all these games, like was an extra life, because you started off with three lives, and you lose your lives, and then it's game over. And there weren't save games in most of this stuff. It was-- it sounds almost crazy to say this, but it was an innovation in Doom to not have lives.</p><p>You know, you could just play Doom as long as you wanted. You just restart at the start of the level. And why not? This is-- we aren't trying to take people's quarters. They've already paid for the entire game. We want them to have a good time. And you would have some old-timer purist that might think that there's something to the epic journey of making it to the end, having to restart all the way from the beginning after a certain number of tries.</p><p>But no, more fun is had when you just let people kind of keep trying when they're stuck, rather than having to go all the way back and learn different things. So you've recommended the book, Game Engine Black Book, Wolfenstein 3D for technical exploration of the game. So looking back 30 years, what are some memorable technical innovations that made this perspective shift into this world that's so immersive that scares you when a monster appears?</p><p>What were some things you had to solve? >>So one of the interesting things that come back to the theme of deadlines and resource constraints, the game Catacombs 3D, we shipped-- we were supposed to be shipping this for Gamers Edge on a monthly cadence. And I had slipped. I was actually late.</p><p>It slipped like six weeks, because this was texture-mapped walls doing stuff that I hadn't done before. And at the six-week point, it was still kind of glitchy and buggy. There were things that I knew that if you had a wall that was almost edge-on, you could slide over to it.</p><p>And you could see some things freak out or vanish or not work. And I hated that. But I was up against the wall. We had to ship the game. It was still a lot of fun to play. It was novel. Nobody had seen it. It gave you that startle reflex reaction.</p><p>So it was worth shipping. But it had these things that I knew were kind of flaky and janky and not what I was really proud of. So one of the things that I did very differently in Wolfenstein was I went-- Catacombs used almost a conventional thing where you had segments that were one-dimensional polygons, basically, that were clipped and back-faced and done kind of like a very crude 3D engine from the professionals.</p><p>But I wasn't getting it done right. I was not doing a good enough job. I didn't really have line of sight to fix it right. There's stuff that, of course, I look back. It's like, oh, it's obvious how to do this, do the math right, do your clipping right, check all of this, how you handle the precision.</p><p>But I did not know how to do that at that time. And I-- Was that the first 3D engine you wrote, Catacombs 3D? Yeah, Hover Tank had been a little bit before that. But that had the flat-shaded walls. So the texture mapping on the walls was what was bringing in some of these challenges that was hard for me.</p><p>And I couldn't solve it right at the time. Can you describe what flat shading is and texture mapping? So the walls were solid color, one of 16 colors in Hover Tank. So that's easy. It's fast. You just draw the solid color for everything. Texture mapping is what we all see today, where you have an image that is stretched and distorted onto the walls or the surfaces that you're working with.</p><p>And it was a long time for me to just figure out how to do that without it distorting in the wrong ways. And I did not get it all exactly right in Catacombs. And I had these flaws. So that was important enough to me that rather than continuing to bang my head on that, when I wasn't positive I was going to get it, I went with a completely different approach for drawing, for figuring out where the walls were, which was a ray casting approach, which I had done-- in Catacombs 3D, I had a bunch of C code trying to make this work right.</p><p>And it wasn't working right. In Wolfenstein, I wound up going to a very small amount of assembly code. So in some ways, this should be a slower way of doing it. But by making it a smaller amount of work that I could more tightly optimize, it worked out. And Wolfenstein 3D was just absolutely rock solid.</p><p>It was nothing glitched in there. The game just was pretty much flawless through all of that. And I was super proud of that. But eventually, like in the later games, I went back to the more span-based things where I could get more total efficiency once I really did figure out how to do it.</p><p>So there were two key technical things to Wolfenstein. One was this ray casting approach, which you still-- to this day, you see people go and say, let's write a ray casting engine, because it's an understandable way of doing things that lets you make games very much like that. So you see ray casters in JavaScript, ray casters in Python, people that are basically going and re-implementing that approach to taking a tiled world and casting out into it.</p><p>It works pretty well, but it's not the fastest way of doing it. Can you describe what ray casting is? So you start off, and you've got your screen, which is 320 pixels across at the time, if you haven't sized down the window for greater speed. And at every pixel, there's going to be an angle from-- you've got your position in the world, and you're going to just run along that angle and keep going until you hit a block.</p><p>So up to 320 times across there, it's going to throw a cast array out into the world from wherever your origin is until it runs into a wall, and then it can figure out exactly where on the wall it hits. The performance challenge of that is, as it's going out, every block it's crossing, it checks, is this a solid wall?</p><p>So that means that in the early Wolfenstein levels, you're in a small jail cell going out into a small hallway. It's super efficient for that, because you're only stepping across three or four blocks. But then if somebody makes a room that covers-- our maps were limited to 64 by 64 blocks.</p><p>If you made one room that was nothing but walls at the far space, it would go pretty slow, because it would be stepping across 80 tile tests or something along the way. By the way, the physics of our universe seems to be competing in this very thing. So this maps nicely to the actual physics of our world.</p><p>Yeah, you get-- Intuitively. I follow a little bit of something like Stephen Wolfram's work on interconnected network information states of that. And it's beyond what I can have an informed opinion on. But it's interesting that people are considering things like that and have things that can back it up.</p><p>Yeah, there's whole different sets of interesting stuff there. So Wolfenstein 3D had ray casting. Ray casting. And then the other key aspect was what I called compiled scalers, where the idea of-- you saw this in the earlier classic arcade games like Space Harrier and stuff, where you would take a picture, which is normally drawn directly on the screen.</p><p>And then if you have the ability to make it bigger or smaller, big chunky pixels or fizzily small drop-sampled pixels, that's the fundamental aspect of what our characters were doing in these 3D games. You would have-- it's just like you might have drawn a tiny little character, but now we can make them really big and make them really small and move it around.</p><p>That was the limited kind of 3D that we had for characters. To make them turn, there were literally eight different views of them. You didn't actually have a 3D model that would rotate. You just had these cardboard cutouts. But that was good enough for that startle fight reaction, and it was kind of what we had to deal with there.</p><p>So a straightforward approach to do that, you could just write out your doubly nested loop of-- you've got your stretch factor, and it's like you've got a point. You stretch by a little bit. It might be on the same pixel. It might be on the next pixel. It might have skipped a pixel.</p><p>You can write that out, but it's not going to be fast enough, where especially you get a character for that right in your face, monster covering almost the entire screen. Doing that with a general purpose scaling routine would have just been much too slow. It would have worked when they're small characters, but then it would get slower and slower as they got closer to you until right at the time when you most care about having a fast reaction time, the game would be chunking down.</p><p>So the fastest possible way to draw pixels at that time was to, instead of saying I've got a general purpose version that can handle any scale, I used a program to make essentially 100 or more separate little programs that was optimized for I will take an image, and I will draw it 12 pixels tall.</p><p>I'll take an image. I'll draw it 14 pixels tall, up by every two pixels even for that. So you would have the most optimized code so that in the normal case where most of the world is fairly large, like the pixels are big, we did not have a lot of memory.</p><p>So in most cases, that meant that you would load a pixel color, and then you would store it multiple times. So that was faster than even copying an image in a normal conventional case because most of the time the image is expanded. So instead of doing one read, one write for a simple copy, you might be doing one read and three or four writes as it got really big.</p><p>And that had the beneficial aspect of just when you needed the performance most when things are covering the screen, it was giving you the most acceleration for that. By the way, were you able to understand this through thinking about it, or were you testing the right speed and-- This again comes back to I can find the antecedents for things like this.</p><p>So back in the Apple II days, the graphics were essentially single bits at a time. And if you wanted to make your little spaceship, if you wanted to make it smoothly go across the world, if you just took the image and you drew it out at the next location, you would move by seven pixels at a time.</p><p>So it would go chunk, chunk, chunk. If you wanted to make it move smoothly, you actually had to make seven versions of the ship that were pre-shifted. You could write a program that would shift it dynamically, but on a 1 megahertz processor, that's not going anywhere fast. So if you wanted to do a smooth moving, fast action game, you made separate versions of each of these sprites.</p><p>Now, there were a few more tricks you could pull that if it still wasn't fast enough, you could make a compiled shape where instead of this program that normally copies an image and it says, like, get this byte from here, store it here, get this byte, store this byte, if you've got a memory space, you could say, I'm going to write the program that does nothing but draw this shape.</p><p>It's going to be like, I'm going to load the immediate value 25, which is some bit pattern, and then I'm going to store that at this location. Rather than loading something from memory that involved indexing registers and this other slow stuff, you could go ahead and say, no, I'm going to hard code the exact values of all of the image right into the program.</p><p>And this was always a horrible trade-off there, because you didn't have much memory and you didn't have much speed. But if you had something that you wanted to go really fast, you could turn it into a program. And that was, you know, knowing about that technique is what made me think about some of these, unwinding it for the PC, where people that didn't come from that background were less likely to think about that.</p><p>- I mean, there's some deep parallels probably to human cognition as well. There's something about optimizing and compressing the processing of a new information that requires you to predict the possible ways in which the game or the world might unroll. And you have something like compiled scalars always there.</p><p>So you have like optima, like you have a prediction of how the world will unroll and you have some kind of optimized data structure for that prediction. And then you can modify if the world turns out to be different, you can modify it a slight way. - And as far as building out techniques, so much of the brain is about the associative context.</p><p>You know, they're just, when you learn something, it's in the context of something else and you can have faint, tiny little hints of things. And I do think there are some deep things, you know, around like sparse distributed memories and boosting that's like, if you can just be slightly above the noise floor of having some hint of something, you can have things refined into pulling the memory back up.</p><p>So being a programmer and having a toolbox of like all of these things that I did in all of these previous lives of programming tasks, that still matters to me about how I'm able to pull up some of these things. Like in that case, it was something I did on the Apple II then being relevant for the PC.</p><p>And I have still cases when I would work on mobile development, then be like, okay, I did something like this back in the doom days, but now it's a different environment, but I still had that tie, I can bring it in and I can transform it into what the world needs right now.</p><p>And I do think that's actually one of the very core things with human cognition and brain-like functioning is finding these ways about, you've got, your brain is kind of everything everywhere all at once. You know, it is just a set of all of this stuff that is just fetched back by these queries that go into it.</p><p>And they can just be slightly above the noise floor with a random noise in your neurons and synapses that are affecting exactly what gets pulled up. - So you're saying some of these very specific solutions for different games, you find that there's a kernel of a deep idea that's generalizable to other things.</p><p>- Yeah, you can't predict what it's going to be, but that idea of like, I called out that compiled shaders in the forward that I wrote for that, the game engine black book, as you know, this is, it's kind of an end point of unrolling code, but that's one of those things that thinking about that and having that in your mind, and I'm sure there are some programmers that hear about that, think about it a little bit, it's kind of the mind blown moment.</p><p>It's like, oh, you can just turn all of that data into code. And nowadays, you know, you have instruction cache issues, and that's not necessarily the best idea, but there are different, it's an idea that has power and has probably relevance in some other areas. Maybe it's in a hardware point of view that there's a way you approach building hardware that has that same, you don't even have to think about iterating, you just bake everything all the way into it in one place.</p><p>- What is the story of how you came to program Doom? What are some memorable technical challenges or innovations within that game? - So the path that we went after Wolfenstein got out, and we were on this crazy arc where Keen 1 through 3, more success than we thought, Keen 4 through 6, even more success, Wolfenstein, even more success.</p><p>So we were on this crazy trajectory for things. So actually our first box commercial project was a Commander Keen game, but then Wolfenstein was going to have a game called Spear of Destiny, which was a commercial version, 60 new levels. So the rest of the team took the game engine pretty much as it was and started working on that.</p><p>We got new monsters, but it's basically re-skins of the things there. And there's a really interesting aspect about that that I didn't appreciate until much, much later about how Wolfenstein clearly did tap out its limit about what you want to play, all the levels and a couple of our licensed things.</p><p>There was a hard creative wall that you did not really benefit much by continuing to beat on it. But a game like Doom and other more modern games like Minecraft or something, there's kind of a Turing completeness level of design freedom that you get in games that Wolfenstein clearly sat on one side of.</p><p>You know, all the creative people in the world could not go and do a masterpiece just with the technology that Wolfenstein had. Wolfenstein could do Wolfenstein, but you really couldn't do something crazy and different. But it didn't take that much more capability to get to Wolfenstein with the freeform lines and a little bit more artistic freedom to get to the point where people still announce new Doom levels today, all these years after, without having completely tapped out the creativity.</p><p>- How did you put it? Turing complete? - Like Turing complete design space. - Design space. - Where it's like, you know, we have the kind of computational universality on a lot of things and how different substrates work. But yeah, there's things where a box can be too small, but above a certain point, you're kind of are at the point where you really have almost unbounded creative ability there.</p><p>- And Doom is the first time you crossed that line. - Yeah, where there were thousands of Doom levels created and some of them still have something new and interesting to say to the world about it. - Is that line, can you introspect what that line was? Is it in the design space?</p><p>Is it something about the programming capabilities that you were able to add to the game? - So the graphics fidelity was a necessary part because the block limitations in Wolfenstein, what we had right there was not enough, the full scale blocks. Although Minecraft, I really did show that perhaps blocks stacked in 3D and at one quarter of the scale of that, or one eighth in volume, is then sufficient to have all of that.</p><p>But the wall sized blocks that we had in Wolfenstein was too much of a creative limitation. You know, we licensed the technology to a few other teams. None of them made too much of a dent with that. It just wasn't enough creative ability, but a little bit more, whether it was the variable floors and ceilings and arbitrary angles in Doom, or the smaller voxel blocks in Minecraft is then enough to open it up to just worlds and worlds of new capabilities.</p><p>- What is binary space partitioning? - So the- - Which is one of the technologies. - Yeah, so jump around a little bit on the story path there. So while the team was working on Spirit Destiny for Wolfenstein, we had met another development team, Raven Software, while we were in Wisconsin, and they were doing, they had RPG background, and I still kind of loved that.</p><p>And I offered to do a game engine for them to let them do a 3D rendered RPG instead of the, like most RPG games were kind of hand drawn. They made it look kind of 3D, but it was done just all with artist work rather than a real engine.</p><p>And after Wolfenstein, this was still a tile-based world, but I added floors and ceilings and some lighting and the ability to have some sloped floors in different areas. And that was my intermediate step for a game called Shadowcaster. And it had slowed down enough. It was not fast enough to do our type of action things.</p><p>So they had the screen crop down a little bit. So you couldn't go the full screen width like we would try to do in Wolfenstein. But I learned a lot. I got the floors and ceilings and lightings, and it looked great. They were great artists up there. And it was an inspiration for us to look at some of that stuff.</p><p>But I had learned enough from that, that I had the plan for, I knew faster ways to do the lighting and shadowing. And I wanted to do this freeform geometry. I wanted to break out of this tile-based 90 degree world limitations. So that was when we got our next stations, and we were working with these higher powered systems.</p><p>And we built an editor that let us draw kind of arbitrary line segments. And I was working hard to try to make something that could render this fast enough. I was pushing myself pretty hard. And we were at a point where we could see some things that looked amazingly cool, but it wasn't really fast enough for the way I was doing it, for this flexibility.</p><p>It was no longer, I couldn't just ray cast into it. And I had these very complex sets of lines, and simple little worlds were okay. But the cool things that we wanted to do just weren't quite fast enough. And I wound up taking a break at that point. And I did the port, I did two ports of our games, Wolfenstein to the Super Nintendo.</p><p>It was a crazy difficult thing to do, which was an even slower processor. It was like two, a couple of megahertz, processor. And it had been this whole thing where we had farmed out the work and it wasn't going well. And I took it back over, and trying to make it go fast on there, where it really did not have much processing power.</p><p>The pixels were stretched up hugely, and it was pretty ugly when you looked at it. But in the end, it did come out fast enough to play and still be kind of fun from that. But that was where I started using BSP trees, or binary space partitioning trees. It was one of those things I had to make it faster there.</p><p>It was a stepping stone where it was reasonably easy to understand in the grid world of Wolfenstein, where it was all still 90 degree angles. BSP trees were, I eased myself into it with that. And it was a big success. Then when I came back to working on Doom, I had this new tool in my toolbox.</p><p>It was gonna be a lot harder with the arbitrary angles of Doom. This was where I really started grappling with epsilon problems. And just, up until that point, I hadn't really had to deal with the fact that I am so many numeric things. This almost felt like a betrayal to me, where people had told me that I had mathematicians up on a bit of a pedestal, where I was, people think I'm a math wizard, and I'm not.</p><p>I really, everything that I did was really done with a solid high school math understanding. Algebra II, trigonometry, and that was what got me all the way through Doom and Quake and all of that, of just understanding basics of matrices and knowing it well enough to do something with it.</p><p>- What's the epsilon problems you ran into? - So I, when you wind up taking a, like a sloped line and you say, I'm going to intersect it with another sloped line, I am, then you wind up with something that's not going to be on these nice grid boundaries.</p><p>With the Wolfenstein tile maps, all you've got is horizontal and vertical lines looking at it from above. And if you cut one of them, it's just obvious the other one gets cut exactly at that point. But when you have angled lines, you're doing a kind of a slope intercept problem and you wind up with rational numbers there, where things that are not going to evenly land on an integer or even on any fixed point value that you've got.</p><p>So everything winds up having to snap to some fixed point value. So the lines slightly change their angle. You wind up, if you cut something here, this one's going to bend a little this way, and it's not going to be completely straight. And then you come down to all these questions of, well, this one is a point on an angled line.</p><p>You can't answer that in finite precision unless you're doing something with actual rational numbers. And later on, I did waste far too much time chasing things like that. How do you do precise arithmetic with rational numbers? And it always blows up eventually, exponentially as you do it. - So these kinds of things are impossible with computers.</p><p>- They're possible, again, there are paths to doing it, but you can't fit them conveniently in any of the numbers you need to start using big nums and different factor trackings and different things. - So you have to, if you have any elements of OCD and you want to do something perfectly, you're screwed if you're working with floating point.</p><p>- Yeah. - So you had to deal with this for the first time. - And there were lots of challenges there about like, okay, they build this cool thing. And the way the BSP trees work is it basically takes the walls and it carves other walls by those walls in this clever way that you can then take all of these fragments.</p><p>And then you can for sure, from any given point, get an ordering of everything in the world. And you can say, this goes in front of this, goes in front of this, all the way back to the last thing. And that's super valuable for graphics, where kind of a classic graphics algorithm would be painter's algorithm.</p><p>You paint the furthest thing first, and then the next thing, and then the next thing. And then it comes up and it's all perfect for you. That's slow because you don't want to have to have drawn everything like that, but you can also flip it around and draw the closest thing to you.</p><p>And then if you're clever about it, you can figure out what you need to draw that's visible beyond that. - And that's what BSP trees allow you to do. - Yeah, so it's combined with a bunch of other things, but it gives you that ordering. It's a clever way of doing things.</p><p>And I remember I had learned this from one of my, my graphics Bible at the time, a book called Folian Van Damme. And again, it was a different world back there. There was a small integer number of books and this book, yeah, this book that was, it was big fat college textbook that I had, I had read through many times.</p><p>I didn't understand everything in it. Some of it wasn't useful to me, but they had the little thing about finite orderings of you draw a little T-shaped thing. And you can say, you can, you can make a fixed ahead of time order from this, and you can generalize this with the BSP trees.</p><p>And I got a little bit more information about that. And it was kind of fun later while I was working on Quake, I got to meet Bruce Naylor, who was one of the original researchers that developed those technologies, you know, for academic literature. And that was kind of fun, but I was very much just finding a tool that can help me solve what I was doing.</p><p>And I was using it in this very crude way in a two-dimensional fashion, rather than the general 3D. The Epsilon problems got much worse in Quake and three-dimensionals when things angle in every way. But eventually I did sort out the, sort out how to do it reliably on Doom.</p><p>There were still a few edge cases in Doom that were not absolutely perfect, where they even got terminologies in the communities. Like when you got to something where it was messed up, it was a hall of mirrors effect because you'd sweep by and it wouldn't draw something there and you would just wind up with the leftover remnants as you flipped between the two pages.</p><p>But BSP trees were important for it. But it's again worth noting that after we did Doom, our major competition came from Ken Silverman and his build engine, which was used for Duke Nukem 3D and some of the other games for 3D Realms. And he used a completely different technology, nothing to do with BSP trees.</p><p>So there's not just a one true way of doing things. There were critical things about to make any of those games fast, you had to separate your drawing into you drew vertical lines and you drew horizontal lines, just kind of changing exactly what you would draw with them. That was critical for the technologies at that time.</p><p>And like all the games that were kind of like that wound up doing something similar, but there were still a bunch of other decisions that could be made. And we made good enough decisions on everything on Doom. We brought in multiplayer significantly. And it was our first game that was designed to be modified by the user community, where we had this whole setup of our WAD files and PWADs and things that people could build with tools that we released to them.</p><p>And they eventually rewrote to be better than what we released, but they could build things and you could add it to your game without destructively modifying it, which is what you had to do in all the early games. You literally hacked the data files or the executable before, while Doom was set up in this flexible way so that you could just say, run the normal game with this added on on top, and it would overlay just the things that you wanted to there.</p><p>- Would you say that Doom was kind of the first true 3D game that you created? - So no, it's still, Doom would usually be called a two and a half D game where it had three dimensional points on it. And this is another one of these kind of pedantic things that people love to argue about, about what was the first 3D game.</p><p>I still, like every month probably I hear from somebody about, well, was Doom really a 3D game or something? And I give the point where characters had three coordinates. So you had like an X, Y, and Z, the cacodemon could be coming in very high and come down towards you.</p><p>The walls had three coordinates on them. So on some sense, it's a 3D game engine, but it was not a fully general 3D game engine. You could not build a pyramid in Doom because you couldn't make a sloped wall, which was slightly different where in that previous Shadowcaster game, I couldn't have vertexes and have a sloped floor there, but the changes that I made for Doom to get higher speed and a different set of flexibility traded away that ability, but you literally couldn't make that.</p><p>You could make different heights of passages, but you could not make a bridge over another area. You could not go over and above it. So it still had some 2D limitations to it. - That's more about the building versus the actual experience, 'cause the experience is- - It felt like things would come at you, but again, you couldn't look up either.</p><p>You could only pitch. It was four degrees of freedom rather than six degrees of freedom. You did not have the ability to tilt your head this way or pitch up and down. - So that takes us to Quake. What was the leap there? What was some fascinating technical challenges and there were a lot, or not challenges, but innovations that you've come up with?</p><p>- So Quake was kind of the first thing where I did have to kind of come face to face with my limitations, where it was the first thing where I really did kind of give it my all and still come up a little bit short in terms of what and when I wanted to get it done.</p><p>And the company had some serious stresses through the whole project. And we bit off a lot. So the things that we set out to do was it was going to be really a true 3D engine where it could do six degree of freedom. You could have all the viewpoints.</p><p>You could model anything. It had a really remarkable new lighting model with the surface caching and things. That was one of those where it was starting to do some things that they weren't doing even on the very high end systems. And it was going to be completely programmable in the modding standpoint, where the thing that you couldn't do in Doom, you could replace almost all of the media, but you couldn't really change the game.</p><p>There were still some people that were doing the hex editing of the executable, the de-hacked things where you could change a few things about rules and people made some early capture the flag type things by hacking the executable, but it wasn't really set out to do that. Quake was going to have its own programming language that the game was going to be implemented in it.</p><p>And that would be able to be overwritten just like any of the media. Code was going to be data for that. And you would be able to have expansion packs that changed fundamental things and mods and so on. And the multiplayer was going to be playable over the internet.</p><p>It was going to support a client server rather than peer to peer. So we had the possibility of supporting larger numbers of players in disparate locations with this full flexibility of the programming overrides with full six degree of freedom, modeling and viewing. And with this fancy new light mapped kind of surface caching side, it was a lot.</p><p>And this was one of those things that if I could go back and tell younger me to do something differently, it would have been to split those innovations up into two phases in two separate games. - Will be phase one and phase two. - So it probably would have been taking the Doom rendering engine and bringing in the TCP/IP client server.</p><p>- Focusing on the multiplayer. - And the Quake C or would have been Doom C programming language there. So I would have split that into programming language and networking with the same Doom engine rather than forcing everybody to go towards the Quake engine, which really meant getting a Pentium.</p><p>You know, while it ran on a 486, it was not a great experience there. We could have made more people happier and gotten two games done in 50% more time. - Aye. - So speaking of people happier, our mutual friend Joe Rogan, it seems like the most important moment of his life is centered around Quake.</p><p>So it was a definitive part of his life. So would he agree with your thinking that they should split? So he is a person who loves Quake and played Quake a lot. Would he agree that you should have done the Doom engine and focus on the multiplayer for phase one?</p><p>Or in your looking back, is the 3D world that Quake created was also fundamental to the enriched experience? - You know, I would say that what would have happened is you would have had a Doom looking, but Quake feeling game eight months earlier and then maybe six months after Quake actually shipped, then there would have been the full running on a Pentium six degree of freedom graphics engine type things there.</p><p>So it's not that it wouldn't have been there. It would have been something amazingly cool earlier and then something even cooler somewhat later where I would much rather have gone and done two one year development efforts. I've cycled them through. I've been a little more pragmatic about that rather than killing ourselves on the whole Quake development.</p><p>But I would say it's obviously things worked out well in the end, but looking back and saying, how would I optimize and do things differently? That did seem to be a clear case where going ahead and we had enormous momentum on Doom. You know, we did Doom two as the kind of commercial boxed version after our shareware success with the original, but we could have just made another Doom game adding those new features in.</p><p>It would have been huge. We would have learned all the same lessons, but faster. And it would have given six degree of freedom and Pentium class systems a little bit more time to get mainstream because we did cut out a lot of people with the hardware requirements for Quake.</p><p>- Was there any dark moments for you personally, psychologically in having such harsh deadlines and having this also mean difficult technical challenges? - So I've never really had really dark black places. I mean, I can't necessarily put myself in anyone else's shoes, but I understand a lot of people have, you know, have significant challenges with kind of their mental health and wellbeing.</p><p>And I've been super stressed. I've been unhappy as a teenager in various ways, but I've never really gone to a very dark place. I just seem to be largely immune to what really wrecks people. I mean, I've had plenty of time when I'm very unhappy and miserable about something, but it's never hit me like, you know, I believe it winds up hitting some other people.</p><p>I've borne up well under whatever stresses have kind of fallen on me. And I've always coped best on that when all I need to do is usually just kind of bear down on my work. I pull myself out of whatever hole I might be slipping into by actually making progress.</p><p>I mean, maybe if I was in a position where I was never able to make that progress, I could have slid down further, but I've always been in a place where, okay, a little bit more work, maybe I'm in a tough spot here, but I always know if I just keep pushing, eventually I break through and I make progress, I feel good about what I'm doing.</p><p>And that's been enough for me so far in my life. - Have you seen in the distance, like, you know, ideas of depression or contemplating suicide, have you seen those things far? - So it was interesting when I was a teenager, I was, you know, I was probably on some level a troubled youth.</p><p>I was unhappy most of my teenage years. I really, I wanted to be on my own doing programming all the time. You know, as soon as I was 18, 19, even though I was poor, I was doing exactly what I wanted and I was very happy, but high school was not a great time for me.</p><p>And I had a conversation with like the school counselor and they're kind of running their script. It's like, okay, it's kind of a weird kid here. Let's carefully probe around. It's like, you know, do you ever think about ending it all? I'm like, no, of course not. Never, not at all.</p><p>This is temporary, things are going to be better. And that's always been kind of the case for me. And obviously that's not that way for everyone and other people do react differently. - And what was your escape from the troubled youth? Like, you know, music, video games, books. How did you escape from a world that's full of cruelty and suffering and that's absurd?</p><p>- Yeah, I mean, I was not, you know, I was not a victim of cruelty and suffering. It's like, I was an unhappy, somewhat petulant youth and, you know, in my point where, you know, I'm not putting myself up with anybody else's suffering, but I was unhappy objectively. And the things that I did that very much characterized my childhood were, I had books, comic books, Dungeons and Dragons, arcade games, video games.</p><p>Like some of my fondest childhood memories are the convenience stores, the 7-Elevens and Quick Trips, because they had a spinner rack of comic books and they had a little side room with two or three video games, arcade games in it. And that was very much my happy place. You know, if I could, I get my comic books and if I could go to a library and, you know, go through those, the little 000 section where computer books were supposed to be.</p><p>And there were a few sad little books there, but still just being able to sit down and go through that. And I read, you know, I read a ridiculous number of books, both fiction and nonfiction as a teenager. And, you know, as I, my rebelling in high school was just sitting there with my nose in a book, ignoring the class, I threw lots of it.</p><p>And teachers had a range of reactions to that, some more accepting of it than others. - I'm with you on that. So let us return to Quake for a bit with the technical challenges. What, everything together from the networking to the graphics, what are some things you remember that were innovations you had to come up with in order to make it all happen?</p><p>- Yeah, so there were a bunch of things on Quake where on the one hand, the idea that I built my own programming language to implement the game in, looking back, and I try to tell people, it's like every high level programmer sometime in their career goes through and they invent their own language.</p><p>It just seems to be a thing that's pretty broadly done. People will be like, I'm gonna go write a computer programming language. And I, you know, I don't regret having done it, but after that, I switched from Quake C, my quirky little pseudo object-oriented or entity-oriented language there. Quake 2 went back to using DLLs with C, and then Quake 3, I implemented my own C interpreter or compiler, which was a much smarter thing to do that I should have done originally for Quake.</p><p>But building my own language was an experience. I learned a lot from that. And then there was a generation of game programmers that learned programming with Quake C, which I feel kind of bad about because, you know, I mean, we give JavaScript a lot of crap, but Quake C was nothing to write home about there.</p><p>But it allowed people to do magical things. You get into programming, not because you love the BNF syntax of a language, it's because the language lets you do something that you cared about. - And here's very much, you could do something in a whole beautiful three-dimensional world. - Yeah, and the idea and the fact that the code for the game was out there, you could say, I like the shotgun, but I want it to be more badass.</p><p>You go in there and say, okay, now it does 200 points damage. And then you go around with a big grin on your face, blowing up monsters all over the game. So yeah, it is not what I would do today going back with that language, but that was a big part of it.</p><p>Learning about the networking stuff, because it's interesting where I learn these things by reading books. So I would get a book on networking, find something, I read all about it and learn, okay, packets, they can be out of order, lost, or duplicated. These are all the things that can theoretically happen to packets.</p><p>So I wind up spending all this time thinking about how do we deal about all of that? And it turns out, of course, in the real world, those are things that yes, theoretically can happen with multiple routes, but they really aren't things that your 99.999% of your packets have to deal with.</p><p>So there was learning experiences about lots of that, like why, when TCP is appropriate versus UDP and how if you do things in UDP, you wind up reinventing TCP badly in almost all cases. So there's good arguments for using both for different game technology, different parts of the game process, transitioning from level to level and all.</p><p>But the graphics were the showcase of what Quake was all about. It was this graphics technology that nobody had seen there. And it was a while before, there were competitive things out there. And it went a long time internally, really not working, where we were even building levels where the game just was not at all shippable with large fractions of the world, like disappearing, not being there, or being really slow in various parts of it.</p><p>And it was this act of faith. It's like, I think I'm gonna be able to fix this. I think I'm gonna be able to make this work. And lots of stuff changed where the level designers would build something and then have to throw it away as something fundamental and the kind of graphics or level technology changed.</p><p>And so there were two big things that contributed to making it possible at that timeframe. Two new things. There was certainly hardcore optimized low-level assembly language. This was where I had hired Michael Abrash away from Microsoft. And he had been one of my early inspirations where that back in the softest days, the library of magazines that they had, some of my most treasured ones were Michael Abrash's articles in Dr.</p><p>Dobbs Journal. And it was amazing after all of our success in Doom, we were able to kind of hit him up and say, "Hey, we'd like you to come work at id Software." And he was in this senior technical role at Microsoft and he was on track for, and this was right when Microsoft was starting to take off.</p><p>And I did eventually convince him that what we were doing was gonna be really amazing with Quake. It was going to be something nobody had seen before. It had these aspects of what we were talking about. We had metaverse talk back then. We had read "Snow Crash" and we knew about this.</p><p>And Michael was big into the science fiction and we would talk about all that and kind of spin this tale. And it was some of the same conversations that we have today about the metaverse, about how you could have different areas linked together by portals and you could have user-generated content and changing out all of these things.</p><p>- So you really were creating the metaverse with Quake. - And we talked about things like - Philosophically. - It used to be advertised as a virtual reality experience. That was the first wave of virtual reality was in the late '80s and early '90s, you had like the "Lawnmower Man" movie and you had "Time" and "Newsweek" talking about the early VPL headsets.</p><p>And of course that cratered so hard that people didn't wanna look at virtual reality for decades afterwards, where it was just, it was smoke and mirrors. It was not real in the sense that you could actually do something real and valuable with it. But still we had that kind of common set of talking points and we were talking about what these games could become and how you'd like to see people building all of these creative things.</p><p>Because we were seeing an explosion of work with Doom at that time, where people were doing amazingly cool things. Like we saw cooler levels that we had built coming out of the user community and then people finding ways to change the characters in different ways and it was great.</p><p>And we knew what we were doing in Quake was removing those last things. There was some quirky things with a couple of the data types that didn't work right for overriding and then the core thing about the programming model. And I was definitely going to hit all of those in Quake.</p><p>But the graphic side of it was still, I knew what I wanted to do and it was one of these hubris things where it's like, well, so far I've been able to kind of kick everything that I set out to go do. But Quake was definitely a little bit more than could be comfortably chewed at that point.</p><p>And, but Michael was one of the strongest programmers and graphics programmers that I knew. And he was one of the people that I trusted to write assembly code better than I could. And there's a few people that I can point to about things like this, where I'm a world-class optimizer.</p><p>I mean, I make things go fast, but I recognize there's a number of people that can write tighter assembly code, tighter SIMD code or tighter CUDA code than I can write. I'm, my best strengths are a little bit more at the system level. I mean, I'm good at all of that, but the most leverage comes from making the decisions that are a little bit higher up, where you figure out how to change your large scale problems so that these lower level problems are easier to do or it makes it possible to do them in a uniquely fast way.</p><p>So most of my, you know, my big wins in a lot of ways from all the way from the early games through, you know, through VR and the aerospace work that I'm doing and, or did, and hopefully the AI work that I'm working on now is finding an angle on something that means you trade off something that you maybe think you need, but it turns out you don't need it.</p><p>And by making a sacrifice in one place, you can get big advantages in another place. - Is it clear at which level of the system those big advantages can be gained? - It's not always clear. And that's why the thing that I try to make one of my core values, and I proselytize to a lot of people is trying to know the entire stack, you know, trying to see through everything that happens.</p><p>And it's almost impossible on like the web browser level of things where there's so many levels to it, but you should at least understand what they all are, even if you can't understand all the performance characteristics at each level, but it goes all the way down to literally the hardware.</p><p>So what does the, what is this chip capable of? And what is this software that you're writing capable of? And then when this architecture you put on top of that, then the ecosystem around it, all the people that are working on it. So there are all these decisions and they're never made in a globally optimal way, but sometimes you can drive a thread of global optimality through it.</p><p>You can't look at everything, it's too complicated, but sometimes you can step back up and make a different decision. And we kind of went through this on the graphics side on Quake where I, in some ways it was kind of bad where Michael would spend his time writing, like I'd rough out the basic routines, like, okay, here's our span rasterizer.</p><p>And he would spend a month writing this, you know, beautiful cycle optimized piece of assembly language that does, you know, does what I asked it to do. And he did it faster than like my original code would do, or probably what I would be able to do even if I had spent that month on it.</p><p>But then we'd have some cases when I'd be like, okay, well, I figured out at this higher level, instead of drawing these in a painter's order here, I do a span buffer and it cuts out 30% or 40% of all of these pixels, but it means you need to rewrite kind of this interface of all of that.</p><p>And I could tell that wore on him a little bit, but in the end it was the right thing to do where we wound up changing that rasterization approach and we wound up with a super optimized assembly language core loop, and then a good system around it, which minimized how much that had to be called.</p><p>- And so in order to be able to do this kind of system level thinking, whether we're talking about game development, aerospace, nuclear energy, AI, VR, you have to be able to understand the hardware, the low level software, the high level software, the design decisions, the whole thing, the full stack of it.</p><p>- Yeah, and that's where a lot of these things become possible when you're bringing the future forward. I mean, there's a pace that everything just kind of glides towards where we have a lot of progress that's happening at such a different, so many different ways you kind of slide towards progress, just left to your own programs just get faster.</p><p>For a while it wasn't clear if they were gonna get fatter more than they get quicker than they get faster and it cancels out, but it is clear now in retrospect, programs just get faster and have gotten faster for a long time. But if you wanna do something like back at that original, talking about scrolling games, say, well, this needs to be five times faster.</p><p>Well, we can wait six years and just, it'll naturally get that much faster at that time, or you come up with some really clever way of doing it. So there are those opportunities like that in a whole bunch of different areas. Now, most programmers don't need to be thinking about that.</p><p>There's not that many, there's a lot of opportunities for this, but it's not everyone's work a day type stuff. So everyone doesn't have to know how all these things work. They don't have to know how their compiler works, how the processor chip manages cache eviction and all these low level things.</p><p>But sometimes there are powerful opportunities that you can look at and say, we can bring the future five years faster. We can do something that, wouldn't it be great if we could do this? Well, we can do it today if we make a certain set of decisions. And it is in some ways smoke and mirrors, where you say it's like, Doom was a lot of smoke and mirrors, where people thought it was more capable than it actually was, but we picked the right smoke and mirrors to deploy in the game, where by doing this, people will think that it's more general, we are going to amaze them with what they've got here, and they won't notice that it doesn't do these other things.</p><p>So smart decision-making at that point, that's where that kind of global, holistic top-down view can work. And I'm really a strong believer that technology should be sitting at that table, having those discussions, because you do have cases where you say, well, you want to be the Jonathan Ivey or whatever, where it's a pure design solution.</p><p>And that's, in some cases now, where you truly have almost infinite resources, like if you're trying to do a scrolling game on the PC now, you don't even have to talk to a technology person, you can just have, any intern can make that go run as fast as it needs to there, and it can be completely design-based.</p><p>But if you're trying to do something that's hard, either that can't be done for resources, like VR on a mobile chip set, or that we don't even know how to do yet, like artificial general intelligence, it's probably going to be a matter of coming at it from an angle.</p><p>Like, I mean, for AGI, we have some of the Hutter principles about how you can, you know, AGI, some of that, there are theoretical ways that you can say, this is the optimal learning algorithm that can solve everything, but it's completely impractical, you know, you just can't do that.</p><p>So clearly you have to make some concessions for general intelligence, and nobody knows what the right ones are yet. So people are taking different angles of attack, I hope I've got something clever to come up with in that space. - It's been surprising to me, and I think perhaps it is a principle of progress that smoke and mirrors somehow is the way you build the future.</p><p>You kind of fake it till you make it, and you almost always make it, and I think that's going to be the way we achieve AGI, that's going to be the way we build consciousness into our machines. There's, you know, philosophers debate about the Turing test, is essentially about faking it till you make it.</p><p>You start by faking it, and I think that always leads to making it, because if you look at history- - Most of the philosophers arguments, when as soon as people start talking about qualia and consciousness and Chinese rooms and things, it's like, I just check out, I just don't think there's any value in those conversations.</p><p>It's just like, go ahead, tell me it's not going to work, I'm going to do my best to try to make it work anyways. - I don't know if you work with legged robots, there's a bunch of these. They make, they sure as heck make me feel like they're cautious.</p><p>In a certain way that's not here today, but is, you could see the kernel, it's like the flame, the beginnings of a flame. - We don't have line of sight, but there's glimmerings of light in the distance for all of these things. - Yeah, I'm hearing murmuring in a distant room.</p><p>Well, let me ask you a human question here. You've, in the game design space, you've done a lot of incredible work throughout, but in terms of game design, you have changed the world and there's a few people around you that did the same. So famously, there's some animosity, there's much love, but there's some animosity between you and John Romero.</p><p>What is at the core of that animosity and human tension? - So there really hasn't been, for a long time, and even at the beginning, it's like, yes, I did push Romero out of the company. And this is one of the things that I look back, if I could go back telling my younger self some advice about things, the original founding kind of corporate structure of id Software really led to a bunch of problems.</p><p>We started off with us as equal partners and we had a buy-sell agreement because we didn't want outsiders to be telling us what to do inside the company. And that did lead to a bunch of the problems where I was sitting here going, it's like, all right, I'm working harder than anyone.</p><p>I'm doing these technologies, nobody's done before, but we're all equal partners. And then I see somebody that's not working as hard. I mean, I can't say I was the most mature about that. I was 20 something years old and it did bother me when I'm like, everybody, okay, we need to all pull together and we've done it before.</p><p>Everybody, we know we can do this if we get together and we grind it all out, but not everybody wanted to do that for all time. And I was the youngest one of the crowd there. I had different sets of kind of backgrounds and motivations and left at that point where it was, all right, either everybody has to be contributing like up to this level or they need to get pushed out, that was not a great situation.</p><p>And I look back on it and no, we pushed people out of the company that could have contributed if there was a different framework for them. And the modern kind of Silicon Valley, like let your stock vest over a time period and maybe it's non-voting stock and all those different things.</p><p>We knew nothing about any of that. I mean, we didn't know what we were doing in terms of corporate structure or anything. - So if you think the framework was different, some of the human tension could have been a little bit. - It almost certainly would have. I mean, I look back at that and it's like even trying to summon up in my mind, it's like, I know I was really, really angry about, I am like Romero not working as hard as I wanted him to work or not carrying his load on the design for Quake and coming up with things there.</p><p>But he was definitely doing things. He made some of the best levels there. He was working with some of our external teams like Raven on the licensing side of things. But there were differences of opinion about it. But he landed right on his feet. He went and he got $20 million from Eidos to go do Ion Storm and he got to do things his way and spun up three teams simultaneously.</p><p>Because that was always one of the challenging things in it where we were doing these single string, one project after another. And I think some of them wanted to grow the company more. And I didn't because I knew people that were saying that, oh, companies turn to shit when you got 50 employees.</p><p>It's just a different world there. And I loved our little dozen people working on the projects. But you can look at it and say, well, business realities matter. It's like you're super successful here and we could take a swing and a miss on something. But you do it a couple of times and you're out of luck.</p><p>There's a reason companies try to have multiple teams running at one time. And so that was, again, something I didn't really appreciate back then. So if you look past all that, you did create some amazing things together. What did you love about John Romero? What did you respect and appreciate about him?</p><p>What did you admire about him? What did you learn from him? When I met him, he was the coolest programmer I had ever met. He had done all of this stuff. He had made all of these games. He had worked at one of the companies that I thought was the coolest at Origin Systems.</p><p>And he knew all this stuff. He made things happen fast. And he was also kind of a polymath about this, where he drew his own art. He made his own levels, as well as he worked on sound design systems on top of actually being a really good programmer. And we went through a little-- it was kind of fun where one of the early things that we did, where there was kind of the young buck bit going in, where I was the new guy and he was the top man programmer at the Softdisk area.</p><p>And eventually, we had sort of a challenge over the weekend that we were going to race to implement this game, to port one of our PC games back down to the Apple II. And that was where we finally kind of became clear. It's like, OK, Carmack stands a little bit apart on the programming side of things.</p><p>But Romero then very gracefully moved into, well, he'll work on the tools. He'll work on the systems, do some of the game design stuff, as well as contributing on starting to lead the design aspects of a lot of things. So he was enormously valuable in the early stuff. And so much of Doom, and even Quake, have his stamp on it in a lot of ways.</p><p>But he wasn't at the same level of focus that I brought to the work that we were doing there. And he really did-- we hit such a degree of success that it was all in the press about that, the rock star game programmers. Yeah, I mean, it's the Beatles problem.</p><p>Yeah, I mean, he ate it up. And he did personify-- there was the whole game developers with Ferraris that we had there. And I thought that led to some challenges there. But so much of the stuff that was great in the games did come from him. And I would certainly not take that away from him.</p><p>And even after we parted ways and he took his swing with Eidos, in some ways, he was ahead of the curve with mobile gaming as well, where one of his companies after Eidos was working on feature phone game development. And I wound up doing some of that just before the iPhone, crossing over into the iPhone phase there.</p><p>And that was something that clearly did turn out to be a huge thing, although he was too early for what he was working on at that time. We've had pretty cordial relationships where I was happy to talk with him anytime I'd run into him at a conference. I have actually had some other people just say, it's like, oh, you shouldn't go over there and give him the time of day, or felt that Masters of Doom was-- I played things up in a way that I shouldn't be too happy with.</p><p>But I'm OK with all of that. So you've still got love in your heart. I mean, I just talked with him last year, or I guess it was even this year, about mentioning that I'm going off doing this AI stuff. I'm going big into artificial intelligence. And he had a bunch of ideas for how AI is going to play into gaming, and asked if I was interested in collaborating.</p><p>And it's not in line with what I'm doing, but I do-- I wish almost everyone the best. I mean, I know I may not have parted on the best of terms with some people, but I was thrilled to see Tom Hall writing VR games now. He wrote-- working on a game called Demio, which is really an awesome VR game.</p><p>It's like Dungeons and Dragons. We all used to play Dungeons and Dragons together. That was one of the things-- that was what we did on Sundays in the early days. I would Dungeon Master, and they'd all play. And so it really made me smile seeing Tom involved with an RPG game in virtual reality.</p><p>- You were the CTO of Oculus VR since 2013, and maybe lessen your involvement a bit in 2019. Oculus was acquired by Facebook now Meta in 2014. You've spoken brilliantly about both the low-level details, the experimental design, and the big picture vision of virtual reality. Let me ask you about the metaverse, the big question here, both philosophically and technically.</p><p>How hard is it to build the metaverse? What is the metaverse in your view? You started with discussing and thinking about Quake as a kind of a metaverse. As you think about it today, what is the metaverse, the thing that could create this compelling user value, this experience that will change the world?</p><p>And how hard is it to build it? - So the term comes from Neil Stevenson's book Snow Crash, which many of us had read back in the '90s. It was one of those kind of formative books. And there was this sense that the possibilities and kind of the freedom and unlimited capabilities to build a virtual world that does whatever you want, whatever you ask of it, has been a powerful draw for generations of developers, game developers specifically, and people that are thinking about more general purpose applications.</p><p>So we were talking about that back in the Doom and Quake days, about how do you wind up with an interconnected set of worlds that you kind of visit from one to another. And as web pages were becoming a thing, you start thinking about what is the interactive kind of 3D-based equivalent of this.</p><p>And there were a lot of really bad takes. You had like Vermont and virtual reality markup languages. And there's aspects like that that came from people saying, well, what kind of capabilities should we develop to enable this? And that kind of capability-first work has usually not panned out very well.</p><p>On the other hand, we have successful games that started with things like Doom and Quake and communities that formed around those, and whether it was server lists in the early days or literal portaling between different games, and then modern things that are on a completely different order of magnitude, like Minecraft and Fortnite, that have 100 million-plus users.</p><p>I still think that that's the right way to go to build the metaverse, is you build something that's amazing that people love and people wind up spending all their time in, because it's awesome. And you expand the capabilities of that. So even if it's a very basic experience, if it's awesome-- Minecraft is an amazing case study in so many things, where what's been able to be done with that is really enlightening.</p><p>And there are other cases where, like right now, Roblox is basically a game construction kit aimed at kids. And that was a capability-first play. And it's achieving scale that's on the same order of those things. So it's not impossible, but my preferred bet would be you make something amazing that people love, and you make it better and better.</p><p>And that's where I could say we could have gone back and followed a path like that in the early days, if you just take the same game, whether it's when Activision demonstrated that you could make Call of Duty every year. And not only is it not bad-- people love it, and it's very profitable-- the idea that you could have taken something like that, take a great game, release a new version every year that lets the capabilities grow and expand to start saying, it's like, OK, it's a game about running around and shooting things.</p><p>But now you can bring your media into it. You can add persistence of social signs of life or whatever you want to add to it. I still think that's quite a good position to take. And I think that while Meta is doing a bottoms-up capability approach with Horizon Worlds, where it's a fairly general-purpose, creators can build whatever they want in there sort of thing, it's hard to compare and compete with something like Fortnite, which also has enormous amounts of creativity, even though it was not designed originally as a general-purpose sort of thing.</p><p>So we have examples on both sides. Me, personally, I would have bet on trying to do entertainment, valuable destination first, and expanding from there. So can you imagine the thing that will be kind of-- if we look back a couple of centuries from now and you think about the experiences that marked the singularity, the transition, where most of our world moved into virtual reality, what do you think those experiences will look like?</p><p>So I do think it's going to be kind of like the way the web slowly took over, where you're the frog in the pot of water that's slowly heating up, where having lived through all of that, I remember when it was shocking to start seeing the first website address on a billboard, when you're like, hey, my computer world is infecting the real world.</p><p>This is spreading out in some way. But there's still-- when you look back and say, well, what made the web take off? And it wasn't a big bang sort of moment there. It was a bunch of little things that turned out not to even be the things that are relevant now that brought them into it.</p><p>So-- I wonder if-- I mean, like you said, you're not a historian. So maybe there is a historian out there that could really identify that moment, data-driven way. It could be like Myspace or something like that. Maybe the first major social network that really reached into non-geek world or something like that.</p><p>I think that's kind of the fallacy of historians, though, looking for some of those kind of primary dominant causes, where so many of these things are-- like, we see an exponential curve. But it's not because one thing is going exponential. It's because we have hundreds of little sigmoid curves overlapped on top of each other.</p><p>And they just happen to keep adding up so that you've got something kind of going exponential at any given point. But no single one of them was the critical thing. There were dozens and dozens of things. I mean, seeing the transitions of stuff, like as, obviously, Myspace giving way to other things, but even like blogging giving way to social media and getting resurrected in other guises and-- And the memes with the-- --things that happened there.</p><p>--dancing baby gif or whatever the-- all your base now belong to us. Whatever those early memes that led to the modern memes and the humor on the different-- the different evolution of humor on the internet that I'm sure the historians will also write books about from the different websites that support, that create the infrastructure for that humor, like Reddit and all that kind of stuff.</p><p>So people will go back, and they will name firsts and critical moments. But it's probably going to be a poor approximation of what actually happens. And we've already seen, like, in the VR space where it didn't play out the way we thought it would in terms of what was going to be-- like, when the modern era of VR basically started with my E3 demo of Doom 3 on the Rift prototype.</p><p>So we're like, first-person shooters in VR, match made in heaven, right? And that didn't work out that way at all. They have-- you know, they have the most comfort problems with it. And then the most popular virtual reality app is Beat Saber, which nobody predicted back then. What's that make you, like, from first principles if you were to, like, reverse engineer that?</p><p>Why are these, like, silly fun games? Well, it actually makes very clear sense when you analyze it from hindsight and look at the engineering reasons, where it's not just that it was a magical, quirky idea. It was something that played almost perfectly to what turned out to be the real strengths of VR, where the one thing that I really underestimated importance in VR was the importance of the controllers.</p><p>You know, I was still thinking we could do a lot more with a game pad. And just the amazingness of taking any existing game, being able to move your head around and look around, that that was really amazing. But the controllers were super important. But the problem is so many things that you do with the controllers just suck.</p><p>It feels like it breaks the illusion, like trying to pick up glasses with the controllers, where you're like, oh, use the grip button when you're kind of close, and it'll snap into your hand. All of those things are unnatural actions, that you do them, and it's still part of the VR experience.</p><p>But Beat Saber winds up playing only to the strengths. It completely hides all the weaknesses of it, because you are holding something in your hand. You keep a solid grip on it the whole time. It slices through things without ever bumping into things. You never get into the point where, you know, I'm knocking on this table, but in VR, my hand just goes right through it.</p><p>So you've got something that slices through, so it's never your brain telling you, oh, I should have hit something. You've got a lightsaber here. It's just you expect it to slice through everything. Audio and music turned out to be a really powerful aspect of virtual reality, where you're blocking the world off and constructing the world around you, and being something that can run efficiently on even this relatively low-powered hardware, and can have a valuable loop in a small amount of time, where a lot of modern games, you're supposed to sit down and play it for an hour, just to get anywhere.</p><p>Sometimes a new game takes an hour to get through the tutorial level, and that's not good for VR for a couple reasons. You do still have the comfort issues if you're moving around at all, but you've also got just discomfort from the headset, battery lifespan on the mobile versions.</p><p>So having things that do break down into three- and four-minute windows of play, that turns out to be very valuable from a gameplay standpoint. So it winds up being kind of a perfect storm of all of these things that are really good. It doesn't have any of the comfort problems.</p><p>You're not navigating around. You're standing still. All the stuff flies at you. It has placed audio strengths. It adds-- the whole fitness in VR, nobody was thinking about that back at the beginning. And it turns out that that is an excellent daily fitness thing to be doing. If you go play an hour of Beat Saber or Supernatural or something, that is legit solid exercise, and it's more fun than doing it just about any other way there.</p><p>- So that's kind of the arcade stage of things. If I were to say, with my experience with VR, the thing that I think is powerful is the-- maybe it's not here yet-- but the degree to which it is immersive in the way that Quake is immersive. It takes you to another world.</p><p>For me, because I'm a fan of role-playing games, the Elder Scrolls series, like Skyrim or even Daggerfall, it just takes you to another world. And when you're not in that world, you miss not being there. And then you just-- you kind of want to stay there forever, because life is shitty.</p><p>- Well, the whole point of my pitch for VR is that there was a time when we were kind of asked to come up with, like, what's your view about VR? And my pitch was that it should be better inside the headset than outside. It's the world as you want it.</p><p>And everybody thought that was dystopian. And that's like, oh, you're just going to forget about the world outside. And I don't get that mindset where the idea that if you can make the world better inside the headset than outside, you've just improved the person's life that has a headset that can wear it.</p><p>And there are plenty of things that we just can't do for everyone in the real world. Everybody can't have Richard Branson's private island. But everyone can have a private VR island. And it can have the things that they want on it. And there's a lot of these kind of rivalrous goods in the real world that VR can just be better at.</p><p>We can do a lot of things like that that can be very, very rich. So yeah, I think it's going to be a positive thing, this world, where people want to go back into their headset, where it can be better than somebody that's living in a tiny apartment can have a palatial estate in virtual reality.</p><p>They can have all their friends from all over the world come over and visit them without everybody getting on a plane and meeting in some place and dealing with all the other logistics hassles. There is real value in the presence that you can get for remote meetings. It's all the little things that we need to sort out.</p><p>But those are things that we have line of sight on. People that have been in a good VR meeting using workrooms, where you can say, oh, that was better than a Zoom meeting. But of course, it's more of a hassle to get into it. Not everyone has a headset.</p><p>Interoperability is worse. You can't have-- you cap out at a certain number. There's all these things that need to be fixed. But that's one of those things you can look at and say, we know there's value there. We just need to really grind hard, file off all the rough edges, and make that possible.</p><p>So you do think we have line of sight, because there's a reason, like-- I do this podcast in person, for example. Doing it remotely, it's not the same. And if somebody were to ask me why it's not the same, I wouldn't be able to write down exactly why. But you're saying that it's possible, whatever the magic is for in-person interaction, that immersiveness of the experience, we are almost there.</p><p>Yes. So it's a technical problem. So the idea of, like, I'm doing a VR interview with someone. I'm not saying it's here right now. But you can see glimmers of what it should be. And we largely know what would need to be fixed and improved to-- like you say, there's a difference between a remote interview doing a podcast over Zoom or something and face-to-face.</p><p>There's that sense of presence, that immediacy, the super low latency responsiveness, being able to see all the subtle things there, just occupying the same field of view. And all of those are things that we absolutely can do in VR. And that simple case of a small meeting with a couple people, that's the much easier case than everybody thinks, the Ready Player One multiverse with 1,000 people going across a huge bridge to amazing places.</p><p>That's harder in a lot of other technical ways. Not to say we can't also do that. But that's further away and has more challenges. But this small thing about being able to have a meeting with one or a few people and have it feel real, feel like you're there, like you have the same interactions and talking with them, you get subtle cues as we start getting eye and face tracking and some of the other things on high-end headsets.</p><p>A lot of that is going to come over. And it doesn't have to be as good. This is an important thing that people miss, where there was a lot of people that, especially rich people, that would look at VR and say, it's like, oh, this just isn't that good.</p><p>And I'd say, it's like, well, you've already been courtside, backstage, and on pit row. And you've done all of these experiences because you get to do them in real life. But most people don't get to. And even if the experience is only half as good, if it's something that they never would have gotten to do before, it's still a very good thing.</p><p>And as we can just-- we can push that number up over time. It has a minimum viable value level when it does something that is valuable enough to people. As long as it's better inside the headset on any metric than it is outside and people choose to go there, we're on the right path.</p><p>And we have a value gradient that I'm just always hammering on, we can just follow this value gradient, just keep making things better, rather than going for that one, close your eyes, swing for the fences, kind of silver bullet approach. - Well, I wonder if there's a value gradient for in-person meetings, because if you get that right, I mean, that would change the world.</p><p>- Yeah. - It doesn't need to, I mean, you don't need a Ready Player One. But I wonder if there's that value gradient you can follow along. Because if there is, and you follow it, then there'll be a certain like phase shift at a certain point where people will shift from Zoom to this.</p><p>I wonder, what are the bottlenecks? Is it software? Is it hardware? Is it like, is it all about latency? - So I have big arguments internally about strategic things like that, where I, like the next headset that's coming out that we've made various announcements about is gonna be a higher end headset, more expensive, more features.</p><p>Lots of people wanna make those trade-offs. I, you know, we'll see what the market has to say about the exact trade-offs we've made here. But if you wanna replace Zoom, you need to have something that everybody has. And- - So you like cheaper. - I like cheaper because also lighter and cheaper wind up being a virtuous cycle there where expensive and more features tends to also lead towards heavier.</p><p>And it just kind of goes, it's like, let's add more features. The features are not, you know, they have physical presence and weight and draw from batteries and all of those things. So I've always favored a lower end, cheaper, faster approach. That's why I was always behind the mobile side of VR rather than the higher end PC headsets.</p><p>And I think that's, you know, that's proven out well. But there's, you always, ideally we have a whole range of things, but if you've only got one or two things, it's important that those two things cover the, you know, the scope that you think is most important. When we're in a world when it's like cell phones and there's 50 of them on the market covering every conceivable ecological niche you want, that's gonna be great, but we're not gonna be there for a while.</p><p>- Where are the bottlenecks? Is it the hardware or the software? - Yeah, so right now, you can play, you can get workrooms on Quest and you can set up these things and it's a pretty good experience. It's surprisingly good. - I haven't tried it. It's surprisingly good. - Yeah, the voice latency is better on that than a lot better than a Zoom meeting.</p><p>So you've got a better sense of immediacy there. The expressions that you get from the current hardware with just kind of your controllers and your head is pretty realistic feeling. You've got a pretty good sense of being there with someone with it. - Are these like avatars of people?</p><p>Like do you get to see their body? - Yeah. - And they're sitting around a table? - Yeah. - And it feels better than Zoom? - Better than you'd expect for that. It is definitely, yeah, I'd say it's quite a bit better than Zoom when everything's working right. But there's still all the rough edges of, the reason Zoom became so successful is because they just nailed the usability of everything.</p><p>It's high quality with a absolutely first rate experience. And we are not there yet with any of the VR stuff. I'm trying to push hard to get, I keep talking about it. It's like, it needs to just be one click to make everything happen. And we're getting there in our home environment, not the whole workrooms application, but the main home where you can now kind of go over and click an invite.</p><p>And it still winds up taking five times longer than it should. But we're getting close to that where you click there, they click on their button and then they're sitting there in this good presence with you. But latencies need to get a lot better. User interface needs to get a lot better.</p><p>Ubiquity of the headsets needs to get better. We need to have a hundred million of them out there just so that everybody knows somebody that uses this all the time. - Well, I think it's a virtuous cycle because I do think the interface is the thing that makes or breaks this kind of revolution.</p><p>It's so interesting how like you said one click, but it's also like how you achieve that one click. I don't know. Can I ask a dark question? Maybe let's keep it outside of meta, but this is about meta, but also Google and big company. Are they able to do this kind of thing?</p><p>It seems like, let me put on my cranky old man hat, is they seem to not do a good job of creating these user-friendly interfaces as they get bigger and bigger as a company. Like Google has created some of the greatest interfaces ever early on in its, I mean, creating Gmail, just so many brilliant interfaces.</p><p>And it just seems to be getting crappier and crappier at that, same with meta, same with Microsoft. It's just, it seems to get worse and worse at that. I don't know what is it, because you've become more conservative, careful, risk averse, is that why? Can you speak to that?</p><p>- So it's been really eyeopening to me working inside a tech titan where I am, you know, I had my small companies and then we're acquired by a mid-size game publisher and then Oculus getting acquired by meta and meta has grown by a factor of many just in the eight years since the acquisition.</p><p>So I did not have experience with this. And it was interesting because I remember like, previously my benchmark for kind of use of resources was some of the government programs I interacted with on the aerospace side. And I remember thinking there was, okay, there's an air force program and they spent $50 million and they didn't launch anything.</p><p>They didn't even build anything. It was just kind of like they, you know, they made a bunch of papers and had some parts in a warehouse and nothing came of it. It's like $50 million. And I've had to radically recalibrate my sense of like how much money can be spent with mediocre resources.</p><p>Where on the plus side, VR has turned out, we've built pretty much exactly what, you know, we just passed the 10 year mark then from my, like my first demo of the Rift. And if I could have said what I wanted to have, it would have been a standalone inside out tracked 4K resolution headset that I, that could still plug into a PC for high-end rendering.</p><p>And that's exactly what we've got on Quest 2 right now. - First of all, let's pause on that with me being cranky and everything. It's what Meta achieved with Oculus and so on is incredible. I mean, this is, when I thought about the future of VR, this is what I imagined in terms of hardware, I would say.</p><p>And maybe in terms of the experience as well, but it's still not there somehow. - On the one hand, we did kind of achieve it and win, and we've got, we've sold, you know, we're a success right now, but the amount of resources that have gone into it, it winds up getting cluttered up in accounting where Mark did announce that they spent $10 billion a year like on Reality Labs.</p><p>Now Reality Labs covers a lot. It was, VR was not the large part of it. It also had Portal and Spark and the big AR research efforts. And it's been expanding out to include AI and other things there where there's a lot going on there. But $10 billion was just a number that I had trouble processing.</p><p>It's just, I feel sick to my stomach thinking about that much money being spent. But that's how they demonstrate commitment to this, where it's not more so than like, yeah, Google goes and cancels all of these projects, different things like that, while Meta is really sticking with the funding of VR and AR is still further out with it.</p><p>So there's something to be said for that. It's not just gonna vanish, the work's going in. I just wish it could be, all those resources could be applied more effectively because I see all these cases. I point out these examples of how a third party that we're kind of competing with in various ways.</p><p>There's a number of these examples and they do work with a 10th of the people that we do internally. And a lot of it comes from, yes, the small company can just go do it, while in a big company, you do have to worry about, is there some SDK internally that you should be using because another team's making it?</p><p>You have to have your cross-functional group meetups for different things. You do have more concerns about privacy or diversity and equity and safety of different things, parental issues and things that a small startup company can just kind of cowboy off and do something interesting. And there's a lot more that is a problem that you have to pay attention to in the big companies, but I'm not willing to believe that we are within even a factor of two or four of what the efficiency could be.</p><p>I am constantly kind of crying out for, it's like, we can do better than this. - Yeah, and you wonder what the mechanisms to unlock that efficiency are. There is some sense in a large company that an individual engineer might not believe that they can change the world. Maybe you delegate a little bit of the responsibility to be the one who changes the world in a big company, I think, but the reality is like the world will get changed by a single engineer anyway.</p><p>So whether inside Google or inside a startup, it doesn't matter. It's just like Google and Meta needs to help those engineers believe. They're the ones that are gonna decrease that latency. It'll take one John Carmack, the 20-year-old Carmack that's inside Meta right now to change everything. - And I try to point that out and push people.</p><p>It's like, try to go ahead. And when you see some, because there is, you get the silo mentality where you're like, okay, I know something's not right over there, but I'm staying in my lane here. And there's a couple people that I can think about that are willing to just like hop all over the place.</p><p>And man, I treasure them, the people that are just willing to, they're fearless. They will go over and they will go rebuild the kernel and change this distribution and go in and hack the firmware over here to get something done right. And that is relatively rare. There's thousands of developers and you've got a small handful that are willing to operate at that level.</p><p>And it's potentially risky for them. The politics are real in a lot of that. And I'm in the, very much the privileged position of, I'm more or less untouchable there where I've been dinged like twice for it. It's like, you said something insensitive in that post and you should probably not say that.</p><p>But for the most part, yes, I get away with every week I'm posting something pretty loud and opinionated internally. And I think that's useful for the company, but yeah, it's rare to have a position like that. And I can't necessarily offer advice for how someone can do that. - Well, you could offer advice to a company in general to give a little bit of freedom for the young, while the wildest ideas come from the young minds.</p><p>And so you need to give the young minds freedom to think big and wild and crazy. And for that, they have to be opinionated. They have to be, they have to think crazy ideas and thoughts and pursue them with a full passion without being slowed down by bureaucracy or managers and all that kind of stuff.</p><p>Obviously startups really empower that, but big companies could too. And that's a design challenge for big companies to see how can you enable that? How can you empower that? - Yeah, because the big company, there are so many resources there. And they do, amazing things do get accomplished, but there's so much more that could come out of that.</p><p>And I'm always hopeful. I'm an optimist in almost everything. I think things can get better. I think that they can improve things, that you go through a path and you're learning kind of what does and doesn't work. And I'm not ready to be fatalistic about the kind of the outcome of any of that.</p><p>- Me neither. I know too many good people inside of those large companies that are incredible. You have a friendship with Elon Musk. Often when I talk to him, he'll bring up how incredible of an engineer and just a big picture thinker you are. He has a huge amount of respect for you.</p><p>I just, I've never been a fly on the wall between the discussion between the two of you. I just wonder, is there something you guys debate, argue about, discuss? Is there some interesting problems that the two of you think about? You come from different worlds. Maybe there's some intersection in aerospace.</p><p>Maybe there's some intersection in your new efforts in artificial intelligence in terms of thinking. Is there something interesting you could say about sort of the debates the two of you have? - So I think in some ways, we do have a kind of similar background where we're almost exactly the same age and we had kind of similar programming backgrounds on the personal computers and even some of the books that we would read and things that would kind of turn us into the people that we are today.</p><p>And I think there is a degree of sensibility similarities where we kind of call bullshit on the same things and kind of see the same opportunities in different technology. And there's that sense of, I always talk about the speed of light solutions for things. And he's thinking about kind of minimum manufacturing and engineering and operational standpoints for things.</p><p>And so, I mean, I first met Elon right at the start of the aerospace era where I wasn't familiar with, I was still in my game dev bubble. I really wasn't familiar with all the startups that were going and being successful and what went on with PayPal and all of his different companies.</p><p>But I met him as I was starting to do Armadillo Aerospace and he came down with kind of his right-hand propulsion guy and we talked about rockets. What can we do with this? And it was kind of specific things about like how are our flight computers set up? What are different propellant options?</p><p>What can happen with different ways of putting things together? And then in some ways, he was certainly the biggest player in the sort of alt space community that was going on in the early 2000s. He was the most well-funded, although his funding in the larger scheme of things compared to a like a NASA or something like that was really tiny.</p><p>It was a lot more than I had at the time, but it was interesting. I had a point years later when I realized, okay, my financial resources at this point are basically what Elon's was when he went all in on SpaceX and Tesla. And there's, I think in many corners, he does not get the respect that he should about being a wealthy person that could just retire.</p><p>And he went all in where he was really going to, he could have gone bust. And there's plenty of people, you'd look at the sad athletes or entertainers that had all the money in the world and blew it. He could have been the business case example of that. But the things that he was doing, space exploration, electrification of transportation, solar city type things, these are big world level things.</p><p>And I have a great deal of admiration that he was willing to throw himself so completely into that. Because in contrast with myself, I was doing Armadillo Aerospace with this tightly bounded, it was John's crazy money at the time that had a finite limit on it. It was never going to impact me or my family if it completely failed.</p><p>And I was still hedging my bets working at id Software at the time when he had been really all in there. And I have a huge amount of respect for that. And people do not, the other thing I get irritated with is people would say, it's like, "Oh, Elon's just a business guy.</p><p>He just got like, he was gifted the money and he's just kind of investing in all of this." When he was really deeply involved in a lot of the decisions. Not all of them were perfect, but he cared very much about engine material selection, propellant selection. And for years he'd be kind of telling me, it's like, "Get off that hydrogen peroxide stuff." It's like, "Liquid oxygen is the only proper oxidizer for this." And the times that I've gone through the factories with him, we're talking very detailed things about like how this weld is made, how this sub-assembly goes together.</p><p>What are like startup shutdown behaviors of the different things. So he is really in there at a very detailed level. And I think that he is the best modern example now of someone that tries to, that can effectively micromanage some decisions on things on both Tesla and SpaceX to some degree where he cares enough about it.</p><p>I worry a lot that he's stretched too thin, that you get boring company and Neuralink and Twitter and all the other possible things there where I know I've got limits on how much I can pay attention to that I have to kind of box off different amounts of time.</p><p>And I look back at like my aerospace side of things. It's like, I did not go all in on that. I did not commit myself at a level that it would have taken to be successful there. And it's kind of a weird thing, just like having a discussion with him.</p><p>He's the richest man in the world right now, and he operates on a level that is still very much in my wheelhouse on a technical side of things. - So doing that systems level type of thinking where you can go to the low level details and go up high to the big picture.</p><p>Do you think in aerospace arena in the next five, 10 years, do you think we're gonna put a human on Mars? Like, what do you think is the interesting? - No, I do. In fact, I made a bet with someone with a group of people kind of this about whether boots on Mars by 2030.</p><p>And this was kind of a fun story because I was at an Intel sponsored event and we had a bunch of just world-class brilliant people. And we were talking about computing stuff, but the after dinner conversation was like, what are some other things? How are they gonna go in the future?</p><p>And one of the ones tossed up on the whiteboard was like boots on Mars by 2030. And most of the people in the room thought, yes. They thought that like SpaceX is kicking ass. We've got all this possible stuff. Seems likely that it's gonna go that way. And I said, no, I think less than 50% chance that it's going to make it there.</p><p>And people were kind of like, oh, why the pessimism or whatever? And of course I'm an optimist at almost everything, but for me to be the one kind of outlier saying, no, I don't think so. Then I started saying some of the things I said, well, let's be concrete about it.</p><p>Let's bet $10,000 that it's not gonna happen. And this was really a startling thing to see that I, again, room full of brilliant people, but as soon as like money came on the line and they were like, do I want to put 10,000? I was not the richest person in the room.</p><p>There were people much better off than I was. There was a spectrum, but as soon as they started thinking, it's like, oh, I could lose money by keeping my position right now. And all these engineers, they engaged their brain. They started thinking, it's like, okay, launch windows, launch delays, how many times would it take to get this right?</p><p>What historical precedents do we have? And then it mostly came down to, it's like, well, what about in transit by 2030? And then what about different things or would you go for 2032? But one of the people did go ahead and was optimistic enough to make a bet with me.</p><p>So I have a $10,000 bet that by 2030, I think it's gonna happen shortly thereafter. I think there will probably be infrastructure on Mars by 2030 but I don't think that we'll have humans on Mars on 2030. I think it's possible, but I think it's less than a 50% chance, so I felt safe making that bet.</p><p>- Well, I think you had an interesting point. Correct me if I'm wrong. That's a dark one. That should perhaps help people appreciate Elon Musk which is in this particular effort, Elon is critical to the success. SpaceX seems to be critical to the 20, humans on Mars by 2030 or thereabouts.</p><p>So if something happens to Elon, then all of this collapses. - And this is in contrast to the other $10,000 bet I made kind of recently. And that was self-driving cars at like a level five running around cities. And people have kind of nitpicked that that we probably don't mean exactly level five but the guy I'm having the bet with is we're gonna be, we know what we mean about this.</p><p>- Jeff Atwood. - Yeah, coding horror and stack overflow and all. But I, yeah, I mean, it's just, he doesn't think that people are gonna be riding around in robo taxis in 2030 in major cities just like you take an Uber now. And I think it will. - You think it will.</p><p>- And I think, and the difference is everybody looks at this it's like, oh, but Tesla has been wrong for years. They've been promising it for years and it's not here yet. And the reason this is different than the bet with Mars is Mars really is more than is comfortable a bet on Elon Musk.</p><p>I am, that is his thing. And he is really going to move heaven and earth to try to make that happen. - Perhaps not even SpaceX. - Yeah. - Perhaps just Elon Musk. - Yeah, because if Elon went away and SpaceX went public and got a board of directors, there are more profitable things they could be doing than focusing on human presence on Mars.</p><p>So this really is a sort of personal thing there. And in contrast with that, self-driving cars have a dozen credible companies working really hard. And while yes, it's going slower than most people thought it would, betting against that is a bet against almost the entire world in terms of all of these companies that have all of these incentives.</p><p>It's not just one guy's passion project. And I do think that it is solvable. Although I recognize it's not a hundred percent chance because it's possible the long tail of self-driving problems winds up being an AGI complete problem. I think there's plenty of value to mine out of it with narrow AI.</p><p>And I think that it's going to happen probably more so than people expect. But it's that whole sigmoid curve where you overestimate the near-term progress and you underestimate the long-term progress. And I think self-driving is gonna be like that. And I think 2030 is still a pretty good bet.</p><p>- Yeah, unfortunately, self-driving is a problem that is safety critical, meaning that if you don't do it well, people get hurt. - But the other side of that is people are terrible drivers. So it is not going to be, that's probably gonna be the argument that gets it through is like we can save 10,000 lives a year by taking imperfect self-driving cars and letting them take over a lot of driving responsibilities.</p><p>It's like, was it 30,000 people a year die in auto accidents right now in America. And a lot of those are preventable. And the problem is you'll have people that every time a Tesla crashes into something, you've got a bunch of people that literally have vested interest shorting Tesla to come out and make it the worst thing in the world.</p><p>And people will be fighting against that. But optimist in me again, I think that we will have systems that are statistically safer than human drivers. And we will be saving thousands and thousands of lives every year when we can hand over more of those responsibilities to it. - I do still think as a person who studied this problem very deeply from a human side as well, it's still an open problem how good/bad humans are driving.</p><p>It's a kind of funny thing we say about each other. Oh, humans suck at driving. Everybody except you, of course, like we think we're good at driving. But after really studying it, I think you start to notice, 'cause I watched hundreds of hours of humans driving with the projects of this kind of thing.</p><p>You've noticed that even with the distraction, even with everything else, humans are able to do some incredible things with the attention. Even when you're just looking at a smartphone, just to get cues from the environment, to make last seconds decisions, to use instinctual type of decisions that actually save your ass time and time and time again, and are able to do that with so much uncertainty around you in such tricky dynamic environments.</p><p>I don't know. I don't know exactly how hard is it to beat that kind of skill of common sense reasoning. - This is one of those interesting things that there've been a lot of studies about how experts in their field usually underestimate the progress that's going to happen because an expert thinks about all the problems they deal with.</p><p>And they're like, "Damn, I'm gonna have a hard time solving all of this." And they filter out the fact that they are one expert in a field of thousands. And you think about, "Yeah, I can't do all of that." And you sometimes forget about the scope of the ecosystem that you're embedded in.</p><p>And if you think back eight years, very specifically the state of AI and machine learning, where was that we had just gotten ResNets probably at that point. And you look at all the amazing magical things that have happened in eight years. And they do kind of seem to be happening a little faster in recent years also.</p><p>And you project that eight more years into the future, where again, I think there's a 50% chance we're gonna have signs of life of AGI, which we can put through driver's ed if we need to, to actually build self-driving cars. And I think that the narrow systems are going to have real value demonstrated well before then.</p><p>- So signs of life in AGI. You've mentioned that, okay, first of all, you're one of the most brilliant people on this earth. You could be solving a number of different problems, as you've mentioned. Your mind was attracted to nuclear energy. Obviously virtual reality with the metaverse is something you could have a tremendous impact on.</p><p>- I do wanna say a quick thing about nuclear energy, where this is something that I really, this so precisely feels like aerospace before SpaceX, where from everything that I know about all of these, the physics of this stuff hasn't changed. And the reasons why things are expensive now are not fundamental.</p><p>Somebody should be going into a really hard Elon Musk style at fission, economical fission, not fusion, where the fusion is the kind of the darling of people that wanna go and do nuclear because it doesn't have the taint that fission has in a lot of people's minds. But it's an almost absurdly complex thing where nuclear fusion, as you look at the tokamaks or any of the things that people are building, and it's doing all of this infrastructure just at the end of the day to make something hot to that you can then turn into energy through a conventional power plant.</p><p>And all of that work, which we think we've got line of sight on, but even if it comes out, then you have to do all of that immensely complex, expensive stuff just to make something hot, where nuclear fission is basically you put these two rocks together and they get hot all by themselves.</p><p>That is just that much simpler. It's just orders of magnitude simpler. And the actual rocks, the refined uranium, is not very expensive. It's a couple percent of the cost of electricity. That's why I made that point where you could have something which was five times less efficient than current systems.</p><p>And if the rest of the plant was a whole bunch cheaper, you could still be super, super valuable. - So how much of the pie do you think could be solved by nuclear energy by fission? So how much could it become the primary source of energy on earth? - It could be most of it.</p><p>Like the reserves of uranium as it stands now could not power the whole earth. But you get into breeder reactors and thorium and things like that that you do for conventional fission. There is enough for everything. Now, I mean, solar photovoltaic has been amazing. One of my current projects is working on an off-grid system.</p><p>And it's been fun just kind of, again, putting my hands on all the stripping the wires and wiring things together and doing all of that. And just having followed that a little bit from the outside over the last couple decades, there's been semiconductor-like magical progress in what's going on there.</p><p>So I'm all for all of that, but it doesn't solve everything. And nuclear really still does seem like the smart money bet for what you should be getting for baseband on a lot of things. And solar may be cheaper for, you know, peaking over air conditioning loads during the summer and things that you can push around in different ways.</p><p>But it's one of those things that's, it's just strange how we've had the technology sitting there, but these non-technical reasons on the social optics of it has been this major forcing function for something that really should be at the cornerstone of all of the world's concerns with energy. It's interesting how the non-technical factors have really dominated something that is so fundamental to kind of the existence of the human race as we know it today.</p><p>- And much of the troubles of the world, including wars in different parts of the world, like Ukraine is energy-based. And yeah, it's just sitting right there to be solved. That said, I mean, to me personally, I think it's clear that if AGI were to be achieved, that would change the course of human history.</p><p>- AGI wise, I was, you know, I was making this decision about what do I want to focus on after VR? And I'm still working on VR regularly. I spend a day a week kind of consulting with Meta and I, you know, Boz styles me the consulting CTO is kind of like the Sherlock Holmes that comes in and consults on some of the specific tough issues.</p><p>And I'm still pretty passionate about all of that, but I have been figuring out how to compartmentalize and force that into a smaller box to work on some other things. And I did come down to this decision between working on economical nuclear fission or artificial general intelligence. And the fission side of things, I've got a bunch of interesting things going that way, but it would take, that would be a fairly big project thing to do.</p><p>I don't think it needs to be as big as people expect. I do think something original SpaceX sized, you build it, power your building off of it, and then the government, I think, will come around to what you need to. Everybody loves an existence proof. I think it's possible somebody should be doing this, but it's going to involve some politics.</p><p>It's going to involve decent sized teams and a bunch of this cross-functional stuff that I don't love. While the artificial general intelligence side of things, it seems to me like this is the highest leverage moment for potentially a single individual, potentially in the history of the world, where the things that we know about the brain, about what we can do with artificial intelligence, nobody can say absolutely on any of these things, but I am not a madman for saying that it is likely that the code for artificial general intelligence is going to be tens of thousands of lines of code, not millions of lines of code.</p><p>This is code that conceivably one individual could write, unlike writing a new web browser operating system. And based on the progress that AI has, machine learning has made in the recent decade, it's likely that the important things that we don't know are relatively simple. There's probably a handful of things, and my bet is that I think there's less than six key insights that need to be made.</p><p>Each one of them can probably be written on the back of an envelope. We don't know what they are, but when they're put together in concert with GPUs at scale and the data that we all have access to, that we can make something that behaves like a human being or like a living creature, and that can then be educated in whatever ways that we need to get to the point where we can have universal remote workers, where anything that somebody does mediated by a computer and doesn't require physical interaction that an AGI will be able to do.</p><p>We can already simulate the equivalent of the Zoom meetings with avatars and synthetic deep fakes and whatnot. We can definitely do that. We have superhuman capabilities on any narrow thing that we can formalize and make a loss function for, but there's things we don't know how to do now, but I don't think they are unapproachably hard.</p><p>Now, that's incredibly hubristic to say that it's like, but I think that what I said a couple years ago is a 50% chance that somewhere there will be signs of life of AGI in 2030, and I've probably increased that slightly. I may be at 55, 60% now, because I do think there's a little sense of acceleration there.</p><p>- So I wonder what the, and by the way, you also written that, "I bet with hindsight, we will find that clear antecedents of all the critical remaining steps for AGI are already buried somewhere in the vast literature of today." So the ideas are already there. - I think that's likely the case.</p><p>One of the things that appeals to so many people, including me, about the promise of AGI is we know that we're only drinking from a straw, from the fire hose of all the information out there. I mean, you look at just in a very narrowly bounded field, like machine learning, like you can't read all the papers that come out all the time.</p><p>You can't go back and read all the clever things that people did in the '90s or earlier that people have forgotten about, because they didn't pan out at the time when they were trying to do them with 12 neurons. And so this idea that, yeah, I think there are gems buried in some of the older literature that was not the path taken by everything.</p><p>And you can see a kind of herd mentality on the things that happen right now. It's almost funny to see. It's like, oh, Google does something, and OpenAI does something, Meta does something. And they're the same people that all talk to each other, and they're all one-upping each other, and they're all capable of implementing each other's work given a month or two after somebody has an announcement of that.</p><p>But there's a whole world of possible approaches to machine learning. And I think that we probably will, in hindsight, go back and see it's like, yeah, that was kind of clearly predicted by this early paper here. You know, and this turns out that if you do this and this and take this result from animal training and this thing from neuroscience over here and put it together and set up this curriculum for them to learn in, that that's kind of what it took.</p><p>You don't have too many people now that are still saying it's not possible or it's going to take hundreds of years. And 10 years ago, you would get a collection of experts, and you would have a decent chunk on the margin that either say not possible or a couple hundred years, might be centuries.</p><p>And the median estimate would be like 50, 70 years. And it's been coming down. And I know with me saying eight years for something, that still puts me on the optimistic side, but it's not crazy out in the fringes. And just being able to look at that at a meta level about the trend of the predictions going down there, the idea that something could be happening relatively soon.</p><p>Now, I do not believe in fast takeoffs. You know, that's one of the safety issues that people say, it's like, oh, it's going to go, boom, and the AI is going to take over the world. There's a lot of reasons. I don't think that's a credible position. And I think that we will go from a point where we start seeing things that credibly look like, look like animals behaviors, and I have a human voice box wired into them.</p><p>It's like, I tried to get Elon to say, it's like your pig at Neuralink, give it a human voice box and let it start learning human words. I think that, you know, I think animal intelligence is closer to human intelligence than a lot of people like to think. And I think that culture and modalities of IO are make the gulf seem a lot bigger than it actually is.</p><p>There's just that smooth spectrum of how the brain developed and cortexes and scaling of different things going on there. - Culture modalities of IO, yes. Languages, sort of loss in translation conceals a lot of intelligence. And so when you think about signs of life for AGI, you're thinking about human interpretable signs.</p><p>- So the example I give, if we get to the point where you've got a learning disabled toddler, some kind of real special needs child that can still interact with their favorite TV show and video game and can be trained and learn in some appreciably human-like way. At that point, you can deploy an army of engineers, cognitive scientists, education, developmental education people.</p><p>And you've got so many advantages there unlike real education, where you can do rollbacks and A/B testing, and you can find a golden path through a curriculum of different things. If you get to that point, learning disabled toddler, I think that it's gonna be a done deal. - But do you think we'll know when we see it?</p><p>So there's been a lot of really interesting general learning progress from DeepMind, opening the eye a little bit too. I tend to believe that Tesla Autopilot deserves a lot more credit than it's getting for making progress in the general, on doing the multitask learning thing and increasing the number of tasks and automating that process of sort of learning from the edge, discovering the edge cases and learning from the edge cases.</p><p>That is, it's really approaching from a different angle, the general learning problem of AGI. But the more clear approach comes from DeepMind, where you have these kind of game situations and you build systems there. But I don't know, people seem to be quite- - Yeah, there will always be people that just won't believe it.</p><p>And I fundamentally don't care. I mean, I don't care if they don't believe it. When it starts doing people's jobs, and I mean, like, I don't care about the philosophical zombie argument at all. - Absolutely, absolutely. But do you think you will notice that something special has happened here?</p><p>And/or, because to me, I've been noticing a lot of special things. I think a lot of credit should go to DeepMind for AlphaZero. That was truly special. So self-play mechanisms achieve, sort of solve problems that used to be thought unsolvable, like the game of Go. Also, I mean, protein folding, starting to get into that space where learning is doing, at first, it wasn't end-to-end learning, and now it's end-to-end learning of a very difficult, previously thought unsolvable problem of protein folding.</p><p>And so, yeah, where do you think would be a really magical moment for you? - There have been incredible things happening in recent years. Like you say, all of the things from DeepMind and OpenAI that have been huge showpiece things. But when you really get down to it, and you read the papers, and you look at the way the models are going, you know, it's still like a feed forward.</p><p>You push something in, something comes out on the end. I mean, maybe there's diffusion models or Monte Carlo tree rollouts and different things going on, but it's not a being. It's not close to a being. I am, that's going through a lifelong learning process. - Do you want something that kind of gives signs of a being?</p><p>Like what's the difference between a neural network, a feed forward neural network and a being? Where's the- - Fundamentally, the brain is a recurrent neural network generating an action policy. I mean, it's implemented on a biological substrate. And it's interesting thinking about things like that, where we know fundamentally the brain is not a convolutional neural network or a transformer.</p><p>Those are specialized things that are very valuable for what we're doing, but it's not the way the brain's doing. Now, I do think consciousness and AI in general is a substrate independent mechanism where it doesn't have to be implemented the way the brain is. But if you've only got one existence proof, there's certainly some value in caring about what it says and does.</p><p>And so the idea that anything that can be done with a narrow AI that you can quantify up a loss function for a reward mechanism, you're almost certainly going to be able to produce something that's more resource effective to train and deploy and use in an inference mode, train a whole lot and use it in inference.</p><p>But a living being is gonna be something that's a continuous lifelong learned task agnostic thing. And while a lot of- - So the lifelong learning is really important too. And the long-term memory. So memory is a big weird part of that puzzle. - We've got, again, I have all the respect in the world for the amazing things that are being done now, but sometimes they can be taken a little bit out of context with things like there's some smoke and mirrors going on, like the Gato, the recent work, the multitask learning stuff.</p><p>It's amazing that it's one model that plays all the Atari games, as well as doing all of these other things. But of course, it didn't learn to do all of those. It was instructed in doing that by other reinforcement learners going through and doing that. And even in the case of all the games, it's still going with a specific hand-coded reward function in each of those Atari games, where it's not that, how does it, it just wants to spend its summer afternoon playing Atari because that's the most interesting thing for it.</p><p>So it's again, not a general, it's not learning the way humans learn. And there's, I believe, a lot of things that are challenging to make a loss function for that you can train through these existing conventional things. We are gonna chip away at all the things that people do, that we can turn into narrow AI problems and billions of, probably trillions of dollars of value are gonna be created by that.</p><p>But there's still gonna be a set of things and we've got questionable cases like the self-driving car, where it's possible, it's not my bet, but it's plausible that the long tail could be problematic enough, that that really does require a full-on artificial general intelligence. The counter argument is that data solves almost everything.</p><p>Everything is an interpolation problem if you have enough data and Tesla may be able to get enough data from all of their deployed stuff to be able to work like that, but maybe not. And there are all the other problems about, like say you wanna have a strategy meeting and you wanna go ahead and bring in all of your remote workers and your consultants, and you want a world where some of those could be AIs that are talking and interacting with you in an area that is too murky to have a crisp loss function, but they still have things that on some level, they're rewarded on some internal level for building a valuable to humans, kind of life and ability to interact with things.</p><p>- See, I still think that a self-driving car solving that problem will take us very far towards AGI. You might not need AGI, but I am really inspired by what Autopilot is doing. Waymo, so some of the other companies, I think Waymo leads the way there, is also really interesting, but they don't have quite as ambitious of an effort in terms of learning-based, sort of data-hungry approach to driving, which I think is very close to the kind of thing that would take us far towards AGI.</p><p>- Yeah, and it's a funny thing because as far as I can tell, Elon is completely serious about all of his concerns about AGI being an existential threat. And I tried to draw him out to talk about AI, he just didn't want to. And I think that, I get that little fatalistic sense from him.</p><p>And it's weird because his company could very well be the leading company leading towards a lot of that, where Tesla being a super pragmatic company that's doing things because they really wanna solve this actual problem. It's a different vibe than the research-oriented companies where it's a great time to be an AI researcher, you've got your pick of trillion dollar companies that will pay you to kind of work on the problems you're interested in, but that's not necessarily driving hard towards the core problem of AGI as something that's going to produce a lot of value by doing things that people currently do or would like to do.</p><p>- I mean, I have a million questions to you about your ideas about AGI, but do you think it needs to be embodied? Do you think it needs to have a body to start to notice the signs of life and to develop the kind of system that's able to reason, perceive the world in the way that an AGI should and act in the world?</p><p>So should we be thinking about robots or can this be achieved in a purely digital system? - I have a clear opinion on that. And that's that, no, it does not need to be embodied in the physical world where you could say most of my career is about making simulated virtual worlds, in games or virtual reality.</p><p>And so on a fundamental level, I believe that you can make a simulated environment that provides much of the value of what the real environment does and restricting yourself to operating at real time in the physical world with physical objects, I think is an enormous handicap. I mean, that's one of the real lessons driven home by all my aerospace work is that, reality is a bitch in so many ways there where dealing with all the mechanical components, like everything fails, Murphy's law, even if you've done it right before on your fifth one, it might come out differently.</p><p>So yeah, I think that anybody that is all in on the embodied aspect of it, they are tying a huge weight to their ankles. And I think that I would almost count them out, anybody that's making that a cornerstone of their belief about it, I would almost write them off as being worried about them getting to AGI first.</p><p>I was very surprised that Elon's big on the humanoid robots. I mean, like the NASA Robonaut stuff was always, almost a gag line, like, what are you doing people? - Well, that's very interesting 'cause he has a very pragmatic view of that. That's just a way to solve a particular problem in a factory.</p><p>- Now I do think that once you have an AGI, robotic bodies, humanoid bodies are going to be enormously valuable. I just don't think they're helpful getting to AGI. - Well, he has a very sort of practical view, which I disagree with and I argue with him, but is a practical view that there's, you know, you could transfer the problem of driving to the problem of robotic manipulation because so much of it is perception.</p><p>It's perception and action, and it's just a different context. And so you can apply all the same kind of data engine learning processes to a different environment. And so why not apply it to the human or robot environment? But I think, I do think that there's a certain magic to the embodied robot.</p><p>- That may be the thing that finally convinces people. - Yes. - But again, I don't really care that much about convincing people. You know, the world that I'm looking towards is, you know, you go to the website and say, I want five Frank 1As to, you know, to work on my team today and they all spin up and they start showing up in your Zoom meetings.</p><p>- To push back, but also to agree with you, but first to push back, I do think you need to convince people for them to welcome that thing into their life. - I think there's enough businesses that operate on an objective kind of profit loss sort of basis that, I mean, if you look at how many things, again, talking about the world as an evolutionary space there, when you do have free markets and you have entrepreneurs, you are gonna have people that are gonna be willing to go out and try whatever crazy things.</p><p>And when it proves to be beneficial, you know, there's fast followers in all sorts of places. - Yeah, and you're saying that, I mean, you know, Quake and VR is a kind of embodiment, but just in a digital world. And if you're able to demonstrate, if you're able to do something productive in that kind of digital reality, then AGI doesn't need to have a body.</p><p>- Yeah, it's like one of the really practical, technical questions that I kind of keep arguing with myself over. If you're doing a training and learning and you've got, like you can watch Sesame Street, you can play Master System games or something, is it enough to have just a video feed that is that video coming in?</p><p>Or should it literally be on a virtual TV set in a virtual room, even if it's, you know, a simple room just to have that sense of, you're looking at a 2D projection on a screen versus having the screen beamed directly into your retinas. And I, you know, I think it's possible to maybe get past some of these signs of life of things with the just kind of projected directly into the receptor fields, but eventually for more kind of human, emotional connection for things, probably having some VR room with a lot of screens in it for the AI to be learning in is likely helpful.</p><p>- And maybe a world of different AIs interacting with each other. - Self-play I do think is one of the critical things where socialization wise, one of the other limitations I set for myself thinking about these is I need something that is at least potentially real time, because I want, it's nice you can always slow down time, you can run on a subscale system and test an algorithm at some lower level.</p><p>And if you've got extra horsepower, running it faster than real time is a great thing. But I want to be able to have the AIs either socially interact with each other or critically with actual people. You're sort of child development psychiatrist that comes in and interacts and does the good boy, bad boy sort of thing as they're going through and exploring different things.</p><p>And it's nice to, I come back to the value of constraints in a lot of ways. And if I say, well, one of my constraints is real time operation. I mean, it might still be a huge data center full of computers, but it should be able to interact on a Zoom meeting with people.</p><p>And that's how you also do start convincing people, even if it's not a robot body moving around, which eventually gets to irrefutable levels. But if you can go ahead and not just type back and forth to a GPT bot on something, but you're literally talking to them in an embodied over Zoom form and working through problems with them or exploring situations, having conversations that are fully stateful and learned.</p><p>I think that that's a valuable thing. So I do keep all of my eyes on things that can be implemented within sort of that 30 frames per second kind of work. And I think that's feasible. - Do you think the most compelling experiences that first will be for pleasure or for business as they ask in airports?</p><p>So meaning is it, if it's interacting with AI agents, will it be sort of like friends, entertainment, almost like a therapist or whatever, that kind of interaction? Or is it in the business setting, something like you said, brainstorming different ideas. So this is all a different formulation of kind of a Turing test or the spirit of the original Turing test.</p><p>Where do you think the biggest benefit will first come? - So it's gonna start off hugely expensive. I mean, you're gonna, if we're still all guessing about what compute is gonna be necessary. I fall on the side of, I don't think you run the numbers and you're like 86 billion neurons, a hundred trillion synapses.</p><p>I don't think those all need to be weights. I don't think we need models that are quite that big, evaluated quite that often. I base that on, we've got reasonable estimates of what some parts of the brain do. We don't have the neocortex formula, but we kind of get some of the other sensory processing.</p><p>And it doesn't feel like we need to, we can simulate that in computers for less weights, but still it's probably going to be thousands of GPUs to be running a human level AGI. Depending on how it's implemented, that might give you sort of a clan of 128 kind of run in batch people, depending on whether there's sparsity in the way the weights are and things are set up.</p><p>If it is a reasonably dense thing, then just the memory bandwidth trade-offs means you get 128 of them at the same time. And either it's all feeding together, learning in parallel or kind of all running together, kind of talking to a bunch of people. But still, if you've got thousands of GPUs necessary to run these things, it's going to be kind of expensive where it might start off $1,000 an hour for your even post-development or something for that, which would be something that you would only use for a business, something where you think they're going to help you make a strategic decision or point out something super important.</p><p>But I also am completely confident that we will have another factor of 1,000 in cost performance increase in AGI-type calculations. Not in general computing necessarily, but there's so much more that we can do with packaging, making those right trade-offs, all those same types of things that in the next couple decades, 1,000x easy.</p><p>And then you're down to $1 an hour. And then you're kind of like, well, I should have an entourage of AIs that are following me around, helping me out on anything that I want them to do. - That's one interesting trajectory, but I'll push back 'cause I have... So in that case, if you want to pay thousands of dollars, it should actually provide some value.</p><p>I think it's easier for cheaper to provide value via a dumb AI that will take us towards AGI to just have a friend. I think there's an ocean of loneliness in the world. And I think an effective friend that doesn't have to be perfect, that doesn't have to be intelligent, that has to be empathic, having emotional intelligence, having ability to remember things, having ability to listen.</p><p>Most of us don't listen to each other. One of the things that love and when you care about somebody, when you love somebody is when you listen. And that is something we treasure about each other. And if an AI can do that kind of thing, I think that provides a huge amount of value.</p><p>And very importantly, provides value in its ability to listen and understand versus provide really good advice. I think providing really good advice is another next level step that would... I think it's just easier to do companionship. - Yeah, I wouldn't disagree. I mean, I think that there's very few things that I would argue can't be reduced to some kind of a narrow AI.</p><p>I think we can do trillion dollars of value easily in all the things that can be done there. And a lot of it can be done with smoke and mirrors without having to go the whole thing. I mean, there's going to be the equivalent of the doom version for the AGI that's not really AGI, it's all smoke and mirrors, but it happens to do enough valuable things that it's enormously useful and valuable to people.</p><p>But at some point you do want to get to the point where you have the fully general thing and you stop making bespoke specialized systems for each thing and you wind up, start using the higher level language instead of writing everything in assembly language. - What about consciousness? The C word, do you think that's fundamental to solving AGI or is it a quirk of human cognition?</p><p>- So I think most of the arguments about consciousness don't have a whole lot of merit. I think that consciousness is kind of the way the brain feels when it's operating. - Yes. - And this idea that, you know, I do generally subscribe to sort of the pandemonium theories of consciousness where there's all these things bubbling around.</p><p>And I think of them as kind of slightly randomized, sparse distributed memory bit strings of things that are kind of happening, recalling different associative memories. And eventually you get some level of consensus and it bubbles up to the point of being a conscious thought there. And the little bits of stochasticity that are sitting on in this, as it cycles between different things and recalls different memory, that's largely our imagination and creativity.</p><p>So I don't think there's anything deeply magical about it, certainly not symbolic. I think it is generally the flow of these associations drawn up with stochastic noise, overlaid on top of them. I think so much of that is like, it depends on what you happen to have in your field of view as some other thought was occurring to you that overlay and blend into the next key that queries your memory for things.</p><p>And that kind of determines how, you know, how your chain of consciousness goes. - So that's kind of the qualia, the subjective experience of it is not essential for intelligence. - I don't think so. I don't think there's anything really important there. - What about some other human qualities like fear of mortality and stuff like that?</p><p>Like the fact that this ride ends, is that important? Like, you know, we've talked so much about this conversation about the value of deadlines and constraints. Do you think that's important for intelligence? - Actually a super interesting angle that I don't usually take on that about has death being a deadline that forces you to make better decisions.</p><p>Because I have heard people talk about how, if you have immortality, people are gonna stop trying and working on things because they've got all the time in the world. But I would say that I don't expect it to be a super critical thing that a sense of mortality and death, impending death is necessary there.</p><p>Because those are things that they do wind up providing reward signals to us. And we will be in control of the reward signals. And there will have to be something fundamental that causes, that engenders curiosity and goal setting. And all of that, something is gonna play in there at the reward level.</p><p>I am, you know, whether it's positive or negative or both. I don't have any strong opinions on exactly what it's going to be. But that's that type of thing where I doubt that might be one of those half dozen key things that has to be sorted out on exactly what the master reward that's the meta reward over all of the local task specific rewards have to be.</p><p>That could be that big negative reward of death. Maybe not death, but ability to walk away from an interaction. So it bothers me when people treat AI systems like servants. So it doesn't bother me, but I mean, it really is drawing the line between what an AI system could be.</p><p>It's limiting the possibility of what an AI system could be is treating them as justice tools. Now that's of course, from a narrow AI perspective, there's so many problems that narrow AI could solve, just like you said, as in its form of a tool, but it could also be a being, which is much more than a tool.</p><p>And to become a being, you have to respect that thing for being a being. And for that, it has to be able to have, to make its own decisions, to walk away, to say I had enough of you. I would like to break up with you now. You've not treated me well, and I would like to move on.</p><p>So I think that actually, that choice to end things. - So I, a couple of things on that. So on the one hand, it is kind of disturbing when you see people being like, people that are mean to robots and mean to Alexa and whatever. And that seems to speak badly about humanity, but there's also the exact opposite side of that, where you have so many people that imbue humanity in inanimate objects or things that are toys or that are relatively limited.</p><p>So I think there may even be more danger about people putting more emotional investment into a lot of these proto-AIs in different ways. - And then the AI would manipulate that. But, you know. - But as far as like the AI ethnic sides of things, I really stay away from any of those discussions or even really thinking about it.</p><p>It's similar with the safety things, where I think it's just premature. And there's a certain class of people that enjoy thinking about impractical things, things that are not in the world and of pragmatic effect around you. And I think that, again, because I don't think there's gonna be a fast takeoff, I think we actually will have time to have these debates when we know the shape of what we're debating.</p><p>And some people do take a principled approach that they think it's gonna go too fast, that you really do need to get ahead of it, that you need to be thinking about this because we have slow processes of coming to any kind of consensus or even coming up with ideas about this.</p><p>And maybe that's true. I wouldn't put any of my money or funding into something like that because I don't think it's a problem yet. And I think that we will have these signs of life when we've got our learning disabled toddler, we should really start talking about some of the safety and ethics issues, but probably not before then.</p><p>- Can you elaborate briefly about why you don't think there'll be a fast takeoff? Is there some deep intuition you have about it? Does it because it's grounded in the physical world or why? - Yeah, so it is my belief that we're gonna start off with something that requires thousands of GPUs.</p><p>And I don't know if you've tried to go get a thousand GPU instance on a cloud anytime recently, but these are not things that you can just go spin up hundreds of. There are real challenges to, I mean, these things are gonna take data centers and data centers take years to build.</p><p>And the last few years, we've seen a few of them kind of coming up, going in different places. They're big engineering efforts. You can hear people bemoan about the fact that, I know the network was wired all wrong and it took them a month to go unwire it and rewire it the right way.</p><p>These aren't things that you can just magic into existence. And the ideas of, like the old tropes about it's gonna escape onto the internet and take over other systems. There's the fast takeoff ones are clearly nonsense because you just can't open TCP connections above a certain rate, no matter how smart you are.</p><p>Even if you have perfect hacking ability that take over the world in an instant sort of thing just isn't plausible at all. And even if you had access to all of the resources, these are going to be specialized systems where you're going to wind up with something that is architected around exactly this chip with this interconnect.</p><p>And it's not just gonna be able to be plopped somewhere else. Now, interestingly, it is going to be something that the entire code for all of it will easily fit on a thumb drive. That's total spy movie thriller sorts of things where you could have, hey, we cracked the secret AGI and it fits on this thumb drive and anyone could steal it.</p><p>Now they're still gonna have to build the right data center to deploy it and have the right kind of life experience curriculum to take it up to the point where it's valuable. But the real core of it, the magic that's gonna happen there is going to be very small.</p><p>It's again, tens of thousands of lines of code, not millions of lines of code. - It is possible to imagine a world, as you mentioned in this spy thriller view, if it's just a few lines of code, we can imagine a world where the surface of computation is growing, maybe growing exponentially, meaning the refrigerators start getting a GPU.</p><p>And just, first of all, the smartphones, the billions of smartphones, but maybe if there become highways through which code can spread across the entirety of the computation surface, then you don't any longer have to book AWS GPUs. - There were real fundamental issues there. When you start getting down to taking an actual problem and putting it on an abstract machine like that, that has not worked out well in practice.</p><p>And the idea that there was always, like it's always been easy to come up with ways to compute faster, to say more flops or more giga ops or whatever there. That's usually the easy part, but you then have interconnect and then memory for what goes into it. And when you talk about saying, well, cell phones, well, you're limited to like a 5G connection or something on that.</p><p>And if you say how, if you take your calculation and you factor it across a million cell phones, instead of a thousand GPUs in a warehouse, you might be able to have some kind of a substrate like that, but it could be operating then at one 1000th the speed.</p><p>And so, yes, you could have an AGI working there, but it wouldn't be a real time AGI. It would be something that is operating at really a snail's pace, much, much slower than kind of human level thought for things. I'm not worried about that problem. - You're transferring the problem into the interconnect, the communication, the shared memory, the collective intelligence aspect of it, which is extremely difficult as well.</p><p>- I mean, it's back to the very earliest days of supercomputers. You still have the balance between bandwidth, storage and computation. And sometimes they're easier to get one or the other, but it's been remarkably constant across all those years that you still need all three. - What do your efforts now, you mentioned to me that you're really committing to AI at this stage.</p><p>What do you see your life in the next few months, years look like? What do you hope to achieve here? - So I literally just this week signed a term sheet to take some investment money for my company where the last two years I had backed off from Meta and I was still doing my consulting CTO role there, but I had styled it as I was going to take the Victorian gentleman scientist route where I was gonna be the wealthy person that was going to go pursue science and learn about this and do experiments.</p><p>And honestly, I'm surprised there aren't more people like that, that are like me, technical people that made a bunch of money and are interested in some of these, possibly the biggest leverage point in human history. I mean, I know of, I've heard of a couple organizations that are basically led by one rich techie guy that gets a few people around him to try to work on this, but I'm surprised that there's not more, that there aren't like a dozen of them.</p><p>I mean, maybe people are still think that it's an unapproachable problem, that it's kind of beyond their ability to get a wrench on and have some effect on like whatever startups they've run before. But that was my kind of, like with all the stuff I've learned, whether it's gaming, aerospace, whatever, I go through a larval phase where I'm like, okay, I'm sucking up all of this information, trying to see, is this something that I can actually do?</p><p>Is this something that's practical to devote a large chunk of my life to? And I've gone through that with the AI, machine learning space of things. And I think I've got my arms around it, I've got the measure of it, where some of the most brilliant people in the world are working on this problem, but nobody knows exactly the path that it's going on.</p><p>We're throwing a lot of things at the wall and seeing what sticks. But I have, you know, another interesting thing, just learning about all of this, the contingency of your path to knowledge and talking about the associations and the context that you have with them, where people that learn in the same path will have similar thought processes.</p><p>And I think it's useful that I come at this from a different background, a different history than the people that have had the largely academic backgrounds for this, where I have huge blind spots that they could easily point out, but I have a different set of experiences in history and approaches to problems in systems engineering that might turn out to be useful.</p><p>And I can afford to take that bet where I'm not going to be destitute. I have enough money to fund myself working on this for the rest of my life. But what I was finding is that I was still not committing, where I had a foot firmly in the VR and meta side of things, where in theory, I've got a very nice position there.</p><p>I only have to work one day a week for my consulting role, but I was engaging every day. I'd still be like, my computer's there. I'd be going and checking the workplace and notes and testing different things and communicating with people. But I did make the decision recently that no, I'm going to get serious.</p><p>I'm still going to keep my ties with meta, but I am seriously going for the AGI side of things. - And it's actually a really interesting point because a lot of the machine learning, the AI community is quite large, but really basically almost everybody has taken the same trajectory through life in that community.</p><p>And it's so interesting to have somebody like you with a fundamentally different trajectory. And that's where the big solutions can come because there's a kind of silo and it is a bunch of people kind of following the same kind of set of ideas. And I was really worried that I didn't want to come off as like an arrogant outsider for things where I have all the respect in the world for the work.</p><p>It's been a miracle decade. We're in the midst of a scientific revolution happening now and everybody doing this is, these are the Einsteins and Bohrs and whatever's of our modern era. And I was really happy to see that the people that I sat down and talked with, everybody does seem to really be quite great about, just happy to talk about things, willing to acknowledge that we don't know what we're doing.</p><p>We're figuring it out as we go along. And I mean, I've got a huge debt on this where this all really started for me because Sam Altman basically tried to recruit me to open AI. And it was at a point when I didn't know anything about what was really going on in machine learning.</p><p>And in fact, it's funny how the first time you reached out to me, it's like four years ago for your AI podcast. - Yeah, for people who are listening to this should know that, first of all, obviously I've been a huge fan of yours for the longest time, but we've agreed to talk like, yeah, like four years ago, back when this was called the Artificial Intelligence Podcast, we wanted to do a thing and you said yes.</p><p>- And I said, it's like, I don't know anything about modern AI. - That's right. - I said, I could kind of take an angle on machine perception 'cause I'm doing a lot of that with the sensors and the virtual reality, but we could probably find something to talk about.</p><p>- And then, so I mean, and that's where, when did Sam talk to you about open AI, around the same time? - No, it was a little bit, it was a bit after that. So I had done the most basic work. I had kind of done the neural networks from scratch where I had gone and written it all in C just to make sure I understood back propagation at the lowest level and my nuts and bolts approach.</p><p>But after Sam approached me, it was flattering to think that he thought that I could be useful at open AI, largely for kind of like systems optimization sorts of things. I am, without being an expert, but I asked Ilya Sutskever to give me a reading list and he gave me a binder full of all the papers that like, okay, these are the important things.</p><p>If you really read and understand all of these, you'll know like 80% of what most of the, the machine language researchers work on. And I went through and I read all those papers multiple times and highlighted them and went through and kind of figured the things out there and then started branching out into my own sets of research on things.</p><p>And I actually started writing my own experiments and doing kind of figuring out, finding out what I don't know, what the limits of my knowledge are and starting to get some of my angles of attack on things, the things that I think are a little bit different from what people are doing.</p><p>And I've had a couple of years now, like two years since I kind of left the full-time position at Meta. And now I've kind of pulled the trigger and said, I'm gonna get serious about it. But some of my lessons all the way back to Armadillo Aerospace about how I know I need to be more committed to this, where there is that, it's both a freedom and a cost in some ways when you know that you're wealthy enough to say, it's like, this doesn't really mean anything.</p><p>I can spend a million dollars a year for the rest of my life and it doesn't mean anything. It's fine. But that is an opportunity to just kind of meander. And I could see that in myself when I'm doing some things, it's like, oh, this is a kind of interesting, curious thing.</p><p>Let's look at this for a little while. Let's look at that. It's not really bearing down on the problem. So there's a few things that I've done that are kind of tactics for myself to make me more effective. Like one thing I noticed I was not doing well is I had a Google Cloud account to get GPUs there.</p><p>And I was finding I was very rarely doing that for no good psychological reasons where I'm like, oh, I can always think of something to do other than to spin up instances and run an experiment. I can keep working on my local Titans or something. But it was really stupid.</p><p>I mean, it was not a lot of money. I should have been running more experiments there. So I thought to myself, well, I'm going to go buy a quarter million dollar DGX station. I'm going to just like sit it right there. And it's going to mock me if I'm not using it.</p><p>If the fans aren't running on that thing, I'm not properly utilizing it. And that's been helpful. You know, I've done a lot more experiments since then. It's been interesting where I thought I'd be doing all this low level NVLink optimized stuff. But 90% of what I do is just spin up four instances of an experiment with different hyper parameters on it.</p><p>- Oh, interesting. You're doing like really sort of building up intuition by doing ML experiments of different kinds. - But so the next big thing though is I am, you know, I decided that I was going to take some investor money because I have an overactive sense of responsibility about other people's money.</p><p>And it's like, I don't want, I mean, a lot of my push and my passionate entreaties for things at Meta are it's like, I don't want Zuck to have wasted his money investing in Oculus. I want it to work out. I want it to change the world. I want it to be worth all of this time, money and effort going into it.</p><p>And I expect that it's going to be that like that with my company where-- - It's a huge forcing function. - Yeah, I have investors that are going to expect something of me. Now we've all had the conversation that this is a low probability long-term bet. It's not something that there's a million things I could do that I would have line of sight on the value proposition for this isn't that.</p><p>I think there are unknown unknowns in the way, but it's one of these things that it's hyperbole, but it's potentially one of the most important things humans ever do. And it's something that I think is within our lifetimes, if not within a decade to happen. So yeah, this is just now happening like term sheet, like the ink is barely, virtual ink is barely dry on.</p><p>- It's drying. I mean, as I mentioned to you offline, like somebody I admire, somebody you know, Andrej Karpathy, I think the two of you different trajectories in life, but approach problems similarly in that he codes stuff from scratch up all the time. And he's created a bunch of little things outside of, even outside the course at Stanford that have been tremendously useful to build up intuition about stuff, but also to help people.</p><p>And they're all in the realm of AI. Do you see yourself potentially doing things like this or not necessarily solving a gigantic problem, but on the journey, on the path to that, building up intuitions and sharing code or ideas or systems that give inklings of AGI, but also kind of are useful to people in some way?</p><p>- So yeah, first of all, Andrej is awesome. I learned a lot when I was going through my larval phase from his blog posts and his Stanford course, and super valuable. I got to meet him first a couple of years ago when I was first kind of starting off on my gentleman scientist bit.</p><p>And just a couple of months ago when he went out on his sabbatical, he stopped by in Dallas and we talked for a while and I had a great time with him. And then when I heard he actually left Tesla, I did of course, along with a hundred other people say, "Hey, if you ever wanna work with me, it would be an honor." So he thinks that he's gonna be doing this educational work, but I think someone's gonna make him an offer he can't refuse before he gets too far along on it.</p><p>- Oh, his current interest is educational. So yeah, he's a special mind. Is there something you could speak to what makes him so special? From your understanding? - You know, like he did, he was very much a programmer's programmer that was doing machine learning work, rather than, it's a different feel than an academic where you can see it in paper sometimes where somebody that's really a mathematician or a statistician at heart, and they're doing something with machine learning.</p><p>But, you know, Andre is about getting something done and you could see it in like all of his earliest approaches to it's like, okay, here's how reinforcement learning works. Here's how recurrent neural networks work. Here's how transformers work. Here's how crypto works. And yeah, it's just, he's a hacker's, you know, one of his old posts was like a hacker's guide to machine learning.</p><p>And, you know, he deprecated that and said, "Don't really pay attention to what's in here." But it's that thought that carries through in a lot of it, where it is that back again to that hacker mentality and the hacker ethic with what he's doing and sharing all of it.</p><p>- Yeah, and a lot of his approach to a new thing, like you said, larva stage is, let me code up the simplest possible thing to build up intuition about it. - Yeah, like I say, I sketch with structs and things when I'm just thinking about a problem, I'm thinking in some degree of code.</p><p>- You are also among many things, a martial artist, both Judo and Jiu-Jitsu. How has this helped make you the person you are? - So, I mean, I was a competent club player in Judo and grappling. I mean, I was, you know, by no means any kind of a superstar, but it was, I went through a few phases with it where I did some, when I was quite young, a little bit more when I was 17, and then I got into it kind of seriously in my mid thirties.</p><p>And, you know, I went pretty far with it and I was pretty good at some of the things that I was doing. And I did appreciate it quite a bit where, I mean, on the one hand, it's always, if you're gonna do exercise or something, it's a more motivating form of exercise.</p><p>If someone is crushing you, you are motivated to do something about that, to up your attributes and be better about getting out. - Up your attributes, yes. - But there's also that sense that I'm, you know, I was not a sports guy. I did do wrestling in junior high.</p><p>And I often wish that, I think I would have, I would have been good for me if I'd carried that on into high school and had a little bit more of that. I mean, it's like I, you know, felt a little bit of wrestling vibe with all was going on about embracing the grind and like that push that I associate with the wrestling team that I, in hindsight, I wish I had gone through that and pushed myself that way.</p><p>But even getting back into Judo and Jiu-Jitsu in my mid thirties, as usually the old man on the mat with that, there was still the, you know, the sense that I, you know, working out with the group and having the guys that you're beating each other up with it, but you just feel good coming out of it.</p><p>And I can remember those driving home, aching in various ways and just thinking, it's like, oh, that was really great. And I, you know, it's mixing with a bunch of people that had nothing to do with any of the things that I worked with. You know, every once in a while, someone would be like, oh, you're the doom guy.</p><p>And I, but for the most part, it was just different slice of life. I, you know, a good thing. And I made the call when I was 40. That's like, maybe I'm getting a little old for this. I had separated a rib and tweaked a few things and I got out of it without any really bad injuries.</p><p>And it was like, have I dodged enough bullets? Should I, you know, should I hang it up? I went back, I've gone a couple of times in the last decade, trying to get my kids into it a little bit. I didn't really stick with any of them, but it was fun to get back on the mats.</p><p>I really hurts for a while when you haven't gone, I gone for a while, but I still debate this pretty constantly. My brother's only a year younger than me and he's going kind of hard in jujitsu right now. And I, you know, he was just, he won a few medals at the last tournament he was at.</p><p>- So he's competing too. - Yeah, and I was thinking, yeah, I guess we're in the executive division if you're over 50 or over 45 or something. And it's not out of the question that I go back at some point to do some of this. But again, I'm just reorganizing my life around more focus, probably not gonna happen.</p><p>I'm pushing my exercise around to give me longer uninterrupted intellectual focus time, pushing it to the beginning or the end of the game. - Like running and stuff like that or walking, yeah. - Yeah, I got running and calisthenics and some things like that, but- - It allows you to still think about a problem.</p><p>But if you're going to a judo club or something, you've got it fixed. It's gonna be seven o'clock or whatever, 10 o'clock on Saturday. Although I talked about this a little bit when I was on Rogan and shortly after that, Carlos Machado did reach out and I had trained with him for years back in the day.</p><p>And he was like, hey, we've got kind of a small private club with a bunch of kind of executive type people. And it does tempt me. - Yeah, I don't know if you know him, but Jon Donahert moved here to Austin with Gordon Ryan and a few other folks.</p><p>And he has a very interesting way, very deep systematic way of thinking about jujitsu that reveals the chess of it, like the science of it. - And I do think about that more as kind of an older person considering the martial arts, where I can remember the very earliest days getting back into judo and I'm like, teach me submissions right now.</p><p>It's like, learn the arm bar, learn the choke. But as you get older, you start thinking more about, it's like, okay, I really do wanna learn the entire canon of judo. It's like all the different things there and all the different approaches for it. Not just the, if you wanna compete, there's just a handful of things you learn really, really well.</p><p>But sometimes there's interest in learning a little bit more of the scope there and figuring some things out from, at one point I had, wasn't exactly a spreadsheet, but I did have a big long text file with like, here's the things that I learned in here, like ways you chain this together.</p><p>And while, when I went back a few years ago, it was good to see that I whipped myself back into reasonable shape about doing the basic grappling, but I know there was a ton of the subtleties that were just, that were gone, but could probably be brought back reasonably quickly.</p><p>- And there's also the benefit, I mean, you're exceptionally successful now, you're brilliant, and the problem, the old problem of the ego is-- - I still pushed kind of harder than I should. I mean, that was, I was one of those people that I, yeah, I'm on the smaller side for a lot of the people competing.</p><p>And I would, I'd go with all the big guys and I'd go hard and I'd push myself a lot. And that would be one of those where I would, I'd be dangerous to anyone for the first five minutes, but then sometimes after I'm already dead. And I knew it was terrible for me 'cause it made the, it meant I got less training time with all of that when you go and you just gas out relatively quickly there.</p><p>And I like to think that I would be better about that where after I gave up judo, I started doing the half marathons and tough butters and things like that. And so when I did go back to the local judo club, I thought it's like, oh, I should have better cardio for this 'cause I'm a runner now and I do all of this and didn't work out that way.</p><p>It was the same old thing where just push really hard, strain really hard. And of course, when I worked with good guys like Carlos, it's like, just the whole flow, like water thing is real. And he's just like. - That's true with judo too. Some of the best people like I've trained with Olympic gold medalists.</p><p>And for some reason with them, everything's easier. Everything is, you actually start to feel the science of it, the music of it, the dance of it. Everything's effortless. You understand that there's an art to it. It's not just an exercise. - It was interesting where I did go to the Kodokan in Japan, kind of the birthplace of judo and everything.</p><p>And I remember I rolled with one old guy. I didn't start standing, just started on groundwork, and it was striking how different it was from Carlos. He was still, he was better than me and he got my arm and I had to tap there, but it was a completely different style where I just felt like I could do nothing.</p><p>He was just enveloping me and just like slowly ground it down, took my arm and bent it. While with Carlos, he's just loose and free. And you always thought like, oh, you're just gonna go grab something, but you never had any chance to do it. But it was very different feeling.</p><p>- That's a good summary of the difference between jujitsu and judo. In jujitsu, it is a dance and you feel like there's a freedom and actually, anybody I trained, like Gordon Ryan, one of the best grappler in the world, nogi grappler in the world. There's a feeling like you can do anything, but when you actually try to do something, you can't.</p><p>- Just magically doesn't work. - But with the best judo players in the world, yeah, it does feel like there's a blanket that weighs a thousand pounds on top of you. And there's not a feeling like you can do anything. You just, you're trapped. And that's a style, that's a difference in the style of martial arts, but it's also once you start to study, you understand it all has to do with human movement and the physics of it and the leverage and all that kind of stuff.</p><p>And that's super fascinating. At the end of the day, for me, the biggest benefit is in the humbling aspect when another human being kind of tells you that there's a hierarchy or there's a, you're not that special. - Yeah, and in the most extreme case, when you tap to a choke, you are basically living because somebody lets you live.</p><p>And that is one of those, if you think about it, that is a closer brush with mortality than most people consider. - And that kind of humbling act is good to take to your work then, where it's harder to get humbled. - Yeah, because nobody that does any martial art is coming out thinking I'm the best in the world at anything because everybody loses.</p><p>- Let me ask you for advice. What advice would you give to young people today about life, about career, how they can have a job, how they can have an impact, how they can have a life they can be proud of? - So it was kind of fun. I got invited to give the commencement speech back at the, I went to a college for two semesters and dropped out and went on to do my tech stuff, but they still wanted me to come back and give a commencement speech.</p><p>And I've got that pinned on my Twitter account. I still feel good about everything that I said there. And my biggest point was that the path for me might not be the path for everyone. And in fact, the advice, the path that I took, and even the advice that I would give based on my experience and learnings probably isn't the best advice for everyone, because what I did was all about this knowledge in depth.</p><p>It was about not just having this surface level ability to make things do what I want, but to really understand them through and through, to let me do the systems engineering work and to sometimes find these inefficiencies that can be bypassed. And the whole world doesn't need that. Most programmers don't need, or engineers of any kind don't necessarily need to do that.</p><p>They need to do a little job that's been parceled out to them. Be reliable, let people depend on you, do quality work with all of that. But people that do have an inclination for wanting to know things deeper and learn things deeper, there are just layers and layers of things out there.</p><p>And it's amazing. If you're the right person that is excited about that, the world's never been like this before. It's better than ever. I mean, everything that was wonderful for me is still there, and there's whole new worlds to explore on the different things that you can do. And that it's hard work.</p><p>Brace the grind with it and understand as much as you can, and then be prepared for opportunities to present themselves, where you can't just say, "This is my goal in life," and just push at that. I mean, you might be able to do that, but you're going to make more total progress if you say, "I am preparing myself with this broad set of tools, and then I'm being aware of all the way things are changing as I move through the world and as the whole world changes around me," and then looking for opportunities to deploy the tools that you've built.</p><p>And there's going to be more and more of those types of things there, where an awareness of what's happening, where the inefficiencies are, what things can be done, what's possible versus what's current practice, and then finding those areas where you can go and make an adjustment and make something that may affect millions or billions of people in the world, make it better.</p><p>- When, maybe from your own example, how were you able to recognize this about yourself, that you saw the layers in a particular thing and you were drawn to discovering deeper and deeper truths about it? Is that something that was obvious to you, that you couldn't help, or is there some actions you had to take to actually allow yourself to dig deep?</p><p>- So in the earliest days of personal computers, I remember the reference manuals, and the very early ones even had schematics of computers in the background, in the back of the books, as well as firmware listings and things. And I could look at that, and at that time when I was a younger teenager, I didn't understand a lot of that stuff, how the different things worked.</p><p>I was pulling out the information that I could get, but I always wanted to know all of that. There was like kind of magical information sitting down there. It's like the elder lore that some gray-beard wizard is the keeper of. And so I always felt that pull for wanting to know more, wanting to explore the mysterious areas there.</p><p>And that followed right in through all the things that got the value, exploring the video cards leading to the scrolling advantages, exploring some of the academic papers and things, learning about BSP trees and the different things that I could do with those systems. And just the huge larval phases going through aerospace, just reading bookshelves full of books.</p><p>I mean, again, that point where I have enough money, I can buy all the books I want. It was so valuable there where I was terrible with my money when I was a kid. My mom thought I would always be broke because I'd buy my comic books and just be out of money.</p><p>But it was like all the pizza I want, all the Diet Coke I want, video games, and then books. Books. And it didn't take that much. As soon as I was making 27K a year, I felt rich. I was just getting all the things that I wanted. But that sense of, books have always been magical to me.</p><p>And that was one of the things that really made me smile is Andre had said, he found, when he came over to my house, he said he found my library inspiring. Just, and it was great to see, I used to look at him, he's kind of a younger guy.</p><p>I sometimes wonder if younger people these days have the same relationship with books that I do where they were such a cornerstone for me in so many ways. But that sense that, yeah, I always wanted to know it all. I know I can't. And that was like one of the last things I said, you can't know everything, but you should convince yourself that you can know anything.</p><p>You know, any one particular thing, it was created and discovered by humans. You can learn it. You can find out what you need on there. - And you can learn it deeply. - Yeah. You can drive a nail down through whatever layer cake problem space you've got and learn a cross section there.</p><p>- And not only can you have an impact doing that, you can attain happiness doing that. There's something so fulfilling about becoming a craftsman of a thing. - Yeah. And I don't want to tell people that, look, this is a good career move, just grit your teeth and bear it.</p><p>And I do think it is possible sometimes to find the joy in something. Like it might not immediately appeal to you, but I had told people early on, like in software times, that a lot of game developers are in it just because they are so passionate about games. But I was always really more flexible in what appealed to me, where I said, I think I could be quite engaged doing operating system work or even database work.</p><p>I would find the interest in that because I think most things that are significant in the world have a lot of layers and complexity to them and a lot of opportunities hidden within them. So that would probably be the most important thing to encourage to people is that you can, it's like weaponized curiosity.</p><p>You can deploy your curiosity to find, to kind of like make things useful and valuable to you, even if they don't immediately appear that way. - Deploy your curiosity, yeah, that's very true. We've mentioned this debate point, whether mortality or fear of mortality is fundamental to creating an AGI, but let's talk about whether it's fundamental to human beings.</p><p>Do you think about your own mortality? - I really don't. And you probably always have to like take with a grain of salt anything somebody says about fundamental things like that. But I don't think about really aging, impending death, legacy with my children, things like that. And clearly it seems most of the world does a lot, a lot more than I do.</p><p>- Yeah. - So, I mean, I think I'm an outlier in that where it's, yeah, it doesn't wind up being a real part of my thinking and motivation about things. - So daily existence is about sort of the people you love and the problems before you. - I'm very much focused on what I'm working on right now.</p><p>I do take that back. There's one aspect where the kind of finiteness of the life does impact me. And that is about thinking about the scope of the problems that I'm working on. When I decided to work on, when I was like nuclear fission or AGI, these are big ticket things that are impact large fractions of the world.</p><p>And I was thinking to myself at some level that, okay, I mean, I may have a couple more swings at bat with me at full capability, but yes, my mental abilities will decay with age, mostly inevitably. I don't think it's a 0% chance that we will address some of that before it becomes a problem for me.</p><p>I think exciting medical stuff in the next couple of decades. But I do have this kind of vague plan that when I'm not at the top of my game and I don't feel that I'm in a position to put a dent in the world some way, that I'll probably wind up doing some kind of recreational retro programming or I'll work on something, something that I would not devote my life to now, but I can while away my time as the old man gardening in the code worlds.</p><p>- And then to step back even bigger, let me ask you about why we're here, we human beings. What's the meaning of it all? What's the meaning of life, John Carmack? - So very similar with that last question. I know a lot of people fret about this question a lot and I just really don't.</p><p>- I really don't give a damn. - We are biological creatures that happenstance of evolution. We have innate drives that evolution crafted for survival and passing on of genetic codes. I don't find a lot of value in trying to go much deeper than that. I have my motivations, some of which are, some of which are probably genetically coded and many of which are contingent on my upbringing and the path that I've had through my life.</p><p>I don't run into like spates of depression or ennui or anything that winds up being a challenge and forcing a degree of soul searching with things like that. I seem to be okay, you know, kind of without that. - As a brilliant ant in the ant colony without looking up to the sky wondering why the hell am I here again?</p><p>So the why of it, the incredible mystery of the fact that we started, first of all, the origin of life on Earth and from that, from single cell organisms, the entirety of the evolutionary process took us somehow to this incredibly intelligent thing that is able to build Wolfenstein 3D and Doom and Quake and take a crack at the problem of AGI and create things that eventually supersede human beings.</p><p>That doesn't, the why of it is- - It's been my experience that people that focus on, that don't focus on the here and now right in front of them tend to be less effective. I mean, it's not 100%. You know, vision matters to some people, but it doesn't seem to be a necessary motivator for me.</p><p>And I think that the process of getting there is usually done, I guess like the magic of gradient descent. People just don't believe that just looking locally gets you to all of these spectacular things. That's been, you know, the decades of looking at, really some of the smartest people in the world that would just push back forever against this idea that it's not this grand, sophisticated vision of everything, but little tiny steps, local information winds up leading to all the best answers.</p><p>- So the meaning of life is following locally wherever the gradient descent takes you. This was an incredible conversation, officially the longest conversation I've ever done on the podcast, which means a lot to me because I get to do it with one of my heroes, John. I can't tell you how much it means to me that you would sit down with me.</p><p>You're an incredible human being. I can't wait what you do next, but you've already changed the world. You're an inspiration to so many people. And again, we haven't covered like most of what I was playing to talk about, so I hope we get a chance to talk someday in the future.</p><p>I can't wait to see what you do next. Thank you so much again for talking to me. - Thank you very much. - Thanks for listening to this conversation with John Carmack. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from John Carmack himself.</p><p>Focused hard work is the real key to success. Keep your eyes on the goal and just keep taking the next step towards completing it. If you aren't sure which way to do something, do it both ways and see which works better. Thank you for listening and hope to see you next time.</p><p>(upbeat music) (upbeat music)</p></div></div></body></html>