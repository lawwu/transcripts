<html><head><title>Stanford XCS224U: NLU I Behavioral Evaluation of NLU Models, Part 6: Adversarial NLI I Spring 2023</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford XCS224U: NLU I Behavioral Evaluation of NLU Models, Part 6: Adversarial NLI I Spring 2023</h2><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w"><img src="https://i.ytimg.com/vi/_ZkewUyBb-w/sddefault.jpg?sqp=-oaymwEmCIAFEOAD8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgZShlMA8=&rs=AOn4CLBPdCqXLVrpeyktwllb9GB740As7g" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./_ZkewUyBb-w.html">Whisper Transcript</a> | <a href="./transcript__ZkewUyBb-w.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Welcome back everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=6" target="_blank">00:00:06.160</a></span> | <span class="t">This is part six in our series on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=7" target="_blank">00:00:07.960</a></span> | <span class="t">advanced behavioral testing for NLU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=10" target="_blank">00:00:10.360</a></span> | <span class="t">To this point, we've been focused on adversarial testing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=13" target="_blank">00:00:13.720</a></span> | <span class="t">We're now going to take a more expansive view and think about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=16" target="_blank">00:00:16.380</a></span> | <span class="t">the potential benefits of training on adversarial cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=20" target="_blank">00:00:20.380</a></span> | <span class="t">The foundational entry in this literature is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=22" target="_blank">00:00:22.820</a></span> | <span class="t">the ANLI paper and the associated benchmark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=25" target="_blank">00:00:25.280</a></span> | <span class="t">As far as I know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=26" target="_blank">00:00:26.560</a></span> | <span class="t">ANLI is the first attempt to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=28" target="_blank">00:00:28.800</a></span> | <span class="t">a really large train set that is filled with adversarial examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=33" target="_blank">00:00:33.620</a></span> | <span class="t">That is, with examples that fooled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=35" target="_blank">00:00:35.820</a></span> | <span class="t">a top performing model but were intuitive for humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=39" target="_blank">00:00:39.000</a></span> | <span class="t">I think it's fair to say that ANLI is a direct response to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=42" target="_blank">00:00:42.800</a></span> | <span class="t">the adversarial test results that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=44" target="_blank">00:00:44.920</a></span> | <span class="t">reviewed in the previous screencast where we saw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=47" target="_blank">00:00:47.720</a></span> | <span class="t">NLI models that were surpassing our estimates for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=50" target="_blank">00:00:50.840</a></span> | <span class="t">human performance but nonetheless falling down on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=54" target="_blank">00:00:54.180</a></span> | <span class="t">very simple phenomena turning on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=56" target="_blank">00:00:56.960</a></span> | <span class="t">systematicity or compositionality in language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=60" target="_blank">00:01:00.120</a></span> | <span class="t">The vision for ANLI is that by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=62" target="_blank">00:01:02.680</a></span> | <span class="t">introducing an adversarial dynamic into the train set creation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=66" target="_blank">00:01:06.760</a></span> | <span class="t">we can get models that are more robust.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=69" target="_blank">00:01:09.220</a></span> | <span class="t">Here's how data set creation worked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=71" target="_blank">00:01:11.860</a></span> | <span class="t">The annotator is presented with a premise sentence and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=75" target="_blank">00:01:15.320</a></span> | <span class="t">a condition that is entailment, contradiction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=77" target="_blank">00:01:17.740</a></span> | <span class="t">or neutral, one of the NLI labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=80" target="_blank">00:01:20.180</a></span> | <span class="t">The annotator writes a hypothesis and then a state of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=84" target="_blank">00:01:24.000</a></span> | <span class="t">the art model makes a prediction about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=86" target="_blank">00:01:26.040</a></span> | <span class="t">the resulting premise hypothesis pair.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=88" target="_blank">00:01:28.580</a></span> | <span class="t">If the model's prediction matches the condition,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=91" target="_blank">00:01:31.400</a></span> | <span class="t">that is, if the model was correct in some sense,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=93" target="_blank">00:01:33.860</a></span> | <span class="t">the annotator returns to step 2 to try again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=97" target="_blank">00:01:37.080</a></span> | <span class="t">Whereas if the model was fooled,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=99" target="_blank">00:01:39.400</a></span> | <span class="t">the premise hypothesis pair is independently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=101" target="_blank">00:01:41.700</a></span> | <span class="t">validated by other human annotators.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=104" target="_blank">00:01:44.740</a></span> | <span class="t">The result of this dynamic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=106" target="_blank">00:01:46.840</a></span> | <span class="t">of this interaction with this top performing model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=109" target="_blank">00:01:49.240</a></span> | <span class="t">is a train set that is full of really hard cases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=113" target="_blank">00:01:53.160</a></span> | <span class="t">cases that fooled this top performing model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=115" target="_blank">00:01:55.600</a></span> | <span class="t">in addition to cases that didn't fool that model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=119" target="_blank">00:01:59.000</a></span> | <span class="t">The examples are interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=121" target="_blank">00:02:01.080</a></span> | <span class="t">The premises in ANLI tend to be long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=123" target="_blank">00:02:03.360</a></span> | <span class="t">The hypotheses are, of course, challenging.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=125" target="_blank">00:02:05.880</a></span> | <span class="t">Interestingly, the dataset also contains these reason texts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=129" target="_blank">00:02:09.240</a></span> | <span class="t">This is the annotator's best attempt to explain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=131" target="_blank">00:02:11.620</a></span> | <span class="t">why the model might have struggled with that particular example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=135" target="_blank">00:02:15.080</a></span> | <span class="t">As far as I know, the reason texts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=137" target="_blank">00:02:17.040</a></span> | <span class="t">haven't been used very much in the literature,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=138" target="_blank">00:02:18.900</a></span> | <span class="t">but they strike me as an interesting source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=140" target="_blank">00:02:20.960</a></span> | <span class="t">of indirect supervision about the task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=143" target="_blank">00:02:23.800</a></span> | <span class="t">You might check those out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=145" target="_blank">00:02:25.960</a></span> | <span class="t">This is the core results table for the ANLI paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=150" target="_blank">00:02:30.080</a></span> | <span class="t">There's a lot of information here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=151" target="_blank">00:02:31.560</a></span> | <span class="t">but I think the story is pretty straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=153" target="_blank">00:02:33.640</a></span> | <span class="t">Let's focus on the BERT model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=155" target="_blank">00:02:35.500</a></span> | <span class="t">The BERT model is doing really well on SNLI and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=158" target="_blank">00:02:38.540</a></span> | <span class="t">multi-NLI across all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=160" target="_blank">00:02:40.040</a></span> | <span class="t">these different variants of the training regimes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=162" target="_blank">00:02:42.760</a></span> | <span class="t">When the model is trained only on SNLI and multi-NLI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=166" target="_blank">00:02:46.280</a></span> | <span class="t">it does really poorly on ANLI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=168" target="_blank">00:02:48.680</a></span> | <span class="t">You can see ANLI had three rounds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=170" target="_blank">00:02:50.760</a></span> | <span class="t">When we pool them together,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=171" target="_blank">00:02:51.880</a></span> | <span class="t">this model gets around 20 percent accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=175" target="_blank">00:02:55.320</a></span> | <span class="t">As we take that model and augment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=177" target="_blank">00:02:57.560</a></span> | <span class="t">its training data with ANLI data from previous rounds,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=180" target="_blank">00:03:00.920</a></span> | <span class="t">we do see improvements overall in the ANLI column,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=184" target="_blank">00:03:04.560</a></span> | <span class="t">which is encouraging.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=185" target="_blank">00:03:05.440</a></span> | <span class="t">It looks like the models are getting better at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=187" target="_blank">00:03:07.680</a></span> | <span class="t">the task as they get more of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=189" target="_blank">00:03:09.200</a></span> | <span class="t">these adversarial examples as part of training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=192" target="_blank">00:03:12.040</a></span> | <span class="t">But the fundamental insight here is that performance on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=195" target="_blank">00:03:15.480</a></span> | <span class="t">ANLI is well below performance for the other benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=198" target="_blank">00:03:18.820</a></span> | <span class="t">This is a substantial challenge and I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=200" target="_blank">00:03:20.920</a></span> | <span class="t">believe that this substantial challenge still stands.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=204" target="_blank">00:03:24.600</a></span> | <span class="t">Models do not excel at ANLI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=207" target="_blank">00:03:27.360</a></span> | <span class="t">even to this day as far as I know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=211" target="_blank">00:03:31.080</a></span> | <span class="t">One thing I love about ANLI is that it projects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=214" target="_blank">00:03:34.600</a></span> | <span class="t">this really interesting vision for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=216" target="_blank">00:03:36.740</a></span> | <span class="t">the future development of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=218" target="_blank">00:03:38.640</a></span> | <span class="t">train and test assets for the field.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=221" target="_blank">00:03:41.040</a></span> | <span class="t">It's actually all credit due to Zellers et al.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=223" target="_blank">00:03:43.840</a></span> | <span class="t">They also described this vision in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=225" target="_blank">00:03:45.680</a></span> | <span class="t">their papers on SWAG and Hella SWAG.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=228" target="_blank">00:03:48.360</a></span> | <span class="t">They write, "A path for NLP progress going forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=231" target="_blank">00:03:51.580</a></span> | <span class="t">towards benchmarks that adversarially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=233" target="_blank">00:03:53.760</a></span> | <span class="t">co-evolve with evolving state-of-the-art models."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=237" target="_blank">00:03:57.100</a></span> | <span class="t">I didn't have time to tell this full story in details,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=239" target="_blank">00:03:59.940</a></span> | <span class="t">but Zellers et al is an interesting story.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=242" target="_blank">00:04:02.240</a></span> | <span class="t">There are two papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=243" target="_blank">00:04:03.520</a></span> | <span class="t">The first one introduced SWAG,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=245" target="_blank">00:04:05.320</a></span> | <span class="t">which is a synthetically created train and test environment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=249" target="_blank">00:04:09.360</a></span> | <span class="t">for adversarial testing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=252" target="_blank">00:04:12.960</a></span> | <span class="t">They found that it was very difficult,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=255" target="_blank">00:04:15.040</a></span> | <span class="t">but when the BERT paper came out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=256" target="_blank">00:04:16.460</a></span> | <span class="t">BERT essentially solved the SWAG problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=259" target="_blank">00:04:19.600</a></span> | <span class="t">In response to that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=261" target="_blank">00:04:21.300</a></span> | <span class="t">Zellers et al made some adjustments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=263" target="_blank">00:04:23.220</a></span> | <span class="t">to the SWAG dataset that produced Hella SWAG.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=266" target="_blank">00:04:26.060</a></span> | <span class="t">Hella SWAG was substantially harder for BERT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=268" target="_blank">00:04:28.560</a></span> | <span class="t">and I believe that Hella SWAG remains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=270" target="_blank">00:04:30.500</a></span> | <span class="t">a challenging benchmark to this day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=272" target="_blank">00:04:32.580</a></span> | <span class="t">I think that started us on the path of seeing how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=275" target="_blank">00:04:35.120</a></span> | <span class="t">productive it could be to create datasets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=277" target="_blank">00:04:37.980</a></span> | <span class="t">use them to develop models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=279" target="_blank">00:04:39.580</a></span> | <span class="t">and then respond when models seem to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=281" target="_blank">00:04:41.420</a></span> | <span class="t">succeed with even harder challenges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=284" target="_blank">00:04:44.500</a></span> | <span class="t">In the ANLI paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=286" target="_blank">00:04:46.180</a></span> | <span class="t">they project this vision very directly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=288" target="_blank">00:04:48.220</a></span> | <span class="t">This process yields a moving post dynamic target for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=292" target="_blank">00:04:52.600</a></span> | <span class="t">NLU systems rather than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=294" target="_blank">00:04:54.020</a></span> | <span class="t">a static benchmark that will eventually saturate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=296" target="_blank">00:04:56.620</a></span> | <span class="t">This sounds so productive to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=298" target="_blank">00:04:58.460</a></span> | <span class="t">Throughout the field, large teams of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=301" target="_blank">00:05:01.260</a></span> | <span class="t">very talented people spend lots of time and money</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=304" target="_blank">00:05:04.140</a></span> | <span class="t">getting epsilon more performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=306" target="_blank">00:05:06.340</a></span> | <span class="t">out of our established benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=308" target="_blank">00:05:08.260</a></span> | <span class="t">Wouldn't it be wonderful if instead,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=310" target="_blank">00:05:10.300</a></span> | <span class="t">when we saw the benchmark saturating,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=312" target="_blank">00:05:12.140</a></span> | <span class="t">we simply created new benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=314" target="_blank">00:05:14.300</a></span> | <span class="t">and posed new challenges for ourselves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=316" target="_blank">00:05:16.540</a></span> | <span class="t">I think it's a very safe bet that models would improve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=319" target="_blank">00:05:19.420</a></span> | <span class="t">more rapidly and become more capable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=321" target="_blank">00:05:21.700</a></span> | <span class="t">if we did this moving post thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=324" target="_blank">00:05:24.860</a></span> | <span class="t">That really is the vision for Dynabench.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=327" target="_blank">00:05:27.780</a></span> | <span class="t">Dynabench is an open-source software effort,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=330" target="_blank">00:05:30.340</a></span> | <span class="t">an open-source platform for doing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=332" target="_blank">00:05:32.460</a></span> | <span class="t">among other things, dynamic adversarial data collection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=336" target="_blank">00:05:36.780</a></span> | <span class="t">Dynabench has produced a number of datasets to this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=340" target="_blank">00:05:40.620</a></span> | <span class="t">ANLI is the first one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=342" target="_blank">00:05:42.700</a></span> | <span class="t">That's the precursor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=343" target="_blank">00:05:43.860</a></span> | <span class="t">We also have Dynabench derived datasets for QA,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=346" target="_blank">00:05:46.940</a></span> | <span class="t">for sentiment, and a number of datasets for hate speech,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=350" target="_blank">00:05:50.860</a></span> | <span class="t">including counter speech to hate speech.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=353" target="_blank">00:05:53.460</a></span> | <span class="t">We have a few on QA and one on German hate speech.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=356" target="_blank">00:05:56.500</a></span> | <span class="t">I think this list will continue to grow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=358" target="_blank">00:05:58.940</a></span> | <span class="t">and offer us these incredible new resources.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=362" target="_blank">00:06:02.620</a></span> | <span class="t">Let me stop there for the next screencast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=365" target="_blank">00:06:05.420</a></span> | <span class="t">I'm going to do a deep dive on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=367" target="_blank">00:06:07.340</a></span> | <span class="t">a Dynabench derived dataset that we created called Dynascent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=_ZkewUyBb-w&t=372" target="_blank">00:06:12.060</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>