<html><head><title>Stanford CS25: V4 I Behind the Scenes of LLM Pre-training: StarCoder Use Case</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford CS25: V4 I Behind the Scenes of LLM Pre-training: StarCoder Use Case</h2><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8"><img src="https://i.ytimg.com/vi/jm2hyJLFfN8/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./jm2hyJLFfN8.html">Whisper Transcript</a> | <a href="./transcript_jm2hyJLFfN8.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">[VIDEO PLAYBACK]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=5" target="_blank">00:00:05.320</a></span> | <span class="t">- Hello.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=5" target="_blank">00:00:05.820</a></span> | <span class="t">Thank you for joining CS25 Transformers Day's last class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=10" target="_blank">00:00:10.680</a></span> | <span class="t">Today, we have Lubna, who is a machine learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=13" target="_blank">00:00:13.880</a></span> | <span class="t">engineer in the science team at Hugging Face,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=16" target="_blank">00:00:16.360</a></span> | <span class="t">working on large language models for code and synthetic data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=20" target="_blank">00:00:20.440</a></span> | <span class="t">generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=21" target="_blank">00:00:21.800</a></span> | <span class="t">She's part of the core team at the Big Code Project</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=25" target="_blank">00:00:25.440</a></span> | <span class="t">and has co-authored the Stack Dataset and the Starcoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=29" target="_blank">00:00:29.760</a></span> | <span class="t">models for code generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=31" target="_blank">00:00:31.320</a></span> | <span class="t">Thank you so much for coming to our talk today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=34" target="_blank">00:00:34.600</a></span> | <span class="t">And as always, attendance link and the Slido questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=39" target="_blank">00:00:39.320</a></span> | <span class="t">are on our website, and we'll be taking questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=41" target="_blank">00:00:41.640</a></span> | <span class="t">after the talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=42" target="_blank">00:00:42.480</a></span> | <span class="t">Thank you, and you can take it off now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=47" target="_blank">00:00:47.080</a></span> | <span class="t">- Hi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=47" target="_blank">00:00:47.640</a></span> | <span class="t">Thank you for the introduction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=50" target="_blank">00:00:50.200</a></span> | <span class="t">So I'm Lubna.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=51" target="_blank">00:00:51.200</a></span> | <span class="t">I'm a machine learning engineer at Hugging Face in the science</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=53" target="_blank">00:00:53.840</a></span> | <span class="t">team.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=54" target="_blank">00:00:54.400</a></span> | <span class="t">And today, I'll tell you about the behind the scenes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=57" target="_blank">00:00:57.600</a></span> | <span class="t">for training large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=59" target="_blank">00:00:59.760</a></span> | <span class="t">And I will use the Starcoder model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=62" target="_blank">00:01:02.400</a></span> | <span class="t">that our team has trained as a use case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=64" target="_blank">00:01:04.960</a></span> | <span class="t">So today's plan is very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=69" target="_blank">00:01:09.920</a></span> | <span class="t">We're going to try to answer this question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=72" target="_blank">00:01:12.120</a></span> | <span class="t">What does it take to train a good LLM?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=74" target="_blank">00:01:14.600</a></span> | <span class="t">So it's one question, but it's very loaded,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=76" target="_blank">00:01:16.680</a></span> | <span class="t">and it has a lot of follow-ups.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=78" target="_blank">00:01:18.120</a></span> | <span class="t">And as you will see, my slides will be a series</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=80" target="_blank">00:01:20.560</a></span> | <span class="t">of questions and answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=84" target="_blank">00:01:24.920</a></span> | <span class="t">So a few years ago, a lot of people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=87" target="_blank">00:01:27.080</a></span> | <span class="t">thought that there was some molten secret source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=90" target="_blank">00:01:30.200</a></span> | <span class="t">to the strong closed models like GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=93" target="_blank">00:01:33.160</a></span> | <span class="t">and that it will take the open source community a lot of time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=96" target="_blank">00:01:36.320</a></span> | <span class="t">to catch up because the open source models that we had back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=98" target="_blank">00:01:38.920</a></span> | <span class="t">then were much smaller and less performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=102" target="_blank">00:01:42.160</a></span> | <span class="t">But now it seems that the community kind of figured out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=105" target="_blank">00:01:45.080</a></span> | <span class="t">most of the pieces for getting strong LLMs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=107" target="_blank">00:01:47.920</a></span> | <span class="t">as it was predicted in this Google memo that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=110" target="_blank">00:01:50.680</a></span> | <span class="t">was leaked and released on semi-analysis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=114" target="_blank">00:01:54.600</a></span> | <span class="t">For example, today we have LLAMA370BD Instruct,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=118" target="_blank">00:01:58.680</a></span> | <span class="t">which has almost the same performance as GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=121" target="_blank">00:02:01.920</a></span> | <span class="t">but it's unlocked so many use cases</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=124" target="_blank">00:02:04.160</a></span> | <span class="t">because the model weights are open.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=125" target="_blank">00:02:05.720</a></span> | <span class="t">The model can be quantized and can even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=127" target="_blank">00:02:07.720</a></span> | <span class="t">run on a consumer desktop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=129" target="_blank">00:02:09.720</a></span> | <span class="t">It also allows the community to build very cool use cases</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=133" target="_blank">00:02:13.280</a></span> | <span class="t">on top through fine tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=135" target="_blank">00:02:15.320</a></span> | <span class="t">So we've made a lot of progress in the open field,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=138" target="_blank">00:02:18.440</a></span> | <span class="t">and this is not the only model that's out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=142" target="_blank">00:02:22.160</a></span> | <span class="t">We're now observing kind of a rise of open LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=145" target="_blank">00:02:25.880</a></span> | <span class="t">And the company-- more and more companies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=147" target="_blank">00:02:27.840</a></span> | <span class="t">are embracing releasing models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=149" target="_blank">00:02:29.920</a></span> | <span class="t">That was the case, for example, with DeepMind's GEMMA models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=153" target="_blank">00:02:33.280</a></span> | <span class="t">and with Mistral's models and also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=156" target="_blank">00:02:36.640</a></span> | <span class="t">other models from GPT-4E.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=159" target="_blank">00:02:39.800</a></span> | <span class="t">Here I put a plot from the LLMSES arena,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=163" target="_blank">00:02:43.840</a></span> | <span class="t">which is kind of the go-to leaderboard for comparing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=167" target="_blank">00:02:47.720</a></span> | <span class="t">Instruct models nowadays.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=170" target="_blank">00:02:50.200</a></span> | <span class="t">It uses human evaluation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=172" target="_blank">00:02:52.360</a></span> | <span class="t">And you can see in this plot that as we went from 2023</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=177" target="_blank">00:02:57.520</a></span> | <span class="t">to May '24, the gap in performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=180" target="_blank">00:03:00.960</a></span> | <span class="t">between the closed models and the open models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=183" target="_blank">00:03:03.760</a></span> | <span class="t">is shrunking and becoming smaller,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=186" target="_blank">00:03:06.120</a></span> | <span class="t">which is very promising.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=190" target="_blank">00:03:10.200</a></span> | <span class="t">So we're on a very great path, but there are still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=193" target="_blank">00:03:13.480</a></span> | <span class="t">a lot of limitations for this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=196" target="_blank">00:03:16.760</a></span> | <span class="t">And this is mainly due to releases missing out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=200" target="_blank">00:03:20.840</a></span> | <span class="t">important details about how the data was processed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=204" target="_blank">00:03:24.440</a></span> | <span class="t">and how the models were trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=206" target="_blank">00:03:26.440</a></span> | <span class="t">And this is usually the case for two main reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=210" target="_blank">00:03:30.120</a></span> | <span class="t">The first one is to avoid legal scrutiny,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=213" target="_blank">00:03:33.120</a></span> | <span class="t">because when companies publicly disclose the training data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=217" target="_blank">00:03:37.080</a></span> | <span class="t">if the training was not done properly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=219" target="_blank">00:03:39.240</a></span> | <span class="t">and the copyrighted were not respected,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=221" target="_blank">00:03:41.440</a></span> | <span class="t">they risk facing a legal investigation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=225" target="_blank">00:03:45.280</a></span> | <span class="t">The other reason for not disclosing the details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=229" target="_blank">00:03:49.240</a></span> | <span class="t">can be to maintain a competitive edge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=231" target="_blank">00:03:51.920</a></span> | <span class="t">So some companies want to be the best at training LLMs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=234" target="_blank">00:03:54.960</a></span> | <span class="t">so they don't want to give all the details for their training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=239" target="_blank">00:03:59.120</a></span> | <span class="t">Nevertheless, because we have a lot of releases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=241" target="_blank">00:04:01.640</a></span> | <span class="t">I think we can still answer this question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=243" target="_blank">00:04:03.600</a></span> | <span class="t">and put a lot of pieces together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=247" target="_blank">00:04:07.400</a></span> | <span class="t">So what do we need to train a good LLM?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=250" target="_blank">00:04:10.040</a></span> | <span class="t">The first thing is probably the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=252" target="_blank">00:04:12.760</a></span> | <span class="t">You need to have a good architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=255" target="_blank">00:04:15.040</a></span> | <span class="t">And I think now transformers are kind of the default,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=258" target="_blank">00:04:18.480</a></span> | <span class="t">but there are also other interesting architectures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=261" target="_blank">00:04:21.240</a></span> | <span class="t">like Mamba, which is a state-based model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=263" target="_blank">00:04:23.920</a></span> | <span class="t">or you can use a mixture of experts, which can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=266" target="_blank">00:04:26.280</a></span> | <span class="t">be multiple transformer models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=269" target="_blank">00:04:29.040</a></span> | <span class="t">But I'm not going to spend a lot of time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=271" target="_blank">00:04:31.240</a></span> | <span class="t">in this lecture on models, because I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=273" target="_blank">00:04:33.720</a></span> | <span class="t">think it's a topic that's already thoroughly explored,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=277" target="_blank">00:04:37.400</a></span> | <span class="t">and there are other aspects that maybe deserve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=280" target="_blank">00:04:40.360</a></span> | <span class="t">a little bit more attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=283" target="_blank">00:04:43.000</a></span> | <span class="t">So that was it for models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=284" target="_blank">00:04:44.440</a></span> | <span class="t">Then for GPUs, I don't think there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=286" target="_blank">00:04:46.520</a></span> | <span class="t">much I can tell you about that, except maybe I ask Jensen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=290" target="_blank">00:04:50.800</a></span> | <span class="t">But the part that they were the most interested of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=294" target="_blank">00:04:54.640</a></span> | <span class="t">is data, which I think is the backbone of LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=299" target="_blank">00:04:59.640</a></span> | <span class="t">Because now almost everyone is using the same architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=302" target="_blank">00:05:02.960</a></span> | <span class="t">and the same training techniques.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=304" target="_blank">00:05:04.840</a></span> | <span class="t">And for a given budget, data is what makes some models better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=309" target="_blank">00:05:09.080</a></span> | <span class="t">than the others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=310" target="_blank">00:05:10.240</a></span> | <span class="t">So it's really worth spending time exploring this data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=313" target="_blank">00:05:13.440</a></span> | <span class="t">and understanding how to get the higher quality samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=317" target="_blank">00:05:17.440</a></span> | <span class="t">So now we're going to try to answer our previous question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=320" target="_blank">00:05:20.320</a></span> | <span class="t">of how to train a good LLM by how do we get good training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=323" target="_blank">00:05:23.880</a></span> | <span class="t">data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=324" target="_blank">00:05:24.360</a></span> | <span class="t">And I think the answer to this is threefold.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=330" target="_blank">00:05:30.640</a></span> | <span class="t">First, we need to understand how much data do we need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=333" target="_blank">00:05:33.920</a></span> | <span class="t">And then once we've figured out the size of the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=336" target="_blank">00:05:36.720</a></span> | <span class="t">that we need, where can we get this data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=339" target="_blank">00:05:39.280</a></span> | <span class="t">And to clean it, which filtering techniques make more sense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=342" target="_blank">00:05:42.920</a></span> | <span class="t">and will give us the best performance?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=346" target="_blank">00:05:46.120</a></span> | <span class="t">So to answer the first one, the answer to that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=350" target="_blank">00:05:50.160</a></span> | <span class="t">is the scaling laws.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=351" target="_blank">00:05:51.920</a></span> | <span class="t">You want to know how much data you want to train a model on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=355" target="_blank">00:05:55.680</a></span> | <span class="t">but also what is the optimal size of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=358" target="_blank">00:05:58.560</a></span> | <span class="t">And the scaling laws try to study</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=361" target="_blank">00:06:01.840</a></span> | <span class="t">the allocation of a computer budget between data size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=364" target="_blank">00:06:04.920</a></span> | <span class="t">and model size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=366" target="_blank">00:06:06.200</a></span> | <span class="t">This means, should you take a smaller model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=368" target="_blank">00:06:08.400</a></span> | <span class="t">and train it longer or take a larger model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=370" target="_blank">00:06:10.800</a></span> | <span class="t">and train it on this data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=373" target="_blank">00:06:13.360</a></span> | <span class="t">And I'm going to present a brief history of the scaling laws</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=379" target="_blank">00:06:19.280</a></span> | <span class="t">because I think it's really interesting to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=381" target="_blank">00:06:21.320</a></span> | <span class="t">how the sizes of the models progress through time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=384" target="_blank">00:06:24.680</a></span> | <span class="t">and also how the size of the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=386" target="_blank">00:06:26.800</a></span> | <span class="t">sets and the number of tokens we train on them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=389" target="_blank">00:06:29.000</a></span> | <span class="t">have changed because there were really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=390" target="_blank">00:06:30.880</a></span> | <span class="t">some drastic changes in that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=393" target="_blank">00:06:33.720</a></span> | <span class="t">I think the first to establish the scaling laws</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=398" target="_blank">00:06:38.000</a></span> | <span class="t">were Kaplan from OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=400" target="_blank">00:06:40.760</a></span> | <span class="t">And they tried to fit the laws as a function of the data size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=408" target="_blank">00:06:48.440</a></span> | <span class="t">and model size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=409" target="_blank">00:06:49.480</a></span> | <span class="t">And they found that if you have a 10 times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=412" target="_blank">00:06:52.280</a></span> | <span class="t">increase in your compute, you should increase your parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=416" target="_blank">00:06:56.040</a></span> | <span class="t">count by 5.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=417" target="_blank">00:06:57.760</a></span> | <span class="t">But your training tokens, you should only increase them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=420" target="_blank">00:07:00.120</a></span> | <span class="t">by 1.8.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=421" target="_blank">00:07:01.840</a></span> | <span class="t">This means that if you have more resources to train your models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=425" target="_blank">00:07:05.280</a></span> | <span class="t">you should make the model much larger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=426" target="_blank">00:07:06.920</a></span> | <span class="t">But the data, it's fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=428" target="_blank">00:07:08.160</a></span> | <span class="t">You shouldn't increase it that much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=431" target="_blank">00:07:11.000</a></span> | <span class="t">And this is what led to models like GPT-3, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=434" target="_blank">00:07:14.240</a></span> | <span class="t">is 175 billion parameters, which was only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=438" target="_blank">00:07:18.160</a></span> | <span class="t">trained on 300 billion tokens, which if we think about it now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=441" target="_blank">00:07:21.880</a></span> | <span class="t">is really small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=444" target="_blank">00:07:24.320</a></span> | <span class="t">Other models also follow this, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=446" target="_blank">00:07:26.720</a></span> | <span class="t">like OPBT, which was the same size as GPT-3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=449" target="_blank">00:07:29.520</a></span> | <span class="t">and trained on a similar amount of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=451" target="_blank">00:07:31.800</a></span> | <span class="t">There was also Bloom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=454" target="_blank">00:07:34.080</a></span> | <span class="t">So all these models are actually very under-trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=457" target="_blank">00:07:37.960</a></span> | <span class="t">Then the Chinchilla scaling laws came after.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=461" target="_blank">00:07:41.080</a></span> | <span class="t">And they kind of revisited the scaling laws.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=464" target="_blank">00:07:44.480</a></span> | <span class="t">And they found that the reason Kaplan thought that data should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=469" target="_blank">00:07:49.520</a></span> | <span class="t">not be as scaled as model size is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=472" target="_blank">00:07:52.040</a></span> | <span class="t">because they used a fixed cosine scheduler</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=474" target="_blank">00:07:54.600</a></span> | <span class="t">for all their experiments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=476" target="_blank">00:07:56.200</a></span> | <span class="t">So although they were changing the data size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=478" target="_blank">00:07:58.400</a></span> | <span class="t">the cosine scheduler was fixed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=480" target="_blank">00:08:00.720</a></span> | <span class="t">This meant that for some models, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=482" target="_blank">00:08:02.760</a></span> | <span class="t">were underestimated because they were not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=485" target="_blank">00:08:05.560</a></span> | <span class="t">using the correct cosine that corresponded to the data size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=489" target="_blank">00:08:09.960</a></span> | <span class="t">This led to kind of false conclusions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=492" target="_blank">00:08:12.520</a></span> | <span class="t">And the Chinchilla can now give us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=495" target="_blank">00:08:15.080</a></span> | <span class="t">new scaling laws that say that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=497" target="_blank">00:08:17.320</a></span> | <span class="t">should scale your data and your model size equally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=501" target="_blank">00:08:21.480</a></span> | <span class="t">And in their paper, they train a 65 billion model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=506" target="_blank">00:08:26.440</a></span> | <span class="t">on 1.6 trillion tokens, which is the Chinchilla optimal point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=510" target="_blank">00:08:30.480</a></span> | <span class="t">And they also perform much larger models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=512" target="_blank">00:08:32.760</a></span> | <span class="t">like GPT-3 and Gopher, which was over 200 billion parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=517" target="_blank">00:08:37.240</a></span> | <span class="t">So here, for example, I have a plot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=522" target="_blank">00:08:42.200</a></span> | <span class="t">which shows what the scaling laws try to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=524" target="_blank">00:08:44.240</a></span> | <span class="t">For example, here you have isoflop curves,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=526" target="_blank">00:08:46.840</a></span> | <span class="t">which each curve uses a fixed budget.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=529" target="_blank">00:08:49.400</a></span> | <span class="t">And then you try to find the sweet spot, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=531" target="_blank">00:08:51.840</a></span> | <span class="t">is the optimal for your budget allocation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=534" target="_blank">00:08:54.640</a></span> | <span class="t">And it tells you what your model size should be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=536" target="_blank">00:08:56.760</a></span> | <span class="t">and what your data size should be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=538" target="_blank">00:08:58.720</a></span> | <span class="t">And as you can see here, if we try to fit the laws,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=541" target="_blank">00:09:01.880</a></span> | <span class="t">we can see that there's a linear increase for data and also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=545" target="_blank">00:09:05.560</a></span> | <span class="t">model size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=546" target="_blank">00:09:06.120</a></span> | <span class="t">In this scheme, I tried to show how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=553" target="_blank">00:09:13.240</a></span> | <span class="t">we've moved from the Chinchilla scaling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=555" target="_blank">00:09:15.200</a></span> | <span class="t">laws to today's models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=558" target="_blank">00:09:18.120</a></span> | <span class="t">And you can see that, for example, the Chinchilla model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=560" target="_blank">00:09:20.960</a></span> | <span class="t">which is 60 billion parameters, was trained on less than 2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=563" target="_blank">00:09:23.760</a></span> | <span class="t">trillion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=565" target="_blank">00:09:25.280</a></span> | <span class="t">But then after that, we have LAMA,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=567" target="_blank">00:09:27.320</a></span> | <span class="t">which was released last year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=568" target="_blank">00:09:28.920</a></span> | <span class="t">And it was just a 7BB model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=570" target="_blank">00:09:30.360</a></span> | <span class="t">And it was trained on as much data as the Chinchilla model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=574" target="_blank">00:09:34.600</a></span> | <span class="t">So it was trained way past the Chinchilla optimal point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=578" target="_blank">00:09:38.840</a></span> | <span class="t">And we might be wondering, why is that the case?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=583" target="_blank">00:09:43.000</a></span> | <span class="t">Did Meta not use their compute budgets in an optimal way?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=587" target="_blank">00:09:47.840</a></span> | <span class="t">And the answer to that is that compute optimal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=590" target="_blank">00:09:50.600</a></span> | <span class="t">is not always optimal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=593" target="_blank">00:09:53.280</a></span> | <span class="t">Because when you train a model, you don't only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=595" target="_blank">00:09:55.680</a></span> | <span class="t">care about what you're going to spend in training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=598" target="_blank">00:09:58.040</a></span> | <span class="t">but you also care about the inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=600" target="_blank">00:10:00.800</a></span> | <span class="t">And the model is trained one time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=602" target="_blank">00:10:02.400</a></span> | <span class="t">but the inference is for more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=603" target="_blank">00:10:03.960</a></span> | <span class="t">The model is going to be served.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=605" target="_blank">00:10:05.320</a></span> | <span class="t">So you want to save some cost in that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=607" target="_blank">00:10:07.600</a></span> | <span class="t">This makes it that people prefer training smaller models longer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=611" target="_blank">00:10:11.240</a></span> | <span class="t">than actually using much larger models that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=613" target="_blank">00:10:13.240</a></span> | <span class="t">are trained on less data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=614" target="_blank">00:10:14.840</a></span> | <span class="t">So this was the case for LAMA1, for other models like Mistral,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=618" target="_blank">00:10:18.360</a></span> | <span class="t">but also for LAMA3, which went even further</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=620" target="_blank">00:10:20.720</a></span> | <span class="t">and trained not on 1 trillion tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=623" target="_blank">00:10:23.000</a></span> | <span class="t">but on 15 trillion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=625" target="_blank">00:10:25.240</a></span> | <span class="t">And if you check the archive paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=627" target="_blank">00:10:27.440</a></span> | <span class="t">the loss kept going down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=629" target="_blank">00:10:29.080</a></span> | <span class="t">And also, the downstream evaluations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=632" target="_blank">00:10:32.160</a></span> | <span class="t">as the model kept training, it kept improving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=635" target="_blank">00:10:35.720</a></span> | <span class="t">And I think this is really interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=637" target="_blank">00:10:37.320</a></span> | <span class="t">Because some people misunderstood</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=639" target="_blank">00:10:39.120</a></span> | <span class="t">the Chinchilla scaling laws as like compute optimal is optimal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=642" target="_blank">00:10:42.160</a></span> | <span class="t">But that's not the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=644" target="_blank">00:10:44.040</a></span> | <span class="t">Because inference cost is not considered.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=646" target="_blank">00:10:46.800</a></span> | <span class="t">So for example, this is the cost for training in GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=651" target="_blank">00:10:51.200</a></span> | <span class="t">It is said that it's estimated that's $100 million.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=654" target="_blank">00:10:54.920</a></span> | <span class="t">But also, the inference is very expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=657" target="_blank">00:10:57.480</a></span> | <span class="t">And the larger the model becomes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=659" target="_blank">00:10:59.440</a></span> | <span class="t">the more time it takes to process the tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=663" target="_blank">00:11:03.120</a></span> | <span class="t">So the scaling laws don't take the inference cost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=666" target="_blank">00:11:06.200</a></span> | <span class="t">in consideration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=667" target="_blank">00:11:07.760</a></span> | <span class="t">And if we do take the inference cost, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=669" target="_blank">00:11:09.840</a></span> | <span class="t">is the case for most people, because they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=673" target="_blank">00:11:13.320</a></span> | <span class="t">want to use these models in inference,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=675" target="_blank">00:11:15.200</a></span> | <span class="t">you might prefer using the smaller models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=677" target="_blank">00:11:17.400</a></span> | <span class="t">and training them longer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=679" target="_blank">00:11:19.520</a></span> | <span class="t">And we do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=680" target="_blank">00:11:20.360</a></span> | <span class="t">We're not respecting the Chinchilla scaling laws.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=682" target="_blank">00:11:22.760</a></span> | <span class="t">So we're choosing to pay what we call a compute overhead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=686" target="_blank">00:11:26.840</a></span> | <span class="t">It's kind of a sacrifice that you do during the training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=689" target="_blank">00:11:29.720</a></span> | <span class="t">You choose to pay more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=691" target="_blank">00:11:31.160</a></span> | <span class="t">But this will have a benefit during inference,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=693" target="_blank">00:11:33.440</a></span> | <span class="t">because you will save a lot of cost and money.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=698" target="_blank">00:11:38.040</a></span> | <span class="t">And there's this very interesting blog post</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=702" target="_blank">00:11:42.000</a></span> | <span class="t">about Harden's law, which tries to measure the compute overhead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=707" target="_blank">00:11:47.360</a></span> | <span class="t">that you will be paying when you choose to train a small model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=711" target="_blank">00:11:51.040</a></span> | <span class="t">For example, here, there's the space on Hugging Face,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=713" target="_blank">00:11:53.720</a></span> | <span class="t">where you can input the model size and what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=716" target="_blank">00:11:56.080</a></span> | <span class="t">data sets you want to train on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=717" target="_blank">00:11:57.560</a></span> | <span class="t">And it will show you where you are regarding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=720" target="_blank">00:12:00.760</a></span> | <span class="t">the Chinchilla optimal point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=722" target="_blank">00:12:02.520</a></span> | <span class="t">So for example, if we take a 7B model and we train it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=724" target="_blank">00:12:04.880</a></span> | <span class="t">on 1 billion tokens, you can see that we are here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=728" target="_blank">00:12:08.080</a></span> | <span class="t">It's the red dots.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=729" target="_blank">00:12:09.200</a></span> | <span class="t">And it's before the Chinchilla optimal model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=732" target="_blank">00:12:12.320</a></span> | <span class="t">And this gives approximately, I think, 40% overhead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=737" target="_blank">00:12:17.760</a></span> | <span class="t">But then during inference, as it shows here in the table--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=741" target="_blank">00:12:21.000</a></span> | <span class="t">sorry, it was 13% overhead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=742" target="_blank">00:12:22.640</a></span> | <span class="t">But there's almost 50% saving costs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=746" target="_blank">00:12:26.160</a></span> | <span class="t">So that's something that almost everyone is doing now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=748" target="_blank">00:12:28.640</a></span> | <span class="t">which is why we see models that are much, much smaller than one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=752" target="_blank">00:12:32.280</a></span> | <span class="t">or two years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=757" target="_blank">00:12:37.440</a></span> | <span class="t">For further reading, there are some very interesting papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=760" target="_blank">00:12:40.600</a></span> | <span class="t">about scaling laws.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=762" target="_blank">00:12:42.000</a></span> | <span class="t">For example, there's this paper called Scaling Data Constraint</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=765" target="_blank">00:12:45.400</a></span> | <span class="t">Language Models, which shows that if you are limited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=769" target="_blank">00:12:49.680</a></span> | <span class="t">in your data size--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=771" target="_blank">00:12:51.240</a></span> | <span class="t">let's say, for example, you want to train a 7B on 10 trillion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=774" target="_blank">00:12:54.800</a></span> | <span class="t">tokens, but you don't have these 10 trillion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=777" target="_blank">00:12:57.680</a></span> | <span class="t">This paper says that you can basically repeat your data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=780" target="_blank">00:13:00.800</a></span> | <span class="t">up to four times, so four epochs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=783" target="_blank">00:13:03.040</a></span> | <span class="t">And you will get similar performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=784" target="_blank">00:13:04.640</a></span> | <span class="t">as if you used unique tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=786" target="_blank">00:13:06.800</a></span> | <span class="t">So for example, instead of using 8 trillion tokens unique,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=790" target="_blank">00:13:10.480</a></span> | <span class="t">you could use just two and repeat them four times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=792" target="_blank">00:13:12.800</a></span> | <span class="t">And you get almost the same performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=794" target="_blank">00:13:14.640</a></span> | <span class="t">as if these tokens were unique.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=797" target="_blank">00:13:17.680</a></span> | <span class="t">And this is especially useful for some domains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=800" target="_blank">00:13:20.640</a></span> | <span class="t">where we almost exhaust all the data that's publicly available.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=805" target="_blank">00:13:25.560</a></span> | <span class="t">As I will show you later, the Stack V2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=807" target="_blank">00:13:27.600</a></span> | <span class="t">which is a code data set that we released,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=810" target="_blank">00:13:30.320</a></span> | <span class="t">I think it has almost all the code available.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=813" target="_blank">00:13:33.280</a></span> | <span class="t">So it's going to be very hard to scrape and get more code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=817" target="_blank">00:13:37.600</a></span> | <span class="t">And if you want to train models longer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=819" target="_blank">00:13:39.480</a></span> | <span class="t">the only option is to actually repeat the data during training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=823" target="_blank">00:13:43.080</a></span> | <span class="t">And this is good news, because repeating the data up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=826" target="_blank">00:13:46.200</a></span> | <span class="t">to four times is actually significant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=830" target="_blank">00:13:50.320</a></span> | <span class="t">Another paper that I think is interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=832" target="_blank">00:13:52.600</a></span> | <span class="t">when it comes to scaling laws is the DeepSeq LLM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=838" target="_blank">00:13:58.080</a></span> | <span class="t">They try to establish new scaling laws that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=841" target="_blank">00:14:01.440</a></span> | <span class="t">are suited for the data, because they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=843" target="_blank">00:14:03.880</a></span> | <span class="t">find that the scaling behavior is highly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=847" target="_blank">00:14:07.400</a></span> | <span class="t">dependent on the data quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=849" target="_blank">00:14:09.760</a></span> | <span class="t">So they tried different data subsets, different filtering,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=852" target="_blank">00:14:12.840</a></span> | <span class="t">and they found that the scaling laws were changing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=855" target="_blank">00:14:15.600</a></span> | <span class="t">So this is very important, because up until now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=858" target="_blank">00:14:18.080</a></span> | <span class="t">we were using the Chinchilla, but the Chinchilla</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=860" target="_blank">00:14:20.280</a></span> | <span class="t">was using fixed data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=861" target="_blank">00:14:21.840</a></span> | <span class="t">They are not necessarily the ones that we are using now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=864" target="_blank">00:14:24.920</a></span> | <span class="t">So it's really important to be aware of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=867" target="_blank">00:14:27.440</a></span> | <span class="t">And this is why DeepSeq tried to come up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=869" target="_blank">00:14:29.560</a></span> | <span class="t">with their own scaling laws that work for their data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=872" target="_blank">00:14:32.840</a></span> | <span class="t">And they also conclude that when you have higher quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=876" target="_blank">00:14:36.400</a></span> | <span class="t">data sets, maybe more compute should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=879" target="_blank">00:14:39.040</a></span> | <span class="t">be allocated to the model size and not to the data size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=883" target="_blank">00:14:43.240</a></span> | <span class="t">So these are interesting things to keep in mind when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=886" target="_blank">00:14:46.280</a></span> | <span class="t">it comes to scaling LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=891" target="_blank">00:14:51.480</a></span> | <span class="t">So we have answered the first question, I hope.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=894" target="_blank">00:14:54.600</a></span> | <span class="t">How much data to train LLMs?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=897" target="_blank">00:14:57.920</a></span> | <span class="t">So let's say now you have your compute budget,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=901" target="_blank">00:15:01.200</a></span> | <span class="t">a fixed number of GPUs for a certain amount of days,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=904" target="_blank">00:15:04.600</a></span> | <span class="t">and you also know approximately how much data you want to use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=909" target="_blank">00:15:09.360</a></span> | <span class="t">The question is that, where do you find this type of data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=913" target="_blank">00:15:13.640</a></span> | <span class="t">For example, Llama3 was trained on 15 trillion tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=916" target="_blank">00:15:16.680</a></span> | <span class="t">but where do you get 15 trillion tokens?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=919" target="_blank">00:15:19.320</a></span> | <span class="t">That's a huge number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=923" target="_blank">00:15:23.320</a></span> | <span class="t">To get this data, the two main sources</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=926" target="_blank">00:15:26.600</a></span> | <span class="t">where you can actually get a very large volume of data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=930" target="_blank">00:15:30.000</a></span> | <span class="t">are the web and then GitHub code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=933" target="_blank">00:15:33.600</a></span> | <span class="t">There are some other curated sources.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=935" target="_blank">00:15:35.520</a></span> | <span class="t">Those are of high quality but are much smaller,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=938" target="_blank">00:15:38.200</a></span> | <span class="t">like Wikipedia, Books, Archive, or Stack Exchange.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=942" target="_blank">00:15:42.080</a></span> | <span class="t">You can also get data and new type</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=945" target="_blank">00:15:45.120</a></span> | <span class="t">You can also get data and new type</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=948" target="_blank">00:15:48.560</a></span> | <span class="t">that's been very trendy recently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=951" target="_blank">00:15:51.200</a></span> | <span class="t">which is synthetic data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=953" target="_blank">00:15:53.560</a></span> | <span class="t">But let's first start with the sources</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=956" target="_blank">00:15:56.360</a></span> | <span class="t">where you can get very large volumes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=960" target="_blank">00:16:00.000</a></span> | <span class="t">The first one is web data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=962" target="_blank">00:16:02.240</a></span> | <span class="t">So that's basically web pages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=965" target="_blank">00:16:05.720</a></span> | <span class="t">And usually people to create these data sets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=968" target="_blank">00:16:08.720</a></span> | <span class="t">they start from Common Crawl, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=970" target="_blank">00:16:10.840</a></span> | <span class="t">is a public repository of crawled web pages</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=975" target="_blank">00:16:15.000</a></span> | <span class="t">and Common Crawl crawls pages regularly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=977" target="_blank">00:16:17.360</a></span> | <span class="t">and they publish dumps every few months.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=981" target="_blank">00:16:21.040</a></span> | <span class="t">But if you start from there, you will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=982" target="_blank">00:16:22.520</a></span> | <span class="t">need to do some heavy filtering at a very large scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=986" target="_blank">00:16:26.160</a></span> | <span class="t">For example, just the latest dump has over 400 terabytes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=989" target="_blank">00:16:29.840</a></span> | <span class="t">and they have almost 95 dumps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=993" target="_blank">00:16:33.040</a></span> | <span class="t">So that's not a very easy task, and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=997" target="_blank">00:16:37.200</a></span> | <span class="t">will need to have a lot of resources and a team</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1000" target="_blank">00:16:40.400</a></span> | <span class="t">to be able to do that crawling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1003" target="_blank">00:16:43.200</a></span> | <span class="t">The other option is to use an existing filtered web data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1008" target="_blank">00:16:48.480</a></span> | <span class="t">Our researchers already filtered Common Crawl and released them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1012" target="_blank">00:16:52.600</a></span> | <span class="t">And luckily, we do have data sets that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1014" target="_blank">00:16:54.480</a></span> | <span class="t">are very large and well-filtered.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1017" target="_blank">00:16:57.120</a></span> | <span class="t">One of them is the web data, FineWeb,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1020" target="_blank">00:17:00.640</a></span> | <span class="t">that was recently released by Hugging Face,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1023" target="_blank">00:17:03.000</a></span> | <span class="t">and it has 15 trillion tokens of web data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1029" target="_blank">00:17:09.440</a></span> | <span class="t">It's also-- it's not just a large data set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1032" target="_blank">00:17:12.120</a></span> | <span class="t">but it also has the best performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1034" target="_blank">00:17:14.600</a></span> | <span class="t">among the publicly available data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1037" target="_blank">00:17:17.240</a></span> | <span class="t">And here, for example, it shows the performance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1040" target="_blank">00:17:20.480</a></span> | <span class="t">which is an aggregation over multiple popular benchmarks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1044" target="_blank">00:17:24.520</a></span> | <span class="t">for NLP, like Hellaswag, MMLU, PICA, and others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1049" target="_blank">00:17:29.160</a></span> | <span class="t">And it averages them and compares to other data sets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1052" target="_blank">00:17:32.120</a></span> | <span class="t">like C4, RefinedWeb, ThinPyjama, and the pile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1058" target="_blank">00:17:38.280</a></span> | <span class="t">So that was for web, so you can get 15 trillion tokens easily.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1062" target="_blank">00:17:42.480</a></span> | <span class="t">And then for code data, we have released the stack data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1066" target="_blank">00:17:46.960</a></span> | <span class="t">set, which is the largest data set of open source code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1072" target="_blank">00:17:52.440</a></span> | <span class="t">This data set comes in two versions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1074" target="_blank">00:17:54.600</a></span> | <span class="t">Version 1 consisted of 6 terabytes of permissive code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1078" target="_blank">00:17:58.800</a></span> | <span class="t">And how we built this data set is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1081" target="_blank">00:18:01.360</a></span> | <span class="t">that we first cloned all the public repositories on GitHub.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1085" target="_blank">00:18:05.640</a></span> | <span class="t">So this gave us over 130 repositories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1089" target="_blank">00:18:09.280</a></span> | <span class="t">and 100 terabytes of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1091" target="_blank">00:18:11.680</a></span> | <span class="t">But we don't want all of that data, because a lot of it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1094" target="_blank">00:18:14.320</a></span> | <span class="t">can be configs or extensions that we don't need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1097" target="_blank">00:18:17.600</a></span> | <span class="t">or languages that are no longer maintained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1099" target="_blank">00:18:19.880</a></span> | <span class="t">So we did some file extension filtering,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1103" target="_blank">00:18:23.360</a></span> | <span class="t">and we ended up with almost 90 terabytes of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1107" target="_blank">00:18:27.240</a></span> | <span class="t">After that, we filtered repositories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1109" target="_blank">00:18:29.440</a></span> | <span class="t">based on their licenses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1111" target="_blank">00:18:31.520</a></span> | <span class="t">So we can have permissive licenses like Apache 2 or MIT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1115" target="_blank">00:18:35.680</a></span> | <span class="t">We can have more restrictive licenses like GPL.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1118" target="_blank">00:18:38.720</a></span> | <span class="t">So we filtered all the repositories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1121" target="_blank">00:18:41.040</a></span> | <span class="t">that did not have a permissive license.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1123" target="_blank">00:18:43.800</a></span> | <span class="t">And after that, we did the deduplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1126" target="_blank">00:18:46.200</a></span> | <span class="t">to remove files that are similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1128" target="_blank">00:18:48.160</a></span> | <span class="t">So we ended up with almost 3 terabytes of deduplicated data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1131" target="_blank">00:18:51.720</a></span> | <span class="t">The stack comes also with a very cool tool for opt-out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1139" target="_blank">00:18:59.440</a></span> | <span class="t">This tool is basically a space where you can go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1142" target="_blank">00:19:02.440</a></span> | <span class="t">You can type your GitHub username,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1144" target="_blank">00:19:04.400</a></span> | <span class="t">and it tells you if you have any of your GitHub repositories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1147" target="_blank">00:19:07.320</a></span> | <span class="t">in the data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1149" target="_blank">00:19:09.160</a></span> | <span class="t">And if that's the case, there's also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1151" target="_blank">00:19:11.160</a></span> | <span class="t">an option to fill a form and request</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1153" target="_blank">00:19:13.360</a></span> | <span class="t">to be removed from all the future trainings of BigCode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1157" target="_blank">00:19:17.400</a></span> | <span class="t">So we did that for the stack v1, but also for the stack v2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1161" target="_blank">00:19:21.720</a></span> | <span class="t">And the v2 is a much larger and enhanced data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1165" target="_blank">00:19:25.360</a></span> | <span class="t">compared to the v1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1167" target="_blank">00:19:27.720</a></span> | <span class="t">This time, instead of cloning GitHub repositories,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1171" target="_blank">00:19:31.360</a></span> | <span class="t">we went through Software Heritage,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1173" target="_blank">00:19:33.040</a></span> | <span class="t">which is an archive of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1174" target="_blank">00:19:34.680</a></span> | <span class="t">They already did the scraping, and we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1177" target="_blank">00:19:37.680</a></span> | <span class="t">extracted the data from their archive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1180" target="_blank">00:19:40.120</a></span> | <span class="t">And we ended up, after all the filtering,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1183" target="_blank">00:19:43.840</a></span> | <span class="t">with almost 1 trillion tokens, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1187" target="_blank">00:19:47.000</a></span> | <span class="t">is a lot compared to the v1, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1188" target="_blank">00:19:48.960</a></span> | <span class="t">we got around 200 billion tokens at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1192" target="_blank">00:19:52.880</a></span> | <span class="t">We also added some high-quality resources</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1195" target="_blank">00:19:55.120</a></span> | <span class="t">like GitHub issues, math and code data sets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1198" target="_blank">00:19:58.640</a></span> | <span class="t">and pull requests.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1200" target="_blank">00:20:00.400</a></span> | <span class="t">So these data sets, the stack v1, the stack v2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1203" target="_blank">00:20:03.120</a></span> | <span class="t">can be used to train LLMs on code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1205" target="_blank">00:20:05.760</a></span> | <span class="t">or to train general LLMs and include code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1208" target="_blank">00:20:08.080</a></span> | <span class="t">as a subset of the general web data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1212" target="_blank">00:20:12.800</a></span> | <span class="t">This shows how the stack v2 compares to the v1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1215" target="_blank">00:20:15.880</a></span> | <span class="t">And you can see that before filtering,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1217" target="_blank">00:20:17.480</a></span> | <span class="t">it's almost 10 times larger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1219" target="_blank">00:20:19.120</a></span> | <span class="t">And after filtering, it's four or five times larger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1224" target="_blank">00:20:24.480</a></span> | <span class="t">So I talk about how to get web data, how to get code data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1228" target="_blank">00:20:28.040</a></span> | <span class="t">And then I also mentioned synthetic data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1230" target="_blank">00:20:30.840</a></span> | <span class="t">And it's this year and last year that synthetic data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1234" target="_blank">00:20:34.200</a></span> | <span class="t">became very important for LLM training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1237" target="_blank">00:20:37.040</a></span> | <span class="t">And I think that in the next few years,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1239" target="_blank">00:20:39.200</a></span> | <span class="t">it will become even more important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1241" target="_blank">00:20:41.320</a></span> | <span class="t">And I think this was mainly sparked by the PHY series</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1244" target="_blank">00:20:44.840</a></span> | <span class="t">of models by Microsoft.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1247" target="_blank">00:20:47.240</a></span> | <span class="t">Their first paper was called Textbooks Are All You Need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1250" target="_blank">00:20:50.440</a></span> | <span class="t">And they basically generated synthetic textbooks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1254" target="_blank">00:20:54.040</a></span> | <span class="t">using GPT-3.5 and GPT-3.4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1258" target="_blank">00:20:58.040</a></span> | <span class="t">And they tried to build a new pre-training corpus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1261" target="_blank">00:21:01.160</a></span> | <span class="t">that is synthetic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1262" target="_blank">00:21:02.280</a></span> | <span class="t">And they were able to match and outperform models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1265" target="_blank">00:21:05.440</a></span> | <span class="t">that are trained on web data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1268" target="_blank">00:21:08.840</a></span> | <span class="t">So this model was trained on almost entirely synthetic data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1272" target="_blank">00:21:12.400</a></span> | <span class="t">But now some of the very popular LLMs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1275" target="_blank">00:21:15.000</a></span> | <span class="t">are using synthetic data as part of their pre-training mix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1279" target="_blank">00:21:19.120</a></span> | <span class="t">For example, Cloud3, in the model card,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1282" target="_blank">00:21:22.080</a></span> | <span class="t">they say that they generate data internally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1284" target="_blank">00:21:24.720</a></span> | <span class="t">and they include it in the pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1287" target="_blank">00:21:27.240</a></span> | <span class="t">This is also the case for LLMA3, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1289" target="_blank">00:21:29.640</a></span> | <span class="t">they used LLMs to build classifiers that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1292" target="_blank">00:21:32.800</a></span> | <span class="t">would annotate samples and only keep the high-quality ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1296" target="_blank">00:21:36.520</a></span> | <span class="t">But they also generated synthetic content</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1299" target="_blank">00:21:39.280</a></span> | <span class="t">to improve performance on coding and reasoning along contexts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1305" target="_blank">00:21:45.480</a></span> | <span class="t">So synthetic data is a very new topic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1307" target="_blank">00:21:47.680</a></span> | <span class="t">but it seems really interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1311" target="_blank">00:21:51.200</a></span> | <span class="t">I'm personally working also on that as a hugging phase.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1314" target="_blank">00:21:54.000</a></span> | <span class="t">We recently released a data set called Cosmopedia,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1317" target="_blank">00:21:57.400</a></span> | <span class="t">which was the largest data set of synthetic texts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1322" target="_blank">00:22:02.120</a></span> | <span class="t">And it had almost 25 billion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1325" target="_blank">00:22:05.120</a></span> | <span class="t">And instead of using closed models like GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1327" target="_blank">00:22:07.840</a></span> | <span class="t">it used an open-source model, which is Mixed Trial 887B.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1333" target="_blank">00:22:13.040</a></span> | <span class="t">And we also released a blog post that explains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1336" target="_blank">00:22:16.640</a></span> | <span class="t">how we created this data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1338" target="_blank">00:22:18.920</a></span> | <span class="t">Because it can be very tricky to get very diverse samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1343" target="_blank">00:22:23.800</a></span> | <span class="t">So we used an approach where we had 80% of the data that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1348" target="_blank">00:22:28.440</a></span> | <span class="t">comes from the web.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1349" target="_blank">00:22:29.640</a></span> | <span class="t">And then we tried to use these web samples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1351" target="_blank">00:22:31.760</a></span> | <span class="t">to build new prompts that ask models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1353" target="_blank">00:22:33.920</a></span> | <span class="t">to generate textbooks that are related to these web samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1357" target="_blank">00:22:37.480</a></span> | <span class="t">But while giving them more context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1359" target="_blank">00:22:39.760</a></span> | <span class="t">so we can limit the generations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1363" target="_blank">00:22:43.080</a></span> | <span class="t">For example, we can have a topic that is mathematics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1367" target="_blank">00:22:47.560</a></span> | <span class="t">And then we have web samples that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1369" target="_blank">00:22:49.040</a></span> | <span class="t">are related to mathematics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1370" target="_blank">00:22:50.560</a></span> | <span class="t">And each time we give the model a prompt,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1372" target="_blank">00:22:52.600</a></span> | <span class="t">generate a textbook in the field of mathematics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1375" target="_blank">00:22:55.560</a></span> | <span class="t">that is related to this web sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1377" target="_blank">00:22:57.760</a></span> | <span class="t">And the more web samples we add, the more diversity we add.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1381" target="_blank">00:23:01.800</a></span> | <span class="t">We also used some curated sources like Stanford courses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1385" target="_blank">00:23:05.200</a></span> | <span class="t">and WikiHow, where we use extracts from these pages</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1388" target="_blank">00:23:08.600</a></span> | <span class="t">to ask the models to generate content</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1390" target="_blank">00:23:10.560</a></span> | <span class="t">that is related to them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1392" target="_blank">00:23:12.880</a></span> | <span class="t">You can find more details in the Cosmopedia blog post.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1398" target="_blank">00:23:18.400</a></span> | <span class="t">So I guess now we also have the answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1400" target="_blank">00:23:20.400</a></span> | <span class="t">for our second question, which was where to find the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1404" target="_blank">00:23:24.480</a></span> | <span class="t">And if you're following, we have one question left,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1407" target="_blank">00:23:27.680</a></span> | <span class="t">which is how can we filter this data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1410" target="_blank">00:23:30.520</a></span> | <span class="t">Because for example, if you use common crawl,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1413" target="_blank">00:23:33.200</a></span> | <span class="t">you need to filter it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1414" target="_blank">00:23:34.360</a></span> | <span class="t">And even if you use the stack, we did not train our models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1417" target="_blank">00:23:37.760</a></span> | <span class="t">on the stack directly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1418" target="_blank">00:23:38.960</a></span> | <span class="t">We did a lot of filtering to get a data set that is smaller,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1422" target="_blank">00:23:42.360</a></span> | <span class="t">but has a higher quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1426" target="_blank">00:23:46.120</a></span> | <span class="t">And for this data set, I will cite this slide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1429" target="_blank">00:23:49.480</a></span> | <span class="t">from Thomas Wolfe's presentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1432" target="_blank">00:23:52.440</a></span> | <span class="t">This lecture is very interesting, by the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1434" target="_blank">00:23:54.320</a></span> | <span class="t">You can find it here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1436" target="_blank">00:23:56.440</a></span> | <span class="t">And this is from the Yi paper, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1438" target="_blank">00:23:58.960</a></span> | <span class="t">they state that a high-quality data set might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1443" target="_blank">00:24:03.240</a></span> | <span class="t">exhibit very advanced capabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1445" target="_blank">00:24:05.600</a></span> | <span class="t">for a standard architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1447" target="_blank">00:24:07.760</a></span> | <span class="t">And this is actually the focus of many recent papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1453" target="_blank">00:24:13.160</a></span> | <span class="t">And we can see that in model releases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1455" target="_blank">00:24:15.720</a></span> | <span class="t">the sections about data sets are becoming smaller and smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1458" target="_blank">00:24:18.480</a></span> | <span class="t">because people are realizing that the data set is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1461" target="_blank">00:24:21.640</a></span> | <span class="t">the backbone, and it is the one that is making some models much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1465" target="_blank">00:24:25.480</a></span> | <span class="t">better than others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1466" target="_blank">00:24:26.960</a></span> | <span class="t">So it's really important to spend a lot of time creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1471" target="_blank">00:24:31.280</a></span> | <span class="t">these data sets and trying to remove all the outliers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1475" target="_blank">00:24:35.160</a></span> | <span class="t">and data sets that can hurt the model during the training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1477" target="_blank">00:24:37.880</a></span> | <span class="t">This is the pipeline from the Yi paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1483" target="_blank">00:24:43.760</a></span> | <span class="t">for filtering their old web data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1487" target="_blank">00:24:47.960</a></span> | <span class="t">So first, they do language filtering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1490" target="_blank">00:24:50.640</a></span> | <span class="t">So I guess in Yi's case, they get English and some Asian</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1493" target="_blank">00:24:53.920</a></span> | <span class="t">languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1494" target="_blank">00:24:54.960</a></span> | <span class="t">Then they apply some filtering techniques</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1497" target="_blank">00:24:57.440</a></span> | <span class="t">to remove low-quality samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1500" target="_blank">00:25:00.040</a></span> | <span class="t">For example, there are some metrics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1501" target="_blank">00:25:01.520</a></span> | <span class="t">like you look for files that have a lot of lines repeated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1505" target="_blank">00:25:05.360</a></span> | <span class="t">and then remove them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1506" target="_blank">00:25:06.600</a></span> | <span class="t">There's also rule-based correction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1508" target="_blank">00:25:08.480</a></span> | <span class="t">You also can use perplexity filtering,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1510" target="_blank">00:25:10.640</a></span> | <span class="t">where you compute something like a loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1513" target="_blank">00:25:13.080</a></span> | <span class="t">and remove samples that have a very high one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1515" target="_blank">00:25:15.840</a></span> | <span class="t">Then after that, they also did a step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1518" target="_blank">00:25:18.800</a></span> | <span class="t">which is very important, deduplication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1522" target="_blank">00:25:22.280</a></span> | <span class="t">Because there are a lot of papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1523" target="_blank">00:25:23.720</a></span> | <span class="t">that study the effect of duplicates on training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1526" target="_blank">00:25:26.640</a></span> | <span class="t">and they find that keeping duplicates in the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1529" target="_blank">00:25:29.280</a></span> | <span class="t">data can cause models to memorize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1532" target="_blank">00:25:32.600</a></span> | <span class="t">and they have less space to be creative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1536" target="_blank">00:25:36.040</a></span> | <span class="t">So this hurts the performance of models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1538" target="_blank">00:25:38.480</a></span> | <span class="t">and it's always advised to remove duplicates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1542" target="_blank">00:25:42.080</a></span> | <span class="t">using exact deduplication to remove files</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1545" target="_blank">00:25:45.280</a></span> | <span class="t">that are exactly identical, but also near deduplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1549" target="_blank">00:25:49.200</a></span> | <span class="t">to remove files that are similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1551" target="_blank">00:25:51.320</a></span> | <span class="t">And this uses techniques like min-hash deduplication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1555" target="_blank">00:25:55.680</a></span> | <span class="t">For Yi, after that, they also did more filtering on top,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1558" target="_blank">00:25:58.680</a></span> | <span class="t">like semantic and topic filtering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1561" target="_blank">00:26:01.280</a></span> | <span class="t">But usually, you can do the classic filtering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1564" target="_blank">00:26:04.120</a></span> | <span class="t">and deduplication and then be more creative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1566" target="_blank">00:26:06.240</a></span> | <span class="t">for the other filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1569" target="_blank">00:26:09.600</a></span> | <span class="t">This was also the case for FineWeb.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1571" target="_blank">00:26:11.840</a></span> | <span class="t">The reason it is better than other data sets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1574" target="_blank">00:26:14.680</a></span> | <span class="t">is that because they spent a lot of time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1577" target="_blank">00:26:17.120</a></span> | <span class="t">trying to come up with better filters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1579" target="_blank">00:26:19.560</a></span> | <span class="t">and also deduplicate the data sets well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1585" target="_blank">00:26:25.320</a></span> | <span class="t">Now the question is, OK, we can do deduplication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1588" target="_blank">00:26:28.760</a></span> | <span class="t">I think we have methods that are established to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1592" target="_blank">00:26:32.360</a></span> | <span class="t">We can also do language filtering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1595" target="_blank">00:26:35.200</a></span> | <span class="t">But then if you want to filter the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1597" target="_blank">00:26:37.400</a></span> | <span class="t">to remove garbage and lower quality files,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1600" target="_blank">00:26:40.680</a></span> | <span class="t">how do you come up with good filters?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1603" target="_blank">00:26:43.200</a></span> | <span class="t">You can, for sure, find some filters in the literature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1607" target="_blank">00:26:47.040</a></span> | <span class="t">But if you want to really build a data set that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1609" target="_blank">00:26:49.320</a></span> | <span class="t">is better than what exists, you need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1611" target="_blank">00:26:51.400</a></span> | <span class="t">to invest some time trying to find more techniques that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1614" target="_blank">00:26:54.120</a></span> | <span class="t">work better for your case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1616" target="_blank">00:26:56.080</a></span> | <span class="t">This can be done with manual inspection, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1620" target="_blank">00:27:00.480</a></span> | <span class="t">is always a good idea to look at the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1622" target="_blank">00:27:02.840</a></span> | <span class="t">and see what it actually looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1624" target="_blank">00:27:04.680</a></span> | <span class="t">And you can come up with filters to help you during the training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1628" target="_blank">00:27:08.640</a></span> | <span class="t">But that is usually not enough because you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1631" target="_blank">00:27:11.200</a></span> | <span class="t">might have an intuition for filtering that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1634" target="_blank">00:27:14.040</a></span> | <span class="t">works better for your model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1635" target="_blank">00:27:15.840</a></span> | <span class="t">But then when you train, actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1637" target="_blank">00:27:17.440</a></span> | <span class="t">this filtering doesn't help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1638" target="_blank">00:27:18.920</a></span> | <span class="t">And for example, for us, when we were developing the StarCoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1643" target="_blank">00:27:23.040</a></span> | <span class="t">series of models, we were thinking, OK,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1646" target="_blank">00:27:26.240</a></span> | <span class="t">what are the best ways for us to filter code?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1648" target="_blank">00:27:28.800</a></span> | <span class="t">So we use some standard filters, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1651" target="_blank">00:27:31.200</a></span> | <span class="t">to remove auto-generated content.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1653" target="_blank">00:27:33.280</a></span> | <span class="t">But we try to come up with a little bit more complex</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1656" target="_blank">00:27:36.440</a></span> | <span class="t">filterings that could help us, like looking for files that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1659" target="_blank">00:27:39.600</a></span> | <span class="t">have a lot of comments because code that is usually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1662" target="_blank">00:27:42.680</a></span> | <span class="t">well-documented is probably of a higher quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1665" target="_blank">00:27:45.840</a></span> | <span class="t">than another code file that doesn't have any comments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1669" target="_blank">00:27:49.080</a></span> | <span class="t">So we implemented this filter that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1671" target="_blank">00:27:51.080</a></span> | <span class="t">looks for files that have almost no comments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1673" target="_blank">00:27:53.920</a></span> | <span class="t">and then removes them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1675" target="_blank">00:27:55.240</a></span> | <span class="t">And we trained a model on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1677" target="_blank">00:27:57.800</a></span> | <span class="t">It turned out the performance improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1679" target="_blank">00:27:59.800</a></span> | <span class="t">was really negligible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1681" target="_blank">00:28:01.080</a></span> | <span class="t">It was not as much as we thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1683" target="_blank">00:28:03.400</a></span> | <span class="t">We also tried to use another filter, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1686" target="_blank">00:28:06.000</a></span> | <span class="t">is using the stars of a repository</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1688" target="_blank">00:28:08.480</a></span> | <span class="t">as an indicator of quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1690" target="_blank">00:28:10.320</a></span> | <span class="t">So we've tried removing all the files from repository</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1693" target="_blank">00:28:13.720</a></span> | <span class="t">that have less than five stars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1695" target="_blank">00:28:15.640</a></span> | <span class="t">And this ended up removing over 70% of the data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1699" target="_blank">00:28:19.360</a></span> | <span class="t">And then when we trained on it, the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1701" target="_blank">00:28:21.240</a></span> | <span class="t">was the worst model that we trained in all our ablation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1704" target="_blank">00:28:24.520</a></span> | <span class="t">experiments, simply because it removed too much data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1707" target="_blank">00:28:27.760</a></span> | <span class="t">It was not worth using this filtering technique.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1711" target="_blank">00:28:31.760</a></span> | <span class="t">This is why it's very important that when you have a filter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1714" target="_blank">00:28:34.680</a></span> | <span class="t">you should run what we call an ablation model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1717" target="_blank">00:28:37.800</a></span> | <span class="t">The ablation is basically you take a subset of your data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1721" target="_blank">00:28:41.000</a></span> | <span class="t">after you applied the filtering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1723" target="_blank">00:28:43.040</a></span> | <span class="t">And you train a small model on it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1724" target="_blank">00:28:44.720</a></span> | <span class="t">and see how it behaves with and without the filtering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1728" target="_blank">00:28:48.560</a></span> | <span class="t">And you might be wondering, OK, if I use a small model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1732" target="_blank">00:28:52.240</a></span> | <span class="t">but does it really extrapolate to larger models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1735" target="_blank">00:28:55.080</a></span> | <span class="t">I think that's a good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1736" target="_blank">00:28:56.520</a></span> | <span class="t">But generally, from our experience,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1738" target="_blank">00:28:58.800</a></span> | <span class="t">we found that this does extrapolate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1740" target="_blank">00:29:00.880</a></span> | <span class="t">for most of the ablations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1744" target="_blank">00:29:04.280</a></span> | <span class="t">When you're doing these ablations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1746" target="_blank">00:29:06.160</a></span> | <span class="t">you should select a set of high signal benchmarks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1750" target="_blank">00:29:10.480</a></span> | <span class="t">that could show you some--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1753" target="_blank">00:29:13.480</a></span> | <span class="t">give you some conclusions about the effect of your filtering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1756" target="_blank">00:29:16.320</a></span> | <span class="t">early in the training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1758" target="_blank">00:29:18.200</a></span> | <span class="t">This can be some of the popular NLP benchmarks for LLMs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1761" target="_blank">00:29:21.880</a></span> | <span class="t">for example, HeLaSwag or MMLU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1765" target="_blank">00:29:25.280</a></span> | <span class="t">You should also-- sorry, here, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1767" target="_blank">00:29:27.200</a></span> | <span class="t">not training, it's training-- with different seeds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1769" target="_blank">00:29:29.760</a></span> | <span class="t">to reduce the noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1771" target="_blank">00:29:31.000</a></span> | <span class="t">Because sometimes you can have filtering techniques</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1773" target="_blank">00:29:33.160</a></span> | <span class="t">that don't give you a very big difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1775" target="_blank">00:29:35.480</a></span> | <span class="t">But if you train with just one seed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1778" target="_blank">00:29:38.160</a></span> | <span class="t">you must draw conclusions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1779" target="_blank">00:29:39.440</a></span> | <span class="t">But they're actually just noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1781" target="_blank">00:29:41.040</a></span> | <span class="t">So if you can and you have the compute,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1783" target="_blank">00:29:43.560</a></span> | <span class="t">it's always better to run the same experiment with two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1786" target="_blank">00:29:46.600</a></span> | <span class="t">or three different seeds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1788" target="_blank">00:29:48.040</a></span> | <span class="t">And then maybe do something like the averaging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1790" target="_blank">00:29:50.480</a></span> | <span class="t">so that you reduce the noise and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1792" target="_blank">00:29:52.160</a></span> | <span class="t">have more robust conclusions about the effect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1794" target="_blank">00:29:54.520</a></span> | <span class="t">of your filtering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1797" target="_blank">00:29:57.880</a></span> | <span class="t">For example, for the fine web data set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1801" target="_blank">00:30:01.080</a></span> | <span class="t">the authors run over 200 plus ablations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1805" target="_blank">00:30:05.080</a></span> | <span class="t">These were like 1 billion models trained on, I think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1808" target="_blank">00:30:08.200</a></span> | <span class="t">30 billion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1809" target="_blank">00:30:09.800</a></span> | <span class="t">And this is how they were able to find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1812" target="_blank">00:30:12.280</a></span> | <span class="t">filterings that worked better for their data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1816" target="_blank">00:30:16.160</a></span> | <span class="t">Now let's go back to our Starcoder use case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1819" target="_blank">00:30:19.920</a></span> | <span class="t">And I will tell you about how we filtered the stack data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1823" target="_blank">00:30:23.600</a></span> | <span class="t">So for the version 1, if you remember,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1827" target="_blank">00:30:27.160</a></span> | <span class="t">we had 6 terabytes of source code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1830" target="_blank">00:30:30.000</a></span> | <span class="t">And then, but when we trained Starcoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1832" target="_blank">00:30:32.520</a></span> | <span class="t">we only used 800 gigabytes of these 6 terabytes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1836" target="_blank">00:30:36.480</a></span> | <span class="t">So a lot of this data was filtered out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1839" target="_blank">00:30:39.800</a></span> | <span class="t">after our filtering, our curation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1844" target="_blank">00:30:44.000</a></span> | <span class="t">The same happened for the Stack V2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1846" target="_blank">00:30:46.200</a></span> | <span class="t">where this time we started from 32 terabytes and 600</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1849" target="_blank">00:30:49.320</a></span> | <span class="t">programming languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1850" target="_blank">00:30:50.520</a></span> | <span class="t">And after the filtering, we ended up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1852" target="_blank">00:30:52.640</a></span> | <span class="t">with only 6.3 terabytes of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1856" target="_blank">00:30:56.680</a></span> | <span class="t">And for filtering code, the approach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1859" target="_blank">00:30:59.960</a></span> | <span class="t">is a bit similar to just filtering web data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1863" target="_blank">00:31:03.520</a></span> | <span class="t">but the filtering techniques are a bit different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1866" target="_blank">00:31:06.880</a></span> | <span class="t">So first, we wanted to include a lot of programming languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1871" target="_blank">00:31:11.200</a></span> | <span class="t">And we looked at them, and we didn't keep all of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1874" target="_blank">00:31:14.480</a></span> | <span class="t">We only kept the popular ones and excluded, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1878" target="_blank">00:31:18.200</a></span> | <span class="t">configs and languages that are no longer maintained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1881" target="_blank">00:31:21.160</a></span> | <span class="t">So this was for V1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1882" target="_blank">00:31:22.640</a></span> | <span class="t">For Starcoder 2, we included more languages, over 600.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1887" target="_blank">00:31:27.360</a></span> | <span class="t">And then we added some other sources</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1889" target="_blank">00:31:29.200</a></span> | <span class="t">that could be interesting for a code model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1891" target="_blank">00:31:31.600</a></span> | <span class="t">to learn from, which are GitHub issues, Git commits,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1895" target="_blank">00:31:35.600</a></span> | <span class="t">and Jupyter notebooks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1897" target="_blank">00:31:37.520</a></span> | <span class="t">We also added for the V2, we added</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1900" target="_blank">00:31:40.080</a></span> | <span class="t">also added for the V2, Kaggle, notebooks, and pull requests.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1906" target="_blank">00:31:46.280</a></span> | <span class="t">The second step, after we selected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1908" target="_blank">00:31:48.480</a></span> | <span class="t">the languages we wanted to train on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1910" target="_blank">00:31:50.680</a></span> | <span class="t">was data quality inspection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1913" target="_blank">00:31:53.360</a></span> | <span class="t">So basically, as I told you, we had some filters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1915" target="_blank">00:31:55.760</a></span> | <span class="t">to remove low-quality files and auto-generated content.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1920" target="_blank">00:32:00.600</a></span> | <span class="t">An example is the average line length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1923" target="_blank">00:32:03.480</a></span> | <span class="t">So if you have an average line length that is too high,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1926" target="_blank">00:32:06.520</a></span> | <span class="t">there's probably something wrong with this file</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1928" target="_blank">00:32:08.480</a></span> | <span class="t">where it's probably auto-generated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1930" target="_blank">00:32:10.440</a></span> | <span class="t">But since we had almost 100 programming languages,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1934" target="_blank">00:32:14.880</a></span> | <span class="t">we should not use the same threshold for all the languages</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1937" target="_blank">00:32:17.920</a></span> | <span class="t">for this filter, because some programming languages just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1940" target="_blank">00:32:20.600</a></span> | <span class="t">have longer lines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1941" target="_blank">00:32:21.960</a></span> | <span class="t">So it's important to do some inspection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1944" target="_blank">00:32:24.240</a></span> | <span class="t">and look at some samples from these languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1946" target="_blank">00:32:26.680</a></span> | <span class="t">In our case, we had the BigCode community,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1949" target="_blank">00:32:29.320</a></span> | <span class="t">which helps us look at 100 samples per extension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1953" target="_blank">00:32:33.400</a></span> | <span class="t">and derive the appropriate thresholds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1955" target="_blank">00:32:35.720</a></span> | <span class="t">in filtering heuristics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1957" target="_blank">00:32:37.080</a></span> | <span class="t">The third filtering step was near deduplication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1966" target="_blank">00:32:46.920</a></span> | <span class="t">We found that near deduplication was the filtering that gave us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1970" target="_blank">00:32:50.240</a></span> | <span class="t">the most performance boost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1972" target="_blank">00:32:52.120</a></span> | <span class="t">It's also very easy to apply, because it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1974" target="_blank">00:32:54.440</a></span> | <span class="t">language agnostic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1975" target="_blank">00:32:55.920</a></span> | <span class="t">Even though we have 86 programming languages,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1978" target="_blank">00:32:58.520</a></span> | <span class="t">we don't need to change the duplication for each language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1981" target="_blank">00:33:01.280</a></span> | <span class="t">We can just apply it to the whole data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1985" target="_blank">00:33:05.360</a></span> | <span class="t">And here I show you some results of the effects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1988" target="_blank">00:33:08.920</a></span> | <span class="t">of deduplication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1990" target="_blank">00:33:10.400</a></span> | <span class="t">For example, here you can see this model, Python all license.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1993" target="_blank">00:33:13.840</a></span> | <span class="t">If the filtering is none, you get a pass at 1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1996" target="_blank">00:33:16.520</a></span> | <span class="t">which is our code metric, of 13.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=1998" target="_blank">00:33:18.960</a></span> | <span class="t">But if you apply near deduplication,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2000" target="_blank">00:33:20.840</a></span> | <span class="t">you go from 13 to 17.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2002" target="_blank">00:33:22.920</a></span> | <span class="t">That's a very big performance bump.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2005" target="_blank">00:33:25.600</a></span> | <span class="t">The same goes for other subsets, like permissive license.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2008" target="_blank">00:33:28.880</a></span> | <span class="t">So we decided to use deduplication for our data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2013" target="_blank">00:33:33.440</a></span> | <span class="t">and to use strong deduplication to really remove</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2016" target="_blank">00:33:36.280</a></span> | <span class="t">all the files that could be similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2020" target="_blank">00:33:40.160</a></span> | <span class="t">Another step in our pipeline is to remove</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2023" target="_blank">00:33:43.240</a></span> | <span class="t">personal identifiable information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2025" target="_blank">00:33:45.840</a></span> | <span class="t">So this could be names, emails, or keys, or passwords,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2030" target="_blank">00:33:50.080</a></span> | <span class="t">because we scraped code from GitHub.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2032" target="_blank">00:33:52.440</a></span> | <span class="t">And although GitHub has some tools</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2035" target="_blank">00:33:55.120</a></span> | <span class="t">to detect secrets and prompt users to remove them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2038" target="_blank">00:33:58.160</a></span> | <span class="t">that's not always the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2039" target="_blank">00:33:59.920</a></span> | <span class="t">And we found that there were still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2041" target="_blank">00:34:01.320</a></span> | <span class="t">a lot of secrets in the data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2043" target="_blank">00:34:03.480</a></span> | <span class="t">And we trained our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2044" target="_blank">00:34:04.640</a></span> | <span class="t">You don't want it to be trained on that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2046" target="_blank">00:34:06.800</a></span> | <span class="t">because in inference, it might generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2048" target="_blank">00:34:08.960</a></span> | <span class="t">sensitive or personal data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2051" target="_blank">00:34:11.800</a></span> | <span class="t">So our approach to removing it was to first annotate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2055" target="_blank">00:34:15.040</a></span> | <span class="t">a data set for PII.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2058" target="_blank">00:34:18.000</a></span> | <span class="t">We collaborated with an annotation company</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2061" target="_blank">00:34:21.560</a></span> | <span class="t">to annotate some samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2063" target="_blank">00:34:23.720</a></span> | <span class="t">So the annotators were tasked with labeling the PII</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2067" target="_blank">00:34:27.920</a></span> | <span class="t">when they found it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2068" target="_blank">00:34:28.840</a></span> | <span class="t">For example, if they find a name,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2070" target="_blank">00:34:30.200</a></span> | <span class="t">they give it a class name.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2071" target="_blank">00:34:31.520</a></span> | <span class="t">If you find an email, they also label it as an email.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2074" target="_blank">00:34:34.160</a></span> | <span class="t">So it was a named entity recognition task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2077" target="_blank">00:34:37.120</a></span> | <span class="t">And then we trained a star PII, which is our NER model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2081" target="_blank">00:34:41.080</a></span> | <span class="t">to detect this PII.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2083" target="_blank">00:34:43.080</a></span> | <span class="t">And then we run it on the whole star coder training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2088" target="_blank">00:34:48.760</a></span> | <span class="t">This took almost 800, 100 GPU hours,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2092" target="_blank">00:34:52.720</a></span> | <span class="t">because it's a neural network, and it needs to run on GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2097" target="_blank">00:34:57.840</a></span> | <span class="t">The last step in our filtering was data decontamination,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2102" target="_blank">00:35:02.800</a></span> | <span class="t">because you should make sure to remove the benchmarks and test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2106" target="_blank">00:35:06.320</a></span> | <span class="t">sets from your training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2108" target="_blank">00:35:08.040</a></span> | <span class="t">Otherwise, your evaluation numbers will just be inflated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2112" target="_blank">00:35:12.000</a></span> | <span class="t">So we made sure to remove the benchmarks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2114" target="_blank">00:35:14.240</a></span> | <span class="t">that we used for evaluation from our training sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2116" target="_blank">00:35:16.920</a></span> | <span class="t">The last step in the data curation of the stack</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2123" target="_blank">00:35:23.440</a></span> | <span class="t">was to format the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2125" target="_blank">00:35:25.680</a></span> | <span class="t">So now that the data is filtered,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2127" target="_blank">00:35:27.680</a></span> | <span class="t">and because code is different from text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2130" target="_blank">00:35:30.960</a></span> | <span class="t">we can allow ourselves to apply some nice formatting that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2135" target="_blank">00:35:35.600</a></span> | <span class="t">could help us do an inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2137" target="_blank">00:35:37.440</a></span> | <span class="t">For example, for a star coder, we had the code file.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2140" target="_blank">00:35:40.800</a></span> | <span class="t">But before the code, we added some tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2143" target="_blank">00:35:43.920</a></span> | <span class="t">that indicate that this is the repository name,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2146" target="_blank">00:35:46.160</a></span> | <span class="t">and another token file name that indicates the file name,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2149" target="_blank">00:35:49.440</a></span> | <span class="t">and another one for stars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2151" target="_blank">00:35:51.280</a></span> | <span class="t">And this is interesting, because this model, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2155" target="_blank">00:35:55.080</a></span> | <span class="t">star coder and other code models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2157" target="_blank">00:35:57.120</a></span> | <span class="t">I guess their main use case is to be plugged in an IDE,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2160" target="_blank">00:36:00.640</a></span> | <span class="t">for example, VS Code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2162" target="_blank">00:36:02.240</a></span> | <span class="t">And when you're using them, it could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2165" target="_blank">00:36:05.120</a></span> | <span class="t">be interesting to append the code file with the name</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2168" target="_blank">00:36:08.560</a></span> | <span class="t">of the file, for example, or file those bytes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2172" target="_blank">00:36:12.000</a></span> | <span class="t">so that the model would know this is a Python file.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2174" target="_blank">00:36:14.400</a></span> | <span class="t">If it's in another language, when you add the file name</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2176" target="_blank">00:36:16.920</a></span> | <span class="t">and you have the extension, it could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2178" target="_blank">00:36:18.440</a></span> | <span class="t">know that this is the language that it should generate code in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2183" target="_blank">00:36:23.120</a></span> | <span class="t">We also added GitHub stars token,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2185" target="_blank">00:36:25.160</a></span> | <span class="t">and we tried to play with it, like to say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2187" target="_blank">00:36:27.960</a></span> | <span class="t">this file has 100 stars, and see if the model would generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2191" target="_blank">00:36:31.520</a></span> | <span class="t">higher quality code than if it were to generate for zero stars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2196" target="_blank">00:36:36.480</a></span> | <span class="t">We didn't find any differences really during inference,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2198" target="_blank">00:36:38.920</a></span> | <span class="t">but it was fun to add all this formatting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2202" target="_blank">00:36:42.840</a></span> | <span class="t">For star coder 2, one of the improvements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2206" target="_blank">00:36:46.160</a></span> | <span class="t">was that star coder 2 was repository aware.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2210" target="_blank">00:36:50.280</a></span> | <span class="t">Because when we have GitHub repositories,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2212" target="_blank">00:36:52.880</a></span> | <span class="t">it's a repository.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2213" target="_blank">00:36:53.800</a></span> | <span class="t">So we have some files that are in the same repository that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2216" target="_blank">00:36:56.760</a></span> | <span class="t">are related to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2218" target="_blank">00:36:58.480</a></span> | <span class="t">But when we built the stack V1, we just shuffled files,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2222" target="_blank">00:37:02.200</a></span> | <span class="t">so we didn't keep this repository structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2225" target="_blank">00:37:05.440</a></span> | <span class="t">And when we trained the model, we just shuffled them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2227" target="_blank">00:37:07.760</a></span> | <span class="t">and the model did not know if two files belong</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2230" target="_blank">00:37:10.920</a></span> | <span class="t">to the same repository.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2232" target="_blank">00:37:12.520</a></span> | <span class="t">But when we did star coder 2, we tried</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2234" target="_blank">00:37:14.560</a></span> | <span class="t">to keep files that are in the same repository next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2237" target="_blank">00:37:17.320</a></span> | <span class="t">to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2238" target="_blank">00:37:18.240</a></span> | <span class="t">And how we did that is by concatenating them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2240" target="_blank">00:37:20.800</a></span> | <span class="t">with some special tokens like file set, which basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2243" target="_blank">00:37:23.720</a></span> | <span class="t">separates files.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2244" target="_blank">00:37:24.880</a></span> | <span class="t">And this way, the model can kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2248" target="_blank">00:37:28.440</a></span> | <span class="t">know which files are in the same repository</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2250" target="_blank">00:37:30.800</a></span> | <span class="t">and try to find links between them, 3D parallelism.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2254" target="_blank">00:37:34.160</a></span> | <span class="t">And then you have also light eval for doing the evaluation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2257" target="_blank">00:37:37.760</a></span> | <span class="t">So this is kind of a good stack to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2259" target="_blank">00:37:39.640</a></span> | <span class="t">able to run your full trainings, but also your ablation models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2263" target="_blank">00:37:43.440</a></span> | <span class="t">You can apply a filter from data to strobe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2265" target="_blank">00:37:45.480</a></span> | <span class="t">and then train with nanotron and evaluate with light eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2268" target="_blank">00:37:48.520</a></span> | <span class="t">And they're well-integrated together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2270" target="_blank">00:37:50.240</a></span> | <span class="t">and they make one ecosystem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2272" target="_blank">00:37:52.720</a></span> | <span class="t">So that's for general LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2274" target="_blank">00:37:54.840</a></span> | <span class="t">For code LLMs, we also released the code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2278" target="_blank">00:37:58.240</a></span> | <span class="t">we used for both the stack and star coder models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2281" target="_blank">00:38:01.560</a></span> | <span class="t">under our big code repository on GitHub.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2284" target="_blank">00:38:04.120</a></span> | <span class="t">And I think we just answered our third question, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2290" target="_blank">00:38:10.920</a></span> | <span class="t">was how to filter the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2292" target="_blank">00:38:12.800</a></span> | <span class="t">So now you know how to--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2294" target="_blank">00:38:14.720</a></span> | <span class="t">first, how much data you need, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2297" target="_blank">00:38:17.320</a></span> | <span class="t">where you can get this data, both web, and code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2300" target="_blank">00:38:20.320</a></span> | <span class="t">and synthetic, and curated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2302" target="_blank">00:38:22.120</a></span> | <span class="t">And you also know how you can properly filter the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2305" target="_blank">00:38:25.480</a></span> | <span class="t">and you can test the filtering techniques</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2308" target="_blank">00:38:28.000</a></span> | <span class="t">that you have in mind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2310" target="_blank">00:38:30.920</a></span> | <span class="t">So now, let me tell you a little bit more about code LLMs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2315" target="_blank">00:38:35.080</a></span> | <span class="t">because that's kind of what I'm working on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2318" target="_blank">00:38:38.680</a></span> | <span class="t">And I'm trying to give you a little bit of an overview</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2321" target="_blank">00:38:41.320</a></span> | <span class="t">about these models so that you know how to train good LLMs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2324" target="_blank">00:38:44.520</a></span> | <span class="t">but you also know how to build very cool code assistants</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2328" target="_blank">00:38:48.160</a></span> | <span class="t">and completion models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2331" target="_blank">00:38:51.600</a></span> | <span class="t">So how all of this started was when GitHub Copilot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2335" target="_blank">00:38:55.560</a></span> | <span class="t">was released.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2337" target="_blank">00:38:57.040</a></span> | <span class="t">And it was very interesting, because it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2338" target="_blank">00:38:58.840</a></span> | <span class="t">was so much better than all the other code completion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2341" target="_blank">00:39:01.920</a></span> | <span class="t">models that were before it, which were very small and much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2345" target="_blank">00:39:05.480</a></span> | <span class="t">less performant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2346" target="_blank">00:39:06.720</a></span> | <span class="t">And GitHub Copilot was using the Codex model by OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2351" target="_blank">00:39:11.960</a></span> | <span class="t">And they just showed that you can train a code LLM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2354" target="_blank">00:39:14.960</a></span> | <span class="t">in the same way that you train an LLM for English,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2357" target="_blank">00:39:17.800</a></span> | <span class="t">for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2358" target="_blank">00:39:18.760</a></span> | <span class="t">You can just take a large transformer model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2361" target="_blank">00:39:21.640</a></span> | <span class="t">and give it a lot of code data, and it will learn this code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2365" target="_blank">00:39:25.640</a></span> | <span class="t">Because before, a lot of people were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2367" target="_blank">00:39:27.160</a></span> | <span class="t">trying to treat code very differently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2369" target="_blank">00:39:29.440</a></span> | <span class="t">for example, by using abstract syntax trees.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2372" target="_blank">00:39:32.960</a></span> | <span class="t">But what Codex model showed is that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2374" target="_blank">00:39:34.960</a></span> | <span class="t">can treat code like text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2376" target="_blank">00:39:36.520</a></span> | <span class="t">And if you want to predict the next line,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2378" target="_blank">00:39:38.640</a></span> | <span class="t">you can predict the next text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2380" target="_blank">00:39:40.360</a></span> | <span class="t">You just do next token prediction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2382" target="_blank">00:39:42.520</a></span> | <span class="t">and you get your code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2384" target="_blank">00:39:44.520</a></span> | <span class="t">It works very well, much better compared to the more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2388" target="_blank">00:39:48.120</a></span> | <span class="t">feature-engineered techniques.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2390" target="_blank">00:39:50.880</a></span> | <span class="t">And that was over two years ago, and we didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2394" target="_blank">00:39:54.560</a></span> | <span class="t">have any good open-code models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2397" target="_blank">00:39:57.600</a></span> | <span class="t">But today, if you go to the hub, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2399" target="_blank">00:39:59.640</a></span> | <span class="t">can find that we have over 1,700 models that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2403" target="_blank">00:40:03.080</a></span> | <span class="t">are trained on code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2404" target="_blank">00:40:04.560</a></span> | <span class="t">So these are models that are either trained only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2407" target="_blank">00:40:07.640</a></span> | <span class="t">on code or LLMs that included code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2410" target="_blank">00:40:10.640</a></span> | <span class="t">as part of their training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2412" target="_blank">00:40:12.960</a></span> | <span class="t">So you can see that we've made a lot of progress</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2415" target="_blank">00:40:15.800</a></span> | <span class="t">in this code generation field, which is amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2421" target="_blank">00:40:21.080</a></span> | <span class="t">And this is the result of the community's work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2426" target="_blank">00:40:26.480</a></span> | <span class="t">to build very good instruction-tuned models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2429" target="_blank">00:40:29.640</a></span> | <span class="t">and base models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2431" target="_blank">00:40:31.160</a></span> | <span class="t">For example, here, as you can see in the leaderboard,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2433" target="_blank">00:40:33.560</a></span> | <span class="t">we have some very strong models that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2435" target="_blank">00:40:35.760</a></span> | <span class="t">score almost 80% on the code evaluation benchmark, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2439" target="_blank">00:40:39.720</a></span> | <span class="t">is human eval, which means they get almost 80%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2442" target="_blank">00:40:42.680</a></span> | <span class="t">of the problems right, which is a very large number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2447" target="_blank">00:40:47.240</a></span> | <span class="t">And when talking about the landscape of open-code LLMs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2451" target="_blank">00:40:51.360</a></span> | <span class="t">in BigCode, we have released the stack data set, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2454" target="_blank">00:40:54.440</a></span> | <span class="t">is now the default data set for training on code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2457" target="_blank">00:40:57.200</a></span> | <span class="t">and also StarCoder1 and StarCoder2 family</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2459" target="_blank">00:40:59.960</a></span> | <span class="t">of models and other instruction-tuned models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2462" target="_blank">00:41:02.560</a></span> | <span class="t">with the H4 team, like StarChat2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2465" target="_blank">00:41:05.800</a></span> | <span class="t">Meta also released some very good code models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2468" target="_blank">00:41:08.840</a></span> | <span class="t">which are the Code Llama series of models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2470" target="_blank">00:41:10.840</a></span> | <span class="t">that go from 7b to 7tb.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2473" target="_blank">00:41:13.680</a></span> | <span class="t">There are also the DeepSeq models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2475" target="_blank">00:41:15.680</a></span> | <span class="t">which are also very strong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2477" target="_blank">00:41:17.800</a></span> | <span class="t">And we have also other models, like the recent Granite models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2481" target="_blank">00:41:21.000</a></span> | <span class="t">from IBM, CodeQuen, CodeGen, and StableCode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2485" target="_blank">00:41:25.280</a></span> | <span class="t">So there are different providers for code LLMs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2489" target="_blank">00:41:29.160</a></span> | <span class="t">and also for data sets for code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2492" target="_blank">00:41:32.880</a></span> | <span class="t">And the main reason we started the BigCode collaboration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2496" target="_blank">00:41:36.400</a></span> | <span class="t">and to train StarCoder models was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2498" target="_blank">00:41:38.800</a></span> | <span class="t">to kind of have a collaboration where we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2500" target="_blank">00:41:40.760</a></span> | <span class="t">have full data transparency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2503" target="_blank">00:41:43.680</a></span> | <span class="t">We released all the details about the training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2505" target="_blank">00:41:45.960</a></span> | <span class="t">but also the data is public so that people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2508" target="_blank">00:41:48.360</a></span> | <span class="t">can inspect it and use it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2510" target="_blank">00:41:50.440</a></span> | <span class="t">And we also have the code for the processing and the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2513" target="_blank">00:41:53.560</a></span> | <span class="t">weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2514" target="_blank">00:41:54.240</a></span> | <span class="t">And the collaboration was open.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2515" target="_blank">00:41:55.880</a></span> | <span class="t">We had over 1,000 researchers joining our Slack</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2518" target="_blank">00:41:58.840</a></span> | <span class="t">and following the journey with us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2522" target="_blank">00:42:02.520</a></span> | <span class="t">And this kind of created a BigCode ecosystem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2525" target="_blank">00:42:05.520</a></span> | <span class="t">where the stack was used in the pre-training of a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2528" target="_blank">00:42:08.480</a></span> | <span class="t">of prominent code models, like CodeGen and StableCode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2533" target="_blank">00:42:13.120</a></span> | <span class="t">And the StarCoder models were used as basis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2536" target="_blank">00:42:16.240</a></span> | <span class="t">for a lot of community fine tunings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2538" target="_blank">00:42:18.280</a></span> | <span class="t">And I think it's very important to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2543" target="_blank">00:42:23.880</a></span> | <span class="t">aware of what makes a release of an LLM,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2548" target="_blank">00:42:28.320</a></span> | <span class="t">whether it be a code LLM or a general LLM,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2550" target="_blank">00:42:30.680</a></span> | <span class="t">open and responsible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2553" target="_blank">00:42:33.000</a></span> | <span class="t">And I think this is fourfold.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2555" target="_blank">00:42:35.240</a></span> | <span class="t">First, it's really good for the community</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2558" target="_blank">00:42:38.440</a></span> | <span class="t">and for research in AI in general.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2561" target="_blank">00:42:41.240</a></span> | <span class="t">If you can make open access data sets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2566" target="_blank">00:42:46.120</a></span> | <span class="t">this will mean having data inspection tools,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2568" target="_blank">00:42:48.920</a></span> | <span class="t">but also opt-out tools to respect people's wishes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2573" target="_blank">00:42:53.160</a></span> | <span class="t">regarding their data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2575" target="_blank">00:42:55.000</a></span> | <span class="t">For example, if they don't want to be included in the trainings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2577" target="_blank">00:42:57.880</a></span> | <span class="t">they should be able to opt-out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2580" target="_blank">00:43:00.120</a></span> | <span class="t">It's also important to remove personal identifiable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2582" target="_blank">00:43:02.800</a></span> | <span class="t">information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2584" target="_blank">00:43:04.560</a></span> | <span class="t">So an open release does not mean just releasing model weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2587" target="_blank">00:43:07.920</a></span> | <span class="t">and stopping there, but also making your work reproducible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2591" target="_blank">00:43:11.560</a></span> | <span class="t">by fully documenting the pipeline for using these models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2595" target="_blank">00:43:15.320</a></span> | <span class="t">and also releasing tools for evaluation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2599" target="_blank">00:43:19.320</a></span> | <span class="t">and technical reports that documents the whole pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2604" target="_blank">00:43:24.160</a></span> | <span class="t">And for us in BigCode, we kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2606" target="_blank">00:43:26.520</a></span> | <span class="t">went from StataCoder, which was part of our obligations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2610" target="_blank">00:43:30.400</a></span> | <span class="t">to understand how to filter the static data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2613" target="_blank">00:43:33.920</a></span> | <span class="t">And then we went to StarCoder, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2615" target="_blank">00:43:35.640</a></span> | <span class="t">was released last year, a $15 billion code generation model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2619" target="_blank">00:43:39.320</a></span> | <span class="t">And then this year, we released StarCoder2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2622" target="_blank">00:43:42.720</a></span> | <span class="t">which was trained on much more programming languages</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2625" target="_blank">00:43:45.360</a></span> | <span class="t">and had a much higher evaluation score.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2631" target="_blank">00:43:51.160</a></span> | <span class="t">And StarCoder was also rated as the most transparent model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2635" target="_blank">00:43:55.880</a></span> | <span class="t">by the Stanford Foundation Model Transparency Index, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2640" target="_blank">00:44:00.440</a></span> | <span class="t">is really hard to remember, given the efforts that we put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2642" target="_blank">00:44:02.840</a></span> | <span class="t">into data governance and into making the model release</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2646" target="_blank">00:44:06.360</a></span> | <span class="t">as transparent as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2647" target="_blank">00:44:07.840</a></span> | <span class="t">Regarding evaluation, so for example, StarCoder15b,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2654" target="_blank">00:44:14.560</a></span> | <span class="t">when it was released, it was the state-of-the-art code model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2659" target="_blank">00:44:19.040</a></span> | <span class="t">And this was also the case for StarCoder215b,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2662" target="_blank">00:44:22.120</a></span> | <span class="t">among other 15b models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2664" target="_blank">00:44:24.360</a></span> | <span class="t">And it was even close or better than larger models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2668" target="_blank">00:44:28.760</a></span> | <span class="t">I think I don't have the plot here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2670" target="_blank">00:44:30.280</a></span> | <span class="t">but it was better than-- it was matching CodeLlama34b.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2674" target="_blank">00:44:34.680</a></span> | <span class="t">And it was close to DeepSeq33b on some benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2678" target="_blank">00:44:38.640</a></span> | <span class="t">And here, for example, you can see the results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2681" target="_blank">00:44:41.200</a></span> | <span class="t">on different benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2683" target="_blank">00:44:43.640</a></span> | <span class="t">Because when releasing a model, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2685" target="_blank">00:44:45.240</a></span> | <span class="t">really important that you don't just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2687" target="_blank">00:44:47.360</a></span> | <span class="t">give a weight on one benchmark, but you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2689" target="_blank">00:44:49.760</a></span> | <span class="t">should add as many benchmarks as you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2692" target="_blank">00:44:52.160</a></span> | <span class="t">In case you had contamination, although we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2694" target="_blank">00:44:54.680</a></span> | <span class="t">tried to avoid this one benchmark,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2696" target="_blank">00:44:56.360</a></span> | <span class="t">there's a very low chance that you also had contamination</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2698" target="_blank">00:44:58.840</a></span> | <span class="t">on other benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2700" target="_blank">00:45:00.360</a></span> | <span class="t">And it also allows you to fully understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2703" target="_blank">00:45:03.120</a></span> | <span class="t">how your model behaves if you add more evaluation benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2708" target="_blank">00:45:08.680</a></span> | <span class="t">And I think that's just a good practice that everyone should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2711" target="_blank">00:45:11.280</a></span> | <span class="t">be doing with their releases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2712" target="_blank">00:45:12.520</a></span> | <span class="t">So with the StarCoder models, we also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2718" target="_blank">00:45:18.000</a></span> | <span class="t">released some tooling, like VS Code implementation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2722" target="_blank">00:45:22.920</a></span> | <span class="t">which also has a membership test that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2725" target="_blank">00:45:25.760</a></span> | <span class="t">tries to see if the generated code was in the training data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2730" target="_blank">00:45:30.120</a></span> | <span class="t">and highlight that to the author.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2732" target="_blank">00:45:32.200</a></span> | <span class="t">So that's part of our code attribution efforts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2737" target="_blank">00:45:37.040</a></span> | <span class="t">for these code models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2738" target="_blank">00:45:38.240</a></span> | <span class="t">Maybe you're interested in using these models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2743" target="_blank">00:45:43.200</a></span> | <span class="t">to build your own personal copilot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2746" target="_blank">00:45:46.000</a></span> | <span class="t">and fine-tune in StarCoder or CodeLAM or other models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2749" target="_blank">00:45:49.200</a></span> | <span class="t">on your personal code bases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2751" target="_blank">00:45:51.440</a></span> | <span class="t">To do that, there's a very nice blog post</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2754" target="_blank">00:45:54.480</a></span> | <span class="t">by Surab and Sayag, where they try to take a code model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2758" target="_blank">00:45:58.440</a></span> | <span class="t">and train it on the Hugging Face internal libraries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2762" target="_blank">00:46:02.720</a></span> | <span class="t">and then deploy it in Olama and have a local code assistant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2767" target="_blank">00:46:07.200</a></span> | <span class="t">And the pipeline is very similar to what we did in pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2770" target="_blank">00:46:10.440</a></span> | <span class="t">First, you take your data set, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2772" target="_blank">00:46:12.360</a></span> | <span class="t">try to filter out the things you don't want to keep,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2775" target="_blank">00:46:15.080</a></span> | <span class="t">and then you do the duplication and you train your model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2778" target="_blank">00:46:18.160</a></span> | <span class="t">So in this case, it will be just a fine-tuning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2780" target="_blank">00:46:20.280</a></span> | <span class="t">so it will be much quicker.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2781" target="_blank">00:46:21.720</a></span> | <span class="t">You can use libraries like PEFT, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2784" target="_blank">00:46:24.440</a></span> | <span class="t">do parameter-efficient fine-tuning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2786" target="_blank">00:46:26.600</a></span> | <span class="t">where you don't need to train all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2788" target="_blank">00:46:28.040</a></span> | <span class="t">the parameters of your models, but you only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2790" target="_blank">00:46:30.000</a></span> | <span class="t">inject a few trainable parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2792" target="_blank">00:46:32.880</a></span> | <span class="t">This makes the training much faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2795" target="_blank">00:46:35.600</a></span> | <span class="t">For example, 7b model can be trained in a Google Colab.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2801" target="_blank">00:46:41.720</a></span> | <span class="t">Now let's go back to evaluation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2804" target="_blank">00:46:44.120</a></span> | <span class="t">So for example, for LLMs, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2806" target="_blank">00:46:46.280</a></span> | <span class="t">the OpenLLM leaderboard that evaluates models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2810" target="_blank">00:46:50.120</a></span> | <span class="t">There's also the LLMs' arena, which compares, instructs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2813" target="_blank">00:46:53.600</a></span> | <span class="t">models, and uses human evaluation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2816" target="_blank">00:46:56.560</a></span> | <span class="t">For code models, one of the most popular benchmarks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2819" target="_blank">00:46:59.640</a></span> | <span class="t">is human eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2821" target="_blank">00:47:01.120</a></span> | <span class="t">And it's basically a benchmark where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2823" target="_blank">00:47:03.120</a></span> | <span class="t">you have a function that the model has to autocomplete.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2828" target="_blank">00:47:08.800</a></span> | <span class="t">And then when the function is completed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2831" target="_blank">00:47:11.200</a></span> | <span class="t">you take this solution, and then you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2833" target="_blank">00:47:13.440</a></span> | <span class="t">run it against multiple unit tests,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2836" target="_blank">00:47:16.240</a></span> | <span class="t">and you count how many solutions pass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2838" target="_blank">00:47:18.600</a></span> | <span class="t">and how many solutions fail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2840" target="_blank">00:47:20.160</a></span> | <span class="t">And then you count a metric that we call pass at one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2843" target="_blank">00:47:23.680</a></span> | <span class="t">for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2844" target="_blank">00:47:24.640</a></span> | <span class="t">This is the one that's been reported in this leaderboard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2847" target="_blank">00:47:27.680</a></span> | <span class="t">And this gives you the human eval score.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2850" target="_blank">00:47:30.480</a></span> | <span class="t">There's also a translation of this benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2852" target="_blank">00:47:32.640</a></span> | <span class="t">to 18 other languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2854" target="_blank">00:47:34.720</a></span> | <span class="t">Here I show Java and JavaScript in C++.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2858" target="_blank">00:47:38.240</a></span> | <span class="t">And this benchmark is called MultiPLE.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2860" target="_blank">00:47:40.760</a></span> | <span class="t">So it allows you to see how well each model does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2864" target="_blank">00:47:44.840</a></span> | <span class="t">on which programming language, and choose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2867" target="_blank">00:47:47.320</a></span> | <span class="t">the one that's the most interesting for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2871" target="_blank">00:47:51.720</a></span> | <span class="t">But these benchmarks usually have an issue of contamination</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2877" target="_blank">00:47:57.640</a></span> | <span class="t">and overfitting, especially instruction-tuned models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2881" target="_blank">00:48:01.720</a></span> | <span class="t">I don't know if you've already checked what these data sets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2884" target="_blank">00:48:04.680</a></span> | <span class="t">look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2885" target="_blank">00:48:05.600</a></span> | <span class="t">But usually for code, there are an instruction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2889" target="_blank">00:48:09.160</a></span> | <span class="t">that asks the model to generate an exercise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2891" target="_blank">00:48:11.840</a></span> | <span class="t">And often, if you look at them, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2893" target="_blank">00:48:13.640</a></span> | <span class="t">look really similar to human eval, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2895" target="_blank">00:48:15.720</a></span> | <span class="t">is function implementations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2898" target="_blank">00:48:18.240</a></span> | <span class="t">So there's a very high chance of having contamination, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2902" target="_blank">00:48:22.560</a></span> | <span class="t">means having some files that look like human eval</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2908" target="_blank">00:48:28.040</a></span> | <span class="t">exercises in your instruction tuning data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2912" target="_blank">00:48:32.120</a></span> | <span class="t">So here, for example, this plot is from the LifeCodeBench</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2915" target="_blank">00:48:35.720</a></span> | <span class="t">leaderboard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2916" target="_blank">00:48:36.640</a></span> | <span class="t">And they find that some benchmarks may</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2920" target="_blank">00:48:40.240</a></span> | <span class="t">be overfitting on human eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2923" target="_blank">00:48:43.080</a></span> | <span class="t">And so their solution was to have a leaderboard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2926" target="_blank">00:48:46.320</a></span> | <span class="t">called LifeCodeBench, where they regularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2930" target="_blank">00:48:50.480</a></span> | <span class="t">scrape new problems from platforms like code contests</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2935" target="_blank">00:48:55.640</a></span> | <span class="t">and least code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2936" target="_blank">00:48:56.680</a></span> | <span class="t">And they evaluate the models only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2938" target="_blank">00:48:58.680</a></span> | <span class="t">on the problems that were released after the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2941" target="_blank">00:49:01.840</a></span> | <span class="t">release date.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2942" target="_blank">00:49:02.840</a></span> | <span class="t">This way, they are sure that there is no contamination.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2947" target="_blank">00:49:07.040</a></span> | <span class="t">And for example, that was the case here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2949" target="_blank">00:49:09.080</a></span> | <span class="t">They tried to evaluate these models on all the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2952" target="_blank">00:49:12.640</a></span> | <span class="t">they have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2953" target="_blank">00:49:13.320</a></span> | <span class="t">And then they compared the performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2955" target="_blank">00:49:15.240</a></span> | <span class="t">to the data that was only released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2957" target="_blank">00:49:17.720</a></span> | <span class="t">after the model release.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2958" target="_blank">00:49:18.960</a></span> | <span class="t">And they found that some models were not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2961" target="_blank">00:49:21.000</a></span> | <span class="t">consistent in their results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2964" target="_blank">00:49:24.240</a></span> | <span class="t">So that's one interesting thing to keep in mind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2967" target="_blank">00:49:27.120</a></span> | <span class="t">And this is also another leaderboard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2971" target="_blank">00:49:31.000</a></span> | <span class="t">that's going to be interesting to compare, not just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2973" target="_blank">00:49:33.320</a></span> | <span class="t">open models, but also closed models like GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2976" target="_blank">00:49:36.640</a></span> | <span class="t">and see where the open source community is standing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2979" target="_blank">00:49:39.320</a></span> | <span class="t">and compare to these code models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2983" target="_blank">00:49:43.040</a></span> | <span class="t">So that was my presentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2984" target="_blank">00:49:44.640</a></span> | <span class="t">Thank you very much for your attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2987" target="_blank">00:49:47.320</a></span> | <span class="t">And if you have any questions, I can answer them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2992" target="_blank">00:49:52.080</a></span> | <span class="t">Yes, thank you very much for the great insightful talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2996" target="_blank">00:49:56.080</a></span> | <span class="t">So we have some questions here on Slido.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=2998" target="_blank">00:49:58.840</a></span> | <span class="t">I'm not sure if there are any in-person questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3001" target="_blank">00:50:01.880</a></span> | <span class="t">or else I will get started with the Slido question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3005" target="_blank">00:50:05.600</a></span> | <span class="t">Sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3011" target="_blank">00:50:11.880</a></span> | <span class="t">OK, I guess not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3012" target="_blank">00:50:12.720</a></span> | <span class="t">So I'll ask some of the questions online.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3016" target="_blank">00:50:16.640</a></span> | <span class="t">I think I had submitted some of these as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3020" target="_blank">00:50:20.200</a></span> | <span class="t">It seems like there's some questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3022" target="_blank">00:50:22.160</a></span> | <span class="t">about synthetic data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3023" target="_blank">00:50:23.240</a></span> | <span class="t">Let me see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3025" target="_blank">00:50:25.600</a></span> | <span class="t">I was also wondering about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3028" target="_blank">00:50:28.000</a></span> | <span class="t">So someone's asking, what are the consequences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3030" target="_blank">00:50:30.200</a></span> | <span class="t">of training AI models on AI-generated synthetic data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3035" target="_blank">00:50:35.280</a></span> | <span class="t">Do you foresee any problems with this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3037" target="_blank">00:50:37.920</a></span> | <span class="t">And there's a related question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3040" target="_blank">00:50:40.200</a></span> | <span class="t">Does synthetic data closely represent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3042" target="_blank">00:50:42.760</a></span> | <span class="t">the natural distribution of language?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3044" target="_blank">00:50:44.440</a></span> | <span class="t">I assume some low-quality data from humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3047" target="_blank">00:50:47.320</a></span> | <span class="t">is necessary for things like learning robustness</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3050" target="_blank">00:50:50.440</a></span> | <span class="t">and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3052" target="_blank">00:50:52.320</a></span> | <span class="t">Yeah, sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3053" target="_blank">00:50:53.080</a></span> | <span class="t">These are very great questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3055" target="_blank">00:50:55.360</a></span> | <span class="t">So about the consequences of training models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3058" target="_blank">00:50:58.720</a></span> | <span class="t">on AI-generated data, I can think of two main ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3062" target="_blank">00:51:02.040</a></span> | <span class="t">First is enforcing some biases, because models already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3066" target="_blank">00:51:06.360</a></span> | <span class="t">have some biases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3067" target="_blank">00:51:07.400</a></span> | <span class="t">And if we train on data that is generated by them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3069" target="_blank">00:51:09.920</a></span> | <span class="t">we might be enforcing it even more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3072" target="_blank">00:51:12.560</a></span> | <span class="t">The other thing is, for example, contamination.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3075" target="_blank">00:51:15.680</a></span> | <span class="t">These models might generate content</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3078" target="_blank">00:51:18.880</a></span> | <span class="t">that looks like the evaluation benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3080" target="_blank">00:51:20.840</a></span> | <span class="t">And when you train on that, you will have contamination</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3083" target="_blank">00:51:23.320</a></span> | <span class="t">in your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3084" target="_blank">00:51:24.560</a></span> | <span class="t">So for example, one of the critiques of the file model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3087" target="_blank">00:51:27.160</a></span> | <span class="t">is that people, because they did not see the synthetic data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3090" target="_blank">00:51:30.040</a></span> | <span class="t">and the models were very good on the benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3092" target="_blank">00:51:32.200</a></span> | <span class="t">they were very skeptical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3093" target="_blank">00:51:33.400</a></span> | <span class="t">Are these models really good, or are they just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3095" target="_blank">00:51:35.440</a></span> | <span class="t">overfitting on the benchmarks?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3097" target="_blank">00:51:37.640</a></span> | <span class="t">So I think contamination and enforcing biases</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3100" target="_blank">00:51:40.120</a></span> | <span class="t">are one of the main things to keep in mind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3103" target="_blank">00:51:43.800</a></span> | <span class="t">And regarding synthetic data not being the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3108" target="_blank">00:51:48.000</a></span> | <span class="t">as web distribution, I think that's a very good point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3112" target="_blank">00:51:52.400</a></span> | <span class="t">And for example, when we were developing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3114" target="_blank">00:51:54.480</a></span> | <span class="t">Cosmopedia, first we found that it was worse than the web.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3119" target="_blank">00:51:59.760</a></span> | <span class="t">And it was surprising, because we spent a lot of time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3123" target="_blank">00:52:03.040</a></span> | <span class="t">trying to curate this data set, which looks so much cleaner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3126" target="_blank">00:52:06.120</a></span> | <span class="t">than the web.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3127" target="_blank">00:52:07.000</a></span> | <span class="t">And then adding some web data and trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3129" target="_blank">00:52:09.120</a></span> | <span class="t">to add more topics was able to help us compensate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3133" target="_blank">00:52:13.400</a></span> | <span class="t">some of the gaps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3134" target="_blank">00:52:14.400</a></span> | <span class="t">But adding some web always gives you a performance boost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3137" target="_blank">00:52:17.880</a></span> | <span class="t">So yes, there is some noise and some specific patterns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3141" target="_blank">00:52:21.520</a></span> | <span class="t">in web data that will probably need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3143" target="_blank">00:52:23.800</a></span> | <span class="t">to be included in the training mix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3145" target="_blank">00:52:25.480</a></span> | <span class="t">to keep a whole coverage of what natural distributions look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3151" target="_blank">00:52:31.680</a></span> | <span class="t">like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3152" target="_blank">00:52:32.680</a></span> | <span class="t">So it sounds like you're saying a good training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3156" target="_blank">00:52:36.280</a></span> | <span class="t">set would have a mix, potentially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3158" target="_blank">00:52:38.320</a></span> | <span class="t">of synthetic and natural data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3160" target="_blank">00:52:40.400</a></span> | <span class="t">Is that correct?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3161" target="_blank">00:52:41.800</a></span> | <span class="t">Yeah, I think so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3163" target="_blank">00:52:43.200</a></span> | <span class="t">Some experiments we're on show that that's the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3166" target="_blank">00:52:46.800</a></span> | <span class="t">Because you can try to spend some time to carefully curate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3169" target="_blank">00:52:49.280</a></span> | <span class="t">the topics, but we'll probably be missing out on some things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3173" target="_blank">00:52:53.200</a></span> | <span class="t">And the human intuition that we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3174" target="_blank">00:52:54.720</a></span> | <span class="t">is not always what works for training models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3177" target="_blank">00:52:57.440</a></span> | <span class="t">It seems that keeping some filtered web helps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3180" target="_blank">00:53:00.080</a></span> | <span class="t">And also, if you see the Phi technical reports,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3182" target="_blank">00:53:02.520</a></span> | <span class="t">for example, in Phi 3, they insist a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3184" target="_blank">00:53:04.840</a></span> | <span class="t">on filtering the web and including it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3186" target="_blank">00:53:06.480</a></span> | <span class="t">in the pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3187" target="_blank">00:53:07.680</a></span> | <span class="t">And I think that now seems like maybe the best way to go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3193" target="_blank">00:53:13.640</a></span> | <span class="t">That makes sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3194" target="_blank">00:53:14.320</a></span> | <span class="t">Great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3195" target="_blank">00:53:15.640</a></span> | <span class="t">Another question is, is RLHF-type preference data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3199" target="_blank">00:53:19.480</a></span> | <span class="t">more important than unsupervised pre-training data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3202" target="_blank">00:53:22.200</a></span> | <span class="t">Should we spend more resources on RLHF data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3207" target="_blank">00:53:27.520</a></span> | <span class="t">Yeah, that's a good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3208" target="_blank">00:53:28.960</a></span> | <span class="t">So for example, the unsupervised pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3211" target="_blank">00:53:31.880</a></span> | <span class="t">is mainly to get base models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3213" target="_blank">00:53:33.760</a></span> | <span class="t">But then you can't use these base models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3215" target="_blank">00:53:35.800</a></span> | <span class="t">as chart assistance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3216" target="_blank">00:53:36.960</a></span> | <span class="t">You need to do another step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3218" target="_blank">00:53:38.720</a></span> | <span class="t">So you can either do RLHF.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3220" target="_blank">00:53:40.800</a></span> | <span class="t">But nowadays, people are just doing instruction tuning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3224" target="_blank">00:53:44.080</a></span> | <span class="t">without needing to go through RL, where you just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3227" target="_blank">00:53:47.120</a></span> | <span class="t">train the model on pairs of instructions and solutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3229" target="_blank">00:53:49.880</a></span> | <span class="t">And that seems to work very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3231" target="_blank">00:53:51.400</a></span> | <span class="t">And there are now some methods that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3233" target="_blank">00:53:53.080</a></span> | <span class="t">don't use reinforcement learning but work as well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3236" target="_blank">00:53:56.200</a></span> | <span class="t">for example, DPO or ORPO.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3238" target="_blank">00:53:58.440</a></span> | <span class="t">So I think if you want to chart assistance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3240" target="_blank">00:54:00.560</a></span> | <span class="t">you definitely need to run a supervised training on top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3244" target="_blank">00:54:04.240</a></span> | <span class="t">of the unsupervised one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3245" target="_blank">00:54:05.960</a></span> | <span class="t">But it doesn't necessarily have to be RLHF.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3248" target="_blank">00:54:08.480</a></span> | <span class="t">There are some other algorithms now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3251" target="_blank">00:54:11.520</a></span> | <span class="t">Great, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3252" target="_blank">00:54:12.240</a></span> | <span class="t">And here's a multimodal question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3255" target="_blank">00:54:15.200</a></span> | <span class="t">Does multimodal grounding, for example, including images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3258" target="_blank">00:54:18.400</a></span> | <span class="t">and videos along with the text, reduce the need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3261" target="_blank">00:54:21.360</a></span> | <span class="t">for so much text-only data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3263" target="_blank">00:54:23.080</a></span> | <span class="t">Yeah, what do you mean?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3267" target="_blank">00:54:27.680</a></span> | <span class="t">I'm sorry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3269" target="_blank">00:54:29.120</a></span> | <span class="t">Oh, the question is asking, does multimodal grounding help?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3273" target="_blank">00:54:33.240</a></span> | <span class="t">If you have images and videos along with the text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3276" target="_blank">00:54:36.360</a></span> | <span class="t">does this reduce the amount of text-only data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3279" target="_blank">00:54:39.240</a></span> | <span class="t">required to train models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3282" target="_blank">00:54:42.640</a></span> | <span class="t">So I can't probably answer that because I haven't tried.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3285" target="_blank">00:54:45.400</a></span> | <span class="t">But I guess all, for example, the multimodal models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3288" target="_blank">00:54:48.600</a></span> | <span class="t">for example, edifix that were recently released,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3291" target="_blank">00:54:51.280</a></span> | <span class="t">there's always a significant text portion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3294" target="_blank">00:54:54.400</a></span> | <span class="t">That seems the case for most vision and language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3298" target="_blank">00:54:58.720</a></span> | <span class="t">But yeah, I don't know really about the percentages for each.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3302" target="_blank">00:55:02.760</a></span> | <span class="t">Right, OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3303" target="_blank">00:55:03.560</a></span> | <span class="t">A more general question-- you probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3307" target="_blank">00:55:07.600</a></span> | <span class="t">touched upon some of this-- but are there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3309" target="_blank">00:55:09.440</a></span> | <span class="t">any major differences between training text versus code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3313" target="_blank">00:55:13.360</a></span> | <span class="t">models, other than the training data being different?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3317" target="_blank">00:55:17.960</a></span> | <span class="t">Yes, that's a good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3319" target="_blank">00:55:19.280</a></span> | <span class="t">So the training data is different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3321" target="_blank">00:55:21.080</a></span> | <span class="t">Regarding the training itself, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3324" target="_blank">00:55:24.080</a></span> | <span class="t">use a similar architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3325" target="_blank">00:55:25.520</a></span> | <span class="t">For example, Starcoder, it was like a LAMA or a MISRA</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3328" target="_blank">00:55:28.880</a></span> | <span class="t">architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3329" target="_blank">00:55:29.920</a></span> | <span class="t">I think one thing that you probably want is long context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3333" target="_blank">00:55:33.720</a></span> | <span class="t">Because if you want to use these models, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3336" target="_blank">00:55:36.280</a></span> | <span class="t">in VS Code and you want to add all the neighboring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3338" target="_blank">00:55:38.600</a></span> | <span class="t">files in the context, you should be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3340" target="_blank">00:55:40.360</a></span> | <span class="t">able to fit a very large context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3342" target="_blank">00:55:42.720</a></span> | <span class="t">So we try to do some long context extension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3345" target="_blank">00:55:45.960</a></span> | <span class="t">But again, people also do this for LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3349" target="_blank">00:55:49.440</a></span> | <span class="t">We also care a lot about inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3351" target="_blank">00:55:51.280</a></span> | <span class="t">So we use the first MQA and then GQA to have faster inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3356" target="_blank">00:55:56.360</a></span> | <span class="t">But these are also techniques that are implemented for LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3359" target="_blank">00:55:59.880</a></span> | <span class="t">So I'd say overall, it's very similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3362" target="_blank">00:56:02.280</a></span> | <span class="t">But yeah, maybe you should prioritize some things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3364" target="_blank">00:56:04.840</a></span> | <span class="t">like having a smaller model that can be used for, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3370" target="_blank">00:56:10.120</a></span> | <span class="t">IDEs faster than actually a much larger model that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3373" target="_blank">00:56:13.000</a></span> | <span class="t">would need more deployment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3375" target="_blank">00:56:15.400</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3376" target="_blank">00:56:16.480</a></span> | <span class="t">All right, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3377" target="_blank">00:56:17.200</a></span> | <span class="t">And here's also a general question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3379" target="_blank">00:56:19.280</a></span> | <span class="t">I guess they're asking for advice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3381" target="_blank">00:56:21.760</a></span> | <span class="t">So if you have a very tiny compute budget, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3384" target="_blank">00:56:24.640</a></span> | <span class="t">a single GPU, what would you recommend prioritizing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3389" target="_blank">00:56:29.200</a></span> | <span class="t">Let's assume you're fine tuning a model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3392" target="_blank">00:56:32.880</a></span> | <span class="t">Yeah, so I think, for example, now there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3395" target="_blank">00:56:35.480</a></span> | <span class="t">are some great solutions for on-device deployment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3399" target="_blank">00:56:39.680</a></span> | <span class="t">and fine tunings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3402" target="_blank">00:56:42.000</a></span> | <span class="t">For example, you can run quantized models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3404" target="_blank">00:56:44.440</a></span> | <span class="t">with LLAMA, CPP, or other frameworks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3407" target="_blank">00:56:47.000</a></span> | <span class="t">And with techniques like PEFT, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3409" target="_blank">00:56:49.960</a></span> | <span class="t">don't need to do full model fine tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3412" target="_blank">00:56:52.040</a></span> | <span class="t">And you should be able to run this on one GPU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3414" target="_blank">00:56:54.480</a></span> | <span class="t">even in a 7B model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3416" target="_blank">00:56:56.480</a></span> | <span class="t">So I think you should just find a very well-curated data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3419" target="_blank">00:56:59.360</a></span> | <span class="t">set because quality is more important than quantity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3422" target="_blank">00:57:02.600</a></span> | <span class="t">And then use one of these techniques for easy fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3425" target="_blank">00:57:05.280</a></span> | <span class="t">tuning, and that should work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3429" target="_blank">00:57:09.560</a></span> | <span class="t">All right, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3430" target="_blank">00:57:10.320</a></span> | <span class="t">Here's a question asking--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3434" target="_blank">00:57:14.400</a></span> | <span class="t">I guess, different from pre-training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3436" target="_blank">00:57:16.600</a></span> | <span class="t">but they're saying, I'm guessing the optimal amount of training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3441" target="_blank">00:57:21.120</a></span> | <span class="t">data depends heavily on the domain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3443" target="_blank">00:57:23.080</a></span> | <span class="t">as well as the task at hand, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3447" target="_blank">00:57:27.320</a></span> | <span class="t">Yes, probably.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3449" target="_blank">00:57:29.000</a></span> | <span class="t">Now, we're following the exchange scaling laws.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3451" target="_blank">00:57:31.880</a></span> | <span class="t">I think they tried to compare English to code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3455" target="_blank">00:57:35.200</a></span> | <span class="t">and they found that the findings still hold.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3458" target="_blank">00:57:38.240</a></span> | <span class="t">But maybe if you go to another domain,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3459" target="_blank">00:57:39.920</a></span> | <span class="t">I don't know, like medical, things could change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3462" target="_blank">00:57:42.160</a></span> | <span class="t">And that's why I mentioned the DeepSeq paper, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3464" target="_blank">00:57:44.240</a></span> | <span class="t">they mentioned that it's really heavily dependent on data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3467" target="_blank">00:57:47.280</a></span> | <span class="t">And for them, it was the same domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3468" target="_blank">00:57:48.880</a></span> | <span class="t">They just changed data sets, like going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3471" target="_blank">00:57:51.040</a></span> | <span class="t">from one generic data set to another well-curated one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3474" target="_blank">00:57:54.200</a></span> | <span class="t">And things started changing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3476" target="_blank">00:57:56.040</a></span> | <span class="t">So I think that's probably the case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3478" target="_blank">00:57:58.440</a></span> | <span class="t">but it's underexplored how these scaling laws change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3481" target="_blank">00:58:01.920</a></span> | <span class="t">depending on domains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3483" target="_blank">00:58:03.400</a></span> | <span class="t">So it's good to be aware of that when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3485" target="_blank">00:58:05.080</a></span> | <span class="t">developing models for domains that are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3487" target="_blank">00:58:07.640</a></span> | <span class="t">explored by these--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3488" target="_blank">00:58:08.800</a></span> | <span class="t">Speaking of different domains, code versus text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3491" target="_blank">00:58:11.080</a></span> | <span class="t">someone's asking, what are some of the interesting differences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3494" target="_blank">00:58:14.240</a></span> | <span class="t">between tokenizing for general purpose,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3498" target="_blank">00:58:18.920</a></span> | <span class="t">like text, versus for code generation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3503" target="_blank">00:58:23.200</a></span> | <span class="t">Yeah, so when we were training the tokenizer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3507" target="_blank">00:58:27.240</a></span> | <span class="t">I think one thing that was important to keep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3509" target="_blank">00:58:29.040</a></span> | <span class="t">was number splitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3511" target="_blank">00:58:31.520</a></span> | <span class="t">And we used the standard BPE.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3513" target="_blank">00:58:33.880</a></span> | <span class="t">And we were training it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3515" target="_blank">00:58:35.080</a></span> | <span class="t">We trained on our data set that we were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3517" target="_blank">00:58:37.720</a></span> | <span class="t">using for the training data, so our code mixture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3521" target="_blank">00:58:41.480</a></span> | <span class="t">And we did some analysis to see if there are any outliers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3524" target="_blank">00:58:44.640</a></span> | <span class="t">any tokens that were underrepresented or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3528" target="_blank">00:58:48.480</a></span> | <span class="t">overrepresented as sanity checks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3530" target="_blank">00:58:50.920</a></span> | <span class="t">But overall, it's very close to the text training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3537" target="_blank">00:58:57.120</a></span> | <span class="t">And now most LLMs have a significant code portion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3540" target="_blank">00:59:00.920</a></span> | <span class="t">in their tokenizers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3542" target="_blank">00:59:02.440</a></span> | <span class="t">So they're also trained on a lot of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3544" target="_blank">00:59:04.520</a></span> | <span class="t">And at the end, you can use either one tokenizer for LLMs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3548" target="_blank">00:59:08.640</a></span> | <span class="t">or code, or the other way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3551" target="_blank">00:59:11.080</a></span> | <span class="t">Because even on code, you have a lot of markdowns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3553" target="_blank">00:59:13.240</a></span> | <span class="t">So there's a lot of English.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3554" target="_blank">00:59:14.600</a></span> | <span class="t">So you end up representing all the English tokens, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3557" target="_blank">00:59:17.640</a></span> | <span class="t">in your code tokenizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3560" target="_blank">00:59:20.760</a></span> | <span class="t">I agree.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3561" target="_blank">00:59:21.280</a></span> | <span class="t">And here's the question about fine tuning, I guess,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3563" target="_blank">00:59:23.480</a></span> | <span class="t">compared to pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3564" target="_blank">00:59:24.520</a></span> | <span class="t">So they're asking, do the same principles</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3567" target="_blank">00:59:27.520</a></span> | <span class="t">apply for fine tuning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3570" target="_blank">00:59:30.320</a></span> | <span class="t">Or do you make a different or additional recommendation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3573" target="_blank">00:59:33.320</a></span> | <span class="t">So yeah, for fine tuning, I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3579" target="_blank">00:59:39.160</a></span> | <span class="t">when you're preparing the data, it's probably a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3581" target="_blank">00:59:41.880</a></span> | <span class="t">thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3582" target="_blank">00:59:42.400</a></span> | <span class="t">You're not going to train on all of the stack.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3584" target="_blank">00:59:44.960</a></span> | <span class="t">You probably want to continue training on specific language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3588" target="_blank">00:59:48.360</a></span> | <span class="t">So maybe you could invest more time to even heavily filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3591" target="_blank">00:59:51.360</a></span> | <span class="t">Because for fine tuning, you don't need as much data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3593" target="_blank">00:59:53.560</a></span> | <span class="t">as for pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3595" target="_blank">00:59:55.040</a></span> | <span class="t">For example, for us, the filtering we tried,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3597" target="_blank">00:59:57.080</a></span> | <span class="t">for example, started to work because they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3598" target="_blank">00:59:58.920</a></span> | <span class="t">removed a lot of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3599" target="_blank">00:59:59.880</a></span> | <span class="t">And we did not have enough for our pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3602" target="_blank">01:00:02.040</a></span> | <span class="t">While for fine tuning, for example, for instruction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3604" target="_blank">01:00:04.280</a></span> | <span class="t">tuning, there was the Lima paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3606" target="_blank">01:00:06.400</a></span> | <span class="t">where the instruction tuned only on 1,000 instructions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3608" target="_blank">01:00:08.920</a></span> | <span class="t">And they had a model that was much better than training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3611" target="_blank">01:00:11.200</a></span> | <span class="t">on millions of samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3612" target="_blank">01:00:12.760</a></span> | <span class="t">So I think data curation is even much more important when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3615" target="_blank">01:00:15.680</a></span> | <span class="t">it comes to fine tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3618" target="_blank">01:00:18.960</a></span> | <span class="t">Great, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3619" target="_blank">01:00:19.600</a></span> | <span class="t">One last question, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3622" target="_blank">01:00:22.560</a></span> | <span class="t">So you might have also touched upon this briefly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3624" target="_blank">01:00:24.800</a></span> | <span class="t">But what are some considerations to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3627" target="_blank">01:00:27.040</a></span> | <span class="t">when publishing very large data sets and more nuanced or less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3631" target="_blank">01:00:31.360</a></span> | <span class="t">known things to be aware of?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3635" target="_blank">01:00:35.200</a></span> | <span class="t">Yeah, so maybe on the technical side,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3640" target="_blank">01:00:40.880</a></span> | <span class="t">really using tools also for filtering and documentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3644" target="_blank">01:00:44.600</a></span> | <span class="t">That is what we try to do with the stack.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3646" target="_blank">01:00:46.680</a></span> | <span class="t">And maybe more on the governance side,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3649" target="_blank">01:00:49.760</a></span> | <span class="t">be aware of where the licenses are respected,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3653" target="_blank">01:00:53.000</a></span> | <span class="t">where the copyrights are respected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3654" target="_blank">01:00:54.480</a></span> | <span class="t">Do you have an opt-out tool for your data set?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3656" target="_blank">01:00:56.840</a></span> | <span class="t">And maybe try to release it on the hub</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3659" target="_blank">01:00:59.360</a></span> | <span class="t">to make it easily accessible for people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3661" target="_blank">01:01:01.680</a></span> | <span class="t">If there are some concerns, you could try to add a gate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3664" target="_blank">01:01:04.200</a></span> | <span class="t">For example, for us, we released the data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3666" target="_blank">01:01:06.200</a></span> | <span class="t">that we used for PII detection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3668" target="_blank">01:01:08.240</a></span> | <span class="t">But we add some gating mechanism because it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3670" target="_blank">01:01:10.280</a></span> | <span class="t">was sensitive information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3672" target="_blank">01:01:12.120</a></span> | <span class="t">So it's good to think of these kind of things in advance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3675" target="_blank">01:01:15.040</a></span> | <span class="t">before releasing a data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3677" target="_blank">01:01:17.640</a></span> | <span class="t">But yeah, in general, these are my advice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3679" target="_blank">01:01:19.480</a></span> | <span class="t">All right, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3684" target="_blank">01:01:24.000</a></span> | <span class="t">Do we have any in-person questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3687" target="_blank">01:01:27.400</a></span> | <span class="t">If not, then we can probably conclude.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3690" target="_blank">01:01:30.800</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=jm2hyJLFfN8&t=3692" target="_blank">01:01:32.360</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>