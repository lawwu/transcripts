<html><head><title>[Paper Club] Writing in the Margins: Chunked Prefill KV Caching for Long Context Retrieval</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>[Paper Club] Writing in the Margins: Chunked Prefill KV Caching for Long Context Retrieval</h2><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4"><img src="https://i.ytimg.com/vi/VHwrhL_MSV4/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./VHwrhL_MSV4.html">Whisper Transcript</a> | <a href="./transcript_VHwrhL_MSV4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">it's recorded but tl;dr probably just shared internal so sam we'll we'll get you recording</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=6" target="_blank">00:00:06.240</a></span> | <span class="t">after cool i'm i'm gonna pass off to you guys whenever you want to start i'm sure people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=16" target="_blank">00:00:16.080</a></span> | <span class="t">trickle in so from writer side i would be presenting i don't know if you guys can hear me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=23" target="_blank">00:00:23.840</a></span> | <span class="t">yep all right uh there should be also a sim i don't know if he's also present but i will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=30" target="_blank">00:00:30.480</a></span> | <span class="t">kick off the presentation let me know whenever you everyone is ready and i will start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=35" target="_blank">00:00:35.920</a></span> | <span class="t">i think we're good take it away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=42" target="_blank">00:00:42.480</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=46" target="_blank">00:00:46.640</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=56" target="_blank">00:00:56.240</a></span> | <span class="t">okay i will start by sharing my screen meanwhile let's see if it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=67" target="_blank">00:01:07.120</a></span> | <span class="t">desktop 2 and let me know if you can see my screen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=73" target="_blank">00:01:13.840</a></span> | <span class="t">yep we can see your slides all right perfect so tonight uh can i start right everyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=87" target="_blank">00:01:27.600</a></span> | <span class="t">yeah you should be good it's recording people might trickle in every now and then but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=92" target="_blank">00:01:32.800</a></span> | <span class="t">all right so tonight i will be presenting a paper that came out from writer writing in the margins</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=100" target="_blank">00:01:40.240</a></span> | <span class="t">to uh writing in the margins better inference pattern for long context retrieval</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=104" target="_blank">00:01:44.720</a></span> | <span class="t">it's a paper that involves a long context and how we leverage the kv cache to make a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=113" target="_blank">00:01:53.040</a></span> | <span class="t">long context modeling more effective so i will uh i will do a very little technical but not so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=122" target="_blank">00:02:02.800</a></span> | <span class="t">technical presentation and later we can deep dive into the details of the paper so let me open the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=128" target="_blank">00:02:08.800</a></span> | <span class="t">chat so i can see what everyone is writing meanwhile i'm while i'm talking oh yeah i think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=136" target="_blank">00:02:16.000</a></span> | <span class="t">i think you can just ignore the chat people are gonna be it's gonna be really buzzy and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=140" target="_blank">00:02:20.560</a></span> | <span class="t">there's gonna be a lot of people like oh wow that's so cool everything yeah vibhu and i will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=144" target="_blank">00:02:24.800</a></span> | <span class="t">take care of the chat for you perfect something super crazy pops up we'll let you know otherwise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=149" target="_blank">00:02:29.360</a></span> | <span class="t">we'll we'll take care of it all right perfect all right so i will skip the part of what is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=154" target="_blank">00:02:34.320</a></span> | <span class="t">a language model but okay the language model is a probabilistic model and that leverages the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=159" target="_blank">00:02:39.040</a></span> | <span class="t">to generate what is the next token and how we generate text to the language model we do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=162" target="_blank">00:02:42.560</a></span> | <span class="t">iteratively so one token at a time most of the language models nowadays are based on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=169" target="_blank">00:02:49.360</a></span> | <span class="t">transformer model and in the transformer model basically whenever we have a prompt the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=175" target="_blank">00:02:55.120</a></span> | <span class="t">thing that we do is we put this prompt into the memory of the language model that is known as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=179" target="_blank">00:02:59.760</a></span> | <span class="t">the kv cache which is basically the keys and values in these transformer layers and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=187" target="_blank">00:03:07.360</a></span> | <span class="t">operation of creating this initial kv cache is known as prefilling so the first thing that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=193" target="_blank">00:03:13.680</a></span> | <span class="t">inference engine which could be vllm which could be tesserati or any other inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=198" target="_blank">00:03:18.160</a></span> | <span class="t">framework that you're using the first thing that it does with your prompt is doing this prefilling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=205" target="_blank">00:03:25.200</a></span> | <span class="t">and if you're interested actually the prefilling is one of the most expensive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=209" target="_blank">00:03:29.040</a></span> | <span class="t">part of the language of processing a prompt because it has a quadratic cost with respect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=213" target="_blank">00:03:33.840</a></span> | <span class="t">to the computations as well in the with respect to the memory so imagine that we have a prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=219" target="_blank">00:03:39.360</a></span> | <span class="t">called austin is a city in a prompt that says austin is a city in then the first thing that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=225" target="_blank">00:03:45.600</a></span> | <span class="t">we do to generate text with this prompt is we prefill it into the language model in the kv cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=231" target="_blank">00:03:51.280</a></span> | <span class="t">and then we leverage it to generate tokens one token at a time and the kv cache is a this kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=238" target="_blank">00:03:58.160</a></span> | <span class="t">of memory in the language model uh in any actually transformer model that is autoregressive that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=244" target="_blank">00:04:04.160</a></span> | <span class="t">that if it contains some tokens then the language model will leverage them if it doesn't contain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=250" target="_blank">00:04:10.160</a></span> | <span class="t">those tokens then the language model cannot leverage them so the language model only sees</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=254" target="_blank">00:04:14.480</a></span> | <span class="t">what is inside of the kv cache so what happens is over prompt austin is a city in the first thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=259" target="_blank">00:04:19.280</a></span> | <span class="t">that we do is we do this prefilling which puts these tokens into the kv cache which is one for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=265" target="_blank">00:04:25.600</a></span> | <span class="t">each layer of the transformer and then we generate what is the next token by asking the language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=271" target="_blank">00:04:31.120</a></span> | <span class="t">model what is the next token and suppose the next token is the word texas we take this token texas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=277" target="_blank">00:04:37.200</a></span> | <span class="t">we keep it in the kv cache so that the language model can leverage to generate the next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=282" target="_blank">00:04:42.080</a></span> | <span class="t">and suppose the next token is a comma etc etc until we generate the the entire response of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=287" target="_blank">00:04:47.680</a></span> | <span class="t">the language model now we have seen that in the past few years prompts are becoming longer and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=293" target="_blank">00:04:53.840</a></span> | <span class="t">longer so we started with 2000 context window to 4000 8000 32 60 or 100 and now we have reached</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=301" target="_blank">00:05:01.840</a></span> | <span class="t">millions of tokens um this means that you can send to an entire book to the language model and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=308" target="_blank">00:05:08.880</a></span> | <span class="t">you can ask the language model questions about this book however with the great prompts comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=314" target="_blank">00:05:14.400</a></span> | <span class="t">great responsibility and the the reason is uh the following so imagine you have a very long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=321" target="_blank">00:05:21.520</a></span> | <span class="t">prompt suppose that you have a book and you want the language model to answer questions about this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=326" target="_blank">00:05:26.720</a></span> | <span class="t">book suppose that this book is like 1 million tokens longer if you do the prefilling of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=334" target="_blank">00:05:34.400</a></span> | <span class="t">1 million tokens prompt in in the kv cache the language model will actually not be able to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=342" target="_blank">00:05:42.320</a></span> | <span class="t">that because as i as i said before the prefilling is one of the most expensive operations that we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=348" target="_blank">00:05:48.080</a></span> | <span class="t">uh when inferencing language models uh why because it's quadratic with respect to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=353" target="_blank">00:05:53.360</a></span> | <span class="t">sequence length in terms of memory and also in terms of compute so uh language models actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=358" target="_blank">00:05:58.560</a></span> | <span class="t">cannot prefill the entire prompt in one single pass in the in the kv cache so what they do is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=365" target="_blank">00:06:05.200</a></span> | <span class="t">they do it by chunks this is called the chunked profile and it's an experimental feature that has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=370" target="_blank">00:06:10.240</a></span> | <span class="t">been recently introduced in vllm but it's probably used in more sophisticated inference engines at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=376" target="_blank">00:06:16.800</a></span> | <span class="t">major companies so what we do by with the chunks prefilling basically we split the prompt of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=387" target="_blank">00:06:27.200</a></span> | <span class="t">user into multiple chunks and we prefill each chunk step by step so suppose that the user sent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=393" target="_blank">00:06:33.440</a></span> | <span class="t">an entire book which is made up of 10 chapters now the chunk usually they are of a fixed size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=399" target="_blank">00:06:39.920</a></span> | <span class="t">this doesn't mean that the the chunk has some contextual meaning it may not be the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=404" target="_blank">00:06:44.720</a></span> | <span class="t">chapter of the book or the second chapter of the book it could be just be the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=409" target="_blank">00:06:49.040</a></span> | <span class="t">4000 tokens of the prompt and then the next 4000 tokens of the prompt so we prefilled the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=415" target="_blank">00:06:55.280</a></span> | <span class="t">chunk into the kv cache then we prefilled the second chunk in the kv cache so now the kv cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=420" target="_blank">00:07:00.480</a></span> | <span class="t">contains the first chunk and the second chunk then the third chunk etc etc until all the prompt is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=425" target="_blank">00:07:05.680</a></span> | <span class="t">inside of the kv cache which can then be leveraged to generate tokens there this is intuitively very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=432" target="_blank">00:07:12.720</a></span> | <span class="t">similar to how a student would read a book for example imagine a student is given a book to read</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=438" target="_blank">00:07:18.640</a></span> | <span class="t">and then to answer questions a question about this book what the student would do with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=445" target="_blank">00:07:25.760</a></span> | <span class="t">students would read the first chapter and now the brain of the student contains information about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=449" target="_blank">00:07:29.920</a></span> | <span class="t">only the first chapter then the student would read the second chapter and now the brain of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=453" target="_blank">00:07:33.840</a></span> | <span class="t">the student contains information about the first chapter and the second chapter of the book and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=457" target="_blank">00:07:37.680</a></span> | <span class="t">then etc etc until the student reads the last chapter now the brain of the student contains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=462" target="_blank">00:07:42.080</a></span> | <span class="t">information about all the chapters and then we the student will be given the question and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=469" target="_blank">00:07:49.520</a></span> | <span class="t">question and then the student has to leverage the information that he has read from the book to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=475" target="_blank">00:07:55.520</a></span> | <span class="t">answer this question however the student would struggle to do it why because intuitively when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=480" target="_blank">00:08:00.960</a></span> | <span class="t">you read a book the the moment you start reading the second chapter you can have already forgetting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=486" target="_blank">00:08:06.240</a></span> | <span class="t">what is the first chapter about um so what is a better strategy that this could this student could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=494" target="_blank">00:08:14.640</a></span> | <span class="t">do well the student could read the chapters and while reading it could take some annotations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=501" target="_blank">00:08:21.040</a></span> | <span class="t">and this is what we do with writing in the margins so because for a very long prompt we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=507" target="_blank">00:08:27.760</a></span> | <span class="t">already forced to split the prompt into multiple chunks to do this chunked prefilled why not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=515" target="_blank">00:08:35.520</a></span> | <span class="t">leverage the partially prefilled kv cache to generate some annotations that can be then be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=522" target="_blank">00:08:42.080</a></span> | <span class="t">leveraged to improve the model's capability of extracting information from this prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=527" target="_blank">00:08:47.120</a></span> | <span class="t">so basically writing the margins and from a technical point of view works as follows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=534" target="_blank">00:08:54.160</a></span> | <span class="t">we have this very large prompt we split it into chunks because we are forced to split</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=538" target="_blank">00:08:58.800</a></span> | <span class="t">it into chunks we cannot prefer the entire context into the kv cache we prefer the first chunk and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=547" target="_blank">00:09:07.360</a></span> | <span class="t">then we add after the first chunk we add a prompt that tells the model okay use the text above to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=553" target="_blank">00:09:13.280</a></span> | <span class="t">instruct information about the query and the query is the question that we want to uh to get an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=558" target="_blank">00:09:18.800</a></span> | <span class="t">answer to so now the kv cache contains the first chunk and this prompt here and we leverage it to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=565" target="_blank">00:09:25.120</a></span> | <span class="t">generate a few tokens which is the this margin annotation and then this is another trick you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=571" target="_blank">00:09:31.200</a></span> | <span class="t">can delete stuff from the kv cache only from the end why you can do that because the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=578" target="_blank">00:09:38.720</a></span> | <span class="t">is an autoregressive language is an autoregressive model which means that every token depends on all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=585" target="_blank">00:09:45.040</a></span> | <span class="t">past tokens which means you can delete from stuff from the end and regenerate it eventually but you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=591" target="_blank">00:09:51.920</a></span> | <span class="t">cannot of course delete stuff from the beginning or from the middle because it would invalidate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=596" target="_blank">00:09:56.960</a></span> | <span class="t">all the future tokens but you can always remove stuff from the end so what we do is we prefer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=601" target="_blank">00:10:01.280</a></span> | <span class="t">the first part of prompt we prefer this instructive instruction we generate a few tokens which is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=608" target="_blank">00:10:08.640</a></span> | <span class="t">margin annotation then we can delete this margin and this instruction that we have added and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=614" target="_blank">00:10:14.720</a></span> | <span class="t">we prefer the second chunk we then append another prompt extractive prompt we generate a few more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=623" target="_blank">00:10:23.120</a></span> | <span class="t">tokens which is the second margin so the second margin will depend on the first and the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=627" target="_blank">00:10:27.680</a></span> | <span class="t">chunk then we delete this second margins tokens we delete the extractive prompt etc etc until</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=634" target="_blank">00:10:34.720</a></span> | <span class="t">we have processed all the prompt and this is a visualization that we have also put in the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=642" target="_blank">00:10:42.640</a></span> | <span class="t">so basically imagine you are given a very large prompt so what we do is we pre-fill the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=648" target="_blank">00:10:48.080</a></span> | <span class="t">part in the in the KVCache and then we extract the information on what is present in the KVCache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=654" target="_blank">00:10:54.160</a></span> | <span class="t">and we call it the first margin we then also can classify these margins and in the paper we also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=662" target="_blank">00:11:02.080</a></span> | <span class="t">show that actually the the computation and the pre-filling of the margins sorry the computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=668" target="_blank">00:11:08.000</a></span> | <span class="t">of the margin and the classification of the margin can be overlapped inside of the same request</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=672" target="_blank">00:11:12.560</a></span> | <span class="t">in the batch so you don't need to have another request in the batch but this is okay a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=677" target="_blank">00:11:17.200</a></span> | <span class="t">KVCache tricks for optimizing the inference so what do we do with these margins basically we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=683" target="_blank">00:11:23.360</a></span> | <span class="t">append them at the end before asking the question to the language model because our goal is okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=689" target="_blank">00:11:29.360</a></span> | <span class="t">we have this very big context and then we have some question so what we do instead of just asking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=694" target="_blank">00:11:34.400</a></span> | <span class="t">the question the model may not be able to find it so we generate these margins and then we append</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=698" target="_blank">00:11:38.960</a></span> | <span class="t">them right before asking the question and then we ask the model the question so now the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=703" target="_blank">00:11:43.200</a></span> | <span class="t">can also leverage these margins which are present right before the question to better answer the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=711" target="_blank">00:11:51.040</a></span> | <span class="t">question why these margins are why this margin will be leveraged by the language model first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=718" target="_blank">00:11:58.560</a></span> | <span class="t">of all because they are they are the instruction that we use to extract them is an extractive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=726" target="_blank">00:12:06.560</a></span> | <span class="t">summary so the we ask the language model to extract information or using the prefilled KVCache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=734" target="_blank">00:12:14.560</a></span> | <span class="t">on knowing what is the query so the margins are relevant to answer that particular query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=742" target="_blank">00:12:22.480</a></span> | <span class="t">why do we add these margins at the end before asking the question because a few months ago</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=748" target="_blank">00:12:28.960</a></span> | <span class="t">there was a paper called lost in the middle basically it says that and it's actually true</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=754" target="_blank">00:12:34.400</a></span> | <span class="t">basically it says that with the relevant information that we're trying to extract from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=759" target="_blank">00:12:39.200</a></span> | <span class="t">this prompt which could be very large is present either at the beginning or at the end of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=765" target="_blank">00:12:45.520</a></span> | <span class="t">prompt then the language model will very likely be able to will be very likely will be able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=770" target="_blank">00:12:50.240</a></span> | <span class="t">find it however this if this information is present kind of in the middle then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=774" target="_blank">00:12:54.720</a></span> | <span class="t">the language model will less likely be able to find it so that's why we add them to the end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=781" target="_blank">00:13:01.760</a></span> | <span class="t">so it improves the language model's ability to to leverage this information but does it even work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=788" target="_blank">00:13:08.880</a></span> | <span class="t">so yes we have proof and we have we show in the paper a comparison of pre-trained language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=795" target="_blank">00:13:15.520</a></span> | <span class="t">so first of all we are not fine-tuning any language model we are not changing anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=800" target="_blank">00:13:20.480</a></span> | <span class="t">this is just a different way of utilizing something that is already being done which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=805" target="_blank">00:13:25.440</a></span> | <span class="t">is the chunked prefill of the KVCache to improve a language model's ability to leverage long context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=811" target="_blank">00:13:31.680</a></span> | <span class="t">so it can be used with any transformer model without fine-tuning it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=815" target="_blank">00:13:35.920</a></span> | <span class="t">just by doing it just by doing this inference differently that is don't just blindly refill</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=822" target="_blank">00:13:42.240</a></span> | <span class="t">the KVCache but refill chunk by chunk because you are forced to and then leverage it to extract</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=827" target="_blank">00:13:47.040</a></span> | <span class="t">these margins and then leverage all these extracted margins at the end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=834" target="_blank">00:13:54.240</a></span> | <span class="t">what you are asking me to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=835" target="_blank">00:13:55.440</a></span> | <span class="t">I think someone had mic on I just made it accidental yeah go ahead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=844" target="_blank">00:14:04.800</a></span> | <span class="t">so yeah in the paper we have a proof that it helps the language model pre-trained language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=851" target="_blank">00:14:11.360</a></span> | <span class="t">models without any fine-tuning to better utilize long context and we provide a few benchmarks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=859" target="_blank">00:14:19.920</a></span> | <span class="t">as you can see for example smaller models have a better more improvement so here we have a for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=868" target="_blank">00:14:28.240</a></span> | <span class="t">example long context so the generic pattern that we use for long context so just the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=873" target="_blank">00:14:33.440</a></span> | <span class="t">context and the question whatever the benchmark is then we have a reg which means basically that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=880" target="_blank">00:14:40.640</a></span> | <span class="t">extract instead of giving the entire context plus the margins and then the question we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=889" target="_blank">00:14:49.840</a></span> | <span class="t">basically extracting each of the chunks separately asking the language model which one of them is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=896" target="_blank">00:14:56.720</a></span> | <span class="t">relevant and then only providing the relevant ones which is what we would do in reg</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=903" target="_blank">00:15:03.040</a></span> | <span class="t">and then asking the language model to leverage only the relevant ones at the end or the writing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=911" target="_blank">00:15:11.120</a></span> | <span class="t">in the margins approach which is all the context plus the margins that were extracted during this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=917" target="_blank">00:15:17.920</a></span> | <span class="t">chunked prefill and then the question at the end now how is this different from a prompting strategy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=926" target="_blank">00:15:26.480</a></span> | <span class="t">because you may be thinking okay but we can already take a very large prompt split it into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=932" target="_blank">00:15:32.080</a></span> | <span class="t">chunks and then use the language model to kind of summarize each of this chunk independently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=938" target="_blank">00:15:38.800</a></span> | <span class="t">and then send it to the language model again to answer the question well it's a matter of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=945" target="_blank">00:15:45.120</a></span> | <span class="t">cost so let's talk about cost imagine that we want we have this very big book made up of 10 chapters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=953" target="_blank">00:15:53.920</a></span> | <span class="t">and then we have a question at the end that we want to get an answer to which is what is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=958" target="_blank">00:15:58.480</a></span> | <span class="t">answer to like the universe and everything now what uh writing in the margins would do is would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=964" target="_blank">00:16:04.160</a></span> | <span class="t">prefill the if you don't use writing in the margins what you would do is you would feed the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=970" target="_blank">00:16:10.640</a></span> | <span class="t">first chapter of the book and then extract some margin with that actually let me show you this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=975" target="_blank">00:16:15.120</a></span> | <span class="t">other slide then you would take the second chapter of the book and then extract the margin with that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=980" target="_blank">00:16:20.240</a></span> | <span class="t">then the third chapter of the book and extract the margin with that etc etc suppose that each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=984" target="_blank">00:16:24.560</a></span> | <span class="t">of this chapter is 100 000 tokens then the cost to generate the margins and suppose that the margins</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=990" target="_blank">00:16:30.800</a></span> | <span class="t">are really small it's more or less 1 million tokens because 100 000 tokens multiplied by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=995" target="_blank">00:16:35.680</a></span> | <span class="t">10 chapters is around 1 million tokens but then then you need to also send the entire book past</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1001" target="_blank">00:16:41.280</a></span> | <span class="t">these extracted margins again to the language model to um to to generate the answer and it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1008" target="_blank">00:16:48.400</a></span> | <span class="t">would cost you another million because the model has to reprocess this prefilling again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1012" target="_blank">00:16:52.560</a></span> | <span class="t">of 1 million tokens so it would cost you 2 million tokens but with writing in the margins it would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1018" target="_blank">00:16:58.400</a></span> | <span class="t">cost you a for 1 million prompt more or less it would cost you 1 million tokens because you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1023" target="_blank">00:17:03.440</a></span> | <span class="t">have to re-prefill the uh the entire context because you are you have already prefilled it so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1030" target="_blank">00:17:10.640</a></span> | <span class="t">the the kvcache is growing and you're extracting some information and then you don't have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1035" target="_blank">00:17:15.600</a></span> | <span class="t">repopulate it which is what you would do if you treat each chunk independently and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1044" target="_blank">00:17:24.560</a></span> | <span class="t">do kind of like a let's say the chunking that we commonly do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1049" target="_blank">00:17:29.840</a></span> | <span class="t">so what are the advantages well it's compatible with any transformer model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1055" target="_blank">00:17:35.600</a></span> | <span class="t">there are other advantages that i want to show you in a video that i made so let me show this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1062" target="_blank">00:17:42.320</a></span> | <span class="t">is on my linkedin post i don't know if you can see now again my my screen right it's a yeah</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1068" target="_blank">00:17:48.880</a></span> | <span class="t">looks good we see the linkedin video perfect okay so we have a large document suppose 1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1074" target="_blank">00:17:54.560</a></span> | <span class="t">million tokens and then we have a question like how many employees were hired in 2006</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1078" target="_blank">00:17:58.560</a></span> | <span class="t">now when we have a very large prompt it must be prefilled in the kvcache by chunks and this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1086" target="_blank">00:18:06.720</a></span> | <span class="t">operation is called the chunks prefill so what happens with chunk prefill is that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1092" target="_blank">00:18:12.720</a></span> | <span class="t">take the first chunk and you prefill it in the kvcache then what we do is we add to the kvcache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1100" target="_blank">00:18:20.160</a></span> | <span class="t">this extractive summary prompt which is for example use the text above to extract information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1104" target="_blank">00:18:24.800</a></span> | <span class="t">about the following query how many employees were hired in 2006 and then we generate tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1110" target="_blank">00:18:30.960</a></span> | <span class="t">using whatever is inside of the kvcache which is the first chunk plus this instructive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1116" target="_blank">00:18:36.160</a></span> | <span class="t">extractive sum prompt and suppose that we generate a few tokens which are visible now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1122" target="_blank">00:18:42.800</a></span> | <span class="t">we take these tokens we save them so we decode whatever is generated we're using the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1130" target="_blank">00:18:50.320</a></span> | <span class="t">and we save it and then we remove it from the kvcache now if you are looking from a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1136" target="_blank">00:18:56.880</a></span> | <span class="t">implementation wise point of view you don't actually remove from the kvcache you just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1141" target="_blank">00:19:01.840</a></span> | <span class="t">usually the kvcache allocation is a static but even if you use vllm it's used it's done using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1147" target="_blank">00:19:07.680</a></span> | <span class="t">the so-called like pages attention so you actually allocate pages of kvcache actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1153" target="_blank">00:19:13.120</a></span> | <span class="t">so basically we it's not like you are removing stuff from the kvcache you are just resizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1162" target="_blank">00:19:22.240</a></span> | <span class="t">the tensor which is actually an o1 operation so it doesn't have additional cost you just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1167" target="_blank">00:19:27.920</a></span> | <span class="t">keep track of how many tokens there are so anyway we we take this margin we save</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1173" target="_blank">00:19:33.600</a></span> | <span class="t">it somewhere and then we prefill the second chunk to the kvcache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1176" target="_blank">00:19:36.320</a></span> | <span class="t">and then we again add another extractive summary prompt and then we leverage it to generate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1185" target="_blank">00:19:45.040</a></span> | <span class="t">second margin which will depend on the first and the second chunk of the of the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1191" target="_blank">00:19:51.920</a></span> | <span class="t">etc etc for all the chunks so we will have a list of margins</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1196" target="_blank">00:19:56.320</a></span> | <span class="t">and then we can also classify these margins so we can also say which because of some of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1206" target="_blank">00:20:06.240</a></span> | <span class="t">the margins may like be the model hallucinating or the model just saying i cannot find this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1212" target="_blank">00:20:12.160</a></span> | <span class="t">information or etc so we can also classify them we can either use an auxiliary classifier or we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1217" target="_blank">00:20:17.440</a></span> | <span class="t">can use the model itself to classify them and we show in the paper that you don't have to actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1222" target="_blank">00:20:22.640</a></span> | <span class="t">create a new request to the model to classify these margins you can actually overlap the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1227" target="_blank">00:20:27.040</a></span> | <span class="t">generation of the margins with the classification of the previous margin using the same request</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1231" target="_blank">00:20:31.760</a></span> | <span class="t">in the batch does the margin pertain to all previous chunks or only the current one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1238" target="_blank">00:20:38.240</a></span> | <span class="t">all the chunks up to that margin so the first margin only the first chunk the second margin</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1244" target="_blank">00:20:44.080</a></span> | <span class="t">the chunk one and through this third margin chunk one two and three etc because we want to leverage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1249" target="_blank">00:20:49.280</a></span> | <span class="t">the prefilled kvcache okay so we classify these margins and then we append them at the end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1256" target="_blank">00:20:56.960</a></span> | <span class="t">and then we append the question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1270" target="_blank">00:21:10.160</a></span> | <span class="t">and then we generate the answer the final answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1272" target="_blank">00:21:12.080</a></span> | <span class="t">so the advantage is that as i said before we exploit chunk profile of a large prompt to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1281" target="_blank">00:21:21.440</a></span> | <span class="t">generate intermediate summary so we are we are exploiting something that we are already forced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1286" target="_blank">00:21:26.640</a></span> | <span class="t">to do but we are not leveraging right now so it's kind of comes for free just with a minor let's say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1294" target="_blank">00:21:34.160</a></span> | <span class="t">compute because you have the the cost of generating these margins but you avoid the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1301" target="_blank">00:21:41.520</a></span> | <span class="t">bigger cost of prefilling so if you just use chunks chunking techniques like you can do with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1307" target="_blank">00:21:47.360</a></span> | <span class="t">the long chain for example you pay twice the cost of prefilling if you do this system you don't pay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1314" target="_blank">00:21:54.480</a></span> | <span class="t">twice the cost of prefilling which is very expensive and to give you an insight on how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1320" target="_blank">00:22:00.800</a></span> | <span class="t">expensive is prefilling basically in most cases so whenever you work with the openai or with cohere or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1330" target="_blank">00:22:10.320</a></span> | <span class="t">any other provider whenever you send a request your request is always overlapped with the token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1337" target="_blank">00:22:17.120</a></span> | <span class="t">generation of other requests so the first time your prompt comes to their server they are overlapping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1341" target="_blank">00:22:21.840</a></span> | <span class="t">the prefill of your request with the token generation of others because the prefilling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1346" target="_blank">00:22:26.960</a></span> | <span class="t">is compute bound because it's very expensive computationally while the token generation is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1352" target="_blank">00:22:32.800</a></span> | <span class="t">memory bound so to to always utilize the gpu fully they over they kind of schedule together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1360" target="_blank">00:22:40.400</a></span> | <span class="t">one prefill with multiple token generations so so it's compatible with any of the shelf</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1366" target="_blank">00:22:46.880</a></span> | <span class="t">language model without any fine tuning and we saw we show some benchmarks in the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1374" target="_blank">00:22:54.000</a></span> | <span class="t">it improves the ability of any language model to extract relevant information so solving the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1378" target="_blank">00:22:58.080</a></span> | <span class="t">lost in the middle problem and another cool thing that you can do is basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1384" target="_blank">00:23:04.640</a></span> | <span class="t">because now you generate these margins while prefilling the the prompt you can also feedback</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1393" target="_blank">00:23:13.120</a></span> | <span class="t">this margin to the user and the user can classify them for you like a thumbs up or thumbs down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1397" target="_blank">00:23:17.840</a></span> | <span class="t">so it adds a human in the loop and also the user can visualize the progress of how the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1403" target="_blank">00:23:23.600</a></span> | <span class="t">prefilling is going because when you have a very very large prompt i believe that because the cost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1409" target="_blank">00:23:29.200</a></span> | <span class="t">of prefilling is quadratic it will become really it will become really expensive to prefill it and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1416" target="_blank">00:23:36.320</a></span> | <span class="t">the user may have to wait many seconds so you can actually give a feedback to the user of how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1422" target="_blank">00:23:42.080</a></span> | <span class="t">content how much context has been processed and you can actually leverage the waiting time of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1426" target="_blank">00:23:46.000</a></span> | <span class="t">user to give you thumbs up or thumbs down on these margins which can actually improve the ability of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1430" target="_blank">00:23:50.560</a></span> | <span class="t">the language model to use them and the user can also early exit so the user found the relevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1436" target="_blank">00:23:56.640</a></span> | <span class="t">information in one of these margins you can say okay stop inference and the user would not have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1440" target="_blank">00:24:00.720</a></span> | <span class="t">to pay for you know all the context uh being processed and we also provide an implementation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1447" target="_blank">00:24:07.920</a></span> | <span class="t">so if you go to this url so github.com/writer/writing in the margins you can find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1454" target="_blank">00:24:14.640</a></span> | <span class="t">our implementation on how we actually do this stuff with the KVCache i don't know how to delete</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1460" target="_blank">00:24:20.080</a></span> | <span class="t">this line it's so annoying let me check i believe it's annotate and then delete clear clear all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1468" target="_blank">00:24:28.480</a></span> | <span class="t">drawings okay so if you go here you can see uh what we do basically um it's a simple it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1479" target="_blank">00:24:39.040</a></span> | <span class="t">with any language model we here we provide a demo or with the llama fi and quen uh here we show for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1485" target="_blank">00:24:45.760</a></span> | <span class="t">example um this this code that is present here in the github repository matches exactly the code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1491" target="_blank">00:24:51.680</a></span> | <span class="t">that we present in the paper which is the pseudo code that you can see here so how we split into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1498" target="_blank">00:24:58.000</a></span> | <span class="t">segments and how we prefill into the KVCache and how we delete stuff from the KVCache so it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1503" target="_blank">00:25:03.520</a></span> | <span class="t">present here so here you have a very simple like we also show the state of the KVCache at each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1509" target="_blank">00:25:09.920</a></span> | <span class="t">line of code so that the user can understand what is happening here and this is the code for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1515" target="_blank">00:25:15.760</a></span> | <span class="t">the method that we use to delete stuff from the KVCache all right uh let me see if there is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1522" target="_blank">00:25:22.480</a></span> | <span class="t">something that is missing here yeah here we provide a comparison of how it differs from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1528" target="_blank">00:25:28.480</a></span> | <span class="t">reg and how it differs from just long context processing questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1534" target="_blank">00:25:34.960</a></span> | <span class="t">all right let me check you in the chat but Eugene is like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1543" target="_blank">00:25:43.840</a></span> | <span class="t">crushing it answering answering the question in the chat thanks Eugene</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1547" target="_blank">00:25:47.840</a></span> | <span class="t">my pleasure thank you for taking time to share with us about uh the paper and even preparing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1554" target="_blank">00:25:54.080</a></span> | <span class="t">slides uh yeah this okay the slides were from another talk I gave in the company so it's uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1563" target="_blank">00:26:03.120</a></span> | <span class="t">reusing stuff but yeah thank you thank you everyone um so let me go through the question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1571" target="_blank">00:26:11.280</a></span> | <span class="t">if there is something in the chat that I can answer um yes this is not any we are not doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1582" target="_blank">00:26:22.160</a></span> | <span class="t">any change to the model architecture so you don't have to fine-tune anything you don't have to change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1586" target="_blank">00:26:26.320</a></span> | <span class="t">anything like the um can you use this stuff with like a length pane no because it requires a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1593" target="_blank">00:26:33.840</a></span> | <span class="t">modification on how the inference engine is using the model so it's a because when you work at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1600" target="_blank">00:26:40.560</a></span> | <span class="t">KVCache level you cannot just work with the apis and tell them to you know remove stuff from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1606" target="_blank">00:26:46.000</a></span> | <span class="t">KVCache or overlap stuff in the KVCache but it doesn't require changes to the model to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1611" target="_blank">00:26:51.760</a></span> | <span class="t">weights of the model that's why we talk about no fine-tuning here is the extractive summary prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1619" target="_blank">00:26:59.520</a></span> | <span class="t">just the instruction to produce the margin yes so the instructive summary prompt is basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1624" target="_blank">00:27:04.880</a></span> | <span class="t">a prompt that we add after each chunk to extract relevant relevant information about that query so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1632" target="_blank">00:27:12.000</a></span> | <span class="t">it's not just to find the relevant information but about the specific query because we this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1636" target="_blank">00:27:16.480</a></span> | <span class="t">inference pattern that we introduced is a specific uh for those prompts that are composed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1642" target="_blank">00:27:22.320</a></span> | <span class="t">of a context plus an instruction so we always know what is the instruction that's why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1646" target="_blank">00:27:26.720</a></span> | <span class="t">this is I mean the best use of this uh this inference pattern now in the in the paper we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1654" target="_blank">00:27:34.720</a></span> | <span class="t">also show um how chunked prefield works at the KVCache level so if you are familiar with how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1660" target="_blank">00:27:40.480</a></span> | <span class="t">the KVCache with the query the keys etc but we also show how to overlap the computation of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1667" target="_blank">00:27:47.360</a></span> | <span class="t">margin with the classification of a margin and this is exactly actually the the representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1674" target="_blank">00:27:54.720</a></span> | <span class="t">of the KVCache during the prefilling of one chunk and how it can be overlapped with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1681" target="_blank">00:28:01.840</a></span> | <span class="t">classification using the same language model and the same request in the same language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1689" target="_blank">00:28:09.120</a></span> | <span class="t">sorry could you go deeper into overlap I don't know where like overlap happens is it between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1694" target="_blank">00:28:14.480</a></span> | <span class="t">the different chunks or you're overlapping the different chunks um let's talk about overlap</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1699" target="_blank">00:28:19.440</a></span> | <span class="t">so I am talking about uh let's say first visualize it uh let's say here we do have a nice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1706" target="_blank">00:28:26.960</a></span> | <span class="t">representation of that so it is here so you extract the margin and you need to find a way to classify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1713" target="_blank">00:28:33.360</a></span> | <span class="t">it you can either use an auxiliary classifier so use another model to classify it as relevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1719" target="_blank">00:28:39.040</a></span> | <span class="t">or irrelevant or you use the same language model to classify but if you want to use the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1723" target="_blank">00:28:43.520</a></span> | <span class="t">language model to classify you would need to create another request in the batch because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1727" target="_blank">00:28:47.200</a></span> | <span class="t">you don't want the classification request to visualize anything in the KVCache you just want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1733" target="_blank">00:28:53.520</a></span> | <span class="t">to ask the language model okay the I ask a language model to extract information about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1738" target="_blank">00:28:58.400</a></span> | <span class="t">this query here so is Ethan Washington in a marble floored room and the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1745" target="_blank">00:29:05.840</a></span> | <span class="t">extracted this stuff here is it relevant to the query or not if you want to do it you would need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1751" target="_blank">00:29:11.680</a></span> | <span class="t">to create another request in the batch but we show here that you can actually um in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1757" target="_blank">00:29:17.600</a></span> | <span class="t">chunked prefilling so let's go here chunked prefilling in the same request in the batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1763" target="_blank">00:29:23.520</a></span> | <span class="t">so when you do chunked prefilling basically what you are doing is you are adding the first chunk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1769" target="_blank">00:29:29.200</a></span> | <span class="t">to the KVCache so the the keys and the queries are the first chunk so this is c1 that you see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1776" target="_blank">00:29:36.080</a></span> | <span class="t">and then what do we do is we actually add after this we also want to add an extractive summary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1780" target="_blank">00:29:40.960</a></span> | <span class="t">prompt right and then we use this one to generate tokens so now the token generation has um is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1788" target="_blank">00:29:48.080</a></span> | <span class="t">I would say this is the part of the prefilling of the first chunk so the first chunk plus the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1793" target="_blank">00:29:53.440</a></span> | <span class="t">extractive summary and then we use it to generate tokens so this is the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1798" target="_blank">00:29:58.000</a></span> | <span class="t">margin token generated usually we pre-allocate the KVCache so the KVCache is not like growing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1805" target="_blank">00:30:05.040</a></span> | <span class="t">tensor we pre-allocate it with a fixed number of let's say padding tokens but they are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1809" target="_blank">00:30:09.280</a></span> | <span class="t">really padding tokens they are just unused spaces in the KVCache and then we replace them with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1814" target="_blank">00:30:14.960</a></span> | <span class="t">tokens that are actually generated from the language model so suppose that you have these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1819" target="_blank">00:30:19.280</a></span> | <span class="t">unused tokens which I call padding here basically what do we do after we have generated the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1827" target="_blank">00:30:27.040</a></span> | <span class="t">margin we delete this margin right and also the instructive token so what we are actually doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1832" target="_blank">00:30:32.480</a></span> | <span class="t">is we don't delete anything we just change the pointer position of the KVCache on how many tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1837" target="_blank">00:30:37.840</a></span> | <span class="t">are used so now the pointer suppose it's pointing here then we can pre-fill the second chunk so the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1844" target="_blank">00:30:44.400</a></span> | <span class="t">second chunk needs to attend to all its tokens in a causal way so each token in the second chunk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1852" target="_blank">00:30:52.240</a></span> | <span class="t">needs to attend to only itself and all the previous tokens in the same chunk but also needs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1857" target="_blank">00:30:57.040</a></span> | <span class="t">to attend to all the past tokens of the first chunk that was already pre-filled and we also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1861" target="_blank">00:31:01.840</a></span> | <span class="t">need to pre-fill the instructive summary prompt which can visualize all the past tokens that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1867" target="_blank">00:31:07.920</a></span> | <span class="t">has seen but while then then we can also skipping some tokens that we reserve for the generation of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1879" target="_blank">00:31:19.360</a></span> | <span class="t">the margin we can also pre-fill the classification instruction for the first margin which was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1890" target="_blank">00:31:30.560</a></span> | <span class="t">generated before in the previous step and then during the token generation step so this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1896" target="_blank">00:31:36.240</a></span> | <span class="t">pre-filling along with the instructives the pre-filling of the second segment after we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1903" target="_blank">00:31:43.600</a></span> | <span class="t">pre-filled the second segment along with the first generated margin we can generate the tokens of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1909" target="_blank">00:31:49.600</a></span> | <span class="t">second margin but classify the first one which we already obtained in the step before so we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1916" target="_blank">00:31:56.320</a></span> | <span class="t">generating two token sets here and the token generation step in the same request now one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1921" target="_blank">00:32:01.840</a></span> | <span class="t">using only the part relevant to the first chunk the second chunk and the extractive summary of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1928" target="_blank">00:32:08.000</a></span> | <span class="t">the of the after the second chunk and one using only as you can see this is the attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1934" target="_blank">00:32:14.240</a></span> | <span class="t">right and one is only using the in the part that is relevant to classifying the first margin that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1940" target="_blank">00:32:20.400</a></span> | <span class="t">was instructing the previous step so you can do it also like this thank you yeah sorry there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1950" target="_blank">00:32:30.160</a></span> | <span class="t">a question in the chat um and i think from explanation i think naz is clear so when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1956" target="_blank">00:32:36.560</a></span> | <span class="t">are creating the margin for the second chunk you're actually paying attention to the first and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1963" target="_blank">00:32:43.600</a></span> | <span class="t">second yeah okay so you can change the attention mask to only look at the latest chunk however</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1970" target="_blank">00:32:50.160</a></span> | <span class="t">that's exactly the question yeah yes but it's not possible actually i mean let me clarify why it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1976" target="_blank">00:32:56.640</a></span> | <span class="t">not possible because the kvcash is made up of contextualized tokens is actually these tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1981" target="_blank">00:33:01.360</a></span> | <span class="t">are not single they are contextualized so the token number one in the kvcash is a contextualized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1986" target="_blank">00:33:06.720</a></span> | <span class="t">version of the token number zero and one the token number two in the kvcash is a contextualized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1990" target="_blank">00:33:10.880</a></span> | <span class="t">version of the token zero one and two so if you tell the model to only look at the last tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=1995" target="_blank">00:33:15.440</a></span> | <span class="t">you are creating an autoregressive model that is generating the logits of p of let's say x10</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2004" target="_blank">00:33:24.800</a></span> | <span class="t">but only looking at p of x9 x8 which are contextualized token that contain information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2013" target="_blank">00:33:33.600</a></span> | <span class="t">about seven six five but you are not using them so you are actually going out of distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2019" target="_blank">00:33:39.760</a></span> | <span class="t">so this is why thank you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2022" target="_blank">00:33:42.000</a></span> | <span class="t">how much of the kvcash do you prefer with the chunk versus leave it um you can you can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2033" target="_blank">00:33:53.600</a></span> | <span class="t">okay if you use for example vllm they use this call thing called the pages attention so actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2038" target="_blank">00:33:58.000</a></span> | <span class="t">they prefer they allocate one entire page which is actually a lot of tokens so it's like another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2043" target="_blank">00:34:03.840</a></span> | <span class="t">chunk which is more than enough to generate the margin so what are the next steps for this well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2051" target="_blank">00:34:11.520</a></span> | <span class="t">the next step is for sure we are sending it to conferences get it published and presenting it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2058" target="_blank">00:34:18.880</a></span> | <span class="t">around but we are recently focused on long context modeling and actually we are looking at you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2067" target="_blank">00:34:27.200</a></span> | <span class="t">how long context modeling long context can be better leverage so we will be working in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2072" target="_blank">00:34:32.000</a></span> | <span class="t">field actually we will be how to say we will be researching a lot in this field</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2091" target="_blank">00:34:51.600</a></span> | <span class="t">i think there's a question from amad how are the queries chosen for the query based summarization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2101" target="_blank">00:35:01.120</a></span> | <span class="t">uh i think it's a classification right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2103" target="_blank">00:35:03.680</a></span> | <span class="t">uh yes okay so the query is basically uh we work with a prompt that is made up of context plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2111" target="_blank">00:35:11.920</a></span> | <span class="t">query so we all always know what is the query that's the structure of the prompt that we work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2117" target="_blank">00:35:17.200</a></span> | <span class="t">with uh what's the use case that writers led you to this research well we are i am personally very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2125" target="_blank">00:35:25.280</a></span> | <span class="t">interested in long context modeling and i am giving the freedom to research what i like and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2131" target="_blank">00:35:31.600</a></span> | <span class="t">writer is also interested in long context modeling so things intersect and this here we are and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2137" target="_blank">00:35:37.680</a></span> | <span class="t">you know we have our many smart people working together we did a few brainstorming and yeah</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2144" target="_blank">00:35:44.160</a></span> | <span class="t">what's the latency you see for typical request</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2152" target="_blank">00:35:52.400</a></span> | <span class="t">well you are delayed there is no kind of latency increase because of this you are just paying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2160" target="_blank">00:36:00.000</a></span> | <span class="t">more price to generate more tokens in intermediate cases of course what would happen is that uh you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2167" target="_blank">00:36:07.520</a></span> | <span class="t">have before for example you need to um process the entire prompt at once so chunk pre-filling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2174" target="_blank">00:36:14.800</a></span> | <span class="t">chunk pre-filling chunk pre-filling now you have chunk pre-filling with some token generation which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2179" target="_blank">00:36:19.600</a></span> | <span class="t">will slow down the entire request but you are actually getting something back which is feedback</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2185" target="_blank">00:36:25.120</a></span> | <span class="t">and you are getting the possibility to see what the model is actually seeing at each step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2189" target="_blank">00:36:29.360</a></span> | <span class="t">so you get human in the loop so the human is waiting but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2194" target="_blank">00:36:34.000</a></span> | <span class="t">is waiting let's say with some feedback which is nice to have progress bars right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2198" target="_blank">00:36:38.480</a></span> | <span class="t">you and maybe this is sensitive do you happen to have a demo of showing how this actually looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2205" target="_blank">00:36:45.360</a></span> | <span class="t">like in the user interface or is it something that we have to sign up to write that we actually see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2209" target="_blank">00:36:49.120</a></span> | <span class="t">we don't have that but we are working on demos yeah</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2214" target="_blank">00:36:54.160</a></span> | <span class="t">here we have you know we have a concept on how it would look like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2218" target="_blank">00:36:58.960</a></span> | <span class="t">yeah thank you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2224" target="_blank">00:37:04.320</a></span> | <span class="t">so okay in some cases the writing margin does not work well as other methods there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2235" target="_blank">00:37:15.200</a></span> | <span class="t">two factors first of all because we are each margin is kind of a summarization of what is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2242" target="_blank">00:37:22.000</a></span> | <span class="t">present in the context it depends highly on how good that model is at summarizing so the better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2248" target="_blank">00:37:28.480</a></span> | <span class="t">the margin the better the information it will extract and the better it can be leveraged so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2253" target="_blank">00:37:33.280</a></span> | <span class="t">if you think about the student if you're not taking skills are not so good then probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2258" target="_blank">00:37:38.240</a></span> | <span class="t">your notes will not be useful the second thing is actually the comparison here that you see with reg</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2265" target="_blank">00:37:45.600</a></span> | <span class="t">this reg actually we put ourself in the worst condition possible which is let's help reg beat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2271" target="_blank">00:37:51.440</a></span> | <span class="t">us but then actually reg doesn't beat us how usually in reg what you do is you have these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2276" target="_blank">00:37:56.720</a></span> | <span class="t">chunks and you extract some vectors of these chunks and then you match them with the dot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2283" target="_blank">00:38:03.120</a></span> | <span class="t">product or whatever with the query what we did with reg actually is we asked the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2289" target="_blank">00:38:09.760</a></span> | <span class="t">to see if the reg yes it was charitable because we asked the language model actually to to to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2296" target="_blank">00:38:16.480</a></span> | <span class="t">if that particular chunk is relevant so actually you have a 70 billion model telling you if that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2303" target="_blank">00:38:23.040</a></span> | <span class="t">chunk is relevant compared to extract some vector and map it with dot product i mean we help reg a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2309" target="_blank">00:38:29.680</a></span> | <span class="t">lot so actually if we did actually a reg approach like a naive reg approach we would do much better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2316" target="_blank">00:38:36.080</a></span> | <span class="t">thanks umar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2323" target="_blank">00:38:43.280</a></span> | <span class="t">do we have anyone else have questions i want to come on screen to just ask umar and sam</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2342" target="_blank">00:39:02.000</a></span> | <span class="t">more questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2343" target="_blank">00:39:03.200</a></span> | <span class="t">if there's nobody else that is interested i actually am having a little bit of trouble</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2355" target="_blank">00:39:15.680</a></span> | <span class="t">wrapping my mind around why chunk pre-filling is so much more efficient i i i looked at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2364" target="_blank">00:39:24.480</a></span> | <span class="t">sort of the reference and i i kind of get the idea but maybe you can help me understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2370" target="_blank">00:39:30.960</a></span> | <span class="t">the intuition okay it is not uh first of all chunk pre-fill doesn't exist because it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2376" target="_blank">00:39:36.880</a></span> | <span class="t">more efficient it's because we need it we must do it so when you pre-fill uh a chunk into the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2383" target="_blank">00:39:43.440</a></span> | <span class="t">language model let me show you actually here we have the kvk representation right so when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2388" target="_blank">00:39:48.080</a></span> | <span class="t">pre-fill a chunk in the language model let's say this one chunk number one c1 you are generating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2394" target="_blank">00:39:54.080</a></span> | <span class="t">a quadratic uh matrix as you can see if you have four tokens you are generating a four by four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2400" target="_blank">00:40:00.720</a></span> | <span class="t">uh matrix which is prohibitive to generate for very long prompts like you imagine you have 1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2407" target="_blank">00:40:07.840</a></span> | <span class="t">million tokens that's 1 b 1 million by 1 million metrics where each of these values is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2412" target="_blank">00:40:12.720</a></span> | <span class="t">a dot product of a vector and then the computation cost of that also it would really be very slow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2420" target="_blank">00:40:20.880</a></span> | <span class="t">and the gpus are really good at parallelizing in this case when you have a lot of operations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2425" target="_blank">00:40:25.120</a></span> | <span class="t">they will actually be parallelized but anyway the problem actually is the memories of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2430" target="_blank">00:40:30.000</a></span> | <span class="t">pre-filling because when you generate it it's really huge and it doesn't fit yeah so you are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2435" target="_blank">00:40:35.040</a></span> | <span class="t">we are forced to do this chunk then we are doing okay we do this chunk pre-filling so check one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2441" target="_blank">00:40:41.040</a></span> | <span class="t">but we are not leveraging these chunks that we are because we are forced to do it right so it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2447" target="_blank">00:40:47.520</a></span> | <span class="t">slower than just doing it in one pass but since we are already forced to do it why not use them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2454" target="_blank">00:40:54.160</a></span> | <span class="t">yeah yeah no i i definitely i think i got most of the paper just the chunk pre-filling part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2460" target="_blank">00:41:00.880</a></span> | <span class="t">the background if you want more information i can give you some references one is the vllm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2468" target="_blank">00:41:08.800</a></span> | <span class="t">page they are actually in the vllm now they are it's an experimental implementation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2473" target="_blank">00:41:13.760</a></span> | <span class="t">there was a nvidia explanation on chunks pre-filling so i will send a link later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2481" target="_blank">00:41:21.520</a></span> | <span class="t">nvidia published recently an article about chunk pre-filling but basically pre-filling is the most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2487" target="_blank">00:41:27.520</a></span> | <span class="t">expensive part of working with long prompts for language models that's why yeah they need to so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2494" target="_blank">00:41:34.080</a></span> | <span class="t">but what i guess i was having trouble understanding why why that is is it just because it's quadratic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2499" target="_blank">00:41:39.440</a></span> | <span class="t">and so you have to break it up into chunks is that maybe maybe i can take a step at it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2504" target="_blank">00:41:44.800</a></span> | <span class="t">so you can imagine so let's look at the attention mask here here i'm generating the first margin</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2510" target="_blank">00:41:50.320</a></span> | <span class="t">am i doing here i am doing uh i have already seven tokens in the kvcache and i am generating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2518" target="_blank">00:41:58.720</a></span> | <span class="t">the eighth token so i am doing seven dot products so token generation which means generating one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2524" target="_blank">00:42:04.960</a></span> | <span class="t">token using whatever is in the kvcache is linear with respect to whatever is in the side of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2528" target="_blank">00:42:08.800</a></span> | <span class="t">kvcache pre-filling the kvcache is quadratic and mostly because it's quadratic it's very expensive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2534" target="_blank">00:42:14.000</a></span> | <span class="t">so we are talking about something that is linear with quadratic so and if you consider about prompts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2539" target="_blank">00:42:19.680</a></span> | <span class="t">long context if you are working with a two million context window one million and nine hundred ninety</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2546" target="_blank">00:42:26.720</a></span> | <span class="t">nine thousand will be prompt nobody will ever generate more than let's say five thousand tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2552" target="_blank">00:42:32.240</a></span> | <span class="t">so yeah because the most expensive is actually pre-filling so so so just to get an intuition here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2560" target="_blank">00:42:40.240</a></span> | <span class="t">the the other extreme is that you your chunk size is one token right so what's the trade-off</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2566" target="_blank">00:42:46.240</a></span> | <span class="t">so what they do is basically they try to put as bigger as as big as possible until it fits in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2573" target="_blank">00:42:53.200</a></span> | <span class="t">gpu so they usually suppose i think good numbers are like four thousand tokens or eight thousand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2581" target="_blank">00:43:01.760</a></span> | <span class="t">tokens or something in this range and as i said before usually the token generation is memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2589" target="_blank">00:43:09.760</a></span> | <span class="t">bound means that the limitation is only given by how much your kvcache can hold so the memory can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2594" target="_blank">00:43:14.160</a></span> | <span class="t">hold in terms of kvcache while pre-filling is compute bound so to maximize the gpu utilization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2600" target="_blank">00:43:20.000</a></span> | <span class="t">whenever you work with open ai or coherent they just overlap your new request with other people's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2606" target="_blank">00:43:26.400</a></span> | <span class="t">old requests so while they are generating tokens they are also pre-filled so the gpu is utilized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2611" target="_blank">00:43:31.280</a></span> | <span class="t">100 okay yeah no that's helpful and i if you do send those uh links i'll definitely read them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2619" target="_blank">00:43:39.040</a></span> | <span class="t">thank you is there is there a break-even point where at like a certain context length it becomes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2626" target="_blank">00:43:46.880</a></span> | <span class="t">more valuable to do writing with margins than um than just using the llm by itself like it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2634" target="_blank">00:43:54.160</a></span> | <span class="t">where the where the compute equals out or is it all together margins is better i believe okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2642" target="_blank">00:44:02.480</a></span> | <span class="t">writing in the margins it's like you read a book and you have margins versus reading the book i</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2648" target="_blank">00:44:08.640</a></span> | <span class="t">think it's always convenient to read the book with the margins because you are actually paying the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2652" target="_blank">00:44:12.720</a></span> | <span class="t">price for that right we are you it's not something that comes for free you are actually paying the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2657" target="_blank">00:44:17.120</a></span> | <span class="t">cost of generating this margin so you're actually putting there some effort and then you you leverage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2662" target="_blank">00:44:22.640</a></span> | <span class="t">then we what we could do is okay does it always help so far yes so it's not like something that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2671" target="_blank">00:44:31.520</a></span> | <span class="t">you get for free right so you pay and it's is it worth it so far yes and if it's always worth it i</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2681" target="_blank">00:44:41.120</a></span> | <span class="t">so far from our data it's always worth it like it doesn't like even if even if you're literally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2688" target="_blank">00:44:48.000</a></span> | <span class="t">just talking about a chunk if you have like a sentence yeah instead of a book oh really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2693" target="_blank">00:44:53.760</a></span> | <span class="t">yeah then it's not convenient because uh in that case you are not even doing chunk refilling right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2700" target="_blank">00:45:00.560</a></span> | <span class="t">because if you have only small context then they just prefilled at once but when you have yeah yeah</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2706" target="_blank">00:45:06.560</a></span> | <span class="t">make sense once you start growing i think the topic still stands right like let's say you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2713" target="_blank">00:45:13.280</a></span> | <span class="t">got a paragraph and your chunks are sentences or you've got a page right so you've got a thousand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2717" target="_blank">00:45:17.600</a></span> | <span class="t">tokens and your chunks per se is every sentence relevant so some form of highlighting is you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2722" target="_blank">00:45:22.720</a></span> | <span class="t">you have a one page but every sentence you highlight what's relevant or not at that level</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2728" target="_blank">00:45:28.080</a></span> | <span class="t">it's it's kind of negligible to throw the whole thing in a prompt versus do i want to highlight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2733" target="_blank">00:45:33.840</a></span> | <span class="t">seven of the 40 sentences and do this approach i think that's so that's the other non-extreme right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2741" target="_blank">00:45:41.520</a></span> | <span class="t">yeah so basically whenever the the context can just be prefilled in the kb cache without any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2748" target="_blank">00:45:48.480</a></span> | <span class="t">chunk refilling i believe it's not worthy to use it but if it's long then it helps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2755" target="_blank">00:45:55.920</a></span> | <span class="t">and it helps much more than uh chunking separately like we do with the apis right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2761" target="_blank">00:46:01.680</a></span> | <span class="t">with the long chain because you are paying double twice the cost of prefilling in this case we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2767" target="_blank">00:46:07.120</a></span> | <span class="t">only paying once and we also prove in the ablation studies that actually it's always convenient to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2773" target="_blank">00:46:13.440</a></span> | <span class="t">send the context plus the margins never just the margins so you can see here this ablation contest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2780" target="_blank">00:46:20.400</a></span> | <span class="t">compression so if you only send the margins or only the context is always worse than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2785" target="_blank">00:46:25.360</a></span> | <span class="t">providing them both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2788" target="_blank">00:46:28.480</a></span> | <span class="t">context being the whole right the entire book</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2802" target="_blank">00:46:42.480</a></span> | <span class="t">and so build building off that ablation let's say you've got a model that doesn't have the context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2810" target="_blank">00:46:50.560</a></span> | <span class="t">you have to do some sort of chunking splitting uh let's say you know you have a total context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2815" target="_blank">00:46:55.280</a></span> | <span class="t">of 8 000 tokens and you have a million token document there's approaches if you know how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2820" target="_blank">00:47:00.560</a></span> | <span class="t">you can process chunk by chunk and then combine so with the you know what you would expect is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2826" target="_blank">00:47:06.640</a></span> | <span class="t">you could for each chunk do this writing with margins approach at every level and then scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2831" target="_blank">00:47:11.920</a></span> | <span class="t">that down with how many ever steps you need is that intuition still pretty accurate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2838" target="_blank">00:47:18.320</a></span> | <span class="t">i believe with 8 000 um with 8 000 uh how to say context window</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2845" target="_blank">00:47:25.280</a></span> | <span class="t">uh i believe that the latency would be higher right because you at each step you are adding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2851" target="_blank">00:47:31.840</a></span> | <span class="t">more yes at that kind of latency it's even more convenient to just do independent chunking and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2859" target="_blank">00:47:39.040</a></span> | <span class="t">generate in that kind of lane because if you you can always split the the context into chunks and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2865" target="_blank">00:47:45.760</a></span> | <span class="t">then you just send multiple requests and you can pay the price of competing in that kind of range</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2870" target="_blank">00:47:50.960</a></span> | <span class="t">but when you are talking about 64 000 tokens that start making more sense to use this approach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2877" target="_blank">00:47:57.200</a></span> | <span class="t">so for that level i think it's all the traditional approaches uh they work fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2888" target="_blank">00:48:08.880</a></span> | <span class="t">any other questions uh well i think another question that came out was why now why right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2896" target="_blank">00:48:16.480</a></span> | <span class="t">i mean why nobody thought about this before because actually uh we didn't have long context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2902" target="_blank">00:48:22.880</a></span> | <span class="t">very long context um models before and we were not forced to even do chunked pre-feeding so as you as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2910" target="_blank">00:48:30.480</a></span> | <span class="t">you can see from blm they have this feature is an experimental feature right now in blm so it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2918" target="_blank">00:48:38.400</a></span> | <span class="t">because right now we need this chunked refilling and everyone is doing it so that's why we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2923" target="_blank">00:48:43.840</a></span> | <span class="t">this so it's always you know innovation is always starts from some problem that you face and some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2929" target="_blank">00:48:49.120</a></span> | <span class="t">need that you have so right now we have this need and we have the capability so right that's how we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2935" target="_blank">00:48:55.360</a></span> | <span class="t">came up with this awesome we have a few more minutes if anyone else has last minute questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2951" target="_blank">00:49:11.360</a></span> | <span class="t">um please feel free to ask and big shout out thanks to the writer team for presenting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2960" target="_blank">00:49:20.080</a></span> | <span class="t">thank you guys for for listening um you are welcome to uh send us uh your questions uh we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2968" target="_blank">00:49:28.960</a></span> | <span class="t">have a you know github repository i i i suggest watching the code it's really you know very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2975" target="_blank">00:49:35.200</a></span> | <span class="t">commented and it follows the same uh kind of pattern that we shared in the paper so it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2980" target="_blank">00:49:40.560</a></span> | <span class="t">easily understandable for everyone and we have we did a lot of nice tricks you know like one of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2985" target="_blank">00:49:45.280</a></span> | <span class="t">tricks is like you can always delete stuff from the kv from the end of the kv cache and you also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2989" target="_blank">00:49:49.440</a></span> | <span class="t">know why now it's an interesting project if anyone's interested on fridays we have a similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=2997" target="_blank">00:49:57.840</a></span> | <span class="t">ai in action section where we try to take practical outside of paper there's the code up there's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3003" target="_blank">00:50:03.360</a></span> | <span class="t">paper up if anyone wants to run it and present it share their learnings it'll be a really good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3007" target="_blank">00:50:07.680</a></span> | <span class="t">learning exercise but that's always there um i guess we got a question from jimmy any future</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3014" target="_blank">00:50:14.960</a></span> | <span class="t">work in this direction any future work in this direction well for sure we will keep working on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3021" target="_blank">00:50:21.920</a></span> | <span class="t">long context and how we can better leverage long context so there is another kind of problem with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3027" target="_blank">00:50:27.600</a></span> | <span class="t">long context which is uh the the whole language models use long context actually depends highly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3034" target="_blank">00:50:34.160</a></span> | <span class="t">on this attention mechanism and how the softmax works so we have seen with the paper called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3039" target="_blank">00:50:39.360</a></span> | <span class="t">sync attentions that actually the language model allocates a lot of a lot of because when you do a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3046" target="_blank">00:50:46.720</a></span> | <span class="t">direction mechanism you are doing a weighted sum over the tokens and each token is given a weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3052" target="_blank">00:50:52.480</a></span> | <span class="t">and we see that most of the weight is given to the first few tokens so there is a lot of research in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3058" target="_blank">00:50:58.560</a></span> | <span class="t">this area recently i saw a few days ago another paper came out called the sigmoid attention which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3063" target="_blank">00:51:03.840</a></span> | <span class="t">is also studying you know the distribution of this logits and the so so i think the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3070" target="_blank">00:51:10.400</a></span> | <span class="t">mechanism will play a big part in how we can extend the long context so if we can also fix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3076" target="_blank">00:51:16.880</a></span> | <span class="t">this part here so i am very interested you know in the kvcache and optimizing long context modeling so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3083" target="_blank">00:51:23.040</a></span> | <span class="t">we are we are working in this direction because it's it's needed by the market and also it's i</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3091" target="_blank">00:51:31.200</a></span> | <span class="t">like it and i i think it's cool to be able to analyze an entire book or an entire codebase</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3096" target="_blank">00:51:36.720</a></span> | <span class="t">instead of hoping that the rag finds the right one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3100" target="_blank">00:51:40.720</a></span> | <span class="t">awesome well uh big shout out to writer team always great to have you guys present</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3109" target="_blank">00:51:49.840</a></span> | <span class="t">um sam is in discord as well i'm sure he'll relay questions and stuff we've got the recording we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3116" target="_blank">00:51:56.080</a></span> | <span class="t">share it with your team i don't know what you choose to do with it but um next week we've got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3121" target="_blank">00:52:01.920</a></span> | <span class="t">swicks he'll be presenting some of the strawberry q star quiet star all those papers so he'll be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3128" target="_blank">00:52:08.240</a></span> | <span class="t">doing that next week and then the following week if anyone's interested in anything volunteers are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3132" target="_blank">00:52:12.640</a></span> | <span class="t">always open i posted a few papers in paper club i think there's also the mistral stuff so if anyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3138" target="_blank">00:52:18.800</a></span> | <span class="t">wants to lead pop in there otherwise um next week swicks is doing strawberry and star stuff so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3145" target="_blank">00:52:25.920</a></span> | <span class="t">that's on the agenda</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3147" target="_blank">00:52:27.760</a></span> | <span class="t">cool thank you guys thanks everyone take care</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3155" target="_blank">00:52:35.840</a></span> | <span class="t">thank you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3158" target="_blank">00:52:38.420</a></span> | <span class="t">yes i was just about to end the meeting yes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3165" target="_blank">00:52:45.840</a></span> | <span class="t">question is there a you can um is there any way you can copy over the comments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3172" target="_blank">00:52:52.000</a></span> | <span class="t">um i'm trying to do it but it seems to like lazy load like as you scroll up and down it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3178" target="_blank">00:52:58.800</a></span> | <span class="t">really painful let me see if i can extract these comments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3183" target="_blank">00:53:03.520</a></span> | <span class="t">do you know if they normally get saved as a zoom recording i'm using you can click save chat where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3194" target="_blank">00:53:14.880</a></span> | <span class="t">you save chat anyone want to help me out chat there's i was able to copy the comments without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3201" target="_blank">00:53:21.600</a></span> | <span class="t">any problem uh the file is usually saved on the host computer in a folder like documents zoom</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3207" target="_blank">00:53:27.760</a></span> | <span class="t">meeting date and time if you're on windows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3209" target="_blank">00:53:29.840</a></span> | <span class="t">see there's a chat log file that as long as okay i got it i just i just saved the chat i'll throw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3218" target="_blank">00:53:38.480</a></span> | <span class="t">it in discord i have a text file of it yes slides would be great too if we can grab them uh yeah</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3224" target="_blank">00:53:44.560</a></span> | <span class="t">get it all i'll pick them i'll pick them right now perfect thanks guys sweet all right thanks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3230" target="_blank">00:53:50.800</a></span> | <span class="t">But, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=VHwrhL_MSV4&t=3231" target="_blank">00:53:51.640</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>