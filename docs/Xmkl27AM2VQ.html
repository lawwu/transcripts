<html><head><title>Unveiling the latest Gemma model advancements: Kathleen Kenealy</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Unveiling the latest Gemma model advancements: Kathleen Kenealy</h2><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ"><img src="https://i.ytimg.com/vi_webp/Xmkl27AM2VQ/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./Xmkl27AM2VQ.html">Whisper Transcript</a> | <a href="./transcript_Xmkl27AM2VQ.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">My name is Kathleen Keneally. I'm a research engineer at Google DeepMind. And as was just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=19" target="_blank">00:00:19.280</a></span> | <span class="t">mentioned, I'm the technical lead of the Gemma team. Before I get started, I just wanted to say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=26" target="_blank">00:00:26.400</a></span> | <span class="t">how awesome it is to get to be here with you all today. When we were building Gemma, our North Star,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=33" target="_blank">00:00:33.600</a></span> | <span class="t">the thing we were most excited about was building something to empower and accelerate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=39" target="_blank">00:00:39.680</a></span> | <span class="t">the amazing work being done by the open source community. And since we launched our first models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=46" target="_blank">00:00:46.000</a></span> | <span class="t">in February, I have been absolutely blown away by the incredible projects and research and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=54" target="_blank">00:00:54.000</a></span> | <span class="t">innovations that have already been built on top of Gemma. So I'm particularly excited to be here with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=61" target="_blank">00:01:01.200</a></span> | <span class="t">so many developers today and especially delighted to unveil the latest advancements and additions to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=69" target="_blank">00:01:09.200</a></span> | <span class="t">the Gemma model family. So without further ado, we'll get started. As many of you probably know, Google has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=78" target="_blank">00:01:18.480</a></span> | <span class="t">been a pioneer in publications of AI and ML research for the past decade, including publishing some of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=86" target="_blank">00:01:26.800</a></span> | <span class="t">the key research that has sparked recent innovations we've seen in AI. Research like the Transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=94" target="_blank">00:01:34.320</a></span> | <span class="t">Sentin piece, BERT, to name a few. Google DeepMind has really continued this tradition and is actively working to share</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=103" target="_blank">00:01:43.680</a></span> | <span class="t">our research for the world to validate and examine and build upon. But Google's support of the open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=110" target="_blank">00:01:50.880</a></span> | <span class="t">community for AI and ML is not just limited to publishing research. We've also been doing work to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=117" target="_blank">00:01:57.760</a></span> | <span class="t">support ML across the entire technical stack for a long time, from hardware breakthroughs of TPUs, which I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=125" target="_blank">00:02:05.360</a></span> | <span class="t">imagine is especially relevant for this crowd and this track, all the way to an evolution in ML frameworks from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=133" target="_blank">00:02:13.200</a></span> | <span class="t">TensorFlow to JAX. Throughout all of this, open development has been especially critical for Google. Our ability to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=142" target="_blank">00:02:22.480</a></span> | <span class="t">collaborate with the open source community has helped us all discover more, innovate faster,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=149" target="_blank">00:02:29.760</a></span> | <span class="t">and really push the limits of what AI is capable of. So this long history of support of the open source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=157" target="_blank">00:02:37.440</a></span> | <span class="t">community leads us to today and to Google's latest investment in open models, Gemma. Gemma is Google</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=166" target="_blank">00:02:46.400</a></span> | <span class="t">DeepMind's family of open source, lightweight, state-of-the-art models, which we build from the same research and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=174" target="_blank">00:02:54.640</a></span> | <span class="t">technology used to create the Gemma models. I'm so sorry, I think that's my phone going off during this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=180" target="_blank">00:03:00.800</a></span> | <span class="t">talk. Please feel free to rummage through that bag. Wow, lesson learned that even the speaker needs to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=187" target="_blank">00:03:07.680</a></span> | <span class="t">remember to silence her cell phone. All right, back to Gemma. There are a couple of key advantages of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=195" target="_blank">00:03:15.200</a></span> | <span class="t">Gemma models that I want to highlight today. The first is that Gemma models were built to be responsible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=201" target="_blank">00:03:21.360</a></span> | <span class="t">by design. I can tell you from personal experience that from day zero of developing a Gemma model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=210" target="_blank">00:03:30.000</a></span> | <span class="t">safety is a top priority. That means we are manually inspecting data sets to make sure that we are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=217" target="_blank">00:03:37.120</a></span> | <span class="t">only training on the highest quality data, but also the safest data we can. This means that we are evaluating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=224" target="_blank">00:03:44.720</a></span> | <span class="t">our models for safety, starting with our earliest experimentation and ablations, so that we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=230" target="_blank">00:03:50.880</a></span> | <span class="t">selecting training methodologies that we know will result in a safer model. And at the end of our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=238" target="_blank">00:03:58.080</a></span> | <span class="t">development, our final models are evaluated against the same rigorous state-of-the-art safety evaluations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=244" target="_blank">00:04:04.960</a></span> | <span class="t">that we evaluate Gemma models against. And we really do this to make sure that no matter where or how you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=253" target="_blank">00:04:13.600</a></span> | <span class="t">deploy a Gemma model, you can count on the fact that you will have a trustworthy and responsible AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=260" target="_blank">00:04:20.160</a></span> | <span class="t">application. No matter how you've customized Gemma models, you can trust that it will be a responsible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=265" target="_blank">00:04:25.440</a></span> | <span class="t">model. Gemma models also achieve unparalleled breakthrough performance for models of their scale,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=273" target="_blank">00:04:33.280</a></span> | <span class="t">including outperforming significantly larger models. But we'll get to more on that very shortly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=281" target="_blank">00:04:41.520</a></span> | <span class="t">We also designed the Gemma models to be highly extensible so that you can use a Gemma model wherever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=289" target="_blank">00:04:49.600</a></span> | <span class="t">and however you want. This means they're optimized for TPUs and GPUs, as well as for use on your local</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=296" target="_blank">00:04:56.080</a></span> | <span class="t">device. They're supported across many frameworks, TensorFlow, JAX, Keras, PyTorch, Ollama, Transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=304" target="_blank">00:05:04.320</a></span> | <span class="t">you name it, Gemma is probably there. And finally, the real power of the Gemma models comes from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=311" target="_blank">00:05:11.280</a></span> | <span class="t">their open access and open license. That period, that's what's powerful about Gemma. We put state-of-the-art</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=319" target="_blank">00:05:19.200</a></span> | <span class="t">technology into your hands so you can decide what the next wave of innovation looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=324" target="_blank">00:05:24.320</a></span> | <span class="t">When we decided to launch the Gemma models, we wanted to make sure that we could meet developers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=331" target="_blank">00:05:31.440</a></span> | <span class="t">exactly where they are, which is why Gemma models are available anywhere and everywhere you can find an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=338" target="_blank">00:05:38.640</a></span> | <span class="t">open model. I will not list all of the frameworks on this slide, but this is only a fraction of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=345" target="_blank">00:05:45.280</a></span> | <span class="t">places where you can find Gemma models today. This means you can use Gemma how you need it, when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=351" target="_blank">00:05:51.600</a></span> | <span class="t">need it, with the tools that you prefer for development. Since our initial launch back in February,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=359" target="_blank">00:05:59.920</a></span> | <span class="t">we've added a couple of different variants to the Gemma model family. We, of course, have our initial models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=365" target="_blank">00:06:05.760</a></span> | <span class="t">Gemma 1.0, which are our foundational LLMs. We also released, shortly after that, Code Gemma,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=373" target="_blank">00:06:13.040</a></span> | <span class="t">which are the Gemma 1.0 models fine-tuned for improved performance on code generation and code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=379" target="_blank">00:06:19.040</a></span> | <span class="t">evaluation. And one variant that I am particularly excited about is Recurrent Gemma, which is a novel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=386" target="_blank">00:06:26.240</a></span> | <span class="t">architecture, a state-space model that's designed for faster and more efficient inference, especially at long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=393" target="_blank">00:06:33.520</a></span> | <span class="t">contexts. We've also updated all of these models since their initial release. We now have Gemma 1.1, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=403" target="_blank">00:06:43.040</a></span> | <span class="t">better at instruction following and chat. We've updated Code Gemma to have even more improved code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=408" target="_blank">00:06:48.560</a></span> | <span class="t">performance. And we now have Recurrent Gemma at not only the original 2B size, but also at a 9 billion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=415" target="_blank">00:06:55.280</a></span> | <span class="t">parameter size. So there's a lot going on in the Gemma model family, and I'm especially excited to tell you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=424" target="_blank">00:07:04.800</a></span> | <span class="t">about our two most recent launches. The first one is actually our most highly requested feature since day zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=434" target="_blank">00:07:14.720</a></span> | <span class="t">of launch, and that was multimodality. So we launched Pally Gemma. Pally Gemma -- oh, thank you. I appreciate it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=444" target="_blank">00:07:24.640</a></span> | <span class="t">This is why I love the open source community, truly the most passionate developers that there are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=451" target="_blank">00:07:31.200</a></span> | <span class="t">Pally Gemma is a combination of the SigLip vision encoder combined with the Gemma 1.0 text decoder. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=460" target="_blank">00:07:40.960</a></span> | <span class="t">combination allows us to do a variety of image text sort of tasks and capabilities, including</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=468" target="_blank">00:07:48.480</a></span> | <span class="t">question answering, image and video captioning, object detection, and object segmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=474" target="_blank">00:07:54.000</a></span> | <span class="t">The model comes in a couple of different variants. It's currently only available at the 2B size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=480" target="_blank">00:08:00.560</a></span> | <span class="t">but we have pre-trained weights that are available that can be fine-tuned for specific tasks. We have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=486" target="_blank">00:08:06.160</a></span> | <span class="t">couple of different fine-tuned variants as well that are already targeted towards things like object</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=491" target="_blank">00:08:11.040</a></span> | <span class="t">detection and object segmentation. And we also have transfer checkpoints that are models that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=497" target="_blank">00:08:17.280</a></span> | <span class="t">specialized to target a couple of academic benchmarks. Up until this morning, that was our latest release,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=507" target="_blank">00:08:27.360</a></span> | <span class="t">but I'm very excited to be here today with you guys because it is Gemma V2 launch day!</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=513" target="_blank">00:08:33.600</a></span> | <span class="t">Woo-hoo!</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=515" target="_blank">00:08:35.680</a></span> | <span class="t">Wow, thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=518" target="_blank">00:08:38.080</a></span> | <span class="t">We have been working very hard on these models since Gemma 1.0 launch date. We tried to do as much as we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=527" target="_blank">00:08:47.520</a></span> | <span class="t">could to gather feedback from the community to learn where the 1.0 and 1.1 models fell short and what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=535" target="_blank">00:08:55.040</a></span> | <span class="t">could do to make them better, and so we created Gemma 2. Gemma 2 comes in both a 9 billion parameter size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=543" target="_blank">00:09:03.120</a></span> | <span class="t">and a 27 billion parameter size. Both models are without a doubt the most performant of their size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=551" target="_blank">00:09:11.600</a></span> | <span class="t">and both models also outperform models that are even two to three times larger than these base models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=560" target="_blank">00:09:20.800</a></span> | <span class="t">But Gemma 2 isn't just powerful. It's designed to easily integrate into the workflows that you already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=567" target="_blank">00:09:27.280</a></span> | <span class="t">have existing. So Gemma 2 uses all of the same tools, all of the same frameworks as Gemma 1, which means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=575" target="_blank">00:09:35.120</a></span> | <span class="t">if you've already started developing with Gemma 1, you can, with only a couple of lines of code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=580" target="_blank">00:09:40.960</a></span> | <span class="t">automatically switch to using the Gemma 2 models and have increased performance and more power behind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=588" target="_blank">00:09:48.160</a></span> | <span class="t">your applications. We also have the same broad framework compatibility. Again, TensorFlow,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=595" target="_blank">00:09:55.440</a></span> | <span class="t">Jaxx, Transformers, Omama, all of the ones I previously named, we have them for Gemma 2 as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=601" target="_blank">00:10:01.120</a></span> | <span class="t">We also have significantly improved documentation. We have more guides, more tutorials, so that we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=609" target="_blank">00:10:09.040</a></span> | <span class="t">coach you through how to get started not only with inference, but with advanced and efficient fine-tuning from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=615" target="_blank">00:10:15.200</a></span> | <span class="t">day zero. And finally, we really wanted to target fine-tuning as one of the key capabilities of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=623" target="_blank">00:10:23.040</a></span> | <span class="t">models. We did extensive research into how our core modeling decisions impact users' ability to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=631" target="_blank">00:10:31.760</a></span> | <span class="t">downstream fine-tuning. So we believe these models are going to be incredibly easy to fine-tune, so you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=638" target="_blank">00:10:38.240</a></span> | <span class="t">customize them to whatever your use case may be. In addition, to make it especially easy to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=645" target="_blank">00:10:45.600</a></span> | <span class="t">started using Gemma 2 models, we have made the 27B model available in Google AI Studios. This means you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=653" target="_blank">00:10:53.520</a></span> | <span class="t">can go to the AI Studio homepage and select Gemma 2 now, if you wanted to, and start playing around with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=660" target="_blank">00:11:00.800</a></span> | <span class="t">prompts right away. You shouldn't have to do anything except come up with an idea for how you want to push</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=667" target="_blank">00:11:07.040</a></span> | <span class="t">the limits of our model. I am especially excited to see what you all end up doing with AI Studios and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=674" target="_blank">00:11:14.960</a></span> | <span class="t">Gemma, and we have a couple of different ways for you to let us know what you're building, which I'll get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=680" target="_blank">00:11:20.720</a></span> | <span class="t">to down the road. But if you have ideas, I'll be here all day and want to hear what you're doing with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=686" target="_blank">00:11:26.480</a></span> | <span class="t">the Gemma models. But let's dive a little bit more into performance. We are incredibly proud of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=695" target="_blank">00:11:35.200</a></span> | <span class="t">models that we've made. As I mentioned, they are without a doubt the best, most performant models of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=701" target="_blank">00:11:41.600</a></span> | <span class="t">their size and are also competitive with models two to three times larger. So our 27B model has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=710" target="_blank">00:11:50.000</a></span> | <span class="t">performance in the same ballpark as LLAMA 370B and outperforms Grock models on many benchmarks by a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=718" target="_blank">00:11:58.480</a></span> | <span class="t">fairly significant margin in some cases. But I think academic benchmarks are only part of the way that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=727" target="_blank">00:12:07.040</a></span> | <span class="t">evaluate Gemma models. Sometimes these benchmarks are not always indicative of how a model will perform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=734" target="_blank">00:12:14.000</a></span> | <span class="t">once it's in your hands. So we've done extensive human evaluations as well, where we find that the Gemma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=740" target="_blank">00:12:20.400</a></span> | <span class="t">models are consistently heavily preferred to other open models, including larger open models. And I'm also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=750" target="_blank">00:12:30.080</a></span> | <span class="t">proud to say that the Gemma 27B model is currently the number one open model of its size. And it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=758" target="_blank">00:12:38.800</a></span> | <span class="t">currently outranks LLAMA 370B, Nemo Tron 340B, Grock, Claude 3, many, many other models as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=769" target="_blank">00:12:49.120</a></span> | <span class="t">Thank you. Wow, you guys are very supportive. I appreciate it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=776" target="_blank">00:12:56.560</a></span> | <span class="t">The only other open model of any size that outperforms the Gemma 27B model is the E large model on LMSS.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=785" target="_blank">00:13:05.840</a></span> | <span class="t">So we expect that you should have some fun playing around with this, especially for chat applications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=792" target="_blank">00:13:12.880</a></span> | <span class="t">We found in our evaluations that the Gemma 2 models are even better at instruction following. They're even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=799" target="_blank">00:13:19.200</a></span> | <span class="t">more creative. They're better at factuality, better all around than the Gemma 1.0 and 1.1 models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=805" target="_blank">00:13:25.760</a></span> | <span class="t">The other important thing that I want to make sure to highlight from our most recent launch is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=813" target="_blank">00:13:33.600</a></span> | <span class="t">Gemma cookbook. The Gemma cookbook is available on GitHub now and contains 20 different recipes of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=820" target="_blank">00:13:40.720</a></span> | <span class="t">ranging from easy to very advanced applications of how to use the Gemma models. And the thing that I am</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=827" target="_blank">00:13:47.200</a></span> | <span class="t">most excited about is the Gemma cookbook is currently accepting pull requests. So this is a great</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=833" target="_blank">00:13:53.280</a></span> | <span class="t">opportunity to share with us what you're building with the Gemma models so we can help share it with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=840" target="_blank">00:14:00.480</a></span> | <span class="t">the rest of the world. And of course, I have to say, we also wouldn't mind if you started the repository.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=847" target="_blank">00:14:07.760</a></span> | <span class="t">Go take a look and tell us what you're building with Gemma. So there are a couple of different ways you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=853" target="_blank">00:14:13.520</a></span> | <span class="t">can get started with the Gemma 2 models. Of course, I just mentioned the cookbook. You can also apply to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=860" target="_blank">00:14:20.240</a></span> | <span class="t">get GCP credits to accelerate your research using Gemma 2. We have a lot of funding available to support</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=869" target="_blank">00:14:29.200</a></span> | <span class="t">research. I would really encourage you to fill out an application regardless of how small or big your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=876" target="_blank">00:14:36.080</a></span> | <span class="t">project is. We also, as I mentioned, have significantly improved documentation. We have many guides, tutorials,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=883" target="_blank">00:14:43.440</a></span> | <span class="t">collabs across every framework so you can get started doing inference, fine tuning, and evaluation with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=889" target="_blank">00:14:49.520</a></span> | <span class="t">Gemma 2 models. You can download them anywhere open models are available. And please chat with us on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=896" target="_blank">00:14:56.720</a></span> | <span class="t">Discord or other social media channels so we can learn more about what you're building.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=900" target="_blank">00:15:00.960</a></span> | <span class="t">And that's about all from me today. I am so excited to see what you all build with Gemma. I have been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=912" target="_blank">00:15:12.000</a></span> | <span class="t">working on this project for almost two years now and started working on this project because I, as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=920" target="_blank">00:15:20.480</a></span> | <span class="t">researcher in academia, was disappointed to see how far behind open foundational LLMs were compared to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=929" target="_blank">00:15:29.520</a></span> | <span class="t">the rapid improvements we were seeing in proprietary models. So this is something that's very near and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=935" target="_blank">00:15:35.920</a></span> | <span class="t">dear to my heart and that I wish I had had when I was actively part of the open source community. So I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=942" target="_blank">00:15:42.880</a></span> | <span class="t">very excited to see the projects and the research that you all do with these models. Please engage with us on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=949" target="_blank">00:15:49.120</a></span> | <span class="t">social media, on GitHub, on Hugging Face, here at the event, and let us know what you think of the models. Let</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=956" target="_blank">00:15:56.720</a></span> | <span class="t">us know what you think we can do better for next time. And thank you all very much. Really appreciate your time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xmkl27AM2VQ&t=967" target="_blank">00:16:07.760</a></span> | <span class="t">Thank you.</span></div></div></body></html>