<html><head><title>Improving RecSys and Search in the age of LLMs — Eugene Yan</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Improving RecSys and Search in the age of LLMs — Eugene Yan</h2><a href="https://www.youtube.com/watch?v=YxpwskHTtkc"><img src="https://i.ytimg.com/vi_webp/YxpwskHTtkc/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./YxpwskHTtkc.html">Whisper Transcript</a> | <a href="./transcript_YxpwskHTtkc.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Okay, so I've been, I work in the field of recommendation systems and search, and every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=10" target="_blank">00:00:10.420</a></span> | <span class="t">now and then I like to pop my head up to try to see what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=13" target="_blank">00:00:13.760</a></span> | <span class="t">I think the recent trend for the past one or two years has been the interaction between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=18" target="_blank">00:00:18.200</a></span> | <span class="t">the recommendation systems and search and LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=22" target="_blank">00:00:22.300</a></span> | <span class="t">Let's say REXs, REXs and LLMs, REXs and search and LLMs, and I think in early 2023,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=29" target="_blank">00:00:29.760</a></span> | <span class="t">we would see some papers where people use the decoder-only models to try to predict IDs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=34" target="_blank">00:00:34.720</a></span> | <span class="t">Those didn't work very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=36" target="_blank">00:00:36.680</a></span> | <span class="t">But at the end of last year and early this year, we're starting to see scenes of life whereby</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=40" target="_blank">00:00:40.060</a></span> | <span class="t">some of these actually are A/B tested and have very good empirical results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=43" target="_blank">00:00:43.760</a></span> | <span class="t">So I want to highlight a few of those patterns and we can see how it goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=49" target="_blank">00:00:49.120</a></span> | <span class="t">The one thing that for the longest time, what we're trying to do for REXs and search is to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=53" target="_blank">00:00:53.060</a></span> | <span class="t">move away slowly from item IDs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=55" target="_blank">00:00:55.740</a></span> | <span class="t">You can imagine if Eugene interacts with item ID 1, 10, 25, his next predicted direction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=61" target="_blank">00:01:01.980</a></span> | <span class="t">is probably item ID number 33.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=64" target="_blank">00:01:04.660</a></span> | <span class="t">But all of this is relying slowly on item IDs and you can imagine every time that you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=68" target="_blank">00:01:08.500</a></span> | <span class="t">a new item ID, you have to learn a new embedding for it and that leads to a close-up problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=73" target="_blank">00:01:13.700</a></span> | <span class="t">So I know this was not part of my recommended reads in my write-up, I will actually go back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=78" target="_blank">00:01:18.340</a></span> | <span class="t">and update it to be recommended reads, but I want to discuss two papers here to try to address</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=82" target="_blank">00:01:22.620</a></span> | <span class="t">this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=83" target="_blank">00:01:23.620</a></span> | <span class="t">The first one is semantic IDs, which is from YouTube.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=86" target="_blank">00:01:26.260</a></span> | <span class="t">You can imagine YouTube has a lot of new videos all the time, they can't learn new item IDs for them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=93" target="_blank">00:01:33.540</a></span> | <span class="t">all the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=94" target="_blank">00:01:34.540</a></span> | <span class="t">So what they do is they have a transformer encoder, it generates dense content embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=98" target="_blank">00:01:38.740</a></span> | <span class="t">This is actually just a video encoder that converts a view into dense content embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=102" target="_blank">00:01:42.860</a></span> | <span class="t">And then they compress this into what they call semantic ID.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=106" target="_blank">00:01:46.180</a></span> | <span class="t">It's via an autoencoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=107" target="_blank">00:01:47.780</a></span> | <span class="t">So the dense video encoding is 248 dimension, but what they do is they take the encoder, find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=113" target="_blank">00:01:53.260</a></span> | <span class="t">the nearest neighbors, assign that to the code book is also 248, assign it to the nearest code book,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=119" target="_blank">00:01:59.340</a></span> | <span class="t">take the residual, find the next nearest neighbors, assign it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=122" target="_blank">00:02:02.180</a></span> | <span class="t">So it just keeps compressing and compressing it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=124" target="_blank">00:02:04.580</a></span> | <span class="t">In the image here, they have four layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=127" target="_blank">00:02:07.860</a></span> | <span class="t">So essentially you can compress an item ID into four integers product in the paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=132" target="_blank">00:02:12.580</a></span> | <span class="t">actually decompress an ID into eight integers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=135" target="_blank">00:02:15.140</a></span> | <span class="t">So I thought this was pretty cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=136" target="_blank">00:02:16.580</a></span> | <span class="t">And then now that you have an item ID, you have a content embeddings, you convert it to eight integers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=143" target="_blank">00:02:23.620</a></span> | <span class="t">How do you then learn it, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=145" target="_blank">00:02:25.620</a></span> | <span class="t">They tried using ngram and sentence piece.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=148" target="_blank">00:02:28.900</a></span> | <span class="t">ngram is really just, you know, like fast text, like character ngrams, you know, every subword,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=154" target="_blank">00:02:34.500</a></span> | <span class="t">every one character, two characters, three characters are learning about embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=157" target="_blank">00:02:37.620</a></span> | <span class="t">And then they also tried using sentence piece.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=159" target="_blank">00:02:39.220</a></span> | <span class="t">Essentially, sentence piece is really just looking at all the version of all these item IDs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=164" target="_blank">00:02:44.100</a></span> | <span class="t">What are the most common subwords, most common sub characters?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=168" target="_blank">00:02:48.740</a></span> | <span class="t">So therefore, it's no longer just a unigram, bigram and trigram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=173" target="_blank">00:02:53.860</a></span> | <span class="t">It's that you can learn variable length subwords.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=175" target="_blank">00:02:55.780</a></span> | <span class="t">What are the results from this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=178" target="_blank">00:02:58.260</a></span> | <span class="t">Well, not surprisingly, dense content embeddings itself do worse than item IDs, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=188" target="_blank">00:03:08.180</a></span> | <span class="t">And you can see this, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=190" target="_blank">00:03:10.180</a></span> | <span class="t">You can see this on the chart on the left here, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=193" target="_blank">00:03:13.860</a></span> | <span class="t">You can see unigram and bigram, the red line and the purple line, the unigram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=201" target="_blank">00:03:21.140</a></span> | <span class="t">It actually is worse than item, the random hash ID, the orange line, for some extent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=207" target="_blank">00:03:27.860</a></span> | <span class="t">Oh, actually, no, I didn't include the--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=211" target="_blank">00:03:31.220</a></span> | <span class="t">Okay, I have the content embeddings line itself on my write-up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=216" target="_blank">00:03:36.100</a></span> | <span class="t">I didn't include it here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=217" target="_blank">00:03:37.300</a></span> | <span class="t">But this chart here is actually trying to show that they use the dense content embeddings, it's crap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=222" target="_blank">00:03:42.020</a></span> | <span class="t">But when they use both ngram and sentence piece, it did better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=225" target="_blank">00:03:45.620</a></span> | <span class="t">So you have to do this trick whereby you have to convert that content embedding, the full dense content embedding into its own semantic ID and then learn those IDs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=235" target="_blank">00:03:55.540</a></span> | <span class="t">Now, the benefit of this, you might be saying, hey, you know, isn't this all back to IDs again?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=239" target="_blank">00:03:59.540</a></span> | <span class="t">Well, not necessarily, because now, given the piece of content, you can convert it to embedding and then you can assign it to its nearest ID.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=245" target="_blank">00:04:05.780</a></span> | <span class="t">And therefore, you don't need to learn on behavioral data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=247" target="_blank">00:04:07.860</a></span> | <span class="t">So that's the benefit here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=249" target="_blank">00:04:09.860</a></span> | <span class="t">Similarly, quite short, which is like a TikTok number two, the number two TikTok in China, they adopted the same approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=258" target="_blank">00:04:18.500</a></span> | <span class="t">They use multimodal content embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=261" target="_blank">00:04:21.780</a></span> | <span class="t">So they use embeddings from ResNet, Sentencebird and VGG to get the respective modality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=267" target="_blank">00:04:27.380</a></span> | <span class="t">And then this is just simply concatenating a single vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=269" target="_blank">00:04:29.780</a></span> | <span class="t">Then they take all these embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=272" target="_blank">00:04:32.420</a></span> | <span class="t">They just do k-means to identify a thousand of the most common clusters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=276" target="_blank">00:04:36.660</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=277" target="_blank">00:04:37.540</a></span> | <span class="t">Then now, therefore, each embedding is now a trainable item ID.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=280" target="_blank">00:04:40.980</a></span> | <span class="t">These cluster IDs are then embedded via motor encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=285" target="_blank">00:04:45.380</a></span> | <span class="t">So this motor encoder, there's quite a bit to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=288" target="_blank">00:04:48.420</a></span> | <span class="t">Let me try to simplify it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=289" target="_blank">00:04:49.780</a></span> | <span class="t">You can see on the top, it says non-visual, non-trainable visual embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=293" target="_blank">00:04:53.940</a></span> | <span class="t">In this example, they only use visual embedding as an example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=296" target="_blank">00:04:56.820</a></span> | <span class="t">But you can imagine all the non-trainable embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=300" target="_blank">00:05:00.180</a></span> | <span class="t">They take it and they project it into a different space via the mapping network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=305" target="_blank">00:05:05.140</a></span> | <span class="t">Secondly, for every cluster ID, they convert it into learned embeddings for visual texture and acoustic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=311" target="_blank">00:05:11.700</a></span> | <span class="t">These are not the original embeddings that come from it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=314" target="_blank">00:05:14.020</a></span> | <span class="t">These are just the representation of the multimodal cluster ID.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=318" target="_blank">00:05:18.020</a></span> | <span class="t">And then fusion is really just concatenating it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=320" target="_blank">00:05:20.420</a></span> | <span class="t">So now you might be thinking, how is this motor encoder learned?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=324" target="_blank">00:05:24.180</a></span> | <span class="t">How is this motor encoder trained, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=326" target="_blank">00:05:26.180</a></span> | <span class="t">This motor encoder is not trained itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=328" target="_blank">00:05:28.180</a></span> | <span class="t">This motor encoder is trained within the overall encoding, overall ranking network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=332" target="_blank">00:05:32.580</a></span> | <span class="t">which you can see the motor encoder is all at the bottom, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=335" target="_blank">00:05:35.380</a></span> | <span class="t">So therefore, this motor encoder network, it takes the user tower, which is on the left,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=340" target="_blank">00:05:40.980</a></span> | <span class="t">and the item tower that's on the right, and it tries to predict the likelihood that user will click or like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=345" target="_blank">00:05:45.380</a></span> | <span class="t">Therefore, based on this, they just backprop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=348" target="_blank">00:05:48.900</a></span> | <span class="t">You backprop the likelihood of clicking or liking or following, and you backprop it through the motor encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=355" target="_blank">00:05:55.220</a></span> | <span class="t">And that's how the motor encoder learns the mapping network and the cluster IDs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=360" target="_blank">00:06:00.740</a></span> | <span class="t">So the benefit of this is that they shared that outperformed several multimodal baselines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=364" target="_blank">00:06:04.420</a></span> | <span class="t">I won't go through them here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=365" target="_blank">00:06:05.460</a></span> | <span class="t">And when they did A/B testing, I think those are pretty freaking significant numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=371" target="_blank">00:06:11.060</a></span> | <span class="t">Anything more than 1% is pretty strong in a platform like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=377" target="_blank">00:06:17.060</a></span> | <span class="t">And the benefit of this is that they mentioned that they had increased cold start velocity and cold start coverage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=381" target="_blank">00:06:21.540</a></span> | <span class="t">It means that, you know, cold start is able to pick up faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=384" target="_blank">00:06:24.340</a></span> | <span class="t">If it's a good cold start video, it's able to pick up faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=387" target="_blank">00:06:27.460</a></span> | <span class="t">And they are also able to show more cold start, 3.6% more cold start content, which increases coverage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=395" target="_blank">00:06:35.300</a></span> | <span class="t">So they also did the ablation studies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=397" target="_blank">00:06:37.540</a></span> | <span class="t">So let me butt into, for those new to the REXIS world, you said anything more than 1% is a big deal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=405" target="_blank">00:06:45.540</a></span> | <span class="t">Pretty huge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=406" target="_blank">00:06:46.500</a></span> | <span class="t">Can you contextualize, like how much is that worth or is that like...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=411" target="_blank">00:06:51.140</a></span> | <span class="t">So you can imagine, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=412" target="_blank">00:06:52.660</a></span> | <span class="t">Imagine you are making, I don't know, let's just make something up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=415" target="_blank">00:06:55.940</a></span> | <span class="t">A billion dollars worth of ads.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=417" target="_blank">00:06:57.460</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=418" target="_blank">00:06:58.180</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=418" target="_blank">00:06:58.740</a></span> | <span class="t">And if people are engaging more, spending 1% more time, you can show 1% more ads.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=423" target="_blank">00:07:03.620</a></span> | <span class="t">That's like 10 million.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=425" target="_blank">00:07:05.780</a></span> | <span class="t">A million dollars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=426" target="_blank">00:07:06.660</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=427" target="_blank">00:07:07.140</a></span> | <span class="t">So you just expand that, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=428" target="_blank">00:07:08.660</a></span> | <span class="t">Of course, clicks and likes and follows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=430" target="_blank">00:07:10.420</a></span> | <span class="t">This is, these are engagement, engagement proxy metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=435" target="_blank">00:07:15.940</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=436" target="_blank">00:07:16.420</a></span> | <span class="t">So like, and is this, is this absolute or relative?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=439" target="_blank">00:07:19.860</a></span> | <span class="t">So for example, are we saying that, let's say likes was plus three right here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=443" target="_blank">00:07:23.940</a></span> | <span class="t">Are we saying they went from six to 9% or are we saying they're currently 6% and now we are 6.09%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=451" target="_blank">00:07:31.860</a></span> | <span class="t">I suspect it's relative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=454" target="_blank">00:07:34.020</a></span> | <span class="t">I suspect it's like maybe from 5% to 5.15%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=457" target="_blank">00:07:37.780</a></span> | <span class="t">going from 6% to 9% is impossible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=461" target="_blank">00:07:41.700</a></span> | <span class="t">You wouldn't have to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=463" target="_blank">00:07:43.540</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=464" target="_blank">00:07:44.820</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=465" target="_blank">00:07:45.780</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=466" target="_blank">00:07:46.100</a></span> | <span class="t">So no surprises here using multi-modality consistently outperform single model features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=474" target="_blank">00:07:54.420</a></span> | <span class="t">But there was also a trick here whereby they had to learn user specific model interests.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=479" target="_blank">00:07:59.380</a></span> | <span class="t">And if you look at it on the left tower there, close to the top, there's this thing called multi-modal interest intensity learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=489" target="_blank">00:08:09.380</a></span> | <span class="t">Essentially what they're learning there is for each user, which modality they are interested in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=494" target="_blank">00:08:14.340</a></span> | <span class="t">And then they actually map to that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=495" target="_blank">00:08:15.460</a></span> | <span class="t">For some people like Swix is very acoustically inclined.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=498" target="_blank">00:08:18.100</a></span> | <span class="t">He might care more about a soundtrack.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=499" target="_blank">00:08:19.620</a></span> | <span class="t">For other people, they might care more about the visuals or the video itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=504" target="_blank">00:08:24.180</a></span> | <span class="t">Or the text, having a good caption is worth a thousand words, maybe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=507" target="_blank">00:08:27.380</a></span> | <span class="t">So yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=508" target="_blank">00:08:28.740</a></span> | <span class="t">So that's one trend I've seen, which is increasingly including more content into the model itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=518" target="_blank">00:08:38.020</a></span> | <span class="t">The other trend that I've seen is that for LLMs for synthetic data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=523" target="_blank">00:08:43.140</a></span> | <span class="t">And there's two papers that I really like here because they share a lot of details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=528" target="_blank">00:08:48.660</a></span> | <span class="t">And they share a lot about the pitfalls that they faced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=532" target="_blank">00:08:52.100</a></span> | <span class="t">So the first one is, this is paper I really like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=535" target="_blank">00:08:55.060</a></span> | <span class="t">It's called expected bad match.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=537" target="_blank">00:08:57.060</a></span> | <span class="t">It's from Indeed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=537" target="_blank">00:08:57.940</a></span> | <span class="t">Essentially, you can imagine you are providing people with job recommendations, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=543" target="_blank">00:09:03.060</a></span> | <span class="t">And then you want to have a final filter at the end to filter out bad job recommendations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=549" target="_blank">00:09:09.780</a></span> | <span class="t">So this paper, it's not easy to get the full access to this paper online.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=554" target="_blank">00:09:14.980</a></span> | <span class="t">I've included it in our, we have a, in our Discord channel, we have a thread.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=560" target="_blank">00:09:20.020</a></span> | <span class="t">I've actually dropped the PDF in there and they talk through the entire, I think they talk through the entire process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=564" target="_blank">00:09:24.980</a></span> | <span class="t">And I think it's a quite a role model process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=567" target="_blank">00:09:27.380</a></span> | <span class="t">They started with looking at 250 job matches, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=572" target="_blank">00:09:32.100</a></span> | <span class="t">250 job matches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=573" target="_blank">00:09:33.140</a></span> | <span class="t">And then they compared it across various experts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=576" target="_blank">00:09:36.020</a></span> | <span class="t">They have very rigorous criteria.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=577" target="_blank">00:09:37.860</a></span> | <span class="t">And in the end, they built a final eval set of 147 matches that were very high confidence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=583" target="_blank">00:09:43.540</a></span> | <span class="t">multiple experts agreed and then, you know, that there was nothing subjective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=586" target="_blank">00:09:46.820</a></span> | <span class="t">Then they tried prompting the LMS with recruitment guidelines, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=590" target="_blank">00:09:50.980</a></span> | <span class="t">And to classify job match quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=592" target="_blank">00:09:52.980</a></span> | <span class="t">And of course, you know, they tried things like the cheap stuff and then they tried things like the expensive stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=597" target="_blank">00:09:57.060</a></span> | <span class="t">Unfortunately, the cheap stuff doesn't work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=599" target="_blank">00:09:59.060</a></span> | <span class="t">Only GPT-4 worked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=601" target="_blank">00:10:01.380</a></span> | <span class="t">But GPT-4 was so slow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=602" target="_blank">00:10:02.900</a></span> | <span class="t">GPT-4 took an average of 31 seconds, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=606" target="_blank">00:10:06.580</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=607" target="_blank">00:10:07.140</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=607" target="_blank">00:10:07.780</a></span> | <span class="t">No problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=608" target="_blank">00:10:08.420</a></span> | <span class="t">OpenAI lets you fine tune GPT-3.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=611" target="_blank">00:10:11.300</a></span> | <span class="t">So what they did was then they fine tune GPT-3.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=615" target="_blank">00:10:15.300</a></span> | <span class="t">And GPT-3.5, you can see, let's just focus on the green boxes and then the red boxes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=622" target="_blank">00:10:22.660</a></span> | <span class="t">You can see GPT-3.5 is able to achieve as almost close good precision and recall as GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=631" target="_blank">00:10:31.620</a></span> | <span class="t">Fine tune, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=632" target="_blank">00:10:32.340</a></span> | <span class="t">And fine tune from the labels of GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=634" target="_blank">00:10:34.100</a></span> | <span class="t">But GPT-3.5 was like reduced latency by two thirds and cost by two thirds, which is perfect, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=643" target="_blank">00:10:43.300</a></span> | <span class="t">But the thing is, you see that the average latency there is like six seconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=648" target="_blank">00:10:48.020</a></span> | <span class="t">And that's still not good enough for when they needed to do it online.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=652" target="_blank">00:10:52.180</a></span> | <span class="t">So then what they did is they fine tune the lightweight classifier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=656" target="_blank">00:10:56.180</a></span> | <span class="t">Unfortunately, they didn't go into very many details of what this lightweight classifier is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=660" target="_blank">00:11:00.020</a></span> | <span class="t">I suspect that this lightweight classifier is maybe not a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=663" target="_blank">00:11:03.460</a></span> | <span class="t">I suspect that it is probably a decision tree because they talk a lot about categorical features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=669" target="_blank">00:11:09.380</a></span> | <span class="t">And then the labels are just solely the ALM generated labels, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=673" target="_blank">00:11:13.300</a></span> | <span class="t">So you can see their entire journey.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=675" target="_blank">00:11:15.620</a></span> | <span class="t">The first to the eval set, then we test GPT-4, GPT-4 good, but too slow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=679" target="_blank">00:11:19.380</a></span> | <span class="t">Then we try GPT-3.5 like step-by-step incremental progress, but still too slow, too expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=684" target="_blank">00:11:24.980</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=685" target="_blank">00:11:25.540</a></span> | <span class="t">We would really not like to have to train our own classifier and have to maintain the ops of retraining</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=691" target="_blank">00:11:31.860</a></span> | <span class="t">it, but we don't have a choice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=693" target="_blank">00:11:33.220</a></span> | <span class="t">This is what we need to do to reduce inference latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=697" target="_blank">00:11:37.380</a></span> | <span class="t">So that's what they did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=698" target="_blank">00:11:38.260</a></span> | <span class="t">They were able to achieve area under the curve, ROC of 0.86.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=705" target="_blank">00:11:45.060</a></span> | <span class="t">That's pretty freaking good against ALM labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=708" target="_blank">00:11:48.100</a></span> | <span class="t">And this is, according to them, low latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=710" target="_blank">00:11:50.340</a></span> | <span class="t">I don't know how low latency is and suitable for real-time filtering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=713" target="_blank">00:11:53.460</a></span> | <span class="t">The benefits of this are pretty tremendous, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=716" target="_blank">00:11:56.020</a></span> | <span class="t">You can read the benefits there yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=719" target="_blank">00:11:59.060</a></span> | <span class="t">But I think the one big benefit is they lowered unsubscribed rates by 5%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=723" target="_blank">00:12:03.060</a></span> | <span class="t">That is huge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=725" target="_blank">00:12:05.300</a></span> | <span class="t">For someone, if you maintain some kind of push notification or email notification thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=730" target="_blank">00:12:10.980</a></span> | <span class="t">subscribe rates, unsubscription rates is like your biggest guardrail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=734" target="_blank">00:12:14.100</a></span> | <span class="t">Because if people aren't subscribed, you're never, ever going to reach out to them again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=737" target="_blank">00:12:17.220</a></span> | <span class="t">You lose them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=739" target="_blank">00:12:19.220</a></span> | <span class="t">So, you know, all your customer acquisition costs is really down the drain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=743" target="_blank">00:12:23.300</a></span> | <span class="t">Like maybe you have an offer and you let people sign up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=746" target="_blank">00:12:26.020</a></span> | <span class="t">Hey, would you like to hear more about us?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=747" target="_blank">00:12:27.540</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=747" target="_blank">00:12:27.940</a></span> | <span class="t">We give that out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=748" target="_blank">00:12:28.820</a></span> | <span class="t">But when I'm subscribed, you lose them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=750" target="_blank">00:12:30.580</a></span> | <span class="t">And so over here on the top line in table two, they share the apply to invite to apply email.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=758" target="_blank">00:12:38.820</a></span> | <span class="t">That's one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=759" target="_blank">00:12:39.460</a></span> | <span class="t">And then that's the results I highlighted here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=761" target="_blank">00:12:41.780</a></span> | <span class="t">And in the bottom, I also see they had online experiments for the homepage recommendation feed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=767" target="_blank">00:12:47.300</a></span> | <span class="t">And that's how low latency this classifier has to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=771" target="_blank">00:12:51.300</a></span> | <span class="t">It has to be on the homepage recommendations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=773" target="_blank">00:12:53.300</a></span> | <span class="t">And similarly, we see very good results, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=778" target="_blank">00:12:58.180</a></span> | <span class="t">You can see it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=779" target="_blank">00:12:59.300</a></span> | <span class="t">For example, impressions, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=780" target="_blank">00:13:00.500</a></span> | <span class="t">Impressions drop 5.1% at threshold of 15 and then drop by 7.95% at threshold 25.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=788" target="_blank">00:13:08.820</a></span> | <span class="t">What does that mean?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=791" target="_blank">00:13:11.460</a></span> | <span class="t">That means you freed up 5% to 8% of impressions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=795" target="_blank">00:13:15.620</a></span> | <span class="t">You can now show more good stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=798" target="_blank">00:13:18.740</a></span> | <span class="t">Right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=800" target="_blank">00:13:20.740</a></span> | <span class="t">That's huge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=801" target="_blank">00:13:21.780</a></span> | <span class="t">But freeing up 1/12 of impressions is a very big deal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=805" target="_blank">00:13:25.380</a></span> | <span class="t">Freeing up more space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=807" target="_blank">00:13:27.140</a></span> | <span class="t">And as we know, more real estate is better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=809" target="_blank">00:13:29.940</a></span> | <span class="t">So I think that this was quite an outstanding result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=814" target="_blank">00:13:34.100</a></span> | <span class="t">The other one I want to share and then we'll pause for questions, short questions before I go into two other sections, is query understanding at Yelp.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=821" target="_blank">00:13:41.380</a></span> | <span class="t">So query understanding at Yelp was very nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=823" target="_blank">00:13:43.940</a></span> | <span class="t">It's purely using opening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=825" target="_blank">00:13:45.220</a></span> | <span class="t">They had two things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=827" target="_blank">00:13:47.540</a></span> | <span class="t">One is query segmentation and another one is highlights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=829" target="_blank">00:13:49.780</a></span> | <span class="t">The query segmentation one is not so straightforward to understand, but essentially given a query like Epcot restaurants, they can identify, they can split this into different things like topic, location, name, question, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=842" target="_blank">00:14:02.660</a></span> | <span class="t">And then by having better segmentation, they can have greater confidence in rewriting those parts of the query to help them search better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=852" target="_blank">00:14:12.900</a></span> | <span class="t">So the second bullet point gives you an example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=855" target="_blank">00:14:15.300</a></span> | <span class="t">If we know that the user's location is approximately there and the user said Epcot restaurants, we can rewrite the user's location from Orlando, Florida to Epcot for the search backend.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=868" target="_blank">00:14:28.100</a></span> | <span class="t">And because the search backend is based on location, by rewriting Orlando, Florida to Epcot, they were able to get more precise results for the user.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=877" target="_blank">00:14:37.620</a></span> | <span class="t">So that's one example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=880" target="_blank">00:14:40.340</a></span> | <span class="t">The other example is segmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=882" target="_blank">00:14:42.580</a></span> | <span class="t">And the original write-up, they have a lot of good images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=885" target="_blank">00:14:45.780</a></span> | <span class="t">I didn't include those images here because I didn't have time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=888" target="_blank">00:14:48.500</a></span> | <span class="t">I only started reading this like an hour before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=891" target="_blank">00:14:51.060</a></span> | <span class="t">One of this is review highlights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=893" target="_blank">00:14:53.620</a></span> | <span class="t">So imagine if you search for some food, maybe you search for vegetarian friendly Thai food, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=901" target="_blank">00:15:01.860</a></span> | <span class="t">And then sometimes in the reviews, people would say things like vegetarian, veggie only, suitable for vegetarians.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=908" target="_blank">00:15:08.980</a></span> | <span class="t">And then I'm sure that there are way more synonyms for this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=914" target="_blank">00:15:14.180</a></span> | <span class="t">In the past, they had to get humans to write these different synonyms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=917" target="_blank">00:15:17.460</a></span> | <span class="t">And then they add these two dictionaries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=918" target="_blank">00:15:18.660</a></span> | <span class="t">And you can imagine this is not scalable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=923" target="_blank">00:15:23.380</a></span> | <span class="t">But now they can use LLMs to replicate the human reasoning, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=925" target="_blank">00:15:25.380</a></span> | <span class="t">In the phrase extraction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=925" target="_blank">00:15:25.940</a></span> | <span class="t">And they get way better coverage and it can cover 95% of traffic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=931" target="_blank">00:15:31.780</a></span> | <span class="t">So for query segmentation, they are able to understand the user intent a little bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=936" target="_blank">00:15:36.500</a></span> | <span class="t">And then for review highlights, because they were showing more reviews, especially for the long tail queries, it makes search more engaging.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=946" target="_blank">00:15:46.260</a></span> | <span class="t">By highlighting the relevant reviews for a user's query, they help the user feel more confident about the food.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=953" target="_blank">00:15:53.460</a></span> | <span class="t">Let's say it's vegetarian friendly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=955" target="_blank">00:15:55.380</a></span> | <span class="t">And then maybe the user review would really say something like, oh, the vegetarian food is great and delicious or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=960" target="_blank">00:16:00.420</a></span> | <span class="t">Or like definitely no meat involved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=962" target="_blank">00:16:02.340</a></span> | <span class="t">It happens to be gluten free as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=964" target="_blank">00:16:04.020</a></span> | <span class="t">I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=964" target="_blank">00:16:04.580</a></span> | <span class="t">Things like that help make the users more confident in the search results that they're seeing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=969" target="_blank">00:16:09.060</a></span> | <span class="t">Okay, I'll pause here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=972" target="_blank">00:16:12.900</a></span> | <span class="t">Any questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=974" target="_blank">00:16:14.820</a></span> | <span class="t">I know there's a lot in the chat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=976" target="_blank">00:16:16.820</a></span> | <span class="t">Oh my goodness.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=977" target="_blank">00:16:17.460</a></span> | <span class="t">There's a quick, I mean, I have a quick question on just this query understanding thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=982" target="_blank">00:16:22.260</a></span> | <span class="t">What was the previous solta in query segmentation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=985" target="_blank">00:16:25.220</a></span> | <span class="t">Like this seems like the most obvious, dumb possible thing to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=988" target="_blank">00:16:28.260</a></span> | <span class="t">Name entity extraction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=992" target="_blank">00:16:32.260</a></span> | <span class="t">You get a span and then you train some kind of classic, you train some kind of transformer model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=996" target="_blank">00:16:36.980</a></span> | <span class="t">that takes the input and then they'll cut it at characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1000" target="_blank">00:16:40.340</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1001" target="_blank">00:16:41.380</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1002" target="_blank">00:16:42.580</a></span> | <span class="t">So like it's basically, but like this guy did not compare it to NER, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1006" target="_blank">00:16:46.420</a></span> | <span class="t">Like they, they, they mentioned that their original was NER and this is better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1011" target="_blank">00:16:51.620</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1013" target="_blank">00:16:53.060</a></span> | <span class="t">Nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1013" target="_blank">00:16:53.380</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1013" target="_blank">00:16:53.540</a></span> | <span class="t">They definitely, yep.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1015" target="_blank">00:16:55.140</a></span> | <span class="t">I mean, everyone starts with some kind of NER based approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1018" target="_blank">00:16:58.020</a></span> | <span class="t">My, I mean, my, my theory is that like, yeah, I, I basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1021" target="_blank">00:17:01.540</a></span> | <span class="t">basically there's no point doing traditional NER anymore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1024" target="_blank">00:17:04.820</a></span> | <span class="t">You just do LMs, uh, with a, with some kind of schema.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1028" target="_blank">00:17:08.740</a></span> | <span class="t">Could be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1029" target="_blank">00:17:09.380</a></span> | <span class="t">So fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1030" target="_blank">00:17:10.260</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1030" target="_blank">00:17:10.980</a></span> | <span class="t">Any fast NER cheap, uh, that's it for, for search, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1035" target="_blank">00:17:15.300</a></span> | <span class="t">Uh, sorry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1037" target="_blank">00:17:17.860</a></span> | <span class="t">Great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1038" target="_blank">00:17:18.260</a></span> | <span class="t">But slow, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1040" target="_blank">00:17:20.020</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1040" target="_blank">00:17:20.260</a></span> | <span class="t">Um, like if you want to spell check auto complete thing, like a grammar tool, Gemini slow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1047" target="_blank">00:17:27.380</a></span> | <span class="t">Oh, so this is why I might rather prefer, uh, present from this, um, where is it search query?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1058" target="_blank">00:17:38.980</a></span> | <span class="t">So, um, um, they started their legacy models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1064" target="_blank">00:17:44.100</a></span> | <span class="t">Uh, their legacy models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1065" target="_blank">00:17:45.540</a></span> | <span class="t">Oh, go ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1066" target="_blank">00:17:46.340</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1067" target="_blank">00:17:47.700</a></span> | <span class="t">So you can see name entity recognition, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1070" target="_blank">00:17:50.580</a></span> | <span class="t">Um, they use aim at the recognition and, and they do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1073" target="_blank">00:17:53.540</a></span> | <span class="t">Um, but then, oh, wow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1076" target="_blank">00:17:56.180</a></span> | <span class="t">People are drawing on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1077" target="_blank">00:17:57.380</a></span> | <span class="t">I didn't know you could do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1078" target="_blank">00:17:58.820</a></span> | <span class="t">Um, but then they actually shed one thing I really like about this, uh, write up is this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1084" target="_blank">00:18:04.340</a></span> | <span class="t">this, this chart right here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1085" target="_blank">00:18:05.540</a></span> | <span class="t">No, this chart seems very, very, very base formulation, scope task, proof of concept scaling up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1091" target="_blank">00:18:11.140</a></span> | <span class="t">Um, but they, they wrote it very well to explain how they did it in the context of these two case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1097" target="_blank">00:18:17.380</a></span> | <span class="t">studies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1097" target="_blank">00:18:17.780</a></span> | <span class="t">I feel like a lot of people just completely just, uh, drop this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1102" target="_blank">00:18:22.100</a></span> | <span class="t">They completely ignore this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1103" target="_blank">00:18:23.940</a></span> | <span class="t">And for query segmentation, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1105" target="_blank">00:18:25.460</a></span> | <span class="t">Um, I know I'm taking a long time to get to the points.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1108" target="_blank">00:18:28.420</a></span> | <span class="t">Is that 10% of queries make up 80% of traffic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1111" target="_blank">00:18:31.860</a></span> | <span class="t">So they could do all this query segmentation once, period.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1115" target="_blank">00:18:35.940</a></span> | <span class="t">And then just retrieve from the cache.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1118" target="_blank">00:18:38.500</a></span> | <span class="t">Um, derive golden data set fine tune.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1123" target="_blank">00:18:43.540</a></span> | <span class="t">I can't remember where they wrote it, but that's how they did for query segmentation and for review</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1127" target="_blank">00:18:47.780</a></span> | <span class="t">highlights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1128" target="_blank">00:18:48.420</a></span> | <span class="t">So essentially a lot of these things that may feel like they have to be done on online,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1133" target="_blank">00:18:53.380</a></span> | <span class="t">but because of the power law in e-commerce and online search,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1136" target="_blank">00:18:56.900</a></span> | <span class="t">you don't have to, uh, you, you can make use of a cache a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1140" target="_blank">00:19:00.260</a></span> | <span class="t">Um, there's also another question from Tyler Cross.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1146" target="_blank">00:19:06.020</a></span> | <span class="t">How do these approaches compare to more information retrieval methods like BM25 vector methods?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1151" target="_blank">00:19:11.380</a></span> | <span class="t">Um, uh, Tyler, do you want to, what do you mean by, by these approaches?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1156" target="_blank">00:19:16.900</a></span> | <span class="t">What approaches specifically?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1158" target="_blank">00:19:18.180</a></span> | <span class="t">Oh, no, maybe Tyler's not on the...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1162" target="_blank">00:19:22.820</a></span> | <span class="t">I think you said this when you were doing the LLM, like we tried 3.5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1166" target="_blank">00:19:26.180</a></span> | <span class="t">fine tune, 3.5, Lama 2, Nostro 11B.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1168" target="_blank">00:19:28.420</a></span> | <span class="t">Ah, okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1170" target="_blank">00:19:30.500</a></span> | <span class="t">I think that's like a classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1171" target="_blank">00:19:31.940</a></span> | <span class="t">I think in this case, uh, if it's a classification approach and this wouldn't work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1175" target="_blank">00:19:35.860</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1176" target="_blank">00:19:36.900</a></span> | <span class="t">Um, but if you're talking more generally, like using LLMs or embeddings, uh, for retrieval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1183" target="_blank">00:19:43.700</a></span> | <span class="t">Hmm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1184" target="_blank">00:19:44.260</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1185" target="_blank">00:19:45.540</a></span> | <span class="t">I actually don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1186" target="_blank">00:19:46.180</a></span> | <span class="t">I don't know the full, the full context of the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1188" target="_blank">00:19:48.260</a></span> | <span class="t">So I probably better not answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1189" target="_blank">00:19:49.620</a></span> | <span class="t">Um, okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1190" target="_blank">00:19:50.740</a></span> | <span class="t">Any, any other questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1191" target="_blank">00:19:51.860</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1195" target="_blank">00:19:55.940</a></span> | <span class="t">I think that's, that's great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1197" target="_blank">00:19:57.700</a></span> | <span class="t">I can move on because the other two sections are fairly heavy and I, and then, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1202" target="_blank">00:20:02.100</a></span> | <span class="t">we have more times, more time after that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1203" target="_blank">00:20:03.860</a></span> | <span class="t">Ooh, wait.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1205" target="_blank">00:20:05.540</a></span> | <span class="t">I don't know if I'm trying to write screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1208" target="_blank">00:20:08.660</a></span> | <span class="t">Give me a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1209" target="_blank">00:20:09.220</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1210" target="_blank">00:20:10.340</a></span> | <span class="t">First I need to go to my Google Chrome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1214" target="_blank">00:20:14.420</a></span> | <span class="t">Ah, see, this is what happens when you get a noob to do slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1217" target="_blank">00:20:17.540</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1221" target="_blank">00:20:21.860</a></span> | <span class="t">Share.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1222" target="_blank">00:20:22.660</a></span> | <span class="t">You are seeing this, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1224" target="_blank">00:20:24.580</a></span> | <span class="t">You're seeing my slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1225" target="_blank">00:20:25.460</a></span> | <span class="t">Are you seeing it in slideshow mode?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1227" target="_blank">00:20:27.300</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1228" target="_blank">00:20:28.820</a></span> | <span class="t">Full screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1229" target="_blank">00:20:29.460</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1229" target="_blank">00:20:29.700</a></span> | <span class="t">Perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1230" target="_blank">00:20:30.100</a></span> | <span class="t">Perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1230" target="_blank">00:20:30.980</a></span> | <span class="t">So then the other thing is, I think that I'm LLM inspired training paradigms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1234" target="_blank">00:20:34.980</a></span> | <span class="t">So maybe it's LLM inspired, maybe you've been doing this for a very long time, but I thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1238" target="_blank">00:20:38.660</a></span> | <span class="t">to highlight it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1239" target="_blank">00:20:39.700</a></span> | <span class="t">The first one is really looking at the scaling laws.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1243" target="_blank">00:20:43.140</a></span> | <span class="t">And ever since I published, I shared about this post.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1245" target="_blank">00:20:45.540</a></span> | <span class="t">Like people have gotten back to me with like at least three or four papers about other studies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1248" target="_blank">00:20:48.740</a></span> | <span class="t">of scaling laws, but along a very similar, very similar view.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1252" target="_blank">00:20:52.580</a></span> | <span class="t">So I want to talk about the experimentation that I did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1255" target="_blank">00:20:55.860</a></span> | <span class="t">This scaling law was decoder only transformer architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1259" target="_blank">00:20:59.060</a></span> | <span class="t">And they tried various model sizes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1260" target="_blank">00:21:00.900</a></span> | <span class="t">The training data is the same as sentences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1263" target="_blank">00:21:03.460</a></span> | <span class="t">Essentially it's fixed length sequences, 50 item IDs each.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1266" target="_blank">00:21:06.740</a></span> | <span class="t">And the training objective is given the past 10 items, predict item number 11.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1270" target="_blank">00:21:10.740</a></span> | <span class="t">Given the past 20 items, predict item number 21.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1273" target="_blank">00:21:13.140</a></span> | <span class="t">So it's fairly straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1274" target="_blank">00:21:14.660</a></span> | <span class="t">But they did introduce two key things that are very interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1280" target="_blank">00:21:20.180</a></span> | <span class="t">The first one is layer-wise adaptive dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1282" target="_blank">00:21:22.500</a></span> | <span class="t">So you can imagine, right, for LLMs, every single layer has same dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1288" target="_blank">00:21:28.660</a></span> | <span class="t">You know, usually when they draw a transformer layer, it's every single layer has same dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1293" target="_blank">00:21:33.060</a></span> | <span class="t">But for recommendation system models, that's not the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1295" target="_blank">00:21:35.540</a></span> | <span class="t">It's usually fairly fat at the bottom and gets skinnier towards the top.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1299" target="_blank">00:21:39.300</a></span> | <span class="t">So what they do over here is they have higher dropout in the lower layers and lower dropout in the higher layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1303" target="_blank">00:21:43.780</a></span> | <span class="t">And ablation studies showed that this works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1306" target="_blank">00:21:46.420</a></span> | <span class="t">So the intuition here is that the lower layers process more direct input from the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1311" target="_blank">00:21:51.140</a></span> | <span class="t">And because e-commerce data or recommendation data is fairly noisy, it's more prone to overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1318" target="_blank">00:21:58.260</a></span> | <span class="t">Therefore, they have more dropout in the lower layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1321" target="_blank">00:22:01.780</a></span> | <span class="t">Vice versa, at the upper layers, it learns from more abstract data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1326" target="_blank">00:22:06.260</a></span> | <span class="t">And therefore, you want to make sure it doesn't underfit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1329" target="_blank">00:22:09.140</a></span> | <span class="t">You want to make sure it gets all the juice you can get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1331" target="_blank">00:22:11.380</a></span> | <span class="t">And therefore, they reduce the lower, they have lower dropout at the higher layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1336" target="_blank">00:22:16.100</a></span> | <span class="t">The other thing, which feels a little bit like black magic, is that they switch optimizers halfway doing training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1342" target="_blank">00:22:22.580</a></span> | <span class="t">Firstly, they start with Adam and then they switch to SGD.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1346" target="_blank">00:22:26.340</a></span> | <span class="t">The observation they had was that, you know, they ran a full run with Adam, ran a full run with SGD,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1350" target="_blank">00:22:30.420</a></span> | <span class="t">is that Adam is able to very quickly reduce the loss at the start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1355" target="_blank">00:22:35.780</a></span> | <span class="t">But then it like slowly tapers off, whereas SGD is slower at the start, but achieves better conversions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1360" target="_blank">00:22:40.500</a></span> | <span class="t">So they had to do these two tricks for their sequential models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1364" target="_blank">00:22:44.660</a></span> | <span class="t">What were the results?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1366" target="_blank">00:22:46.820</a></span> | <span class="t">I mean, obviously, no, this is fairly obvious.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1370" target="_blank">00:22:50.340</a></span> | <span class="t">Higher model capacity reduce cross entropy loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1373" target="_blank">00:22:53.140</a></span> | <span class="t">And this model capacity is model capacity, model params excluding ID embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1379" target="_blank">00:22:59.380</a></span> | <span class="t">So it's purely just the layers itself without the ID embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1383" target="_blank">00:23:03.380</a></span> | <span class="t">And they were able to model this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1385" target="_blank">00:23:05.860</a></span> | <span class="t">If you look at the dash line, the test loss curve and the blue dots, they estimated this with the blue dots, estimated that power law curve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1394" target="_blank">00:23:14.900</a></span> | <span class="t">And they were able to fairly accurately predict where the red dots are going to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1399" target="_blank">00:23:19.300</a></span> | <span class="t">And, you know, this is like the Kaplan-style scaling loss and the Chinchilla-style scaling loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1405" target="_blank">00:23:25.140</a></span> | <span class="t">So essentially, given some smaller model, if we had bigger model, how would it perform?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1409" target="_blank">00:23:29.060</a></span> | <span class="t">The other thing was, oh gosh, these lines don't look correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1413" target="_blank">00:23:33.860</a></span> | <span class="t">Okay, the red arrow does look correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1416" target="_blank">00:23:36.740</a></span> | <span class="t">Everything else is fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1418" target="_blank">00:23:38.020</a></span> | <span class="t">So over here, I think this is a very nice result, which is that smaller models need more data to achieve comparable performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1426" target="_blank">00:23:46.980</a></span> | <span class="t">So over here on the left, you can see that there's a small model there on the orange line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1431" target="_blank">00:23:51.700</a></span> | <span class="t">It needed twice the amount of data compared to a bigger model to get similar performance, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1439" target="_blank">00:23:59.540</a></span> | <span class="t">So the flip side of it is that, hey, you know, if you want highly performant models online, you're going to need a factor more data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1449" target="_blank">00:24:09.940</a></span> | <span class="t">Of course, this is also nothing unusual.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1452" target="_blank">00:24:12.820</a></span> | <span class="t">This is something we know, but it's really nice to have someone have done the experiments and distill it into the results here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1459" target="_blank">00:24:19.140</a></span> | <span class="t">The other thing that I thought was really interesting is this idea of recommendation model pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1468" target="_blank">00:24:28.500</a></span> | <span class="t">So this was fairly new to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1471" target="_blank">00:24:31.140</a></span> | <span class="t">I didn't think it could be done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1472" target="_blank">00:24:32.420</a></span> | <span class="t">Most people do this on content embeddings, which is given some content of this item, can you predict the content of that item?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1480" target="_blank">00:24:40.180</a></span> | <span class="t">I thought this was fairly novel, whereby it's trained solely on item popularity statistics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1484" target="_blank">00:24:44.580</a></span> | <span class="t">They say it works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1487" target="_blank">00:24:47.940</a></span> | <span class="t">It's still quite unfantom to me on how it works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1491" target="_blank">00:24:51.860</a></span> | <span class="t">Essentially just take the item popularity statistic in the monthly and the weekly timescale, convert it to percentiles, and then convert those percentiles to vector representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1502" target="_blank">00:25:02.340</a></span> | <span class="t">And that's it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1503" target="_blank">00:25:03.940</a></span> | <span class="t">That's your representation of the item.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1506" target="_blank">00:25:06.500</a></span> | <span class="t">So anytime you have a new item, so long as you have the past statistic for the past month and week, you can convert the percentile and then map it into vector representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1514" target="_blank">00:25:14.900</a></span> | <span class="t">So what this means is that imagine if our percentiles are only at the hundreds and we have stats for monthly and weekly, all we need is 200 embeddings for a month and a week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1524" target="_blank">00:25:24.660</a></span> | <span class="t">And for each hundred, for 100 and we need 100 percentiles, we need vector representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1531" target="_blank">00:25:31.220</a></span> | <span class="t">So instead of millions of item IDs or billions of item IDs, all you need is 200 percentile vector representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1539" target="_blank">00:25:39.300</a></span> | <span class="t">So that is extremely compressed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1541" target="_blank">00:25:41.060</a></span> | <span class="t">They also had to do several tricks like relative time intervals and fixed position encoding that don't come across as ventuitive to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1550" target="_blank">00:25:50.340</a></span> | <span class="t">They explained that they say that they did that, but it's unclear, like how would I know a priori that I need to, how would I know if without running experiment that I needed to do it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1559" target="_blank">00:25:59.700</a></span> | <span class="t">So it feels like there's like too many tricks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1562" target="_blank">00:26:02.900</a></span> | <span class="t">There's so many tricks in like, okay, I need these three things, the stats to perfectly align for this to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1567" target="_blank">00:26:07.380</a></span> | <span class="t">So I think it's very promising, but I wish there was a simpler way to do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1571" target="_blank">00:26:11.300</a></span> | <span class="t">The results, it has promising zero shot performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1575" target="_blank">00:26:15.380</a></span> | <span class="t">What I mean by zero performance, basically it trains on the standard domain and then tries to apply it across the domain to another domain, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1583" target="_blank">00:26:23.700</a></span> | <span class="t">And you can see two to six percent drop in recall at 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1585" target="_blank">00:26:25.940</a></span> | <span class="t">This is compared to baselines, which are fairly good baselines, SASTRAC and BOFORAC, which are trained on the target domain itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1592" target="_blank">00:26:32.020</a></span> | <span class="t">Now, if you take this model and you train it on that target domain,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1598" target="_blank">00:26:38.660</a></span> | <span class="t">it matches or surpasses SASTRAC and BOFORAC when trained from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1602" target="_blank">00:26:42.100</a></span> | <span class="t">But the test, it only uses one to five percent of parameters because it doesn't have item embeddings, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1608" target="_blank">00:26:48.100</a></span> | <span class="t">It only has those 200 embeddings at the monthly and the weekly scale for every percentile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1612" target="_blank">00:26:52.100</a></span> | <span class="t">So this is quite promising in the sense, it's one direction to its pre-trained models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1620" target="_blank">00:27:00.180</a></span> | <span class="t">You can imagine some kind of recommendation as a service, adopting this idea and maybe it could work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1627" target="_blank">00:27:07.060</a></span> | <span class="t">Maybe something like Shopify, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1628" target="_blank">00:27:08.660</a></span> | <span class="t">Shopify has a lot of new merchants onboarding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1631" target="_blank">00:27:11.220</a></span> | <span class="t">Hey, you know, can we take existing merchant data with their permission?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1633" target="_blank">00:27:13.860</a></span> | <span class="t">Of course, completely anonymized, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1636" target="_blank">00:27:16.260</a></span> | <span class="t">It's just solely trained on popularity, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1639" target="_blank">00:27:19.220</a></span> | <span class="t">And then we just train this model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1640" target="_blank">00:27:20.580</a></span> | <span class="t">Now for any new merchant that's onboarding, as long as we have a week of data, we can use the weekly popularity embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1646" target="_blank">00:27:26.820</a></span> | <span class="t">And once we have a month of data, we can use that model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1649" target="_blank">00:27:29.860</a></span> | <span class="t">So we don't actually need semantic IDs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1651" target="_blank">00:27:31.860</a></span> | <span class="t">The second one is we have two papers from YouTube.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1656" target="_blank">00:27:36.660</a></span> | <span class="t">We have two pictures from Google and YouTube here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1658" target="_blank">00:27:38.900</a></span> | <span class="t">And this is so the one thing about distillation is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1664" target="_blank">00:27:44.900</a></span> | <span class="t">if you solely learn on the teacher labels, it is very noisy, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1674" target="_blank">00:27:54.260</a></span> | <span class="t">The teacher models are not the perfect models. It's better to learn from the ground truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1677" target="_blank">00:27:57.140</a></span> | <span class="t">But we do know that adding the teacher models does help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1680" target="_blank">00:28:00.100</a></span> | <span class="t">So what they do here is on the left side, you can see that direct distillation, which is learning from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1686" target="_blank">00:28:06.980</a></span> | <span class="t">both the hard labels, which is the ground truth and the distillation labels, which is what the teacher provides,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1691" target="_blank">00:28:11.860</a></span> | <span class="t">the teacher model, the big teacher model provides, is not as good as auxiliary distillation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1697" target="_blank">00:28:17.620</a></span> | <span class="t">And essentially, what auxiliary distillation means is that you just split, give them two logits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1701" target="_blank">00:28:21.620</a></span> | <span class="t">One logit to learn from the hard label, one logit to learn from the distillation label.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1705" target="_blank">00:28:25.060</a></span> | <span class="t">And they find that this works very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1708" target="_blank">00:28:28.100</a></span> | <span class="t">I didn't have time to put the results here, but they find that this works well for YouTube.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1712" target="_blank">00:28:32.580</a></span> | <span class="t">And then the thing is that the teacher model is useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1715" target="_blank">00:28:35.060</a></span> | <span class="t">So what they did is that they amortized the cost by having a big fat teacher model. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1720" target="_blank">00:28:40.260</a></span> | <span class="t">by big fat teacher model, I mean, it's only two to four X bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1724" target="_blank">00:28:44.100</a></span> | <span class="t">By having a teacher model that's two to four X bigger, this teacher model will just keep pumping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1728" target="_blank">00:28:48.580</a></span> | <span class="t">out the soft labels that all the students can learn from. And this makes all the students better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1733" target="_blank">00:28:53.460</a></span> | <span class="t">And of course, why do we want students? If you're saying that teacher model is better,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1736" target="_blank">00:28:56.420</a></span> | <span class="t">why do we want students? We want the students because the student models are small and cheap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1740" target="_blank">00:29:00.580</a></span> | <span class="t">And at YouTube scale, where they have to make a lot of requests, this is probably what they need to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1745" target="_blank">00:29:05.140</a></span> | <span class="t">Another approach, which is from Google, and I think they applied this in the YouTube setting as well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1752" target="_blank">00:29:12.660</a></span> | <span class="t">is called self auxiliary distillation. So the intuition here is this, don't look at the image first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1759" target="_blank">00:29:19.380</a></span> | <span class="t">So intuition here is this, they want to prioritize high quality labels and improve the resolution of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1764" target="_blank">00:29:24.340</a></span> | <span class="t">low quality. What does it mean to improve the resolution of lower quality labels? Essentially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1769" target="_blank">00:29:29.220</a></span> | <span class="t">what they're saying is that if something is impressed, but not clicked, we should not treat that as a label</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1776" target="_blank">00:29:36.900</a></span> | <span class="t">of zero. Instead, what we should do is to try to get the teacher to predict what that label is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1782" target="_blank">00:29:42.820</a></span> | <span class="t">to smoothen it out. So if you look at the image, you can see that they have ground truth labels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1788" target="_blank">00:29:48.660</a></span> | <span class="t">which is those in green, and they have teacher predictions, which is those in yellow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1792" target="_blank">00:29:52.020</a></span> | <span class="t">So to combine a hard label with the soft label, they suggested a very simple function in the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1797" target="_blank">00:29:57.300</a></span> | <span class="t">I don't know if that's what they actually use, but essentially the max of the teacher and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1802" target="_blank">00:30:02.740</a></span> | <span class="t">student. So the max of the teacher and the ground truth. So imagine if the actual label was zero,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1809" target="_blank">00:30:09.540</a></span> | <span class="t">and the teacher said that, you know, it's a 0.3, you just use the 0.3. Or if the actual label is one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1814" target="_blank">00:30:14.660</a></span> | <span class="t">and it's just a 0.5, you just take the one. So by smoothing it, and then having the teacher,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1820" target="_blank">00:30:20.020</a></span> | <span class="t">having the student learn on the auxiliary head, right, you are actually able to improve the teacher</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1827" target="_blank">00:30:27.540</a></span> | <span class="t">model itself and use it for serving. So there's a lot of distillation techniques, which I think is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1833" target="_blank">00:30:33.780</a></span> | <span class="t">quite inspired by what we see from computer vision and language models. I haven't seen too many of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1841" target="_blank">00:30:41.940</a></span> | <span class="t">these distillation techniques myself in the field of recommendations, which I thought were pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1845" target="_blank">00:30:45.700</a></span> | <span class="t">interesting. The last one, and unfortunately this is the last one I have slides for, I can go through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1851" target="_blank">00:30:51.140</a></span> | <span class="t">the other recommended reads I have, but unfortunately I didn't have slides to do for it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1856" target="_blank">00:30:56.980</a></span> | <span class="t">is this one. So this is quite eye-opening for me. Essentially what LinkedIn did was they replaced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1867" target="_blank">00:31:07.700</a></span> | <span class="t">several ID-based ranking models into a single 150B decoder-only model. What this means is that, for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1876" target="_blank">00:31:16.900</a></span> | <span class="t">example, you could replace 30 different logistic regressions or decision trees or neural networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1882" target="_blank">00:31:22.660</a></span> | <span class="t">with a single text-based decoder-only model. This model is based, it's built on the Mistro MOE, right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1890" target="_blank">00:31:30.500</a></span> | <span class="t">that's why it's like approximately 150B. And it's trained on three, six months of interaction data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1896" target="_blank">00:31:36.180</a></span> | <span class="t">and the key, the main, so you may think, okay, decoder-only model, what does it mean?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1900" target="_blank">00:31:40.500</a></span> | <span class="t">Will you write posts for me? Will you write LinkedIn posts for me? Will you write my,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1903" target="_blank">00:31:43.780</a></span> | <span class="t">will you write, update my job title, whatever? The focus here is solely binary classification,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1910" target="_blank">00:31:50.420</a></span> | <span class="t">if the user will like with, will like or interact with a post or interact for, apply for a job.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1916" target="_blank">00:31:56.340</a></span> | <span class="t">So you can imagine that this model probably only needs to output like or not like. It's probably more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1923" target="_blank">00:32:03.220</a></span> | <span class="t">complex than that. But essentially, this is a big fat decoder-only model that is very good at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1927" target="_blank">00:32:07.140</a></span> | <span class="t">binary classification. That's why it's able to actually do well. And that's how they were evaluated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1934" target="_blank">00:32:14.180</a></span> | <span class="t">So there are different training stages. And over here, I think maybe it's better for me to go over,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1938" target="_blank">00:32:18.500</a></span> | <span class="t">go into the actual write-up itself because I just didn't have time to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1946" target="_blank">00:32:26.980</a></span> | <span class="t">share this. So they have continuous pre-training. So continuous pre-training, they just take member</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1953" target="_blank">00:32:33.540</a></span> | <span class="t">interactions on LinkedIn, different LinkedIn products, right? And then your raw entity data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1958" target="_blank">00:32:38.260</a></span> | <span class="t">essentially just take all this job-related, job hunting-related data to pre-train the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1963" target="_blank">00:32:43.860</a></span> | <span class="t">to help the model get some idea of what is the domain. After continuous pre-training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1971" target="_blank">00:32:51.380</a></span> | <span class="t">they do the post-training approach. They do instruction tuning. So essentially, this is like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1976" target="_blank">00:32:56.900</a></span> | <span class="t">training the model for instructions. They follow, they use UltraChat and internally generated instruction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1984" target="_blank">00:33:04.260</a></span> | <span class="t">following data, right? So get LLMs to come up with questions and answers, relevant LinkedIn tasks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1988" target="_blank">00:33:08.820</a></span> | <span class="t">and then try to find high-quality ones. So that's training it, fine-tuning it to follow instructions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1994" target="_blank">00:33:14.020</a></span> | <span class="t">And then finally is supervised fine-tuning. I don't say something, a lot of things like multi-turn chat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=1998" target="_blank">00:33:18.980</a></span> | <span class="t">format. But essentially, the goal for supervised fine-tuning is to train the model to do the specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2009" target="_blank">00:33:29.780</a></span> | <span class="t">task. I don't remember where it is exactly, but it's like, ah, so this is a specific task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2016" target="_blank">00:33:36.820</a></span> | <span class="t">So now that we know it can follow instructions, now let's make it better at the specific task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2022" target="_blank">00:33:42.260</a></span> | <span class="t">Speaker 1: What action would a member take on this post? Would it solely be impressed? Will it be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2028" target="_blank">00:33:48.420</a></span> | <span class="t">liked? Will it be comment? Etc. So that's how they go through differences. And I'm going back to my slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2043" target="_blank">00:34:03.540</a></span> | <span class="t">Okay. So they have these three different stages. And so here's the crazy thing. You can see the slides,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2055" target="_blank">00:34:15.140</a></span> | <span class="t">right? Can someone just say yes? Yes. Okay. The crazy thing is that they have now replaced feature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2063" target="_blank">00:34:23.220</a></span> | <span class="t">engineering with prop engineering because of this unified decoder model. So you can broadly read it. It's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2070" target="_blank">00:34:30.900</a></span> | <span class="t">this is the instruction. Here's the current member profile, software engineer at Google. Here's their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2076" target="_blank">00:34:36.020</a></span> | <span class="t">job. Here's their resume. Here's the things that they have applied to. So will the user apply to this job?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2084" target="_blank">00:34:44.500</a></span> | <span class="t">And the answer is apply. And you can probably simplify this into a one or zero, right? I guess they just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2090" target="_blank">00:34:50.180</a></span> | <span class="t">say in the text as an example, but that's all this model is doing. For a user, we have retrieved several</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2097" target="_blank">00:34:57.220</a></span> | <span class="t">jobs. This model is doing the final pass of which one to rank. And they take the log props of the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2104" target="_blank">00:35:04.020</a></span> | <span class="t">to score it. So essentially, if this says that the member will apply, maybe you have 10 jobs that a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2109" target="_blank">00:35:09.780</a></span> | <span class="t">member will apply. Then we take the log props to rank it. I don't know if this is a good thing or bad thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2116" target="_blank">00:35:16.260</a></span> | <span class="t">I find feature engineering more intuitive than prop engineering, but maybe it's a skill issue. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2122" target="_blank">00:35:22.020</a></span> | <span class="t">essentially now, all PMs can engineer their own features. The impressive thing was, is that this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2131" target="_blank">00:35:31.700</a></span> | <span class="t">can support 30 different ranking tasks. That's insane. So now, instead of 30 different models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2138" target="_blank">00:35:38.820</a></span> | <span class="t">you just have one big fat decoder model. That sounds a bit crazy to me. Firstly, it's crazy impressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2146" target="_blank">00:35:46.260</a></span> | <span class="t">Secondly, it's a lot of savings. Thirdly, I don't know how to deal with the alignment tax, or maybe it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2151" target="_blank">00:35:51.620</a></span> | <span class="t">just a do no harm tax. I don't know. Essentially, the goal of REXIS was to decouple everything, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2157" target="_blank">00:35:57.940</a></span> | <span class="t">It's like, have retrieval be very good at retrieval, have ranking be very good at ranking. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2162" target="_blank">00:36:02.740</a></span> | <span class="t">each model just squeezes as much juice as we can. Now, what this is saying is that, okay, we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2168" target="_blank">00:36:08.660</a></span> | <span class="t">to unify. We have too many separate ranking models. We're going to unify into a big fat model and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2175" target="_blank">00:36:15.220</a></span> | <span class="t">push all the data through it. And hopefully, you'll outperform. And it does outperform. It needs a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2180" target="_blank">00:36:20.260</a></span> | <span class="t">of data. So you can see in the graph of that, right? Up to release three, it was not better than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2187" target="_blank">00:36:27.620</a></span> | <span class="t">production. And you can see that based on the axis on the left, which is the gap production. Zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2193" target="_blank">00:36:33.220</a></span> | <span class="t">means that it's on par with production. Up to release three, it was not better. I mean, I don't know who</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2197" target="_blank">00:36:37.540</a></span> | <span class="t">had to get whatever budget or just to quarterback to make sure that this work, to push this through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2206" target="_blank">00:36:46.340</a></span> | <span class="t">But as they add more and more tokens, it starts to get better than production, like 2.5% increase. So this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2217" target="_blank">00:36:57.300</a></span> | <span class="t">a huge leap of faith that, okay, we'll just say, uh, with the lesson. Just give us more data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2224" target="_blank">00:37:04.900</a></span> | <span class="t">we will outperform, um, and with a single model. Um, okay, so that's it. That's all I had to share.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2231" target="_blank">00:37:11.860</a></span> | <span class="t">Um, I, I can go through two other, I want to just briefly highlight two other papers, which I think are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2239" target="_blank">00:37:19.300</a></span> | <span class="t">good. Um, it's a little bit less connected to LLMs, but the two other papers, which I think are very good is because of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2246" target="_blank">00:37:26.900</a></span> | <span class="t">how do they go into their system architecture. The first one is Etsy. Um, Etsy, you can see this, this is extremely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2253" target="_blank">00:37:33.780</a></span> | <span class="t">complicated. Uh, but this really shows you a very realistic and practical approach, right? Classic two-tower</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2260" target="_blank">00:37:40.900</a></span> | <span class="t">architecture. They share about negative sampling and then talk about product quality, right? The thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2266" target="_blank">00:37:46.020</a></span> | <span class="t">is you can have very good baby crap, realized images, but when people buy it, they return it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2272" target="_blank">00:37:52.660</a></span> | <span class="t">Um, you will never be able to detect that if you're just using that. So what they did was that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2277" target="_blank">00:37:57.780</a></span> | <span class="t">actually have a product quality embedding index that they use, used to augment, um, their approximate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2284" target="_blank">00:38:04.820</a></span> | <span class="t">nearest neighbor index, right? So you can see the quality back quality vector. Uh, this is extremely pragmatic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2291" target="_blank">00:38:11.540</a></span> | <span class="t">and I can tell you that not, uh, no, no e-commerce website or no search engine, search, whatever online</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2298" target="_blank">00:38:18.260</a></span> | <span class="t">discovery thing can do without some form of quality vector or some kind of post quality filtering. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2304" target="_blank">00:38:24.820</a></span> | <span class="t">saw that with indeed, right? Expected bad match. They need the quality. They just, uh, operationalize it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2309" target="_blank">00:38:29.540</a></span> | <span class="t">in a different way as a final post filtering layer over here. They include it in the approximate nearest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2314" target="_blank">00:38:34.900</a></span> | <span class="t">neighbors index. So I highly recommend reading this, um, very practical, uh, shares a lot of detail into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2321" target="_blank">00:38:41.460</a></span> | <span class="t">their system design. Uh, the next one I also highly recommend is the model ranking platform at Zalando.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2326" target="_blank">00:38:46.900</a></span> | <span class="t">I think this is all the best practices, uh, talks about all the different tenants, like composability,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2332" target="_blank">00:38:52.020</a></span> | <span class="t">scalability, steerable ranking, and they really go right deep into, Hey, you know, here's the candidate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2336" target="_blank">00:38:56.260</a></span> | <span class="t">generator, essentially the retrieval step to tower model. And then, you know, they just, uh, using an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2342" target="_blank">00:39:02.340</a></span> | <span class="t">ANN to retrieve it. And then they talk about the ranker and then finally the policy layer. What is this policy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2347" target="_blank">00:39:07.860</a></span> | <span class="t">layer, right? Policy layer, encourage exploration, uh, business rules, like previously purchased item, item</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2353" target="_blank">00:39:13.380</a></span> | <span class="t">diversity, again, some kind of, some, some, some measure of quality that the model would never be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2360" target="_blank">00:39:20.340</a></span> | <span class="t">able to learn from the data. The model will never learn that showing good items is good, right? Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2364" target="_blank">00:39:24.260</a></span> | <span class="t">they're untested. So you have to override the model with this policy layer. Um, and of course, very good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2370" target="_blank">00:39:30.260</a></span> | <span class="t">results. Uh, but what, what I really like about this paper is that if you want to learn about system design</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2376" target="_blank">00:39:36.020</a></span> | <span class="t">for Rex's like the Zalano paper and the Etsy paper, uh, really, really, really good and really in depth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2382" target="_blank">00:39:42.980</a></span> | <span class="t">Um, but of course everything here is, uh, very good. If there were a few papers I read, I'm like, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2388" target="_blank">00:39:48.340</a></span> | <span class="t">this is pretty crap. I wouldn't include it. Uh, but every paper here is pretty good for system design.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2392" target="_blank">00:39:52.900</a></span> | <span class="t">Um, under the final section, which is unified architectures. Um, okay. Any, I spoke a lot,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2400" target="_blank">00:40:00.980</a></span> | <span class="t">any questions, they'll lose anyone. They'll lose everyone. Uh, Eugene, I have one quick question to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2410" target="_blank">00:40:10.020</a></span> | <span class="t">double check on the LinkedIn's paper. Hmm. My understanding is the, the big model on the 150</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2417" target="_blank">00:40:17.860</a></span> | <span class="t">billion model is actually used as teacher model and then distilled the knowledge into smaller models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2424" target="_blank">00:40:24.500</a></span> | <span class="t">then used for kind of different tasks. So I don't know if that aligns with your understanding because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2430" target="_blank">00:40:30.580</a></span> | <span class="t">practically 150 billion model and surf data for prediction, the latency will not be acceptable and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2438" target="_blank">00:40:38.020</a></span> | <span class="t">too costly also. They do actually have a, like a full, like a paper discuss more about how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2445" target="_blank">00:40:45.220</a></span> | <span class="t">knowledge deceleration is happening with that 150 billion models. I kind of put it in the, in the chat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2451" target="_blank">00:40:51.860</a></span> | <span class="t">I don't know if you have come across that paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2453" target="_blank">00:40:53.860</a></span> | <span class="t">I have not. Um, but my impression was that they were actually using it. Thank you for sharing this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2459" target="_blank">00:40:59.540</a></span> | <span class="t">and thank you for correcting my misunderstanding. I need to look deeper into the original paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2464" target="_blank">00:41:04.260</a></span> | <span class="t">Um, um, um, to confirm this. Let me take you in this thread. That's my understanding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2472" target="_blank">00:41:12.020</a></span> | <span class="t">So, but I also find this, uh, the, the approach very interesting. So we were actually thinking of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2478" target="_blank">00:41:18.980</a></span> | <span class="t">similar kind of approach and as well, but actually they kind of proved that this, this way kind of works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2484" target="_blank">00:41:24.980</a></span> | <span class="t">Yeah. Thank you. I, I think that, I think that could probably be it. I think there's no way for it to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2490" target="_blank">00:41:30.900</a></span> | <span class="t">feasible to serve it at that scale. Uh, I think you're probably right. I, I don't know. I, I didn't see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2498" target="_blank">00:41:38.020</a></span> | <span class="t">anything in the original paper that actually suggest us that. Um, but I, I, I think you're right. That's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2503" target="_blank">00:41:43.380</a></span> | <span class="t">there's just no way for it to serve it at scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2506" target="_blank">00:41:46.100</a></span> | <span class="t">Yeah. So I checked you in this thread. Maybe, maybe I can,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2512" target="_blank">00:41:52.820</a></span> | <span class="t">I have the paper. Thank you. I, I don't, I added my safe list to confirm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2517" target="_blank">00:41:57.700</a></span> | <span class="t">Yeah. Yeah. Thanks. Thanks for explaining this. Just to double check. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2523" target="_blank">00:42:03.940</a></span> | <span class="t">Any other questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2528" target="_blank">00:42:08.980</a></span> | <span class="t">I mean, so, um, one thing that I tried to look for and I found myself doing, but I might as well ask the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2542" target="_blank">00:42:22.180</a></span> | <span class="t">pre-trained LLM, uh, that is you, uh, is to rank, um, what is highest, uh, you know, the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2550" target="_blank">00:42:30.980</a></span> | <span class="t">the lowest hanging fruit versus the higher ones. Um, so for example, right, you, the way that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2557" target="_blank">00:42:37.380</a></span> | <span class="t">organize your, at your write-up was four sections. It was model architecture, data generation, scaling laws,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2566" target="_blank">00:42:46.180</a></span> | <span class="t">and then unified architectures. Um, why there's no particular reason. There's no order, right? Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2573" target="_blank">00:42:53.780</a></span> | <span class="t">to me, it was very clear that model architecture is basically useless. Is that true? Would you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2578" target="_blank">00:42:58.340</a></span> | <span class="t">would you recommend? I don't think so. I actually think that, um, I think the model architecture right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2585" target="_blank">00:43:05.140</a></span> | <span class="t">now, it's like a little bit more like, um, you know, meters dilemma. Um, I would say that in 2023</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2591" target="_blank">00:43:11.860</a></span> | <span class="t">is useless. Um, I haven't seen good results. Now I'm seeing good results. Um, would you classify this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2598" target="_blank">00:43:18.420</a></span> | <span class="t">YouTube one as a good result? Because I was, I read it and I was like, wait, like this, I don't know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2603" target="_blank">00:43:23.300</a></span> | <span class="t">you know, like it's, these are smart ideas. And then the, then the results are like, uh, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2609" target="_blank">00:43:29.300</a></span> | <span class="t">doesn't, doesn't really outperform our baseline. I, I, I think it's decent results. Um, so, and, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2616" target="_blank">00:43:36.260</a></span> | <span class="t">coincidentally, after I published this, I think after I made the rounds on Hacker News, people from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2621" target="_blank">00:43:41.220</a></span> | <span class="t">YouTube actually reached out. One of the authors on this exact paper, I should reached out. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2625" target="_blank">00:43:45.540</a></span> | <span class="t">they wanted me to like go in and chat with them. Uh, and then they were like, we have more papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2630" target="_blank">00:43:50.580</a></span> | <span class="t">We're pushing to publish it. And this is a perennial problem, right? Especially for YouTube and TikTok,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2635" target="_blank">00:43:55.700</a></span> | <span class="t">right? Um, new videos get uploaded all the time. They have to deal with, costar is their bread and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2642" target="_blank">00:44:02.500</a></span> | <span class="t">butter. So I wouldn't be surprised that they are focusing so hard on content embeddings for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2647" target="_blank">00:44:07.460</a></span> | <span class="t">costar. This is for, for a new video, but not, I mean, they have users, uh, they have user histories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2654" target="_blank">00:44:14.740</a></span> | <span class="t">and they saturated the world on that. I think very likely. So, right. Um, you can imagine YouTube,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2662" target="_blank">00:44:22.420</a></span> | <span class="t">Twitter, I mean, it's unmentioned here, but ads, Google ads, it's always costar being able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2669" target="_blank">00:44:29.540</a></span> | <span class="t">crack this costar problem. Just even 0.1% is huge. It is huge. And you can see a lot of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2676" target="_blank">00:44:36.020</a></span> | <span class="t">papers in this semantic IDs, YouTube quite show, which is like TikTok. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2681" target="_blank">00:44:41.940</a></span> | <span class="t">Huawei, this one, I'm not very sure why they did this. Um, yeah, a lot of it, Kyle Rack also,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2687" target="_blank">00:44:47.060</a></span> | <span class="t">uh, solving costar. So yeah. Okay. But like, you know, orders of magnitude is, um, which takes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2697" target="_blank">00:44:57.700</a></span> | <span class="t">orders of magnitude. I really think that the low hanging fruit right now is really using LLM data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2702" target="_blank">00:45:02.260</a></span> | <span class="t">generation. Right. Yeah. That's my, yeah. I mean, obviously that is the, I think everyone can do this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2708" target="_blank">00:45:08.020</a></span> | <span class="t">now. And you know, the expected bad match paper, um, indeed did, right. I actually did this, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2714" target="_blank">00:45:14.820</a></span> | <span class="t">last year, something very similar. I did this last year. Uh, it got published internally. This is very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2721" target="_blank">00:45:21.300</a></span> | <span class="t">very, very, very, very, very effective. This approach of, um, starting from somewhere active</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2727" target="_blank">00:45:27.620</a></span> | <span class="t">learning, fine tuning model, more active learning. It really helps, uh, uh, improve quality. Um, I was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2734" target="_blank">00:45:34.180</a></span> | <span class="t">doing it in the context of LLM and hallucinations, but I can imagine doing this in terms of relevance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2739" target="_blank">00:45:39.780</a></span> | <span class="t">in terms of any level of measure of quality that you want to focus on, it will work very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2744" target="_blank">00:45:44.580</a></span> | <span class="t">Okay. Um, and then of course, yeah. Then architecture. I would say data generation and then like model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2752" target="_blank">00:45:52.420</a></span> | <span class="t">architecture and system architecture. Yeah. Oh, wait, actually the, the, even the scaling loss part,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2757" target="_blank">00:45:57.460</a></span> | <span class="t">there are some things that are very, uh, practical. Um, one example is, which I didn't have time to go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2763" target="_blank">00:46:03.860</a></span> | <span class="t">through is this, um, basically Laura's for recommendation. So what they did is they train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2771" target="_blank">00:46:11.460</a></span> | <span class="t">a single model on all domain data. You can imagine all domain, like fashion, e-commerce, uh, fashion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2778" target="_blank">00:46:18.580</a></span> | <span class="t">furniture, toys, et cetera. Or it could be like all domain, like ads, videos, uh, e-commerce. And then after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2786" target="_blank">00:46:26.340</a></span> | <span class="t">that they have specific LoRa's for each domain. Um, and this works very well. So I, I, I definitely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2794" target="_blank">00:46:34.900</a></span> | <span class="t">think that essentially right now it's not easy to learn from data across domains for recommendation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2802" target="_blank">00:46:42.260</a></span> | <span class="t">system. It's actually for recommendation system. And, you know, correct me if I'm wrong. I really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2805" target="_blank">00:46:45.700</a></span> | <span class="t">think that you want to overfit on your domain. Um, you want to overfit and predict the next best thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2811" target="_blank">00:46:51.540</a></span> | <span class="t">for tomorrow. And that's it, period. I, I can overfit and just retrain every day. Um, but yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2816" target="_blank">00:46:56.820</a></span> | <span class="t">I know we have a few questions here. Uh, Daniel asks, shouldn't the LinkedIn model combine with an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2822" target="_blank">00:47:02.900</a></span> | <span class="t">information model that's used to generate? Yes, correct. Um, that's probably an upstream, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2828" target="_blank">00:47:08.660</a></span> | <span class="t">retrieval model. And then the LinkedIn model just does the ranking. So in a two-step process,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2834" target="_blank">00:47:14.020</a></span> | <span class="t">you have a retrieval, the LinkedIn, the decoder model, I think it just does the ranking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2838" target="_blank">00:47:18.180</a></span> | <span class="t">Um, for LM-based search retrieval, any papers talk about impact of query writing prompt engineering?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2844" target="_blank">00:47:24.020</a></span> | <span class="t">Also the sensitivity. Uh, I think we know that LMs are, are sensitive to prompts, but I think they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2849" target="_blank">00:47:29.700</a></span> | <span class="t">increasingly less sensitive to prompts, uh, because they're just way more instruction tuned. Um, I'm not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2855" target="_blank">00:47:35.220</a></span> | <span class="t">sure about LM papers that talk about the power, the impact of query writing. I think the only one that I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2859" target="_blank">00:47:39.620</a></span> | <span class="t">have seen at least covered here is the one by Yelp. Uh, so I think that could be helpful. What's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2865" target="_blank">00:47:45.460</a></span> | <span class="t">process for keeping this hybrid models up to date and personalization, uh, keeping them up to date.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2870" target="_blank">00:47:50.660</a></span> | <span class="t">That's a good question. I don't know if they actually need to be kept up to date. So if you look at the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2877" target="_blank">00:47:57.140</a></span> | <span class="t">if you look at this hybrid models, right, let's just take the, this, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2886" target="_blank">00:48:06.180</a></span> | <span class="t">semantic ID embedding, it actually uses a frozen video bird. Similarly for quite sure, they use frozen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2893" target="_blank">00:48:13.380</a></span> | <span class="t">sentence, but resnet and VGG ish. So the content itself doesn't mean to be up to date. And the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2900" target="_blank">00:48:20.100</a></span> | <span class="t">assumption is that, okay, content today is going to be the same as content. Tomorrow is going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2903" target="_blank">00:48:23.220</a></span> | <span class="t">same as content for one month. So that is not up to date, but what is learnable is the semantic ID</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2908" target="_blank">00:48:28.500</a></span> | <span class="t">embedding and a cluster embedding. Now for personalization, that's very interesting. Uh, that's the hard question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2913" target="_blank">00:48:33.220</a></span> | <span class="t">Right. And the personalization, I guess, how you include personalization is okay. After we learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2917" target="_blank">00:48:37.620</a></span> | <span class="t">the content, we also need to learn what the user is interested in. And that's how they have this two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2921" target="_blank">00:48:41.780</a></span> | <span class="t">tower approach. And that's why you can see over here, there's this small layer, uh, which is multimodal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2927" target="_blank">00:48:47.780</a></span> | <span class="t">interest intensity, right? Which is given a user and their past historical sequence. How can we tell what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2933" target="_blank">00:48:53.380</a></span> | <span class="t">layers are, what modality they're interested in? I think that's how they do personalization over here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2938" target="_blank">00:48:58.820</a></span> | <span class="t">Any other questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2941" target="_blank">00:49:01.700</a></span> | <span class="t">If not, we can always ask for volunteers for next week's session.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2948" target="_blank">00:49:08.180</a></span> | <span class="t">Anyone?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2959" target="_blank">00:49:19.220</a></span> | <span class="t">No, I think, I think this is, uh, really helpful. Uh, it just feels like rexys is always these,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2974" target="_blank">00:49:34.340</a></span> | <span class="t">like these bundles of ideas. Yeah. Like in the way that agents are bundles of ideas for LLMs, rexys was,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2984" target="_blank">00:49:44.420</a></span> | <span class="t">is also a bundle of ideas. And I, I think that they are obviously converging. Um, you don't, yeah, I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2992" target="_blank">00:49:52.020</a></span> | <span class="t">I, I, I definitely think so. Right. And you can see that you can see examples, right? We learned item</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=2998" target="_blank">00:49:58.580</a></span> | <span class="t">embeddings via word to back. You know, when people talk about graph embeddings, it's actually just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3002" target="_blank">00:50:02.260</a></span> | <span class="t">taking the graph, doing a random walk, converting that random walk into a sentence of item IDs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3006" target="_blank">00:50:06.500</a></span> | <span class="t">and just using word to back. Similarly learning the next best action, GRU is transformers and BERT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3012" target="_blank">00:50:12.500</a></span> | <span class="t">very obvious it will work. So I think we will see more from the LLM space being in, being adopted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3019" target="_blank">00:50:19.540</a></span> | <span class="t">in rexys as well. What is the link in your mind between re-rankers and rexys?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3028" target="_blank">00:50:28.900</a></span> | <span class="t">I think, so in rexys, we have, uh, retrieval and recommendation, right? Um, so you can see over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3040" target="_blank">00:50:40.740</a></span> | <span class="t">here, uh, where is it? So what we do over here is retrieval will retrieve a lot of top candidates. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3050" target="_blank">00:50:50.900</a></span> | <span class="t">going to retrieve a hundred candidates. And then ranking is going to find the best five candidates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3055" target="_blank">00:50:55.460</a></span> | <span class="t">You can focus on the best five. I think it's the same thing in retrieval and re-ranking, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3060" target="_blank">00:51:00.980</a></span> | <span class="t">in, in ranking and rexys. What people say in reg as re-ranking, I think it's just really just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3068" target="_blank">00:51:08.900</a></span> | <span class="t">taking retrieval and then finding the best five. And, you know, Cohear has re-rankers and finding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3073" target="_blank">00:51:13.220</a></span> | <span class="t">a best five for the LLM as part of the context. Yeah. It's, to me, it's a bit weird, right? Like, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3078" target="_blank">00:51:18.420</a></span> | <span class="t">the re-ranker models are being promoted as a way to just, you feed in your top K whatever results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3084" target="_blank">00:51:24.900</a></span> | <span class="t">And then they re-rank them. And somehow that is supposed to produce better rag because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3089" target="_blank">00:51:29.780</a></span> | <span class="t">the more relevant results is at the top, but without the context that rexys have, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3095" target="_blank">00:51:35.780</a></span> | <span class="t">user preferences and user histories and whatever, like, how can you have any useful re-ranking at all?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3101" target="_blank">00:51:41.300</a></span> | <span class="t">Right? Like, I think there are some ways. So for example, like maybe retrieval, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3104" target="_blank">00:51:44.660</a></span> | <span class="t">You can imagine the most naive retrieval is really just BM25 or, um, semantic search.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3110" target="_blank">00:51:50.420</a></span> | <span class="t">Now, then you can imagine you have a lot of historical data on all these BM25 and his, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3116" target="_blank">00:51:56.500</a></span> | <span class="t">semantic search and all the associated metadata, which you probably cannot use in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3120" target="_blank">00:52:00.340</a></span> | <span class="t">retrieval stage because it's too expensive. And then you can just train a re-ranker.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3123" target="_blank">00:52:03.380</a></span> | <span class="t">Just say that when the author match or this author usually looks for this kind of document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3129" target="_blank">00:52:09.220</a></span> | <span class="t">um, and then you can try to re-rank it. I think it's possible. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3133" target="_blank">00:52:13.460</a></span> | <span class="t">I haven't, I haven't dove too deep into how re-ranking is done for a rag, but it's possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3141" target="_blank">00:52:21.220</a></span> | <span class="t">Oh, Apulantia, you had a hand raise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3142" target="_blank">00:52:22.740</a></span> | <span class="t">Yeah, no. And thank you so much, Swix and Eugene. You guys are amazing. I'm huge fans of you both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3148" target="_blank">00:52:28.100</a></span> | <span class="t">But, um, I, with the question I had, I guess is, is it worthwhile for an organization to go and build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3154" target="_blank">00:52:34.340</a></span> | <span class="t">this when you have something like Gina.ai, who, as we know, popularized a lot of work on deep search and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3160" target="_blank">00:52:40.740</a></span> | <span class="t">not just internal retrieval, but external search and retrieval, because they have the embedding models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3165" target="_blank">00:52:45.860</a></span> | <span class="t">the re-rankers, the retrieving deep search APIs, all unified. Um, how do you feel about that, Eugene and Swix?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3173" target="_blank">00:52:53.220</a></span> | <span class="t">Should teams build them, build it themselves? Or should they just buy something off the shelf?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3178" target="_blank">00:52:58.740</a></span> | <span class="t">Yeah, like Gina.ai has kind of this full stack that you're talking about with all these fine-tuned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3183" target="_blank">00:53:03.780</a></span> | <span class="t">clip models, embedding models, re-rankers. They have the deep search retrieval. There's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3188" target="_blank">00:53:08.980</a></span> | <span class="t">they've posted probably some of the better technical blogs on deep search. I think that's out right now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3194" target="_blank">00:53:14.500</a></span> | <span class="t">and embedding models and re-rank. Yeah, my answer is going to be probably very boring and you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3199" target="_blank">00:53:19.460</a></span> | <span class="t">apply it to any answer, whether they should, someone should use an LMP off the shelf or just finding a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3204" target="_blank">00:53:24.100</a></span> | <span class="t">model. I think that for prototyping, just do whatever is fast, right? Demonstrate user value. It's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3210" target="_blank">00:53:30.340</a></span> | <span class="t">to get to a point in time where what you need does not fit, um, what something off the shelf is going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3217" target="_blank">00:53:37.060</a></span> | <span class="t">do. Um, and that's what, um, that's, uh, Indeed's story, right? For expected bad match. Latency</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3227" target="_blank">00:53:47.460</a></span> | <span class="t">continued to be too high. Even if they need to be too high, the only way to fine-tune your own model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3233" target="_blank">00:53:53.620</a></span> | <span class="t">Similarly, like for retrieval, you can imagine, okay, they're going to provide a lot of out-of-the-box</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3238" target="_blank">00:53:58.340</a></span> | <span class="t">embeddings and maybe it's going to be good enough. And then finally, you want to really squeeze more juice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3243" target="_blank">00:54:03.540</a></span> | <span class="t">out. You probably need to go fine-tune your own embeddings. I know like Replit recently such</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3247" target="_blank">00:54:07.380</a></span> | <span class="t">shared something about fine-tuning their own embeddings, half the size, et cetera, et cetera,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3250" target="_blank">00:54:10.660</a></span> | <span class="t">and it does way better. Um, there are a lot of examples here. I think Etsy also fine-tune their own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3254" target="_blank">00:54:14.820</a></span> | <span class="t">embeddings, um, and it outperform embeddings out of the box. I think it's a little bit of unfair</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3261" target="_blank">00:54:21.140</a></span> | <span class="t">comparison. I think if you take those models, those embedding models and you further fine-tune them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3265" target="_blank">00:54:25.700</a></span> | <span class="t">I think they could do better, but essentially point by just use us off the shelf to move fast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3270" target="_blank">00:54:30.820</a></span> | <span class="t">and then just, and then after that, if you do need to customize it, then you customize it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3276" target="_blank">00:54:36.180</a></span> | <span class="t">I love it. Thank you so much. Super helpful. You're welcome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3279" target="_blank">00:54:39.460</a></span> | <span class="t">Sorry, we have a question. Let's go ahead. And I think this is probably my last question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3289" target="_blank">00:54:49.540</a></span> | <span class="t">Okay. Uh, what do you think of the, uh, biggest opportunity in terms of for, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3294" target="_blank">00:54:54.820</a></span> | <span class="t">apply IOM in recommendation domain because we're discussing in ritual,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3298" target="_blank">00:54:58.900</a></span> | <span class="t">ranking, content understanding, etc., right? There are so many different prediction tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3304" target="_blank">00:55:04.500</a></span> | <span class="t">You're asking me what I think is the big opportunity?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3312" target="_blank">00:55:12.100</a></span> | <span class="t">Is that your question? Yeah. Uh, I think, I think embeddings, I think what I've seen is that embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3320" target="_blank">00:55:20.900</a></span> | <span class="t">are helpful for retrieval. So instead of purely keyword retrieval, like, and killer, someone might,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3326" target="_blank">00:55:26.260</a></span> | <span class="t">might just ask, I have ants in my house. I think a semantic embedding could be able to help you match</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3332" target="_blank">00:55:32.100</a></span> | <span class="t">that. Um, and I think ranking is definitely clearly, uh, it will clearly work, uh, using an LLM-based ranker.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3339" target="_blank">00:55:39.460</a></span> | <span class="t">I think LinkedIn actually really could clearly, can clearly work. And of course for search, I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3344" target="_blank">00:55:44.100</a></span> | <span class="t">there's this card, this guy, Doc Turnbull, um, he's going, increasingly going down the route of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3350" target="_blank">00:55:50.100</a></span> | <span class="t">and we've seen examples from Yelp, right? Using an LLM to do query, uh, segmentation, query expansion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3356" target="_blank">00:55:56.980</a></span> | <span class="t">query rewriting. It clearly works in Yelp's use case and you can just catch all these results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3362" target="_blank">00:56:02.740</a></span> | <span class="t">So those are the three things I, off the top of my head that I can't think of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3368" target="_blank">00:56:08.740</a></span> | <span class="t">Okay. Thank you, everyone. I do need to drop. Maybe you can discuss what the next paper is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3373" target="_blank">00:56:13.220</a></span> | <span class="t">Maybe Swix will talk about Moore's Law for AI every seven months, which I think is interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3377" target="_blank">00:56:17.540</a></span> | <span class="t">No, not on the image generation, autoregressive image generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3381" target="_blank">00:56:21.300</a></span> | <span class="t">Okay. All right. Bye. Bye. Bye. Bye. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3385" target="_blank">00:56:25.300</a></span> | <span class="t">Thank you, everyone. Take care.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YxpwskHTtkc&t=3386" target="_blank">00:56:26.580</a></span> | <span class="t">Thank you. Thank you.</span></div></div></body></html>