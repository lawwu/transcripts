<html><head><title>Netflix's Big Bet: One model to rule recommendations: Yesu Feng, Netflix</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Netflix's Big Bet: One model to rule recommendations: Yesu Feng, Netflix</h2><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ"><img src="https://i.ytimg.com/vi_webp/AbZ4IYGbfpQ/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./AbZ4IYGbfpQ.html">Whisper Transcript</a> | <a href="./transcript_AbZ4IYGbfpQ.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">good afternoon thank you Eugene for the introduction so today I'm going to share</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=22" target="_blank">00:00:22.200</a></span> | <span class="t">our big bet and Netflix on personalization namely to use one foundation model to cover</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=28" target="_blank">00:00:28.080</a></span> | <span class="t">all the recommendation use cases and Netflix we have diverse recommendation needs this is an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=36" target="_blank">00:00:36.360</a></span> | <span class="t">example homepage of one node profile on Netflix it's a 2d layout roles and items diversity comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=45" target="_blank">00:00:45.780</a></span> | <span class="t">at at least the three levels there is first level about role we have diverse roles we have a young</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=53" target="_blank">00:00:53.100</a></span> | <span class="t">runs for example roles on comedies roles on action movies we have roles about new trending just the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=61" target="_blank">00:01:01.080</a></span> | <span class="t">release titles we also have a rose about for example titles only available on Netflix so that's the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=68" target="_blank">00:01:08.760</a></span> | <span class="t">dimension second dimension is of course of the items or entities in addition to traditionally movie and TV</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=76" target="_blank">00:01:16.380</a></span> | <span class="t">shows now we have games we have live streaming and we're going to add more so our content space is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=83" target="_blank">00:01:23.660</a></span> | <span class="t">expanding to very heterogeneous content types the third level is page so we have home page we have search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=94" target="_blank">00:01:34.640</a></span> | <span class="t">page we have a kids home page which is tailored very differently to what kids interest mobile feed is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=102" target="_blank">00:01:42.600</a></span> | <span class="t">linear page is not a 2d layout so on and so forth so page different pages are also very diverse what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=109" target="_blank">00:01:49.880</a></span> | <span class="t">happened traditionally was that these lead to naturally many specialized models that get developed over the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=119" target="_blank">00:01:59.320</a></span> | <span class="t">years some models rank videos some rank rows some focus on for example shows user have not watched yet some focus on shows was a user are already engaging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=131" target="_blank">00:02:11.880</a></span> | <span class="t">and many of those models are were built independently over the years they may have different objectives but have a lot of overlaps as well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=141" target="_blank">00:02:21.880</a></span> | <span class="t">as well so naturally this lead to duplications duplications in our label engineering as well as feature engineering take the feature engineering as example we have this very commonly used the factual data about user intact and history</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=161" target="_blank">00:02:41.160</a></span> | <span class="t">uh the the the factual data is the same but over the years many features are developed derived out of the same facts data like counts of different actions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=171" target="_blank">00:02:51.160</a></span> | <span class="t">counts of actions within various time window or other kind of uh slice and dice dimensions similarity between the users history titles against the target titles unique</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=183" target="_blank">00:03:03.160</a></span> | <span class="t">and lastly like uh lastly like uh just a sequence of unique show ids uh to be used as a sequence feature into the model so this list can go on and on and on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=193" target="_blank">00:03:13.160</a></span> | <span class="t">and a lot of those features uh because they are developed independently into each model they have slight variations but become very but largely uh very similar so become very hard to uh maintain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=205" target="_blank">00:03:25.160</a></span> | <span class="t">so the challenge the challenge the challenge back then was uh is this scalable uh obviously not if we keep expanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=215" target="_blank">00:03:35.160</a></span> | <span class="t">our landscape of our landscape of content type or business use cases it's not manageable to spin up new models for each uh individual use cases</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=225" target="_blank">00:03:45.160</a></span> | <span class="t">uh there's not much leverage uh there's some shared components on building the feature label but still by and large each model uh basically uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=235" target="_blank">00:03:55.160</a></span> | <span class="t">uh spinned up independently and that also impact our innovation velocity in in the terms that you don't reuse as much as you can instead you just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=245" target="_blank">00:04:05.160</a></span> | <span class="t">spin up new models uh pretty much from scratch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=249" target="_blank">00:04:09.160</a></span> | <span class="t">uh so this was the situation about four years ago uh at the beginning or middle of the pandemic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=255" target="_blank">00:04:15.400</a></span> | <span class="t">so the question we asked at that time was uh can we centralize the learning of user representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=261" target="_blank">00:04:21.720</a></span> | <span class="t">in one place so the answer is yes and we had this key hypothesis that about foundation model based on transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=271" target="_blank">00:04:31.480</a></span> | <span class="t">architecture uh concretely two hypotheses here one hypothesis is that through scaled up semi-supervised learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=278" target="_blank">00:04:38.360</a></span> | <span class="t">personalization can be improved uh the scaling law also applies to recommendation system as it applies to llm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=286" target="_blank">00:04:46.040</a></span> | <span class="t">second is that by integrating the foundation model into all systems we can create high leverage we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=291" target="_blank">00:04:51.880</a></span> | <span class="t">simultaneously improve all the downstream canvas facing models at the same time so we'll see in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=299" target="_blank">00:04:59.080</a></span> | <span class="t">following slides how we validate those hypotheses uh i'll break up the overview into two subsessions first about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=307" target="_blank">00:05:07.640</a></span> | <span class="t">data data data and training and the later uh second about application and serving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=312" target="_blank">00:05:12.280</a></span> | <span class="t">so um about data and training so starting from data a very interesting aspect of a building such foundation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=320" target="_blank">00:05:20.120</a></span> | <span class="t">model auto regressive transformer is that there's a lot of analogy but also differences sometimes uh between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=327" target="_blank">00:05:27.400</a></span> | <span class="t">this and llm so we can transfer a lot of learnings inspirations from llm development if we start from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=337" target="_blank">00:05:37.400</a></span> | <span class="t">very bottom layer which is basically data cleaning and tokenization people work with llm understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=343" target="_blank">00:05:43.960</a></span> | <span class="t">tokenization decisions have profound impact in your model quality so although it's the bottom layer the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=352" target="_blank">00:05:52.120</a></span> | <span class="t">decision you made there can percolate through all the downstream layers and manifest as either your model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=357" target="_blank">00:05:57.160</a></span> | <span class="t">quality problem or model quality plus so this applies to recommendation uh foundation model as well instead of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=366" target="_blank">00:06:06.520</a></span> | <span class="t">uh there are some differences very importantly instead of language tokens which is just one id here for uh if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=373" target="_blank">00:06:13.800</a></span> | <span class="t">we want to translate the user interaction history or sequence each of the token is a event interaction event</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=381" target="_blank">00:06:21.720</a></span> | <span class="t">from the user right but that event has many facets or many fields so it's not just the one id you can represent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=387" target="_blank">00:06:27.320</a></span> | <span class="t">there are a lot of rich information about the event so how you all of those fields can play a role in making the decision of tokenization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=396" target="_blank">00:06:36.120</a></span> | <span class="t">uh i think that's what we need to consider very carefully um what is the granularity of tokenization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=403" target="_blank">00:06:43.320</a></span> | <span class="t">and trade off that versus the context window for example um and through many iterations we reach the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=409" target="_blank">00:06:49.320</a></span> | <span class="t">right i think reach the right abstraction and interfaces that we can use to uh adjust our tokenization to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=416" target="_blank">00:06:56.680</a></span> | <span class="t">different use cases for example you can imagine we have a token at one version of tokenization used for pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=422" target="_blank">00:07:02.040</a></span> | <span class="t">for fine-tuning against a specific application we apply slightly different tokenization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=426" target="_blank">00:07:06.760</a></span> | <span class="t">um so moving up from the tokenization layer then becomes the model layers uh at high level</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=438" target="_blank">00:07:18.200</a></span> | <span class="t">uh from bottom to top we go through the uh event representation embedding layer transformer layer and the objective layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=448" target="_blank">00:07:28.200</a></span> | <span class="t">uh so event representation as we just briefly touched upon uh many information in the event about a high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=456" target="_blank">00:07:36.200</a></span> | <span class="t">level you can break it down by when where and what when that even happened that's about timing coding and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=463" target="_blank">00:07:43.640</a></span> | <span class="t">where it happened it's about a physical location your locale country so and so forth but also about device</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=469" target="_blank">00:07:49.080</a></span> | <span class="t">about the uh canvas or which row which page this action happened uh and then uh what basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=477" target="_blank">00:07:57.880</a></span> | <span class="t">is about the target entity or the title which title you interacted with what is the interaction how long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=484" target="_blank">00:08:04.760</a></span> | <span class="t">and uh any that kind of information associated with the action so um that's where the we need to decide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=493" target="_blank">00:08:13.480</a></span> | <span class="t">what information we need to keep what we should drop so on and so forth uh moving one layer above uh the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=500" target="_blank">00:08:20.440</a></span> | <span class="t">embedding feature transformation layer uh one thing that needs to be pointed out is that for recommendation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=506" target="_blank">00:08:26.760</a></span> | <span class="t">we need to combine id embedding learning with other semantic content information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=511" target="_blank">00:08:31.800</a></span> | <span class="t">if you only have id embedding learn from scratch in the model then you have problem with costar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=517" target="_blank">00:08:37.720</a></span> | <span class="t">meaning that titles the model hasn't seen during training it doesn't know how to deal with it at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=523" target="_blank">00:08:43.000</a></span> | <span class="t">inference time so we need to have semantic content information to be a comp complementary to those id embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=532" target="_blank">00:08:52.280</a></span> | <span class="t">this is not a problem for llm but very commonly encountered a costar problem for rec recommendation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=537" target="_blank">00:08:57.480</a></span> | <span class="t">system uh transformer layer i think there's no need to talk too much into this in terms of architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=543" target="_blank">00:09:03.880</a></span> | <span class="t">choices optimization so on and so forth the only thing that i want to point out is that uh we are using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=550" target="_blank">00:09:10.280</a></span> | <span class="t">the hidden state output from this layer as our user representation which is one of the primary goal of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=555" target="_blank">00:09:15.880</a></span> | <span class="t">the foundation model is to learn a good long-term user representation then uh we need to put this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=562" target="_blank">00:09:22.040</a></span> | <span class="t">into context then things to consider are for example how stable is our user user representation given</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=568" target="_blank">00:09:28.280</a></span> | <span class="t">our user profile user interaction history keep changing how do we guarantee or maintain the stability of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=573" target="_blank">00:09:33.960</a></span> | <span class="t">their representation and what kind of aggregation we should use you can think of broadly aggregate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=579" target="_blank">00:09:39.880</a></span> | <span class="t">across the time dimension in terms of sequence dimension or aggregate uh across the layers you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=587" target="_blank">00:09:47.080</a></span> | <span class="t">multiple self-attention layer how do you aggregate that um and then lastly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=591" target="_blank">00:09:51.880</a></span> | <span class="t">do we need to do explicit adaptation of the representation based on our downstream objective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=597" target="_blank">00:09:57.240</a></span> | <span class="t">to fine tune it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=598" target="_blank">00:09:58.120</a></span> | <span class="t">so then we move to last uh the very top layer uh objective loss function this is also very interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=606" target="_blank">00:10:06.680</a></span> | <span class="t">in the sense that it's much richer than llm because you can see first we use uh instead of one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=612" target="_blank">00:10:12.600</a></span> | <span class="t">sequence but multiple sequence to represent the output because you can have a sequence of entity ids</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=619" target="_blank">00:10:19.000</a></span> | <span class="t">that's your like uh next token prediction softmax or sample softmax but then we have many many other facets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=627" target="_blank">00:10:27.400</a></span> | <span class="t">of field of each event that can be also used as a target okay so it could be for things like uh action</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=634" target="_blank">00:10:34.520</a></span> | <span class="t">type it could be some aspect of the entities metadata like entity type young round language so on and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=640" target="_blank">00:10:40.280</a></span> | <span class="t">forth and also about your action like the prediction of the duration or uh the device where the action</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=647" target="_blank">00:10:47.000</a></span> | <span class="t">happened or the time when the next uh user play will happen so those are all legitimate targets or labels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=655" target="_blank">00:10:55.880</a></span> | <span class="t">depends on your use case you can use them to do the fine tuning now instead of so you can cast the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=660" target="_blank">00:11:00.840</a></span> | <span class="t">problem as a multi-task learning problem multi-head or hierarchical prediction but you can also use them just as your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=668" target="_blank">00:11:08.440</a></span> | <span class="t">your weights your rewards or your mask on the loss function so in terms of to adapt the model to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=674" target="_blank">00:11:14.120</a></span> | <span class="t">zooming into one subcategory of uh user behavior you want to you want the model to learn okay so that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=681" target="_blank">00:11:21.720</a></span> | <span class="t">about the model architecture that i want to talk about um so does it scale the first question a part of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=690" target="_blank">00:11:30.680</a></span> | <span class="t">first hypothesis we want to answer is that does a school a scaling law apply and i think the answer is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=695" target="_blank">00:11:35.880</a></span> | <span class="t">yes so this is over the uh roughly two to two to two and a half a years we were scaling up and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=704" target="_blank">00:11:44.120</a></span> | <span class="t">constantly still see the gain uh from only on the order of 10 million profile or a few million profile to now on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=712" target="_blank">00:11:52.840</a></span> | <span class="t">the order of one billion uh model parameters we scale up for the data accordingly um now we stop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=721" target="_blank">00:12:01.720</a></span> | <span class="t">here because we can still keep going but uh as you may realize that recommendation system usually have much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=729" target="_blank">00:12:09.080</a></span> | <span class="t">stringent latency cost requirement so scaling up scaling up more requires to also distill back yeah but certainly i think this is not the end of the scaling law</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=740" target="_blank">00:12:20.840</a></span> | <span class="t">uh before we're wrapping up the data and training session uh discussion i would like to highlight some of the learnings i think quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=746" target="_blank">00:12:26.840</a></span> | <span class="t">interesting we borrow from llm this is not exhaustive list but uh i think very interesting to me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=754" target="_blank">00:12:34.360</a></span> | <span class="t">uh the top three one is multi-token prediction you may have seen this in the deep seek paper so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=760" target="_blank">00:12:40.520</a></span> | <span class="t">and so forth so you get uh implementation wise you can use multi-head multi-label so and uh different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=766" target="_blank">00:12:46.360</a></span> | <span class="t">implementation flavor but the goal is really to force the model to be less mild</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=770" target="_blank">00:12:50.760</a></span> | <span class="t">biopic more robust to serving time shift because you have a time gap between your training and serving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=776" target="_blank">00:12:56.680</a></span> | <span class="t">and also force the model to targets long-term user satisfaction and long-term user behavior instead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=782" target="_blank">00:13:02.920</a></span> | <span class="t">of just focus on next action i we have observed in a very notable uh metrics improvement by doing that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=791" target="_blank">00:13:11.400</a></span> | <span class="t">uh the second is multi-layer representation which i touched upon on the profile representation so this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=797" target="_blank">00:13:17.480</a></span> | <span class="t">is also translated from llm aside of techniques of layer wise supervision self-distillation or multi-layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=804" target="_blank">00:13:24.200</a></span> | <span class="t">output aggregation the goal here is really to make a better and more stable user representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=810" target="_blank">00:13:30.680</a></span> | <span class="t">lastly uh this is also should be no surprise long context window handling from truncated sliding window</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=817" target="_blank">00:13:37.240</a></span> | <span class="t">to sparse attention to progressively training uh longer and longer sequences uh to eventually all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=824" target="_blank">00:13:44.440</a></span> | <span class="t">the parallelism strategies so this is about more efficient training and maximize the learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=831" target="_blank">00:13:51.640</a></span> | <span class="t">okay so uh shift gear to talk about the serving and applications uh before the foundation model fm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=838" target="_blank">00:13:58.360</a></span> | <span class="t">this is a roughly the algo stack we have for personalization many data many features many models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=845" target="_blank">00:14:05.800</a></span> | <span class="t">independently developed each serving multiple or one canvases or applications we call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=851" target="_blank">00:14:11.160</a></span> | <span class="t">now with the foundation model we consolidate largely the data and representation layer especially the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=859" target="_blank">00:14:19.400</a></span> | <span class="t">representation as well as content representation in the personalization domain model layer as well because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=867" target="_blank">00:14:27.080</a></span> | <span class="t">model now each application model now are built on top of fm so become a thinner layer instead of a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=873" target="_blank">00:14:33.400</a></span> | <span class="t">standalone full-fledged model trained from scratch so how do the various models utilize the foundation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=879" target="_blank">00:14:39.960</a></span> | <span class="t">model there are three main approaches or consumption patterns the first is foundation model can be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=887" target="_blank">00:14:47.720</a></span> | <span class="t">integrated as a sub graph within the downstream model additionally the content embeddings learned from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=893" target="_blank">00:14:53.320</a></span> | <span class="t">foundation model can be integrated as the embedding lookup layers so downstream model is a newer network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=898" target="_blank">00:14:58.680</a></span> | <span class="t">it may already have initially some of the sequence transformer tower or graph and then using a pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=910" target="_blank">00:15:10.440</a></span> | <span class="t">foundation model model sub graph to directly replace that uh second is that uh we can push out embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=917" target="_blank">00:15:17.720</a></span> | <span class="t">this is no surprise from both content side and entity embedding as well as member embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=922" target="_blank">00:15:22.600</a></span> | <span class="t">uh the only uh the main concern here of course is how we want to ref how frequently we want to refresh the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=929" target="_blank">00:15:29.480</a></span> | <span class="t">member embeddings and how we make sure they are stable uh and push them to the centralized embedding store and this of course allow far more uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=938" target="_blank">00:15:38.840</a></span> | <span class="t">uh wider use cases than just personalization because people analytics data scientists can also just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=945" target="_blank">00:15:45.880</a></span> | <span class="t">fetch those embeddings directly to do the things that they want finally user can uh extract the models and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=955" target="_blank">00:15:55.000</a></span> | <span class="t">fine-tune it for specific applications either fine-tune or they need to do distillation to meet the online</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=961" target="_blank">00:16:01.240</a></span> | <span class="t">serving requirement especially for those with very strict latency requirement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=967" target="_blank">00:16:07.080</a></span> | <span class="t">to wrap up uh i want to show at high level the wings we accumulated over the last one year and a half</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=975" target="_blank">00:16:15.480</a></span> | <span class="t">by incorporating fm into various places so the blue bar represent how many applications have fm incorporated the green bar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=986" target="_blank">00:16:26.440</a></span> | <span class="t">represent the a b test wings because in any application we may have multiple a b tests going on there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=992" target="_blank">00:16:32.680</a></span> | <span class="t">to have wings so we see we indeed see high leverage of fm to bring about both a b test wings as well as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1000" target="_blank">00:16:40.360</a></span> | <span class="t">infrastructure consolidation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1004" target="_blank">00:16:44.520</a></span> | <span class="t">uh so i think the big back uh big bets are validated uh it is a scalable solution uh in terms of both in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1011" target="_blank">00:16:51.880</a></span> | <span class="t">terms of a scalable scaled up the model with improved quality as well as making the whole infra consolidated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1019" target="_blank">00:16:59.080</a></span> | <span class="t">and the scale uh to new applications to be much easier high leverage because it's a centralized learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1025" target="_blank">00:17:05.960</a></span> | <span class="t">innovation velocity also is faster because we allow a lot of newly launched applications to directly fine-tune</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1033" target="_blank">00:17:13.880</a></span> | <span class="t">the foundation model to launch the first experience</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1036" target="_blank">00:17:16.760</a></span> | <span class="t">so the current directions one is that um we want to have universal representation for heterogeneous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1046" target="_blank">00:17:26.600</a></span> | <span class="t">entities this is uh as you can guess the semantic id and along those lines because we want to cover that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1052" target="_blank">00:17:32.680</a></span> | <span class="t">as netflix expanding to very different very heterogeneous content types second is generative retrieval for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1061" target="_blank">00:17:41.080</a></span> | <span class="t">collection recommendation right so instead of just recommending a single video be generative at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1065" target="_blank">00:17:45.240</a></span> | <span class="t">inference time and serving time because you have a modest step decoding a lot of the consideration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1071" target="_blank">00:17:51.000</a></span> | <span class="t">about business business rules or diversity for example can be naturally handled in the decoding process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1076" target="_blank">00:17:56.520</a></span> | <span class="t">lastly faster adaptation through prompt tuning so this is also borrowed from llm can we just train some soft tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1085" target="_blank">00:18:05.080</a></span> | <span class="t">uh so that at inference time we can directly swap in and out of those soft tokens to prompt the fm to behave differently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1092" target="_blank">00:18:12.280</a></span> | <span class="t">so that is also a very promising direction that we are getting into all right that concludes my talk thank you for your attention and questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1105" target="_blank">00:18:25.240</a></span> | <span class="t">thank you um if you have any questions may i invite you to come to the mic in front um while we get our next speakers from mr kata get set up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1115" target="_blank">00:18:35.640</a></span> | <span class="t">uh hi thank you for the talk uh since you get billions of users so except the recommendation system you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1125" target="_blank">00:18:45.320</a></span> | <span class="t">you're maybe you're maybe you can do much more right so what's your cloud on that since i can just ask you to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1132" target="_blank">00:18:52.120</a></span> | <span class="t">to predict who's the next president in the united states thank you um so i actually don't uh could you explain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1140" target="_blank">00:19:00.280</a></span> | <span class="t">a little bit what do you mean by beyond recommendation do you mean the other personalization or other things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1145" target="_blank">00:19:05.000</a></span> | <span class="t">um yeah yeah since you get kind of beating users preference so actually that that that preference is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1153" target="_blank">00:19:13.720</a></span> | <span class="t">also been linked to what things they're buying or who they will vote for the next president so do you think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1160" target="_blank">00:19:20.200</a></span> | <span class="t">your foundation model has that capability to expand not only recommendation what videos they want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1165" target="_blank">00:19:25.800</a></span> | <span class="t">look but what others they like or what's their opinions on anything else thank you yes so i think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1172" target="_blank">00:19:32.280</a></span> | <span class="t">we are expanding to different uh i think entity type and also capture uh users taste from both on and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1180" target="_blank">00:19:40.760</a></span> | <span class="t">off our platform i think that's a general trend that we're going to yes great thank you this was really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1190" target="_blank">00:19:50.040</a></span> | <span class="t">helpful um question on and you might not be able to share it um for ipv reasons but whatever you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1195" target="_blank">00:19:55.640</a></span> | <span class="t">thoughts on graph models didn't i didn't hear a lot of that in your talks graphs and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1201" target="_blank">00:20:01.880</a></span> | <span class="t">uh reinforcement learning any utilization there any benefits you saw any boost in performance and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1207" target="_blank">00:20:07.720</a></span> | <span class="t">accuracy yeah that's a good question i think we have actually uh a dedicated team sub team doing graph</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1215" target="_blank">00:20:15.160</a></span> | <span class="t">model uh especially around our knowledge graph to cover the content space both on and off our platform in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1222" target="_blank">00:20:22.200</a></span> | <span class="t">the whole entire entertainment ecosystem so we use actually a lot of embeddings for example from the graph</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1229" target="_blank">00:20:29.800</a></span> | <span class="t">graph model to co-start that's where i see i show those semantic embeddings that's where it comes from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1235" target="_blank">00:20:35.960</a></span> | <span class="t">in terms of reinforcement learning yes as well especially where we consider sparse reward that we have on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1242" target="_blank">00:20:42.760</a></span> | <span class="t">users from users action are pretty much sparse but we want to use them to guide how for example we generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1250" target="_blank">00:20:50.040</a></span> | <span class="t">the whole collection that's where we need to the whole collection that's where we need to consider how to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1254" target="_blank">00:20:54.120</a></span> | <span class="t">those reward to guide those uh process yeah i think one more question i'm sorry can i ask a two-part question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1262" target="_blank">00:21:02.600</a></span> | <span class="t">sure i would be here and so we can also follow up yeah do you also use these unified representations as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1269" target="_blank">00:21:09.400</a></span> | <span class="t">embedding features to downstream models you had a slide how you use the unified model yeah so uh the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1278" target="_blank">00:21:18.280</a></span> | <span class="t">we so for the embeddings learning within our model we also expose the downstream to do and consume them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1285" target="_blank">00:21:25.400</a></span> | <span class="t">uh we also have able to train our unified embedding we also have some upstream like just the for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1293" target="_blank">00:21:33.320</a></span> | <span class="t">the gn embeddings that those are also consumed to to do that last one is it fast yes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1301" target="_blank">00:21:41.480</a></span> | <span class="t">uh hello uh in your embeddings are you just using when someone does an action or sorry for the in these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1311" target="_blank">00:21:51.560</a></span> | <span class="t">embeddings you're just using metadata over the video to understand what they like or are you actually using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1316" target="_blank">00:21:56.200</a></span> | <span class="t">like frame by frame of the video or second clips uh not yet we do have that from some other content group of our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1326" target="_blank">00:22:06.040</a></span> | <span class="t">or organization but i think the trend will go there so we are not yet uh into very granular sub</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1332" target="_blank">00:22:12.360</a></span> | <span class="t">like clips level or view level we have those embeddings but not quite yet to incorporate yeah thank you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AbZ4IYGbfpQ&t=1338" target="_blank">00:22:18.680</a></span> | <span class="t">thank you yesu please another round of applause for yesu</span></div></div></body></html>