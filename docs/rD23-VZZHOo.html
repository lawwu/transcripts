<html><head><title>Serving Voice AI at $1/hr: Open-source, LoRAs, Latency, Load Balancing - Neil Dwyer, Gabber</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Serving Voice AI at $1/hr: Open-source, LoRAs, Latency, Load Balancing - Neil Dwyer, Gabber</h2><a href="https://www.youtube.com/watch?v=rD23-VZZHOo"><img src="https://i.ytimg.com/vi_webp/rD23-VZZHOo/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=0">0:0</a> Introduction to Gabber and Real-Time AI<br><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=135">2:15</a> Gabber's Mission for Consumer AI<br><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=257">4:17</a> The Orpheus Voice Model<br><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=343">5:43</a> Challenges in Voice Cloning<br><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=464">7:44</a> Latency Management and "Head of Line Silence"<br><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=667">11:7</a> Infrastructure for Batch Inference<br><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=696">11:36</a> Leveraging vLLM and Dynamic Quantization<br><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=801">13:21</a> Load Balancing with a Consistent Hash Ring<br><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=857">14:17</a> System Architecture Overview<br><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=907">15:7</a> Conclusion and Open Source Shout-outs<br><br><div style="text-align: left;"><a href="./rD23-VZZHOo.html">Whisper Transcript</a> | <a href="./transcript_rD23-VZZHOo.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">-</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=2" target="_blank">00:00:02.000</a></span> | <span class="t">- I'm Neil.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=15" target="_blank">00:00:15.860</a></span> | <span class="t">That's Jack in the front there, but it's just me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=19" target="_blank">00:00:19.160</a></span> | <span class="t">So yeah, we're really just gonna talk about our experience</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=22" target="_blank">00:00:22.800</a></span> | <span class="t">hosting Orpheus inference for our real-time stack.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=27" target="_blank">00:00:27.440</a></span> | <span class="t">So, I'm Neil.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=29" target="_blank">00:00:29.980</a></span> | <span class="t">I'm the CTO at a company called Gabber, a small startup.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=34" target="_blank">00:00:34.280</a></span> | <span class="t">But I spent a lot of my career doing real-time media stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=37" target="_blank">00:00:37.240</a></span> | <span class="t">so sending audio and video around the internet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=39" target="_blank">00:00:39.600</a></span> | <span class="t">Started at a company called Bebo,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=42" target="_blank">00:00:42.360</a></span> | <span class="t">was ultimately acquired by Amazon,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=43" target="_blank">00:00:43.800</a></span> | <span class="t">but there I was doing a lot of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=45" target="_blank">00:00:45.960</a></span> | <span class="t">we did like a game streaming app, kind of like OBS,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=48" target="_blank">00:00:48.940</a></span> | <span class="t">built a lot of the streaming infrastructure there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=51" target="_blank">00:00:51.800</a></span> | <span class="t">built a ML pipeline to watch people play video games,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=55" target="_blank">00:00:55.660</a></span> | <span class="t">so they would watch people play Fortnite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=57" target="_blank">00:00:57.020</a></span> | <span class="t">and put some cool effects on the screen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=59" target="_blank">00:00:59.020</a></span> | <span class="t">when they got a kill or a victory or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=61" target="_blank">00:01:01.600</a></span> | <span class="t">So I spent a lot of time in like the G-Streamer trenches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=64" target="_blank">00:01:04.320</a></span> | <span class="t">and with WebRTC and RTMP and all that stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=68" target="_blank">00:01:08.360</a></span> | <span class="t">Took a detour, worked at Uber for a couple years,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=70" target="_blank">00:01:10.640</a></span> | <span class="t">then left that, did a multiplayer gaming startup</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=75" target="_blank">00:01:15.320</a></span> | <span class="t">with my brother Jack here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=77" target="_blank">00:01:17.320</a></span> | <span class="t">So doing, basically trying to bring like AAA style multiplayer to web games,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=82" target="_blank">00:01:22.040</a></span> | <span class="t">so a lot of real, and with voice and stuff too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=83" target="_blank">00:01:23.620</a></span> | <span class="t">So there's a lot of real-time media slash real-time simulation kind of stuff there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=88" target="_blank">00:01:28.940</a></span> | <span class="t">And then yeah, we didn't do a super good job there and shut that company down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=95" target="_blank">00:01:35.320</a></span> | <span class="t">And we were using LiveKit, I made a LiveKit SDK and that segwayed to me working at LiveKit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=100" target="_blank">00:01:40.660</a></span> | <span class="t">I think a lot of people probably heard of LiveKit in this room.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=103" target="_blank">00:01:43.240</a></span> | <span class="t">And yeah, the second half of my time at LiveKit, I was spent doing the LiveKit agents platform.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=109" target="_blank">00:01:49.780</a></span> | <span class="t">So that's like the platform that was kind of born out of LiveKit's involvement with GPT voice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=114" target="_blank">00:01:54.860</a></span> | <span class="t">So yeah, wrote the first line of code on that and worked on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=118" target="_blank">00:01:58.300</a></span> | <span class="t">And then yeah, I left LiveKit and did another startup with my brother Gabber.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=122" target="_blank">00:02:02.780</a></span> | <span class="t">So that's what we're doing now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=125" target="_blank">00:02:05.560</a></span> | <span class="t">So Gabber is real-time, info for real-time, basically AI personas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=130" target="_blank">00:02:10.740</a></span> | <span class="t">So we have some core building blocks like voice, memory, video inputs coming soon, tool calling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=135" target="_blank">00:02:15.980</a></span> | <span class="t">kind of like the usual suspects, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=137" target="_blank">00:02:17.780</a></span> | <span class="t">But our focus is really on the consumer apps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=142" target="_blank">00:02:22.420</a></span> | <span class="t">We see the replacing human use cases pretty often, like the call center use cases, customer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=148" target="_blank">00:02:28.480</a></span> | <span class="t">support, AI, SDR, that kind of stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=151" target="_blank">00:02:31.740</a></span> | <span class="t">But our interest is really in the consumer space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=154" target="_blank">00:02:34.180</a></span> | <span class="t">We think these kind of like real-time synchronous AI experiences are going to be as ubiquitous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=159" target="_blank">00:02:39.980</a></span> | <span class="t">as websites and apps in the next kind of like two to five years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=163" target="_blank">00:02:43.020</a></span> | <span class="t">So that's our focus and that's how we try and differentiate in terms of opinion into our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=168" target="_blank">00:02:48.140</a></span> | <span class="t">product and our SDKs and APIs and stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=172" target="_blank">00:02:52.980</a></span> | <span class="t">Here are some of the use cases we're seeing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=174" target="_blank">00:02:54.940</a></span> | <span class="t">These are also kind of like the usual suspects, AI Girlfriends was the first one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=179" target="_blank">00:02:59.120</a></span> | <span class="t">That is like -- I'll get to why that's the first one, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=182" target="_blank">00:03:02.560</a></span> | <span class="t">But other ones are like AI NPCs, AI therapists, AI personal trainers, AI toys for kids.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=189" target="_blank">00:03:09.520</a></span> | <span class="t">I think that you saw that a couple of sessions ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=191" target="_blank">00:03:11.560</a></span> | <span class="t">These use cases, like we're seeing a lot of different use cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=193" target="_blank">00:03:13.560</a></span> | <span class="t">And I saw it at LiveKit, too, and it got me really, really excited about this stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=197" target="_blank">00:03:17.560</a></span> | <span class="t">But AI Girlfriends was the first one mainly because everything is so expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=204" target="_blank">00:03:24.000</a></span> | <span class="t">Some of these voice platforms, it's, you know, end-to-end upwards of $5 an hour and that doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=210" target="_blank">00:03:30.060</a></span> | <span class="t">really work for like 90% of the consumer apps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=213" target="_blank">00:03:33.000</a></span> | <span class="t">But AI Girlfriends, it works because like the users are paying like -- it's like usually like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=218" target="_blank">00:03:38.560</a></span> | <span class="t">a credit system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=219" target="_blank">00:03:39.560</a></span> | <span class="t">Like you buy credits and you use the app and it uses credit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=222" target="_blank">00:03:42.000</a></span> | <span class="t">So they're more comfortable with that kind of spend.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=224" target="_blank">00:03:44.440</a></span> | <span class="t">But most consumer use cases, they need something pretty close to free.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=228" target="_blank">00:03:48.440</a></span> | <span class="t">So we knew that -- and at the time, we were not hosting any voice models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=232" target="_blank">00:03:52.600</a></span> | <span class="t">But we knew we had to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=234" target="_blank">00:03:54.060</a></span> | <span class="t">We knew that the only way to really get this -- to execute on our vision of putting these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=238" target="_blank">00:03:58.400</a></span> | <span class="t">experiences everywhere, we had to start bringing more things in-house and running on our own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=242" target="_blank">00:04:02.500</a></span> | <span class="t">GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=244" target="_blank">00:04:04.700</a></span> | <span class="t">So at the time, open-source, there weren't a lot of good open-source voice models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=249" target="_blank">00:04:09.580</a></span> | <span class="t">There were a lot of good ones for asynchronous use cases, so generating voice slower than real-time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=255" target="_blank">00:04:15.200</a></span> | <span class="t">But there weren't any really good like real-time streaming ones until Orpheus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=260" target="_blank">00:04:20.060</a></span> | <span class="t">Orpheus was the first really good one that was kind of like ready to go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=264" target="_blank">00:04:24.920</a></span> | <span class="t">So Orpheus came out and we're like, okay, this is our time to shine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=268" target="_blank">00:04:28.840</a></span> | <span class="t">We immediately like put it on an H100, hosted it, went viral with Jack's tweets, and got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=274" target="_blank">00:04:34.960</a></span> | <span class="t">a ton of top-of-funnel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=277" target="_blank">00:04:37.680</a></span> | <span class="t">And yeah, that was kind of like the starting point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=279" target="_blank">00:04:39.500</a></span> | <span class="t">It's like our company -- there's like before Orpheus and after Orpheus, our company kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=283" target="_blank">00:04:43.100</a></span> | <span class="t">of changed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=285" target="_blank">00:04:45.260</a></span> | <span class="t">So a little background on what Orpheus is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=287" target="_blank">00:04:47.520</a></span> | <span class="t">It's a voice model, but it started as a Lama 3 billion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=291" target="_blank">00:04:51.420</a></span> | <span class="t">It was trained on -- pre-trained on like 100,000 hours of voice data and text data as well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=298" target="_blank">00:04:58.480</a></span> | <span class="t">to make sure it kept its understanding of kind of like language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=303" target="_blank">00:05:03.220</a></span> | <span class="t">And it was trained to output audio tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=305" target="_blank">00:05:05.060</a></span> | <span class="t">They're called Snack tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=306" target="_blank">00:05:06.060</a></span> | <span class="t">So that's another open-source project, Snack, which is an audio codec.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=311" target="_blank">00:05:11.980</a></span> | <span class="t">So it's trained to output the 24-kilohertz version of Snack tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=316" target="_blank">00:05:16.740</a></span> | <span class="t">Those Snack tokens are then decoded, and then you get audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=318" target="_blank">00:05:18.900</a></span> | <span class="t">You get 24-kilohertz audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=321" target="_blank">00:05:21.600</a></span> | <span class="t">Important thing to note here is it's about 85 Snack tokens for one second of audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=325" target="_blank">00:05:25.880</a></span> | <span class="t">So Orpheus, wherever you're hosting it, it has to be a throughput of about 85.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=333" target="_blank">00:05:33.180</a></span> | <span class="t">I mean, you want like 90 to 100 tokens per second to keep up with real-time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=337" target="_blank">00:05:37.140</a></span> | <span class="t">Otherwise, you get gaps, obviously, in the audio, and it sounds bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=342" target="_blank">00:05:42.400</a></span> | <span class="t">Other things that were important to us because we're going up to the consumer use cases was cloning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=345" target="_blank">00:05:45.960</a></span> | <span class="t">So our clones need to be emotive and high-fidelity, and one-shot cloning doesn't work that well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=355" target="_blank">00:05:55.120</a></span> | <span class="t">That's more true for Orpheus because it only had 100,000 hours of pre-trained data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=360" target="_blank">00:06:00.120</a></span> | <span class="t">Whereas I think some of the zero-shot emergent behavior comes at like a million-plus hours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=365" target="_blank">00:06:05.200</a></span> | <span class="t">So we're scrappy, I think you can tell by like our design here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=369" target="_blank">00:06:09.360</a></span> | <span class="t">That we're like pretty scrappy, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=371" target="_blank">00:06:11.360</a></span> | <span class="t">We weren't going to fill that gap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=374" target="_blank">00:06:14.360</a></span> | <span class="t">So we went with low-rank fine-tunes for our clones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=377" target="_blank">00:06:17.700</a></span> | <span class="t">So here's an example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=378" target="_blank">00:06:18.700</a></span> | <span class="t">So this is a low-rank fine-tune.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=381" target="_blank">00:06:21.640</a></span> | <span class="t">We have some better ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=382" target="_blank">00:06:22.640</a></span> | <span class="t">This isn't like the best example, but they're customers, so I didn't want to put it in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=385" target="_blank">00:06:25.520</a></span> | <span class="t">thing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=386" target="_blank">00:06:26.520</a></span> | <span class="t">Jack's voice like yesterday and used 16 rank, alpha 32, basically all the projections.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=392" target="_blank">00:06:32.840</a></span> | <span class="t">Here's the source audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=393" target="_blank">00:06:33.840</a></span> | <span class="t">Let's see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=394" target="_blank">00:06:34.840</a></span> | <span class="t">So that's the source, and then here's the result of a fine-tune.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=407" target="_blank">00:06:47.840</a></span> | <span class="t">So let me manage expectations here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=413" target="_blank">00:06:53.200</a></span> | <span class="t">This was like pretty bad data, like 10 minutes of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=418" target="_blank">00:06:58.220</a></span> | <span class="t">You really want like 30 minutes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=419" target="_blank">00:06:59.840</a></span> | <span class="t">So I had to overfit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=420" target="_blank">00:07:00.840</a></span> | <span class="t">So I trained on like five epics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=423" target="_blank">00:07:03.740</a></span> | <span class="t">It's pretty overfit, but you'll see it like still sounds okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=427" target="_blank">00:07:07.400</a></span> | <span class="t">Hey, how are you?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=431" target="_blank">00:07:11.160</a></span> | <span class="t">I'm kind of sick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=434" target="_blank">00:07:14.200</a></span> | <span class="t">This is a longer generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=436" target="_blank">00:07:16.060</a></span> | <span class="t">Let's see if it sounds okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=437" target="_blank">00:07:17.600</a></span> | <span class="t">So it's not bad, but you know, my whole life, or most of my, I'm the older brother so most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=443" target="_blank">00:07:23.860</a></span> | <span class="t">of my life, so I know his voice very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=445" target="_blank">00:07:25.920</a></span> | <span class="t">So it's jarring to me, but cool thing is like, yeah, it's trained to do these tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=450" target="_blank">00:07:30.840</a></span> | <span class="t">which is important for consumer, and it's pretty emotive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=455" target="_blank">00:07:35.060</a></span> | <span class="t">Like when it said I'm kind of sick, it sounded pretty sad, so it picks up on the language cues</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=459" target="_blank">00:07:39.220</a></span> | <span class="t">as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=463" target="_blank">00:07:43.580</a></span> | <span class="t">Other thing that's really important, obviously, for all voice use cases, not just consumer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=468" target="_blank">00:07:48.740</a></span> | <span class="t">is latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=469" target="_blank">00:07:49.740</a></span> | <span class="t">So there's four things that really affect latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=473" target="_blank">00:07:53.040</a></span> | <span class="t">Time to first token is one of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=475" target="_blank">00:07:55.300</a></span> | <span class="t">Tokens per second is one of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=478" target="_blank">00:07:58.700</a></span> | <span class="t">I'll get into why that is later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=481" target="_blank">00:08:01.420</a></span> | <span class="t">But what we found in network latency is another one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=484" target="_blank">00:08:04.180</a></span> | <span class="t">But we found the most biggest cause of latency was what we're calling head of line silence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=489" target="_blank">00:08:09.060</a></span> | <span class="t">This is somewhat specific to the Orpheus model, so this isn't gonna be true for all models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=495" target="_blank">00:08:15.860</a></span> | <span class="t">But head of line silence is basically that somewhere in the fine tune of Orpheus, the data had a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=502" target="_blank">00:08:22.560</a></span> | <span class="t">lot of silence at the beginning, because it was voice actors that they hired, and they trained,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=507" target="_blank">00:08:27.080</a></span> | <span class="t">and they like took those scripts and trained, fine-tuned a model from it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=511" target="_blank">00:08:31.240</a></span> | <span class="t">So this is like the default Orpheus voice, or one of the ones that came with it, called Tara.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=515" target="_blank">00:08:35.060</a></span> | <span class="t">And it has 600 milliseconds of latency at the beginning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=518" target="_blank">00:08:38.640</a></span> | <span class="t">And they probably had other good reasons for adding silence at the beginning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=523" target="_blank">00:08:43.940</a></span> | <span class="t">But there's a lot, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=525" target="_blank">00:08:45.740</a></span> | <span class="t">So 600 milliseconds of silence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=528" target="_blank">00:08:48.060</a></span> | <span class="t">We actually found that, oh, so 600 milliseconds of silence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=532" target="_blank">00:08:52.100</a></span> | <span class="t">We're running on L40s machines as of now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=536" target="_blank">00:08:56.520</a></span> | <span class="t">They can do about 100 tokens a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=538" target="_blank">00:08:58.620</a></span> | <span class="t">So 600 milliseconds is almost half a second of silence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=542" target="_blank">00:09:02.620</a></span> | <span class="t">So we are filtering out the silence, like we're not just playing that audio back to the user,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=546" target="_blank">00:09:06.200</a></span> | <span class="t">but because it takes a while to generate those tokens, we're adding like basically half a second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=550" target="_blank">00:09:10.860</a></span> | <span class="t">of latency just on wasted compute, pretty much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=556" target="_blank">00:09:16.440</a></span> | <span class="t">So yeah, even filtering out the silence, you're only like saving 10% there, because you're just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=559" target="_blank">00:09:19.700</a></span> | <span class="t">barely faster than real time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=561" target="_blank">00:09:21.780</a></span> | <span class="t">We're scrappy again, so we're running on L40s.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=565" target="_blank">00:09:25.900</a></span> | <span class="t">But what we found was interesting is that we could actually just fine-tune the silence away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=569" target="_blank">00:09:29.060</a></span> | <span class="t">So this is an example of a clone that we did, a LoRa fine-tune of a customer's clone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=574" target="_blank">00:09:34.700</a></span> | <span class="t">And the latency is basically like 100 milliseconds, like P50.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=579" target="_blank">00:09:39.240</a></span> | <span class="t">So much better, like half a second basically for free.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=583" target="_blank">00:09:43.560</a></span> | <span class="t">And that matters because these real-time, you kind of have a latency budget on the real-time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=588" target="_blank">00:09:48.200</a></span> | <span class="t">application.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=589" target="_blank">00:09:49.200</a></span> | <span class="t">So the way these work is the human talks, and then at some point you decide, is the human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=594" target="_blank">00:09:54.300</a></span> | <span class="t">done talking?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=595" target="_blank">00:09:55.440</a></span> | <span class="t">Those models are not perfect, so you typically add like a snooze period at the end of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=599" target="_blank">00:09:59.940</a></span> | <span class="t">But during that snooze period, you can still do work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=603" target="_blank">00:10:03.100</a></span> | <span class="t">So what we do is we kick off the LLM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=606" target="_blank">00:10:06.060</a></span> | <span class="t">The way we have our Orpheus stack set up is we start generating audio after two sentences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=611" target="_blank">00:10:11.540</a></span> | <span class="t">or if it's done, but two sentences typically, which gives it enough context to like capture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=615" target="_blank">00:10:15.760</a></span> | <span class="t">the emotions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=617" target="_blank">00:10:17.700</a></span> | <span class="t">So all that to say is if we generate the first audio packet within that snooze period,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=621" target="_blank">00:10:21.860</a></span> | <span class="t">then we're kind of like in the money on latency, in our latency budget.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=625" target="_blank">00:10:25.360</a></span> | <span class="t">Now these end-pointing models are going to get better, so you know that snooze period's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=629" target="_blank">00:10:29.020</a></span> | <span class="t">going to go down to like half a second to a second is probably like the sweet spot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=633" target="_blank">00:10:33.020</a></span> | <span class="t">But one and a half seconds is kind of the threshold I think for anything above that sounds pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=637" target="_blank">00:10:37.600</a></span> | <span class="t">bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=638" target="_blank">00:10:38.600</a></span> | <span class="t">And anything kind of equal to or below that is like acceptable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=642" target="_blank">00:10:42.860</a></span> | <span class="t">So yeah, that half a second mattered a lot because it gives our LLM more time to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=648" target="_blank">00:10:48.220</a></span> | <span class="t">tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=649" target="_blank">00:10:49.220</a></span> | <span class="t">And because we're letting customers bring their own LLMs, it's somewhat out of our control.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=655" target="_blank">00:10:55.900</a></span> | <span class="t">So the next big category here is infrastructure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=658" target="_blank">00:10:58.500</a></span> | <span class="t">Again, we're scrappy, so we really needed something that was robust and not too complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=667" target="_blank">00:11:07.460</a></span> | <span class="t">And we needed batch inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=668" target="_blank">00:11:08.460</a></span> | <span class="t">So we needed batch inference obviously to save money.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=670" target="_blank">00:11:10.500</a></span> | <span class="t">So we need to run multiple generations in the same batch or on the same GPU concurrently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=678" target="_blank">00:11:18.460</a></span> | <span class="t">And we also needed multiple LORAs to be running in the same batch on the same GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=683" target="_blank">00:11:23.920</a></span> | <span class="t">And we wanted one load balancer in front of everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=685" target="_blank">00:11:25.900</a></span> | <span class="t">We're spinning up multiple different models for different languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=688" target="_blank">00:11:28.600</a></span> | <span class="t">So we all wanted this to sort of be like a black box that just sort of worked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=694" target="_blank">00:11:34.640</a></span> | <span class="t">So VLLM to the rescue supports all those things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=698" target="_blank">00:11:38.140</a></span> | <span class="t">So VLLM can do batch inference with LORAs, which is really, really awesome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=706" target="_blank">00:11:46.100</a></span> | <span class="t">Unfortunately, the FP16 model was slower than real time on L40s.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=709" target="_blank">00:11:49.100</a></span> | <span class="t">It worked on H100, but it was slower than real time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=712" target="_blank">00:11:52.100</a></span> | <span class="t">But again, VLLM to the rescue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=715" target="_blank">00:11:55.100</a></span> | <span class="t">They support FP8 dynamic quantization, which requires basically zero work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=720" target="_blank">00:12:00.100</a></span> | <span class="t">It just works automatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=722" target="_blank">00:12:02.060</a></span> | <span class="t">It does all the scaling and everything automatically, so you don't have to train the calibration data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=728" target="_blank">00:12:08.060</a></span> | <span class="t">into your own quant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=730" target="_blank">00:12:10.060</a></span> | <span class="t">It just works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=731" target="_blank">00:12:11.060</a></span> | <span class="t">And it's amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=732" target="_blank">00:12:12.060</a></span> | <span class="t">So that brought us up to 105 tokens a second on the non-fine-tuned voices and 95 tokens a second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=739" target="_blank">00:12:19.060</a></span> | <span class="t">on the LoRa voices with a batch of 10, which were, yeah, well in the money in terms of margins</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=747" target="_blank">00:12:27.020</a></span> | <span class="t">and things like that, so that's nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=750" target="_blank">00:12:30.020</a></span> | <span class="t">Part of the infrastructure is, of course, load balancing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=753" target="_blank">00:12:33.020</a></span> | <span class="t">So LoRa's are, depending on what your hyperparameters are, they're between 100 and 200 megabytes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=760" target="_blank">00:12:40.020</a></span> | <span class="t">So you want to make sure you end up on a server that has the LoRa and memory and things like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=764" target="_blank">00:12:44.980</a></span> | <span class="t">that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=765" target="_blank">00:12:45.980</a></span> | <span class="t">We also wanted to support, so that's where like sticky session comes in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=771" target="_blank">00:12:51.980</a></span> | <span class="t">And yeah, latency low, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=773" target="_blank">00:12:53.980</a></span> | <span class="t">But we also wanted to support streaming inputs, mainly because the LLM often, you know, might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=779" target="_blank">00:12:59.380</a></span> | <span class="t">not be done by the time you want to start producing audio, but we also wanted to support arbitrarily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=783" target="_blank">00:13:03.780</a></span> | <span class="t">long generation, so like storytelling, things like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=788" target="_blank">00:13:08.020</a></span> | <span class="t">So we have, so that's another reason why it, I guess, this load balancing problem is interesting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=794" target="_blank">00:13:14.180</a></span> | <span class="t">because you want to make sure you end up on the same GPU across the whole session.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=799" target="_blank">00:13:19.380</a></span> | <span class="t">So we went with pretty much like a by-the-book consistent hashring setup.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=804" target="_blank">00:13:24.620</a></span> | <span class="t">So if you've seen hashrings before, this is not that interesting, but basically the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=808" target="_blank">00:13:28.180</a></span> | <span class="t">it works is you hash the servers multiple times, so you want it called virtual nodes, so it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=813" target="_blank">00:13:33.540</a></span> | <span class="t">distributes around this hashring, and then when a LoRa generation starts, you hash that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=818" target="_blank">00:13:38.500</a></span> | <span class="t">with the same hashing algorithm, you pick the nearest server to that, and it just works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=824" target="_blank">00:13:44.220</a></span> | <span class="t">And the reason this is chosen is because you can like remove a server, and it doesn't read</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=829" target="_blank">00:13:49.220</a></span> | <span class="t">load balance like everything, just only a few, I guess, migrations that are needed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=835" target="_blank">00:13:55.980</a></span> | <span class="t">The other nice thing about this strategy is if a clone gets very popular, it's pretty easy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=841" target="_blank">00:14:01.420</a></span> | <span class="t">to handle that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=842" target="_blank">00:14:02.420</a></span> | <span class="t">You can just append to the LoRa, so you can just, the more popular LoRa is, you can just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=847" target="_blank">00:14:07.580</a></span> | <span class="t">add it to more servers and upscale and downscale that very elegantly without really a ton of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=853" target="_blank">00:14:13.540</a></span> | <span class="t">engineering work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=854" target="_blank">00:14:14.540</a></span> | <span class="t">So yeah, at the high level it looks something like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=859" target="_blank">00:14:19.540</a></span> | <span class="t">We have our WebRTC backend that kind of like terminates the client connections, then we use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=863" target="_blank">00:14:23.700</a></span> | <span class="t">WebSockets to our GPUs, and then the GPUs are talking to Redis, Redis is not the best choice,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=872" target="_blank">00:14:32.460</a></span> | <span class="t">but if we scale beyond needing Redis for this kind of thing, we can just solve that with piles</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=878" target="_blank">00:14:38.060</a></span> | <span class="t">of money, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=880" target="_blank">00:14:40.100</a></span> | <span class="t">But yeah, the way it works here is you start a session, the WebRTC backend just connects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=884" target="_blank">00:14:44.940</a></span> | <span class="t">to any GPU, then it asks Redis, "Hey, what GPU is this request supposed to be on?" and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=891" target="_blank">00:14:51.720</a></span> | <span class="t">then it just proxies it with another TCP connection to the correct GPU, which is fine because these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=896" target="_blank">00:14:56.220</a></span> | <span class="t">GPUs are in the same data center, private networking, so low latency, TCP, that's totally fine within</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=902" target="_blank">00:15:02.420</a></span> | <span class="t">the same network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=905" target="_blank">00:15:05.700</a></span> | <span class="t">That's pretty much it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=906" target="_blank">00:15:06.700</a></span> | <span class="t">I mean, the conclusion here is we're pretty scrappy and we were able to host voice models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=913" target="_blank">00:15:13.000</a></span> | <span class="t">on GPUs and handle that infrastructure, so you can too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=916" target="_blank">00:15:16.860</a></span> | <span class="t">Open source is there and yeah, I think it's gonna unlock a ton of cool use cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=924" target="_blank">00:15:24.100</a></span> | <span class="t">Shout out Swix, he's a supporter of ours and obviously put this on or half of it, I guess,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=931" target="_blank">00:15:31.240</a></span> | <span class="t">but Swix is awesome, we love them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=933" target="_blank">00:15:33.800</a></span> | <span class="t">Canopy Labs, who created Orpheus, haven't met them, would love to if they're here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=939" target="_blank">00:15:39.760</a></span> | <span class="t">And then just free open source software in general, Canopy Labs is built on Llama and Snack, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=945" target="_blank">00:15:45.280</a></span> | <span class="t">this whole ecosystem is greater than the sum of its parts, I guess, and LiveKit, we're LiveKit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=951" target="_blank">00:15:51.120</a></span> | <span class="t">alum, so love those guys, and our WebRTC infras is built on them, and then VLLM, a notable open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=959" target="_blank">00:15:59.340</a></span> | <span class="t">source project.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=961" target="_blank">00:16:01.900</a></span> | <span class="t">And yeah, that's it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=962" target="_blank">00:16:02.680</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=966" target="_blank">00:16:06.240</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=966" target="_blank">00:16:06.240</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=966" target="_blank">00:16:06.240</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=966" target="_blank">00:16:06.240</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=966" target="_blank">00:16:06.240</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=rD23-VZZHOo&t=966" target="_blank">00:16:06.240</a></span> | <span class="t">We'll see you next time.</span></div></div></body></html>