<html><head><title>Stanford XCS224U: NLU I Contextual Word Representations, Part 5: BERT I Spring 2023</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford XCS224U: NLU I Contextual Word Representations, Part 5: BERT I Spring 2023</h2><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg"><img src="https://i.ytimg.com/vi/H0Zw0_22JRg/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=18">0:18</a> BERT: Core model structure<br><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=127">2:7</a> Masked Language Modeling (MLM)<br><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=223">3:43</a> BERT: MLM loss function<br><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=299">4:59</a> Binary next sentence prediction pretraining<br><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=344">5:44</a> BERT: Transfer learning and fine-tuning<br><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=415">6:55</a> Tokenization and the BERT embedding space<br><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=461">7:41</a> BERT: Core model releases<br><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=567">9:27</a> BERT: Known limitations<br><br><div style="text-align: left;"><a href="./H0Zw0_22JRg.html">Whisper Transcript</a> | <a href="./transcript_H0Zw0_22JRg.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Welcome back everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=6" target="_blank">00:00:06.000</a></span> | <span class="t">This is part five in our series on contextual representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=9" target="_blank">00:00:09.680</a></span> | <span class="t">We're going to focus on BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=11" target="_blank">00:00:11.320</a></span> | <span class="t">BERT is the slightly older sibling to GPT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=14" target="_blank">00:00:14.400</a></span> | <span class="t">but arguably just as important and famous.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=18" target="_blank">00:00:18.280</a></span> | <span class="t">Let's start with the core model structure for BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=21" target="_blank">00:00:21.720</a></span> | <span class="t">This is mostly going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=23" target="_blank">00:00:23.200</a></span> | <span class="t">combinations of familiar elements at this point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=26" target="_blank">00:00:26.020</a></span> | <span class="t">given that we've already reviewed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=27" target="_blank">00:00:27.680</a></span> | <span class="t">the transformer architecture in BERT is essentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=30" target="_blank">00:00:30.440</a></span> | <span class="t">just an interesting use of the transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=33" target="_blank">00:00:33.720</a></span> | <span class="t">As usual to illustrate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=35" target="_blank">00:00:35.420</a></span> | <span class="t">I have our sequence, the rock rules at the bottom here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=38" target="_blank">00:00:38.680</a></span> | <span class="t">but that sequence is augmented in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=40" target="_blank">00:00:40.700</a></span> | <span class="t">a bunch of BERT specific ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=42" target="_blank">00:00:42.560</a></span> | <span class="t">All the way on the left here, we have a class token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=45" target="_blank">00:00:45.000</a></span> | <span class="t">That's an important token for the BERT architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=47" target="_blank">00:00:47.500</a></span> | <span class="t">Every sequence begins with the class token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=50" target="_blank">00:00:50.780</a></span> | <span class="t">That has a positional encoding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=52" target="_blank">00:00:52.620</a></span> | <span class="t">We also have a hierarchical positional encoding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=55" target="_blank">00:00:55.680</a></span> | <span class="t">This is given by the token sent A.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=58" target="_blank">00:00:58.080</a></span> | <span class="t">This won't be so interesting for our illustration,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=61" target="_blank">00:01:01.200</a></span> | <span class="t">but as I mentioned before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=63" target="_blank">00:01:03.080</a></span> | <span class="t">for problems like natural language inference,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=65" target="_blank">00:01:05.340</a></span> | <span class="t">we might have a separate token for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=67" target="_blank">00:01:07.080</a></span> | <span class="t">the premise and a separate one for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=69" target="_blank">00:01:09.140</a></span> | <span class="t">the hypothesis to help encode the fact that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=72" target="_blank">00:01:12.080</a></span> | <span class="t">a word appearing in the premise is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=74" target="_blank">00:01:14.200</a></span> | <span class="t">a slightly different occurrence of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=75" target="_blank">00:01:15.920</a></span> | <span class="t">that word than when it appears in a hypothesis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=79" target="_blank">00:01:19.040</a></span> | <span class="t">That generalizes to lots of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=81" target="_blank">00:01:21.340</a></span> | <span class="t">different hierarchical position for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=84" target="_blank">00:01:24.520</a></span> | <span class="t">different tasks that we might pose.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=86" target="_blank">00:01:26.960</a></span> | <span class="t">But we have this very position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=89" target="_blank">00:01:29.560</a></span> | <span class="t">sensitive encoding of our input sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=92" target="_blank">00:01:32.400</a></span> | <span class="t">We look up the embedding representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=94" target="_blank">00:01:34.920</a></span> | <span class="t">for all those pieces as usual,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=97" target="_blank">00:01:37.060</a></span> | <span class="t">and then we do an additive combination of them to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=100" target="_blank">00:01:40.000</a></span> | <span class="t">our first context sensitive encoding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=103" target="_blank">00:01:43.520</a></span> | <span class="t">of this input sequence in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=104" target="_blank">00:01:44.880</a></span> | <span class="t">these vectors that are in green here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=107" target="_blank">00:01:47.200</a></span> | <span class="t">Then just as with GPT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=109" target="_blank">00:01:49.320</a></span> | <span class="t">we have lots of transformer blocks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=111" target="_blank">00:01:51.280</a></span> | <span class="t">potentially dozens of them repeated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=114" target="_blank">00:01:54.040</a></span> | <span class="t">until we finally get to some output states,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=116" target="_blank">00:01:56.560</a></span> | <span class="t">which I've given in dark green here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=118" target="_blank">00:01:58.620</a></span> | <span class="t">Those are going to be the basis for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=120" target="_blank">00:02:00.400</a></span> | <span class="t">further things that we do with the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=123" target="_blank">00:02:03.000</a></span> | <span class="t">That's the structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=124" target="_blank">00:02:04.680</a></span> | <span class="t">Let's think about how we train this artifact.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=127" target="_blank">00:02:07.360</a></span> | <span class="t">The core objective is masked language modeling or MLM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=132" target="_blank">00:02:12.200</a></span> | <span class="t">The idea here is essentially that we're going to mask out or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=135" target="_blank">00:02:15.760</a></span> | <span class="t">obscure the identities of some words in the sequence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=139" target="_blank">00:02:19.820</a></span> | <span class="t">and then have the model try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=141" target="_blank">00:02:21.440</a></span> | <span class="t">reconstruct the missing piece.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=143" target="_blank">00:02:23.760</a></span> | <span class="t">For our sequence, we could have a scenario where we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=146" target="_blank">00:02:26.520</a></span> | <span class="t">no masking on the word rules,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=148" target="_blank">00:02:28.880</a></span> | <span class="t">but we nonetheless train the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=150" target="_blank">00:02:30.840</a></span> | <span class="t">to predict rules at that time step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=153" target="_blank">00:02:33.060</a></span> | <span class="t">That might be relatively easy as a reconstruction task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=156" target="_blank">00:02:36.540</a></span> | <span class="t">Harder, we'll be doing masking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=158" target="_blank">00:02:38.880</a></span> | <span class="t">In this case, we have a special designated token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=161" target="_blank">00:02:41.840</a></span> | <span class="t">that we insert in the place of the token rules.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=165" target="_blank">00:02:45.240</a></span> | <span class="t">Then we try to get the model to a state where it can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=168" target="_blank">00:02:48.920</a></span> | <span class="t">reconstruct that rules was the missing piece</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=171" target="_blank">00:02:51.640</a></span> | <span class="t">using the full bidirectional context around that point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=175" target="_blank">00:02:55.680</a></span> | <span class="t">Then relatedly, in addition to masking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=177" target="_blank">00:02:57.920</a></span> | <span class="t">we could do random word replacement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=180" target="_blank">00:03:00.400</a></span> | <span class="t">In this case, we simply take the actual word,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=183" target="_blank">00:03:03.040</a></span> | <span class="t">in this case rules,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=184" target="_blank">00:03:04.180</a></span> | <span class="t">and replace it with a random one like every,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=186" target="_blank">00:03:06.880</a></span> | <span class="t">and then try to have the model learn to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=189" target="_blank">00:03:09.400</a></span> | <span class="t">what was the actual token at that position.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=193" target="_blank">00:03:13.080</a></span> | <span class="t">All of these things are using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=194" target="_blank">00:03:14.640</a></span> | <span class="t">the bidirectional context of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=196" target="_blank">00:03:16.720</a></span> | <span class="t">the model in order to do this reconstruction task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=200" target="_blank">00:03:20.040</a></span> | <span class="t">When we train this model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=201" target="_blank">00:03:21.400</a></span> | <span class="t">we mask out only a small percentage of all the tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=204" target="_blank">00:03:24.800</a></span> | <span class="t">mostly leaving the other ones in place so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=207" target="_blank">00:03:27.720</a></span> | <span class="t">the model has lots of context to use to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=210" target="_blank">00:03:30.040</a></span> | <span class="t">predict the masked or missing or corrupted tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=213" target="_blank">00:03:33.760</a></span> | <span class="t">That's actually a limitation of the model and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=215" target="_blank">00:03:35.920</a></span> | <span class="t">if inefficiency in the MLM objective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=218" target="_blank">00:03:38.540</a></span> | <span class="t">that Electra in particular will seek to address.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=222" target="_blank">00:03:42.440</a></span> | <span class="t">Here's the MLM loss function in some detail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=225" target="_blank">00:03:45.920</a></span> | <span class="t">Again, as before with these loss functions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=228" target="_blank">00:03:48.400</a></span> | <span class="t">there are a lot of details here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=229" target="_blank">00:03:49.800</a></span> | <span class="t">but I think the crucial thing to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=231" target="_blank">00:03:51.640</a></span> | <span class="t">zoom in on is first the numerator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=233" target="_blank">00:03:53.920</a></span> | <span class="t">It's very familiar from before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=235" target="_blank">00:03:55.680</a></span> | <span class="t">We're going to use the embedding representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=237" target="_blank">00:03:57.680</a></span> | <span class="t">of the token that we want to predict,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=239" target="_blank">00:03:59.760</a></span> | <span class="t">and we're going to get a dot product of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=241" target="_blank">00:04:01.600</a></span> | <span class="t">that with a model representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=243" target="_blank">00:04:03.520</a></span> | <span class="t">In this case, we can use the entire surrounding context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=247" target="_blank">00:04:07.840</a></span> | <span class="t">leaving out only the representation at T.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=250" target="_blank">00:04:10.960</a></span> | <span class="t">Whereas for the autoregressive objective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=253" target="_blank">00:04:13.500</a></span> | <span class="t">that we reviewed before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=254" target="_blank">00:04:14.940</a></span> | <span class="t">we could only use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=256" target="_blank">00:04:16.240</a></span> | <span class="t">the preceding context to make this prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=259" target="_blank">00:04:19.280</a></span> | <span class="t">The other thing to notice here is that we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=261" target="_blank">00:04:21.760</a></span> | <span class="t">this indicator function MT here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=264" target="_blank">00:04:24.280</a></span> | <span class="t">which is going to be one if we're looking at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=266" target="_blank">00:04:26.680</a></span> | <span class="t">a masked token and zero otherwise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=270" target="_blank">00:04:30.000</a></span> | <span class="t">What that's essentially doing is turning off</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=272" target="_blank">00:04:32.560</a></span> | <span class="t">this objective for tokens that we didn't mask out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=275" target="_blank">00:04:35.840</a></span> | <span class="t">We get a learning signal only from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=278" target="_blank">00:04:38.360</a></span> | <span class="t">the masked tokens or the ones that we have corrupted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=281" target="_blank">00:04:41.720</a></span> | <span class="t">That again feeds into a inefficiency of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=286" target="_blank">00:04:46.040</a></span> | <span class="t">this objective because we in effect do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=288" target="_blank">00:04:48.280</a></span> | <span class="t">the work of making predictions for all the time steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=291" target="_blank">00:04:51.040</a></span> | <span class="t">but get an error signal for the loss function only for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=294" target="_blank">00:04:54.480</a></span> | <span class="t">the ones that we have designated as masked in some sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=299" target="_blank">00:04:59.040</a></span> | <span class="t">For the BERT paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=301" target="_blank">00:05:01.240</a></span> | <span class="t">they supplemented the MLM objective with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=303" target="_blank">00:05:03.660</a></span> | <span class="t">a binary next sentence prediction task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=306" target="_blank">00:05:06.800</a></span> | <span class="t">In this case, we use our corpus resources to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=309" target="_blank">00:05:09.920</a></span> | <span class="t">actual sentence sequences with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=311" target="_blank">00:05:11.920</a></span> | <span class="t">all of their special tokens in them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=313" target="_blank">00:05:13.960</a></span> | <span class="t">For sequences that actually occurred in the corpus,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=317" target="_blank">00:05:17.040</a></span> | <span class="t">we label them as next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=318" target="_blank">00:05:18.680</a></span> | <span class="t">Then for negative instances,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=320" target="_blank">00:05:20.320</a></span> | <span class="t">we have randomly chosen sentences that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=322" target="_blank">00:05:22.600</a></span> | <span class="t">pair up and label them as not next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=325" target="_blank">00:05:25.400</a></span> | <span class="t">The motivation for this part of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=327" target="_blank">00:05:27.280</a></span> | <span class="t">the objective is to help the model learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=329" target="_blank">00:05:29.640</a></span> | <span class="t">some discourse level information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=332" target="_blank">00:05:32.280</a></span> | <span class="t">as part of learning how to reconstruct sequences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=334" target="_blank">00:05:34.880</a></span> | <span class="t">I think that's a really interesting intuition about how we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=338" target="_blank">00:05:38.080</a></span> | <span class="t">might bring an even richer notions of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=339" target="_blank">00:05:39.920</a></span> | <span class="t">context into the transformer representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=344" target="_blank">00:05:44.280</a></span> | <span class="t">When we think about transfer learning or fine-tuning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=348" target="_blank">00:05:48.040</a></span> | <span class="t">there are a few different approaches that we can take.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=350" target="_blank">00:05:50.440</a></span> | <span class="t">Here's a depiction of the transformer architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=353" target="_blank">00:05:53.600</a></span> | <span class="t">The standard lightweight thing to do is to build out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=357" target="_blank">00:05:57.640</a></span> | <span class="t">task parameters on top of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=359" target="_blank">00:05:59.600</a></span> | <span class="t">the final output representation above the class token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=363" target="_blank">00:06:03.400</a></span> | <span class="t">I think that works really well because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=365" target="_blank">00:06:05.320</a></span> | <span class="t">the class token is used as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=366" target="_blank">00:06:06.800</a></span> | <span class="t">the first token in every single sequence that BERT processes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=371" target="_blank">00:06:11.400</a></span> | <span class="t">and it's always in that fixed position.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=373" target="_blank">00:06:13.840</a></span> | <span class="t">It becomes a constant element that contains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=376" target="_blank">00:06:16.520</a></span> | <span class="t">a lot of information about the corresponding sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=380" target="_blank">00:06:20.440</a></span> | <span class="t">The standard thing is to build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=382" target="_blank">00:06:22.160</a></span> | <span class="t">a few dense layers on top of that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=384" target="_blank">00:06:24.400</a></span> | <span class="t">and then maybe do some classification learning there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=387" target="_blank">00:06:27.680</a></span> | <span class="t">But of course, as with GPT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=389" target="_blank">00:06:29.600</a></span> | <span class="t">we shouldn't feel limited by that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=391" target="_blank">00:06:31.320</a></span> | <span class="t">A standard alternative to this would be to pool</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=394" target="_blank">00:06:34.200</a></span> | <span class="t">together all of the output states and then build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=397" target="_blank">00:06:37.040</a></span> | <span class="t">the task parameters on top of that mean pooling or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=400" target="_blank">00:06:40.360</a></span> | <span class="t">max pooling or whatever decision you use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=403" target="_blank">00:06:43.000</a></span> | <span class="t">to bring together all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=405" target="_blank">00:06:45.840</a></span> | <span class="t">the output states to make predictions for your task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=408" target="_blank">00:06:48.680</a></span> | <span class="t">That can be very powerful as well because you bring in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=411" target="_blank">00:06:51.600</a></span> | <span class="t">much more information about the entire sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=415" target="_blank">00:06:55.240</a></span> | <span class="t">I thought I would remind you a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=417" target="_blank">00:06:57.760</a></span> | <span class="t">about how tokenization works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=419" target="_blank">00:06:59.480</a></span> | <span class="t">Remember that BERT has this tiny vocabulary and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=423" target="_blank">00:07:03.360</a></span> | <span class="t">therefore a tiny static embedding space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=426" target="_blank">00:07:06.640</a></span> | <span class="t">The reason it gets away with that is because it does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=429" target="_blank">00:07:09.280</a></span> | <span class="t">word piece tokenization which means that we have lots of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=432" target="_blank">00:07:12.560</a></span> | <span class="t">these word pieces indicated by these double hash marks here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=436" target="_blank">00:07:16.440</a></span> | <span class="t">That means that the model essentially never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=438" target="_blank">00:07:18.960</a></span> | <span class="t">unks out any of its input tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=441" target="_blank">00:07:21.000</a></span> | <span class="t">but rather breaks them down into familiar pieces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=445" target="_blank">00:07:25.000</a></span> | <span class="t">Then the intuition is that the power of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=448" target="_blank">00:07:28.480</a></span> | <span class="t">masked language modeling in particular will allow us to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=451" target="_blank">00:07:31.680</a></span> | <span class="t">learn internal representations of things that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=454" target="_blank">00:07:34.600</a></span> | <span class="t">correspond even to words like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=456" target="_blank">00:07:36.560</a></span> | <span class="t">encode which got spread out over multiple tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=460" target="_blank">00:07:40.960</a></span> | <span class="t">Let's talk a little bit about core model releases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=465" target="_blank">00:07:45.120</a></span> | <span class="t">For the original BERT paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=467" target="_blank">00:07:47.400</a></span> | <span class="t">I believe they just did BERT base and BERT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=469" target="_blank">00:07:49.600</a></span> | <span class="t">large encased and uncased variants.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=472" target="_blank">00:07:52.200</a></span> | <span class="t">I would recommend always using the cased ones at this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=475" target="_blank">00:07:55.280</a></span> | <span class="t">Very happily, lots of teams including</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=477" target="_blank">00:07:57.920</a></span> | <span class="t">the Google team have worked to develop even smaller ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=480" target="_blank">00:08:00.680</a></span> | <span class="t">We have tiny, mini, small, and medium as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=484" target="_blank">00:08:04.200</a></span> | <span class="t">This is really welcome because it means you can do a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=487" target="_blank">00:08:07.160</a></span> | <span class="t">development on these tiny models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=489" target="_blank">00:08:09.240</a></span> | <span class="t">and then possibly scale up to larger ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=491" target="_blank">00:08:11.720</a></span> | <span class="t">For example, BERT tiny has just two layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=495" target="_blank">00:08:15.080</a></span> | <span class="t">that is two transformer blocks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=497" target="_blank">00:08:17.080</a></span> | <span class="t">relatively small model dimensionality and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=499" target="_blank">00:08:19.600</a></span> | <span class="t">relatively small expansion inside its feed-forward layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=503" target="_blank">00:08:23.160</a></span> | <span class="t">for a total number of parameters of only four million.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=506" target="_blank">00:08:26.320</a></span> | <span class="t">I will say that that is tiny,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=508" target="_blank">00:08:28.240</a></span> | <span class="t">but it's surprising how much juice you can get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=510" target="_blank">00:08:30.600</a></span> | <span class="t">out of it when you fine-tune it for tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=513" target="_blank">00:08:33.120</a></span> | <span class="t">But then you can move on up to mini, small, medium,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=516" target="_blank">00:08:36.080</a></span> | <span class="t">and then large is the largest from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=518" target="_blank">00:08:38.320</a></span> | <span class="t">the original release at 24 layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=520" target="_blank">00:08:40.720</a></span> | <span class="t">relatively large model dimensionality,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=523" target="_blank">00:08:43.240</a></span> | <span class="t">relatively large feed-forward layer for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=525" target="_blank">00:08:45.720</a></span> | <span class="t">a total number of parameters of around 340 million.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=530" target="_blank">00:08:50.360</a></span> | <span class="t">All of these models, because all of them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=533" target="_blank">00:08:53.960</a></span> | <span class="t">as far as I know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=535" target="_blank">00:08:55.120</a></span> | <span class="t">use absolute positional embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=537" target="_blank">00:08:57.760</a></span> | <span class="t">have a maximum sequence length of 512.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=540" target="_blank">00:09:00.920</a></span> | <span class="t">That's an important limitation that increasingly we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=543" target="_blank">00:09:03.760</a></span> | <span class="t">feeling is constraining the kinds of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=545" target="_blank">00:09:05.520</a></span> | <span class="t">work we can do with models like BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=548" target="_blank">00:09:08.560</a></span> | <span class="t">There are many new releases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=550" target="_blank">00:09:10.480</a></span> | <span class="t">and I would say to stay up to date,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=552" target="_blank">00:09:12.080</a></span> | <span class="t">you could check out Hugging Face,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=553" target="_blank">00:09:13.440</a></span> | <span class="t">which has variants of these models for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=555" target="_blank">00:09:15.360</a></span> | <span class="t">different languages and maybe some different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=557" target="_blank">00:09:17.120</a></span> | <span class="t">sizes and other kinds of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=559" target="_blank">00:09:19.200</a></span> | <span class="t">Maybe, for example, there are by now versions that use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=562" target="_blank">00:09:22.040</a></span> | <span class="t">relative positional encoding which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=563" target="_blank">00:09:23.720</a></span> | <span class="t">would be quite welcome, I would say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=566" target="_blank">00:09:26.600</a></span> | <span class="t">For BERT, some known limitations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=569" target="_blank">00:09:29.120</a></span> | <span class="t">and this will feed into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=570" target="_blank">00:09:30.320</a></span> | <span class="t">subsequent things that we want to talk about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=572" target="_blank">00:09:32.160</a></span> | <span class="t">with Roberta and Elektra especially.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=574" target="_blank">00:09:34.840</a></span> | <span class="t">First, the original BERT paper is admirably detailed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=579" target="_blank">00:09:39.320</a></span> | <span class="t">but it's still very partial in terms of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=582" target="_blank">00:09:42.080</a></span> | <span class="t">ablation studies and studies of how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=584" target="_blank">00:09:44.280</a></span> | <span class="t">effectively optimize the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=586" target="_blank">00:09:46.600</a></span> | <span class="t">That means that we might not be looking at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=589" target="_blank">00:09:49.160</a></span> | <span class="t">the very best BERT that we could possibly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=591" target="_blank">00:09:51.560</a></span> | <span class="t">have if we explored more widely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=594" target="_blank">00:09:54.600</a></span> | <span class="t">Devlin et al also observe a downside.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=598" target="_blank">00:09:58.120</a></span> | <span class="t">They say the first downside is that we're creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=600" target="_blank">00:10:00.400</a></span> | <span class="t">a mismatch between pre-training and fine-tuning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=603" target="_blank">00:10:03.440</a></span> | <span class="t">since the mask token is never seen during fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=606" target="_blank">00:10:06.800</a></span> | <span class="t">That is indeed unusual.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=608" target="_blank">00:10:08.480</a></span> | <span class="t">Remember, the mask token is a crucial element</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=611" target="_blank">00:10:11.120</a></span> | <span class="t">in training the model against the MLM objective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=614" target="_blank">00:10:14.200</a></span> | <span class="t">You introduce this foreign element into that phase that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=617" target="_blank">00:10:17.560</a></span> | <span class="t">presumably you never see when you do fine-tuning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=620" target="_blank">00:10:20.760</a></span> | <span class="t">and that could be dragging down model performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=624" target="_blank">00:10:24.560</a></span> | <span class="t">The second downside that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=626" target="_blank">00:10:26.360</a></span> | <span class="t">mentioned is one that I mentioned as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=628" target="_blank">00:10:28.400</a></span> | <span class="t">We're using only around 15 percent of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=631" target="_blank">00:10:31.240</a></span> | <span class="t">the tokens to make predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=633" target="_blank">00:10:33.400</a></span> | <span class="t">We do all this work of processing these sequences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=635" target="_blank">00:10:35.800</a></span> | <span class="t">but then we turn off the modeling objective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=638" target="_blank">00:10:38.440</a></span> | <span class="t">for the tokens that we didn't mask,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=640" target="_blank">00:10:40.320</a></span> | <span class="t">and we can mask only a tiny number of them because we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=643" target="_blank">00:10:43.440</a></span> | <span class="t">need the bidirectional context to do the reconstruction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=646" target="_blank">00:10:46.480</a></span> | <span class="t">That's the essence of the intuition there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=649" target="_blank">00:10:49.120</a></span> | <span class="t">That's obviously inefficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=651" target="_blank">00:10:51.680</a></span> | <span class="t">The final one is intriguing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=653" target="_blank">00:10:53.520</a></span> | <span class="t">I'll mention this only at the end of this series.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=655" target="_blank">00:10:55.640</a></span> | <span class="t">This comes from the ExcelNet paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=658" target="_blank">00:10:58.120</a></span> | <span class="t">and they just observed that BERT assumes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=659" target="_blank">00:10:59.800</a></span> | <span class="t">the predicted tokens are independent of each other,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=662" target="_blank">00:11:02.640</a></span> | <span class="t">given the unmasked tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=664" target="_blank">00:11:04.600</a></span> | <span class="t">which is oversimplified as high-order,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=667" target="_blank">00:11:07.160</a></span> | <span class="t">long-range dependency is prevalent in natural language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=670" target="_blank">00:11:10.720</a></span> | <span class="t">This is just the observation that if you do happen to mask out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=674" target="_blank">00:11:14.040</a></span> | <span class="t">two tokens like new and York from the place named New York,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=678" target="_blank">00:11:18.040</a></span> | <span class="t">the model will try to reconstruct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=679" target="_blank">00:11:19.960</a></span> | <span class="t">those two tokens independently of each other,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=682" target="_blank">00:11:22.520</a></span> | <span class="t">even though we can see that they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=684" target="_blank">00:11:24.280</a></span> | <span class="t">a very clear statistical dependency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=686" target="_blank">00:11:26.960</a></span> | <span class="t">The BERT objective simply misses that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=689" target="_blank">00:11:29.240</a></span> | <span class="t">and I'll mention later on about how ExcelNet brings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=692" target="_blank">00:11:32.920</a></span> | <span class="t">that dependency back in possibly to very powerful effect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=H0Zw0_22JRg&t=697" target="_blank">00:11:37.640</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>