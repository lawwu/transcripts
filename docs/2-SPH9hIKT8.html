<html><head><title>A little guide to building Large Language Models in 2024</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>A little guide to building Large Language Models in 2024</h2><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8"><img src="https://i.ytimg.com/vi/2-SPH9hIKT8/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=59">0:59</a> Workflow for LLMs<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=77">1:17</a> Data preparation - intro and good recent ressources on data preparation<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=328">5:28</a> A web scale pretraining corpus - goals and challenges<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=689">11:29</a> Web scale data sources – Focus on recent datasets<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1081">18:1</a> Language, and quality filtering<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1474">24:34</a> Diving in data deduplication<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1660">27:40</a> Final data preparation for training<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1891">31:31</a> How to evaluate data quality at scale<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2189">36:29</a> The datatrove and lighteval libraries<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2298">38:18</a> Introduction in modeling technics for LLM training<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2349">39:9</a> When the model is too big: parallelism<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2400">40:0</a> Data parallelism<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2478">41:18</a> Tensor parallelism<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2678">44:38</a> Pipeline parallelism<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2820">47:0</a> Sequence parallelism and references on 4D parallelism<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2872">47:52</a> Synchronisation: GPU-CPU and GPU-GPU challenges<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3134">52:14</a> Flash attention v1 and v2<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3383">56:23</a> Stable training recipes<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3552">59:12</a> New architectures: Mixture-of-experts<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3793">63:13</a> New architectures: Mamba<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3889">64:49</a> The nanotron library<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3975">66:15</a> RLHF in 2024<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4103">68:23</a> PPO, DPO and REINFORCE<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4283">71:23</a> Quantization, speculative decoding and compilation: overview and ressources<br><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4476">74:36</a> Sharing your model, datasets and demo – final words<br><br><div style="text-align: left;"><a href="./2-SPH9hIKT8.html">Whisper Transcript</a> | <a href="./transcript_2-SPH9hIKT8.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hi everyone. So two weeks ago I gave a graduate class here in Amsterdam to 200 PhD students about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=6" target="_blank">00:00:06.560</a></span> | <span class="t">how to build, how to train a large language model from scratch in 2024. I tried in this talk to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=14" target="_blank">00:00:14.320</a></span> | <span class="t">highlight the dark secrets, the thing that people don't talk a lot about but are very crucial to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=19" target="_blank">00:00:19.600</a></span> | <span class="t">getting good performance large language models, and maybe to also highlight a bit what is more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=24" target="_blank">00:00:24.640</a></span> | <span class="t">hype than reality. And when I shared the slides afterwards there was a lot of interest for this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=30" target="_blank">00:00:30.480</a></span> | <span class="t">so I decided I would actually re-record the talk and post it on YouTube as well. So here is our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=38" target="_blank">00:00:38.080</a></span> | <span class="t">little guide to building a large language model in 2024. In this talk I'm gonna cover three main</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=46" target="_blank">00:00:46.320</a></span> | <span class="t">parts - training, fine-tuning, inference. I think for fine-tuning and inference you can already find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=51" target="_blank">00:00:51.520</a></span> | <span class="t">super good recipes, super good blog posts and explanations online so I really spend most of my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=57" target="_blank">00:00:57.360</a></span> | <span class="t">time on training, which is the part that's you know mostly like dark science I would say today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=62" target="_blank">00:01:02.400</a></span> | <span class="t">In training you have three parts - data preparation, efficient training technique,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=67" target="_blank">00:01:07.680</a></span> | <span class="t">evaluation. It's the same here, I'll spend most of my time on the first part, data preparation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=72" target="_blank">00:01:12.880</a></span> | <span class="t">because that's really the secret sauce that I want to highlight today. So let's start writing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=81" target="_blank">00:01:21.280</a></span> | <span class="t">You can believe me or you can also believe much smarter people at OpenAI or Entropiq</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=86" target="_blank">00:01:26.640</a></span> | <span class="t">when I say that basically the most important part in your training is the dataset. So I really like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=91" target="_blank">00:01:31.760</a></span> | <span class="t">this blog post from James at OpenAI which highlights how you know by training many many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=98" target="_blank">00:01:38.480</a></span> | <span class="t">architectures he basically found that in the end they all converge to roughly the same behavior</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=104" target="_blank">00:01:44.720</a></span> | <span class="t">which is determined fully by the dataset. So what he says is this - the hit in AI models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=110" target="_blank">00:01:50.800</a></span> | <span class="t">is the dataset. Basically model behavior is much less determined by architecture or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=116" target="_blank">00:01:56.800</a></span> | <span class="t">high-performance than we think and much more by your dataset. He actually says it's your dataset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=122" target="_blank">00:02:02.160</a></span> | <span class="t">nothing else. Well I still talk about architecture a little bit. And Amanda, a girl from Entropiq,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=128" target="_blank">00:02:08.240</a></span> | <span class="t">basically said the same thing last week when she tweeted "is this emergent behavior</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=134" target="_blank">00:02:14.800</a></span> | <span class="t">coming from data or from the model?" and basically she said "none of us has ever magically pulled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=141" target="_blank">00:02:21.680</a></span> | <span class="t">anything out of the ether, it's all coming from the dataset". So if you're more into YouTube than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=148" target="_blank">00:02:28.560</a></span> | <span class="t">Twitter, I think there is a nice video that jokingly summarizes all of this by Rutger Bergman</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=155" target="_blank">00:02:35.040</a></span> | <span class="t">Bergman when he said "let me play it". That's a video I think about when I read all the tech</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=160" target="_blank">00:02:40.880</a></span> | <span class="t">reports that are only talking about model architecture and don't say anything about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=166" target="_blank">00:02:46.000</a></span> | <span class="t">data. I mean it feels like I'm at a firefighters conference and no one's allowed to speak about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=172" target="_blank">00:02:52.080</a></span> | <span class="t">water. I mean this is not rocket science. I mean we can talk for a very long time about all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=176" target="_blank">00:02:56.800</a></span> | <span class="t">stupid philanthropy schemes. We can invite Bono once more but come on, we got to be talking about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=182" target="_blank">00:03:02.160</a></span> | <span class="t">taxes. That's it. Taxes, taxes, taxes. All the rest is bullshit in my opinion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=186" target="_blank">00:03:06.640</a></span> | <span class="t">So basically for us we got to be talking about data. Data, data, data. All the rest is bullshit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=195" target="_blank">00:03:15.920</a></span> | <span class="t">in my opinion. So I mean now that I kind of planted you know the landscape, let's dive in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=202" target="_blank">00:03:22.160</a></span> | <span class="t">what I mean about that. I mean it feels like I'm at a fire. Thanks. I think another nice well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=210" target="_blank">00:03:30.800</a></span> | <span class="t">recent paper I think is the Yi paper. So maybe if you've been following the field you probably saw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=215" target="_blank">00:03:35.840</a></span> | <span class="t">that many Chinese teams have actually trained very good models recently. And the nice thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=221" target="_blank">00:03:41.360</a></span> | <span class="t">is that they also have a very very good tech report. Much better than what we have I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=225" target="_blank">00:03:45.520</a></span> | <span class="t">say in the western world where everyone is now very shy about sharing anything. And so the Yi</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=231" target="_blank">00:03:51.360</a></span> | <span class="t">models are a very good model if you look at the benchmark. And basically when training them they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=237" target="_blank">00:03:57.760</a></span> | <span class="t">say that their underlying assumption is that when you train on extensive data of high enough quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=243" target="_blank">00:04:03.120</a></span> | <span class="t">a standard architecture can exhibit advanced capabilities. So basically you don't need yet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=249" target="_blank">00:04:09.440</a></span> | <span class="t">now to you know go look behind beyond transformers or maybe like I will be talking later like slight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=257" target="_blank">00:04:17.360</a></span> | <span class="t">extension like mixture of experts. If you have very good data just spend the time on carefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=264" target="_blank">00:04:24.320</a></span> | <span class="t">crafting your data set and for now stay on one of these simple architectures that we use today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=269" target="_blank">00:04:29.840</a></span> | <span class="t">I think there is extensive resources as always. I could have cited like 20 papers but I try to keep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=277" target="_blank">00:04:37.920</a></span> | <span class="t">like a small list of resources so you can read them extensively. I think these four ones are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=286" target="_blank">00:04:46.080</a></span> | <span class="t">nice recent examples. The survey on data selection for language model by LNAI is very nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=293" target="_blank">00:04:53.680</a></span> | <span class="t">The paper I just mentioned by the Yi team is really great and I think two recent data sets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=300" target="_blank">00:05:00.080</a></span> | <span class="t">that were open source and shared a lot more about how they were built were the the Dolma data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=306" target="_blank">00:05:06.160</a></span> | <span class="t">from LNAI and also RefineWeb. So I think a nice thing about RefineWeb is that I'm working with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=312" target="_blank">00:05:12.720</a></span> | <span class="t">Guilherme the lead author of this at Hugging Face and so we'll have much more news about this data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=318" target="_blank">00:05:18.720</a></span> | <span class="t">set to share and I think it's a very nice work. So you can use data for many things. So when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=325" target="_blank">00:05:25.760</a></span> | <span class="t">talk about data you actually talk about various type of data. You can use data for pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=331" target="_blank">00:05:31.280</a></span> | <span class="t">your model, you can use data for instruction tuning, you can use data for alignment which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=337" target="_blank">00:05:37.200</a></span> | <span class="t">basically after having pre-trained your model you really want to align it so it learns how to exhibit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=342" target="_blank">00:05:42.080</a></span> | <span class="t">the nice behavior that you want. In particular a dialogue behavior which is one we often want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=347" target="_blank">00:05:47.680</a></span> | <span class="t">have when we interact with these models. You can also have model data more for in-context learning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=353" target="_blank">00:05:53.280</a></span> | <span class="t">for rag training, retrieval training and I would say each of these aspects will have different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=359" target="_blank">00:05:59.120</a></span> | <span class="t">goals and will require different data. So as a rough idea for instance for pre-training you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=364" target="_blank">00:06:04.640</a></span> | <span class="t">really the maximal diversity. You want to assume that your model just has no way to generalize. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=371" target="_blank">00:06:11.120</a></span> | <span class="t">if the behavior you want at the end is not in the pre-training data there is no way the model will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=378" target="_blank">00:06:18.160</a></span> | <span class="t">discover it. You have to put it in the training data. For alignment it's quite different. You want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=382" target="_blank">00:06:22.880</a></span> | <span class="t">very clean data because you're training your model to exhibit some specific behavior. You want model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=388" target="_blank">00:06:28.160</a></span> | <span class="t">to really be very good at you know like a function call or like you want your model to be very good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=394" target="_blank">00:06:34.080</a></span> | <span class="t">at dialogue. So you want the model really to train and to learn this behavior. So usually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=400" target="_blank">00:06:40.480</a></span> | <span class="t">this data set can be much smaller and they can be much more carefully cleaned.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=404" target="_blank">00:06:44.320</a></span> | <span class="t">In pre-training you will want some noise so your model knows about the noise. In particular there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=409" target="_blank">00:06:49.520</a></span> | <span class="t">is a debate you know should you use no toxic data or like maybe no bad language data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=414" target="_blank">00:06:54.880</a></span> | <span class="t">Right now I think the main approach to this problem by people is to use a lot of like toxic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=423" target="_blank">00:07:03.520</a></span> | <span class="t">data or like a lot a decent amount so that the model is already exposed to this. It's a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=428" target="_blank">00:07:08.160</a></span> | <span class="t">bit like your kid if you want. If you want to tell them that drug is bad right they have to first know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=433" target="_blank">00:07:13.760</a></span> | <span class="t">about drug. You cannot really you know expect them to learn that this is something they shouldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=441" target="_blank">00:07:21.120</a></span> | <span class="t">touch they should not be using if you don't tell them what it is. It's the same for language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=446" target="_blank">00:07:26.960</a></span> | <span class="t">in some way. We want them to be exposed to this data to a small amount of it so that they can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=451" target="_blank">00:07:31.920</a></span> | <span class="t">learn later to avoid this and they will know what they need to avoid. Basically assume that there is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=457" target="_blank">00:07:37.440</a></span> | <span class="t">no generalization capabilities in this model. If you want to tell them anything about something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=462" target="_blank">00:07:42.480</a></span> | <span class="t">positive or negative you have to first put it in the model. So let's talk about pre-training stage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=469" target="_blank">00:07:49.200</a></span> | <span class="t">I already covered a little bit but basically you want to have maximal coverage you want to cover</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=472" target="_blank">00:07:52.880</a></span> | <span class="t">everything. So you will train a massive quantity of texts at least 1 trillion token nowadays and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=478" target="_blank">00:07:58.960</a></span> | <span class="t">I think you probably want to aim for like more 10 trillion tokens. The challenges that you want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=484" target="_blank">00:08:04.480</a></span> | <span class="t">solve here you want to maximize diversity and coverage and you want to maximize quality as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=490" target="_blank">00:08:10.080</a></span> | <span class="t">much as possible because this is still you know something that your model will learn. So if your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=495" target="_blank">00:08:15.440</a></span> | <span class="t">model learn mostly noise you will still get noise out. So you want to have a little bit of this so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=500" target="_blank">00:08:20.320</a></span> | <span class="t">it's kind of robust to this but you don't want to have too much of this. Here is one example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=506" target="_blank">00:08:26.320</a></span> | <span class="t">Basically you would want your model a good rule of thumb is that you will want your model to know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=511" target="_blank">00:08:31.520</a></span> | <span class="t">two things. You want your model to know the thing that you may want it to generate at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=516" target="_blank">00:08:36.240</a></span> | <span class="t">So if you want to generate knowledge about physics you will want to put that in the model and we want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=522" target="_blank">00:08:42.080</a></span> | <span class="t">also your model to learn the thing that it might be exposed to. So you want your model to be familiar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=527" target="_blank">00:08:47.920</a></span> | <span class="t">with the thing that the users might input. So if you have inputs that might be noisy from the users</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=533" target="_blank">00:08:53.360</a></span> | <span class="t">your model should still be trained on it. Otherwise it will be out of distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=538" target="_blank">00:08:58.160</a></span> | <span class="t">and as I said the safest bet here is to assume your model don't generalize at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=542" target="_blank">00:09:02.400</a></span> | <span class="t">The main challenge here is maximal diversity, good quality but still a little bit of noise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=549" target="_blank">00:09:09.280</a></span> | <span class="t">and data quality evaluation. How do you measure data quality at the billion token scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=554" target="_blank">00:09:14.800</a></span> | <span class="t">That's what we're going to talk a little bit about as well. So here is the typical pipeline to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=559" target="_blank">00:09:19.680</a></span> | <span class="t">a model. So you start by collection. I'm going to talk a little bit about that. You want to filter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=563" target="_blank">00:09:23.840</a></span> | <span class="t">by languages which language you want to keep and then you have a set of filters. You have basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=568" target="_blank">00:09:28.800</a></span> | <span class="t">two main type of filters. You have some filters that are more heuristic so they are kind of rules</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=573" target="_blank">00:09:33.760</a></span> | <span class="t">that you wrote and there are some filters that are more like ML models. So you have a model that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=580" target="_blank">00:09:40.160</a></span> | <span class="t">train to identify some good quality text. Usually you want to combine two and then you have a set of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=586" target="_blank">00:09:46.160</a></span> | <span class="t">filters that are more semantic. The rule and the ML model are usually a little bit more on the surface</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=591" target="_blank">00:09:51.040</a></span> | <span class="t">level and then you want to cover really the topics that you need to know about. If you want to know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=596" target="_blank">00:09:56.000</a></span> | <span class="t">about physics, you want to know about technology, you want to be sure that these are in and so you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=600" target="_blank">00:10:00.480</a></span> | <span class="t">have a step of like more topic filtering and basically be sure that you extract this topic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=606" target="_blank">00:10:06.160</a></span> | <span class="t">very well. This is another example from RefineWeb. The first one was from Yi. This is from RefineWeb</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=616" target="_blank">00:10:16.160</a></span> | <span class="t">just to show you how much data we remove. So we start from Common Crawl which is basically the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=621" target="_blank">00:10:21.920</a></span> | <span class="t">internet crawled since 10 years ago and basically we filter that and you can see that there is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=630" target="_blank">00:10:30.000</a></span> | <span class="t">lot of things that you will remove. First I would say language removal. If you only keep English,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=634" target="_blank">00:10:34.640</a></span> | <span class="t">English is roughly half of the internet. The second biggest language is usually Russian and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=639" target="_blank">00:10:39.760</a></span> | <span class="t">then you have all of the other in Common Crawl. So basically remove half of it when you only filter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=645" target="_blank">00:10:45.440</a></span> | <span class="t">for English you will have a lot of like duplication removal. Why do you want to do duplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=651" target="_blank">00:10:51.600</a></span> | <span class="t">removal? Well we'll talk a little bit about that later so wait. And then you extract a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=656" target="_blank">00:10:56.880</a></span> | <span class="t">and in the end you end up with about 10% of the original Common Crawl sizes. So if you want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=662" target="_blank">00:11:02.960</a></span> | <span class="t">get a trillion token that means you really want to start with a very large source. This is an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=669" target="_blank">00:11:09.280</a></span> | <span class="t">example this one from the from the LNAI survey. It's roughly the same steps that you will see here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=675" target="_blank">00:11:15.600</a></span> | <span class="t">Language filtering, some heuristics, some what they call data quality which is machine learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=681" target="_blank">00:11:21.360</a></span> | <span class="t">based usually. Some deduplication and then topic filtering basically. So where can you start from?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=691" target="_blank">00:11:31.920</a></span> | <span class="t">You want as I said something very large because you'll just keep like 10% of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=696" target="_blank">00:11:36.880</a></span> | <span class="t">So there is two main large sources of data I would say today. One is Common Crawl,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=700" target="_blank">00:11:40.960</a></span> | <span class="t">one is the internet basically and the other one is more like for code. Usually you want to start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=706" target="_blank">00:11:46.160</a></span> | <span class="t">from GitHub or something like Software Heritage or like a place where this has been carefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=711" target="_blank">00:11:51.920</a></span> | <span class="t">already extracted from the web. You can use some curated sources like Wikipedia or books and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=719" target="_blank">00:11:59.920</a></span> | <span class="t">in books you have this big question you know like I should use only public domain books which stops</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=725" target="_blank">00:12:05.280</a></span> | <span class="t">usually 100 years from now so in 1924 for today or do you want to dive in more like copyright</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=733" target="_blank">00:12:13.040</a></span> | <span class="t">equation. So that's the big big question I would say for today for mobile trainers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=737" target="_blank">00:12:17.760</a></span> | <span class="t">And you have more recent trends like synthetic data generation where you basically will ask one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=743" target="_blank">00:12:23.200</a></span> | <span class="t">LLM to generate some data specifically for you and because you're kind of paying compute for data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=749" target="_blank">00:12:29.520</a></span> | <span class="t">here you can scale this quite largely. So there is a full new trend on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=756" target="_blank">00:12:36.080</a></span> | <span class="t">spearheaded by Microsoft and the fee models which were trained on billions of synthetically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=762" target="_blank">00:12:42.160</a></span> | <span class="t">generated data from GPT-4. I think it's quite interesting that you can really craft the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=768" target="_blank">00:12:48.400</a></span> | <span class="t">set in a more controlled way here because you can say okay I want this topic, this topic, this topic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=773" target="_blank">00:12:53.920</a></span> | <span class="t">this behavior and given the quality of large language models today the quality of the resulting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=780" target="_blank">00:13:00.000</a></span> | <span class="t">data is actually very high. There is even a recent interesting paper from Apple which is about you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=786" target="_blank">00:13:06.480</a></span> | <span class="t">know rephrasing the web so you take one page and you actually ask an LLM to write it cleanly and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=792" target="_blank">00:13:12.400</a></span> | <span class="t">if you train on this data which is very clean and still cover a lot of diversity you can train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=797" target="_blank">00:13:17.440</a></span> | <span class="t">actually three times faster because you use three times less data. It's very recent but it's super</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=802" target="_blank">00:13:22.720</a></span> | <span class="t">interesting. Okay I talk a little bit about this resource in more details because we've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=810" target="_blank">00:13:30.480</a></span> | <span class="t">releasing data set on this at HuggingFace and I want to show you a little bit what we released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=815" target="_blank">00:13:35.120</a></span> | <span class="t">and I go in reverse order so I start with synthetic data. We released recently Lubna and Anton</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=821" target="_blank">00:13:41.760</a></span> | <span class="t">and Leandro at HuggingFace have been releasing a data data set called Cosmopedia which is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=827" target="_blank">00:13:47.360</a></span> | <span class="t">synthetic data set of 30 million samples, that's actually billions of tokens and it was generated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=833" target="_blank">00:13:53.120</a></span> | <span class="t">using one of the best open source models today which is MixedTrail Instruct and here you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=839" target="_blank">00:13:59.360</a></span> | <span class="t">see how basically this is controlled for various seeds so basically we give the model a slight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=846" target="_blank">00:14:06.480</a></span> | <span class="t">small topic you know or a sentence from a document and you can choose where this comes from and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=852" target="_blank">00:14:12.720</a></span> | <span class="t">ask the model to to write content you know from this seed sample on the topic. So we took some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=859" target="_blank">00:14:19.600</a></span> | <span class="t">very clean sources like the Stanford open courses or OpenStacks which is also open textbook,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=866" target="_blank">00:14:26.480</a></span> | <span class="t">Khan Academy that you maybe know and also some web data so I would say more more diverse data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=872" target="_blank">00:14:32.880</a></span> | <span class="t">and even instruction tuning data set and then you can ask model also to write you know using various</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=880" target="_blank">00:14:40.240</a></span> | <span class="t">language you can ask the model to write this for college students you know to write textbook</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=884" target="_blank">00:14:44.720</a></span> | <span class="t">article on this topic for college students or for high school students you can also ask the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=890" target="_blank">00:14:50.560</a></span> | <span class="t">to write in various styles to write blog posts about this topic and so you can actually have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=895" target="_blank">00:14:55.680</a></span> | <span class="t">a lot of diversity even though it's synthetic. Here is a quick example of all the clusters you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=904" target="_blank">00:15:04.480</a></span> | <span class="t">can do topic clustering to check that you know that you cover a lot what we discovered is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=909" target="_blank">00:15:09.680</a></span> | <span class="t">we could still cover even more clusters and I would say right now the work on Cosmopedia 0.2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=916" target="_blank">00:15:16.400</a></span> | <span class="t">is to extend this to even more cluster and to get basically more coverage and so here you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=922" target="_blank">00:15:22.400</a></span> | <span class="t">that we train a we train 1 billion model 1 billion parameters model on this to to show the performances</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=928" target="_blank">00:15:28.720</a></span> | <span class="t">and it's really competitive with web data set even being much smaller but I would say it can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=934" target="_blank">00:15:34.480</a></span> | <span class="t">it can even be better you know by having more coverage so stay tuned for Cosmopedia 0.2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=940" target="_blank">00:15:40.960</a></span> | <span class="t">coming in April. If we go now to code data there was a very nice release earlier this year called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=949" target="_blank">00:15:49.440</a></span> | <span class="t">Starcoder 2 and the Stack V2 so the Stack V2 is really the largest code data set out there that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=957" target="_blank">00:15:57.360</a></span> | <span class="t">prepared for large language model pre-training it's more than 3 billion files in 600 programming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=965" target="_blank">00:16:05.920</a></span> | <span class="t">languages in total you have like billions of tokens you have roughly 1 trillion tokens in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=971" target="_blank">00:16:11.760</a></span> | <span class="t">Stack V2. So to get all this data basically we didn't crawl ourself we partnered with one of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=978" target="_blank">00:16:18.720</a></span> | <span class="t">non-profit foundation out there called Software Heritage which is a non-profit who has been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=984" target="_blank">00:16:24.560</a></span> | <span class="t">focusing on archiving all code that has been out there since you know 10 years ago really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=991" target="_blank">00:16:31.520</a></span> | <span class="t">and basically there is a question you know when you when you when you all when you gather all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=997" target="_blank">00:16:37.360</a></span> | <span class="t">this data set what do you do do you sell it to I would say private you know closed source companies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1003" target="_blank">00:16:43.040</a></span> | <span class="t">or do you partner with like an open source company to train an open source model on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1007" target="_blank">00:16:47.440</a></span> | <span class="t">and so Software Heritage can reach out to us to partner on the training of a new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1012" target="_blank">00:16:52.880</a></span> | <span class="t">code open source code generation model called Starcoder 2 that you can use as well and which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1018" target="_blank">00:16:58.320</a></span> | <span class="t">is one of one of the best code completion model out there today it's a very large collaboration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1025" target="_blank">00:17:05.120</a></span> | <span class="t">actually an open collaboration so you see all the others there mostly led by Hugging Face and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1032" target="_blank">00:17:12.000</a></span> | <span class="t">great people at ServiceNow. So really go check this out if you're interested in code data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1037" target="_blank">00:17:17.520</a></span> | <span class="t">it's by far the largest and the cleanest data set out there on this. On web data so as I told</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1043" target="_blank">00:17:23.200</a></span> | <span class="t">you we've been working on with the lead author of RefineWeb to get a very large and very high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1049" target="_blank">00:17:29.680</a></span> | <span class="t">quality web data out there so basically a filtered common crawl out there for people to basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1056" target="_blank">00:17:36.720</a></span> | <span class="t">start their training from a high quality data set so this should be also out in the beginning of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1063" target="_blank">00:17:43.440</a></span> | <span class="t">April maybe already next to it so just stay tuned on this. So now that we got our data source we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1070" target="_blank">00:17:50.640</a></span> | <span class="t">need to filter it so filtering by language I would say stay simple fast text by meta facebook</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1077" target="_blank">00:17:57.600</a></span> | <span class="t">is just great so just use fast text it's a great one it's worked pretty fine it has like all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1084" target="_blank">00:18:04.240</a></span> | <span class="t">language you may want to filter. Now that we filter by language we want to start cleaning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1090" target="_blank">00:18:10.800</a></span> | <span class="t">our data sets so there is basically two ways to do that heuristics ML based. We started by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1096" target="_blank">00:18:16.480</a></span> | <span class="t">heuristics the heuristics is this idea that you will count items so basically if your documents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1102" target="_blank">00:18:22.080</a></span> | <span class="t">only have like you know two characters per line probably it's just it's just a bad list or like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1108" target="_blank">00:18:28.720</a></span> | <span class="t">something that you actually don't really want to use in your large language model so as a reminder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1113" target="_blank">00:18:33.600</a></span> | <span class="t">you don't want to use the thing that are naser things that your model will ever generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1118" target="_blank">00:18:38.400</a></span> | <span class="t">and there's another thing that you will think your user might input in your model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1123" target="_blank">00:18:43.440</a></span> | <span class="t">so basically repetition you know a very long repetition of single character something that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1130" target="_blank">00:18:50.320</a></span> | <span class="t">you know have a very strange ratio of alphabetic character to punctuation all these statistics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1138" target="_blank">00:18:58.080</a></span> | <span class="t">that you can extract are way to easily filter documents the nice thing about heuristics is you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1143" target="_blank">00:19:03.840</a></span> | <span class="t">kind of know what you're filtering out you know you wrote the things yourself you can really set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1148" target="_blank">00:19:08.480</a></span> | <span class="t">the threshold by inspecting it and you have a very clear control on what you're removing from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1155" target="_blank">00:19:15.200</a></span> | <span class="t">your data set you know what's what's this so these are the annotations I told you it's kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1161" target="_blank">00:19:21.200</a></span> | <span class="t">control it's robust you know the prior and I would say the drawbacks are that you're only relying on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1167" target="_blank">00:19:27.440</a></span> | <span class="t">surface level okay you're not looking in the meaning of the document you may also remove too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1172" target="_blank">00:19:32.320</a></span> | <span class="t">much sometimes you think you're just removing bad lists but maybe these are also good lists that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1177" target="_blank">00:19:37.200</a></span> | <span class="t">your user may want to input in your model one way to be a little bit more flexible about that is to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1183" target="_blank">00:19:43.600</a></span> | <span class="t">use stochastic removal instead of you know being a one-off binary choice you sample a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1189" target="_blank">00:19:49.520</a></span> | <span class="t">and you keep a little bit of noisy data another drawback is that you will need to carefully tune</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1195" target="_blank">00:19:55.840</a></span> | <span class="t">your hyper parameters here you know the statistics that you want to filter and that's sometimes a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1201" target="_blank">00:20:01.920</a></span> | <span class="t">little bit time-consuming process another way to do data set filtering quality filtering is to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1210" target="_blank">00:20:10.000</a></span> | <span class="t">machine learning filtering so here basically how you do is that you will have a set of good example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1214" target="_blank">00:20:14.960</a></span> | <span class="t">a set of bad example and you will train either a classifier or a perplexity based filtering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1222" target="_blank">00:20:22.480</a></span> | <span class="t">to you know to classify or to predict the next token so classifier based you know usually the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1230" target="_blank">00:20:30.800</a></span> | <span class="t">standard one is to use a fast classification with some n-grams and you label your documents as good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1237" target="_blank">00:20:37.840</a></span> | <span class="t">bad whatever perplexity based you train a very small language model so usually we could we use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1244" target="_blank">00:20:44.240</a></span> | <span class="t">the this this kn uh old model right and we say that if the perplexity is too high then we filter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1252" target="_blank">00:20:52.640</a></span> | <span class="t">documents i would say the advantage is here is that you have a more like semantic understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1259" target="_blank">00:20:59.200</a></span> | <span class="t">hopefully from your ml model even though we use very simple machine learning techniques here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1264" target="_blank">00:21:04.240</a></span> | <span class="t">um and you don't you know need to tweak all the hyper parameter that you tweak for heuristics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1270" target="_blank">00:21:10.560</a></span> | <span class="t">the main disadvantage is that you're not really controlling what you remove okay you you have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1277" target="_blank">00:21:17.920</a></span> | <span class="t">very vague view of what the biases are so let me give you an example wikipedia okay if you train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1284" target="_blank">00:21:24.320</a></span> | <span class="t">your model on wikipedia and you filter based on this wikipedia is written 90 more than 90 actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1292" target="_blank">00:21:32.160</a></span> | <span class="t">by men so you're basically also filtering your pre-training corpus to be mostly male written</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1298" target="_blank">00:21:38.640</a></span> | <span class="t">do you want this bias well maybe not right so these are things that you you still need to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1304" target="_blank">00:21:44.720</a></span> | <span class="t">careful and basically it's really hard to know exactly what bias you're introducing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1313" target="_blank">00:21:53.040</a></span> | <span class="t">um a couple of notes additional on data filtering very important notes actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1317" target="_blank">00:21:57.840</a></span> | <span class="t">you will have several parts in your training data even if it's only web documents you will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1323" target="_blank">00:22:03.920</a></span> | <span class="t">have you know some part of the web data are blog posts some part of the web are you know like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1328" target="_blank">00:22:08.640</a></span> | <span class="t">tutorials some part of these are companies websites all of these are somehow specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1335" target="_blank">00:22:15.840</a></span> | <span class="t">domains and you want to make sure they are all you know um processed in a good way so you need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1342" target="_blank">00:22:22.160</a></span> | <span class="t">to make sure that for each of these big domains that you want to have at the end you actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1346" target="_blank">00:22:26.800</a></span> | <span class="t">didn't do something bad in the pre-processing so there is various way to do that you can you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1351" target="_blank">00:22:31.600</a></span> | <span class="t">cluster and identify a list of documents in a cluster but just one thing to remember about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1357" target="_blank">00:22:37.600</a></span> | <span class="t">all of this and i would say it's a general rule of all good quality data processing is that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1362" target="_blank">00:22:42.800</a></span> | <span class="t">will want to manually inspect the data inspect the data that you've been keeping inspect how it is at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1369" target="_blank">00:22:49.520</a></span> | <span class="t">the end how it was filtered is it still really readable is your latex um document well processed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1378" target="_blank">00:22:58.000</a></span> | <span class="t">is your pdf ocr well extracted manually go through the data that you keep and also through the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1384" target="_blank">00:23:04.720</a></span> | <span class="t">that you remove did you remove something that you think is actually very important you need to sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1390" target="_blank">00:23:10.160</a></span> | <span class="t">you need to take a look you can take a look just at the most important so for instance you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1395" target="_blank">00:23:15.280</a></span> | <span class="t">sort your data by top urls per token and just read 10 documents for this top urls and make sure that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1402" target="_blank">00:23:22.400</a></span> | <span class="t">these 10 documents are really well filtered okay very likely you need to also craft specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1410" target="_blank">00:23:30.320</a></span> | <span class="t">domain focused hyperparameters for instance for your heuristics maybe they will work well for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1416" target="_blank">00:23:36.240</a></span> | <span class="t">blog posts but maybe they will just badly filter latex documents so you can either say okay i craft</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1422" target="_blank">00:23:42.240</a></span> | <span class="t">specific rule for this domain or you can also say i'll just add this domain afterwards uh for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1428" target="_blank">00:23:48.560</a></span> | <span class="t">instance code you could say i remove all code for web and just i'll just add a very big code data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1434" target="_blank">00:23:54.080</a></span> | <span class="t">set but try to think about the implication of doing that okay you will basically remove for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1438" target="_blank">00:23:58.960</a></span> | <span class="t">instance some mixed natural language and code documents so you want to make sure you add this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1444" target="_blank">00:24:04.000</a></span> | <span class="t">back again uh so that your model still cover this type of inputs um as i told you you can also make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1451" target="_blank">00:24:11.520</a></span> | <span class="t">use of some stochastic selection so if a rule is maybe just too hard too harsh you may want to just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1458" target="_blank">00:24:18.880</a></span> | <span class="t">stochastically sample in the filtering so that you keep a little bit of noise you can smooth a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1465" target="_blank">00:24:25.600</a></span> | <span class="t">your rules now the duplication why do you want to do the application well the idea is that there is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1473" target="_blank">00:24:33.920</a></span> | <span class="t">a lot of duplication on the web that's something to really be mindful and to be aware of the web is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1479" target="_blank">00:24:39.920</a></span> | <span class="t">hugely duplicated and so duplication will increase the density around some topics okay wikipedia is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1487" target="_blank">00:24:47.760</a></span> | <span class="t">copied a lot over the internet so maybe that's nice to have a lot of density around wikipedia so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1492" target="_blank">00:24:52.880</a></span> | <span class="t">that you're sure that your model has seen it a lot but um you also have to be aware that duplicated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1498" target="_blank">00:24:58.080</a></span> | <span class="t">points they have more chance of being memorized okay they will also take more time because you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1503" target="_blank">00:25:03.120</a></span> | <span class="t">will go during your training more times over the same data points so it takes more compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1509" target="_blank">00:25:09.040</a></span> | <span class="t">during training and you really want that okay you really need to see that um reducing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1514" target="_blank">00:25:14.960</a></span> | <span class="t">duplication duplication also has been shown to improve accuracy so generally the duplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1519" target="_blank">00:25:19.680</a></span> | <span class="t">is something that's very important and that you want to have a lot uh how can you duplicate well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1527" target="_blank">00:25:27.760</a></span> | <span class="t">you have a couple of methods you have more like fuzzy method where you basically will extract some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1533" target="_blank">00:25:33.040</a></span> | <span class="t">hash fixed size hash of your documents and so you will lose here a little bit of accuracy because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1540" target="_blank">00:25:40.240</a></span> | <span class="t">this hash are just a rough summary of the n grants in your document and then you will want to filter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1545" target="_blank">00:25:45.600</a></span> | <span class="t">them either by min hash which is a i would say quite a good method in general or by bloom filters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1554" target="_blank">00:25:54.800</a></span> | <span class="t">which are much stronger on the duplication because you just keep one hash and just keep one document</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1560" target="_blank">00:26:00.320</a></span> | <span class="t">per hash so it's very it's very strong you have a fixed size vector which is very constraining</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1565" target="_blank">00:26:05.120</a></span> | <span class="t">um and if you don't want to do fuzzy duplication you can use exact duplication where you will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1570" target="_blank">00:26:10.880</a></span> | <span class="t">extract you know uh with a suffix array you will extract exactly all the duplicate in your document</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1577" target="_blank">00:26:17.360</a></span> | <span class="t">they have both trade-off uh in advantages and drawback um exact filtering is very costly in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1586" target="_blank">00:26:26.560</a></span> | <span class="t">memory because the the table the suffix array table are really huge um i say bloom filter is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1594" target="_blank">00:26:34.000</a></span> | <span class="t">very very strong uh a filter so usually we we use a lot for instance in fine where we use a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1600" target="_blank">00:26:40.640</a></span> | <span class="t">min hash because you can you can control you can control a little bit more um your trade-off between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1606" target="_blank">00:26:46.320</a></span> | <span class="t">memory and um and accuracy uh speeding the duplication is also a very big issue i would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1616" target="_blank">00:26:56.400</a></span> | <span class="t">say on very big challenges uh and we saw a very nice very interesting counterintuitive result</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1622" target="_blank">00:27:02.160</a></span> | <span class="t">recently that more duplication also led us to keeping only bad data so basically when we were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1627" target="_blank">00:27:07.040</a></span> | <span class="t">deduplicating more and more all the good data was now taken out and only the the remaining things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1633" target="_blank">00:27:13.760</a></span> | <span class="t">were just basically bad quality data that was not the duplicated but that was just so random that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1640" target="_blank">00:27:20.320</a></span> | <span class="t">didn't fall in the duplication uh buckets so uh i would say for the duplication also be careful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1647" target="_blank">00:27:27.360</a></span> | <span class="t">investigate what you're removing at the end and also what you're keeping and don't be sure don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1653" target="_blank">00:27:33.360</a></span> | <span class="t">don't take this as a silver bullet just like every filter out there it's something that you should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1658" target="_blank">00:27:38.400</a></span> | <span class="t">double check yourself now that we've finished you know uh sourcing language filtering filtering by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1666" target="_blank">00:27:46.640</a></span> | <span class="t">quality heuristic or ml deduplicating uh topic we need to prepare the data for training there's two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1673" target="_blank">00:27:53.600</a></span> | <span class="t">main thing you need to do we need to shuffle it it might seem as a joke but it's still very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1678" target="_blank">00:27:58.160</a></span> | <span class="t">important today you don't want to train in the order of the common crawl terms you want a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1685" target="_blank">00:28:05.040</a></span> | <span class="t">a good shuffling of all your data and then you want to tokenize it so recently there was a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1690" target="_blank">00:28:10.800</a></span> | <span class="t">nice video by by andrej carpati on tokenizer you should watch it if you want to know everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1696" target="_blank">00:28:16.000</a></span> | <span class="t">about tokenizer but generally there's just a set of good practices you should fit you should be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1702" target="_blank">00:28:22.320</a></span> | <span class="t">mindful of the first one i would say is sample well through your whole data set i would say the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1709" target="_blank">00:28:29.440</a></span> | <span class="t">first gpt2 tokenizer was famous for including in in the in the final vocabulary token the name of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1716" target="_blank">00:28:36.400</a></span> | <span class="t">redditors because it was really trained on ready data only you don't want that you want really to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1722" target="_blank">00:28:42.080</a></span> | <span class="t">shuffle so that the single you know the one single part of your data set is not over represented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1728" target="_blank">00:28:48.880</a></span> | <span class="t">in your vocabulary the vocabulary of your model for math you want to be careful about numbers you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1735" target="_blank">00:28:55.360</a></span> | <span class="t">want to be careful that they are well you know you don't have like for instance 42 as a single token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1740" target="_blank">00:29:00.880</a></span> | <span class="t">and 43 as two token because 42 is much more used since uh the douglas adams book and so usually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1749" target="_blank">00:29:09.360</a></span> | <span class="t">what people do is either they split digits so you split all the tickets in every in every number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1755" target="_blank">00:29:15.280</a></span> | <span class="t">that's what for instance llama do or you add you know the list of all numbers manually in your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1762" target="_blank">00:29:22.000</a></span> | <span class="t">vocabulary up to a thousand for instance that's what gpt4 do then you need to be sure that your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1768" target="_blank">00:29:28.320</a></span> | <span class="t">data set is big enough that every number is really well represented in it for code you want to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1774" target="_blank">00:29:34.960</a></span> | <span class="t">mindful about tabs and spaces they're very important for instance in python and so you want to handle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1781" target="_blank">00:29:41.920</a></span> | <span class="t">them well you want to model to know what is a double space and four spaces so just be careful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1787" target="_blank">00:29:47.840</a></span> | <span class="t">about this and for basically if you need something by default i would say a byte level dpe is a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1794" target="_blank">00:29:54.960</a></span> | <span class="t">standard way to train a tokenizer don't fall in a rabbit hole for tokenizer they are not the thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1802" target="_blank">00:30:02.000</a></span> | <span class="t">that will bring you to adi okay this is just something you want to make in a clean way so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1808" target="_blank">00:30:08.720</a></span> | <span class="t">that you don't fall in the in the traps along the way that you're able to process code numbers you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1815" target="_blank">00:30:15.360</a></span> | <span class="t">know that you don't have some strange tokens over represented but that's it by the way you can also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1822" target="_blank">00:30:22.560</a></span> | <span class="t">use tokenizer to inspect your data set i'm going to talk a little bit about that scaling tokenization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1827" target="_blank">00:30:27.840</a></span> | <span class="t">is non-trivial you want to really parallelize that well because otherwise pre-processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1834" target="_blank">00:30:34.240</a></span> | <span class="t">and tokenizing trillions of token can take quite a long time in the end and so there is two main</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1840" target="_blank">00:30:40.400</a></span> | <span class="t">approach the first one is well parallelizing and then finding a way to efficiently merging the post</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1847" target="_blank">00:30:47.360</a></span> | <span class="t">the tokenized data sets and shuffling it and the other way is that you tokenize during training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1853" target="_blank">00:30:53.360</a></span> | <span class="t">basically you feed the direct text to your model and you tokenize just before feeding the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1859" target="_blank">00:30:59.760</a></span> | <span class="t">i would say the the nice thing about the first one is once your doc once your data set is tokenized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1865" target="_blank">00:31:05.280</a></span> | <span class="t">and everything stopping training and continuing training around resuming training is very easy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1870" target="_blank">00:31:10.960</a></span> | <span class="t">it's very efficient it's very reliable and in the second case is well you can change the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1877" target="_blank">00:31:17.920</a></span> | <span class="t">easily but usually you don't really need to do that a lot but resuming and being sure that you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1885" target="_blank">00:31:25.280</a></span> | <span class="t">you know we're starting exactly from where you were is usually slightly trickier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1892" target="_blank">00:31:32.320</a></span> | <span class="t">now how do you evaluate data quality so that's really tricky because we're talking about trillion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1899" target="_blank">00:31:39.920</a></span> | <span class="t">size data sets okay so it's really hard to have some good metrics to evaluate the data quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1905" target="_blank">00:31:45.520</a></span> | <span class="t">so a lot of this is you know inspecting yourself some exact documents as i will tell you and some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1912" target="_blank">00:31:52.240</a></span> | <span class="t">easy i would say one one one good way is training small model to test it so typically what we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1918" target="_blank">00:31:58.000</a></span> | <span class="t">been training here for instance is like one to two billion size model and you train at this on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1923" target="_blank">00:32:03.600</a></span> | <span class="t">like a chinchilla optimal size you don't need to train for longer you're not using this model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1928" target="_blank">00:32:08.480</a></span> | <span class="t">for inference or anything so which is roughly 30 giga token when you train your model you need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1934" target="_blank">00:32:14.960</a></span> | <span class="t">find some high signal benchmark not all the benchmark in nlp are high signal what is a high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1940" target="_blank">00:32:20.480</a></span> | <span class="t">signal there is two way i've seen it uh being being being used one way is to make sure that your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1947" target="_blank">00:32:27.840</a></span> | <span class="t">matrix on this benchmark is monotonically increasing during training okay you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1954" target="_blank">00:32:34.400</a></span> | <span class="t">basically some benchmark where you really see your model learning learning increasingly and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1959" target="_blank">00:32:39.520</a></span> | <span class="t">not like oscillating a lot otherwise depending when you stop you will have like very different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1965" target="_blank">00:32:45.120</a></span> | <span class="t">results you want to have a low variance which means if you train on various seeds if you train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1971" target="_blank">00:32:51.680</a></span> | <span class="t">on various um you know parts of your data set you want to be sure that you're you're roughly in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1978" target="_blank">00:32:58.000</a></span> | <span class="t">same ballpark at least the the standard deviation that you're measuring is small enough that you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1982" target="_blank">00:33:02.800</a></span> | <span class="t">really tell data set apart so usually you will want to have two debugging data sets one of high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1990" target="_blank">00:33:10.080</a></span> | <span class="t">quality a standard very high quality data set is c4 it's a very it's really a data set that has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=1996" target="_blank">00:33:16.800</a></span> | <span class="t">standard test of time in terms of high quality and you want another data set that's maybe much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2002" target="_blank">00:33:22.160</a></span> | <span class="t">more complex the power is some some sometime an example or you can take just a pure common crawl</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2007" target="_blank">00:33:27.040</a></span> | <span class="t">and filtered and you should see really a distance between the measurement on your benchmark on these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2013" target="_blank">00:33:33.760</a></span> | <span class="t">two data sets the performance of your train model on these two data sets and obviously you want your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2019" target="_blank">00:33:39.040</a></span> | <span class="t">model to be above the random baseline you know that's also one indication of a good benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2025" target="_blank">00:33:45.280</a></span> | <span class="t">so if a 1-2 billion size model is not above the random baseline you're just measuring noise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2031" target="_blank">00:33:51.360</a></span> | <span class="t">and there is some tricky details to make sure that you have high signal these are some things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2037" target="_blank">00:33:57.280</a></span> | <span class="t">we have in in light table but basically for instance if you want to measure multiple choices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2042" target="_blank">00:34:02.640</a></span> | <span class="t">question it's often the case for this small benchmark and that's why for instance you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2046" target="_blank">00:34:06.640</a></span> | <span class="t">four continuation you want to predict you know you want to select one of the four small model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2052" target="_blank">00:34:12.720</a></span> | <span class="t">what i call small model is one to two billion size model small models really like more what we call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2059" target="_blank">00:34:19.600</a></span> | <span class="t">normalized likelihood so we'll measure the likelihood of each answer normalize it by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2064" target="_blank">00:34:24.800</a></span> | <span class="t">length and take you know the highest likelihood and larger model when we move to like 30 40</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2071" target="_blank">00:34:31.760</a></span> | <span class="t">even 70 model well trained they will like more you know lettered answer when you explain the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2076" target="_blank">00:34:36.720</a></span> | <span class="t">answer and then you say select between a b c d and the model just generates a b c d and here you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2082" target="_blank">00:34:42.640</a></span> | <span class="t">can have nice calibration curve because you have a very clear uncertainty on this single generated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2088" target="_blank">00:34:48.960</a></span> | <span class="t">token so keep this one for larger model for small model i would say focus on normalized likelihood</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2096" target="_blank">00:34:56.240</a></span> | <span class="t">so these are small model training another thing talk about this a lot but manual data inspection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2102" target="_blank">00:35:02.160</a></span> | <span class="t">take your top domains take your top url inspect 10 documents for each of them inspect also at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2108" target="_blank">00:35:08.400</a></span> | <span class="t">various stages in your pipeline and also take a look at what you've discarded okay always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2116" target="_blank">00:35:16.560</a></span> | <span class="t">you can set up a search tool in your data set that's also very useful you can do some clustering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2122" target="_blank">00:35:22.480</a></span> | <span class="t">to see and to be able also to inspect top documents per maybe more clusters than url so we have here a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2128" target="_blank">00:35:28.800</a></span> | <span class="t">nice library by leandro at hugging face called text clustering we also have a nice search tool</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2136" target="_blank">00:35:36.720</a></span> | <span class="t">in this so really take a look at this library and use it if you think there is a more uncommon that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2143" target="_blank">00:35:43.040</a></span> | <span class="t">that i really like from tevin who was a there was a lot of people at hugging face you know who are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2149" target="_blank">00:35:49.360</a></span> | <span class="t">now at mistral and tevin who is now at mistral also told me once that he used the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2155" target="_blank">00:35:55.600</a></span> | <span class="t">to inspect and basically you can train a tokenizer on your data set and you can take a look at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2162" target="_blank">00:36:02.560</a></span> | <span class="t">longest token and maybe the last token so the less the less the least frequent token and see there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2169" target="_blank">00:36:09.520</a></span> | <span class="t">okay do you have strange things do you have like javascript parts do you have like name of redditors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2174" target="_blank">00:36:14.880</a></span> | <span class="t">like i was telling you and if they look bad that means that you have some high frequency of bad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2181" target="_blank">00:36:21.840</a></span> | <span class="t">quality data in your data set um here we have some nice library that we've been releasing you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2190" target="_blank">00:36:30.320</a></span> | <span class="t">just last month for doing all of this all of this data processing pipelines it's called data trove</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2196" target="_blank">00:36:36.560</a></span> | <span class="t">it's by uh gilerme the lead author of refined web and basically it started as an open reproduction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2203" target="_blank">00:36:43.200</a></span> | <span class="t">of refined web so a very high quality filtered common crawl and what we ended up was kind of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2209" target="_blank">00:36:49.360</a></span> | <span class="t">fully fledged lightweight library for processing filter the duplicated test data and basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2214" target="_blank">00:36:54.880</a></span> | <span class="t">preparing very large data set for other than training you have pre-built block for all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2221" target="_blank">00:37:01.280</a></span> | <span class="t">steps that i showed you here it's fully in python and it's very easy to set up on slurm or locally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2229" target="_blank">00:37:09.360</a></span> | <span class="t">and to use remote file system as well if you need to so take a look at data trove it's a very small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2237" target="_blank">00:37:17.440</a></span> | <span class="t">library i would say self-contained python thing but you really you have all the basic blocks that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2242" target="_blank">00:37:22.000</a></span> | <span class="t">you may want to use here um when you want to evaluate your model we have one library that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2247" target="_blank">00:37:27.840</a></span> | <span class="t">works well with data trove and the pipeline which is called light evil light evil is a very lightweight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2254" target="_blank">00:37:34.640</a></span> | <span class="t">llm evaluation suite usually inspired by the amazing eluther airness i would say the main</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2261" target="_blank">00:37:41.600</a></span> | <span class="t">difference is that integrate from the ground up 3d parallelism i'm going to talk about next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2267" target="_blank">00:37:47.600</a></span> | <span class="t">so basically efficient model uh training and inference and you can play a lot with the prompts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2274" target="_blank">00:37:54.560</a></span> | <span class="t">and the eval so i was telling you for instance small model really like this like normalized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2280" target="_blank">00:38:00.240</a></span> | <span class="t">log likelihood while while bigger model like more like lettered answers and so here you can play with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2286" target="_blank">00:38:06.000</a></span> | <span class="t">the prompts easily and so to see how much signal you can extract for each benchmark on your specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2294" target="_blank">00:38:14.560</a></span> | <span class="t">debugging model size now we've talked a lot about data so let's talk a little bit about modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2303" target="_blank">00:38:23.040</a></span> | <span class="t">that's the part everyone is waiting for that's the most exciting part easily that's the reason we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2307" target="_blank">00:38:27.840</a></span> | <span class="t">all in ml and i'm very happy to still cover this i would say so what are the essential elements when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2314" target="_blank">00:38:34.320</a></span> | <span class="t">you train well there is three main thing the first one is efficiency and size you want to fit your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2321" target="_blank">00:38:41.280</a></span> | <span class="t">billion parameters model efficiently on your gpu and you want to train really fast so you have some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2326" target="_blank">00:38:46.800</a></span> | <span class="t">recepts for this that i'm going to cover quickly and then you want to train in a kind of a roughly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2333" target="_blank">00:38:53.760</a></span> | <span class="t">stable way you have to avoid instabilities but still you want to stay really close to it and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2339" target="_blank">00:38:59.360</a></span> | <span class="t">then you have the last question which is capacity and that's where we're going to talk a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2343" target="_blank">00:39:03.200</a></span> | <span class="t">about other architecture than just the transformers but that's i would say just the last part so how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2349" target="_blank">00:39:09.680</a></span> | <span class="t">do you train model efficiently in particular when it's too big to fit on one gpu so when it fits on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2354" target="_blank">00:39:14.800</a></span> | <span class="t">one gpu there is no real problem right so you won't be model no problem your 7 13 30b model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2363" target="_blank">00:39:23.920</a></span> | <span class="t">they are just too big for one gpu and a decent batch size so you need to parallelize them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2368" target="_blank">00:39:28.400</a></span> | <span class="t">today we have four way to do parallelism roughly we have data parallelism that's something everyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2375" target="_blank">00:39:35.040</a></span> | <span class="t">has been using already i would say you have tensor parallelism pipeline parallelism and a much more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2381" target="_blank">00:39:41.840</a></span> | <span class="t">recent i would say or slightly more recent sequence parallelism i'm going to cover them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2386" target="_blank">00:39:46.080</a></span> | <span class="t">briefly so i would say here my idea is more to give you kind of a overview of everything more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2392" target="_blank">00:39:52.080</a></span> | <span class="t">than really dive deep because in each of these topics you could dive really deep in a technical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2397" target="_blank">00:39:57.360</a></span> | <span class="t">point of view okay so this is really entry level and i put some references again just select a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2404" target="_blank">00:40:04.400</a></span> | <span class="t">couple of references that you can read to dive deeper in this let's start with the first parallelism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2409" target="_blank">00:40:09.280</a></span> | <span class="t">data parallelism usually it works out of the box that's the easiest one the only challenge is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2415" target="_blank">00:40:15.840</a></span> | <span class="t">data loading to make sure that your mobile replica will have different data as input so what does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2424" target="_blank">00:40:24.640</a></span> | <span class="t">data parallelism do you take the one model and you duplicate it on several gpu you feed it several</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2431" target="_blank">00:40:31.360</a></span> | <span class="t">parts of your batch and then you just you know match the gradient reduce the gradients so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2437" target="_blank">00:40:37.200</a></span> | <span class="t">you have basically a larger batch on three gpu for instance than you had on one gpu so you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2443" target="_blank">00:40:43.040</a></span> | <span class="t">process on parallel you know different part of your data and you just make the optimization step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2449" target="_blank">00:40:49.360</a></span> | <span class="t">the main challenge i would say is the last part is the all reduce that you use to to kind of merge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2456" target="_blank">00:40:56.960</a></span> | <span class="t">the gradient updates and actually when you scale very large model it can start to become a huge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2463" target="_blank">00:41:03.120</a></span> | <span class="t">bottleneck so we'll talk a little bit about that um yeah the tensor parallelism is when you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2473" target="_blank">00:41:13.200</a></span> | <span class="t">want to when you're limited in your data parallelism so why would you be limited by data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2479" target="_blank">00:41:19.520</a></span> | <span class="t">parallelism there is two main cases one case is basically your model is just too big to fit on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2485" target="_blank">00:41:25.120</a></span> | <span class="t">one gpu so you cannot replicate your model on various gpu you need to split the model somehow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2492" target="_blank">00:41:32.400</a></span> | <span class="t">the other case is when your batch size by replicating the model start to be too big</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2497" target="_blank">00:41:37.920</a></span> | <span class="t">okay so let's say you want to really scale the model and now you start to have like one to four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2504" target="_blank">00:41:44.320</a></span> | <span class="t">million token batch size well if you start to have a very large batch size the model for each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2510" target="_blank">00:41:50.240</a></span> | <span class="t">optimization step make less efficient use of each token because the batch size is so big that each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2517" target="_blank">00:41:57.520</a></span> | <span class="t">token is kind of watched out in the optimization step and roughly it's a little bit hard to measure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2523" target="_blank">00:42:03.520</a></span> | <span class="t">this limit which we call the critical batch size it's roughly around four to six million token it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2529" target="_blank">00:42:09.200</a></span> | <span class="t">different for like small and bigger model but basically you cannot really go to 100 million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2534" target="_blank">00:42:14.960</a></span> | <span class="t">token base like that so you want to find another way to parallelize to make more efficient use of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2541" target="_blank">00:42:21.440</a></span> | <span class="t">your data and so one way to do that is to use tensor parallelism tensor parallelism is slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2548" target="_blank">00:42:28.640</a></span> | <span class="t">more involved because you need to rewrite your model code you cannot just rewrite the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2553" target="_blank">00:42:33.440</a></span> | <span class="t">loading code you need to change the model why because you will divide all the matrix multiplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2559" target="_blank">00:42:39.600</a></span> | <span class="t">all the matrices that we use in the model into or like four or like eight depending on your tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2565" target="_blank">00:42:45.440</a></span> | <span class="t">parallelism degree and you will put each part of the weights each sub part of this weight matrices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2573" target="_blank">00:42:53.360</a></span> | <span class="t">on various gpu and synchronization will happen after the operation so here you need to rewind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2581" target="_blank">00:43:01.040</a></span> | <span class="t">model code the nice thing is that you can combine smart column and row slicing to try to reduce the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2587" target="_blank">00:43:07.120</a></span> | <span class="t">number of synchronization points let me show you a little bit here you have two main parts in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2594" target="_blank">00:43:14.000</a></span> | <span class="t">transformer as you may remember you have feed forward networks you know you usually have two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2600" target="_blank">00:43:20.160</a></span> | <span class="t">two matrix multiplication with an activation in between it can be a bit more if you're using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2606" target="_blank">00:43:26.720</a></span> | <span class="t">something different than just if you're using clue but basically you will have one matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2610" target="_blank">00:43:30.720</a></span> | <span class="t">multiplication some activation and another matrix multiplication okay and here you can basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2617" target="_blank">00:43:37.680</a></span> | <span class="t">split the first matrix multiplication in one direction usually column wise you do separately</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2624" target="_blank">00:43:44.880</a></span> | <span class="t">your activation on each gpu you don't need to synchronize and then you gather by doing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2630" target="_blank">00:43:50.480</a></span> | <span class="t">opposite slicing at the end on the second matrix multiplication you do a row slicing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2636" target="_blank">00:43:56.080</a></span> | <span class="t">to gather again your output your activation you can do the same smart thing for self-attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2644" target="_blank">00:44:04.320</a></span> | <span class="t">where you will do one part matrix multiplication in one direction you will split the matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2649" target="_blank">00:44:09.200</a></span> | <span class="t">you will do like softmax dropouts separately and then you will combine them with you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2655" target="_blank">00:44:15.360</a></span> | <span class="t">another parallel operation in the other direction this way you reduce the number of synchronization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2664" target="_blank">00:44:24.160</a></span> | <span class="t">point because you can do a couple of like operation without needing to synchronize between the gpu</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2669" target="_blank">00:44:29.360</a></span> | <span class="t">the tricky part is always that when you're synchronized you're going through the network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2673" target="_blank">00:44:33.680</a></span> | <span class="t">that's much that's much slower than just the computation the last part that you can use when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2680" target="_blank">00:44:40.960</a></span> | <span class="t">you when you don't want to use tensor parallelism or when you cannot scale tensor parallelism enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2685" target="_blank">00:44:45.120</a></span> | <span class="t">is pipeline parallelism so usually you want pipeline parallelism when your like network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2690" target="_blank">00:44:50.800</a></span> | <span class="t">is not fast enough to do full tensor parallelism everywhere okay pipeline parallelism reduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2698" target="_blank">00:44:58.480</a></span> | <span class="t">the number of network exchanges because you will put some layers on some gpu</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2703" target="_blank">00:45:03.360</a></span> | <span class="t">and other layers and other gpu and you will just communicate at the interface between two layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2709" target="_blank">00:45:09.920</a></span> | <span class="t">or like two groups of layers so you can see here you will put one for instance level layer two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2717" target="_blank">00:45:17.520</a></span> | <span class="t">zero to three on one gpu layer four to seven on the second gpu etc etc here the challenge i would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2724" target="_blank">00:45:24.800</a></span> | <span class="t">say is to keep all the gpu busy so you don't want to have just you know one group one gpu working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2730" target="_blank">00:45:30.880</a></span> | <span class="t">for the first layers of your batch and then being idle while you have the other gpu working for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2737" target="_blank">00:45:37.040</a></span> | <span class="t">other layer you know as we go as we go forward in the model and it can be very challenging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2743" target="_blank">00:45:43.520</a></span> | <span class="t">to actually keep have maximal utilization of the gpu so usually you have like complex interleaving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2750" target="_blank">00:45:50.320</a></span> | <span class="t">of the forward and the backward path so i can show you here a little bit where you have the forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2756" target="_blank">00:45:56.480</a></span> | <span class="t">path in blue and the backwards path in green and you can see what we do in this case is that we will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2762" target="_blank">00:46:02.960</a></span> | <span class="t">split our batch in smaller sub-batch mini-batches so for instance we split a long batch in four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2770" target="_blank">00:46:10.800</a></span> | <span class="t">mini-batches and when the first mini-batch is done on the last device we already start the backward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2778" target="_blank">00:46:18.400</a></span> | <span class="t">while we are still doing the forward path on the other gpu for the last batches and this way you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2784" target="_blank">00:46:24.800</a></span> | <span class="t">can reduce what we call the bubble the tricky thing here as you probably got it is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2790" target="_blank">00:46:30.000</a></span> | <span class="t">for tensor parallelism you needed to rewrite the model code as i told you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2794" target="_blank">00:46:34.880</a></span> | <span class="t">and here you also need to rewrite the optimization code okay you cannot just do forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2801" target="_blank">00:46:41.680</a></span> | <span class="t">and then you're lost at backward because you have parallel execution of a backward and forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2808" target="_blank">00:46:48.880</a></span> | <span class="t">path so this makes using the code quite complex and that's why actually we have a new library</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2813" target="_blank">00:46:53.680</a></span> | <span class="t">called nanotron that's right to have this as simple as possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2817" target="_blank">00:46:57.440</a></span> | <span class="t">there is a last way to do parallelization called sequence parallelism so be careful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2825" target="_blank">00:47:05.040</a></span> | <span class="t">because there is two use of sequence parallelism there is one which is kind of a smart way to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2830" target="_blank">00:47:10.800</a></span> | <span class="t">ring attention to do attention on very long sequences but the one i talk a little bit about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2836" target="_blank">00:47:16.240</a></span> | <span class="t">today is another simpler way it's quite similar to tensor parallelism in a way but instead of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2843" target="_blank">00:47:23.280</a></span> | <span class="t">slicing the parameter matrices like we do we slice the sequence this way and the idea is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2849" target="_blank">00:47:29.680</a></span> | <span class="t">if you took tensor parallelism here it's the top box we still had some operation between each tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2858" target="_blank">00:47:38.080</a></span> | <span class="t">parallelism operation where we were not really parallelized in any way and the idea is on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2864" target="_blank">00:47:44.160</a></span> | <span class="t">operation which are applied independently for each token we could split along the sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2872" target="_blank">00:47:52.880</a></span> | <span class="t">and so we could parallelize this along the sequence axis it's only interesting you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2878" target="_blank">00:47:58.720</a></span> | <span class="t">doing training usually because you need long sequences or which is a little bit doing prefill</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2883" target="_blank">00:48:03.600</a></span> | <span class="t">now what can you read if you want to know more about this there is many reference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2890" target="_blank">00:48:10.480</a></span> | <span class="t">on parallelism i try to extract i think the one and i think give you the highest level overview</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2896" target="_blank">00:48:16.480</a></span> | <span class="t">i would say and cover as much as possible of this thing i really like this first paper from joel at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2902" target="_blank">00:48:22.960</a></span> | <span class="t">service now which is not very well known but i think it's very interesting as it covers like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2908" target="_blank">00:48:28.160</a></span> | <span class="t">lot of challenges here red first pipeline parallelism reducing activation computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2914" target="_blank">00:48:34.320</a></span> | <span class="t">in large transformer model is very nice one and the last one is actually the one on sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2920" target="_blank">00:48:40.320</a></span> | <span class="t">parallelism that i told you and the last one called sequence parallelism is actually this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2924" target="_blank">00:48:44.960</a></span> | <span class="t">ring attention paper that i think is also very interesting but more maybe an extension of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2930" target="_blank">00:48:50.800</a></span> | <span class="t">presentation now we talk about a lot about parallelization okay but there is an additional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2936" target="_blank">00:48:56.960</a></span> | <span class="t">thing that you need to be mindful about is synchronization i already talked a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2941" target="_blank">00:49:01.680</a></span> | <span class="t">about synchronization okay during tensor parallelism and the thing i talk a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2945" target="_blank">00:49:05.840</a></span> | <span class="t">about reducing synchronization and here you you have to be very careful about that well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2950" target="_blank">00:49:10.720</a></span> | <span class="t">why well you have two type of synchronization you have one synchronization which is between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2955" target="_blank">00:49:15.920</a></span> | <span class="t">values gpu which is uh basically when you when you do like a like a like a reduced operation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2964" target="_blank">00:49:24.080</a></span> | <span class="t">in tensor parallelism and you have one synchronization which is between cpu and gpu which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2969" target="_blank">00:49:29.120</a></span> | <span class="t">is when your cpu basically launched the kernel on gpu and you want to reduce or at least you want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2975" target="_blank">00:49:35.920</a></span> | <span class="t">make sure that for both of these as much as possible you can do an overlap of computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2982" target="_blank">00:49:42.560</a></span> | <span class="t">and communication so basically if you can do something called asynchronous computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2988" target="_blank">00:49:48.160</a></span> | <span class="t">basically where you will asynchronously start some operation and do some communication during</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2993" target="_blank">00:49:53.760</a></span> | <span class="t">this time it's much better so let me talk about two things we we talk a little bit during the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=2999" target="_blank">00:49:59.600</a></span> | <span class="t">data parallelism part about the cost of the all reduce at the end so that's something you probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3005" target="_blank">00:50:05.520</a></span> | <span class="t">have been using already without knowing it in pytorch which is if you look at the distributed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3011" target="_blank">00:50:11.600</a></span> | <span class="t">data parallel so the ddp uh in pytorch you can see that there is a very smart way to do all reduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3020" target="_blank">00:50:20.000</a></span> | <span class="t">so let's look at here basically typically you will usually do like all your forward and your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3024" target="_blank">00:50:24.960</a></span> | <span class="t">backward and then you will do your all reduce at the end okay well this is very annoying because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3032" target="_blank">00:50:32.000</a></span> | <span class="t">during the all reduce where you gather all your gradient together you don't do any computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3038" target="_blank">00:50:38.000</a></span> | <span class="t">you're just waiting for synchronization there you're just waiting for your gpu to exchange</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3043" target="_blank">00:50:43.440</a></span> | <span class="t">all the all the great and that's not something you really want you want to keep your gpu busy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3048" target="_blank">00:50:48.560</a></span> | <span class="t">so if you have a way that once every time um one layer is finished with computing you can already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3054" target="_blank">00:50:54.880</a></span> | <span class="t">start you know reducing you can already start in parallel to computation you can already start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3060" target="_blank">00:51:00.000</a></span> | <span class="t">communicating gradient then you should try to do that and if you take a look at the pytorch code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3065" target="_blank">00:51:05.440</a></span> | <span class="t">for for distributed data parallel that's something that they do um another example is in pipeline</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3073" target="_blank">00:51:13.440</a></span> | <span class="t">parallelism you know we saw this this this uh forward backward reducing of the bubble and here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3082" target="_blank">00:51:22.160</a></span> | <span class="t">you can also try to you know overlap this very long here g so this very long gradient reduction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3089" target="_blank">00:51:29.360</a></span> | <span class="t">here with some you know forward pass of the next batch and just a quick example and a quicker note</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3100" target="_blank">00:51:40.960</a></span> | <span class="t">about cp and gpu synchronization here what you will want is to reduce as much as possible the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3106" target="_blank">00:51:46.800</a></span> | <span class="t">number of time your cpu need to inspect the data or need to start a kernel so we want to fuse kernel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3114" target="_blank">00:51:54.000</a></span> | <span class="t">so you want to fuse the operation that could go together the result of your attention your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3118" target="_blank">00:51:58.720</a></span> | <span class="t">activation if you can do all of that in the gpu without the cpu needing to say okay now it's time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3124" target="_blank">00:52:04.960</a></span> | <span class="t">to compute the activation now it's time to do you should do that so that's usually done by merging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3130" target="_blank">00:52:10.000</a></span> | <span class="t">merging operation in single kernels um now i want to talk a little bit about attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3138" target="_blank">00:52:18.240</a></span> | <span class="t">that's very interesting because if you were already in the field like one year one year</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3143" target="_blank">00:52:23.760</a></span> | <span class="t">and a half ago a little bit more maybe now um we had a lot of work on designing efficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3150" target="_blank">00:52:30.720</a></span> | <span class="t">attention computation because people were really very scared by the quadratic cost of attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3158" target="_blank">00:52:38.720</a></span> | <span class="t">okay and all of this disappeared now you know there was like all this reformer all these very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3164" target="_blank">00:52:44.160</a></span> | <span class="t">long attention smart and the main reason this disappeared was that uh our friend tree dao at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3172" target="_blank">00:52:52.000</a></span> | <span class="t">stanford invented flash attention flash attention the idea is basically you will just not materialize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3179" target="_blank">00:52:59.520</a></span> | <span class="t">the attention matrix so the attention matrix is this very like large is the n square sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3186" target="_blank">00:53:06.000</a></span> | <span class="t">square size matrices comparing each token you know to make the attention between all of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3192" target="_blank">00:53:12.000</a></span> | <span class="t">what you could do is instead of building these very large matrices you can just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3196" target="_blank">00:53:16.880</a></span> | <span class="t">on the fly you know build small matrices and just keep the statistics that you need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3201" target="_blank">00:53:21.200</a></span> | <span class="t">to compute your softmax along the way and that's what flash attention does that's the first step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3207" target="_blank">00:53:27.040</a></span> | <span class="t">and the second step for flash attention is that if you just compute along the way small part of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3212" target="_blank">00:53:32.720</a></span> | <span class="t">your attention matrix you may even have this small part small enough so that they fit actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3219" target="_blank">00:53:39.760</a></span> | <span class="t">in the sram of the gpu so the static random access memory the sram is a much much smaller memory but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3230" target="_blank">00:53:50.560</a></span> | <span class="t">which is really next to each chip and this this this cannot be shared between processes right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3236" target="_blank">00:53:56.320</a></span> | <span class="t">this has to be this is a single memory for for a group of of processing while the hbm the high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3244" target="_blank">00:54:04.240</a></span> | <span class="t">bandwidth memory is shared by everything so it's the it's the hbm is this 80 or 40 gigabytes memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3250" target="_blank">00:54:10.800</a></span> | <span class="t">you know that you see it's really large but it's also much smaller and much lower bandwidth than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3256" target="_blank">00:54:16.240</a></span> | <span class="t">this sram okay so you can compute just like your attention not in one big memory but in small one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3263" target="_blank">00:54:23.200</a></span> | <span class="t">with statistics and the small one can be small enough to be fitted in the very very high bandwidth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3268" target="_blank">00:54:28.320</a></span> | <span class="t">memory and this way you can actually compute attention really much faster and while using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3274" target="_blank">00:54:34.800</a></span> | <span class="t">actually much less memory so flash attention can solve somehow the quadratic attention costs of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3281" target="_blank">00:54:41.680</a></span> | <span class="t">attention and that's why we don't really care a lot anymore about you know linear attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3289" target="_blank">00:54:49.040</a></span> | <span class="t">mechanism for instance also because performance were never able to match full attention somehow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3295" target="_blank">00:54:55.840</a></span> | <span class="t">just apart from sparse attention in some way flash attention v2 was a development of flash</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3302" target="_blank">00:55:02.320</a></span> | <span class="t">attention still roughly two times faster and here the idea was mostly to really have as much as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3309" target="_blank">00:55:09.440</a></span> | <span class="t">possible of the computation in matmul flop so you have to know something about gp as well which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3316" target="_blank">00:55:16.400</a></span> | <span class="t">gpu already optimized to do matrix matrix multiplication so each time you do something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3322" target="_blank">00:55:22.560</a></span> | <span class="t">like a division or something basically else than a multiplication you're paying a cost and the cost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3329" target="_blank">00:55:29.600</a></span> | <span class="t">is very expensive a division is like 60 times more expensive than a multiplication and so for instance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3336" target="_blank">00:55:36.720</a></span> | <span class="t">when we do softmax we usually divide by some normalization like some some number some square</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3343" target="_blank">00:55:43.200</a></span> | <span class="t">root of the dimension of our model we want to keep this and do it just one time at the end you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3348" target="_blank">00:55:48.000</a></span> | <span class="t">want to do that every you know on every and every element of your computation so these type of things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3354" target="_blank">00:55:54.960</a></span> | <span class="t">are basically what flash attention 2 is bringing with also a better parallelism causal mask if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3361" target="_blank">00:56:01.600</a></span> | <span class="t">you're just computing causal mask you just don't need to compute half of the matrix and just better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3366" target="_blank">00:56:06.720</a></span> | <span class="t">work partitioning and using more better like the blocks and the wraps of the gpu so i won't dive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3371" target="_blank">00:56:11.920</a></span> | <span class="t">into this because there's a lot to unfold here but i would say it's more like a little bit more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3377" target="_blank">00:56:17.440</a></span> | <span class="t">incremental but it's still like very very nice beta so now that we have something efficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3384" target="_blank">00:56:24.880</a></span> | <span class="t">we've parallelized this well we have a very efficient attention computation we want to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3390" target="_blank">00:56:30.800</a></span> | <span class="t">sure that we train well and here don't miss this hyperparameter search you have a couple of very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3397" target="_blank">00:56:37.760</a></span> | <span class="t">important things that you need to go over learning rate you want to do a nice hyperparameter search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3403" target="_blank">00:56:43.360</a></span> | <span class="t">you want to make sure that your initialization is well done you want to create a normal where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3408" target="_blank">00:56:48.480</a></span> | <span class="t">they need to be you want to make sure that your training is stable but also that you're not too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3413" target="_blank">00:56:53.840</a></span> | <span class="t">stable that you still at the verge of like you're still training with very high learning rate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3418" target="_blank">00:56:58.000</a></span> | <span class="t">and here i would say there is very few uh recent work on this but there is two that i really like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3425" target="_blank">00:57:05.120</a></span> | <span class="t">there is the mu transfer work slightly older i would say now but it's still very very interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3430" target="_blank">00:57:10.160</a></span> | <span class="t">on how to find a hyperparameter on a small model and how to scale them on a larger model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3435" target="_blank">00:57:15.920</a></span> | <span class="t">this work by cerebras was maybe one of the most interesting application of mu transfer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3442" target="_blank">00:57:22.480</a></span> | <span class="t">and a very interesting recent work from also a chinese team again but very well you know set of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3450" target="_blank">00:57:30.240</a></span> | <span class="t">experiments open source is this mini cpm block post where they really try to optimize the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3456" target="_blank">00:57:36.800</a></span> | <span class="t">and to optimize you know the uh scaling of activation between various part of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3462" target="_blank">00:57:42.800</a></span> | <span class="t">how you want to scale the activation between embeddings and then the first layers etc so you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3467" target="_blank">00:57:47.200</a></span> | <span class="t">should really probably should really give it a look what is also very interesting is that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3471" target="_blank">00:57:51.680</a></span> | <span class="t">challenged the dominant view that cosine learning rate was the end learning rate that everyone should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3478" target="_blank">00:57:58.800</a></span> | <span class="t">use from now on cosine is still that really the great great default learning rate but they use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3483" target="_blank">00:58:03.920</a></span> | <span class="t">a linear plus uh you know warm up and decay and they show that they do have some uh decent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3490" target="_blank">00:58:10.960</a></span> | <span class="t">performances with that as well and the nice thing about having a linear uh learning rate like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3497" target="_blank">00:58:17.680</a></span> | <span class="t">constant learning rate is that you don't need to know from the beginning how long you will train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3503" target="_blank">00:58:23.760</a></span> | <span class="t">your model on and that's very interesting because the cosine kind of force you in a very specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3509" target="_blank">00:58:29.520</a></span> | <span class="t">shape where you need to decide from the beginning of your training how long you are going to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3514" target="_blank">00:58:34.480</a></span> | <span class="t">and you cannot resume for longer and if we find a way to have good performances with like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3519" target="_blank">00:58:39.440</a></span> | <span class="t">a flat learning rate and just like warm up decay decay is very important that's what they show in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3523" target="_blank">00:58:43.840</a></span> | <span class="t">this paper um then maybe we can get away uh out of this constraint of knowing from the beginning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3532" target="_blank">00:58:52.960</a></span> | <span class="t">how long we're going to train so uh take a look at this paper i think they're very nice in terms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3537" target="_blank">00:58:57.120</a></span> | <span class="t">of stable training recipes and the takeaway here i would say is don't skip this step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3543" target="_blank">00:59:03.440</a></span> | <span class="t">do your work in terms of research for hyperparameters now the last part uh that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3553" target="_blank">00:59:13.920</a></span> | <span class="t">the one usually people spend the most time on talking about so it's a good indication that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3559" target="_blank">00:59:19.520</a></span> | <span class="t">that's it's also the least important part but yeah let me still talk a little bit about this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3564" target="_blank">00:59:24.640</a></span> | <span class="t">for a long time transformer were believed to be the end architecture so uh maybe slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3573" target="_blank">00:59:33.280</a></span> | <span class="t">sad i would say for the field that we didn't have anything new since you know the transformer paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3579" target="_blank">00:59:39.200</a></span> | <span class="t">in 2018 and uh recently there was two extension they want to cover one is mixture of expert</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3587" target="_blank">00:59:47.440</a></span> | <span class="t">so mixture of experts reduced to transformers in the limit of one experts so it's still slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3593" target="_blank">00:59:53.440</a></span> | <span class="t">a stretch to say that it's a fully new architecture but it's still very interesting as a new knob</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3599" target="_blank">00:59:59.360</a></span> | <span class="t">to you know play with capacity um so basically one problem was that until now it was not very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3606" target="_blank">01:00:06.240</a></span> | <span class="t">efficient to train a mixture of experts so let me explain you a little bit okay in a mixture of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3611" target="_blank">01:00:11.280</a></span> | <span class="t">experts when you go through uh when your sequence of tokens will go through your model at some point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3617" target="_blank">01:00:17.280</a></span> | <span class="t">you will have a router that will say for each token where in which experts should this token go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3623" target="_blank">01:00:23.440</a></span> | <span class="t">and experts are basically at the mlp level feed forward so you have basically several mlp several</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3629" target="_blank">01:00:29.600</a></span> | <span class="t">feed forward layers and you will select like these are the number of your experts for instance three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3634" target="_blank">01:00:34.880</a></span> | <span class="t">feed forward layers three different feed forward layer will be three experts and your router will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3640" target="_blank">01:00:40.240</a></span> | <span class="t">say for each token okay you should go through to expert one to expert two to expert three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3645" target="_blank">01:00:45.040</a></span> | <span class="t">now each each expert was designed to be able to welcome a certain number of token so for instance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3652" target="_blank">01:00:52.960</a></span> | <span class="t">two token in this example here okay and if three token should go to one expert and then two token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3659" target="_blank">01:00:59.680</a></span> | <span class="t">to one and one to the last one the expert that would get three token was not able to welcome</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3665" target="_blank">01:01:05.040</a></span> | <span class="t">them all and so would drop one token so without one token that would just be not used in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3671" target="_blank">01:01:11.440</a></span> | <span class="t">computation one input token so that's quite strong i would say as a as a impact that means you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3677" target="_blank">01:01:17.760</a></span> | <span class="t">kind of ignoring a part of your inputs and that led to i would say non-optimal performances</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3684" target="_blank">01:01:24.240</a></span> | <span class="t">but that was needed for the sake of having a very uh determined like a very static you know matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3691" target="_blank">01:01:31.760</a></span> | <span class="t">and our gpu and tpu are not really well adapt to dynamic architecture well recently using ideas of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3699" target="_blank">01:01:39.600</a></span> | <span class="t">sparsity but not too sparse because we also know gpu don't really like very sparse matrices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3704" target="_blank">01:01:44.880</a></span> | <span class="t">but you can they are actually quite good for block sparse matrices so what is block sparse this means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3710" target="_blank">01:01:50.160</a></span> | <span class="t">you it's sparse but you have blocks and these blocks are big enough so that they make efficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3715" target="_blank">01:01:55.120</a></span> | <span class="t">use of the gpus you know so they are big enough that they will fill like your your math mill here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3720" target="_blank">01:02:00.080</a></span> | <span class="t">you will have like enough to crush um but between these blocks you have like empty places and here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3728" target="_blank">01:02:08.160</a></span> | <span class="t">this is basically what mega blocks recently did and that's how it unlocked actually efficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3733" target="_blank">01:02:13.920</a></span> | <span class="t">mixture of expert training which is saying maybe our experts could be these blocks they are very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3739" target="_blank">01:02:19.520</a></span> | <span class="t">big feed-forward matrices and if we actually use this we could just like repeat this block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3746" target="_blank">01:02:26.320</a></span> | <span class="t">for the various number of token and we can maybe dynamically do the sparsity because it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3752" target="_blank">01:02:32.880</a></span> | <span class="t">it's actually just blocks that will repeat so it's i would say it's a kind of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3757" target="_blank">01:02:37.760</a></span> | <span class="t">low level of dynamicity uh low level low enough that it can be very efficient so that's basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3765" target="_blank">01:02:45.360</a></span> | <span class="t">what kind of changed the the thing here we don't need to drop token anymore we can just dynamically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3770" target="_blank">01:02:50.880</a></span> | <span class="t">build these big sparse matrices from experts and it actually even opened the door for something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3776" target="_blank">01:02:56.800</a></span> | <span class="t">i think nobody has been really using yet which is you could have experts of various sizes you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3782" target="_blank">01:03:02.080</a></span> | <span class="t">add you could have like big experts smaller experts etc etc very interesting and i'm really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3789" target="_blank">01:03:09.760</a></span> | <span class="t">looking forward to uh what will be built on top of this another interesting development was kind of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3796" target="_blank">01:03:16.480</a></span> | <span class="t">revival of recurrence model and you have two uh main uh model well i mean i just talk about mamba</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3804" target="_blank">01:03:24.880</a></span> | <span class="t">and the idea here is that you can you can use like space state space model so if you're just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3812" target="_blank">01:03:32.000</a></span> | <span class="t">out of your master in ai you probably learn about space states model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3816" target="_blank">01:03:36.720</a></span> | <span class="t">there are these discrete models this continuous model that make evolving you know a space state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3825" target="_blank">01:03:45.120</a></span> | <span class="t">and here the all the smart all the smart thing was about how to discretize this and keep this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3830" target="_blank">01:03:50.080</a></span> | <span class="t">efficient and so that was solved by um by albert gu and and again for flash attention and how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3837" target="_blank">01:03:57.920</a></span> | <span class="t">train this efficient it's very funny because when you train this mamba model when you train it it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3843" target="_blank">01:04:03.120</a></span> | <span class="t">behave kind of like a like a convolution convolutional network and when you use it in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3847" target="_blank">01:04:07.760</a></span> | <span class="t">inference you can use it in a kind of a recurrence mode so it's really really fast actually um mamba</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3853" target="_blank">01:04:13.840</a></span> | <span class="t">itself is quite hard to dive in and i think the best entry point is again an annotated blog post</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3860" target="_blank">01:04:20.080</a></span> | <span class="t">by sasha rush so maybe you learn about the transformer architecture from the annotated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3865" target="_blank">01:04:25.680</a></span> | <span class="t">transformer by sasha rush a few years ago so now you have also annotated mamba blog posts which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3872" target="_blank">01:04:32.000</a></span> | <span class="t">i think a very nice way to learn about the mamba architecture we're actually training several</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3877" target="_blank">01:04:37.040</a></span> | <span class="t">mamba at hugging face at the moment with nanotron and so it's also very easy to train i'll show you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3884" target="_blank">01:04:44.080</a></span> | <span class="t">a little bit there so talking about nanotron we wanted to have a very simple library to use all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3892" target="_blank">01:04:52.240</a></span> | <span class="t">the techniques that i showed you um so we talk about parallelism we talked about efficient training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3898" target="_blank">01:04:58.320</a></span> | <span class="t">we talk about being able to you know nicely iterate on your hyperparameter and also have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3904" target="_blank">01:05:04.720</a></span> | <span class="t">mixture of experts on mamba if you want to gather all of this you usually have a very large library</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3910" target="_blank">01:05:10.960</a></span> | <span class="t">with a lot of bell and whistle we want to keep something very minimalistic so that's how nanotron</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3915" target="_blank">01:05:15.920</a></span> | <span class="t">was born so we want to keep this really under 10 000 lines of code and we want to make it very fast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3923" target="_blank">01:05:23.600</a></span> | <span class="t">basically train as fast as possible and also very transparent so there's not a lot of wrapping around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3930" target="_blank">01:05:30.480</a></span> | <span class="t">the things that you do here and as the idea is uh it's very open it's very transparent and you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3936" target="_blank">01:05:36.720</a></span> | <span class="t">in it like 3d parallelism radiant accumulation didn't talk a little bit about values mixed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3943" target="_blank">01:05:43.200</a></span> | <span class="t">precision but it's in it and you have all the all the way to do also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3947" target="_blank">01:05:47.280</a></span> | <span class="t">smart optimizer zero one and all the architecture i was talking about at the end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3956" target="_blank">01:05:56.400</a></span> | <span class="t">so uh take a look at nanotron it's a kind of a research code that we use so it's still roughly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3962" target="_blank">01:06:02.240</a></span> | <span class="t">it's still a bit rough on the edges but it's a very very nice code base</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3967" target="_blank">01:06:07.520</a></span> | <span class="t">now that we trained our model took a long time i'm gonna cover briefly uh the the next step so uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3977" target="_blank">01:06:17.200</a></span> | <span class="t">talking a little bit about that because we also have nice open source library on this so i want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3982" target="_blank">01:06:22.720</a></span> | <span class="t">to tell you a little bit about them once you've pre-trained your model you usually want to align</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3989" target="_blank">01:06:29.040</a></span> | <span class="t">it which means you want to have it not as a completion model which just you know generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=3995" target="_blank">01:06:35.200</a></span> | <span class="t">the most likely tokens after the prompts but you want to extract you want to have it behave in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4001" target="_blank">01:06:41.440</a></span> | <span class="t">specific way so usually you want to start to have your model behave as a dialogue model so that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4006" target="_blank">01:06:46.880</a></span> | <span class="t">learn to generate answers to prompt and not just continuation and you also sometimes want to you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4013" target="_blank">01:06:53.120</a></span> | <span class="t">know have specific behaviors or you want to do some safety and you know for like forbid or like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4021" target="_blank">01:07:01.200</a></span> | <span class="t">reduce the occurrence of specific behaviors of your model okay so this step is called alignment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4027" target="_blank">01:07:07.600</a></span> | <span class="t">or fine tuning and i would say up to now there was a very uh complex technique called rl rl hf</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4035" target="_blank">01:07:15.440</a></span> | <span class="t">reinforcement learning from human feedback the impressive thing about our hf i would say is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4041" target="_blank">01:07:21.680</a></span> | <span class="t">it works at all that's basically maybe the first widespread occurrence of reinforcement learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4048" target="_blank">01:07:28.640</a></span> | <span class="t">in ai world that's actually really useful for many many people but it's still really really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4054" target="_blank">01:07:34.240</a></span> | <span class="t">complex basically how it works and the main tricky thing here is as always reinforcement learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4062" target="_blank">01:07:42.480</a></span> | <span class="t">is the reward so usually in reinforcement learning you define your reward manually it's very complex</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4068" target="_blank">01:07:48.240</a></span> | <span class="t">you know it's very full of heuristics and that's kind of one reason you don't generalize to anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4073" target="_blank">01:07:53.200</a></span> | <span class="t">else on your uh test test environment and the nice thing about rl hf is the hf part which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4079" target="_blank">01:07:59.920</a></span> | <span class="t">you will define your reward from human feedback so we'll ask you will generate some completion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4087" target="_blank">01:08:07.040</a></span> | <span class="t">we ask human to rank them and you will use that to train a reward model now it's very nice but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4094" target="_blank">01:08:14.960</a></span> | <span class="t">it's kind of a complex thing as you can see here some typical uh labeling interface for human to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4101" target="_blank">01:08:21.920</a></span> | <span class="t">label the the rewards and in practical i would say the very impressive thing is that it's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4107" target="_blank">01:08:27.920</a></span> | <span class="t">working as well but in practice the implementation is very complicated you have like four models you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4114" target="_blank">01:08:34.240</a></span> | <span class="t">have your like your model that you're training so the dpo model you have a base model that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4118" target="_blank">01:08:38.640</a></span> | <span class="t">still use because you want to stay not too far from it you have a reward model that you trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4123" target="_blank">01:08:43.600</a></span> | <span class="t">on the on the human feedback you have the sft model so all of these models need to be at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4128" target="_blank">01:08:48.720</a></span> | <span class="t">same time in memory and so you can do some smart sharing of layers but that's basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4134" target="_blank">01:08:54.880</a></span> | <span class="t">very complex and that's why we actually started to build a library called trl to make this easier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4142" target="_blank">01:09:02.800</a></span> | <span class="t">and it's also very challenging in terms of fitting all of this in memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4146" target="_blank">01:09:06.800</a></span> | <span class="t">now something very interesting happened uh last year which was uh dpo direct preference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4155" target="_blank">01:09:15.440</a></span> | <span class="t">optimization and the idea here was that basically maybe your language model already know the reward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4161" target="_blank">01:09:21.280</a></span> | <span class="t">somehow and so uh maybe it can be used without being trained as a reward model and i'm saying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4168" target="_blank">01:09:28.080</a></span> | <span class="t">that with my hands but basically you can write that much more um much more precisely in an equation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4175" target="_blank">01:09:35.280</a></span> | <span class="t">which is the dpo equation here and which is actually the the dpo paper has a very nice math</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4181" target="_blank">01:09:41.760</a></span> | <span class="t">part it's not always the case for machine learning paper sometimes the math is just there to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4186" target="_blank">01:09:46.720</a></span> | <span class="t">pass reviewer too but in this case uh the math is really very nice and very interesting and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4193" target="_blank">01:09:53.760</a></span> | <span class="t">conclusion is that you can maybe just go with two models the dpo model and the sft model and that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4198" target="_blank">01:09:58.560</a></span> | <span class="t">make uh much easier training and what we saw with the rlhf team uh led by uh lewis lewis tenstall</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4206" target="_blank">01:10:06.320</a></span> | <span class="t">and ed beshing also with former hf people like nathan and nesny what they saw was that basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4213" target="_blank">01:10:13.440</a></span> | <span class="t">it makes training much more stable and it's actually just kind of work out of the box</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4217" target="_blank">01:10:17.840</a></span> | <span class="t">because your objective is much closer to a standard like language modeling objective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4222" target="_blank">01:10:22.720</a></span> | <span class="t">so dpo changed a lot i would say how we used to align this model and um there was this question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4230" target="_blank">01:10:30.880</a></span> | <span class="t">maybe earlier this year which was is this the end of it do have we again move reinforcement learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4239" target="_blank">01:10:39.040</a></span> | <span class="t">out of the most used ml technique well no no no there is a revival recently of rl through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4247" target="_blank">01:10:47.920</a></span> | <span class="t">the reinforcement algorithm that's maybe some of you know if you were working in the field</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4252" target="_blank">01:10:52.720</a></span> | <span class="t">some time ago at least i was playing a lot with it for language modeling a long time ago</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4257" target="_blank">01:10:57.520</a></span> | <span class="t">and the idea is that at least the the paper from from rika here and and from cohere show that uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4264" target="_blank">01:11:04.240</a></span> | <span class="t">reinforcement and kind of more on policy rl was maybe still very very competitive with dpo and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4270" target="_blank">01:11:10.720</a></span> | <span class="t">maybe even better so the jury is still open in 2024 is dpo the answer or will we see back a revival</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4280" target="_blank">01:11:20.320</a></span> | <span class="t">of rl we'll see now you find your new model you've pre-trained it you find you need the behavior are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4288" target="_blank">01:11:28.640</a></span> | <span class="t">great you're very happy you think it's it's nice model you evaluated it as we told you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4294" target="_blank">01:11:34.000</a></span> | <span class="t">you need to deploy it and that will be my my last slides uh it will be actually very uh short</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4301" target="_blank">01:11:41.120</a></span> | <span class="t">because i think there's a lot of resources here but maybe just something to keep in mind is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4305" target="_blank">01:11:45.520</a></span> | <span class="t">there was multiple breakthrough in inference optimization over the last few months i would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4311" target="_blank">01:11:51.680</a></span> | <span class="t">say it's really impressive i remember like two years ago when i was saying okay we might want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4316" target="_blank">01:11:56.800</a></span> | <span class="t">to deploy a news model of seven or ten billion parameters people like this is never going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4322" target="_blank">01:12:02.960</a></span> | <span class="t">work these are just too big well the reality is that today on my laptop i can run you know mistral</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4329" target="_blank">01:12:09.200</a></span> | <span class="t">7b and it's just really fast it's even faster than me talking and there is a couple of things that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4335" target="_blank">01:12:15.680</a></span> | <span class="t">made that possible that's the things that i'm listing in these slides the first one i would say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4340" target="_blank">01:12:20.400</a></span> | <span class="t">is quantization that's the first impressive thing we can just quantize this model we can move them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4345" target="_blank">01:12:25.680</a></span> | <span class="t">from the floating point values that they have fp16 for most of them bfloat16 to quantized integer and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4354" target="_blank">01:12:34.800</a></span> | <span class="t">that just work we lose minimal performances we have values set up you know we have various techniques</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4361" target="_blank">01:12:41.760</a></span> | <span class="t">gptq we have the techniques included in a in lama cpp the dgml and nm nf4 so i put a couple of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4370" target="_blank">01:12:50.640</a></span> | <span class="t">out there they all just work really well i think a good default honestly is the one from lama cpp</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4377" target="_blank">01:12:57.120</a></span> | <span class="t">out there it's very nice it worked well and this basically solved use pay point also in terms of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4383" target="_blank">01:13:03.120</a></span> | <span class="t">model sizes because models are much much smaller in one's quantized now we can do even better now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4389" target="_blank">01:13:09.120</a></span> | <span class="t">with like speculative decoding which is super interesting and it's developed a recent development</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4394" target="_blank">01:13:14.000</a></span> | <span class="t">called medusa and here the idea is that we have two models that are roughly similar but one is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4399" target="_blank">01:13:19.040</a></span> | <span class="t">much smaller than the other one and they're trained roughly on the same data set i mean they should be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4404" target="_blank">01:13:24.480</a></span> | <span class="t">as close as possible and the small one will actually predict full sentences and then we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4409" target="_blank">01:13:29.760</a></span> | <span class="t">just use the big one to validate you know how good are these sentences and to keep you know the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4415" target="_blank">01:13:35.040</a></span> | <span class="t">tokens until they start to diverge from the token that the large model would have outputted and this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4422" target="_blank">01:13:42.000</a></span> | <span class="t">means we can generate a token by bunch and just validate them by the big model by the big model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4428" target="_blank">01:13:48.160</a></span> | <span class="t">take a little bit more room in the memory but not so much because the small model is much smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4433" target="_blank">01:13:53.920</a></span> | <span class="t">and it speed up inference by a lot as well and this basically let us use very large model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4439" target="_blank">01:13:59.040</a></span> | <span class="t">on a laptop there is a nice blog post i really like called accelerating generative ai with pytorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4446" target="_blank">01:14:06.720</a></span> | <span class="t">gpt fast which show you all the other techniques you can use you can compile your model you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4452" target="_blank">01:14:12.800</a></span> | <span class="t">use cuda graph basically this is something we covered just earlier and this is just the idea</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4457" target="_blank">01:14:17.840</a></span> | <span class="t">of reducing as much as possible cpu gpu synchronization so you put as much as possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4464" target="_blank">01:14:24.080</a></span> | <span class="t">your gpu autonomously going through the layers and you do as few as possible synchronization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4470" target="_blank">01:14:30.400</a></span> | <span class="t">with with your cpu and give you even more like a speed up really really impressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4475" target="_blank">01:14:35.120</a></span> | <span class="t">these are the inference techniques a lot of there just put it a few reference there basically for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4481" target="_blank">01:14:41.680</a></span> | <span class="t">you to to explore the final step you've pre-trained your model you aligned it you're very happy about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4489" target="_blank">01:14:49.760</a></span> | <span class="t">the inference you quantized it well you distribute it final step share it with the world okay we need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4496" target="_blank">01:14:56.320</a></span> | <span class="t">more knowledge we need more model outputs opens we need more data set open we need a lot more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4501" target="_blank">01:15:01.840</a></span> | <span class="t">sharing the world uh thankfully at honey face we'll be building a place to share stuff so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4508" target="_blank">01:15:08.080</a></span> | <span class="t">use the spaces evaluate your model openly on the open leaderboard put this on the really great chat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4514" target="_blank">01:15:14.480</a></span> | <span class="t">but arena set up a chat for people to try it basically please share all the knowledge that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4521" target="_blank">01:15:21.600</a></span> | <span class="t">you've learned and all the artifact that you've created as much as you can that will be my only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4527" target="_blank">01:15:27.920</a></span> | <span class="t">reward i asking you from this video thanks i actually kept this question slide from my talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4536" target="_blank">01:15:36.720</a></span> | <span class="t">i cannot really answer question on youtube but please put comments or like open a post</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4542" target="_blank">01:15:42.080</a></span> | <span class="t">on a happy face or ping me everywhere and i'm very happy to answer any question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2-SPH9hIKT8&t=4547" target="_blank">01:15:47.840</a></span> | <span class="t">that you may have on this thanks a lot for watching bye</span></div></div></body></html>