<html><head><title>How does 4o ImageGen work? Visual Autoregressive Modeling paper - Best Paper @ NeurIPS</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>How does 4o ImageGen work? Visual Autoregressive Modeling paper - Best Paper @ NeurIPS</h2><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo"><img src="https://i.ytimg.com/vi/QhYjYHwdqOo/sddefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./QhYjYHwdqOo.html">Whisper Transcript</a> | <a href="./transcript_QhYjYHwdqOo.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">yeah we're good all right you guys see my screen yeah okay so um so for the var paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=10" target="_blank">00:00:10.460</a></span> | <span class="t">just kind of a quick overview um so previously people said hey alums they work great uh let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=20" target="_blank">00:00:20.780</a></span> | <span class="t">try just doing auto regressive on images and um you can do this at the pixel level you can do this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=28" target="_blank">00:00:28.940</a></span> | <span class="t">at the patch level and the most obvious first thing you might do is just raster order so i'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=33" target="_blank">00:00:33.980</a></span> | <span class="t">start the top left corner i'm going to go across the top and keep going um and uh you can imagine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=41" target="_blank">00:00:41.480</a></span> | <span class="t">that this is this is great because there's a a natural sequencing for language but for images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=47" target="_blank">00:00:47.440</a></span> | <span class="t">it feels a little wrong right um because you you uh if you're in the middle of the image then then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=55" target="_blank">00:00:55.560</a></span> | <span class="t">your context is every all the pixels above you but you have no context for the pixels below you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=60" target="_blank">00:01:00.320</a></span> | <span class="t">right um and so what the var paper is going to suggest is that if you go from low res to high res</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=68" target="_blank">00:01:08.600</a></span> | <span class="t">then this provides a natural uh a good inductive bias and so this is just my overview slide obviously</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=75" target="_blank">00:01:15.380</a></span> | <span class="t">we'll get into the details of how they do all this but but so that's the big change is rather than just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=81" target="_blank">00:01:21.040</a></span> | <span class="t">switching from raster order to spiral to space filling curve those all still fundamentally have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=85" target="_blank">00:01:25.980</a></span> | <span class="t">the problem that when you're halfway done half of the content half the pixels are in your context but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=91" target="_blank">00:01:31.100</a></span> | <span class="t">half pixels are not okay whereas if you go from low res to high res then what you say is all of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=97" target="_blank">00:01:37.180</a></span> | <span class="t">pixels but only at a low res are in my context and then so eventually we'll get global features like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=103" target="_blank">00:01:43.940</a></span> | <span class="t">it's a picture of a dog and so then you'll have the background is blue sky above green grass below</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=109" target="_blank">00:01:49.620</a></span> | <span class="t">no high frequency fine details you'll just have like you know that that high level stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=116" target="_blank">00:01:56.100</a></span> | <span class="t">um and so in order to implement this uh what they used is they use variational auto encoders uh and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=123" target="_blank">00:02:03.700</a></span> | <span class="t">actually they use vector quantizations so it's um bqvae um and they purposefully decided to use a gpt2 like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=134" target="_blank">00:02:14.500</a></span> | <span class="t">llm uh which actually i think is one of the strengths of the paper is that they didn't go for the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=140" target="_blank">00:02:20.340</a></span> | <span class="t">possible transformer architecture they said uh we want to show that what worked was the low to high scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=150" target="_blank">00:02:30.020</a></span> | <span class="t">technique not what worked was we had a really awesome transformer okay they did make a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=155" target="_blank">00:02:35.460</a></span> | <span class="t">changes to like the normalization and stuff but they they tried not to just say like let me get the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=160" target="_blank">00:02:40.340</a></span> | <span class="t">um and one of the consequences when you go from the way they did low scale to high scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=166" target="_blank">00:02:46.420</a></span> | <span class="t">is if i'm at a medium scale and i'm going to predict the medium high scale image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=172" target="_blank">00:02:52.020</a></span> | <span class="t">that medium high scale image is multiple tokens so even though we are now still going left to right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=180" target="_blank">00:03:00.580</a></span> | <span class="t">linearly we're not going one token at a time we're actually going to go multiple tokens at a time and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=186" target="_blank">00:03:06.100</a></span> | <span class="t">again this is just the overview so the details we'll see in a minute so i'll pause just to see if there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=194" target="_blank">00:03:14.100</a></span> | <span class="t">any any burning questions before we get into the details how they do this um all right yeah i'm i'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=202" target="_blank">00:03:22.580</a></span> | <span class="t">trying to explain vae for those who are newer to the concepts in the in the i i have a slide on it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=207" target="_blank">00:03:27.540</a></span> | <span class="t">although you you can explain there because it's just one slide it's not really explaining it helps with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=213" target="_blank">00:03:33.140</a></span> | <span class="t">images yeah yeah okay so again i i think i kind of covered this but but you can imagine so we have lms and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=220" target="_blank">00:03:40.660</a></span> | <span class="t">the diagram from the paper says yeah here we have this nice clear ordering the cat sat by blah blah</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=225" target="_blank">00:03:45.780</a></span> | <span class="t">blah and you could take an image you could break it into these nine and then if you go in raster order</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=230" target="_blank">00:03:50.900</a></span> | <span class="t">then you go one two three four or five right so again the problem is when you're uh when you've seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=237" target="_blank">00:03:57.620</a></span> | <span class="t">one two three four five and you're predicting six patch six then uh patch three is in your context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=244" target="_blank">00:04:04.580</a></span> | <span class="t">and so so you can say okay yeah yeah but you don't have patch eight in your context and that's a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=249" target="_blank">00:04:09.380</a></span> | <span class="t">bit unnatural right and you can change the ordering like i said but any one d sequence is still going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=254" target="_blank">00:04:14.820</a></span> | <span class="t">to fundamentally have this problem so what they say is that let's have lower res higher res images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=262" target="_blank">00:04:22.580</a></span> | <span class="t">and now there's sort of a logical ordering so you could see at what they call r3 here um maybe you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=270" target="_blank">00:04:30.020</a></span> | <span class="t">maybe you can't tell that it's a bird a parrot at this point if you knew it was a parrot and i asked you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=275" target="_blank">00:04:35.620</a></span> | <span class="t">is the parrot facing to the right or the left at r3 you could probably say yeah i think this is the beak</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=281" target="_blank">00:04:41.780</a></span> | <span class="t">and so i think it's facing to my right okay um and so so you could imagine that at r4 you're getting this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=289" target="_blank">00:04:49.700</a></span> | <span class="t">global context you know what color is the main body of the bird it's probably blue right there are things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=295" target="_blank">00:04:55.620</a></span> | <span class="t">that you can learn it's not working out the fine details and so then as you keep going more and more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=301" target="_blank">00:05:01.860</a></span> | <span class="t">local information is is available and so now if you're actually trying to predict specific pixels on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=308" target="_blank">00:05:08.900</a></span> | <span class="t">a portion of the beak you have uh from this you have a lot of more local context in addition to just the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=316" target="_blank">00:05:16.340</a></span> | <span class="t">general global context about this so this is a nice concept but it still begs the question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=324" target="_blank">00:05:24.420</a></span> | <span class="t">how do we actually implement this idea of going from low scale to high res scale by the way just stop at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=332" target="_blank">00:05:32.660</a></span> | <span class="t">any point and ask questions uh i i can try to monitor the chat but it's not always easy when i'm screen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=338" target="_blank">00:05:38.420</a></span> | <span class="t">sharing so i apologize that either somebody else give a shout if there's a question good question in the chat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=344" target="_blank">00:05:44.580</a></span> | <span class="t">that that i'm missing um i i have a question here um what what i'm really um i'm not sure um i i can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=355" target="_blank">00:05:55.940</a></span> | <span class="t">understand what is a token in an image in a in a sentence but i i what what would be a token in an image is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=364" target="_blank">00:06:04.340</a></span> | <span class="t">some some some some some pixels because uh it you can have like lots of different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=374" target="_blank">00:06:14.180</a></span> | <span class="t">it's uh it's uh would be a really huge it's the perfect question that's the perfect question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=380" target="_blank">00:06:20.820</a></span> | <span class="t">okay i have this idea that i want to go from low scale to high res what the heck is the token how do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=386" target="_blank">00:06:26.180</a></span> | <span class="t">i tokenize this what what are the pieces so that that that's that's the the the what we need to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=395" target="_blank">00:06:35.620</a></span> | <span class="t">into next that's the solution that we need to solve this is just a high level description but it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=400" target="_blank">00:06:40.980</a></span> | <span class="t">actually make it obvious at all how you how you pull this off so perfect question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=406" target="_blank">00:06:46.740</a></span> | <span class="t">okay so um a couple concepts that we're going to use in order to to explain the tokenization scheme</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=416" target="_blank">00:06:56.340</a></span> | <span class="t">okay uh so one is auto encoder right so here we have a a simple auto encoder and you take an image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=425" target="_blank">00:07:05.060</a></span> | <span class="t">you pass it through some cnn layers you have a bottleneck in the middle and this can be considered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=429" target="_blank">00:07:09.460</a></span> | <span class="t">your embedding uh this is a deterministic embedding so you can't use a simple auto encoder as a generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=437" target="_blank">00:07:17.780</a></span> | <span class="t">okay um so we have variational auto encoders which then uh take the input and you may have cnn layers and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=445" target="_blank">00:07:25.220</a></span> | <span class="t">whatnot up front but ultimately instead of getting a single embedding uh what you're doing is you're you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=450" target="_blank">00:07:30.980</a></span> | <span class="t">uh uh uh you're you're creating a probability distribution okay so generally speaking what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=459" target="_blank">00:07:39.780</a></span> | <span class="t">we're doing is we're transforming it to something simple and so here we have uh in this slide uh it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=465" target="_blank">00:07:45.700</a></span> | <span class="t">a multi-dimensional gaussian distribution with diagonal covariance okay and what we want is we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=475" target="_blank">00:07:55.220</a></span> | <span class="t">want the encoder to basically transform our data distribution into this simple gaussian distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=481" target="_blank">00:08:01.060</a></span> | <span class="t">which we know how to sample from and then when we do generation the real um real power of this variational</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=491" target="_blank">00:08:11.540</a></span> | <span class="t">auto encoder is that the decoder knows how to do the reverse transform uh basically to take something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=498" target="_blank">00:08:18.340</a></span> | <span class="t">sampled from this multi-dimensional gaussian and put it into the data distribution um so i don't know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=506" target="_blank">00:08:26.260</a></span> | <span class="t">this is all i have i i wasn't really covering vaes in this so if you want to add any color about vaes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=517" target="_blank">00:08:37.780</a></span> | <span class="t">it looks like anton's giving um people are talking about vq vaes but um my my understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=523" target="_blank">00:08:43.380</a></span> | <span class="t">stops at vae and uh the only thing i'd add is that this is basically what led to latent diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=529" target="_blank">00:08:49.460</a></span> | <span class="t">yeah yeah so so vaes were used for image generation standalone uh i don't know how many years ago right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=538" target="_blank">00:08:58.500</a></span> | <span class="t">like four years ago or whatever um and they weren't they weren't very good um at the time they were very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=543" target="_blank">00:09:03.940</a></span> | <span class="t">interesting but but ultimately you got some blurry images and you can do things to clean up the fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=548" target="_blank">00:09:08.900</a></span> | <span class="t">that the images are blurry so then yes next we're going to go to um vector quantization because vaes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=556" target="_blank">00:09:16.340</a></span> | <span class="t">actually if i go back uh uh this uh this latent vector that you sample is is continuous okay so if we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=565" target="_blank">00:09:25.700</a></span> | <span class="t">say the dimensionality here is 256 you have 256 floats they're continuous uh real valued all right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=572" target="_blank">00:09:32.580</a></span> | <span class="t">so for anything where we're going to do a gpt style thing we need a vocabulary we need a discrete</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=579" target="_blank">00:09:39.860</a></span> | <span class="t">distribution so we're going to use vector quantization and um the way i describe vector quantization is it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=588" target="_blank">00:09:48.420</a></span> | <span class="t">just um a multi-dimensional uh uh version of rounding or quantization and so super quickly if i said you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=599" target="_blank">00:09:59.220</a></span> | <span class="t">have floating point numbers between zero one and rounded to the nearest hundredth okay you'd create a hundred</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=604" target="_blank">00:10:04.740</a></span> | <span class="t">buckets and basically uh right we know how you just like at the hundredth place you just you look you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=611" target="_blank">00:10:11.460</a></span> | <span class="t">truncate the rest of it and you drop things into the buckets um so that would just be very simple rounding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=617" target="_blank">00:10:17.380</a></span> | <span class="t">into 100 equal sized buckets but if i said to you hey my data is actually not distributed uniformly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=624" target="_blank">00:10:24.420</a></span> | <span class="t">uh let's say it's it's you know somehow whatever like heights of people and it's kind of bell curve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=629" target="_blank">00:10:29.300</a></span> | <span class="t">shaped right but i want good use of my buckets i want my buckets to be have roughly equal numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=635" target="_blank">00:10:35.460</a></span> | <span class="t">of people in them then one thing you might do is you might have narrow buckets near the middle and wider</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=640" target="_blank">00:10:40.980</a></span> | <span class="t">buckets at the ends and if you do it right then what you'll wind up with is once you see your data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=647" target="_blank">00:10:47.060</a></span> | <span class="t">you'll get approximately one percent of the of the people falling in every bucket so that's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=653" target="_blank">00:10:53.460</a></span> | <span class="t">from just simple rounding to uh uneven sized buckets then the last thing you could do is you could say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=660" target="_blank">00:11:00.580</a></span> | <span class="t">rather than predetermining those i'm actually going to get some data and i'm just going to learn i'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=665" target="_blank">00:11:05.540</a></span> | <span class="t">to see based on that data uh uh how i should apportion my buckets in order to have them all be roughly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=671" target="_blank">00:11:11.460</a></span> | <span class="t">equal samples um so good so now we just basically have a learned hundred bucket thing for one-dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=677" target="_blank">00:11:17.940</a></span> | <span class="t">data how do you do that for multi-dimensional data well if you have a vector of length uh 256 you just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=684" target="_blank">00:11:24.020</a></span> | <span class="t">do the exact same thing that you were doing in the one-dimensional case except you use let's say l2 loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=689" target="_blank">00:11:29.140</a></span> | <span class="t">in order to uh figure out which bucket you're closest to and then you just shift the buckets around until</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=695" target="_blank">00:11:35.300</a></span> | <span class="t">you get roughly equal numbers in every bucket so for me i just say that uh vector quantization is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=702" target="_blank">00:11:42.980</a></span> | <span class="t">learned rounding on multi-dimensional vectors and and then for me i have the the mental intuition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=711" target="_blank">00:11:51.140</a></span> | <span class="t">or it's not something super fancy or anything like that yeah i see you raised hand yeah i have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=718" target="_blank">00:11:58.900</a></span> | <span class="t">question so so the basic question i think it's also being as in the chat window is why do we have to go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=724" target="_blank">00:12:04.820</a></span> | <span class="t">towards uh vector quantization because one of the reasons for actually doing a vae is is that you have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=733" target="_blank">00:12:13.140</a></span> | <span class="t">continuous distribution so that a subtle change in the input will lead to a subtle change in the output as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=740" target="_blank">00:12:20.660</a></span> | <span class="t">opposed to any kind of dramatic changes whereas once you move into the quantization world you lose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=746" target="_blank">00:12:26.580</a></span> | <span class="t">that subtlety the proportional change uh uh benefit that you actually get from vaes um i don't know if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=758" target="_blank">00:12:38.020</a></span> | <span class="t">i can answer the the question fully uh uh i'm not the the author of the paper but what i will say is that if if we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=768" target="_blank">00:12:48.740</a></span> | <span class="t">want to use a gpt style transformer we are going to have a fixed vocabulary um</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=775" target="_blank">00:12:55.620</a></span> | <span class="t">and and so we want to discretize this if you're familiar with like whisper or these other audio</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=781" target="_blank">00:13:01.780</a></span> | <span class="t">models what they do is they do uh residual vector quantization and so you vector quantize and there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=788" target="_blank">00:13:08.660</a></span> | <span class="t">is this rounding error that you're losing information so then what you can do is you can take the the the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=793" target="_blank">00:13:13.700</a></span> | <span class="t">error between the original and the um and your first quantization and then you can quantize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=800" target="_blank">00:13:20.180</a></span> | <span class="t">that error okay yeah and then you can take the leftover from that you do that four times and now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=806" target="_blank">00:13:26.020</a></span> | <span class="t">you've actually got a a much much more accurate approximation of your original than if you just did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=811" target="_blank">00:13:31.300</a></span> | <span class="t">one round of quantization and so we'll see that they don't explicitly use residual vector quantization in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=818" target="_blank">00:13:38.020</a></span> | <span class="t">var paper but the process they use ends up imitating that as they go through the scales</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=824" target="_blank">00:13:44.900</a></span> | <span class="t">from low to high res they are doing residuals and so it ends up uh kind of being like rvq</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=831" target="_blank">00:13:51.780</a></span> | <span class="t">got it thank you and and one other question while i'm still here would you be able to make this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=839" target="_blank">00:13:59.060</a></span> | <span class="t">presentation available to me or to us so yeah yeah i i have a pdf on github i can share the link great</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=848" target="_blank">00:14:08.100</a></span> | <span class="t">thanks um yeah so so again if you just think that this is just multi-dimensional rounding uh such that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=858" target="_blank">00:14:18.260</a></span> | <span class="t">we get equal numbers in every bucket so that we're making good use of our buckets uh then what do we call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=864" target="_blank">00:14:24.820</a></span> | <span class="t">the list of buckets so so right if you use equal size buckets then you just have a formula for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=870" target="_blank">00:14:30.660</a></span> | <span class="t">calculating the buckets but if you if you are now learning them you you have to just write them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=875" target="_blank">00:14:35.300</a></span> | <span class="t">down you have to store them somewhere and so by convention um the list of the buckets uh is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=882" target="_blank">00:14:42.420</a></span> | <span class="t">um is called a code book okay and uh rather than super fancy buckets i think what they do is they just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=890" target="_blank">00:14:50.740</a></span> | <span class="t">store the center of the bucket the centroid or whatever you want to call it uh and so then uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=896" target="_blank">00:14:56.260</a></span> | <span class="t">you're not actually like defining the upper and lower bound of the bucket where you're just saying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=901" target="_blank">00:15:01.140</a></span> | <span class="t">here's the middle of the bucket here's the middle of that bucket and then uh when you want to quantize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=905" target="_blank">00:15:05.860</a></span> | <span class="t">something what you do is you actually compare it to every bucket and you see which has the the lowest l2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=913" target="_blank">00:15:13.060</a></span> | <span class="t">distance and then that's the bucket that you that you uh quantize it to that's the one that you round it to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=919" target="_blank">00:15:19.540</a></span> | <span class="t">um so it is i don't know slightly expensive so if you have 4096 buckets it does it is like order 4096</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=928" target="_blank">00:15:28.580</a></span> | <span class="t">to quantize something you have to compare to every one of those and then you say yeah it was closest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=933" target="_blank">00:15:33.700</a></span> | <span class="t">to bucket 17 so i'm now going to throw it in bucket 17.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=943" target="_blank">00:15:43.220</a></span> | <span class="t">all right so now that we kind of have a little bit of information on on vaes and vqvaes um so now the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=950" target="_blank">00:15:50.980</a></span> | <span class="t">question is how do we tokenize how do we fit images into an llm okay um and so the solution in the var paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=960" target="_blank">00:16:00.100</a></span> | <span class="t">is we're going to break the image into patches and each patch is each patch is going to go through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=967" target="_blank">00:16:07.940</a></span> | <span class="t">uh our our vector quantizer our vector vqvae um but what we're going to do is if it's a low res image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=976" target="_blank">00:16:16.980</a></span> | <span class="t">we're going to give it fewer patches and if it's a high res image we're going to give it more patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=983" target="_blank">00:16:23.940</a></span> | <span class="t">um specifically in the var paper they worked on image net 256 by 256 color images uh for image net</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=993" target="_blank">00:16:33.060</a></span> | <span class="t">and they said the high res in their case is 16 by 16 256 patches and the lowest res is one patch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1002" target="_blank">00:16:42.660</a></span> | <span class="t">so low res is very very low res it would really just be like the average color</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1010" target="_blank">00:16:50.740</a></span> | <span class="t">of the entire image right just the mean so that's like extremely extremely low res and if you think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1019" target="_blank">00:16:59.220</a></span> | <span class="t">about it the the 16 by 16 is actually not not that high but it's a small image it's only 256 by 256</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1025" target="_blank">00:17:05.700</a></span> | <span class="t">okay so uh they actually sped it up a little bit they didn't use every single possible size in between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1034" target="_blank">00:17:14.020</a></span> | <span class="t">but so you have a one by one is your lowest res then a two by two and then a three by three and then a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1040" target="_blank">00:17:20.180</a></span> | <span class="t">four by four and then at some point they got to like you know eight and they jumped to 10 and then they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1044" target="_blank">00:17:24.420</a></span> | <span class="t">jumped to 12 and whatever but that's not that's not like the schedule they used is not particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1049" target="_blank">00:17:29.540</a></span> | <span class="t">important if you just did it naively you would you would say i have 16 steps from one to 16. they had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1055" target="_blank">00:17:35.860</a></span> | <span class="t">i believe 10 steps if you look at the code in that uh in that var paper all right so so basically that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1065" target="_blank">00:17:45.780</a></span> | <span class="t">means that the lowest res image is going to get one token as it's embedding and the the token id is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1075" target="_blank">00:17:55.460</a></span> | <span class="t">the bucket number uh from our vector quantizer right so i was saying if if you if you compare it to all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1082" target="_blank">00:18:02.740</a></span> | <span class="t">4096 and 17 is the closest one then literally what you do is you just say 17 is my is my token number um and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1093" target="_blank">00:18:13.300</a></span> | <span class="t">gpt2 right it goes through the embedding layer that turns it into a dense specter it goes through however</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1099" target="_blank">00:18:19.220</a></span> | <span class="t">many was it 12 i don't remember if they even use gpt2 small medium whatever goes through 12 transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1104" target="_blank">00:18:24.820</a></span> | <span class="t">layers and then out pops your next token prediction um you guys all know lms right so um so so basically uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1116" target="_blank">00:18:36.660</a></span> | <span class="t">the bottom point here is normally our llm is predicting the next token but if we're predicting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1123" target="_blank">00:18:43.060</a></span> | <span class="t">the next higher resolution now that's multiple patches so when i start with just one patch i'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1129" target="_blank">00:18:49.220</a></span> | <span class="t">to predict the next image which means i'm actually predicting four tokens at once and then when i have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1136" target="_blank">00:18:56.580</a></span> | <span class="t">that one i have the first and the second one i have five tokens in my context i'm now going to predict the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1142" target="_blank">00:19:02.340</a></span> | <span class="t">the next nine tokens all at once and then when i have 14 tokens in my context i'm going to predict the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1149" target="_blank">00:19:09.300</a></span> | <span class="t">16 tokens all at once okay um and basically what you can do is is you if you just change the shape of your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1158" target="_blank">00:19:18.260</a></span> | <span class="t">auto regressive mask instead of being purely diagonal you have it be kind of block uh diagonal then what you can do is you can say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1164" target="_blank">00:19:24.340</a></span> | <span class="t">then what you can do is you can say when i have five tokens in my context and i'm predicting nine more so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1171" target="_blank">00:19:31.140</a></span> | <span class="t">what is that six through 14 or something like that um i'm going to change my mask so that tokens seven</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1178" target="_blank">00:19:38.660</a></span> | <span class="t">through 14 can still only see the first five they cannot see token six okay so tokens tokens six through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1188" target="_blank">00:19:48.180</a></span> | <span class="t">14 all have equal amount of 14 all have equal amount of keys that they can attend to equal amount of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1193" target="_blank">00:19:53.540</a></span> | <span class="t">information though the the fact that they are ordered in a particular order gives them no extra information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1200" target="_blank">00:20:00.820</a></span> | <span class="t">because we are we are creating the mask um you know slightly block wise so that yes in fact the very last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1210" target="_blank">00:20:10.100</a></span> | <span class="t">token the 14th token still can only attend to tokens one through five it cannot see any of the earlier tokens from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1217" target="_blank">00:20:17.220</a></span> | <span class="t">its level</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1218" target="_blank">00:20:18.900</a></span> | <span class="t">okay um and then in practice what we do is uh um if you're familiar with like you know pre-fill versus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1228" target="_blank">00:20:28.340</a></span> | <span class="t">decoding right in the pre-fill stage we we we are uh uh uh inferencing multiple positions at once</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1235" target="_blank">00:20:35.540</a></span> | <span class="t">here there's no reason not to do that as well you could do them one at a time but it would just be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1241" target="_blank">00:20:41.220</a></span> | <span class="t">less efficient but that's just an implementation issue okay whether you inference the nine tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1246" target="_blank">00:20:46.260</a></span> | <span class="t">one at a time or you do them all at once because of the attention mask it's it's exactly the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1251" target="_blank">00:20:51.220</a></span> | <span class="t">all right um so now the thing we're going to do is we're going to modify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1262" target="_blank">00:21:02.660</a></span> | <span class="t">our vector quantizer a little bit uh and we're not going to just use a vanilla vqvae uh there's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1270" target="_blank">00:21:10.500</a></span> | <span class="t">special vqvae that was trained specifically for var um and uh ultimately they tried it both ways they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1280" target="_blank">00:21:20.980</a></span> | <span class="t">said i will just take this image and when i want low res they just did linear interpolation okay there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1288" target="_blank">00:21:28.660</a></span> | <span class="t">nothing fancy here uh whether you're using like the the cv2 function or the pytorch built-in function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1295" target="_blank">00:21:35.860</a></span> | <span class="t">it's literally just linear interpolation so i start with my image when i want a one by one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1301" target="_blank">00:21:41.780</a></span> | <span class="t">you just basically say resize or linear interpolate down to one by one and it gives you you know the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1308" target="_blank">00:21:48.980</a></span> | <span class="t">average and if you say uh you know two by two um it's just the the the simple thing so there's no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1315" target="_blank">00:21:55.860</a></span> | <span class="t">there's no fancy learning going on here um uh so they tried it where they said i'm just going to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1323" target="_blank">00:22:03.220</a></span> | <span class="t">one by one two by two three by three so on and so forth and every one of those i'm going to run through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1328" target="_blank">00:22:08.420</a></span> | <span class="t">run my patches through the vector quantizer it worked what they found worked a little bit better however</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1334" target="_blank">00:22:14.180</a></span> | <span class="t">is after you have the one by one you can project that back to your full size image 256 by 256 and of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1345" target="_blank">00:22:25.620</a></span> | <span class="t">course you're it's a little bit more complicated but but you can imagine that you're then just going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1350" target="_blank">00:22:30.820</a></span> | <span class="t">get a solid color for the whole thing because you only have one data point so you so when you when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1356" target="_blank">00:22:36.340</a></span> | <span class="t">um upscale that you're just going to get this flat uniform thing uh what they do is they say for the two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1364" target="_blank">00:22:44.340</a></span> | <span class="t">by two instead of also predicting the original image i'm going to subtract what the one by one predicted my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1372" target="_blank">00:22:52.420</a></span> | <span class="t">full image was going to be i'm going to subtract so so if you have this mean color that you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1376" target="_blank">00:22:56.900</a></span> | <span class="t">predicted i'm going to subtract that from the image and that's what i'm actually going to predict for my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1382" target="_blank">00:23:02.020</a></span> | <span class="t">that's what i'm going to use what i'm going to quantize for my two by two so this is where the part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1387" target="_blank">00:23:07.140</a></span> | <span class="t">i mentioned earlier about it's a little bit like um residual vector quantization right so then after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1394" target="_blank">00:23:14.020</a></span> | <span class="t">you have a two by two that's been vector quantized you then upscale that back to 256 subtract that from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1403" target="_blank">00:23:23.460</a></span> | <span class="t">what you have and so you're successively doing this so when they did it in 10 steps what it means is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1408" target="_blank">00:23:28.660</a></span> | <span class="t">that the the last step that's the 16 by 16 patches they're not predicting the original image they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1416" target="_blank">00:23:36.740</a></span> | <span class="t">predicting the leftover after all the previous nine uh quantizations have done their job okay and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1425" target="_blank">00:23:45.060</a></span> | <span class="t">you can imagine like now you're really getting into i'm just predicting fine uh details looking at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1433" target="_blank">00:23:53.220</a></span> | <span class="t">the chat numbers going up and i apologize if if i should be answering questions or if you guys are just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1438" target="_blank">00:23:58.500</a></span> | <span class="t">super chatty but i'm like 44 freaking messages uh exactly if it's important someone will interrupt but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1446" target="_blank">00:24:06.340</a></span> | <span class="t">that's all okay uh coding which is always fun for images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1451" target="_blank">00:24:11.940</a></span> | <span class="t">uh i don't actually remember what they did for positional encodings off the top of my head sorry</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1461" target="_blank">00:24:21.860</a></span> | <span class="t">i could go look at the paper real quick but yes there have to be positional codings because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1468" target="_blank">00:24:28.580</a></span> | <span class="t">attention is position invariant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1471" target="_blank">00:24:31.220</a></span> | <span class="t">and um i think you mentioned that uh in the last step they're predicting the deltas from the previous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1478" target="_blank">00:24:38.900</a></span> | <span class="t">step right i wonder do you have an intuition of why um a vq vae would work better here as opposed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1485" target="_blank">00:24:45.380</a></span> | <span class="t">to a residual vae because it seems that residual would work better with predicting residual but i i don't know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1492" target="_blank">00:24:52.260</a></span> | <span class="t">um i'm not familiar with the what you're saying residual vae um yeah um i mean the idea here is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1502" target="_blank">00:25:02.660</a></span> | <span class="t">you you have the the the the vae but in this case we're quantizing it okay and so um</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1513" target="_blank">00:25:13.940</a></span> | <span class="t">so you have you have two forms of error uh so to speak you have the fact that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1521" target="_blank">00:25:21.620</a></span> | <span class="t">have downscaled this a lot okay and then you upscale it back and so then you've lost a lot of information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1529" target="_blank">00:25:29.780</a></span> | <span class="t">there and then the other error you have is the fact that when you downscaled it you then quantized it so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1535" target="_blank">00:25:35.620</a></span> | <span class="t">quantized it so you moved it a little bit and then you upscaled that sucker that you moved back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1540" target="_blank">00:25:40.900</a></span> | <span class="t">yep so um so i don't know how to answer your question because i don't know that that other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1546" target="_blank">00:25:46.580</a></span> | <span class="t">residual v but i can tell you that what so what they're doing is the combination of those two errors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1551" target="_blank">00:25:51.460</a></span> | <span class="t">is what the next iteration is then trying to uh uh uh encode okay gotcha thank you and then so the two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1561" target="_blank">00:26:01.300</a></span> | <span class="t">by two is going to downscale quantize have those both kinds of errors created uh when you upscale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1567" target="_blank">00:26:07.460</a></span> | <span class="t">that back and then the three by three is going to just look at the leftover errors from both levels one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1573" target="_blank">00:26:13.940</a></span> | <span class="t">and two and then the four by four is going to look at the leftover errors after those three and so on and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1579" target="_blank">00:26:19.220</a></span> | <span class="t">so forth so um so this this vqvae one of the key things though is that the code book used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1589" target="_blank">00:26:29.460</a></span> | <span class="t">when you do level one versus the last level the 16 by 16 it's using the exact same code book</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1597" target="_blank">00:26:37.700</a></span> | <span class="t">so uh i've seen different people ask you you potentially could have a more accurate quantizer if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1606" target="_blank">00:26:46.740</a></span> | <span class="t">you use customized code books for the one by one level versus the 16 by 16 level but since we want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1613" target="_blank">00:26:53.540</a></span> | <span class="t">feed all of these into our same gpt model that's why we we're forced to use um same code book for for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1621" target="_blank">00:27:01.300</a></span> | <span class="t">all the different levels and and so basically then uh um uh the the vqvae when it's learning its code book</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1633" target="_blank">00:27:13.540</a></span> | <span class="t">has to decide on uh uh codes that work well both at the high res and and at the low res and it has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1643" target="_blank">00:27:23.060</a></span> | <span class="t">to come up with some sort of compromise because these these these codes are going to be shared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1647" target="_blank">00:27:27.780</a></span> | <span class="t">everywhere in my head my intuition is that even though the the code book has to be shared and it may</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1654" target="_blank">00:27:34.660</a></span> | <span class="t">not be optimized for low and high res still what's happening is you're going to get these broad global</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1660" target="_blank">00:27:40.980</a></span> | <span class="t">features at lower resolutions you're going to get the sort of low frequency information um encoded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1668" target="_blank">00:27:48.820</a></span> | <span class="t">and as you get to the last and that's where the high frequency features so the the details of the grass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1675" target="_blank">00:27:55.140</a></span> | <span class="t">you know the the texture of the fur that's going to not happen until until probably quite late in the in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1682" target="_blank">00:28:02.740</a></span> | <span class="t">the quantization process and so this this next slide i wasn't planning on spending a lot of time on it but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1689" target="_blank">00:28:09.620</a></span> | <span class="t">what you can see just from this algorithm is that you input an image and it's going to loop in this case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1696" target="_blank">00:28:16.580</a></span> | <span class="t">10 times it doesn't matter if it's 10 or 16 times going from the one by one up to the 16 by 16 and and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1703" target="_blank">00:28:23.060</a></span> | <span class="t">the key thing though is that they have this queue that they're sticking on but you get all of those those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1708" target="_blank">00:28:28.420</a></span> | <span class="t">embeddings at the different layers at once this is not like a separate kind of a thing you you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1714" target="_blank">00:28:34.020</a></span> | <span class="t">do the multi-resolution quantization in one fell swoop you get all the resolutions simultaneously out of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1723" target="_blank">00:28:43.300</a></span> | <span class="t">after you you run your for loop okay um so it's a it's a package deal okay you so this is a dedicated multi-scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1733" target="_blank">00:28:53.060</a></span> | <span class="t">vqvae that gives you all your resolutions at once and then reconstruction uh also has to be an iterative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1741" target="_blank">00:29:01.300</a></span> | <span class="t">process you cannot say let me do the reconstruction at the eight by eight level without the information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1748" target="_blank">00:29:08.260</a></span> | <span class="t">about the other ones because this is a residual process you have to have all the earlier ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1753" target="_blank">00:29:13.780</a></span> | <span class="t">and then you sum all the predictions from all the earlier ones with your predictions in order to get your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1760" target="_blank">00:29:20.100</a></span> | <span class="t">your final prediction it's just like in an llm you you couldn't say what is the output of just the eighth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1766" target="_blank">00:29:26.980</a></span> | <span class="t">layer right it's a residual stream so you have to have layers one through seven in order to know what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1772" target="_blank">00:29:32.500</a></span> | <span class="t">the output of that they are i didn't say that quite right what's the residual stream after the eighth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1778" target="_blank">00:29:38.740</a></span> | <span class="t">layer you can say what the output of just the eighth layer is but you can't say what's the residual stream</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1783" target="_blank">00:29:43.540</a></span> | <span class="t">after the eighth layer unless you also have the first seven layers so it's the same thing here you can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1788" target="_blank">00:29:48.260</a></span> | <span class="t">say what's the eighth resolution unless you also have the first one all right so just to clarify what the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1798" target="_blank">00:29:58.020</a></span> | <span class="t">training process looks like is the multi-scale vqvae is trained separately so you in this case it was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1805" target="_blank">00:30:05.060</a></span> | <span class="t">image net so you give it a bunch of image net and it tries to um uh encode these images in a way that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1813" target="_blank">00:30:13.780</a></span> | <span class="t">that when they're decoded the l2 loss is the look the lowest um and it's going to do this as best it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1819" target="_blank">00:30:19.300</a></span> | <span class="t">can and then it's going to be frozen so the actual lm part did not involve any of this training at this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1828" target="_blank">00:30:28.980</a></span> | <span class="t">point this this sucker is completely frozen then what we do is we say given a fixed vqvae i'm now going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1836" target="_blank">00:30:36.660</a></span> | <span class="t">to train my actual lm on this idea of i'm going to give it one patch it's going to predict four i'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1844" target="_blank">00:30:44.340</a></span> | <span class="t">going to give it one plus four patches it's going to predict nine then it's going to predict 16 then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1848" target="_blank">00:30:48.980</a></span> | <span class="t">it's going to predict 25 up until at the very end for the 16 by 16 it has all the context of all of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1855" target="_blank">00:30:55.620</a></span> | <span class="t">earlier resolutions and it's going to predict 256 tokens in one fell swoop um so in this case it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1869" target="_blank">00:31:09.460</a></span> | <span class="t">was trained on image net and so if you're wondering for the very beginning of the process what is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1875" target="_blank">00:31:15.380</a></span> | <span class="t">prompt uh there's one token that encodes the class so there's a thousand classes in image net and so i</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1881" target="_blank">00:31:21.780</a></span> | <span class="t">don't remember i think it was embedded but basically so you start with a class token and it predicts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1887" target="_blank">00:31:27.140</a></span> | <span class="t">the one by one and then you have the class plus one by one and it predicts two by two and then so on and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1892" target="_blank">00:31:32.820</a></span> | <span class="t">so forth um and this this predict that this repeats until you get the the final the 256 tokens and then for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1901" target="_blank">00:31:41.300</a></span> | <span class="t">your actual image you need to sum up um all of this and have the decoder turn that into uh pixel values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1910" target="_blank">00:31:50.500</a></span> | <span class="t">because this is this is still a very special vqvae and you still need the decoder part here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1917" target="_blank">00:31:57.940</a></span> | <span class="t">so all of this stuff that's happening with the multiple scales this is all happening in latent space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1923" target="_blank">00:32:03.940</a></span> | <span class="t">this is not predicting pixels this is predicting latence okay so when we when we have tokens that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1930" target="_blank">00:32:10.260</a></span> | <span class="t">embedding from our our our vqvae vocabulary these are all vocabularies in the latent space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1938" target="_blank">00:32:18.420</a></span> | <span class="t">um and that's that's uh pretty much it so then you can see uh some of the results here and um they had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1947" target="_blank">00:32:27.540</a></span> | <span class="t">really good image quality um if you guys are familiar with a um fid distance inception score and then they also said</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1956" target="_blank">00:32:36.260</a></span> | <span class="t">said because we were able to do inference in chunks uh we actually had many fewer steps than if you did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1967" target="_blank">00:32:47.380</a></span> | <span class="t">auto regression naively so if you did one patch at a time you would have 256 inference steps they had 10</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1975" target="_blank">00:32:55.460</a></span> | <span class="t">inference steps going from 1 to 16 by 16 in just 10 steps maybe those individual steps were a little bit more expensive each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1983" target="_blank">00:33:03.220</a></span> | <span class="t">which maybe not not i haven't really done the math um but you can imagine that 10 inference steps is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1989" target="_blank">00:33:09.220</a></span> | <span class="t">still going to be a lot cheaper than 256 inference steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=1992" target="_blank">00:33:12.740</a></span> | <span class="t">and i think oh they also uh talked a little about scaling so um if you look at some of these other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2001" target="_blank">00:33:21.620</a></span> | <span class="t">models uh the performance improves as they get bigger and then they sort of hit a wall</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2006" target="_blank">00:33:26.500</a></span> | <span class="t">um and in this case they said uh yeah ours didn't hit a wall they didn't really run this over a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2012" target="_blank">00:33:32.580</a></span> | <span class="t">large uh uh number of orders of magnitude so it's still tbd whether or not as you really get bigger i</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2020" target="_blank">00:33:40.660</a></span> | <span class="t">don't blame them for not having the resources they're not a google okay um but nevertheless the fact that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2028" target="_blank">00:33:48.020</a></span> | <span class="t">it didn't hit the wall is good but it's not really proved yet until you really get to probably like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2035" target="_blank">00:33:55.700</a></span> | <span class="t">more like seven billion parameter scale or something like that uh but just if you just if you compare</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2041" target="_blank">00:34:01.620</a></span> | <span class="t">for example dit if you looked at these first three data points you'd like yeah this thing scales great</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2046" target="_blank">00:34:06.900</a></span> | <span class="t">and then you get the first fourth data point and it just fundamentally uh architecturally hits a wall</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2052" target="_blank">00:34:12.580</a></span> | <span class="t">okay so they're saying var hasn't hit a wall but we still don't know that it's not going to hit a wall</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2057" target="_blank">00:34:17.140</a></span> | <span class="t">on the next data point you know you really have to right so so the ultimate proof is in the pudding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2062" target="_blank">00:34:22.020</a></span> | <span class="t">until you build try to build a gpt4 size thing or whatever you know you just don't um whether or not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2069" target="_blank">00:34:29.300</a></span> | <span class="t">you're going to get a wall for images maybe it's not gp4 size but it's the same concept that um it's good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2075" target="_blank">00:34:35.380</a></span> | <span class="t">to be asking that question but i just don't think that they quite did it over a large enough spread</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2082" target="_blank">00:34:42.420</a></span> | <span class="t">um some sample images and here uh if you look you can see um uh this is uh left is earlier in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2092" target="_blank">00:34:52.900</a></span> | <span class="t">training right is later in training and this is scaling up the size of the lm that they used um inside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2100" target="_blank">00:35:00.340</a></span> | <span class="t">var and so obviously the bigger lm does better and then i i don't know that early in training is really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2106" target="_blank">00:35:06.740</a></span> | <span class="t">that important but you know it does learn better and so uh late in training it does it does better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2112" target="_blank">00:35:12.260</a></span> | <span class="t">better quality images that's not surprising so to conclude uh the the key things that they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2119" target="_blank">00:35:19.380</a></span> | <span class="t">selling us on why they think this paper is good why they think this technology is good is that um it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2124" target="_blank">00:35:24.660</a></span> | <span class="t">fast uh it's much faster than auto regression in in uh more naive ways it generates very high quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2132" target="_blank">00:35:32.820</a></span> | <span class="t">images um and they say that it has the right inductive bias that going from low scale to high scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2138" target="_blank">00:35:38.740</a></span> | <span class="t">um there is a very clear 1d ordering nobody would argue that somehow medium res should come before low</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2145" target="_blank">00:35:45.860</a></span> | <span class="t">res everyone's going to agree on the inductive bias whether or not that inductive bias proves to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2151" target="_blank">00:35:51.700</a></span> | <span class="t">encapsulate everything that we need you know i would not have necessarily guessed before gpt2 that next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2158" target="_blank">00:35:58.740</a></span> | <span class="t">token prediction was sufficient to be able to generate really complex you know mathematical proofs or something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2165" target="_blank">00:36:05.300</a></span> | <span class="t">like that right so i i don't have the ability to guess whether or not low res to high res is enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2171" target="_blank">00:36:11.220</a></span> | <span class="t">information for it to be able to um uh do whatever but because it has a very uh uh i don't know intuitive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2181" target="_blank">00:36:21.460</a></span> | <span class="t">inductive bias then it does mean that you can do in painting you can do out painting you can you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2187" target="_blank">00:36:27.460</a></span> | <span class="t">fill in any direction um with you know a fixed auto regressive patch order you can't if you if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2194" target="_blank">00:36:34.660</a></span> | <span class="t">if you do raster scan and you give it just the bottom of the image and you tell it give me fill in the top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2198" target="_blank">00:36:38.900</a></span> | <span class="t">of the image you can't do that it can only go from top to bottom so this one because of the way it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2203" target="_blank">00:36:43.620</a></span> | <span class="t">it can it can go in any direction in out mass whatever whatever um so byte dance did uh share the code here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2212" target="_blank">00:36:52.580</a></span> | <span class="t">and um uh they uh also they have uh uh two follow-up papers that are um that i've seen maybe there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2224" target="_blank">00:37:04.740</a></span> | <span class="t">more uh they they had an infinity paper um they did video they've also done um this was just image net now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2233" target="_blank">00:37:13.380</a></span> | <span class="t">they've done text to image like that that's a pretty obvious thing and there's a um xar instead of var paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2241" target="_blank">00:37:21.860</a></span> | <span class="t">now where um they generalized instead of just scale they say you can have arbitrary um uh uh precedence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2253" target="_blank">00:37:33.700</a></span> | <span class="t">um and then they also added some stuff that i haven't quite worked my way through where they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2259" target="_blank">00:37:39.060</a></span> | <span class="t">um matching as a what seems like a a little carrot on top of the auto regressive uh learning to to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2267" target="_blank">00:37:47.620</a></span> | <span class="t">the image quality even better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2269" target="_blank">00:37:49.220</a></span> | <span class="t">one other thing i have if you're reading the cheat sheet there's a lot of terminology and so i did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2276" target="_blank">00:37:56.660</a></span> | <span class="t">sorry if you're reading the paper there's a lot of terminology and so i did actually make a cheat sheet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2283" target="_blank">00:38:03.540</a></span> | <span class="t">um uh i'll share the link to the pdf but so basically um they have images and then they talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2290" target="_blank">00:38:10.500</a></span> | <span class="t">about their f um and you're doing this on individual patches at individual scales um and so then you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2298" target="_blank">00:38:18.500</a></span> | <span class="t">your tokens here um that are these cues which combine all the cues together make an image r or rather a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2306" target="_blank">00:38:26.260</a></span> | <span class="t">latent r at a given um resolution and then when you're decoding then you go back and you get your f hats and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2312" target="_blank">00:38:32.580</a></span> | <span class="t">eventually you get your chat so that's useful all right so i don't know if you guys want to ask me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2323" target="_blank">00:38:43.540</a></span> | <span class="t">questions or if there's other discussion you guys want to have um i mean first off thank you i mean it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2332" target="_blank">00:38:52.260</a></span> | <span class="t">great uh that you volunteered in the last minute and i've charted this uh this entire session uh and also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2341" target="_blank">00:39:01.060</a></span> | <span class="t">also thanks for the pdf file it looks uh the all the slides look amazing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2344" target="_blank">00:39:04.660</a></span> | <span class="t">i i'm just thinking in terms of does it even make sense to think or rationalize var</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2352" target="_blank">00:39:12.740</a></span> | <span class="t">against how diffusion models work is that going to help me because some of these are rat hole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2359" target="_blank">00:39:19.300</a></span> | <span class="t">things that i don't want to get into but do you think in your based on your experience does it help to understand or rationalize var</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2368" target="_blank">00:39:28.020</a></span> | <span class="t">var by comparing it against diffusion models because even in the diffusion models you have a sense of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2373" target="_blank">00:39:33.700</a></span> | <span class="t">uh resolution increments that you see as as uh in practice although behind the scenes uh the the thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2384" target="_blank">00:39:44.740</a></span> | <span class="t">the thing that is driving is actually the uh differential equations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2387" target="_blank">00:39:47.780</a></span> | <span class="t">um i think there's there's one thing that i think personally is a very important trend from var</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2402" target="_blank">00:40:02.820</a></span> | <span class="t">and that's the idea of predicting multiple tokens at once um</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2407" target="_blank">00:40:07.380</a></span> | <span class="t">the when when we do next token prediction we're sort of fixing the information content first step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2421" target="_blank">00:40:21.300</a></span> | <span class="t">okay and you know for me if if you have words like the and whatever um there's not a lot of information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2429" target="_blank">00:40:29.620</a></span> | <span class="t">content there but if you're processing code or you're processing like what is you know 12 times 15 or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2437" target="_blank">00:40:37.460</a></span> | <span class="t">whatever and you're outputting digits or something like that there's like really high information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2443" target="_blank">00:40:43.220</a></span> | <span class="t">density and and you cannot get it slightly wrong or you're just dead um and so whether it's scaling up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2451" target="_blank">00:40:51.940</a></span> | <span class="t">or scaling down or whatever but this idea that we can have variable information content so i think the the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2457" target="_blank">00:40:57.620</a></span> | <span class="t">the the byte latent paper from meta and and then and to a certain extent the large concept model uh for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2464" target="_blank">00:41:04.900</a></span> | <span class="t">me one of the things that they all all these papers have in common is that they're addressing the idea</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2470" target="_blank">00:41:10.660</a></span> | <span class="t">that the information content may not be uniform token by token by token um and so i think that the idea that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2478" target="_blank">00:41:18.500</a></span> | <span class="t">maybe if we're doing reasoning or doing other things that we can we can embed things with multiple tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2487" target="_blank">00:41:27.060</a></span> | <span class="t">that allows us to to get more information content into one inference step uh and so i think there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2494" target="_blank">00:41:34.740</a></span> | <span class="t">a huge opportunity to either make transformers faster language models faster or have reasoning better if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2501" target="_blank">00:41:41.940</a></span> | <span class="t">they have certain capabilities to dial up and down so i think the idea of predicting multiple tokens at once</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2507" target="_blank">00:41:47.860</a></span> | <span class="t">i think there will be a lot of successful research playing with that uh the xar paper already says that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2516" target="_blank">00:41:56.820</a></span> | <span class="t">maybe scale is not the one and only way to do it um uh but they they are looking at this idea and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2526" target="_blank">00:42:06.900</a></span> | <span class="t">diffusion has like really strong mathematical foundations um but we know that transformers are just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2537" target="_blank">00:42:17.140</a></span> | <span class="t">really full so uh so there's no reason why like the transformer can't learn the score function that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2546" target="_blank">00:42:26.500</a></span> | <span class="t">diffusion models are learning the real question which i i don't know is just kind of who can do it in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2554" target="_blank">00:42:34.660</a></span> | <span class="t">fewest steps uh but it seems like if if if a diffusion model uh using a unit or replacing the unit with a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2563" target="_blank">00:42:43.700</a></span> | <span class="t">transformer can learn the score function then if you gave it something similar a progression of images then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2570" target="_blank">00:42:50.020</a></span> | <span class="t">you should be able to learn um that same score function using attention um so yeah so i think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2576" target="_blank">00:42:56.500</a></span> | <span class="t">that this is something to pay attention to but not necessarily that it has to be literally just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2581" target="_blank">00:43:01.540</a></span> | <span class="t">the scale technique that these guys use um but um but yeah i i would pay attention to this idea of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2589" target="_blank">00:43:09.220</a></span> | <span class="t">of um that multiple people are approaching of of changing around our tokenization whether it's bite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2598" target="_blank">00:43:18.500</a></span> | <span class="t">latent lcm this or something like that so there's a answer sorry uh just to answer the question um more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2607" target="_blank">00:43:27.460</a></span> | <span class="t">directly though at least my understanding uh whether there's something to take away from this uh for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2612" target="_blank">00:43:32.660</a></span> | <span class="t">whether understanding diffusion helps um i think to me this is an example of uh an earlier paper both both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2623" target="_blank">00:43:43.380</a></span> | <span class="t">diffusion and this approach of scale prediction is an example of um an earlier paper i think it's by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2630" target="_blank">00:43:50.180</a></span> | <span class="t">such cover where the idea is you actually don't need to solve an ode or something if you can train a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2637" target="_blank">00:43:57.140</a></span> | <span class="t">model to denoise for an arbitrary um uh corruption um either adding gaussian noise or maybe in this case you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2646" target="_blank">00:44:06.900</a></span> | <span class="t">can interpret the next scale like down sampling prediction as uh uh a corruption where you you actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2653" target="_blank">00:44:13.780</a></span> | <span class="t">think of it backwards you have a high resolution image and you've corrupted it by sampling it down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2658" target="_blank">00:44:18.260</a></span> | <span class="t">and you're trying to predict backwards um like all of these are viable ways to think about the the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2665" target="_blank">00:44:25.300</a></span> | <span class="t">generation process so in this case it's a combination of using an llm for attention uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2671" target="_blank">00:44:31.460</a></span> | <span class="t">for being able to predict the next scale rather than raster scan plus the fact that you can you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2677" target="_blank">00:44:37.380</a></span> | <span class="t">need some sort of tokenization to actually use the llm in the first place other than that it's kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2682" target="_blank">00:44:42.660</a></span> | <span class="t">similar and it seems to work really well yeah thanks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2686" target="_blank">00:44:46.980</a></span> | <span class="t">regarding that point of multi-token prediction meta put out a paper last year</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2697" target="_blank">00:44:57.140</a></span> | <span class="t">about training llms with multiple tokens they did it during training and not inference and then they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2703" target="_blank">00:45:03.460</a></span> | <span class="t">mentioned in llama 3 that they use this technique in ted basically all your points there for sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2708" target="_blank">00:45:08.580</a></span> | <span class="t">efficiency or like spot on they they go into that um in terms of at inference time this is what um this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2716" target="_blank">00:45:16.500</a></span> | <span class="t">is kind of what motivated a lot of the work behind speculative decoding so speculative decoding is kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2721" target="_blank">00:45:21.540</a></span> | <span class="t">of multi-token prediction with a small model and that idea came out of research that you know they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2727" target="_blank">00:45:27.620</a></span> | <span class="t">started off with let's just predict multiple tokens and see how that goes and that led down to the path of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2732" target="_blank">00:45:32.820</a></span> | <span class="t">some speculative decoding nice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2737" target="_blank">00:45:37.540</a></span> | <span class="t">i have a question on the on the training time of this one so this is this approach seems clearly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2746" target="_blank">00:45:46.180</a></span> | <span class="t">very fast at inference time because it can predict so many tokens in parallel um but did they put any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2753" target="_blank">00:45:53.060</a></span> | <span class="t">mention in and how long it takes to train something also in comparison for example to diffusion models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2760" target="_blank">00:46:00.580</a></span> | <span class="t">i that's a great question i don't remember them discussing that in the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2764" target="_blank">00:46:04.820</a></span> | <span class="t">or maybe i just didn't pay close attention these are actually a lot bigger models than diffusion models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2772" target="_blank">00:46:12.660</a></span> | <span class="t">and their inference is a lot slower it's like you trial try 4-0 in mid-generation it takes on the order</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2778" target="_blank">00:46:18.820</a></span> | <span class="t">of you know 15-20 seconds and it's significantly larger um the big thing with autoregressive generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2784" target="_blank">00:46:24.420</a></span> | <span class="t">is you kind of scale up a lot more than you do with diffusion right we have really small local</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2789" target="_blank">00:46:29.460</a></span> | <span class="t">diffusion models like uh your iphone locally can do genmoji diffusion but autoregressive models just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2796" target="_blank">00:46:36.020</a></span> | <span class="t">at you know base layer they're larger than diffusion models now the inference tricks of like um you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2803" target="_blank">00:46:43.380</a></span> | <span class="t">lcm laura where you can skip a bunch of steps for diffusion those haven't been super applied to image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2808" target="_blank">00:46:48.740</a></span> | <span class="t">generation right so uh var is for autoregressive image generation don't have speculative decoding yet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2815" target="_blank">00:46:55.380</a></span> | <span class="t">or maybe they do but you know there's a lot of inference optimization that hasn't hit yet so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2819" target="_blank">00:46:59.620</a></span> | <span class="t">there's a room to grow but base level we expect diffusion models to stay small uh autoregressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2827" target="_blank">00:47:07.940</a></span> | <span class="t">models kind of get big as they generalize and yeah there's there's a lot of inference optimization that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2833" target="_blank">00:47:13.860</a></span> | <span class="t">hasn't hit yet yeah i think that the optimization is a key point um that that fibo shared right so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2840" target="_blank">00:47:20.980</a></span> | <span class="t">you compare this to like the very first diffusion models they were doing i don't remember either</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2844" target="_blank">00:47:24.500</a></span> | <span class="t">hundreds or thousands of steps um and we've dramatically uh improved that and so um if this is a useful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2853" target="_blank">00:47:33.060</a></span> | <span class="t">technique then you would expect that there's going to be a bunch of optimizations improvements upon it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2858" target="_blank">00:47:38.500</a></span> | <span class="t">this is just day one that's a minor point i guess uh you mentioned 4o image generation being slow i'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2866" target="_blank">00:47:46.980</a></span> | <span class="t">actually not sure whether uh it's so they're clearly doing var but i'm not sure they're doing the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2872" target="_blank">00:47:52.740</a></span> | <span class="t">var because you can imagine that if you want to do text to image or sort of this kind of multimodal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2879" target="_blank">00:47:59.620</a></span> | <span class="t">thing you want to actually um fine tune your text model to actually intake the same tokens and alert</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2887" target="_blank">00:48:07.780</a></span> | <span class="t">like teach it to do the task all with one model rather than uh doing it with separate models um so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2893" target="_blank">00:48:13.540</a></span> | <span class="t">it could be that that is the reason like if you just had a dedicated var model you could you can imagine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2898" target="_blank">00:48:18.740</a></span> | <span class="t">it being pretty good anyway a question about this actually and i think we had a short thread in discord</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2906" target="_blank">00:48:26.500</a></span> | <span class="t">about this it doesn't really seem practical to like completely jointly train one model like you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2915" target="_blank">00:48:35.140</a></span> | <span class="t">if you have the sort of 4o architecture or something like that it probably has to be just a post training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2920" target="_blank">00:48:40.660</a></span> | <span class="t">thing right and then yeah so you need some way to integrate that with like the separate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2926" target="_blank">00:48:46.580</a></span> | <span class="t">like var architecture that you've already trained and i think rj and in discord i'm not sure if he's here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2934" target="_blank">00:48:54.500</a></span> | <span class="t">had a plausible explanation that like you have some reserve token that you use to like delineate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2942" target="_blank">00:49:02.180</a></span> | <span class="t">image tokens from the text tokens and then the only thing you need to do in like post training is like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2947" target="_blank">00:49:07.780</a></span> | <span class="t">the chat model needs to learn to like say okay now this is um an image or something and then it gives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2954" target="_blank">00:49:14.980</a></span> | <span class="t">you text tokens and you take the text tokens and you have a text conditional var and that generates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2959" target="_blank">00:49:19.140</a></span> | <span class="t">image or something like that which kind of pencils out to me but i am i'm very curious practically how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2964" target="_blank">00:49:24.580</a></span> | <span class="t">they do something like that but i don't know i think you could do it with tool use like you're describing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2969" target="_blank">00:49:29.940</a></span> | <span class="t">but um people fine tune on tasks all the time when they for example you want to add like a tabular or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2976" target="_blank">00:49:36.900</a></span> | <span class="t">like a numeric modality or like an image modality to a language model you do your pre-training on a big like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2983" target="_blank">00:49:43.860</a></span> | <span class="t">like text corpus and then you have a much smaller like modality corpus that you sort of uh train your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2990" target="_blank">00:49:50.900</a></span> | <span class="t">encoder to to do uh the quantization so that you can actually have a image token but then you sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=2999" target="_blank">00:49:59.700</a></span> | <span class="t">fine-tune your model to understand image tokens and text tokens all in the same sequence but then then you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3006" target="_blank">00:50:06.740</a></span> | <span class="t">don't actually need to do uh co-train everything it is like a post-training thing um and you hope that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3014" target="_blank">00:50:14.180</a></span> | <span class="t">you don't lose the text capability when you gain the image capability um but i think apple has a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3021" target="_blank">00:50:21.940</a></span> | <span class="t">of uh papers on basically anything to anything prediction um like i think it's called like 4m or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3028" target="_blank">00:50:28.740</a></span> | <span class="t">something um uh i don't know how well it works but meta meta meta has a um the segment anything then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3037" target="_blank">00:50:37.620</a></span> | <span class="t">there's another one that's six modalities in one audio video depth meta also has chameleon which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3044" target="_blank">00:50:44.580</a></span> | <span class="t">native training so separate than like lava they have a native image language model i guess apple might too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3052" target="_blank">00:50:52.980</a></span> | <span class="t">but i if there's i'm thinking yeah i'm thinking of the forum uh series of papers which i think is apple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3059" target="_blank">00:50:59.620</a></span> | <span class="t">but again i don't know how well it works um anyway i don't know how anything works in practice at these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3065" target="_blank">00:51:05.860</a></span> | <span class="t">scales uh but yeah that's my guess regardless you need some sort of like tool use thing to like say okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3073" target="_blank">00:51:13.460</a></span> | <span class="t">now this is an image right and then you generate the image tokens and then you like end the image and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3079" target="_blank">00:51:19.300</a></span> | <span class="t">keep generating text or something like that or whatever is that right but you may need that just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3084" target="_blank">00:51:24.740</a></span> | <span class="t">for the ui essentially the the lm model may not care um and whether you use tool use to sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3092" target="_blank">00:51:32.100</a></span> | <span class="t">dispatch to a new model that's clearly how it used to work because you could basically trick one model into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3097" target="_blank">00:51:37.540</a></span> | <span class="t">the uh to uh generating some description that then you know would fail downstream but if it's all one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3103" target="_blank">00:51:43.620</a></span> | <span class="t">model uh it's all in the same space and that allows you to do uh image understanding whereas previously</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3109" target="_blank">00:51:49.780</a></span> | <span class="t">like these models didn't understand what was in the image that they generated themselves so that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3115" target="_blank">00:51:55.220</a></span> | <span class="t">maybe a test a way to check whether like if you ask to generate an image of like a tech bro with uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3120" target="_blank">00:52:00.580</a></span> | <span class="t">and say no glasses and it generates glasses you can ask it whether it contained glasses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3127" target="_blank">00:52:07.060</a></span> | <span class="t">yeah yes no no that's an issue and i'm sure it does know that yeah and also just just moving this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3134" target="_blank">00:52:14.340</a></span> | <span class="t">into a different track of conversation in the case of diffusion models lots of things have evolved like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3140" target="_blank">00:52:20.740</a></span> | <span class="t">there are control nets and lauras and image prompts and whatnot i wonder what would happen in this world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3147" target="_blank">00:52:27.540</a></span> | <span class="t">in this universe to get that kind of control because i work in the movie industry and and one of the things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3153" target="_blank">00:52:33.620</a></span> | <span class="t">that we uh actually care a lot about is consistency like character consistencies and so on and control</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3161" target="_blank">00:52:41.540</a></span> | <span class="t">nets are the current way of dealing with all of that so so do you know if there is any literature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3167" target="_blank">00:52:47.700</a></span> | <span class="t">around var's along those lines i don't think there's any literature yet but but but like uh open ai uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3177" target="_blank">00:52:57.940</a></span> | <span class="t">they let you refine the image and there's there's clear uh character consistency when you do multi-step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3185" target="_blank">00:53:05.780</a></span> | <span class="t">refinement of your image so it seems like they've definitely had that in mind yeah they actually call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3192" target="_blank">00:53:12.740</a></span> | <span class="t">that out in the in the blog post they have about the 4-0 image capability and they the i think what i recall</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3201" target="_blank">00:53:21.460</a></span> | <span class="t">is that they claim that uh that's because of this auto aggressive nature of it right so you have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3207" target="_blank">00:53:27.940</a></span> | <span class="t">history so that the attention can pay attention to the previous image so you kind of get it for free</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3212" target="_blank">00:53:32.900</a></span> | <span class="t">that was my interpretation of what they were saying yeah then this suggests that it is one model and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3219" target="_blank">00:53:39.460</a></span> | <span class="t">that's cool or i guess it could be one uh change model yeah no i i guess so my point in the discord was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3227" target="_blank">00:53:47.220</a></span> | <span class="t">actually um that i i just it's unclear to me whether there are uh reserve tokens that are that it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3234" target="_blank">00:53:54.100</a></span> | <span class="t">trained on in post training or if it's if they're just reusing the text tokens but with some sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3239" target="_blank">00:53:59.300</a></span> | <span class="t">special token to say okay now i'm generating an image and then now i'm not generating an image but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3244" target="_blank">00:54:04.580</a></span> | <span class="t">like i don't think it matters too much but you might like lose less of the text capability if you use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3250" target="_blank">00:54:10.100</a></span> | <span class="t">reserve tokens yeah if i had to bet that i i would bet on um them using reserve tokens um because you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3258" target="_blank">00:54:18.020</a></span> | <span class="t">don't need that many it's a pretty small vocabulary on your code book um and exactly your point uh you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3264" target="_blank">00:54:24.260</a></span> | <span class="t">don't want any any forgetting yeah i don't well normally you don't um reuse tokens well i i was not aware</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3274" target="_blank">00:54:34.100</a></span> | <span class="t">that people do uh reuse tokens ever uh you just uh you have your dictionary for for text tokens and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3281" target="_blank">00:54:41.780</a></span> | <span class="t">you have your implicit dictionary through your uh encoder that you use your vqvae that is now your image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3288" target="_blank">00:54:48.980</a></span> | <span class="t">dictionary and they're like they don't overlap um so yeah you just use those and your model learns to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3298" target="_blank">00:54:58.020</a></span> | <span class="t">sort of uh naturally use whatever it needs yeah i think there were some early multimodal llms where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3306" target="_blank">00:55:06.900</a></span> | <span class="t">you you you had like a beginning you know image token and then you reuse the same space uh but yeah i think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3315" target="_blank">00:55:15.780</a></span> | <span class="t">we're all saying the same thing that that's probably not the the conventional wisdom now it's just use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3322" target="_blank">00:55:22.980</a></span> | <span class="t">separate tokens and then and then and then you can have uh whatever hypothetically just an orthogonal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3329" target="_blank">00:55:29.940</a></span> | <span class="t">corner of your embedding space yeah but those tokens i so i totally agree those tokens are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3334" target="_blank">00:55:34.820</a></span> | <span class="t">delimination uh delimiting tokens for example uh when you train a lm model for fill in the middle tasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3342" target="_blank">00:55:42.180</a></span> | <span class="t">even though it can only generate one way right you use like a special you add new tokens that say like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3348" target="_blank">00:55:48.260</a></span> | <span class="t">now you're doing the fill in the middle task and here's the beginning and here's the end and now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3352" target="_blank">00:55:52.740</a></span> | <span class="t">start generating the the whole essentially uh you create new tokens for those delimiters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3358" target="_blank">00:55:58.020</a></span> | <span class="t">but the vocabulary that it it like learns to use the right vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3370" target="_blank">00:56:10.420</a></span> | <span class="t">well thank you so much ted for yeah again we were just gonna casual discuss slides are always appreciated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3376" target="_blank">00:56:16.980</a></span> | <span class="t">and uh good to see you here for next week anyone have a topic they want to discuss they want to volunteer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3384" target="_blank">00:56:24.500</a></span> | <span class="t">they want someone else to volunteer they want to do half a paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3387" target="_blank">00:56:27.220</a></span> | <span class="t">i want someone to volunteer the um the stuff that just came out of anthropic on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3394" target="_blank">00:56:34.900</a></span> | <span class="t">uh okay i might do that since i've done the other three so unless someone else wants to do it i'll do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3400" target="_blank">00:56:40.740</a></span> | <span class="t">the fourth one awesome okay okay i i might get someone from anthropic to join us we'll see uh otherwise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3408" target="_blank">00:56:48.100</a></span> | <span class="t">next week is anthropic if anyone hasn't seen my favorite mean uh matthew berman he said you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3414" target="_blank">00:56:54.900</a></span> | <span class="t">this is the most surprise he's ever been but he was just as surprised in the thumbnail as always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3420" target="_blank">00:57:00.660</a></span> | <span class="t">it's very sad very sad we have a running discord of all his thumbnails</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3423" target="_blank">00:57:03.860</a></span> | <span class="t">but okay i'll share i'm gonna make the thumbnail for this youtube ah okay good all right we're uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QhYjYHwdqOo&t=3435" target="_blank">00:57:15.700</a></span> | <span class="t">we got the thumbnail cool thanks guys see you next week and thank you ted thank you ted thank you</span></div></div></body></html>