<html><head><title>Navigating RAG Optimization with an Evaluation Driven Compass: Atita Arora and Deanna Emery</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Navigating RAG Optimization with an Evaluation Driven Compass: Atita Arora and Deanna Emery</h2><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4"><img src="https://i.ytimg.com/vi_webp/DId2KP8Ykz4/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./DId2KP8Ykz4.html">Whisper Transcript</a> | <a href="./transcript_DId2KP8Ykz4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hello, everyone. Welcome to our talk. My name is Atita, and I work as a solution architect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=18" target="_blank">00:00:18.320</a></span> | <span class="t">at Quadrant, and together with me, I have Deanna. I'm Deanna Emery, and I'm a founding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=24" target="_blank">00:00:24.540</a></span> | <span class="t">AI researcher at Quotient AI. Cool. So we would be talking about navigating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=29" target="_blank">00:00:29.160</a></span> | <span class="t">RAG optimization with an evaluation-driven compass. So I think the track is about RAG,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=35" target="_blank">00:00:35.020</a></span> | <span class="t">so let's talk and extend what we already know and what we've already seen so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=39" target="_blank">00:00:39.980</a></span> | <span class="t">So in this talk today, we will be discussing some of the key essential topics for anyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=44" target="_blank">00:00:44.420</a></span> | <span class="t">interested in building or productionizing the most popular implementation of GenerateAVI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=50" target="_blank">00:00:50.160</a></span> | <span class="t">that is RAG, Retrieval Augmented Generation. In simple terms, RAG combines the capabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=55" target="_blank">00:00:55.460</a></span> | <span class="t">of searching and retrieving through the vast amount of information stored in knowledge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=61" target="_blank">00:01:01.320</a></span> | <span class="t">source, usually a vector database. And then we use this information to generate relevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=67" target="_blank">00:01:07.700</a></span> | <span class="t">and coherent responses, leveraging the capabilities of a large language model. We will be talking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=73" target="_blank">00:01:13.680</a></span> | <span class="t">through the known challenges of this approach and how can you combat them by adopting an evaluation-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=80" target="_blank">00:01:20.280</a></span> | <span class="t">optimization techniques to get the desired results. So without further ado, let's get started.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=87" target="_blank">00:01:27.140</a></span> | <span class="t">So yeah, as simple as it's defined, RAG can be implemented in many different ways, as we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=92" target="_blank">00:01:32.960</a></span> | <span class="t">can see on the slide. Apologies for the busy slide, as I wanted to cover all the aspects of how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=99" target="_blank">00:01:39.140</a></span> | <span class="t">RAG can be implemented. And we will be starting with the simplest one, the naive RAG. This involves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=105" target="_blank">00:01:45.000</a></span> | <span class="t">three key steps. First, we split the documents using the specific chunking strategy. Next, we process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=111" target="_blank">00:01:51.860</a></span> | <span class="t">the document embedding and store them into a vector database. For each user query, we then retrieve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=117" target="_blank">00:01:57.860</a></span> | <span class="t">the most relevant document chunks based on our retrieval strategy. Finally, we add these retrieved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=123" target="_blank">00:02:03.640</a></span> | <span class="t">three chunks to our prompt to generate an answer using a chosen LLM. Advanced versions involve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=130" target="_blank">00:02:10.180</a></span> | <span class="t">enhancement to user queries, such as query expansion or rewriting, and post-retrieval treatments like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=137" target="_blank">00:02:17.180</a></span> | <span class="t">result re-ranking or fusion. The further advanced version of RAG includes query routing to task-based agents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=147" target="_blank">00:02:27.380</a></span> | <span class="t">and self-improvement modules like TSPI. However, there's one tool that is common in all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=153" target="_blank">00:02:33.240</a></span> | <span class="t">implementations if you notice, no matter if you want to build a naive or agentic RAG, and that is a vector database.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=160" target="_blank">00:02:40.240</a></span> | <span class="t">One of the most common use cases for building RAG is for knowledge management. There are aspects like retrieval performance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=167" target="_blank">00:02:47.080</a></span> | <span class="t">scalability to support large data volume, and resource optimization are paramount.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=172" target="_blank">00:02:52.240</a></span> | <span class="t">Speaking of vector database, Quadrant is open source vector search database built on Rust, and is purpose-built to support your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=182" target="_blank">00:03:02.500</a></span> | <span class="t">Generative AI applications built on large scale of data. If you haven't already checked out, please do check out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=190" target="_blank">00:03:10.740</a></span> | <span class="t">So coming back to our topic, it is worth to understand and acknowledge the challenges that come along with all the goodness of RAG.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=197" target="_blank">00:03:17.100</a></span> | <span class="t">I'm repurposing our naive RAG architecture to highlight common possible issues on each level. After all, the first step to solving any problem is to recognize there is one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=207" target="_blank">00:03:27.360</a></span> | <span class="t">To begin with, during the data processing stage, we could have issues with information missing from our data set, or information that fails to get extracted from our source of information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=218" target="_blank">00:03:38.360</a></span> | <span class="t">This would result in incorrect and incomplete responses. On data ingestion, there is a constant battle to determine the optimum chunking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=226" target="_blank">00:03:46.620</a></span> | <span class="t">strategy, along with determining a suitable embedding model that basically understands the specificity and jargons used in your data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=235" target="_blank">00:03:55.120</a></span> | <span class="t">Information retrieval itself is quite interesting and an ever-evolving field. Having spent 17 years in the space myself, I can probably say that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=244" target="_blank">00:04:04.620</a></span> | <span class="t">Relevancy is an unsolved problem. So the challenge with determining relevant documents, retrieval size, or retrieval window, if you may call it, and the order of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=254" target="_blank">00:04:14.880</a></span> | <span class="t">documents is unskippable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=256" target="_blank">00:04:16.880</a></span> | <span class="t">Response generation can face challenges such as incorrect and incomplete answers to all the previously mentioned issues, and the issues of straying from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=266" target="_blank">00:04:26.880</a></span> | <span class="t">the provided context. To add, our query is also vulnerable to ambiguous or vague questions. There are certainly other challenges,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=277" target="_blank">00:04:37.140</a></span> | <span class="t">like generating coherent responses, maintaining user conversations, scaling a RAG for hundreds or thousands of concurrent users,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=284" target="_blank">00:04:44.740</a></span> | <span class="t">along with data security and compliance issues. So looks like RAG isn't really a piece of cake after all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=291" target="_blank">00:04:51.140</a></span> | <span class="t">Fortunately, as for like the challenges, we have plenty of improvement techniques as well for the RAG. Let's look at them next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=298" target="_blank">00:04:58.400</a></span> | <span class="t">So we saw challenges zooming into data quality, data that missed to get generated. After all, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=303" target="_blank">00:05:03.400</a></span> | <span class="t">foundation of great responses is, it lies in the richness and accuracy of its information or context in case of RAG, which can be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=312" target="_blank">00:05:12.400</a></span> | <span class="t">controlled through adopting data cleaning and advanced data extraction methodologies. It is not a bad idea to use a general purpose embedding model to begin with,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=320" target="_blank">00:05:20.400</a></span> | <span class="t">But for added improvements, it would be a good idea to use an embedding model that comprehends the terminologies of your domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=327" target="_blank">00:05:27.660</a></span> | <span class="t">Metadata. It is a very versatile feature that can help you retrieve your added understanding of your documents and improving your retrieval,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=337" target="_blank">00:05:37.660</a></span> | <span class="t">plus leveraging the metadata filtering during the retrieval, it can also help you out with filtering out the irrelevant documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=343" target="_blank">00:05:43.660</a></span> | <span class="t">So it is also probably a good idea to invest your time into determining and improving your chunking strategy, which we spoke about earlier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=352" target="_blank">00:05:52.920</a></span> | <span class="t">Sometimes just by reducing the chunk size or adding semantic chunking can work wonders. We would be seeing that also when Deanna walks us through all the experimentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=360" target="_blank">00:06:00.920</a></span> | <span class="t">So, we have been aware of lost in the middle problem, and this is where it may be a good idea to determine an apt context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=368" target="_blank">00:06:08.180</a></span> | <span class="t">context size needed for your RAG to generate a helpful response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=371" target="_blank">00:06:11.440</a></span> | <span class="t">Also, using suitable indexing algorithms like HNSW, BM25, or even graphs, they can do wonders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=380" target="_blank">00:06:20.440</a></span> | <span class="t">Talking about suitable context size also prioritizes the document re-ranking as one of the key improvement parameters to ensure the most relevant documents that are provided in the context for LLM to generate a helpful response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=391" target="_blank">00:06:31.180</a></span> | <span class="t">With LLMs in the picture, we cannot overlook the difference. A good prompt or thinking about questions as a chain of thought can make to the progress of process of response generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=407" target="_blank">00:06:47.440</a></span> | <span class="t">Semantic understanding is clearly desired. We know that text search alone doesn't work, but if the dataset has the requirement for the exact matches, it may be worth exploring dense as well as sparse vectors, and you can do that on one or many fields.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=420" target="_blank">00:07:00.440</a></span> | <span class="t">Similar to the embedding model, it may be worth switching and experimenting with different LLMs as well, to ensure that the desired response is generated, and lastly, for better handling of task-driven user queries, such as fetching specific information or using custom data, it is beneficial to address these challenges using agents, which are well suited for the job.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=442" target="_blank">00:07:22.040</a></span> | <span class="t">So with so many different levers to tweak in RAC pipeline, it's hard to know what's going wrong, what to change, where to start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=450" target="_blank">00:07:30.840</a></span> | <span class="t">This is why evaluation is very important. Without an evaluation-based guided flow, it is difficult to accurately measure progress and ensure optimal performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=460" target="_blank">00:07:40.680</a></span> | <span class="t">The evaluation also helps you to iteratively refine applications, making informed decisions, and ultimately achieve goals more effectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=467" target="_blank">00:07:47.480</a></span> | <span class="t">So on that topic, I would like to welcome Tiana, who is going to basically walk us through how we did this experimentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=475" target="_blank">00:07:55.320</a></span> | <span class="t">Thanks, Satitha, for the perfect setup.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=480" target="_blank">00:08:00.520</a></span> | <span class="t">So this is where Quotient comes in. I might steal that from you. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=484" target="_blank">00:08:04.920</a></span> | <span class="t">So because the quality of RAG is so dependent on the underlying documents, a thorough evaluation of RAG system has to be customized to suit that specific domain and data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=499" target="_blank">00:08:19.320</a></span> | <span class="t">So Quotient's evaluation solution fills this need by enabling developers to measure the effectiveness of their LLM products accurately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=508" target="_blank">00:08:28.520</a></span> | <span class="t">Quotient's platform accelerates the experimentation process. With an evaluation data set that contains realistic examples of inputs and expected outputs for your AI solution, you can quickly experiment and iterate to optimize your RAG solutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=525" target="_blank">00:08:45.720</a></span> | <span class="t">And if you don't have an evaluation data set, don't worry, Quotient can help you get started by generating one for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=533" target="_blank">00:08:53.720</a></span> | <span class="t">And you can hear more from us on this at the AI Sizzle and Waves meetup on Friday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=538" target="_blank">00:08:58.200</a></span> | <span class="t">So how does this work in practice?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=542" target="_blank">00:09:02.280</a></span> | <span class="t">Once you have your quadrant vector database set up, you can populate your evaluation data set by submitting queries to return the context for the LLM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=551" target="_blank">00:09:11.320</a></span> | <span class="t">You can then submit your evaluation data set to Quotient, which handles the full orchestration, including the prompt formatting, execution of LLMs, and the metric computations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=563" target="_blank">00:09:23.560</a></span> | <span class="t">So to see it in action, we've put together a demo walkthrough where we'll show you a workflow for making evaluation informed changes to optimize your RAG system using Quotient and Quadrant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=575" target="_blank">00:09:35.240</a></span> | <span class="t">For the sake of time, we've executed the notebook ahead of time and we'll be walking you through the code outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=581" target="_blank">00:09:41.400</a></span> | <span class="t">And if you scan the QR code here, you can find the notebook on GitHub.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=586" target="_blank">00:09:46.600</a></span> | <span class="t">In this demo, we are building a RAG solution for question answering on Quadrants documentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=593" target="_blank">00:09:53.480</a></span> | <span class="t">And this will help enable Quadrant users to get help quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=597" target="_blank">00:09:57.240</a></span> | <span class="t">So before we begin evaluation, it's important to take a step back and consider what we're optimizing for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=604" target="_blank">00:10:04.200</a></span> | <span class="t">Given this use case, it's generally important to get helpful answers to the questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=609" target="_blank">00:10:09.720</a></span> | <span class="t">But it's perhaps more important that the answers do not contain any inaccurate information that could misguide users.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=616" target="_blank">00:10:16.440</a></span> | <span class="t">And so in other words, we want to minimize hallucinations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=621" target="_blank">00:10:21.400</a></span> | <span class="t">And with that in mind, we will be looking at the following metrics shown here with a focus on faithfulness.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=627" target="_blank">00:10:27.000</a></span> | <span class="t">The first two metrics are both focused on measuring the quality of the retrieval side of RAG.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=633" target="_blank">00:10:33.240</a></span> | <span class="t">Context relevance tells us whether the necessary information to answer the question is in the retrieved documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=639" target="_blank">00:10:39.080</a></span> | <span class="t">Chunk relevance tells us how much of the information retrieved is actually useful for answering the question versus just noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=646" target="_blank">00:10:46.360</a></span> | <span class="t">Faithfulness is our hallucination metric.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=649" target="_blank">00:10:49.560</a></span> | <span class="t">And then because the focus of this talk is going to be optimizing the retrieval side of RAG,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=655" target="_blank">00:10:55.960</a></span> | <span class="t">we're sticking to some of the more general text quality metrics here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=661" target="_blank">00:11:01.800</a></span> | <span class="t">So when we're first getting started, we want to consider a simple naive RAG implementation to help us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=667" target="_blank">00:11:07.960</a></span> | <span class="t">better optimize the data processing and vector database setup.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=672" target="_blank">00:11:12.040</a></span> | <span class="t">So we start off by choosing a reasonable embedding model and chunking parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=677" target="_blank">00:11:17.720</a></span> | <span class="t">retrieval window and the mistral instruct model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=680" target="_blank">00:11:20.680</a></span> | <span class="t">And then to see if we require additional context to answer the questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=686" target="_blank">00:11:26.040</a></span> | <span class="t">we set up a second experiment where we increase the chunk parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=691" target="_blank">00:11:31.160</a></span> | <span class="t">And so here are the results of those first two experiments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=694" target="_blank">00:11:34.040</a></span> | <span class="t">You can see that by increasing the chunk size in experiment two, we had some minor improvements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=699" target="_blank">00:11:39.720</a></span> | <span class="t">in our text quality metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=701" target="_blank">00:11:41.240</a></span> | <span class="t">That said, we had a considerable drop in our faithfulness, which is the metric we're optimizing for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=707" target="_blank">00:11:47.960</a></span> | <span class="t">Of note, you can see that the context relevance increased, meaning that we retrieved more of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=714" target="_blank">00:11:54.680</a></span> | <span class="t">and so what this implies is that if we simply retrieve more documents but use the smaller chunk size from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=732" target="_blank">00:12:12.680</a></span> | <span class="t">before, we might get better results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=734" target="_blank">00:12:14.280</a></span> | <span class="t">As expected, the smaller chunk size with the larger retrieval window achieved the highest relevance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=744" target="_blank">00:12:24.200</a></span> | <span class="t">scores and the best faithfulness score, meaning that we have a lower occurrence of hallucinations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=749" target="_blank">00:12:29.400</a></span> | <span class="t">In our next two iterations, we test out a new embedding model as well as a different LLM switching to GPT 3.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=758" target="_blank">00:12:38.200</a></span> | <span class="t">And while the embedding model experiment in the light grey didn't quite work out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=762" target="_blank">00:12:42.840</a></span> | <span class="t">for experiment five in the dark grey, we found that using the same RAG configuration,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=767" target="_blank">00:12:47.480</a></span> | <span class="t">but changing the LLM improved performance across all our metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=774" target="_blank">00:12:54.440</a></span> | <span class="t">So here we're looking at the aggregated metrics for our top performing RAG configuration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=778" target="_blank">00:12:58.760</a></span> | <span class="t">And the large variance in the context relevance, which is highlighted in red,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=783" target="_blank">00:13:03.000</a></span> | <span class="t">implies that some of the questions are having a harder time retrieving the right documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=787" target="_blank">00:13:07.000</a></span> | <span class="t">So to better understand what's going on, we have to look into the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=791" target="_blank">00:13:11.000</a></span> | <span class="t">And here we've shown the two worst performing data points in terms of hallucination.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=796" target="_blank">00:13:16.520</a></span> | <span class="t">This third column here shows us the retrieved documents, and it's a lot of text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=801" target="_blank">00:13:21.400</a></span> | <span class="t">so I'll just summarize. So it seems like we're returning a lot of unrelated documents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=807" target="_blank">00:13:27.160</a></span> | <span class="t">that are likely over indexing on specific words in the query, like quadrant, support, and search,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=814" target="_blank">00:13:34.520</a></span> | <span class="t">and we're returning documents that repeat these terms many times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=817" target="_blank">00:13:37.720</a></span> | <span class="t">So to address this issue, one possible solution could be expanding our retrieval window to capture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=824" target="_blank">00:13:44.520</a></span> | <span class="t">more documents and thereby making it more likely we get the right information. But in doing so,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=829" target="_blank">00:13:49.960</a></span> | <span class="t">we'd also be adding a lot of noise to our context. So by now we likely need to expand out of naive RAG</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=836" target="_blank">00:13:56.840</a></span> | <span class="t">and start to add in some more advanced techniques. And this is where re-ranking comes in. So we could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=843" target="_blank">00:14:03.080</a></span> | <span class="t">try using a different embedding model to re-rank the retrieved documents and then return only the top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=848" target="_blank">00:14:08.120</a></span> | <span class="t">few, thus weeding out some of the more unrelated ones. So we try this out. We perform three different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=854" target="_blank">00:14:14.120</a></span> | <span class="t">re-ranking experiments, trying re-rankers from mixed-bred, Cohere, and Gina's Colbert model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=859" target="_blank">00:14:19.240</a></span> | <span class="t">and we plot them here against our top naive RAG approach in blue. And you can see that in general,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=865" target="_blank">00:14:25.800</a></span> | <span class="t">our context relevance and with it our faithfulness have improved with this strategy, with Cohere achieving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=872" target="_blank">00:14:32.120</a></span> | <span class="t">the best relevance and faithfulness scores. If we return to those same two worst-performing data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=878" target="_blank">00:14:38.760</a></span> | <span class="t">points from experiment five now, and look at how our re-ranking implementation did, you can see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=884" target="_blank">00:14:44.680</a></span> | <span class="t">in the second example, we're now retrieving documents that contain the desired answer. And with it, our context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=891" target="_blank">00:14:51.240</a></span> | <span class="t">relevance and faithfulness are close to one. That said, in the first example, we're still getting poor results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=897" target="_blank">00:14:57.000</a></span> | <span class="t">And this suggests that even after expanding our retrieval windows, we're still unable to identify the relevant documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=903" target="_blank">00:15:03.240</a></span> | <span class="t">So if we think about the quadrant documentation and the text within it, it contains a lot of special terminology,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=910" target="_blank">00:15:10.520</a></span> | <span class="t">jargon, acronyms, and so it's unsurprising that these generally trained embedding models are going to be limited in performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=917" target="_blank">00:15:17.320</a></span> | <span class="t">So we could try fine-tuning or training our own model to address this issue, but this could be time-consuming and costly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=926" target="_blank">00:15:26.680</a></span> | <span class="t">So another option to try is hybrid search, which combines sparse and dense vectors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=932" target="_blank">00:15:32.200</a></span> | <span class="t">and these sparse vectors help us capture documents that share similar terminology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=936" target="_blank">00:15:36.200</a></span> | <span class="t">So we tried two implementations of this, one where we incorporate hybrid search with a re-ranker and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=942" target="_blank">00:15:42.680</a></span> | <span class="t">one without, and you can see that using the Cohere re-ranker with hybrid search gives us the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=948" target="_blank">00:15:48.760</a></span> | <span class="t">performance across all metrics except for chunk relevance. So looking at this hybrid search re-ranking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=955" target="_blank">00:15:55.560</a></span> | <span class="t">experiment now on these same two data points, you can see that the context relevance and faithfulness</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=960" target="_blank">00:16:00.520</a></span> | <span class="t">scores are both close to one now, a significant improvement over our prior ones. And we're also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=966" target="_blank">00:16:06.440</a></span> | <span class="t">better able to retrieve the information necessary to answer these questions. And so this suggests that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=973" target="_blank">00:16:13.000</a></span> | <span class="t">domain-specific terminology has a big effect on our overall performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=977" target="_blank">00:16:17.080</a></span> | <span class="t">So to summarize, the table here shows what gains in performance we were able to make over just 10</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=983" target="_blank">00:16:23.800</a></span> | <span class="t">experiments. Starting from a faithfulness score of 0.76, we worked our way up to a score of just under</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=989" target="_blank">00:16:29.800</a></span> | <span class="t">0.85. And notably, all of these gains were made without changing from a generic question-answering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=995" target="_blank">00:16:35.640</a></span> | <span class="t">prompt. So there's certainly many more experiments to run, and we have plenty of room for improvement,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1000" target="_blank">00:16:40.680</a></span> | <span class="t">but you can see how, starting from scratch, you can improve your RAG system by making incremental</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1006" target="_blank">00:16:46.360</a></span> | <span class="t">changes, evaluating using a combination of metrics that together can help you identify underlying issues,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1013" target="_blank">00:16:53.160</a></span> | <span class="t">then observing patterns in your data, forming a hypothesis, and repeating the process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1019" target="_blank">00:16:59.640</a></span> | <span class="t">So to summarize this talk and the experimentation, in this talk we covered several key aspects of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1029" target="_blank">00:17:09.000</a></span> | <span class="t">improving RAG. The baseline takeaway is that there is no substitute for evaluation-based or data-driven</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1035" target="_blank">00:17:15.960</a></span> | <span class="t">improvements. We emphasized leveraging domain understanding to achieve significant wins and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1041" target="_blank">00:17:21.960</a></span> | <span class="t">outlined various techniques for enhancement in our experiments. To ensure continuous improvement,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1048" target="_blank">00:17:28.120</a></span> | <span class="t">it is crucial to keep your evaluation data set up to date. Lastly, avoid over-engineering your RAG</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1054" target="_blank">00:17:34.200</a></span> | <span class="t">application without considering a combination of carefully chosen metrics. If this talk picked your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1060" target="_blank">00:17:40.120</a></span> | <span class="t">interest and you are interested to get in touch with us, before that, some key references and the QR code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1067" target="_blank">00:17:47.160</a></span> | <span class="t">please feel free to scan them, get in touch with us. We're going to be around and looking forward to all your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1072" target="_blank">00:17:52.360</a></span> | <span class="t">questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DId2KP8Ykz4&t=1080" target="_blank">00:18:00.360</a></span> | <span class="t">We'll see you next time.</span></div></div></body></html>