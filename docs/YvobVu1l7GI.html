<html><head><title>The Hidden Life of Embeddings: Linus Lee</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>The Hidden Life of Embeddings: Linus Lee</h2><a href="https://www.youtube.com/watch?v=YvobVu1l7GI"><img src="https://i.ytimg.com/vi/YvobVu1l7GI/sddefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./YvobVu1l7GI.html">Whisper Transcript</a> | <a href="./transcript_YvobVu1l7GI.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=14" target="_blank">00:00:14.000</a></span> | <span class="t">Hey everyone, I'm Linus, I'm here to talk about embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=17" target="_blank">00:00:17.000</a></span> | <span class="t">I'm grateful to be here at the inaugural AI engineer conference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=20" target="_blank">00:00:20.000</a></span> | <span class="t">Who learned something new today?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=22" target="_blank">00:00:22.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=24" target="_blank">00:00:24.000</a></span> | <span class="t">Before I talk about that, a little bit about myself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=26" target="_blank">00:00:26.000</a></span> | <span class="t">If you don't know me already, I am Linus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=28" target="_blank">00:00:28.000</a></span> | <span class="t">I work on AI at Notion for the last year or so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=32" target="_blank">00:00:32.000</a></span> | <span class="t">Before that, I did a lot of independent work prototyping,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=34" target="_blank">00:00:34.000</a></span> | <span class="t">experimenting with, trying out different things with language models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=37" target="_blank">00:00:37.000</a></span> | <span class="t">with traditional LLP, things like TF-IDF, BM25,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=40" target="_blank">00:00:40.000</a></span> | <span class="t">to build interesting interfaces for reading and writing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=42" target="_blank">00:00:42.000</a></span> | <span class="t">In particular, I worked a lot with embedding models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=44" target="_blank">00:00:44.000</a></span> | <span class="t">and latent spaces of models, which is what I'll be talking about today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=48" target="_blank">00:00:48.000</a></span> | <span class="t">But before I do that, I want to take a moment to say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=51" target="_blank">00:00:51.000</a></span> | <span class="t">it's been almost a year since Notion launched Notion AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=54" target="_blank">00:00:54.000</a></span> | <span class="t">Our public beta was first announced in around November 2022.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=58" target="_blank">00:00:58.000</a></span> | <span class="t">So as we get close to a year, we've been steadily launching new and interesting features inside Notion AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=64" target="_blank">00:01:04.000</a></span> | <span class="t">From November, we have AI autofill inside databases, translation, and things coming soon,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=70" target="_blank">00:01:10.000</a></span> | <span class="t">though not today, so keep an eye on the space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=72" target="_blank">00:01:12.000</a></span> | <span class="t">And obviously we're hiring, just like everybody else here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=74" target="_blank">00:01:14.000</a></span> | <span class="t">We're looking for AI engineers, product engineers, machine learning engineers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=78" target="_blank">00:01:18.000</a></span> | <span class="t">to tackle the full gamut of problems that people have been talking about today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=81" target="_blank">00:01:21.000</a></span> | <span class="t">Agents, tool use, evaluations, data, training, and all the interface stuff that we'll see today and tomorrow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=88" target="_blank">00:01:28.000</a></span> | <span class="t">So if you're interested, please grab me, and we'll have a little chat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=92" target="_blank">00:01:32.000</a></span> | <span class="t">Now, it wouldn't be Alan's talk without talking about latent spaces, so let's talk about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=96" target="_blank">00:01:36.000</a></span> | <span class="t">One of the problems that I find always motivated by is the problem of steering language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=101" target="_blank">00:01:41.000</a></span> | <span class="t">And I always say that prompting language models feels a lot like you're steering a car from the backseat with a pool noodle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=106" target="_blank">00:01:46.000</a></span> | <span class="t">Like, yes, technically you have some control over the motion of the vehicle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=110" target="_blank">00:01:50.000</a></span> | <span class="t">It's like there's some connection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=111" target="_blank">00:01:51.000</a></span> | <span class="t">But you're not really in the driver's seat, the control isn't really there, it's not really direct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=115" target="_blank">00:01:55.000</a></span> | <span class="t">There's like three layers of indirection between you and what the vehicle's doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=118" target="_blank">00:01:58.000</a></span> | <span class="t">And that, to me, trying to prompt a model, especially smaller, more efficient models that we can use for production,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=125" target="_blank">00:02:05.000</a></span> | <span class="t">with just tokens, just prompts, feels a lot like there's too many layers of indirection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=130" target="_blank">00:02:10.000</a></span> | <span class="t">And even though models are getting better at understanding prompts, I think there's always going to be this fundamental barrier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=134" target="_blank">00:02:14.000</a></span> | <span class="t">between indirect control of models with just prompts and getting the model to do what we want them to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=141" target="_blank">00:02:21.000</a></span> | <span class="t">And so perhaps we can get a closer layer of control, a more direct layer of control, by looking inside the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=146" target="_blank">00:02:26.000</a></span> | <span class="t">which is where we look at latent spaces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=148" target="_blank">00:02:28.000</a></span> | <span class="t">Latent spaces arise, I think, most famously inside embedding models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=155" target="_blank">00:02:35.000</a></span> | <span class="t">If you embed some piece of text, that vector of 1536 numbers or 1024 numbers is inside a high-dimensional vector space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=162" target="_blank">00:02:42.000</a></span> | <span class="t">That's a latent space, but also you can look at the latent spaces inside activation spaces of models, inside token embeddings, inside image models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=169" target="_blank">00:02:49.000</a></span> | <span class="t">and then obviously other model architectures like auto-encoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=171" target="_blank">00:02:51.000</a></span> | <span class="t">Today we're going to be looking at embedding models, but I think a lot of the general takeaways apply to other models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=176" target="_blank">00:02:56.000</a></span> | <span class="t">and I think there's a lot of fascinating research work happening inside other models as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=180" target="_blank">00:03:00.000</a></span> | <span class="t">When you look at an embedding, you kind of see this, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=184" target="_blank">00:03:04.000</a></span> | <span class="t">You see rows and rows of numbers if you ever debug some kind of an embedding pipeline and you'll print out the embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=189" target="_blank">00:03:09.000</a></span> | <span class="t">You can kind of tell it has like a thousand numbers, but it's just looking at a matrix screen of numbers raining down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=194" target="_blank">00:03:14.000</a></span> | <span class="t">But in theory, there's a lot of information actually packed inside those embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=198" target="_blank">00:03:18.000</a></span> | <span class="t">If you get an embedding of a piece of text or image, these latent spaces, these embeddings represent, in theory, the most salient features of a text or the image that the model is using to lower its loss or do its task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=209" target="_blank">00:03:29.000</a></span> | <span class="t">And so maybe if we can disentangle some meaningful attributes or features out of these embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=214" target="_blank">00:03:34.000</a></span> | <span class="t">if we can look at them a little more closely and interpret them a little better,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=217" target="_blank">00:03:37.000</a></span> | <span class="t">maybe we can build more expressive interfaces that let them control the model by interfering or intervening inside the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=223" target="_blank">00:03:43.000</a></span> | <span class="t">Another way to say that is that embeddings show us what the model sees in a sample of input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=229" target="_blank">00:03:49.000</a></span> | <span class="t">So maybe we can read out what it sees and try to understand better what the model's doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=233" target="_blank">00:03:53.000</a></span> | <span class="t">And maybe we can even control the embedding, intermediate activations to see what the model can generate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=240" target="_blank">00:04:00.000</a></span> | <span class="t">So let's see some of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=244" target="_blank">00:04:04.000</a></span> | <span class="t">So some of this some of you might have seen before, but I promise there's some new stuff at the end, so hang tight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=256" target="_blank">00:04:16.000</a></span> | <span class="t">So here's some sentence that I have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=258" target="_blank">00:04:18.000</a></span> | <span class="t">It's a sentence about this novel, one of my favorite novels, named Diaspora.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=262" target="_blank">00:04:22.000</a></span> | <span class="t">It's a science fiction novel by Greg Egan that explores evolution and existence, post-human artificial intelligences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=267" target="_blank">00:04:27.000</a></span> | <span class="t">something to do with alien civilizations and the questioning the nature of reality and consciousness,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=271" target="_blank">00:04:31.000</a></span> | <span class="t">which you might be doing a lot given all the things that are happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=275" target="_blank">00:04:35.000</a></span> | <span class="t">And so I have trained this model that can generate some embeddings out of this text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=281" target="_blank">00:04:41.000</a></span> | <span class="t">So if I hit the center, it's going to give us an embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=284" target="_blank">00:04:44.000</a></span> | <span class="t">But it's an embedding of length 2048, and so it's quite large.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=287" target="_blank">00:04:47.000</a></span> | <span class="t">But it's just a row of numbers, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=289" target="_blank">00:04:49.000</a></span> | <span class="t">But then I have a decoder half of this model that can take this embedding and try to reconstruct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=294" target="_blank">00:04:54.000</a></span> | <span class="t">the original input that may have produced this embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=297" target="_blank">00:04:57.000</a></span> | <span class="t">So in this case, it took the original sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=299" target="_blank">00:04:59.000</a></span> | <span class="t">There's some variation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=300" target="_blank">00:05:00.000</a></span> | <span class="t">You can tell it's not exactly the same length, maybe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=302" target="_blank">00:05:02.000</a></span> | <span class="t">But it's mostly reconstructed the original sentence, including the specific details like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=305" target="_blank">00:05:05.000</a></span> | <span class="t">the title of the book and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=308" target="_blank">00:05:08.000</a></span> | <span class="t">So we have an encoder that's going from text to embedding and a decoder that's going from embedding back to text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=314" target="_blank">00:05:14.000</a></span> | <span class="t">And now we can start to do things with the embedding to vary it a little bit and see what the decoder might see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=319" target="_blank">00:05:19.000</a></span> | <span class="t">if we make some modifications to the embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=322" target="_blank">00:05:22.000</a></span> | <span class="t">So here I've tried to kind of blur the embedding and sample some points around the embedding with this blur radius.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=329" target="_blank">00:05:29.000</a></span> | <span class="t">And you can see the text that's generated from those blurry embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=332" target="_blank">00:05:32.000</a></span> | <span class="t">They're a little off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=333" target="_blank">00:05:33.000</a></span> | <span class="t">Like, this is not the correct title.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=335" target="_blank">00:05:35.000</a></span> | <span class="t">The title's kind of gone here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=338" target="_blank">00:05:38.000</a></span> | <span class="t">It still kept the name Greg, but it's a different person.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=340" target="_blank">00:05:40.000</a></span> | <span class="t">And so there's kind of a semantic blur that's happened here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=345" target="_blank">00:05:45.000</a></span> | <span class="t">But this is kind of boring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=346" target="_blank">00:05:46.000</a></span> | <span class="t">This is not really useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=347" target="_blank">00:05:47.000</a></span> | <span class="t">What's a little more useful is trying to actually manipulate things in more meaningful directions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=351" target="_blank">00:05:51.000</a></span> | <span class="t">Now we have the same taste of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=353" target="_blank">00:05:53.000</a></span> | <span class="t">And now here I have a bunch of controls.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=355" target="_blank">00:05:55.000</a></span> | <span class="t">So maybe I want to find a direction in this embedding space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=359" target="_blank">00:05:59.000</a></span> | <span class="t">Here I've computed a direction where if you push an embedding in that direction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=362" target="_blank">00:06:02.000</a></span> | <span class="t">that's going to represent a shorter piece of text of roughly the same topic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=366" target="_blank">00:06:06.000</a></span> | <span class="t">And so I pick this direction and I hit go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=369" target="_blank">00:06:09.000</a></span> | <span class="t">And it'll try to push the embedding of this text in that direction and decode them out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=375" target="_blank">00:06:15.000</a></span> | <span class="t">And you can tell they're a little bit shorter if I push it a little bit further even.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=379" target="_blank">00:06:19.000</a></span> | <span class="t">So now I'm taking that shorter direction and moving a little farther along it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=383" target="_blank">00:06:23.000</a></span> | <span class="t">and sampling, generating text out of those embeddings again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=386" target="_blank">00:06:26.000</a></span> | <span class="t">And they're even a little bit shorter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=388" target="_blank">00:06:28.000</a></span> | <span class="t">But they've still kept the general kind of idea, general topic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=393" target="_blank">00:06:33.000</a></span> | <span class="t">And with that kind of building block, you can build really interesting interfaces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=396" target="_blank">00:06:36.000</a></span> | <span class="t">Like, for example, I can plop this piece of text down here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=399" target="_blank">00:06:39.000</a></span> | <span class="t">And maybe I want to generate a couple of sort of shorter versions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=403" target="_blank">00:06:43.000</a></span> | <span class="t">So this is like a little bit shorter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=406" target="_blank">00:06:46.000</a></span> | <span class="t">This is even more short.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=408" target="_blank">00:06:48.000</a></span> | <span class="t">But maybe I like this version.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=410" target="_blank">00:06:50.000</a></span> | <span class="t">So I'm going to clone this over here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=412" target="_blank">00:06:52.000</a></span> | <span class="t">And I'm going to make the sentiment of the sentence a little more negative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=417" target="_blank">00:06:57.000</a></span> | <span class="t">And you can start to explore the latent space of this embedding model, this language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=423" target="_blank">00:07:03.000</a></span> | <span class="t">by actually moving around in a kind of spatial canvas interface, which is kind of interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=427" target="_blank">00:07:07.000</a></span> | <span class="t">Another thing you can do with this kind of embedding model is now that we have a vague sense that there are specific directions in this space that mean specific things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=435" target="_blank">00:07:15.000</a></span> | <span class="t">we can start to more directly look at a text and ask the model, hey, where does this piece of text lie along your length direction or along your negative sentiment direction?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=446" target="_blank">00:07:26.000</a></span> | <span class="t">So this is the original text that we've been playing with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=449" target="_blank">00:07:29.000</a></span> | <span class="t">It's pretty objective, like a Wikipedia-style piece of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=451" target="_blank">00:07:31.000</a></span> | <span class="t">Here I've asked ChatGPT to take the original text and make it sound a lot more pessimistic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=456" target="_blank">00:07:36.000</a></span> | <span class="t">So things like the futile quest for meaning and plunging deeper into the abyss of nihilism.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=461" target="_blank">00:07:41.000</a></span> | <span class="t">And if I embed both of these, what I'm asking the model to do here is embed both of these things in the embedding space of the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=468" target="_blank">00:07:48.000</a></span> | <span class="t">and then project those embeddings down onto each of these directions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=473" target="_blank">00:07:53.000</a></span> | <span class="t">So one way to read this table is that this default piece of text is at this point in this negative direction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=479" target="_blank">00:07:59.000</a></span> | <span class="t">which by itself doesn't mean anything, but it's clearly less than this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=482" target="_blank">00:08:02.000</a></span> | <span class="t">So this piece of text is much further along the negative sentiment axis inside this model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=486" target="_blank">00:08:06.000</a></span> | <span class="t">When you look at other properties, like how much of the artistic kind of topic does it talk about is roughly the same,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=491" target="_blank">00:08:11.000</a></span> | <span class="t">the length is roughly the same, maybe the negative sentiment text is a bit more elaborate in its vocabulary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=500" target="_blank">00:08:20.000</a></span> | <span class="t">and so you can start to project these things into these meaningful directions and say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=503" target="_blank">00:08:23.000</a></span> | <span class="t">what are the features of the models, what are the attributes of the models finding in the text that we're feeding it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=509" target="_blank">00:08:29.000</a></span> | <span class="t">Another way you could test out some of these ideas is by mixing embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=514" target="_blank">00:08:34.000</a></span> | <span class="t">And so here I'm going to embed both of these pieces of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=517" target="_blank">00:08:37.000</a></span> | <span class="t">This one's the one that we've been playing with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=518" target="_blank">00:08:38.000</a></span> | <span class="t">This one is the beginning of a short story that I wrote once.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=521" target="_blank">00:08:41.000</a></span> | <span class="t">It's about this town in the Mediterranean coast that's calm and a little bit old.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=527" target="_blank">00:08:47.000</a></span> | <span class="t">And both of these have been embedded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=529" target="_blank">00:08:49.000</a></span> | <span class="t">And so I'm going to say, this is a 2,000-dimensional embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=533" target="_blank">00:08:53.000</a></span> | <span class="t">I'm going to say, give me a new embedding that's just the first 1,000 or so dimensions from the one embedding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=538" target="_blank">00:08:58.000</a></span> | <span class="t">and then take the last 1,000 dimensions of the second embedding and just like slam them together,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=542" target="_blank">00:09:02.000</a></span> | <span class="t">you're going to have this new embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=544" target="_blank">00:09:04.000</a></span> | <span class="t">And naively, you wouldn't really think that that would amount too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=546" target="_blank">00:09:06.000</a></span> | <span class="t">That would be kind of gibberish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=547" target="_blank">00:09:07.000</a></span> | <span class="t">But actually, if you generate some samples from it, you can tell, you can see in a bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=553" target="_blank">00:09:13.000</a></span> | <span class="t">you get a sentence that's kind of a semantic mix of both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=556" target="_blank">00:09:16.000</a></span> | <span class="t">You have structural similarities to both of those things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=559" target="_blank">00:09:19.000</a></span> | <span class="t">Like you have this structure where there's a quoted kind of title of a book in the beginning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=562" target="_blank">00:09:22.000</a></span> | <span class="t">There's topical similarities, there's punctuation similarities, tone similarities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=567" target="_blank">00:09:27.000</a></span> | <span class="t">And so this is an example of interpolating in latent space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=571" target="_blank">00:09:31.000</a></span> | <span class="t">The last thing I have, you may have seen on Twitter, is about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=576" target="_blank">00:09:36.000</a></span> | <span class="t">okay, I have this un-embedding model and I have kind of an un-embedding model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=579" target="_blank">00:09:39.000</a></span> | <span class="t">That works pretty well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=580" target="_blank">00:09:40.000</a></span> | <span class="t">Can I use this un-embedding model and somehow fine-tune it or otherwise adapt it so we can read out text from other kinds of embedding spaces?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=588" target="_blank">00:09:48.000</a></span> | <span class="t">So this is the same sentence we've been using, but now when I hit this run button,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=592" target="_blank">00:09:52.000</a></span> | <span class="t">it's going to embed this text not using my embedding model, but using OpenAI's text-to-eta2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=598" target="_blank">00:09:58.000</a></span> | <span class="t">And then there's a linear adapter that I've trained so that my decoder model can read out not from my embedding model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=604" target="_blank">00:10:04.000</a></span> | <span class="t">but from OpenAI's embedding space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=606" target="_blank">00:10:06.000</a></span> | <span class="t">So I'm going to embed it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=608" target="_blank">00:10:08.000</a></span> | <span class="t">It's going to try to decode out the text from given just the OpenAI embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=612" target="_blank">00:10:12.000</a></span> | <span class="t">And you can see, okay, it's not as perfect, but there's a surprising amount of detail that we've recovered out of just the embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=622" target="_blank">00:10:22.000</a></span> | <span class="t">with no reference to the source text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=624" target="_blank">00:10:24.000</a></span> | <span class="t">So you can see this proper noun, diaspora, it's surprisingly still in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=628" target="_blank">00:10:28.000</a></span> | <span class="t">This feature where there's a quoted title of a book is in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=631" target="_blank">00:10:31.000</a></span> | <span class="t">It's roughly about the same topic, things like the rogue AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=634" target="_blank">00:10:34.000</a></span> | <span class="t">Sometimes when I rerun this, there's also references to the author where the name is roughly correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=640" target="_blank">00:10:40.000</a></span> | <span class="t">So even surprising features like proper nouns, punctuation, things like the quotes, general structure and topic, obviously,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=648" target="_blank">00:10:48.000</a></span> | <span class="t">those are recoverable given just the embedding because of the amount of detail that these high-capacity embedding spaces have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=655" target="_blank">00:10:55.000</a></span> | <span class="t">But not only can you do this in the text space, you can also do this in image space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=659" target="_blank">00:10:59.000</a></span> | <span class="t">So here I have a few prepared files.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=664" target="_blank">00:11:04.000</a></span> | <span class="t">Let's start with me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=667" target="_blank">00:11:07.000</a></span> | <span class="t">And for dumb technical reasons, I have to put two of me in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=670" target="_blank">00:11:10.000</a></span> | <span class="t">And then let's try to interpolate in this image space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=673" target="_blank">00:11:13.000</a></span> | <span class="t">So this is now using clip, clip's embedding space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=675" target="_blank">00:11:15.000</a></span> | <span class="t">I'm going to try to generate, say, like six images in between me and the Notion avatar version of me, the cartoon version of me,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=684" target="_blank">00:11:24.000</a></span> | <span class="t">if the backend will warm up, cold starting models is sometimes difficult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=689" target="_blank">00:11:29.000</a></span> | <span class="t">There we go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=693" target="_blank">00:11:33.000</a></span> | <span class="t">So now it's generating six images, bridging, kind of interpolating between the photographic version of me and the cartoon version of me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=699" target="_blank">00:11:39.000</a></span> | <span class="t">And again, it's not perfect, but you can see here, on the left, it's quite photographic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=705" target="_blank">00:11:45.000</a></span> | <span class="t">And then as you move further down this interpolation, you're seeing more kind of cartoony features appear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=711" target="_blank">00:11:51.000</a></span> | <span class="t">And it's actually quite a surprisingly smooth transition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=714" target="_blank">00:11:54.000</a></span> | <span class="t">Another thing you can do on top of this is you can do text manipulations as well, because clip is a multimodal text and image model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=721" target="_blank">00:12:01.000</a></span> | <span class="t">And so I can say, let's add some text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=726" target="_blank">00:12:06.000</a></span> | <span class="t">I'm going to subtract the vector for a photo of a smiling man.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=732" target="_blank">00:12:12.000</a></span> | <span class="t">And instead, I'm going to add the vector for a photo of a very sad, crying man.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=738" target="_blank">00:12:18.000</a></span> | <span class="t">And then I'll embed these pieces of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=741" target="_blank">00:12:21.000</a></span> | <span class="t">And empirically, I find that for text, I have to be a little more careful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=744" target="_blank">00:12:24.000</a></span> | <span class="t">So I'm going to dial down how much of those vectors I'm adding and subtracting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=747" target="_blank">00:12:27.000</a></span> | <span class="t">And then generate six again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=749" target="_blank">00:12:29.000</a></span> | <span class="t">And...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=752" target="_blank">00:12:32.000</a></span> | <span class="t">It's taking a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=761" target="_blank">00:12:41.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=764" target="_blank">00:12:44.000</a></span> | <span class="t">I'm really sad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=765" target="_blank">00:12:45.000</a></span> | <span class="t">And you can do even more fun things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=770" target="_blank">00:12:50.000</a></span> | <span class="t">Like, you can try to add...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=771" target="_blank">00:12:51.000</a></span> | <span class="t">Like, here's a photo of a beach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=773" target="_blank">00:12:53.000</a></span> | <span class="t">I'm going to try to add some beach in this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=775" target="_blank">00:12:55.000</a></span> | <span class="t">This time, maybe just generate four for the sake of time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=778" target="_blank">00:12:58.000</a></span> | <span class="t">Or maybe there's a bug and it won't let me generate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=783" target="_blank">00:13:03.000</a></span> | <span class="t">So in all these images that I've done, both in the text and image domain...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=796" target="_blank">00:13:16.000</a></span> | <span class="t">Okay, the beach didn't quite survive the latent space arithmetic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=799" target="_blank">00:13:19.000</a></span> | <span class="t">But in all these demos, the only thing I'm doing is calculating vectors, calculating embeddings for examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=805" target="_blank">00:13:25.000</a></span> | <span class="t">And embedding them and just adding them together with some normalization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=810" target="_blank">00:13:30.000</a></span> | <span class="t">And it's surprising that just by doing that, you can try to manipulate interesting features in text and images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=815" target="_blank">00:13:35.000</a></span> | <span class="t">And with this, you can also do things like add style and subject at the same time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=821" target="_blank">00:13:41.000</a></span> | <span class="t">You can...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=822" target="_blank">00:13:42.000</a></span> | <span class="t">This is a cool image that I thought I generated when I made my first demo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=824" target="_blank">00:13:44.000</a></span> | <span class="t">And then you can also do some pretty smooth transitions between landscape imagery.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=827" target="_blank">00:13:47.000</a></span> | <span class="t">So...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=829" target="_blank">00:13:49.000</a></span> | <span class="t">That's interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=833" target="_blank">00:13:53.000</a></span> | <span class="t">In all these prototypes, one principle that I've tried to reiterate to myself is that oftentimes when you're studying this very complex, sophisticated models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=844" target="_blank">00:14:04.000</a></span> | <span class="t">you don't necessarily have the ability to look inside and say, "Okay, what's happening?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=847" target="_blank">00:14:07.000</a></span> | <span class="t">Not even getting an intuitive understanding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=848" target="_blank">00:14:08.000</a></span> | <span class="t">Even getting an intuitive understanding of what is the model thinking, what is the model looking at, can be difficult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=852" target="_blank">00:14:12.000</a></span> | <span class="t">And I think these are some of the ways that I've tried to render these invisible parts of the model a little bit more visible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=858" target="_blank">00:14:18.000</a></span> | <span class="t">To let you a little bit more directly observe exactly what the model is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=862" target="_blank">00:14:22.000</a></span> | <span class="t">The representations the model is operating in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=866" target="_blank">00:14:26.000</a></span> | <span class="t">And sometimes you can also take those and directly interact or let humans directly interact with the representations to explore what these spaces represent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=874" target="_blank">00:14:34.000</a></span> | <span class="t">And I think there's a ton of interesting, pretty groundbreaking research that's happening here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=879" target="_blank">00:14:39.000</a></span> | <span class="t">On the left here is the Othello world model paper, which is fascinating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=882" target="_blank">00:14:42.000</a></span> | <span class="t">Neurons in a haystack.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=884" target="_blank">00:14:44.000</a></span> | <span class="t">And then on the right is a very, very recent, I had to add this in last minute because it's super relevant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=889" target="_blank">00:14:49.000</a></span> | <span class="t">In a lot of these examples, I've calculated these feature dimensions by just giving examples and calculating centroids between them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=894" target="_blank">00:14:54.000</a></span> | <span class="t">But here, Anthropix and Newark, along with other work from Conjecture and other labs, have found unsupervised ways to try to automatically discover these dimensions inside models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=901" target="_blank">00:15:01.000</a></span> | <span class="t">So that's super exciting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=903" target="_blank">00:15:03.000</a></span> | <span class="t">And in general, I'm really excited to see latent spaces that appear to encode, by some definition, interpretable, controllable representations of the models, input and output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=912" target="_blank">00:15:12.000</a></span> | <span class="t">I want to talk a little bit in the last few minutes about the models that I'm using.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=916" target="_blank">00:15:16.000</a></span> | <span class="t">The text model is a custom model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=918" target="_blank">00:15:18.000</a></span> | <span class="t">I won't go into too much detail, but it's fine-tuned from a T5 checkpoint as a denoising autoencoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=924" target="_blank">00:15:24.000</a></span> | <span class="t">It's an encoder-decoder transformer with some modifications that you can see in the code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=927" target="_blank">00:15:27.000</a></span> | <span class="t">So here's a general transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=930" target="_blank">00:15:30.000</a></span> | <span class="t">Encoder on the left, decoder on the right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=932" target="_blank">00:15:32.000</a></span> | <span class="t">I have some pooling layers to get an embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=934" target="_blank">00:15:34.000</a></span> | <span class="t">This is like a normal T5 embedding model stack.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=936" target="_blank">00:15:36.000</a></span> | <span class="t">And then on the right, I have this special kind of gated layer that pulls from the embedding to decode from the embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=943" target="_blank">00:15:43.000</a></span> | <span class="t">You can look at the code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=944" target="_blank">00:15:44.000</a></span> | <span class="t">It's a little more easy to understand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=947" target="_blank">00:15:47.000</a></span> | <span class="t">But we take this model, and we can adapt it to other models as well, as you saw with the OpenAI embedding recovery.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=952" target="_blank">00:15:52.000</a></span> | <span class="t">And so on the left is the normal trading regime where you have an encoder, you get an embedding, and you try to reconstruct the text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=957" target="_blank">00:15:57.000</a></span> | <span class="t">On the right, we just train this linear adapter layer to go from embedding of a different model to then reconstruct the text with a normal decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=964" target="_blank">00:16:04.000</a></span> | <span class="t">And today, I'm excited to share that these models that I've been dealing with, that you may have asked about before, are open on HuggingFace.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=974" target="_blank">00:16:14.000</a></span> | <span class="t">So you can go download them and try them out now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=976" target="_blank">00:16:16.000</a></span> | <span class="t">These are the links.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=977" target="_blank">00:16:17.000</a></span> | <span class="t">On the left is the HuggingFace models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=978" target="_blank">00:16:18.000</a></span> | <span class="t">And then there's a Colab notebook that lets you get started really quickly and try to do things like interpolation and interpretation of these features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=984" target="_blank">00:16:24.000</a></span> | <span class="t">And so if you find any interesting results with these, please let me know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=987" target="_blank">00:16:27.000</a></span> | <span class="t">And if you have any questions, also reach out and I'll be able to help you out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=991" target="_blank">00:16:31.000</a></span> | <span class="t">The image model that I was using at the end was CacaoBrainsCarlo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=995" target="_blank">00:16:35.000</a></span> | <span class="t">Excited to see Korea stepping up there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=998" target="_blank">00:16:38.000</a></span> | <span class="t">In this model, this model is an unclip model, which is trained kind of like the way that DALI 2 was trained as a diffusion model that's trained to invert clip embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1005" target="_blank">00:16:45.000</a></span> | <span class="t">So go from clip embedding of images back to text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1008" target="_blank">00:16:48.000</a></span> | <span class="t">And that lets us do similar things as the text model that we used.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1012" target="_blank">00:16:52.000</a></span> | <span class="t">In all this prototyping, I think a general principle, if you have one takeaway from this talk,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1017" target="_blank">00:16:57.000</a></span> | <span class="t">it's that when you're working with these really complex models and kind of inscrutable pieces of data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1022" target="_blank">00:17:02.000</a></span> | <span class="t">if you can get something into a thing that feels like it can fit in your hand that you can play with,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1026" target="_blank">00:17:06.000</a></span> | <span class="t">that you can concretely see and observe and interact with, can be directly manipulated, visualized,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1031" target="_blank">00:17:11.000</a></span> | <span class="t">all these things, all the tools and prototypes that you can build around these things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1034" target="_blank">00:17:14.000</a></span> | <span class="t">I think help us get a deeper understanding of how these models work and how we can improve them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1038" target="_blank">00:17:18.000</a></span> | <span class="t">And in that way, I think models, language models and image models, generative models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1044" target="_blank">00:17:24.000</a></span> | <span class="t">are a really interesting laboratory for knowledge, for studying how these different kinds of modalities can be represented.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1051" target="_blank">00:17:31.000</a></span> | <span class="t">And Brad Victor said, "The purpose of a thinking medium is to bring thought outside the head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1056" target="_blank">00:17:36.000</a></span> | <span class="t">to represent these concepts in a form that can be seen with the senses and manipulated with the body.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1061" target="_blank">00:17:41.000</a></span> | <span class="t">In this way, the medium is literally an extension of the mind."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1064" target="_blank">00:17:44.000</a></span> | <span class="t">And I think that's a great poetic way to kind of describe the philosophy that I've approached a lot of my prototyping with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1071" target="_blank">00:17:51.000</a></span> | <span class="t">So, if you follow some of these principles and try to dig deeper in what the models are actually looking at,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1076" target="_blank">00:17:56.000</a></span> | <span class="t">build interfaces around them, I think more humane interfaces to knowledge are possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1080" target="_blank">00:18:00.000</a></span> | <span class="t">I'm really excited to see that future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1083" target="_blank">00:18:03.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1084" target="_blank">00:18:04.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1085" target="_blank">00:18:05.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1086" target="_blank">00:18:06.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1087" target="_blank">00:18:07.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1088" target="_blank">00:18:08.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1088" target="_blank">00:18:08.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1089" target="_blank">00:18:09.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvobVu1l7GI&t=1090" target="_blank">00:18:10.000</a></span> | <span class="t">I'll see you next time.</span></div></div></body></html>