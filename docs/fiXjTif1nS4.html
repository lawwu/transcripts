<html><head><title>Best Practices for Evaluating Large Language Model Applications with llmeval: Niklas Nielsen</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Best Practices for Evaluating Large Language Model Applications with llmeval: Niklas Nielsen</h2><a href="https://www.youtube.com/watch?v=fiXjTif1nS4"><img src="https://i.ytimg.com/vi/fiXjTif1nS4/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./fiXjTif1nS4.html">Whisper Transcript</a> | <a href="./transcript_fiXjTif1nS4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hi, this is Niklas. I'm the CTO and co-founder of Log10. And we want to talk about how you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=22" target="_blank">00:00:22.800</a></span> | <span class="t">scale the reliability of LLM applications using a new tool that we've built. During this year,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=28" target="_blank">00:00:28.560</a></span> | <span class="t">I think we all can agree that there's been like this kind of craze in the industry. And we've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=34" target="_blank">00:00:34.480</a></span> | <span class="t">rolling out a ton of intelligence features based on GPT. And we're now kind of finding ourselves in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=40" target="_blank">00:00:40.880</a></span> | <span class="t">a now what moment. Because without knowing what good means in a generative setting, it's really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=47" target="_blank">00:00:47.120</a></span> | <span class="t">hard and risky to evolve your applications by changing your prompts, configurations, let alone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=53" target="_blank">00:00:53.760</a></span> | <span class="t">considering going from one model provider to another, to more advanced use cases like self-posting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=60" target="_blank">00:01:00.400</a></span> | <span class="t">or fine tuning. We want to introduce a new tool today called LLM eval that enables teams to ship</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=68" target="_blank">00:01:08.400</a></span> | <span class="t">reliable LLM products. It is a command line tool that you can run locally. And with these four lines of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=79" target="_blank">00:01:19.520</a></span> | <span class="t">code, you should be good to go. The initialization creates a folder structure and best practices for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=90" target="_blank">00:01:30.480</a></span> | <span class="t">storing prompts and tests. And then this is based on a super configurable system from Meta called Hydra.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=99" target="_blank">00:01:39.760</a></span> | <span class="t">So you could basically extend it to your heart's desire. And the metrics that we have wired up are in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=107" target="_blank">00:01:47.360</a></span> | <span class="t">Python. So they could be any logic, could be called out to all the LLMs, whatever you want. And after these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=115" target="_blank">00:01:55.440</a></span> | <span class="t">evaluations have been run, you can generate some reports that basically gives you like a brief</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=121" target="_blank">00:02:01.200</a></span> | <span class="t">overview of how the entire app and all the tests are looking, but still support flexible test criteria,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=129" target="_blank">00:02:09.440</a></span> | <span class="t">because these models are very fuzzy. It's very hard to say with a guarantee that it's going to be one or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=134" target="_blank">00:02:14.400</a></span> | <span class="t">the other. But it's fairly safe to say that the majority cases or say three out of five should pass.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=142" target="_blank">00:02:22.400</a></span> | <span class="t">And we're going to jump into command line and take a look. We're just going to create a directory for today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=151" target="_blank">00:02:31.440</a></span> | <span class="t">And go into this directory and create ourselves a virtual environment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=158" target="_blank">00:02:38.320</a></span> | <span class="t">From here, we're going to install LLM eval</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=170" target="_blank">00:02:50.560</a></span> | <span class="t">and initialize the folder structure. What we should be able to see here is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=175" target="_blank">00:02:55.360</a></span> | <span class="t">a directory structure where we have our prompts. Let's see, a simple case could be this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=184" target="_blank">00:03:04.560</a></span> | <span class="t">where we have this message template saying like what is A plus B, only return the answer without any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=190" target="_blank">00:03:10.480</a></span> | <span class="t">explanation. So in this case, we know that we have to prompt engineer further in order to get an exact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=197" target="_blank">00:03:17.280</a></span> | <span class="t">output. Because let's take a look at how the test looks like. In this case, we're taking like the actual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=203" target="_blank">00:03:23.520</a></span> | <span class="t">output from the LLM and comparing it with the expected. And this is like a strict comparison.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=210" target="_blank">00:03:30.400</a></span> | <span class="t">What we had taken the liberty to do is to strip any spaces that might be come from the left. And that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=218" target="_blank">00:03:38.960</a></span> | <span class="t">because some models, in this case, clod, tends to prepend spaces. And so it's things like that that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=225" target="_blank">00:03:45.200</a></span> | <span class="t">you have to watch out for. And then we have the metric, which could be any metric that you want to surface</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=231" target="_blank">00:03:51.120</a></span> | <span class="t">in the report. And then the result, which is then pass or fail. And in this case, we want to add 4 and 5, and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=238" target="_blank">00:03:58.480</a></span> | <span class="t">expect it to be 9. And I'm just going to try to run this test here and try to revert some of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=245" target="_blank">00:04:05.920</a></span> | <span class="t">the prompt engineering that we did earlier. So I'm going to remove, only return the answer without any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=254" target="_blank">00:04:14.640</a></span> | <span class="t">explanation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=255" target="_blank">00:04:15.200</a></span> | <span class="t">And the way you get started is the lmeval run. But if you want to overwrite anything, if you just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=266" target="_blank">00:04:26.240</a></span> | <span class="t">do lmeval run, it runs everything. But if you do like prompts equals math, then it's only going to run the math</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=273" target="_blank">00:04:33.200</a></span> | <span class="t">example. If you do n tries one, then it's just going to do one sample. By default, we do five</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=283" target="_blank">00:04:43.200</a></span> | <span class="t">samples. So we get like a better read on the stability of each test, but it might be too much for you. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=289" target="_blank">00:04:49.760</a></span> | <span class="t">you can override anything. You can find these default settings here in the lmeval.yaml. And, but let's try to run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=299" target="_blank">00:04:59.920</a></span> | <span class="t">this and see what happens. And so this ran across Claude, GPT-4 and GPT-3.5 once. So we can go in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=308" target="_blank">00:05:08.640</a></span> | <span class="t">and generate a report.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=310" target="_blank">00:05:10.000</a></span> | <span class="t">And see like actually something failed. What was it that failed? So let's take a look at the output here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=317" target="_blank">00:05:17.280</a></span> | <span class="t">And in this case, because we've removed our prompt engineering, GPT-3.5 starts being a bit chatty. It says like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=325" target="_blank">00:05:25.440</a></span> | <span class="t">4.5 equals 9, Claude does something similar. So it kind of writes out the, writes out the equation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=331" target="_blank">00:05:31.600</a></span> | <span class="t">And now I'm going to try to revert. And see, let's, let's get this in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=337" target="_blank">00:05:37.440</a></span> | <span class="t">And we try to run one more time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=341" target="_blank">00:05:41.200</a></span> | <span class="t">Great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=346" target="_blank">00:05:46.560</a></span> | <span class="t">Now, when we change the report, it can say some tests failed, but the most recent tests that we ran</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=351" target="_blank">00:05:51.280</a></span> | <span class="t">passed. So when you do the report, it's going to generate a summary, you can generate a report</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=356" target="_blank">00:05:56.160</a></span> | <span class="t">per run, but then also say overall, was there anything that failed out of these reports.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=362" target="_blank">00:06:02.400</a></span> | <span class="t">If you want to go a bit more advanced, let's say you want to use tools, we have an example here where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=371" target="_blank">00:06:11.280</a></span> | <span class="t">we are generating some Python code. And again, we had to add a number of different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=375" target="_blank">00:06:15.680</a></span> | <span class="t">clauses to make sure that it only outputs Python. It tends to be very happy generating surrounding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=382" target="_blank">00:06:22.400</a></span> | <span class="t">explanations. So in this case, we are going to see whether or not it returns an actual Python program</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=392" target="_blank">00:06:32.000</a></span> | <span class="t">that could be parsed. So let's try to run that. If you go in and take a look at this report,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=399" target="_blank">00:06:39.440</a></span> | <span class="t">you can see that these tests actually end up passing our tool use. And to round up, we have model-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=409" target="_blank">00:06:49.440</a></span> | <span class="t">evaluation as well, where you can test using other models. And so in this case, say with grading,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=418" target="_blank">00:06:58.720</a></span> | <span class="t">we can go in and define like a full set of criteria. Here, we're evaluating mermaid diagrams,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=424" target="_blank">00:07:04.480</a></span> | <span class="t">giving a score between one and five, and the reason. And that is also supported in LLM eval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=432" target="_blank">00:07:12.160</a></span> | <span class="t">One thing about the previous approach is that it takes quite an amount of work to set up these tests and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=438" target="_blank">00:07:18.560</a></span> | <span class="t">gather your test cases. And one really compelling answer to evaluation has been model-based evaluation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=446" target="_blank">00:07:26.480</a></span> | <span class="t">And it's a setting where you have typically a larger model to discriminate or kind of grade or be a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=453" target="_blank">00:07:33.200</a></span> | <span class="t">judge over the output from another LLM. And that makes it so you can get more nuanced output like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=460" target="_blank">00:07:40.000</a></span> | <span class="t">pass/fail or a grade from one to five or preferences between different options and its reasoning behind it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=466" target="_blank">00:07:46.960</a></span> | <span class="t">There's a number of pitfalls, unfortunately, around this approach, around biases towards the output from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=475" target="_blank">00:07:55.120</a></span> | <span class="t">the model itself. If you're sweeping different models, they tend to prefer their own output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=479" target="_blank">00:07:59.120</a></span> | <span class="t">They are very good at giving point scores, saying I think between 0 and 1, or larger scores between 0 and 100.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=487" target="_blank">00:08:07.840</a></span> | <span class="t">But there are different ways where you can start increasing the accuracy of the kind of feedback</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=494" target="_blank">00:08:14.800</a></span> | <span class="t">that's been generated. And we've been working on this, where you basically start bridging between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=502" target="_blank">00:08:22.400</a></span> | <span class="t">model-based and human feedback. So instead of removing the human completely from the feedback,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=507" target="_blank">00:08:27.440</a></span> | <span class="t">you start taking in all the feedback that might have been given prior and start modeling it. And say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=514" target="_blank">00:08:34.160</a></span> | <span class="t">like, if you have all the feedback from John, then we create an auto-John that will start generating feedback</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=520" target="_blank">00:08:40.240</a></span> | <span class="t">for review for any incoming completions. And so in this case here, we have two pieces of feedback that's been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=526" target="_blank">00:08:46.880</a></span> | <span class="t">already given by a human. So here it was all just a score of five, or here just like a bit more nuanced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=534" target="_blank">00:08:54.720</a></span> | <span class="t">But here we are kind of pending feedback. And if you click this, we have AI suggested an answer to this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=546" target="_blank">00:09:06.480</a></span> | <span class="t">And that's all I have today. If you want to get started on LLM-Eval, we have our documentation at our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=553" target="_blank">00:09:13.360</a></span> | <span class="t">usual documentation site. And you can find me at Nicholas Crawford on X, or formerly known as Twitter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fiXjTif1nS4&t=561" target="_blank">00:09:21.440</a></span> | <span class="t">or it should be an email at nick@log10.io. Thank you.</span></div></div></body></html>