<html><head><title>Going Further with CUDA for Python Programmers</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Going Further with CUDA for Python Programmers</h2><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo"><img src="https://i.ytimg.com/vi/eUuGdh3nBGo/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=0">0:0</a> Introduction to Optimized Matrix Multiplication<br><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=724">12:4</a> Shared Memory Techniques for CUDA<br><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1212">20:12</a> Implementing Shared Memory Optimization in Python<br><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2535">42:15</a> Translating Python to CUDA and Performance Considerations<br><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3355">55:55</a> Numba: Bringing Python and CUDA Together<br><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4306">71:46</a> The Future of AI in Coding<br><br><div style="text-align: left;"><a href="./eUuGdh3nBGo.html">Whisper Transcript</a> | <a href="./transcript_eUuGdh3nBGo.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">So, welcome. This is going further with CUDA for Python programmers. As the name suggests,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=7" target="_blank">00:00:07.640</a></span> | <span class="t">this won't make too much sense unless you've got started with CUDA for Python programmers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=13" target="_blank">00:00:13.640</a></span> | <span class="t">The good news is that I have a video called Getting Started with CUDA for Python programmers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=19" target="_blank">00:00:19.320</a></span> | <span class="t">So, start there. It's only a bit over an hour long. You might be surprised at how quick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=26" target="_blank">00:00:26.160</a></span> | <span class="t">and easy it is to get started if you haven't. So, assuming that you have got started, today</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=32" target="_blank">00:00:32.000</a></span> | <span class="t">we're going to be looking at the most important next step of taking advantage of CUDA, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=40" target="_blank">00:00:40.400</a></span> | <span class="t">is we've already learnt to take advantage of the thousands of threads that you can run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=45" target="_blank">00:00:45.260</a></span> | <span class="t">simultaneously on a GPU. Today we're going to learn how to take advantage of the incredibly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=51" target="_blank">00:00:51.480</a></span> | <span class="t">fast memory. So, up to now, although we haven't really talked about it, the memory we've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=58" target="_blank">00:00:58.600</a></span> | <span class="t">using is what's called global memory. It's basically think of this. So, this is the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=68" target="_blank">00:01:08.360</a></span> | <span class="t">book we looked at last week, which we do recommend programming massively parallel processes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=74" target="_blank">00:01:14.960</a></span> | <span class="t">And the stuff we're covering today is largely covered in chapter 5 of that book. In this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=82" target="_blank">00:01:22.340</a></span> | <span class="t">CUDA mode series, there's a lecture from Thomas Boonerman, which goes through this and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=90" target="_blank">00:01:30.000</a></span> | <span class="t">previous chapter in some detail. And so, that's actually a good video to watch maybe after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=95" target="_blank">00:01:35.040</a></span> | <span class="t">this one or before this one. Either order is fine. They're covering similar material</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=100" target="_blank">00:01:40.160</a></span> | <span class="t">in different ways. The key thing to understand is so, that we're looking at here today is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=107" target="_blank">00:01:47.520</a></span> | <span class="t">that this, if we look at this box here, which is basically you can think of as a GPU. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=112" target="_blank">00:01:52.280</a></span> | <span class="t">in the GPU, you have global memory. Global memory is basically what we've always been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=117" target="_blank">00:01:57.440</a></span> | <span class="t">using so far when we just put, when we say like dot CUDA in PyTorch, it's actually putting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=126" target="_blank">00:02:06.720</a></span> | <span class="t">the tensor into global memory. Global memory is pretty fast compared to some other types</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=133" target="_blank">00:02:13.880</a></span> | <span class="t">of memory we might be used to, but it's far from the quickest memory available on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=138" target="_blank">00:02:18.880</a></span> | <span class="t">GPU. In fact, this shared memory is much faster. Shared memory, however, is not global, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=148" target="_blank">00:02:28.280</a></span> | <span class="t">is to say that not all of the threads can see it. In fact, as this box indicates, shared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=157" target="_blank">00:02:37.600</a></span> | <span class="t">memory is something that's only available to the threads on a specific streaming multiprocessor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=166" target="_blank">00:02:46.440</a></span> | <span class="t">SM, or in CUDA programming world within a block. So, all of the different threads in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=174" target="_blank">00:02:54.120</a></span> | <span class="t">a block can access shared memory. And the reason we care about this is that shared memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=180" target="_blank">00:03:00.600</a></span> | <span class="t">is about 10 times faster than global memory. And because CUDA with all of its simultaneous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=192" target="_blank">00:03:12.680</a></span> | <span class="t">thousands of threads running at the same time is so incredibly quick, because GPUs are so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=196" target="_blank">00:03:16.520</a></span> | <span class="t">incredibly quick, the speed at which you access memory turns out to matter a whole lot. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=202" target="_blank">00:03:22.960</a></span> | <span class="t">being able to use this shared memory effectively is as important as being able to use the thousands</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=208" target="_blank">00:03:28.400</a></span> | <span class="t">of threads at the same time simultaneously is important. So, in the last lecture we focused</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=214" target="_blank">00:03:34.160</a></span> | <span class="t">on how to use all of those threads, and today we'll focus on how to use shared memory. Those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=219" target="_blank">00:03:39.240</a></span> | <span class="t">two things will get you quite a long way in terms of creating pretty fast CUDA code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=229" target="_blank">00:03:49.600</a></span> | <span class="t">Okay. So, the repo for these lectures is the CUDA mode repo, and specifically the CUDA</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=244" target="_blank">00:04:04.800</a></span> | <span class="t">mode /lectures repo. And in there you'll find there's a lecture 5. You don't have to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=250" target="_blank">00:04:10.840</a></span> | <span class="t">seen all the lectures beforehand, but they're certainly all useful. Just need to have seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=256" target="_blank">00:04:16.120</a></span> | <span class="t">lecture 3, which is the one I mentioned. Lecture 5 is where today's notebook will be found.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=264" target="_blank">00:04:24.160</a></span> | <span class="t">And here it is. Okay. So, one thing I'll just mention that I've added is a little utils.py</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=275" target="_blank">00:04:35.520</a></span> | <span class="t">where some of the stuff that we used last time, and what we used quite a bit, I've just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=280" target="_blank">00:04:40.520</a></span> | <span class="t">put it all into a script so we can access it multiple times. So, we've got the C div,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=286" target="_blank">00:04:46.840</a></span> | <span class="t">which is sealing the vision function, the little load inline wrapper called load CUDA,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=292" target="_blank">00:04:52.400</a></span> | <span class="t">and the little kind of prefix we have that has the hash includes and the stuff we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=296" target="_blank">00:04:56.660</a></span> | <span class="t">going to need there. And so, you'll see that we're going to import those here. Other than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=306" target="_blank">00:05:06.200</a></span> | <span class="t">that, we're going to import all the usual stuff that we like to use. Last time we used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=313" target="_blank">00:05:13.720</a></span> | <span class="t">simple namespace, but actually thought let's make things closer to -- let's make things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=320" target="_blank">00:05:20.880</a></span> | <span class="t">closer to how CUDA does things, and let's create a little thing called dim3. So, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=331" target="_blank">00:05:31.000</a></span> | <span class="t">is a 3D grid with an X, a Y, and a Z using the handy little Python named tuple functionality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=338" target="_blank">00:05:38.200</a></span> | <span class="t">So, here's a nice way for us. And we can, just like in CUDA, provide as many of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=348" target="_blank">00:05:48.200</a></span> | <span class="t">dimensions as we want. Today we'll be doing two-dimensional grids. So, there'll be implicit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=356" target="_blank">00:05:56.120</a></span> | <span class="t">Z equals 1. So, we can access these as D dot X and D dot Y, for example. Like before, we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=365" target="_blank">00:06:05.680</a></span> | <span class="t">use Wurlitzer to print stuff from CUDA if we want to. CUDA launch blocking is helpful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=374" target="_blank">00:06:14.960</a></span> | <span class="t">for debugging, so you can turn that on if you want to. And so, today we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=381" target="_blank">00:06:21.360</a></span> | <span class="t">do a matrix multiplication of a 5120 by 256 matrix M1 by a 256 by 5120 matrix M2. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=392" target="_blank">00:06:32.440</a></span> | <span class="t">approach of going from -- it's not true. Okay. So, like before, we're going to start by looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=404" target="_blank">00:06:44.720</a></span> | <span class="t">at pure Python, and so pure Python is going to be really, really slow. So, to handle that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=410" target="_blank">00:06:50.880</a></span> | <span class="t">we're going to create a sample of the first matrix with the first four rows, and a sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=416" target="_blank">00:06:56.000</a></span> | <span class="t">of the second matrix with the first four columns. And so, we'll use that for our pure Python</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=420" target="_blank">00:07:00.760</a></span> | <span class="t">example. All right. So, just to remind you what we've already done in the past is we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=425" target="_blank">00:07:05.520</a></span> | <span class="t">created this simple kernel runner that goes through every block and every thread. Not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=434" target="_blank">00:07:14.960</a></span> | <span class="t">real blocks and threads, they're actually just integers. And calls some kernel, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=439" target="_blank">00:07:19.920</a></span> | <span class="t">is not actually a kernel, it's just a function. And I'm going to use dem3 now that we've got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=444" target="_blank">00:07:24.320</a></span> | <span class="t">it to pass into that. And so, this was our previous matrix multiplication. We grabbed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=449" target="_blank">00:07:29.240</a></span> | <span class="t">the row, we grabbed the column from the indexes we passed in. We have a guard. And we then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=457" target="_blank">00:07:37.000</a></span> | <span class="t">accumulated our dot product for whatever particular row and column we're filling in. So, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=467" target="_blank">00:07:47.680</a></span> | <span class="t">is basically the -- ignore the extra details here, but conceptually, we're just doing this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=478" target="_blank">00:07:58.080</a></span> | <span class="t">dot product, for example, to fill in -- this is -- so, if we're filling in this here, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=487" target="_blank">00:08:07.680</a></span> | <span class="t">this is R. And this is C. So, this is R comma C. And so, we're doing the dot product between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=502" target="_blank">00:08:22.240</a></span> | <span class="t">that column and that row. And so, that's what this looping is here. So, I is going through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=512" target="_blank">00:08:32.720</a></span> | <span class="t">all of the elements of the row and the column. And multiplying, adding, and then putting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=519" target="_blank">00:08:39.120</a></span> | <span class="t">that into the output. So, that's what we do. We have a so-called kernel. And then we created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=525" target="_blank">00:08:45.920</a></span> | <span class="t">something that would call the kernel by calling our kernel runner, passing in the function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=532" target="_blank">00:08:52.360</a></span> | <span class="t">We need our blocks and our threads per block, which are just dem3 tuples. And then we pass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=539" target="_blank">00:08:59.560</a></span> | <span class="t">in our flattened data and our -- any other information that's required. And so, we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=547" target="_blank">00:09:07.560</a></span> | <span class="t">check that that matrix multiplication result using these small sample versions is close</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=555" target="_blank">00:09:15.380</a></span> | <span class="t">to the PyTorch version. And it is. And then we also looked at the CUDA version. And the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=565" target="_blank">00:09:25.280</a></span> | <span class="t">CUDA version we created by pasting the kernel into chat GPT. And it's bad out something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=573" target="_blank">00:09:33.200</a></span> | <span class="t">which we hardly had to change at all to get this. And the kernel runner also looks very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=578" target="_blank">00:09:38.840</a></span> | <span class="t">similar except that the syntax for calling a kernel in CUDA is different with this weird</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=585" target="_blank">00:09:45.000</a></span> | <span class="t">triple angle bracket. To make life a little bit simpler for myself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=593" target="_blank">00:09:53.760</a></span> | <span class="t">you might remember before we had the CPP source where we would copy and paste that into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=600" target="_blank">00:10:00.720</a></span> | <span class="t">string. I got a bit bored of doing that manually. So, I created a little get signature function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=606" target="_blank">00:10:06.480</a></span> | <span class="t">that just uses a regular expression to automatically find that line of code. And so, for the rest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=613" target="_blank">00:10:13.080</a></span> | <span class="t">of this lesson, I will be getting this CPP source automatically. That way I don't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=618" target="_blank">00:10:18.560</a></span> | <span class="t">to worry about changing it. But you can see that regex is just returning the necessary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=626" target="_blank">00:10:26.160</a></span> | <span class="t">line of code plus the semicolon. So, that makes life a little bit simpler. And I like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=633" target="_blank">00:10:33.760</a></span> | <span class="t">being simple. Okay. So, then we go load CUDA. It ran very quickly because I've already compiled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=638" target="_blank">00:10:38.720</a></span> | <span class="t">this once and PyTorch caches that. And this is actually another change I made since last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=643" target="_blank">00:10:43.800</a></span> | <span class="t">time is that in the load CUDA function, if you don't pass in a name, then it uses the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=653" target="_blank">00:10:53.480</a></span> | <span class="t">function's name. And that means that PyTorch will cache different versions of your code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=660" target="_blank">00:11:00.880</a></span> | <span class="t">with different names for the various different things you're doing. So, you won't lose your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=664" target="_blank">00:11:04.200</a></span> | <span class="t">cache each time. So, that's handy as well. Okay. So, now we can use the full matrices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=669" target="_blank">00:11:09.800</a></span> | <span class="t">because we're going to be nice and fast. We need them to be contiguous in CUDA. So, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=674" target="_blank">00:11:14.120</a></span> | <span class="t">will create M1C and M2C for that. And they should be similar to the result of PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=681" target="_blank">00:11:21.760</a></span> | <span class="t">doing it. And it takes about six milliseconds. One thing I wondered about is how long of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=691" target="_blank">00:11:31.760</a></span> | <span class="t">that six milliseconds was it actually running the matrix multiplication compared to doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=698" target="_blank">00:11:38.840</a></span> | <span class="t">all this other stuff before it. So, I just commented out those two lines of code and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=704" target="_blank">00:11:44.040</a></span> | <span class="t">reran it. And that took about 50 microseconds. So, that's 0.05 milliseconds. So, very little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=711" target="_blank">00:11:51.720</a></span> | <span class="t">of this time is kind of overhead. Most of this is actually doing a matrix multiplication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=716" target="_blank">00:11:56.560</a></span> | <span class="t">So, I think that's an encouraging start. Okay. So, how do we take advantage of shared memory?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=725" target="_blank">00:12:05.680</a></span> | <span class="t">The problem here is that in a loop here, M and N are global memory. And so, in this loop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=737" target="_blank">00:12:17.680</a></span> | <span class="t">that's happening K times, we are reading from global memory again and again and again. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=745" target="_blank">00:12:25.280</a></span> | <span class="t">that is a bit of a bummer. So, there's a better thing we could do, which is instead we could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=751" target="_blank">00:12:31.880</a></span> | <span class="t">use shared memory. Now, the problem is that shared memory is quite small. So, we can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=762" target="_blank">00:12:42.600</a></span> | <span class="t">just dump everything into shared memory for every single thread. Because we've got lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=768" target="_blank">00:12:48.560</a></span> | <span class="t">and lots of threads running at the same time. Or I should say for every block. So, we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=773" target="_blank">00:12:53.960</a></span> | <span class="t">got lots of blocks running at the same time. If every one of them had the entire matrices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=777" target="_blank">00:12:57.460</a></span> | <span class="t">in memory for every block, that's going to be an enormous amount of data. And that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=781" target="_blank">00:13:01.600</a></span> | <span class="t">going to be far too much for our GPU to handle. So, to deal with that, what we do is we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=790" target="_blank">00:13:10.080</a></span> | <span class="t">something called tiling. And a tile is basically -- so, we're going to pick a tile width of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=798" target="_blank">00:13:18.080</a></span> | <span class="t">16. So, here it says tile width here. We're going to use 16. We basically say, okay, if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=802" target="_blank">00:13:22.560</a></span> | <span class="t">we're going to calculate this R comma C thing here, right, instead of doing the entire dot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=809" target="_blank">00:13:29.320</a></span> | <span class="t">product of all of this row and all of this column, what we could instead do is just grab</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=821" target="_blank">00:13:41.760</a></span> | <span class="t">the first little bit of that row. And the first little bit of that column. We could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=832" target="_blank">00:13:52.680</a></span> | <span class="t">take the dot product of those and put them into R comma C. And then we could do that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=838" target="_blank">00:13:58.040</a></span> | <span class="t">again for the next tile across and the next tile across and so forth. And this is what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=842" target="_blank">00:14:02.320</a></span> | <span class="t">this dot, dot, dot here is. And the next tile across. And so, then, you know, eventually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=848" target="_blank">00:14:08.680</a></span> | <span class="t">we get to this bit of the row by this bit of the column, take the dot product of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=854" target="_blank">00:14:14.560</a></span> | <span class="t">and add them up to the existing R comma C output we've already got. And so, that's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=862" target="_blank">00:14:22.760</a></span> | <span class="t">-- it's doing exactly the same thing. But rather than doing the dot product all at once,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=867" target="_blank">00:14:27.880</a></span> | <span class="t">we're doing it one step at a time. That's not interesting of itself. But what is interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=879" target="_blank">00:14:39.560</a></span> | <span class="t">is you might notice that let's say for calculating this bit here, let's say, so this is thread</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=889" target="_blank">00:14:49.960</a></span> | <span class="t">zero comma zero, we can do the same thing. We can take the first little bit of this and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=896" target="_blank">00:14:56.560</a></span> | <span class="t">the first little bit of this and take their dot product. And that gives us the first piece</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=904" target="_blank">00:15:04.520</a></span> | <span class="t">we're going to need of that one. And we can do that again and again and again until eventually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=908" target="_blank">00:15:08.840</a></span> | <span class="t">we get to this one. And we do this bit times this bit. And we keep going all the way to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=915" target="_blank">00:15:15.960</a></span> | <span class="t">the end until there's a final tile at the end. And once we've done that for all of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=922" target="_blank">00:15:22.960</a></span> | <span class="t">bits, eventually we're going to have the correct answer in zero comma zero. Why is that interesting?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=928" target="_blank">00:15:28.560</a></span> | <span class="t">Well, it's interesting because we could reorder this rather than doing the whole first little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=935" target="_blank">00:15:35.400</a></span> | <span class="t">bit of this row and then the next bit of that row and the next bit of that row and the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=938" target="_blank">00:15:38.400</a></span> | <span class="t">bit of that row. Instead, what we could do is we could calculate zero comma zero for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=948" target="_blank">00:15:48.280</a></span> | <span class="t">the first tile and then we could calculate zero comma one for the first tile. And notice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=954" target="_blank">00:15:54.520</a></span> | <span class="t">this is zero comma one. It's exactly the same row as we had before, right? But a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=959" target="_blank">00:15:59.880</a></span> | <span class="t">column. Now, with a normal kind of CPU style thinking, you'd say like, oh, maybe this will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=967" target="_blank">00:16:07.600</a></span> | <span class="t">be in the cache. So this could be faster. And that doesn't work in GPU programming and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=971" target="_blank">00:16:11.760</a></span> | <span class="t">GPU programming, we instead use shared memory. So we could have put this into shared memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=977" target="_blank">00:16:17.940</a></span> | <span class="t">And if we had done so, then the second time we use it, we don't have to read it from global</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=981" target="_blank">00:16:21.720</a></span> | <span class="t">memory. It's already there in shared memory. And then the same thing will happen when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=985" target="_blank">00:16:25.920</a></span> | <span class="t">get to the second row, right? We could put that into shared memory. And then we go second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=994" target="_blank">00:16:34.960</a></span> | <span class="t">row of that tile times the first column of that tile is needed to do one comma zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1002" target="_blank">00:16:42.040</a></span> | <span class="t">And if you think about it, we've already accessed the first column of the tile in N. So if we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1008" target="_blank">00:16:48.720</a></span> | <span class="t">had put that in shared memory as well, then we won't have to get that from global memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1013" target="_blank">00:16:53.020</a></span> | <span class="t">either. So maybe you see where this is going. What we're going to be able to do actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1018" target="_blank">00:16:58.180</a></span> | <span class="t">is before we do any work is we'll put this whole tile into shared memory and we'll put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1025" target="_blank">00:17:05.640</a></span> | <span class="t">this whole tile into shared memory. And then we'll take the matrix multiplication of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1033" target="_blank">00:17:13.480</a></span> | <span class="t">two tiles. And that will give us all of the first pieces of the entire tile output. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1041" target="_blank">00:17:21.600</a></span> | <span class="t">then we'll do the same for the tile one to the right of this one, and one underneath</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1046" target="_blank">00:17:26.600</a></span> | <span class="t">this one. And we'll take the matrix product of those and add it to this again, and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1050" target="_blank">00:17:30.760</a></span> | <span class="t">forth until eventually again, we get up to here, we put that whole tile into shared memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1057" target="_blank">00:17:37.480</a></span> | <span class="t">we put that whole tile into shared memory, we take the matrix product, which again, remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1063" target="_blank">00:17:43.000</a></span> | <span class="t">it's just lots and lots of dot products, the column and row dot products. And so all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1067" target="_blank">00:17:47.200</a></span> | <span class="t">those are going to be able to use shared memory and we can we add them to the outputs here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1072" target="_blank">00:17:52.320</a></span> | <span class="t">And so once we eventually do that for all of the tiles, we will have finished calculating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1080" target="_blank">00:18:00.160</a></span> | <span class="t">these outputs. So how many times did we read from global memory? Each of the input elements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1088" target="_blank">00:18:08.120</a></span> | <span class="t">only got read from global memory once. And the soon as we grabbed it, all we did with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1093" target="_blank">00:18:13.240</a></span> | <span class="t">it was we put it into shared memory, and then the actual dot product was entirely done from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1098" target="_blank">00:18:18.100</a></span> | <span class="t">shared memory. And that's how we make this faster. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1112" target="_blank">00:18:32.460</a></span> | <span class="t">to do that, let's use Python, plain Python. And we're going to basically try to design</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1122" target="_blank">00:18:42.620</a></span> | <span class="t">something in Python that looks a lot like how CUDA is going to do it. And then we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1126" target="_blank">00:18:46.680</a></span> | <span class="t">going to auto generate CUDA just like we have in the past. So in CUDA, the kind of maximally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1136" target="_blank">00:18:56.080</a></span> | <span class="t">flexible way to do things is what's called dynamic shared memory, where you tell CUDA</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1142" target="_blank">00:19:02.000</a></span> | <span class="t">how much shared memory you're going to want. And it puts it aside for you. And then in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1148" target="_blank">00:19:08.480</a></span> | <span class="t">basically one contiguous block with a pointer to that block that you will have access to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1153" target="_blank">00:19:13.880</a></span> | <span class="t">which is the same as an array. And then you basically grab from that block any of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1158" target="_blank">00:19:18.120</a></span> | <span class="t">pieces you want. In Python, we can do exactly the same kind of thing by using a trick which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1165" target="_blank">00:19:25.560</a></span> | <span class="t">is true for both NumPy arrays and PyTorch tensors, which is that views into those tensors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1171" target="_blank">00:19:31.220</a></span> | <span class="t">are writable. So if we create a tensor of length 5, and then we create a view of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1176" target="_blank">00:19:36.800</a></span> | <span class="t">first three elements and of the last two elements called B and C, if we then modify B, it actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1188" target="_blank">00:19:48.080</a></span> | <span class="t">changes A because they're a view of the same memory. And if we change C, it'll also change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1196" target="_blank">00:19:56.420</a></span> | <span class="t">A. And so that's going to be handy for us. You'll see why in a moment. We're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1201" target="_blank">00:20:01.960</a></span> | <span class="t">basically use our shared memory like that. Now, the thing is, we've got to restructure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1209" target="_blank">00:20:09.000</a></span> | <span class="t">our kernel runner a little bit because we have two steps now. Step number one is copy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1221" target="_blank">00:20:21.140</a></span> | <span class="t">all of our input into shared memory. And then step two is take the dot product. And so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1227" target="_blank">00:20:27.200</a></span> | <span class="t">doesn't quite work with our previous approach because we just have one big loop and we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1234" target="_blank">00:20:34.680</a></span> | <span class="t">have one thing that we do. So I've changed our kernel runner to create a shared memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1242" target="_blank">00:20:42.840</a></span> | <span class="t">kernel runner. I've still got the same loop through blocks dot Y, the same loop through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1247" target="_blank">00:20:47.880</a></span> | <span class="t">blocks dot X. This is all pure Python again. And here I'm going to create our shared memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1254" target="_blank">00:20:54.480</a></span> | <span class="t">And so this is now going to be passed the shared memory into each function. So all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1261" target="_blank">00:21:01.120</a></span> | <span class="t">our threads are going to have access to the same shared memory. Now, we don't actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1265" target="_blank">00:21:05.880</a></span> | <span class="t">create the threads here. So instead, step number one is in my kernel, I'm actually going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1274" target="_blank">00:21:14.600</a></span> | <span class="t">to do the loop through the threads manually. We'll improve this in a moment. Don't worry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1279" target="_blank">00:21:19.520</a></span> | <span class="t">It's pretty messy with all this kind of duplicate code. But at least it's nice and simple to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1284" target="_blank">00:21:24.460</a></span> | <span class="t">understand. So first of all, let's just run this and confirm we get the same answer as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1290" target="_blank">00:21:30.080</a></span> | <span class="t">before. And we do. So let's see what's happening. The bit that does the running is exactly the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1297" target="_blank">00:21:37.520</a></span> | <span class="t">same, except that I'm calling our new shared memory runner. And I'm also telling it the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1308" target="_blank">00:21:48.240</a></span> | <span class="t">third thing you have to pass in is the shared size is how much shared memory. So how much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1312" target="_blank">00:21:52.880</a></span> | <span class="t">shared memory do we need? We need tile width times tile width. Because that's the size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1320" target="_blank">00:22:00.280</a></span> | <span class="t">of the tile is tile width by tile width. But we're going to need two of them, one for m</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1327" target="_blank">00:22:07.080</a></span> | <span class="t">and one for n. So the amount of shared memory we need is tile width times tile width times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1332" target="_blank">00:22:12.520</a></span> | <span class="t">two. So that's what this is. Tile width times tile width times two. So that's going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1338" target="_blank">00:22:18.920</a></span> | <span class="t">passed in as the shared memory size. And that will be constructed here. Okay. So that shared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1351" target="_blank">00:22:31.920</a></span> | <span class="t">then gets passed into our kernel. Our pretend kernel. And it's just one big continuous block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1359" target="_blank">00:22:39.040</a></span> | <span class="t">of memory. So we have to grab the first share size bits and that will be our m shared memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1366" target="_blank">00:22:46.120</a></span> | <span class="t">So our two inputs are m and n. And everything from there onwards is going to be our n shared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1374" target="_blank">00:22:54.840</a></span> | <span class="t">memory. So then what we do is we loop through. This is exactly the same as we had before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1380" target="_blank">00:23:00.800</a></span> | <span class="t">In fact, I should use C div here to make it a bit more obvious what's going on. C div.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1395" target="_blank">00:23:15.640</a></span> | <span class="t">So we go through every element in the dot product we're going to need. And so the indexing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1401" target="_blank">00:23:21.640</a></span> | <span class="t">starts to get a bit complicated here. So pH is what the book and therefore we will use,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1409" target="_blank">00:23:29.480</a></span> | <span class="t">which is basically the index of what tile are we up to. So we loop through each tile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1415" target="_blank">00:23:35.580</a></span> | <span class="t">So look through each tile. So the number of tiles we'll need is the size of the k dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1424" target="_blank">00:23:44.640</a></span> | <span class="t">So that's the number of columns in m or the number of rows in n. And then divide that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1431" target="_blank">00:23:51.920</a></span> | <span class="t">by the tile width. And that tells you how many tiles will fit. We do a ceiling division</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1438" target="_blank">00:23:58.120</a></span> | <span class="t">to go all the way to the end. So then we need to know. So let's say we're doing again we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1445" target="_blank">00:24:05.000</a></span> | <span class="t">doing this R comma C one here. So we need to know where this is. Where does it start? And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1461" target="_blank">00:24:21.040</a></span> | <span class="t">the answer is that we've done pH lots of tiles so far. Each one has jumped across TW or tile</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1468" target="_blank">00:24:28.640</a></span> | <span class="t">width. So this distance here is pH times tile width. And we're going to call that IDX. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1479" target="_blank">00:24:39.480</a></span> | <span class="t">this is an important tip. I found I had a lot of trouble getting this to like settled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1484" target="_blank">00:24:44.640</a></span> | <span class="t">in my head until I drew it all out and wrote on my picture what everything is. So and I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1495" target="_blank">00:24:55.760</a></span> | <span class="t">been doing this with the help also of my friend Karim who works with me at answer.ai. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1500" target="_blank">00:25:00.680</a></span> | <span class="t">he found the same thing. We were both like our first attempts were both to do it just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1504" target="_blank">00:25:04.680</a></span> | <span class="t">in code and we did not get it working until we actually started drawing it out. And that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1510" target="_blank">00:25:10.320</a></span> | <span class="t">when Karim and I actually were like oh OK that all makes sense. So that's what IDX is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1516" target="_blank">00:25:16.760</a></span> | <span class="t">And so notice IDX is that but it's also because this is these are symmetric it's also that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1524" target="_blank">00:25:24.260</a></span> | <span class="t">Like it's also IDX. OK. So now we need to fill in the shared memory. So we've got two sets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1533" target="_blank">00:25:33.740</a></span> | <span class="t">of threads one to fill in the shared memory and one to do the matrix product. Let's write</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1540" target="_blank">00:25:40.920</a></span> | <span class="t">that in fill shared to the dot products from shared. OK. So we need to go through all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1556" target="_blank">00:25:56.760</a></span> | <span class="t">our threads find out what row and column we're in. So how do we find out what row and column</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1563" target="_blank">00:26:03.120</a></span> | <span class="t">we're in. And again these are the things that get complicated. So this is our as we've already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1567" target="_blank">00:26:07.440</a></span> | <span class="t">mentioned. So R is going to be equal to look there's two pieces of it. There's the IDX</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1573" target="_blank">00:26:13.560</a></span> | <span class="t">piece goes from here to here. And then there's also an additional piece which is from here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1578" target="_blank">00:26:18.760</a></span> | <span class="t">to here. What is that piece. Well that piece is simply the coordinates of this grid location</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1589" target="_blank">00:26:29.680</a></span> | <span class="t">within the tile. And so remember that we are looping through. So blocked in dot Y and blocked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1601" target="_blank">00:26:41.040</a></span> | <span class="t">into X is the size of the tile. Right. So that means that. All right. So we've got tile row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1610" target="_blank">00:26:50.320</a></span> | <span class="t">and tile column. And so that's what that is. So that's so therefore this here is tile row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1620" target="_blank">00:27:00.320</a></span> | <span class="t">and this here is tile column. And so therefore to find R we have to add together IDX plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1627" target="_blank">00:27:07.800</a></span> | <span class="t">TR. And here it is IDX plus TR. And that needs to be less than the second dimension of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1639" target="_blank">00:27:19.640</a></span> | <span class="t">matrix. And then here we just need to index into it. So if this was a two dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1651" target="_blank">00:27:31.560</a></span> | <span class="t">tensor we could just do TR comma TC but it's not it's one dimensional so we have to flatten</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1658" target="_blank">00:27:38.600</a></span> | <span class="t">out our dimensions so it becomes TR times TW plus TC. So this is filling in our M shared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1668" target="_blank">00:27:48.600</a></span> | <span class="t">and N shared by going through all the possible elements of the tile and filling them all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1673" target="_blank">00:27:53.600</a></span> | <span class="t">in. Okay. So after this bunch of loops is complete MS and NS will simply contain a copy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1687" target="_blank">00:28:07.280</a></span> | <span class="t">of the appropriate tile from M and N. And again here the indexing we're doing is so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1693" target="_blank">00:28:13.640</a></span> | <span class="t">this remember is the kind of element that we're up to in terms of the column. And this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1699" target="_blank">00:28:19.680</a></span> | <span class="t">is the row that we're doing but we have to do times C times K in order to deal with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1705" target="_blank">00:28:25.480</a></span> | <span class="t">fact that we've flattened out our indexes. If one thing to think about that you might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1712" target="_blank">00:28:32.080</a></span> | <span class="t">have been wondering is what about this this final tile that goes off the edge. So it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1722" target="_blank">00:28:42.120</a></span> | <span class="t">not big enough. So what happens there. So for that final tile we put in zeros. So we call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1729" target="_blank">00:28:49.960</a></span> | <span class="t">that padding. And so they show that in the book here. So in this case they're doing a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1739" target="_blank">00:28:59.120</a></span> | <span class="t">four by four matrix multiplication containing two by two grids. And you can see here when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1746" target="_blank">00:29:06.520</a></span> | <span class="t">we're doing this one we've actually sorry it's a three by three using a two by two grid.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1752" target="_blank">00:29:12.200</a></span> | <span class="t">So we get to this piece here it goes off the edge. So what happens when we go off the edge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1760" target="_blank">00:29:20.560</a></span> | <span class="t">we just put zeros in to the shared memory. And so that means then when we do the dot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1766" target="_blank">00:29:26.440</a></span> | <span class="t">product between this one here containing zeros and this one here containing zeros then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1772" target="_blank">00:29:32.640</a></span> | <span class="t">zeros can just be ignored. They don't they don't do anything because they're just zeros.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1780" target="_blank">00:29:40.600</a></span> | <span class="t">So that's why we put zeros in if we are outside the dimensions of the matrix for both m and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1788" target="_blank">00:29:48.720</a></span> | <span class="t">n. So now that has filled in our shared memory or our pretend shared memory. I mean it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1795" target="_blank">00:29:55.800</a></span> | <span class="t">shared memory it's just not any faster because we're just in Python. And so now we've done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1800" target="_blank">00:30:00.080</a></span> | <span class="t">that we can go through all the threads again and find out what row and column we're in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1804" target="_blank">00:30:04.160</a></span> | <span class="t">using exactly the same code. And then we can go through our tile width and aggregate all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1814" target="_blank">00:30:14.240</a></span> | <span class="t">of the bits of our dot product. So why are we aggregating through tile width because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1821" target="_blank">00:30:21.500</a></span> | <span class="t">the dot product will always be between tile width on this side and tile width on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1828" target="_blank">00:30:28.920</a></span> | <span class="t">side. So every one every row from here and every column from here will be of size TW.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1837" target="_blank">00:30:37.180</a></span> | <span class="t">So that's why we do that. Okay so okay so that's that rather messy tiled matrix modification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1849" target="_blank">00:30:49.680</a></span> | <span class="t">in Python. So then I but like this is the place to start. So if you don't understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1853" target="_blank">00:30:53.240</a></span> | <span class="t">anything come back to here because you can run it through in the debugger. You can print</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1856" target="_blank">00:30:56.320</a></span> | <span class="t">out what the shared memory looks like. You know you can make sure you understand exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1861" target="_blank">00:31:01.840</a></span> | <span class="t">what's going on because it's plain Python. And so then all I've I did is I basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1865" target="_blank">00:31:05.640</a></span> | <span class="t">said okay well effectively that is saying oh run this bit of code as all the threads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1873" target="_blank">00:31:13.360</a></span> | <span class="t">and then run this bit of code as all the threads. So just to refactor this a little bit I created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1879" target="_blank">00:31:19.480</a></span> | <span class="t">a run threads function that just says okay look through all the threads and call some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1886" target="_blank">00:31:26.640</a></span> | <span class="t">function. And so using this approach so with this function available we can now change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1894" target="_blank">00:31:34.240</a></span> | <span class="t">our loop so that instead of having to do this big for loop we can just say run this function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1904" target="_blank">00:31:44.680</a></span> | <span class="t">in every thread and run this function in every thread. And so then those functions just contain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1913" target="_blank">00:31:53.080</a></span> | <span class="t">the two pieces. So this is now going to get a bit closer to what the CUDA code is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1916" target="_blank">00:31:56.920</a></span> | <span class="t">to look like. The CUDA code is going to have something that says go through each tile and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1923" target="_blank">00:32:03.000</a></span> | <span class="t">then fill the shared using all the threads and then do the dot product using all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1928" target="_blank">00:32:08.640</a></span> | <span class="t">threads. Okay so this is identical to the last one we've just refactored out the loops. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1936" target="_blank">00:32:16.480</a></span> | <span class="t">it's going to get a little bit closer to what the final CUDA code will look like. The thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1939" target="_blank">00:32:19.960</a></span> | <span class="t">that calls it is identical and of course therefore the result's the same. Are there any questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1950" target="_blank">00:32:30.320</a></span> | <span class="t">so far? I think he asked about the relationship between blocks in CUDA and the tile size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1959" target="_blank">00:32:39.680</a></span> | <span class="t">Sure yeah so in CUDA a block is a as we learned in the last one of these lectures a block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1974" target="_blank">00:32:54.640</a></span> | <span class="t">is and is just a kind of a conceptual thing that the CUDA programming model provides. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1982" target="_blank">00:33:02.480</a></span> | <span class="t">just a bunch of numbers basically that are passed to your function as block IDX. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1992" target="_blank">00:33:12.640</a></span> | <span class="t">you know that all of the threads in a block will be running on the same SM on the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=1996" target="_blank">00:33:16.920</a></span> | <span class="t">streaming multiprocessor. What you do with that information is entirely up to you and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2004" target="_blank">00:33:24.000</a></span> | <span class="t">last time we did nothing with that information. This time we're going to we're taking advantage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2011" target="_blank">00:33:31.000</a></span> | <span class="t">of it to say like okay well everything in a block has access to the same shared memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2017" target="_blank">00:33:37.660</a></span> | <span class="t">So we decided that we will treat a block as something that is calculating one particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2025" target="_blank">00:33:45.120</a></span> | <span class="t">part of our output a tile. So that's what we called it we just called it a tile. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2031" target="_blank">00:33:51.920</a></span> | <span class="t">a tile is just a is a semantic thing that we're using. And by mapping that semantic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2038" target="_blank">00:33:58.560</a></span> | <span class="t">idea of a tile to the CUDA programming models idea of a block and basically saying okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2044" target="_blank">00:34:04.560</a></span> | <span class="t">we're going to treat each block as a tile. It's going to allow us to use one block to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2049" target="_blank">00:34:09.520</a></span> | <span class="t">calculate one tile in our output. And so therefore we're going to have one sort of shared memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2057" target="_blank">00:34:17.760</a></span> | <span class="t">for each block which we're mapping to each tile in our output. So you can kind of think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2062" target="_blank">00:34:22.000</a></span> | <span class="t">of them as being the same thing. But they're kind of conceptually different. Okay so now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2076" target="_blank">00:34:36.280</a></span> | <span class="t">we're going to make it even more CUDA like because actually CUDA code does not have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2081" target="_blank">00:34:41.400</a></span> | <span class="t">thing called run threads. It doesn't look like this. Instead in CUDA code there is no loop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2091" target="_blank">00:34:51.760</a></span> | <span class="t">like this. But instead all of these functions across all of these possible I0 and I1 coordinates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2098" target="_blank">00:34:58.160</a></span> | <span class="t">are run at the same time. I mean not necessarily the same time but they can be the same. They</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2103" target="_blank">00:35:03.000</a></span> | <span class="t">can all be the same time or some subset of the same time. Conceptually for the programming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2107" target="_blank">00:35:07.760</a></span> | <span class="t">model you think of them as all running at the same time. To do that in Python we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2114" target="_blank">00:35:14.240</a></span> | <span class="t">to use threads. Now in real life Python threads don't actually all run at the same time except</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2123" target="_blank">00:35:23.200</a></span> | <span class="t">in certain situations at least with the current version of Python because there's a thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2127" target="_blank">00:35:27.200</a></span> | <span class="t">called the global interpreter lock. They actually run one after the other. But again for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2132" target="_blank">00:35:32.240</a></span> | <span class="t">programming model we can ignore that. So we're just going to pretend that they actually are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2137" target="_blank">00:35:37.600</a></span> | <span class="t">in parallel. So to create threads we use Python's threading library. It has a thread class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2147" target="_blank">00:35:47.120</a></span> | <span class="t">And so let me show you a couple of interesting things here. I've got a function here called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2153" target="_blank">00:35:53.720</a></span> | <span class="t">g that just prints whatever you pass it and it prints the negative of whatever you pass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2158" target="_blank">00:35:58.960</a></span> | <span class="t">it and it prints whatever you pass it times 10. I'm going to call g using a bunch of threads.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2169" target="_blank">00:36:09.920</a></span> | <span class="t">One convenient way to create and run a bunch of threads is with a thread pool executor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2174" target="_blank">00:36:14.760</a></span> | <span class="t">This is going to create three threads and run them at the same time or as much as that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2180" target="_blank">00:36:20.800</a></span> | <span class="t">this Python can handle. And so that thread pool dot map basically will run all the numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2189" target="_blank">00:36:29.160</a></span> | <span class="t">from one up to num and call our function g. So it'll call this three times. So if I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2201" target="_blank">00:36:41.720</a></span> | <span class="t">comment out these mysterious lines of code you can see what it does is it runs all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2210" target="_blank">00:36:50.680</a></span> | <span class="t">them for the first thread and then all of them for the second thread and then all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2216" target="_blank">00:36:56.480</a></span> | <span class="t">them for the third thread. This is not going to work for us because we want all of our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2224" target="_blank">00:37:04.720</a></span> | <span class="t">threads to first complete the task of fill in shared memory and then all of them to complete</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2229" target="_blank">00:37:09.920</a></span> | <span class="t">the task of doing the dot product. So we need to have a way to tell a thread to stop until</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2238" target="_blank">00:37:18.340</a></span> | <span class="t">all of the threads are up to this point and in Python that thing is called a barrier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2244" target="_blank">00:37:24.680</a></span> | <span class="t">And so we can create a barrier like so and we can say create a barrier so that until</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2251" target="_blank">00:37:31.200</a></span> | <span class="t">three threads have hit that barrier stop. So that's what and so then we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2256" target="_blank">00:37:36.200</a></span> | <span class="t">pass that in this sink barrier SBSinkBarrier. And so it's going to pause at the sink barrier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2262" target="_blank">00:37:42.160</a></span> | <span class="t">until all the threads are here and then pause at this sink barrier until all the threads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2267" target="_blank">00:37:47.880</a></span> | <span class="t">are here. And now if you run it you can see they all complete the first task and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2276" target="_blank">00:37:56.320</a></span> | <span class="t">they all complete the second task and then they all complete the third task. And you'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2281" target="_blank">00:38:01.020</a></span> | <span class="t">see they don't necessarily do it in the same order because threads can you know happen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2285" target="_blank">00:38:05.880</a></span> | <span class="t">in any order. And so this is the trick which is going to allow us to have a single loop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2292" target="_blank">00:38:12.280</a></span> | <span class="t">which everything in that loop first does the shared memory filling in task and then does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2297" target="_blank">00:38:17.940</a></span> | <span class="t">the dot product task. So here is our new kernel runner as before it goes through each block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2309" target="_blank">00:38:29.720</a></span> | <span class="t">as before it creates our shared memory and it's now going to create a synchronization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2315" target="_blank">00:38:35.320</a></span> | <span class="t">barrier containing the number of threads. So threads per block Y times threads per block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2322" target="_blank">00:38:42.040</a></span> | <span class="t">X is how many threads there will be. And then we're going to create a whole bunch of threads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2327" target="_blank">00:38:47.920</a></span> | <span class="t">one for every Y and one for every X. If you haven't seen this before in Python if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2334" target="_blank">00:38:54.480</a></span> | <span class="t">have two things in a list comprehension it just does the Cartesian product of those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2339" target="_blank">00:38:59.360</a></span> | <span class="t">So go through every anything in Y and everything in X and so O and P will be our two coordinates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2347" target="_blank">00:39:07.520</a></span> | <span class="t">So create a new thread the function that it's going to call is whatever function you asked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2351" target="_blank">00:39:11.640</a></span> | <span class="t">for and the arguments are going to be the coordinates of the block the coordinates of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2359" target="_blank">00:39:19.360</a></span> | <span class="t">the thread. And then we'll say how many threads per block pass in the shared memory pass in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2365" target="_blank">00:39:25.680</a></span> | <span class="t">the synchronization barrier and any arguments you requested. And so now this looks like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2373" target="_blank">00:39:33.680</a></span> | <span class="t">actually as you'll see like CUDA code we can figure out what our row and column is using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2383" target="_blank">00:39:43.760</a></span> | <span class="t">exactly the approach we saw before although now our row and column are actually going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2393" target="_blank">00:39:53.000</a></span> | <span class="t">to be based on block IDX and block DIM because this is actually telling us whereabouts we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2405" target="_blank">00:40:05.920</a></span> | <span class="t">are. The shared memory is exactly the same as before and so again we loop through all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2413" target="_blank">00:40:13.200</a></span> | <span class="t">of our tiles and again we set the shared memory just like before. But you'll notice now we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2421" target="_blank">00:40:21.640</a></span> | <span class="t">don't need two separate loops we just do the set the shared memory piece and then we say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2427" target="_blank">00:40:27.640</a></span> | <span class="t">wait for the synchronization barrier. So remember that this is happening for every this is happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2438" target="_blank">00:40:38.480</a></span> | <span class="t">for every output value in the tile simultaneously. At least as far as the programming model is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2444" target="_blank">00:40:44.200</a></span> | <span class="t">concerned it's simultaneously in fact in Python it doesn't do a good job of actually paralyzing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2448" target="_blank">00:40:48.660</a></span> | <span class="t">it and in CUDA we don't know for sure if they're happening exactly the same time but as far</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2453" target="_blank">00:40:53.760</a></span> | <span class="t">as the programming model is concerned we should think of them as happening at the same time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2458" target="_blank">00:40:58.080</a></span> | <span class="t">So all of these different coordinates are running conceptually at the same time. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2465" target="_blank">00:41:05.240</a></span> | <span class="t">so when we hit wait here that means that all of the threads have finished running those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2471" target="_blank">00:41:11.720</a></span> | <span class="t">two lines of code. And so now we know that MS and NS are filled in for that tile. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2477" target="_blank">00:41:17.520</a></span> | <span class="t">so now we can go ahead and do the dot product. And then once every thread has done its own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2487" target="_blank">00:41:27.080</a></span> | <span class="t">dot product we then need to stop and wait until they're all done. And then once they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2494" target="_blank">00:41:34.680</a></span> | <span class="t">are all done we can go ahead and fill in the next tile shared memory. This is very important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2499" target="_blank">00:41:39.840</a></span> | <span class="t">to have this wait here because if this wait wasn't here then some of them will still be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2505" target="_blank">00:41:45.000</a></span> | <span class="t">going ahead and doing the dot product and others will be replacing the shared memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2509" target="_blank">00:41:49.760</a></span> | <span class="t">and that was going to give you wrong answers. So you have to wait after you've completed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2514" target="_blank">00:41:54.560</a></span> | <span class="t">the shared memory filling in and you have to wait after you've completed doing the dot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2518" target="_blank">00:41:58.640</a></span> | <span class="t">product. Okay this code's identical to before. And again it's giving us the same answer so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2529" target="_blank">00:42:09.080</a></span> | <span class="t">that is a good sign. So here's the cool thing. I then took this code and I passed it into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2536" target="_blank">00:42:16.480</a></span> | <span class="t">chatgpt and I said convert the following Python code to CUDA C and I pointed out that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2543" target="_blank">00:42:23.480</a></span> | <span class="t">can remove these from the argument list. So we don't need those in the argument list.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2548" target="_blank">00:42:28.720</a></span> | <span class="t">I mean obviously you can manually remove this but I just thought if I have one prompt that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2551" target="_blank">00:42:31.640</a></span> | <span class="t">always works I don't have to do anything manually. I said change sync_b.wait to sync_threads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2558" target="_blank">00:42:38.080</a></span> | <span class="t">and I said for creating shared. So we'll talk about all this in a moment. So basically told</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2562" target="_blank">00:42:42.800</a></span> | <span class="t">it about the minor things it would have to change to convert the Python into CUDA C.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2569" target="_blank">00:42:49.680</a></span> | <span class="t">And the thing it gave me worked first time. Although I did do some minor cleanups. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2576" target="_blank">00:42:56.800</a></span> | <span class="t">this is the code it created after my minor cleanups. So you'll see now it's getting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2583" target="_blank">00:43:03.440</a></span> | <span class="t">so it's converted the, it recognises that we need float arrays for our input and output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2590" target="_blank">00:43:10.040</a></span> | <span class="t">matrices. It's typed all of those things correctly. And so in my cleanup I added a few things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2600" target="_blank">00:43:20.600</a></span> | <span class="t">So I've got now the tile column is thread_idx.x, the tile row, thread_idx.y, and then we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2610" target="_blank">00:43:30.400</a></span> | <span class="t">got r and c just like before. Now CUDA the way it does shared memory is a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2616" target="_blank">00:43:36.640</a></span> | <span class="t">weird. It doesn't get passed in just like thread_idx and block_idx don't get passed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2622" target="_blank">00:43:42.080</a></span> | <span class="t">in. You just have to put this magic incantation in exactly one line of code in your, in your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2628" target="_blank">00:43:48.560</a></span> | <span class="t">kernel. And so here it is. Here's this one line of code. And then following that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2633" target="_blank">00:43:53.680</a></span> | <span class="t">say what data type you want your shared memory to be. And then you say what you want to call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2637" target="_blank">00:43:57.800</a></span> | <span class="t">it and that's an array. So this is created something called ms, which is the pointer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2644" target="_blank">00:44:04.880</a></span> | <span class="t">to the start of the shared memory that CUDA is going to create. So that's what externed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2648" target="_blank">00:44:08.760</a></span> | <span class="t">under shared means. So ms is a pointer to the start of the shared memory. We need ns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2656" target="_blank">00:44:16.320</a></span> | <span class="t">to be a pointer to the start of the second half of the shared memory. So go in tile_width</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2661" target="_blank">00:44:21.800</a></span> | <span class="t">times tile_width because that will finish off the m part of the shared memory. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2669" target="_blank">00:44:29.800</a></span> | <span class="t">tile width by tile width. And the second half is the n part, just tile width by tile width.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2674" target="_blank">00:44:34.240</a></span> | <span class="t">So remember we did this in the Python version as well. So if any of this is confusing, go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2678" target="_blank">00:44:38.000</a></span> | <span class="t">back to the Python version and step through it in a debugger. So now we've got ms and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2683" target="_blank">00:44:43.440</a></span> | <span class="t">ns as our shared memory. And then this is exactly the same as the Python version. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2690" target="_blank">00:44:50.920</a></span> | <span class="t">we've now got this sync_threads. So sync_threads is identical to the sync_b.wait. It says wait</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2711" target="_blank">00:45:11.180</a></span> | <span class="t">until all of the threads are finished doing the previous lines of code before any of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2717" target="_blank">00:45:17.560</a></span> | <span class="t">are allowed to do the next one. Because this stuff's built into CUDA, we don't have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2723" target="_blank">00:45:23.200</a></span> | <span class="t">create a sync_barrier object and pass it in and all that. You just have this magic line</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2728" target="_blank">00:45:28.660</a></span> | <span class="t">of code. So there's quite a bit of magic in CUDA, like this externed_shared and this_sink_threads.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2736" target="_blank">00:45:36.520</a></span> | <span class="t">But there's not too many pieces. And you can see we're basically using them all here. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2743" target="_blank">00:45:43.800</a></span> | <span class="t">the next part is then to call the kernel. And so when we call the kernel, we've got the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2751" target="_blank">00:45:51.400</a></span> | <span class="t">normal triple angle brackets, blocks, threads per block, and then we pass in one third argument</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2756" target="_blank">00:45:56.480</a></span> | <span class="t">to the triple angle brackets, which is how much shared memory do you want to create.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2761" target="_blank">00:46:01.360</a></span> | <span class="t">And so that is what's going to be used automatically when it creates this shared memory that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2766" target="_blank">00:46:06.120</a></span> | <span class="t">get a pointer to here. That's how much shared memory it will create. How much shared memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2771" target="_blank">00:46:11.680</a></span> | <span class="t">should you create? Well, in this case, I've commented out this section, so ignore that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2776" target="_blank">00:46:16.400</a></span> | <span class="t">for a moment. For now, we're just going to do the same thing. We're just going to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2780" target="_blank">00:46:20.640</a></span> | <span class="t">the tile_width 16. So the amount of shared memory we need in bytes is tile_width times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2785" target="_blank">00:46:25.920</a></span> | <span class="t">tile_width for m times 2 for n as well, times size of float, because we don't want bytes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2792" target="_blank">00:46:32.720</a></span> | <span class="t">we want floats. So that's the amount of bytes of shared memory we need. And that's what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2797" target="_blank">00:46:37.560</a></span> | <span class="t">we pass in. Okay. So that's basically that. And so we can then run that. And we can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2811" target="_blank">00:46:51.520</a></span> | <span class="t">that we get the same result, which is good. One thing, though, which is a bit of a worry,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2820" target="_blank">00:47:00.360</a></span> | <span class="t">is that our time is actually slightly worse. It's gone from 6 milliseconds to 6.5 milliseconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2826" target="_blank">00:47:06.920</a></span> | <span class="t">So we'll talk about that in a moment. I just want to mention one other thing that is in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2830" target="_blank">00:47:10.360</a></span> | <span class="t">the book, they say, okay, for your size, you should write some function to calculate what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2837" target="_blank">00:47:17.640</a></span> | <span class="t">size it should be. But they never say how to do that. And so in future lectures, we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2842" target="_blank">00:47:22.680</a></span> | <span class="t">be talking about how to think about things like this and how to design this correctly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2849" target="_blank">00:47:29.820</a></span> | <span class="t">But in this commented out section here, you can see the basic idea. So this will work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2853" target="_blank">00:47:33.860</a></span> | <span class="t">if you run it, even though it's not necessarily optimized. So you can call this special function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2860" target="_blank">00:47:40.460</a></span> | <span class="t">CUDA, get device properties, passing in a structure to fill in. So and means a pointer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2867" target="_blank">00:47:47.480</a></span> | <span class="t">to that. That's like a reference to the structure to fill in. And I think this is the device</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2872" target="_blank">00:47:52.680</a></span> | <span class="t">number, if I remember correctly. And it will return back a structure containing a number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2876" target="_blank">00:47:56.480</a></span> | <span class="t">of things, including max threads per block. So and it will also give you shared memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2884" target="_blank">00:48:04.480</a></span> | <span class="t">per block. So you can use that to dynamically figure out threads per block and to dynamically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2893" target="_blank">00:48:13.880</a></span> | <span class="t">figure out your tile width and stuff like that. I'm not saying this is an optimized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2898" target="_blank">00:48:18.960</a></span> | <span class="t">way to do any of those things. It's just an indicative kind of showing you how you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2903" target="_blank">00:48:23.360</a></span> | <span class="t">get all the pieces you can need to calculate that. And so in later lectures, we will learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2908" target="_blank">00:48:28.840</a></span> | <span class="t">more about how to actually figure out what would be the optimal tile width and shared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2915" target="_blank">00:48:35.240</a></span> | <span class="t">memory size and so forth. But for now, I'm just using 16. Okay, so this is the mystery</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2921" target="_blank">00:48:41.680</a></span> | <span class="t">part. The mystery part is this is slower, as we saw. But if I take the exact same code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2931" target="_blank">00:48:51.560</a></span> | <span class="t">instead I use this thing where we tell it what size to create is called dynamic shared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2937" target="_blank">00:48:57.100</a></span> | <span class="t">memory allocation. If we don't use dynamic shared memory allocation, then we do that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2944" target="_blank">00:49:04.840</a></span> | <span class="t">by not passing in the shared memory size here. But instead, if we know at compile time how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2952" target="_blank">00:49:12.360</a></span> | <span class="t">big we want our tiles to be, so we can try I've tried both 32 or 16, you can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2958" target="_blank">00:49:18.360</a></span> | <span class="t">create an MS of TW by TW and an NS of TW by TW. So you can have two separate things and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2968" target="_blank">00:49:28.080</a></span> | <span class="t">because we know we're deciding at compile time what our tile width is, then this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2973" target="_blank">00:49:33.420</a></span> | <span class="t">not dynamically created. The rest of the code is the same, except now we've got proper kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2979" target="_blank">00:49:39.040</a></span> | <span class="t">of two-dimensional indexing, which is nice. And with this one, this is faster. So we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2988" target="_blank">00:49:48.040</a></span> | <span class="t">gone down from 6 to 5. And I think if I remember correctly, when I tried 16 tile width, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=2996" target="_blank">00:49:56.960</a></span> | <span class="t">a bit faster too, it's more like 4. We'll have that running in the background. 16. Okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3007" target="_blank">00:50:07.480</a></span> | <span class="t">let's recompile that. Okay, any more questions before I move on?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3021" target="_blank">00:50:21.800</a></span> | <span class="t">So we have to the shared memory, we need to be able to store the tile for M and the tile</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3039" target="_blank">00:50:39.400</a></span> | <span class="t">for N. So each one of those is TW by TW. And so therefore we need two times TW by TW in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3047" target="_blank">00:50:47.400</a></span> | <span class="t">order to have enough room for both of those two input tiles. And then we use it here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3059" target="_blank">00:50:59.000</a></span> | <span class="t">We've got a pointer to the start of M, we've got a pointer to the start of N. We also saw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3063" target="_blank">00:51:03.800</a></span> | <span class="t">it in the Python version, the shared memory size we passed in. TW times TW times 2, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3082" target="_blank">00:51:22.320</a></span> | <span class="t">we needed the MS, M's shared memory tile and N's shared memory tile. Okay, thank you for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3092" target="_blank">00:51:32.960</a></span> | <span class="t">the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3093" target="_blank">00:51:33.960</a></span> | <span class="t">Do you find some documentation or some reference why the dynamic shared memory version is supposed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3106" target="_blank">00:51:46.080</a></span> | <span class="t">to be this way? I'm a little bit surprised that it's...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3110" target="_blank">00:51:50.200</a></span> | <span class="t">No, it's a total mystery to me. So maybe there's something wrong with my code. I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3118" target="_blank">00:51:58.060</a></span> | <span class="t">So this is something I think we should try to follow up on and maybe some of our friends</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3122" target="_blank">00:52:02.240</a></span> | <span class="t">at Nvidia can tell me the dumb thing I did because, you know, I'm a newbie to all this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3126" target="_blank">00:52:06.560</a></span> | <span class="t">stuff, so I probably did something stupid. But yeah, I've looked around, I've read around,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3132" target="_blank">00:52:12.080</a></span> | <span class="t">I've searched, I've asked chat GPT, nothing so far has told me. I've found some other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3136" target="_blank">00:52:16.500</a></span> | <span class="t">people who have said the same thing on the internet saying like, "Oh, why is my dynamic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3141" target="_blank">00:52:21.240</a></span> | <span class="t">and static having different speeds?" I haven't found answers to any of those either. So yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3146" target="_blank">00:52:26.160</a></span> | <span class="t">this one's a... The theory is that it definitely should not be solid. They should be identical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3151" target="_blank">00:52:31.920</a></span> | <span class="t">They should create exactly the same PTX code. So yeah, my guess is maybe I've made a mistake</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3158" target="_blank">00:52:38.640</a></span> | <span class="t">in my code somewhere. So I will... If anybody figures this out, I will update the YouTube</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3163" target="_blank">00:52:43.600</a></span> | <span class="t">description to say what the answer turned out to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3168" target="_blank">00:52:48.240</a></span> | <span class="t">Oh, hi there. Jeremy here with a message from the future. I figured out why that code was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3179" target="_blank">00:52:59.080</a></span> | <span class="t">going slowly. And the reason is because of this tiny little bit here. The problem is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3188" target="_blank">00:53:08.440</a></span> | <span class="t">that when TW, the tile width, is not known at compile time, it turns out that CUDA does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3196" target="_blank">00:53:16.320</a></span> | <span class="t">not know how to create an optimized piece of code for a range of tile widths. So it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3204" target="_blank">00:53:24.320</a></span> | <span class="t">falls back to the slowest possible version. I found a somewhat better solution than just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3212" target="_blank">00:53:32.000</a></span> | <span class="t">supporting one constant tile width which is... You can skip over this if you're not interested.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3219" target="_blank">00:53:39.040</a></span> | <span class="t">It's a bit more advanced, but basically you can use a C++ template and you can make tile</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3225" target="_blank">00:53:45.200</a></span> | <span class="t">width a template parameter instead of a normal parameter. When you do this, now you can only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3231" target="_blank">00:53:51.640</a></span> | <span class="t">call it with a constant tile width, which is a bit ugly, but you can actually deal with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3237" target="_blank">00:53:57.000</a></span> | <span class="t">that by basically supporting some fixed number of tile widths and it will compile a separate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3242" target="_blank">00:54:02.560</a></span> | <span class="t">version of the kernel for each one. So I've got it here doing eight and a 16 and a 32.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3249" target="_blank">00:54:09.240</a></span> | <span class="t">So you could have something... So here I've just got tile width equals 16, but it's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3252" target="_blank">00:54:12.840</a></span> | <span class="t">variable to kind of show it's possible and you could replace that with some code that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3256" target="_blank">00:54:16.440</a></span> | <span class="t">calculates dynamically whether you want to make it eight or 16 or 32, or you could do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3260" target="_blank">00:54:20.340</a></span> | <span class="t">additional ones as well. And then there's a lambda. This is how C++ very ugly does lambdas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3268" target="_blank">00:54:28.640</a></span> | <span class="t">Looks quite different to Python lambdas as you can see, but basically this is a lambda</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3272" target="_blank">00:54:32.960</a></span> | <span class="t">now which we'll take. So this is the function that we're going to call and we'll call that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3279" target="_blank">00:54:39.240</a></span> | <span class="t">function using some particular kernel. This is the kernel function, kf is the kernel function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3285" target="_blank">00:54:45.320</a></span> | <span class="t">Anyway, so lots of messiness there. It's pretty hideous code. And I guess this is where it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3293" target="_blank">00:54:53.080</a></span> | <span class="t">gets pretty complicated when you actually want to have optimized kernels for a range</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3299" target="_blank">00:54:59.120</a></span> | <span class="t">of different hardware. The good news is that at the moment at least any even reasonably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3308" target="_blank">00:55:08.080</a></span> | <span class="t">modern Nvidia GPU supports exactly the same amount of shared memory. So maybe all this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3315" target="_blank">00:55:15.560</a></span> | <span class="t">dynamic stuff isn't that necessary. Although having said that I do think that you do need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3320" target="_blank">00:55:20.320</a></span> | <span class="t">to change the tile width depending on the matrix size or the size of the matrices that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3324" target="_blank">00:55:24.960</a></span> | <span class="t">you're using. So yeah, I do think this is actually reasonably complicated to make it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3333" target="_blank">00:55:33.160</a></span> | <span class="t">work well in lots of different situations. And I guess this is why there's a whole team</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3336" target="_blank">00:55:36.880</a></span> | <span class="t">of people at Nvidia who work on doing this in Kublai and Gudian and so we don't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3344" target="_blank">00:55:44.360</a></span> | <span class="t">to worry about it. Anyway, I'm glad I got it figured out and I will now return you back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3351" target="_blank">00:55:51.240</a></span> | <span class="t">to our scheduled programming. All right. So now I've got something really exciting to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3357" target="_blank">00:55:57.440</a></span> | <span class="t">show which is that we can do everything that we've just seen in a different library called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3368" target="_blank">00:56:08.240</a></span> | <span class="t">number. Number is another way of writing CUDA code. It's a way of writing CUDA code where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3376" target="_blank">00:56:16.000</a></span> | <span class="t">you actually write the CUDA code in Python. Here is the CUDA code for our call. I haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3391" target="_blank">00:56:31.560</a></span> | <span class="t">tried this before but we can actually see how long this takes to run. Okay. That's interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3399" target="_blank">00:56:39.240</a></span> | <span class="t">So this one is slower still. So again, maybe I'm doing something weird. This is using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3408" target="_blank">00:56:48.840</a></span> | <span class="t">dynamic shared memory approach. I've got two times tile width, times tile width, times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3415" target="_blank">00:56:55.240</a></span> | <span class="t">-- I just manually put four which is how many bytes an hour in a float. But still it's running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3421" target="_blank">00:57:01.320</a></span> | <span class="t">at CUDA speeds which is good even if it's not the full speed we were getting from CUDA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3429" target="_blank">00:57:09.200</a></span> | <span class="t">Now why would you do this? Because actually if you look at the amount of code I have here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3435" target="_blank">00:57:15.240</a></span> | <span class="t">it's not less code than the amount that I had here. So it's not like -- it's not easier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3444" target="_blank">00:57:24.840</a></span> | <span class="t">to write. I mean, so I've still got to use block IDX, block damn thread IDX. So all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3449" target="_blank">00:57:29.600</a></span> | <span class="t">are now available in the CUDA -- what would that be -- module, I guess. And they're kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3458" target="_blank">00:57:38.240</a></span> | <span class="t">of globals available here. We can create our shared array here because we say shared.array0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3466" target="_blank">00:57:46.200</a></span> | <span class="t">This is actually quite a new thing in number. It does the dynamic approach. So when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3471" target="_blank">00:57:51.120</a></span> | <span class="t">call the kernel rather than using triple angle brackets, you use square brackets, passing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3476" target="_blank">00:57:56.800</a></span> | <span class="t">in the blocks, threads per block, stream number which we haven't learned about yet, and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3481" target="_blank">00:58:01.280</a></span> | <span class="t">dynamic shared memory size. And so here is where it creates it with a dynamic shared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3485" target="_blank">00:58:05.760</a></span> | <span class="t">memory size. Tell it that you want them to be floats. And so now we can do the exact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3491" target="_blank">00:58:11.440</a></span> | <span class="t">same trick that we did before. Grabbing our MS and NS. Instead of underscore, underscore</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3497" target="_blank">00:58:17.520</a></span> | <span class="t">sync threads, it's CUDA.sync threads. So in some ways I'd say, like, okay, this is not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3504" target="_blank">00:58:24.560</a></span> | <span class="t">necessarily a big win. But there's a couple of things that do make it a big win. So one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3511" target="_blank">00:58:31.000</a></span> | <span class="t">I'll show you, for instance, is -- I mean, we could just do something pointless like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3517" target="_blank">00:58:37.040</a></span> | <span class="t">a times one here. There we go. So that should force it to recompile the kernel. Okay, run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3522" target="_blank">00:58:42.360</a></span> | <span class="t">There we go. Done. So it took less than a second to recompile the kernel. So for some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3527" target="_blank">00:58:47.040</a></span> | <span class="t">reason which I don't fully understand, compiling number kernels, CUDA kernels, is way faster</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3537" target="_blank">00:58:57.440</a></span> | <span class="t">than compiling C and C++ CUDA kernels. And I have asked an NVIDIA guy about this, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3545" target="_blank">00:59:05.600</a></span> | <span class="t">he was like, oh, well, it's just how it is. Sorry. It doesn't seem to be an obvious way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3549" target="_blank">00:59:09.520</a></span> | <span class="t">to make the C, C++ version faster. So I actually think this is great for doing development,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3557" target="_blank">00:59:17.320</a></span> | <span class="t">is I can, you know, have actual CUDA running and just change things and run it very fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3564" target="_blank">00:59:24.640</a></span> | <span class="t">So I think that's very handy. The second thing that's very handy is that I don't have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3568" target="_blank">00:59:28.800</a></span> | <span class="t">flatten my tensors. M and N here are being passed in -- actually, M and N. The only thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3576" target="_blank">00:59:36.200</a></span> | <span class="t">I've done to them is wrapped them with as CUDA array, which is a take zero time. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3582" target="_blank">00:59:42.340</a></span> | <span class="t">just changing the type, basically. So you don't have to flatten it. So I can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3588" target="_blank">00:59:48.520</a></span> | <span class="t">use proper indexing notation, which is convenient. That's another nice thing. I can do things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3596" target="_blank">00:59:56.340</a></span> | <span class="t">like dot shape, so I don't have to pass in the H, K, and W, which, again, is quite nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3603" target="_blank">01:00:03.040</a></span> | <span class="t">So there's some conveniences. But then I'm going to tell you the most amazingly cool</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3607" target="_blank">01:00:07.720</a></span> | <span class="t">thing, which is the Python thread thing we created back here that kind of simulates threads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3619" target="_blank">01:00:19.160</a></span> | <span class="t">and simulates CUDA in Python is fully built in to number. So everything that we kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3626" target="_blank">01:00:26.880</a></span> | <span class="t">recreated from scratch here actually already exists. And so in number, to use it, if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3634" target="_blank">01:00:34.280</a></span> | <span class="t">Google for number CUDA simulator, you'll see here that if you set the environment variable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3643" target="_blank">01:00:43.560</a></span> | <span class="t">number enable CUDA sim to one, then that enables the CUDA simulator. The code is executed as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3652" target="_blank">01:00:52.840</a></span> | <span class="t">normal, except that it's actually run on the CPU as pure Python code, just like ours was.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3662" target="_blank">01:01:02.720</a></span> | <span class="t">So you can, for example, set a break point or print stuff directly from Python. Now notice,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3674" target="_blank">01:01:14.140</a></span> | <span class="t">because this is not running CUDA, it's going to be slow. It's going to be exactly as slow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3678" target="_blank">01:01:18.580</a></span> | <span class="t">as our manual Python version, because this is just their Python, manual Python version,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3683" target="_blank">01:01:23.480</a></span> | <span class="t">or I think it's exactly as slow. So you still want to use much smaller subsets of your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3689" target="_blank">01:01:29.880</a></span> | <span class="t">But this is a great way to actually, in my opinion, to do real world CUDA development</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3697" target="_blank">01:01:37.320</a></span> | <span class="t">is do it in number. Do it all with number enable CUDA sim set to one with small amounts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3704" target="_blank">01:01:44.600</a></span> | <span class="t">of data until everything works. And you have to, by the way, you have to set that environment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3712" target="_blank">01:01:52.600</a></span> | <span class="t">variable before you import number, right? So you would have it before you import number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3719" target="_blank">01:01:59.880</a></span> | <span class="t">And if you're using a notebook, you'd have to reset the kernel, restart the kernel, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3725" target="_blank">01:02:05.080</a></span> | <span class="t">then change the environment variable and then reimport number. And then you can set it to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3729" target="_blank">01:02:09.040</a></span> | <span class="t">zero, and now the exact same code will now be running on the GPU. And then I've tested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3734" target="_blank">01:02:14.920</a></span> | <span class="t">this. If you then take your code and paste it into chat GPT and say, please convert this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3740" target="_blank">01:02:20.860</a></span> | <span class="t">into CUDA C code, for me, at least, it did it perfectly correctly first time. So I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3748" target="_blank">01:02:28.520</a></span> | <span class="t">this is a really useful way to kind of combine all the stuff we've learned about from first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3753" target="_blank">01:02:33.920</a></span> | <span class="t">principles. And we've done it all from scratch. And so we understand how it all works. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3758" target="_blank">01:02:38.120</a></span> | <span class="t">now to implement it in practice, maybe the easiest way to do that is actually to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3764" target="_blank">01:02:44.080</a></span> | <span class="t">number. Now, of course, you don't even need to convert it to C or C++. You could just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3769" target="_blank">01:02:49.600</a></span> | <span class="t">leave it in number. The challenge is from a deployment point of view, you know, it might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3775" target="_blank">01:02:55.280</a></span> | <span class="t">be a bit more tricky. With PyTorch, if you use our load inline, load CUDA approach, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3785" target="_blank">01:03:05.640</a></span> | <span class="t">documentation explains how you can precompile that and actually provide a pip or conda installable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3790" target="_blank">01:03:10.840</a></span> | <span class="t">package that people can just use right away without having any of the CUDA development</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3797" target="_blank">01:03:17.280</a></span> | <span class="t">toolkit installed. The number, that's not true. Having said that, if you do install number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3804" target="_blank">01:03:24.040</a></span> | <span class="t">from conda, it automatically installs all the stuff you need for the toolkit. So maybe that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3808" target="_blank">01:03:28.240</a></span> | <span class="t">okay. So anyway, these are some things like pros and cons to think about. So maybe you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3814" target="_blank">01:03:34.840</a></span> | <span class="t">just just use number as is. Maybe it's a little bit slower. So maybe that'll be a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3821" target="_blank">01:03:41.640</a></span> | <span class="t">Or maybe you auto-convert it to CUDA C and actually use that in practice. Yeah. So I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3831" target="_blank">01:03:51.000</a></span> | <span class="t">think that basically covers everything. Any more questions or anything anybody wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3838" target="_blank">01:03:58.320</a></span> | <span class="t">to add?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3839" target="_blank">01:03:59.320</a></span> | <span class="t">From my side, first of all, I must say, this was a super fantastic session. I learned a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3846" target="_blank">01:04:06.920</a></span> | <span class="t">lot. And I didn't expect that you would go so deep into the Metamol stuff. And also I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3852" target="_blank">01:04:12.560</a></span> | <span class="t">think this shows so many elements of the CUDA development. It's starting from having this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3859" target="_blank">01:04:19.040</a></span> | <span class="t">single character variables that you normally see. And it also maybe shocks people if they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3864" target="_blank">01:04:24.880</a></span> | <span class="t">see curves for the first time. It makes it a little bit inaccessible in the first class</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3870" target="_blank">01:04:30.920</a></span> | <span class="t">because you just see this variables in the class and multiply whatever. So magic happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3877" target="_blank">01:04:37.280</a></span> | <span class="t">That's what you showed this, like the starting from this drawing, all the memory, like basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3884" target="_blank">01:04:44.960</a></span> | <span class="t">the structures look like and what you need to do. And then reference back to this, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3889" target="_blank">01:04:49.960</a></span> | <span class="t">normally in the first approach, you already get something wrong. And looking back, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3896" target="_blank">01:04:56.360</a></span> | <span class="t">do the variables come from? This is why I'm full. And I also have mine, always, some pencil</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3903" target="_blank">01:05:03.800</a></span> | <span class="t">and paper beside me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3905" target="_blank">01:05:05.320</a></span> | <span class="t">Yes, marvelous. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3906" target="_blank">01:05:06.320</a></span> | <span class="t">Yeah. There are also a few things that stood out for me. I think if more people are interested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3911" target="_blank">01:05:11.320</a></span> | <span class="t">in a lot of ship number kernels, that's something we can certainly take a look at. As far as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3918" target="_blank">01:05:18.520</a></span> | <span class="t">I know, I think number did have an ahead-of-time compilation mode, which should make some stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3923" target="_blank">01:05:23.960</a></span> | <span class="t">easier. But because it's all sort of old Python, you can ship it. You just have to ease the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3929" target="_blank">01:05:29.440</a></span> | <span class="t">compilation cost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3930" target="_blank">01:05:30.440</a></span> | <span class="t">Yeah. The AOT ahead-of-time compilation is deprecated as of, what is this, February 2024.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3938" target="_blank">01:05:38.880</a></span> | <span class="t">They say they're going to replace it with something newer and better, but they haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3942" target="_blank">01:05:42.120</a></span> | <span class="t">said what that is yet. So that's currently an outstanding question. They did say they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3947" target="_blank">01:05:47.120</a></span> | <span class="t">won't remove the previous AOT approach until the new approach is working and everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3954" target="_blank">01:05:54.640</a></span> | <span class="t">So yeah, hopefully, by the time people watch this video on YouTube in the future, maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3960" target="_blank">01:06:00.160</a></span> | <span class="t">this will all be fully resolved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3961" target="_blank">01:06:01.640</a></span> | <span class="t">So we have a question here from Jonas, who wants to know if you have checked it out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3967" target="_blank">01:06:07.720</a></span> | <span class="t">how it compares to Q+ to the optimized tutor library, or maybe also to the PyTorch metrics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3975" target="_blank">01:06:15.440</a></span> | <span class="t">modification as a baseline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3977" target="_blank">01:06:17.840</a></span> | <span class="t">I haven't because I'm not a CUDA expert. I actually don't know how to optimize all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3985" target="_blank">01:06:25.480</a></span> | <span class="t">shared memory sizes and tiles and blah, blah, blah. So I know that stuff like Kuberless</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3993" target="_blank">01:06:33.080</a></span> | <span class="t">has a whole lot of-- so actually, one of the things you might have noticed is I changed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=3998" target="_blank">01:06:38.480</a></span> | <span class="t">my input matrix sizes from last time. Last time, I used the MNIST data and a kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4004" target="_blank">01:06:44.760</a></span> | <span class="t">a pretend set of weights for MNIST. And so the output was 50,000 by 10. And that really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4013" target="_blank">01:06:53.920</a></span> | <span class="t">kind of long, narrow matrix is particularly hard to optimize, because with a tile width</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4019" target="_blank">01:06:59.760</a></span> | <span class="t">of 32, for example, most of it's padding. So I actually used kind of a simpler-- not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4028" target="_blank">01:07:08.200</a></span> | <span class="t">your old shapes to make this a bit easier for me to think about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4032" target="_blank">01:07:12.500</a></span> | <span class="t">So I think it'll be a fun exercise as we go further to see if we can figure out for that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4039" target="_blank">01:07:19.440</a></span> | <span class="t">like a one layer MNIST model, can we create something that is close in performance to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4046" target="_blank">01:07:26.520</a></span> | <span class="t">what Q+ or QDNN does? Because yeah, I think it's kind of-- I found it quite tricky to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4055" target="_blank">01:07:35.040</a></span> | <span class="t">think about how I would do all that automatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4058" target="_blank">01:07:38.680</a></span> | <span class="t">There are things like TVM, which maybe one day we can look at TVM together. I know Thomas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4065" target="_blank">01:07:45.560</a></span> | <span class="t">Feynman says he's used that. Yeah, so maybe he can even help us there, which is something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4069" target="_blank">01:07:49.960</a></span> | <span class="t">which can kind of automatically optimize these and a lot more details for you. And then also,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4078" target="_blank">01:07:58.320</a></span> | <span class="t">I know sometime hopefully in the next month or so-- so sometime around late February or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4082" target="_blank">01:08:02.320</a></span> | <span class="t">March, 2024, Mojo GPU should be becoming available, at least in a preview form. And that has an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4089" target="_blank">01:08:09.000</a></span> | <span class="t">autotune functionality which might help us to automatically find the best parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4094" target="_blank">01:08:14.720</a></span> | <span class="t">as well. But yeah, for now, I didn't even bother checking because I suspected I was going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4099" target="_blank">01:08:19.840</a></span> | <span class="t">be quite embarrassed at how much further there is to go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4102" target="_blank">01:08:22.520</a></span> | <span class="t">Well, I think this is a super good opportunity for the community because you have this baggable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4111" target="_blank">01:08:31.360</a></span> | <span class="t">notebook which can be-- yes, everybody can fork it and play around with it and try out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4116" target="_blank">01:08:36.720</a></span> | <span class="t">different stuff, like make performance measurements and it will be-- I'm pretty sure that somebody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4122" target="_blank">01:08:42.680</a></span> | <span class="t">can make reports on things and experiment with it and maybe we can look at what we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4127" target="_blank">01:08:47.480</a></span> | <span class="t">found. So the current state isn't-- I think I'm closer to what state-of-the-art with this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4134" target="_blank">01:08:54.480</a></span> | <span class="t">metrics multiplication. And I think also the session today played the foundation for further</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4139" target="_blank">01:08:59.920</a></span> | <span class="t">stuff like special currents, technology from tensor cores, for example, from NVIDIA, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4149" target="_blank">01:09:09.200</a></span> | <span class="t">is specifically in the hardware, the further hardware features for sitting metrics multiplications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4158" target="_blank">01:09:18.000</a></span> | <span class="t">So thanks for keeping it in the future, maybe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4161" target="_blank">01:09:21.800</a></span> | <span class="t">Great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4164" target="_blank">01:09:24.800</a></span> | <span class="t">So for what's worth, I think getting something less competitive is probably going to be very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4170" target="_blank">01:09:30.400</a></span> | <span class="t">difficult, at least on basically the server's use of things like A100s. I suspect that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4177" target="_blank">01:09:37.600</a></span> | <span class="t">not as true for consumer-only use. So that's potentially like [INAUDIBLE] because it wants</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4184" target="_blank">01:09:44.400</a></span> | <span class="t">to be less attention from the video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4189" target="_blank">01:09:49.000</a></span> | <span class="t">Good point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4190" target="_blank">01:09:50.000</a></span> | <span class="t">So MikeG, Misa wants to know what is PyTorch currently using for metrics multiplications,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4194" target="_blank">01:09:54.000</a></span> | <span class="t">I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4195" target="_blank">01:09:55.000</a></span> | <span class="t">Do you know?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4196" target="_blank">01:09:56.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4197" target="_blank">01:09:57.000</a></span> | <span class="t">So some writers mostly still use as like a loss. There is like an experimental-- with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4204" target="_blank">01:10:04.000</a></span> | <span class="t">if you use PyTorch compile, there's a flag called torch.enductor.config. I think it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4213" target="_blank">01:10:13.600</a></span> | <span class="t">off by default. But, you know, it's something we're potentially interested in exploring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4219" target="_blank">01:10:19.400</a></span> | <span class="t">But I think as far as today, it's mostly still the loss. The way you can tell, by the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4224" target="_blank">01:10:24.200</a></span> | <span class="t">is if you launch the PyTorch profiler, the function names will have specific signatures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4231" target="_blank">01:10:31.600</a></span> | <span class="t">to sort of say, OK, it's using a loss, it's using test records. So like a profile trace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4237" target="_blank">01:10:37.000</a></span> | <span class="t">as well would be really different from what you're trying to think about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4241" target="_blank">01:10:41.000</a></span> | <span class="t">And Jeremy, what you said, I think, regarding this speed of compilation, for me personally,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4246" target="_blank">01:10:46.600</a></span> | <span class="t">this is super important in getting like, experimenting with things. I was trying to optimize for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4252" target="_blank">01:10:52.400</a></span> | <span class="t">this, and I think it's a big advantage if this is in-- well, it's really much faster</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4258" target="_blank">01:10:58.600</a></span> | <span class="t">and you're running and you succeed, and you're voicelessly waiting for the next result after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4264" target="_blank">01:11:04.600</a></span> | <span class="t">you get into the failures you went through. Exactly. Yeah, you need a quick iteration loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4271" target="_blank">01:11:11.440</a></span> | <span class="t">So I think between the CUDA simulator and the fast number CUDA JIT, it can make life</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4279" target="_blank">01:11:19.360</a></span> | <span class="t">a lot better. I think there were two more general questions regarding Chagipiti use. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4290" target="_blank">01:11:30.400</a></span> | <span class="t">one was whether Chagipiti could, because it was fusing much bit corners, or is this like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4298" target="_blank">01:11:38.920</a></span> | <span class="t">what the limits basically are for what Chagipiti can do, because I think it's take how to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4304" target="_blank">01:11:44.000</a></span> | <span class="t">that. And you have to try it. Let's try it. That'd be an interesting thing for people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4307" target="_blank">01:11:47.560</a></span> | <span class="t">to experiment with, wouldn't it? See how far we can go. I think, in general, people tend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4311" target="_blank">01:11:51.040</a></span> | <span class="t">to underestimate maybe what Chagipiti can do. So yeah, why don't you try some things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4318" target="_blank">01:11:58.240</a></span> | <span class="t">that maybe you suspect might be a bit too hard for it, and we'll find out where the limits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4321" target="_blank">01:12:01.320</a></span> | <span class="t">are. For example, this-- I put that prompt in-- well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4333" target="_blank">01:12:13.520</a></span> | <span class="t">so when I converted number into CUDA, it automatically changed the number shared memory. In my prompt,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4341" target="_blank">01:12:21.680</a></span> | <span class="t">I had something saying replace sync_b.wait with __sync_threads. I didn't try doing it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4350" target="_blank">01:12:30.040</a></span> | <span class="t">without it. Maybe it would have guessed. Personally, I haven't found it at all useful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4371" target="_blank">01:12:51.780</a></span> | <span class="t">for anything remotely novel. So I found it really useful for using languages I'm not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4385" target="_blank">01:13:05.640</a></span> | <span class="t">that familiar with, or frameworks I'm not that familiar with, and it gets me-- or calling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4390" target="_blank">01:13:10.920</a></span> | <span class="t">some API. I find it really good for that. But for doing anything at all algorithm-related,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4398" target="_blank">01:13:18.520</a></span> | <span class="t">which is anything other than just replicating a well-known algorithm, I've found it terrible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4404" target="_blank">01:13:24.160</a></span> | <span class="t">So at least the kind of work I do, which is kind of-- because it's research-oriented,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4409" target="_blank">01:13:29.200</a></span> | <span class="t">so most of what I write is pretty new, I haven't found it at all useful. So at least I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4417" target="_blank">01:13:37.440</a></span> | <span class="t">my work's safe for a while. I don't know about yours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4439" target="_blank">01:13:59.920</a></span> | <span class="t">Yeah, a little bit. I mean, it's-- I'm not an expert. I know you guys know a lot more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4445" target="_blank">01:14:05.720</a></span> | <span class="t">than me. So I mean, Triton's different in that in Triton, you can have a matrix multiplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4454" target="_blank">01:14:14.680</a></span> | <span class="t">inside. You can have @ inside your kernel. And Triton's really clever at optimizing these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4463" target="_blank">01:14:23.520</a></span> | <span class="t">much more sophisticated things. So number's a lot more basic, really. It's just a mapping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4471" target="_blank">01:14:31.520</a></span> | <span class="t">of the CUDA-C concepts directly to Python concepts. Triton is a fairly recent, literally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4483" target="_blank">01:14:43.400</a></span> | <span class="t">a PhD thesis artifact. So it's doing something a lot more clever. I mean, there are similarities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4491" target="_blank">01:14:51.680</a></span> | <span class="t">It works with a decorator. It converts Python code to GPU code. I think they're good for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4501" target="_blank">01:15:01.160</a></span> | <span class="t">different things, because Triton is somewhat limited as well. It's very, very smart, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4506" target="_blank">01:15:06.760</a></span> | <span class="t">it's not a mapping of the entire CUDA programming model. So for example, when I know at Meta,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4513" target="_blank">01:15:13.360</a></span> | <span class="t">when you guys, Horace and those guys did the GPT fast thing and wanted to do 4-bit discretization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4521" target="_blank">01:15:21.760</a></span> | <span class="t">you found that you couldn't do it in Triton. And that's because Triton doesn't have any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4525" target="_blank">01:15:25.440</a></span> | <span class="t">way to express that at the moment. So yeah, I think they both have their place. Do you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4534" target="_blank">01:15:34.040</a></span> | <span class="t">guys feel the same way?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4535" target="_blank">01:15:35.840</a></span> | <span class="t">Yeah, so we are going to have Charles, who is the author of the GPT fast kernel, give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4541" target="_blank">01:15:41.520</a></span> | <span class="t">us a talk in two weeks. So he's going to sort of tell us the first time it'll happen. I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4546" target="_blank">01:15:46.680</a></span> | <span class="t">think when people ask this question, the motivation is sort of can you avoid learning CUDA? And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4552" target="_blank">01:15:52.920</a></span> | <span class="t">after that, it's like that's a negative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4555" target="_blank">01:15:55.000</a></span> | <span class="t">Does seem to be, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4556" target="_blank">01:15:56.000</a></span> | <span class="t">So when I'm like learning both, and trying it will just be slightly easier to ship some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4561" target="_blank">01:16:01.200</a></span> | <span class="t">sort of useful kernel, but you're going to sort of run into the limits of the language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4566" target="_blank">01:16:06.480</a></span> | <span class="t">Yeah, and I'm not even sure it's easier to use Triton. I feel like Triton is more complex</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4574" target="_blank">01:16:14.200</a></span> | <span class="t">in many ways. So once you know CUDA, then you can find the places where Triton can help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4580" target="_blank">01:16:20.000</a></span> | <span class="t">I think trying to use Triton effectively if you didn't know CUDA would be an even harder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4585" target="_blank">01:16:25.840</a></span> | <span class="t">path, especially now that we've kind of figured out these ways of doing iterative notebook</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4595" target="_blank">01:16:35.200</a></span> | <span class="t">based CUDA development, which is one of the big benefits of Triton is just it's a decorator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4599" target="_blank">01:16:39.640</a></span> | <span class="t">and it's Python and stuff. So, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4612" target="_blank">01:16:52.040</a></span> | <span class="t">Okay, so I think then this was wonderful session today. Thank you so much, Henry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4641" target="_blank">01:17:21.040</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4642" target="_blank">01:17:22.040</a></span> | <span class="t">Thank you so much for the opportunity now to work on this. And yeah, fantastic, a really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4648" target="_blank">01:17:28.560</a></span> | <span class="t">deep dive into a metrics modification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=eUuGdh3nBGo&t=4651" target="_blank">01:17:31.240</a></span> | <span class="t">Bye, everybody. Thanks for joining.</span></div></div></body></html>