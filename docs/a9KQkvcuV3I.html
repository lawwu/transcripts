<html><head><title>Stanford XCS224U: NLU I In-context Learning, Part 3: Current Moment I Spring 2023</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford XCS224U: NLU I In-context Learning, Part 3: Current Moment I Spring 2023</h2><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I"><img src="https://i.ytimg.com/vi/a9KQkvcuV3I/sddefault.jpg?sqp=-oaymwEmCIAFEOAD8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGFkgZChlMA8=&rs=AOn4CLBHdKE1KMXss-7q3ZMX_1LgfgZjlA" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./a9KQkvcuV3I.html">Whisper Transcript</a> | <a href="./transcript_a9KQkvcuV3I.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Welcome back everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=6" target="_blank">00:00:06.080</a></span> | <span class="t">This is part three in our series on in-context learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=8" target="_blank">00:00:08.880</a></span> | <span class="t">I've called this part the current moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=10" target="_blank">00:00:10.720</a></span> | <span class="t">That is either foolish or foolhardy or both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=13" target="_blank">00:00:13.760</a></span> | <span class="t">The current moment is surely going to change very fast as the field changes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=17" target="_blank">00:00:17.840</a></span> | <span class="t">I think I can say that the lessons here will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=20" target="_blank">00:00:20.480</a></span> | <span class="t">useful no matter what direction the field takes next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=23" target="_blank">00:00:23.720</a></span> | <span class="t">As always, I want to start with data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=26" target="_blank">00:00:26.360</a></span> | <span class="t">Data used for self-supervision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=28" target="_blank">00:00:28.000</a></span> | <span class="t">This is an incredibly important ingredient when it comes to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=30" target="_blank">00:00:30.480</a></span> | <span class="t">understanding the behaviors of our large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=34" target="_blank">00:00:34.520</a></span> | <span class="t">This is a slide that I used in a previous screencast,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=37" target="_blank">00:00:37.200</a></span> | <span class="t">but I augmented it with the colossal clean crawled corpus C4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=41" target="_blank">00:00:41.240</a></span> | <span class="t">This is a dataset that was created as part of the T5 modeling effort,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=45" target="_blank">00:00:45.400</a></span> | <span class="t">and it is audited by Dodge et al 2021.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=49" target="_blank">00:00:49.120</a></span> | <span class="t">Interesting side note,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=51" target="_blank">00:00:51.060</a></span> | <span class="t">the Washington Post did an article that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=52" target="_blank">00:00:52.880</a></span> | <span class="t">essentially about the dataset and the auditing work that Dodge et al did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=56" target="_blank">00:00:56.680</a></span> | <span class="t">They called that article inside the secret list of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=59" target="_blank">00:00:59.320</a></span> | <span class="t">websites that make AI like chat GPT sound smart.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=62" target="_blank">00:01:02.920</a></span> | <span class="t">I'm not sure secret is appropriate here because it seems like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=65" target="_blank">00:01:05.920</a></span> | <span class="t">everyone is being pretty open about what is in C4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=69" target="_blank">00:01:09.040</a></span> | <span class="t">But nonetheless, the article is very useful in terms of helping you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=72" target="_blank">00:01:12.640</a></span> | <span class="t">people like us, audit what was in datasets like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=76" target="_blank">00:01:16.520</a></span> | <span class="t">Undoubtedly, the data that are used for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=80" target="_blank">00:01:20.040</a></span> | <span class="t">unsupervised pre-training are an incredibly important ingredient when it comes to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=83" target="_blank">00:01:23.760</a></span> | <span class="t">understanding what our models can do and where they're limited.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=87" target="_blank">00:01:27.760</a></span> | <span class="t">But as I mentioned at the end of the previous screencast,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=91" target="_blank">00:01:31.440</a></span> | <span class="t">this is no longer the only ingredient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=93" target="_blank">00:01:33.440</a></span> | <span class="t">We have left the era when all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=96" target="_blank">00:01:36.200</a></span> | <span class="t">the language model pre-training was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=97" target="_blank">00:01:37.960</a></span> | <span class="t">simply unsupervised language model pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=100" target="_blank">00:01:40.740</a></span> | <span class="t">We have now entered into the era of instruct fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=105" target="_blank">00:01:45.100</a></span> | <span class="t">Unfortunately, we know much less about what is happening with instruct fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=109" target="_blank">00:01:49.760</a></span> | <span class="t">We don't really know what the large industrial labs are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=113" target="_blank">00:01:53.400</a></span> | <span class="t">doing in terms of data and protocols here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=116" target="_blank">00:01:56.460</a></span> | <span class="t">We can infer that they are paying lots of people to generate instruct data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=121" target="_blank">00:02:01.440</a></span> | <span class="t">That means that very often these people are doing quite sophisticated things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=125" target="_blank">00:02:05.300</a></span> | <span class="t">For example, I think people might be prompted with a text that says,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=129" target="_blank">00:02:09.100</a></span> | <span class="t">write a certain Python program,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=131" target="_blank">00:02:11.200</a></span> | <span class="t">and then a human actually writes that Python program.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=134" target="_blank">00:02:14.320</a></span> | <span class="t">That's just one instance of many domains and areas of expertise where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=139" target="_blank">00:02:19.120</a></span> | <span class="t">they have recruited people to exemplify the desired behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=142" target="_blank">00:02:22.860</a></span> | <span class="t">Again, a reminder that the really sophisticated things that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=146" target="_blank">00:02:26.600</a></span> | <span class="t">seeing from language models these days are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=149" target="_blank">00:02:29.640</a></span> | <span class="t">emerging in some magical way from unsupervised pre-training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=153" target="_blank">00:02:33.300</a></span> | <span class="t">but rather emerging very directly from standard,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=156" target="_blank">00:02:36.880</a></span> | <span class="t">good old-fashioned supervision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=159" target="_blank">00:02:39.960</a></span> | <span class="t">I think we can also infer that these large industrial labs are using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=163" target="_blank">00:02:43.840</a></span> | <span class="t">their own models to generate examples and adjudicate between examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=168" target="_blank">00:02:48.000</a></span> | <span class="t">In fact, we're going to review a method along those lines,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=170" target="_blank">00:02:50.800</a></span> | <span class="t">self-instruct, in just a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=173" target="_blank">00:02:53.900</a></span> | <span class="t">If you would like to get a feel for what instruct fine-tuning is like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=178" target="_blank">00:02:58.120</a></span> | <span class="t">I would encourage you to check out the Stanford Human Preferences dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=181" target="_blank">00:03:01.700</a></span> | <span class="t">This is a new release on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=183" target="_blank">00:03:03.420</a></span> | <span class="t">instruct fine-tuning dataset that was derived from Reddit posts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=188" target="_blank">00:03:08.580</a></span> | <span class="t">You could use that, maybe using subparts of it or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=191" target="_blank">00:03:11.500</a></span> | <span class="t">different protocols for fine-tuning to get a feel for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=194" target="_blank">00:03:14.060</a></span> | <span class="t">how instruct data affects model behaviors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=197" target="_blank">00:03:17.980</a></span> | <span class="t">and that could be quite illuminating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=200" target="_blank">00:03:20.460</a></span> | <span class="t">I mentioned self-instruct before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=202" target="_blank">00:03:22.640</a></span> | <span class="t">I think this is a powerful method that points to lots of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=205" target="_blank">00:03:25.260</a></span> | <span class="t">new ways in which we could use models to make models better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=209" target="_blank">00:03:29.020</a></span> | <span class="t">For self-instruct, we begin from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=211" target="_blank">00:03:31.440</a></span> | <span class="t">175 tasks that were written by humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=215" target="_blank">00:03:35.280</a></span> | <span class="t">Those go into a task pool,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=217" target="_blank">00:03:37.460</a></span> | <span class="t">and then we have a language model generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=219" target="_blank">00:03:39.680</a></span> | <span class="t">some new instructions via in-context learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=223" target="_blank">00:03:43.120</a></span> | <span class="t">The generated instruction is then fed back into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=226" target="_blank">00:03:46.120</a></span> | <span class="t">that same language model with a new kind of prompt that helps the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=229" target="_blank">00:03:49.620</a></span> | <span class="t">decide whether the instruction is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=231" target="_blank">00:03:51.880</a></span> | <span class="t">a classification task or some other kind of task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=234" target="_blank">00:03:54.980</a></span> | <span class="t">Depending on the generated response at step 2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=237" target="_blank">00:03:57.720</a></span> | <span class="t">we feed the generated output into one or another of these two prompts down here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=242" target="_blank">00:04:02.900</a></span> | <span class="t">and that step gives us new input-output pairs that we can use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=248" target="_blank">00:04:08.060</a></span> | <span class="t">for subsequent supervised language model pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=252" target="_blank">00:04:12.600</a></span> | <span class="t">There's some filtering there for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=254" target="_blank">00:04:14.260</a></span> | <span class="t">quality and to make sure the dataset is diverse,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=256" target="_blank">00:04:16.660</a></span> | <span class="t">but then those generated instructions go back into the task pool and can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=260" target="_blank">00:04:20.660</a></span> | <span class="t">participate in parts of these prompts to generate more data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=265" target="_blank">00:04:25.500</a></span> | <span class="t">In that way, we can use a language model to bootstrap a new dataset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=270" target="_blank">00:04:30.820</a></span> | <span class="t">and then we can update that very same language model with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=274" target="_blank">00:04:34.260</a></span> | <span class="t">the new dataset in the hopes that that will lead it to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=276" target="_blank">00:04:36.660</a></span> | <span class="t">have more and more diverse abilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=280" target="_blank">00:04:40.100</a></span> | <span class="t">That was abstract, so let's walk through how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=282" target="_blank">00:04:42.620</a></span> | <span class="t">self-instruct happens at the level of the prompts that they use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=285" target="_blank">00:04:45.980</a></span> | <span class="t">At step 1, we have instruction generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=288" target="_blank">00:04:48.300</a></span> | <span class="t">This is the prompt. You can see the model is given</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=290" target="_blank">00:04:50.740</a></span> | <span class="t">eight demonstrations and then asked to generate a new instruction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=294" target="_blank">00:04:54.740</a></span> | <span class="t">The majority of these demonstrations were human-created,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=297" target="_blank">00:04:57.900</a></span> | <span class="t">but in subsequent rounds of self-instruct,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=300" target="_blank">00:05:00.300</a></span> | <span class="t">some of them were actually model-generated instructions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=304" target="_blank">00:05:04.340</a></span> | <span class="t">At step 2, we have classification task identification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=307" target="_blank">00:05:07.780</a></span> | <span class="t">The generated response from step 1 is fed into this prompt,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=311" target="_blank">00:05:11.100</a></span> | <span class="t">and the model learns in context to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=313" target="_blank">00:05:13.420</a></span> | <span class="t">predict whether or not it was a classification task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=316" target="_blank">00:05:16.540</a></span> | <span class="t">Depending on the generated response there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=318" target="_blank">00:05:18.860</a></span> | <span class="t">we either feed it into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=320" target="_blank">00:05:20.020</a></span> | <span class="t">a classification task prompt or a non-classification task prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=324" target="_blank">00:05:24.620</a></span> | <span class="t">The results here give us new input-output pairs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=328" target="_blank">00:05:28.340</a></span> | <span class="t">that we can use to augment our self-instruct dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=331" target="_blank">00:05:31.500</a></span> | <span class="t">Then as I said, we do subsequent language model supervised,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=335" target="_blank">00:05:35.620</a></span> | <span class="t">pre-training in the standard way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=337" target="_blank">00:05:37.580</a></span> | <span class="t">or maybe with some other techniques to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=339" target="_blank">00:05:39.700</a></span> | <span class="t">update the model that was used for this generation process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=343" target="_blank">00:05:43.220</a></span> | <span class="t">That self-instruct was a major mechanism behind Alpaca.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=348" target="_blank">00:05:48.220</a></span> | <span class="t">Alpaca was an important recent moment for the field because it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=351" target="_blank">00:05:51.420</a></span> | <span class="t">started to show people that we could via self-instruct methods,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=355" target="_blank">00:05:55.380</a></span> | <span class="t">take relatively small models like a seven billion parameter model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=359" target="_blank">00:05:59.820</a></span> | <span class="t">do some instruct fine-tuning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=361" target="_blank">00:06:01.500</a></span> | <span class="t">and get a very capable result as the output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=364" target="_blank">00:06:04.660</a></span> | <span class="t">In more detail, the way Alpaca works is we begin with a Lama model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=369" target="_blank">00:06:09.100</a></span> | <span class="t">Lama is a class of models that was released recently by Meta AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=373" target="_blank">00:06:13.900</a></span> | <span class="t">The Alpaca team began from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=375" target="_blank">00:06:15.660</a></span> | <span class="t">the 175 tasks that were written by humans for the self-instruct paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=380" target="_blank">00:06:20.860</a></span> | <span class="t">Then they follow self-instruct with some minor simplifications using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=385" target="_blank">00:06:25.020</a></span> | <span class="t">Text DaVinci 3 as the engine to create the new input-output pairs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=389" target="_blank">00:06:29.420</a></span> | <span class="t">That gives them a dataset ultimately of 52,000 examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=393" target="_blank">00:06:33.700</a></span> | <span class="t">and those examples were used to update the Lama model to create Alpaca.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=398" target="_blank">00:06:38.540</a></span> | <span class="t">The observation is that the results of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=400" target="_blank">00:06:40.740</a></span> | <span class="t">this relatively small-scale effort to update</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=403" target="_blank">00:06:43.540</a></span> | <span class="t">the Lama model are actually quite powerful in terms of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=406" target="_blank">00:06:46.620</a></span> | <span class="t">imbuing Alpaca with new instruct following behaviors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=410" target="_blank">00:06:50.780</a></span> | <span class="t">Again, there's a major lesson there about technology,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=414" target="_blank">00:06:54.340</a></span> | <span class="t">and I think this is an exciting new direction for the field as we think about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=417" target="_blank">00:06:57.580</a></span> | <span class="t">making these relatively small models ever more performant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=421" target="_blank">00:07:01.380</a></span> | <span class="t">There is also a lesson for you about what's going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=423" target="_blank">00:07:03.940</a></span> | <span class="t">effective for in-context learning because obviously,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=426" target="_blank">00:07:06.620</a></span> | <span class="t">to the extent that you can tune</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=428" target="_blank">00:07:08.980</a></span> | <span class="t">your own prompts to align with the instruction fine-tuning data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=432" target="_blank">00:07:12.300</a></span> | <span class="t">that models like Alpaca have seen,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=434" target="_blank">00:07:14.340</a></span> | <span class="t">you will be more successful,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=435" target="_blank">00:07:15.780</a></span> | <span class="t">and that lesson generalizes to all of these large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=439" target="_blank">00:07:19.180</a></span> | <span class="t">For some, we have visibility into the instruct fine-tuning data as with Alpaca,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=443" target="_blank">00:07:23.660</a></span> | <span class="t">but for the largest ones, we don't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=445" target="_blank">00:07:25.540</a></span> | <span class="t">People have to organically discover which prompting techniques work,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=449" target="_blank">00:07:29.980</a></span> | <span class="t">which is really a process of uncovering, I believe,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=452" target="_blank">00:07:32.580</a></span> | <span class="t">what their instruct fine-tuning phase was like at this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=456" target="_blank">00:07:36.580</a></span> | <span class="t">Alpaca, as I said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=458" target="_blank">00:07:38.660</a></span> | <span class="t">was exciting because it bucked the trend of model sizes going up, up, up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=463" target="_blank">00:07:43.460</a></span> | <span class="t">This is a slide that I used in the intro lecture for the course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=466" target="_blank">00:07:46.860</a></span> | <span class="t">We got all the way up to Palm at 540 billion parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=470" target="_blank">00:07:50.380</a></span> | <span class="t">It may be that GPT-4 is substantially larger even than that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=474" target="_blank">00:07:54.860</a></span> | <span class="t">As a result of this instruct fine-tuning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=478" target="_blank">00:07:58.540</a></span> | <span class="t">we're starting to see that model sizes might come down and nonetheless be very performant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=484" target="_blank">00:08:04.660</a></span> | <span class="t">That is incredibly exciting because it's going to happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=487" target="_blank">00:08:07.980</a></span> | <span class="t">There are lots of incentives, intellectual, technological,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=490" target="_blank">00:08:10.820</a></span> | <span class="t">financial for us to find a way to have smaller models be performant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=494" target="_blank">00:08:14.940</a></span> | <span class="t">I think that will be an important step toward actually truly democratizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=499" target="_blank">00:08:19.540</a></span> | <span class="t">access to large language models and the capabilities that they can enable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a9KQkvcuV3I&t=504" target="_blank">00:08:24.460</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>