<html><head><title>Thinking Deeper in Gemini — Jack Rae, Google DeepMind</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Thinking Deeper in Gemini — Jack Rae, Google DeepMind</h2><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw"><img src="https://i.ytimg.com/vi_webp/8EQo4J2BWKw/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./8EQo4J2BWKw.html">Whisper Transcript</a> | <a href="./transcript_8EQo4J2BWKw.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hi, everybody.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=25" target="_blank">00:00:25.440</a></span> | <span class="t">Yeah, my name is Jack.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=26" target="_blank">00:00:26.640</a></span> | <span class="t">I'm a researcher at Google, and I'm the tech lead of Thinking Within Gemini.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=31" target="_blank">00:00:31.320</a></span> | <span class="t">I'm going to give a brief, deep dive into thinking from the research perspective within</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=38" target="_blank">00:00:38.980</a></span> | <span class="t">Gemini.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=39" target="_blank">00:00:39.980</a></span> | <span class="t">I'm going to give this talk in three stages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=43" target="_blank">00:00:43.040</a></span> | <span class="t">One is to give a research motivation of why we actually are excited about thinking in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=47" target="_blank">00:00:47.280</a></span> | <span class="t">terms of unblocking bottlenecks towards intelligence, and I'm going to give a few examples of how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=54" target="_blank">00:00:54.600</a></span> | <span class="t">often discovering the most prescient bottlenecks in our current models, our most advanced systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=63" target="_blank">00:01:03.660</a></span> | <span class="t">how often, if you can just identify the crucial issues and shortcomings, you often will then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=69" target="_blank">00:01:09.480</a></span> | <span class="t">find a solution, and there's a reason how that is linked to thinking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=72" target="_blank">00:01:12.280</a></span> | <span class="t">I'm then going to talk a little bit more just pragmatically about what is thinking in Gemini,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=79" target="_blank">00:01:19.340</a></span> | <span class="t">and why is it interesting to developers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=81" target="_blank">00:01:21.340</a></span> | <span class="t">And I think you're -- the slides are still not here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=88" target="_blank">00:01:28.680</a></span> | <span class="t">We did do a rehearsal this morning where the slides are there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=91" target="_blank">00:01:31.400</a></span> | <span class="t">But, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=92" target="_blank">00:01:32.400</a></span> | <span class="t">Keynote speaker slide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=93" target="_blank">00:01:33.400</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=94" target="_blank">00:01:34.400</a></span> | <span class="t">Someone's -- I can see someone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=96" target="_blank">00:01:36.400</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=97" target="_blank">00:01:37.400</a></span> | <span class="t">Keynote speaker folder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=100" target="_blank">00:01:40.400</a></span> | <span class="t">I think it's in the keynote speaker.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=112" target="_blank">00:01:52.460</a></span> | <span class="t">Anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=113" target="_blank">00:01:53.460</a></span> | <span class="t">It's going to come up soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=115" target="_blank">00:01:55.460</a></span> | <span class="t">You are close, person.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=116" target="_blank">00:01:56.460</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=117" target="_blank">00:01:57.460</a></span> | <span class="t">But -- and then I'm also going to talk a little bit about what's next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=122" target="_blank">00:02:02.460</a></span> | <span class="t">So, Logan did a great job of kind of giving an incredible overview of Gemini as a whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=144" target="_blank">00:02:24.460</a></span> | <span class="t">ecosystem, everything that's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=146" target="_blank">00:02:26.460</a></span> | <span class="t">I'm going to really be focusing on kind of what we're excited about in the reasoning space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=152" target="_blank">00:02:32.160</a></span> | <span class="t">So, with intelligence bottlenecks, we're kind of -- the message of this section is really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=157" target="_blank">00:02:37.420</a></span> | <span class="t">about progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=158" target="_blank">00:02:38.800</a></span> | <span class="t">So, progress has really been marked by identifying key bottlenecks towards intelligence and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=164" target="_blank">00:02:44.420</a></span> | <span class="t">solving them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=165" target="_blank">00:02:45.560</a></span> | <span class="t">And I'm going to kind of give some examples throughout history.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=167" target="_blank">00:02:47.660</a></span> | <span class="t">I'm going to actually rewind the clock to 1948.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=170" target="_blank">00:02:50.700</a></span> | <span class="t">Claude Shannon, he invents the language model, mathematical theory of communication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=174" target="_blank">00:02:54.480</a></span> | <span class="t">He builds a language model, a 2-gram, using a textbook of word statistics that was hand-calculated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=180" target="_blank">00:03:00.940</a></span> | <span class="t">And he samples from it, and he kind of marvels at the samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=183" target="_blank">00:03:03.860</a></span> | <span class="t">He feels like these are getting pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=185" target="_blank">00:03:05.600</a></span> | <span class="t">They're a lot better than unigram character, this 2-gram word model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=189" target="_blank">00:03:09.260</a></span> | <span class="t">But kind of he remarks, like, "I think this would be better if we could really, like, make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=193" target="_blank">00:03:13.200</a></span> | <span class="t">a better language model and scale up this current method."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=196" target="_blank">00:03:16.080</a></span> | <span class="t">So he really wanted to just scale up the n-gram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=198" target="_blank">00:03:18.080</a></span> | <span class="t">That was the bottleneck, like, small amount of data, very, you know, elementary statistics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=203" target="_blank">00:03:23.880</a></span> | <span class="t">And unfortunately for Claude Shannon, kind of the solution was pretty hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=207" target="_blank">00:03:27.100</a></span> | <span class="t">He needed the digitalization of human knowledge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=209" target="_blank">00:03:29.420</a></span> | <span class="t">And he needed modern computing to be able to aggregate these statistics at scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=212" target="_blank">00:03:32.800</a></span> | <span class="t">So, you know, that wasn't so easy for him to solve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=215" target="_blank">00:03:35.120</a></span> | <span class="t">He had it a bit more tricky.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=217" target="_blank">00:03:37.080</a></span> | <span class="t">But fast forward a few decades.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=218" target="_blank">00:03:38.300</a></span> | <span class="t">At Google, in the 2000s, my colleagues, such as Jeff Dean, are training n-gram language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=225" target="_blank">00:03:45.840</a></span> | <span class="t">over trillions of tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=227" target="_blank">00:03:47.460</a></span> | <span class="t">These are powering, at the time, the most sophisticated speech recognition and translation systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=233" target="_blank">00:03:53.060</a></span> | <span class="t">And a lot of progress has been made.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=234" target="_blank">00:03:54.680</a></span> | <span class="t">But their bottleneck was actually, with these systems, was that these n-gram language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=238" target="_blank">00:03:58.600</a></span> | <span class="t">were very restricted to short context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=240" target="_blank">00:04:00.880</a></span> | <span class="t">And they were because there's an exponential storage cost with context length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=246" target="_blank">00:04:06.640</a></span> | <span class="t">And there wasn't really a way around that, with just sticking with n-grams.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=249" target="_blank">00:04:09.860</a></span> | <span class="t">The solution was the early, kind of, introduction of deep learning in 2010, with the introduction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=256" target="_blank">00:04:16.440</a></span> | <span class="t">of recurrent neural language models, so recurrent neural networks applied to modeling text, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=261" target="_blank">00:04:21.900</a></span> | <span class="t">the recurrent neural networks could avoid this problem by storing compressed representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=266" target="_blank">00:04:26.740</a></span> | <span class="t">of the past into the state of a neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=268" target="_blank">00:04:28.920</a></span> | <span class="t">And they could now start to model, beyond a 5-gram, sentences or even paragraphs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=273" target="_blank">00:04:33.820</a></span> | <span class="t">And this was a massive, kind of, step change and improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=277" target="_blank">00:04:37.220</a></span> | <span class="t">However, a couple of years later, people would notice, even there, there was a bottleneck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=281" target="_blank">00:04:41.220</a></span> | <span class="t">So the recurrent neural network's representation of the past is in a fixed-size state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=286" target="_blank">00:04:46.260</a></span> | <span class="t">And this fixed-size state, there's only so much information you could put into it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=291" target="_blank">00:04:51.380</a></span> | <span class="t">And so, as a result, there's often observed to be kind of lossy, a lossy kind of representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=296" target="_blank">00:04:56.100</a></span> | <span class="t">of its context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=297" target="_blank">00:04:57.320</a></span> | <span class="t">The solution that was derived, I think, once people kind of really encountered this information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=302" target="_blank">00:05:02.420</a></span> | <span class="t">bottleneck in the past, was actually just keep everything around, in terms of your past neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=307" target="_blank">00:05:07.980</a></span> | <span class="t">embeddings, and use an attention operator to aggregate things on the fly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=312" target="_blank">00:05:12.140</a></span> | <span class="t">So this was the birth of attention, and then shortly after, transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=315" target="_blank">00:05:15.840</a></span> | <span class="t">So transformers then, kind of, led to the modern deep learning revolution as we know it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=321" target="_blank">00:05:21.140</a></span> | <span class="t">And many other progress was made, but if we skip forward 10 years, we then are in 2024,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=326" target="_blank">00:05:26.620</a></span> | <span class="t">we have large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=329" target="_blank">00:05:29.360</a></span> | <span class="t">They're increasingly powerful general conversational agents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=331" target="_blank">00:05:31.720</a></span> | <span class="t">We have models such as Gemini, ChatGPT, people are using them for all sorts of use cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=337" target="_blank">00:05:37.280</a></span> | <span class="t">And there, that's where we kind of come to the bottleneck that's relevant to this talk, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=340" target="_blank">00:05:40.940</a></span> | <span class="t">is that although these models are very, very powerful, they're still trained to respond immediately</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=345" target="_blank">00:05:45.920</a></span> | <span class="t">to requests.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=346" target="_blank">00:05:46.920</a></span> | <span class="t">So, in other words, in terms of a compute bottleneck, there is a constant amount of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=350" target="_blank">00:05:50.600</a></span> | <span class="t">compute that they apply at test time to transition from your request or your question to the response</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=356" target="_blank">00:05:56.660</a></span> | <span class="t">or your answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=357" target="_blank">00:05:57.660</a></span> | <span class="t">So, the bottleneck of test time compute, this is relevant to thinking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=362" target="_blank">00:06:02.660</a></span> | <span class="t">So, we can impact this a little bit more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=364" target="_blank">00:06:04.400</a></span> | <span class="t">So, when we talk about a fixed amount of test time compute, the test time compute is interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=368" target="_blank">00:06:08.900</a></span> | <span class="t">to you because that's the compute that the model is spending on your particular problem, your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=372" target="_blank">00:06:12.820</a></span> | <span class="t">particular question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=374" target="_blank">00:06:14.100</a></span> | <span class="t">And the way it actually kind of mechanically works is you have some text in your request.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=380" target="_blank">00:06:20.200</a></span> | <span class="t">It gets translated to tokens, and then it's going to go through a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=384" target="_blank">00:06:24.240</a></span> | <span class="t">And at the transition from the request to its response, it's going to pass some computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=388" target="_blank">00:06:28.800</a></span> | <span class="t">up through a large language model, which will have some parallel computation for every layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=393" target="_blank">00:06:33.060</a></span> | <span class="t">and it'll have some iterative computation across layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=396" target="_blank">00:06:36.280</a></span> | <span class="t">So, that computation is really where the model can apply its intelligence to your particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=400" target="_blank">00:06:40.220</a></span> | <span class="t">problem, and it's a fixed size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=403" target="_blank">00:06:43.000</a></span> | <span class="t">One solution if you wanted a smarter model and more computation is just to make the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=406" target="_blank">00:06:46.540</a></span> | <span class="t">larger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=407" target="_blank">00:06:47.540</a></span> | <span class="t">And then you can have more compute, and you can get a smarter response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=410" target="_blank">00:06:50.840</a></span> | <span class="t">However, it's still not really enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=413" target="_blank">00:06:53.280</a></span> | <span class="t">Users might want to be able to think a thousand or a million times and have a very large dynamic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=417" target="_blank">00:06:57.400</a></span> | <span class="t">range and a lot of compute for very hard or challenging or valuable tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=422" target="_blank">00:07:02.140</a></span> | <span class="t">And also, users might want to have a very dynamic application of test time compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=426" target="_blank">00:07:06.560</a></span> | <span class="t">So, less compute for simpler requests, more compute for harder requests, and have this process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=430" target="_blank">00:07:10.080</a></span> | <span class="t">be very dynamic and instigated by the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=433" target="_blank">00:07:13.620</a></span> | <span class="t">And that is what motivates thinking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=435" target="_blank">00:07:15.620</a></span> | <span class="t">So, thinking in Gemini, mechanically, I'm sure almost everyone in this room is familiar with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=442" target="_blank">00:07:22.760</a></span> | <span class="t">this general process where we will now have a model, and we insert a thinking stage that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=448" target="_blank">00:07:28.620</a></span> | <span class="t">that the model can emit some additional text before it decides to emit a final answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=454" target="_blank">00:07:34.160</a></span> | <span class="t">So, going back to this notion of test time compute now, we've added an additional kind of loop of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=460" target="_blank">00:07:40.160</a></span> | <span class="t">computation where the model can kind of iteratively loop and perform additional test time compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=466" target="_blank">00:07:46.160</a></span> | <span class="t">during this thinking stage, and this loop can be potentially thousands or tens of thousands of iterations, which gives you tens of thousands more compute before it decides to commit to what its response will be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=477" target="_blank">00:07:57.700</a></span> | <span class="t">And also, because it's a loop, it's dynamic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=479" target="_blank">00:07:59.700</a></span> | <span class="t">So, the model can learn how many iterations of this loop to apply before it decides to actually commit to its answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=485" target="_blank">00:08:05.700</a></span> | <span class="t">So, we train this model to think, to use this kind of thinking stage via reinforcement learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=493" target="_blank">00:08:13.240</a></span> | <span class="t">So, when we pre-train Gemini, we then have after a reinforcement learning stage where we train it to do many different tasks and we give it positive and negative rewards depending on whether or not it solves the task correctly or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=507" target="_blank">00:08:27.240</a></span> | <span class="t">And this is essentially a very general training recipe really, and it's kind of remarkable it works, but the model is able to just get a very vague signal of what is correct and what is not correct,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=518" target="_blank">00:08:38.780</a></span> | <span class="t">and to back-propagate this through this loop of thinking stage such that it can try and shape how it uses its thinking computation and thinking tokens in order to be more useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=528" target="_blank">00:08:48.780</a></span> | <span class="t">In fact, we weren't really sure this would work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=532" target="_blank">00:08:52.740</a></span> | <span class="t">It wasn't clear how much structure we should put into something like a reasoning stage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=537" target="_blank">00:08:57.280</a></span> | <span class="t">And although I think probably many people here have now seen reasoning traces and played with these models, I'll just show you a historical artifact.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=544" target="_blank">00:09:04.280</a></span> | <span class="t">From one of the times we were trying to use reinforcement learning, we started to see cool emergent behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=550" target="_blank">00:09:10.500</a></span> | <span class="t">So, in this problem, there's kind of like an integer prediction problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=553" target="_blank">00:09:13.780</a></span> | <span class="t">This was just like a kind of a particular example, in this case, kind of like a MATSI example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=561" target="_blank">00:09:21.980</a></span> | <span class="t">And what we saw was the model was using its thinking tokens to actually first pose a hypothesis, and then test out the hypothesis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=569" target="_blank">00:09:29.520</a></span> | <span class="t">And then it found that basically things weren't really working, and it kind of states that this formula doesn't hold.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=575" target="_blank">00:09:35.020</a></span> | <span class="t">It rejects its own idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=576" target="_blank">00:09:36.520</a></span> | <span class="t">And then it tries an alternative approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=578" target="_blank">00:09:38.520</a></span> | <span class="t">And I think it's easy to become desensitized to technology because it's so amazing every single day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=583" target="_blank">00:09:43.520</a></span> | <span class="t">But we were truly blown away when we saw the general recipe of reinforcement learning was creating all sorts of interesting emergent behavior, trying different ideas, self-correction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=592" target="_blank">00:09:52.060</a></span> | <span class="t">And I think these days, we see a lot of different strategies that the model learns to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=596" target="_blank">00:09:56.600</a></span> | <span class="t">So, it learns to break down the problem into various components, explore multiple solutions, draft fragments of code and build these up in a modular way, perform intermediate calculations and use tools.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=609" target="_blank">00:10:09.600</a></span> | <span class="t">All under the umbrella of using more test-type compute to give you a smarter response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=615" target="_blank">00:10:15.140</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=616" target="_blank">00:10:16.140</a></span> | <span class="t">So, I've talked a bit about why we are interested in thinking in terms of the path to AGI and unblocking bottlenecks of intelligence, and just a little bit about mechanically what it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=626" target="_blank">00:10:26.140</a></span> | <span class="t">Why is it interesting to developers?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=627" target="_blank">00:10:27.140</a></span> | <span class="t">Obviously, the number one reason is we think this is driving more capable models, and it also stacks on top of our current paradigms of how we accelerate model progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=637" target="_blank">00:10:37.640</a></span> | <span class="t">So, thinking we can accelerate this process by scaling the amount of test-time compute, and we find that this can stack as a paradigm on top of pre-existing paradigms, such as pre-training, where you can scale the amount of pre-training data and model size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=654" target="_blank">00:10:54.680</a></span> | <span class="t">and also post-training where you can scale the quality and diversity of human feedback for many different types of tasks, and as a result, within Google, by investing in all of these and really accelerating all of them, we get kind of a multiplicative effect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=669" target="_blank">00:11:09.980</a></span> | <span class="t">And why is this interesting to developers?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=671" target="_blank">00:11:11.880</a></span> | <span class="t">I think it results in just overall faster model improvement, which is very nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=677" target="_blank">00:11:17.880</a></span> | <span class="t">We also see, if we kind of look back over a lineage of recent Gemini launches, you know, there's improved reasoning performance, and we can actually map this to how much test-time compute these models will devote to problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=692" target="_blank">00:11:32.880</a></span> | <span class="t">So, there's kind of like a log scale, test-time compute on the x-axis, and performance across like math, code, and some science topics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=699" target="_blank">00:11:39.880</a></span> | <span class="t">And we see that there's kind of this trend in increasing reasoning performance, whilst also it tracks very well with increasing test-time compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=706" target="_blank">00:11:46.680</a></span> | <span class="t">And on the far left, you know, you have 2.0 Flash Experimental.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=710" target="_blank">00:11:50.680</a></span> | <span class="t">This was a model that was not launched with Thinking back in December last year, so ancient history.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=717" target="_blank">00:11:57.680</a></span> | <span class="t">And now we have, on the right-hand side, the first launched version of 2.5 Pro.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=725" target="_blank">00:12:05.680</a></span> | <span class="t">So, test-time scaling is working empirically, but it's not just capability that matters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=732" target="_blank">00:12:12.680</a></span> | <span class="t">It's also interesting from the notion of being able to steer the model's quality over cost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=738" target="_blank">00:12:18.680</a></span> | <span class="t">So, you know, before, you had the option of choosing a discrete number of possible model sizes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=744" target="_blank">00:12:24.680</a></span> | <span class="t">and that was a way to gauge how much quality you wanted and also how much cost you wanted to spend,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=751" target="_blank">00:12:31.680</a></span> | <span class="t">cost you wanted to kind of incur for any given task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=754" target="_blank">00:12:34.680</a></span> | <span class="t">But it was kind of a discrete choice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=756" target="_blank">00:12:36.680</a></span> | <span class="t">Now, with Thinking, we can have a continuous budget, which allows you to have a much more granular slider</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=763" target="_blank">00:12:43.680</a></span> | <span class="t">of how much capability you want for any given kind of class of tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=768" target="_blank">00:12:48.680</a></span> | <span class="t">And we have Thinking Budgets now launched in Flash and Pro in the 2.5 series.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=775" target="_blank">00:12:55.680</a></span> | <span class="t">And this allows you to have very granular choice of cost to performance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=779" target="_blank">00:12:59.680</a></span> | <span class="t">and also allows us to then push the frontier and allow you to kind of augment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=785" target="_blank">00:13:05.680</a></span> | <span class="t">and drive cost higher and performance higher if your application requires it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=790" target="_blank">00:13:10.680</a></span> | <span class="t">So, okay, I think a lot of this stuff is really covering ground that, you know, up to the present day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=798" target="_blank">00:13:18.680</a></span> | <span class="t">So, what's next and what are we excited about?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=801" target="_blank">00:13:21.680</a></span> | <span class="t">So, we're very excited about just generally improving the models and having better reasoning, of course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=806" target="_blank">00:13:26.680</a></span> | <span class="t">We're also excited about making the thinking process as efficient as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=810" target="_blank">00:13:30.680</a></span> | <span class="t">Really, we want thinking to just work for you and be quite adaptive and be something that you don't have to actively spend a lot of energy tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=818" target="_blank">00:13:38.680</a></span> | <span class="t">And a big part of that is ensuring our models are very efficient in how they use their thoughts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=823" target="_blank">00:13:43.680</a></span> | <span class="t">This is definitely an area of progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=825" target="_blank">00:13:45.680</a></span> | <span class="t">I think we can find examples of our models over thinking on tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=828" target="_blank">00:13:48.680</a></span> | <span class="t">And this is just an area of research to get these things faster and faster and as cost effective as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=833" target="_blank">00:13:53.680</a></span> | <span class="t">We're very proud of how cost effective our Gemini models are, and this is just an area for improvement as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=840" target="_blank">00:14:00.680</a></span> | <span class="t">And there's also deeper thinking, which is really about scaling the amount of inference compute further to drive even higher capability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=847" target="_blank">00:14:07.680</a></span> | <span class="t">So, people may be familiar with Gemini deep research, where you can kind of type in a query and then the model will go away for a long period of time and research a topic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=856" target="_blank">00:14:16.680</a></span> | <span class="t">We also now have announced at I/O, and we're launching to trusted testers, a notion of deep think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=862" target="_blank">00:14:22.680</a></span> | <span class="t">Deep think is a very high budget mode, thinking budget mode, built on top of 2.5 Pro.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=868" target="_blank">00:14:28.680</a></span> | <span class="t">And its desired application is for things where you have a very hard problem, and you're happy to essentially fire off the query,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=876" target="_blank">00:14:36.680</a></span> | <span class="t">and then have some asynchronous process that's running for a while, and you'll come back to arrive at a stronger solution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=882" target="_blank">00:14:42.680</a></span> | <span class="t">And its key idea is we leverage much deeper chains of thought and parallel chains of thought that can integrate with each other to produce better responses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=891" target="_blank">00:14:51.680</a></span> | <span class="t">We find this enhances model performance on very tough multimodal code math problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=897" target="_blank">00:14:57.680</a></span> | <span class="t">An example would be USA Math Olympiad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=903" target="_blank">00:15:03.680</a></span> | <span class="t">This is a task that basically the state-of-the-art model in January was completely negligible performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=905" target="_blank">00:15:05.680</a></span> | <span class="t">2.5 Pro is now probably even better with the updated one today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=910" target="_blank">00:15:10.680</a></span> | <span class="t">It was about a 50th percentile of all participants that participated in Math Olympiad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=915" target="_blank">00:15:15.680</a></span> | <span class="t">And with deep think, it goes up to 65 percentile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=919" target="_blank">00:15:19.680</a></span> | <span class="t">And the interesting thing about deep think is as we continue to both improve the base model and improve the algorithmic ingredients that go into deep think, those two will stack together as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=927" target="_blank">00:15:27.680</a></span> | <span class="t">Here is kind of like a video animation of one of these USA Math Olympiad algebra problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=937" target="_blank">00:15:37.680</a></span> | <span class="t">And the key idea really with this video is just this notion of having multiple iterative ideas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=943" target="_blank">00:15:43.680</a></span> | <span class="t">So maybe the model starts out with some proof by contradiction idea, but then it explores two different aspects, some Rawls theorem, Newton's inequalities, it integrates them, and eventually arrives at some correct proof.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=953" target="_blank">00:15:53.680</a></span> | <span class="t">There is not that much you can take away from this video, but it looks pretty cool, so I added it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=958" target="_blank">00:15:58.680</a></span> | <span class="t">One thing that's, you know, other than we talk about math a little bit in the previous slides, I'm very excited about any application where the model can spend longer and longer thinking on very open-ended coding tasks and one-shot or very few interaction vibe code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=975" target="_blank">00:16:15.680</a></span> | <span class="t">Things that would have taken us months in the past.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=978" target="_blank">00:16:18.680</a></span> | <span class="t">And one example that I like from a researcher is just some of my colleagues kind of vibe-coded from DeepMind's original DQN paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=987" target="_blank">00:16:27.680</a></span> | <span class="t">which was a revolution in deep reinforcement learning, kind of vibe-coded, Gemini vibe-coded the kind of training setup, the algorithm, even an Atari emulator such that it could play some of the games.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=999" target="_blank">00:16:39.680</a></span> | <span class="t">And, you know, this is remarkable to me because these kind of things would have taken me and my colleagues months in the past, and these things are starting to happen kind of in minutes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1010" target="_blank">00:16:50.680</a></span> | <span class="t">One thing I'm quite excited about looking forward to the future is not really the landscape of models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1016" target="_blank">00:16:56.680</a></span> | <span class="t">but coming back to, like, what's our gold standard, which is the human mind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1020" target="_blank">00:17:00.680</a></span> | <span class="t">I would love for our models to be able to contemplate from a very small set of knowledge and think about it incredibly deeply such that we can push the frontier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1029" target="_blank">00:17:09.680</a></span> | <span class="t">And one example I often think about is Romain Ajaan, who's one of the world's greatest mathematicians from the early 20th century.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1035" target="_blank">00:17:15.680</a></span> | <span class="t">And famously, he just had this one math textbook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1039" target="_blank">00:17:19.680</a></span> | <span class="t">He was kind of cut away from the mathematical community, but just from a small set of problems, he spent many textbooks' worth of thinking, going through problems, inventing his own theories to further extend ideas, and he invented an incredible quantity of mathematics, really just by deeply thinking from a small source subset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1060" target="_blank">00:17:40.680</a></span> | <span class="t">And this is where I think we are going with thinking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1063" target="_blank">00:17:43.680</a></span> | <span class="t">We want a model to be able to be incredibly data efficient and actually go to millions or beyond of inference tokens where the model is really building up knowledge and artifacts such that we can eventually start to push the frontier of human understanding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1078" target="_blank">00:17:58.680</a></span> | <span class="t">So with that said, thank you very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1083" target="_blank">00:18:03.680</a></span> | <span class="t">Thank you very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1085" target="_blank">00:18:05.680</a></span> | <span class="t">Thank you very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1086" target="_blank">00:18:06.680</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8EQo4J2BWKw&t=1087" target="_blank">00:18:07.680</a></span> | <span class="t">We'll see you next time.</span></div></div></body></html>