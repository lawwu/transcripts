<html><head><title>Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 12 - Question Answering</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 12 - Question Answering</h2><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU" target="_blank"><img src="https://i.ytimg.com/vi/NcqfHa0_YmU/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=0 target="_blank"">0:0</a> <Untitled Chapter 1><br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=18 target="_blank"">0:18</a> Announcements<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=98 target="_blank"">1:38</a> Dante Chen<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=173 target="_blank"">2:53</a> What Is Question Answering<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=212 target="_blank"">3:32</a> Open Domain Question Answering<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=229 target="_blank"">3:49</a> What Is the Question Answering<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=680 target="_blank"">11:20</a> Visual Question Answering<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=707 target="_blank"">11:47</a> Part 2 Reading Comprehension<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=722 target="_blank"">12:2</a> Reading Comprehension<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=867 target="_blank"">14:27</a> Why Do We Care about the Reading Comprehension Problem<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=965 target="_blank"">16:5</a> Information Extraction<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=1010 target="_blank"">16:50</a> Cementite Labeling<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=1079 target="_blank"">17:59</a> Stanford Question String Dataset<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=1207 target="_blank"">20:7</a> Stanford Question Three Data Sets<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=1235 target="_blank"">20:35</a> Evaluation<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=1241 target="_blank"">20:41</a> Evaluation Metrics<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=1455 target="_blank"">24:15</a> Build a Neural Models for Reading Comprehension<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=1856 target="_blank"">30:56</a> Character Embedding Layer<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=1878 target="_blank"">31:18</a> Word Embedding<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=2037 target="_blank"">33:57</a> Attention Flow Layer<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=4310 target="_blank"">71:50</a> The Reading Comprehension Model<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=4503 target="_blank"">75:3</a> Demo<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=5109 target="_blank"">85:9</a> Natural Questions<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=5619 target="_blank"">93:39</a> In What Extent Can in-Context Learning Help Models To Be More Robust with Respect to Different Domains<br><a href="https://www.youtube.com/watch?v=NcqfHa0_YmU&t=5721 target="_blank"">95:21</a> Future of Nlp<br><h3>Transcript</h3><div class='max-width'><p></p></div></div></body></html>