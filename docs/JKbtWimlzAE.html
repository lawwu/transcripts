<html><head><title>Stanford CS25: V5 I Overview of Transformers</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford CS25: V5 I Overview of Transformers</h2><a href="https://www.youtube.com/watch?v=JKbtWimlzAE"><img src="https://i.ytimg.com/vi/JKbtWimlzAE/sddefault.jpg?sqp=-oaymwEmCIAFEOAD8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGFMgWChlMA8=&rs=AOn4CLBVIqfhEBh29QcPMA3PoCocDcljcw" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./JKbtWimlzAE.html">Whisper Transcript</a> | <a href="./transcript_JKbtWimlzAE.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Welcome to the fifth iteration of our CS25 Transformers class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=9" target="_blank">00:00:09.040</a></span> | <span class="t">So, Dev and I kind of started this class a long time ago after seeing, you know, how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=14" target="_blank">00:00:14.100</a></span> | <span class="t">transformers and machine learning in general and AI became such a prevalent thing and how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=19" target="_blank">00:00:19.680</a></span> | <span class="t">we predicted how it would become an even bigger part of our lives going forward, which does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=23" target="_blank">00:00:23.820</a></span> | <span class="t">seem to be the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=25" target="_blank">00:00:25.060</a></span> | <span class="t">So, as large language models and AI in general takes over the world, whether it's through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=30" target="_blank">00:00:30.360</a></span> | <span class="t">things like ChatGPT or image generation models like Sora, video generation models like Sora</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=35" target="_blank">00:00:35.680</a></span> | <span class="t">and so forth, we felt that, you know, having a class where people are able to sort of come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=41" target="_blank">00:00:41.820</a></span> | <span class="t">and learn about transformers, how they work, and especially hear from leading experts in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=47" target="_blank">00:00:47.400</a></span> | <span class="t">industry and academia working on state-of-the-art research in this area, how that would be very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=52" target="_blank">00:00:52.640</a></span> | <span class="t">beneficial to everybody's learning and help us progress further within AI and technology</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=59" target="_blank">00:00:59.960</a></span> | <span class="t">in general.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=60" target="_blank">00:01:00.400</a></span> | <span class="t">So, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=61" target="_blank">00:01:01.600</a></span> | <span class="t">So, welcome to our class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=63" target="_blank">00:01:03.180</a></span> | <span class="t">So, how our class works is typically each week we invite a leading researcher from either</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=68" target="_blank">00:01:08.840</a></span> | <span class="t">industry or academia to come speak about some state-of-the-art topic they're working on in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=73" target="_blank">00:01:13.740</a></span> | <span class="t">transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=74" target="_blank">00:01:14.340</a></span> | <span class="t">So, we have an exciting lineup of speakers prepared for you guys this quarter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=79" target="_blank">00:01:19.400</a></span> | <span class="t">And so, this first lecture will be delivered by us, where we'll sort of go through the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=83" target="_blank">00:01:23.760</a></span> | <span class="t">basics of transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=84" target="_blank">00:01:24.940</a></span> | <span class="t">And then we sort of divided this lecture a bit differently from the previous lectures, in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=89" target="_blank">00:01:29.860</a></span> | <span class="t">that we kind of have a section on pre-training and data strategies, and then a section focused</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=95" target="_blank">00:01:35.920</a></span> | <span class="t">more on post-training, which has become a very popular topic these days.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=99" target="_blank">00:01:39.900</a></span> | <span class="t">We'll also touch briefly on some applications of transformers and some remaining sort of weaknesses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=106" target="_blank">00:01:46.120</a></span> | <span class="t">or challenges that we should hopefully address to be able to further improve the state of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=111" target="_blank">00:01:51.920</a></span> | <span class="t">AI and our machine learning models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=113" target="_blank">00:01:53.620</a></span> | <span class="t">So, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=115" target="_blank">00:01:55.060</a></span> | <span class="t">Oops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=116" target="_blank">00:01:56.060</a></span> | <span class="t">I forgot I have control.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=118" target="_blank">00:01:58.000</a></span> | <span class="t">Yeah, so we'll start with some instructor introductions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=121" target="_blank">00:02:01.700</a></span> | <span class="t">So, we have a very good team of co-instructors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=125" target="_blank">00:02:05.320</a></span> | <span class="t">So, my name is Steven.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=128" target="_blank">00:02:08.600</a></span> | <span class="t">I'm a current third-year CS PhD here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=131" target="_blank">00:02:11.680</a></span> | <span class="t">Previously did my undergrad at Waterloo in Canada.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=134" target="_blank">00:02:14.800</a></span> | <span class="t">I've done some research in industry as well at Amazon and NVIDIA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=138" target="_blank">00:02:18.800</a></span> | <span class="t">And in general, my research sort of focuses, hovers around natural language processing, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=144" target="_blank">00:02:24.100</a></span> | <span class="t">machine learning for language and text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=145" target="_blank">00:02:25.860</a></span> | <span class="t">Looking at things like, can we improve the controllability and reasoning models of large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=150" target="_blank">00:02:30.320</a></span> | <span class="t">language models, and more recently, cognitive science and psychology-inspired work, especially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=156" target="_blank">00:02:36.120</a></span> | <span class="t">bringing the gap, the data gap, and the learning efficiencies between machine learning models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=161" target="_blank">00:02:41.080</a></span> | <span class="t">and how the humans learn, how human children learn, and how our brains are able to learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=165" target="_blank">00:02:45.600</a></span> | <span class="t">so efficiently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=166" target="_blank">00:02:46.140</a></span> | <span class="t">I've also done some work with multimodal, as well as computer vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=170" target="_blank">00:02:50.200</a></span> | <span class="t">So, things like diffusion models and image generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=172" target="_blank">00:02:52.580</a></span> | <span class="t">And just for fun, I also run the piano club here with Karan.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=176" target="_blank">00:02:56.460</a></span> | <span class="t">And we have an upcoming concert on April 11th, in case you guys are interested.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=179" target="_blank">00:02:59.920</a></span> | <span class="t">Hi, everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=185" target="_blank">00:03:05.000</a></span> | <span class="t">I'm Karan, a second-year electrical engineering PhD student.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=187" target="_blank">00:03:07.980</a></span> | <span class="t">I did my undergrad at Cal Poly San Luis Obispo, after which I was a research scientist here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=193" target="_blank">00:03:13.520</a></span> | <span class="t">not doing my PhD.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=194" target="_blank">00:03:14.800</a></span> | <span class="t">I'm a little bit more on the medical imaging and computer vision side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=198" target="_blank">00:03:18.460</a></span> | <span class="t">So, a lot of my current work is at the intersection of computer vision and neuroscience, working with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=204" target="_blank">00:03:24.360</a></span> | <span class="t">things like fMRI and ultrasound.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=205" target="_blank">00:03:25.960</a></span> | <span class="t">And I currently work at the STAI lab, a new lab, under Dr. Hassan Adeli.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=212" target="_blank">00:03:32.260</a></span> | <span class="t">Hi, everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=216" target="_blank">00:03:36.840</a></span> | <span class="t">I'm Chelsea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=217" target="_blank">00:03:37.580</a></span> | <span class="t">I'm a first-year master's student in symbolic systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=221" target="_blank">00:03:41.160</a></span> | <span class="t">And my general research interests are in multi-agentic frameworks, self-improving AI agents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=227" target="_blank">00:03:47.680</a></span> | <span class="t">and overall just kind of improving, like, the interpretability and explainability of models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=233" target="_blank">00:03:53.320</a></span> | <span class="t">So, previously, I studied applied math and neuroscience, and I did a bunch of, like, interdisciplinary research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=239" target="_blank">00:03:59.760</a></span> | <span class="t">in computer vision, robotics, cognitive science, things of that sort.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=245" target="_blank">00:04:05.160</a></span> | <span class="t">And currently, I'm working part-time at a VC firm, and over the summer, I'll be interning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=250" target="_blank">00:04:10.580</a></span> | <span class="t">at a conversational AI startup as a machine learning engineer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=254" target="_blank">00:04:14.540</a></span> | <span class="t">So, I'm very interested in exploring the startup scene here at Stanford, so feel free to reach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=259" target="_blank">00:04:19.700</a></span> | <span class="t">out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=259" target="_blank">00:04:19.940</a></span> | <span class="t">Hi, everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=262" target="_blank">00:04:22.400</a></span> | <span class="t">I'm Jenny.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=263" target="_blank">00:04:23.100</a></span> | <span class="t">I'm a current student majoring in SimSys, as well as a sociology co-term here at Stanford.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=268" target="_blank">00:04:28.120</a></span> | <span class="t">My background is primarily in technology ethics and policy, so if you have any questions or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=272" target="_blank">00:04:32.620</a></span> | <span class="t">want to talk about that, I'd love to have a conversation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=274" target="_blank">00:04:34.740</a></span> | <span class="t">In the past, I've worked doing product at DE Shaw and also research in the tech ethics and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=281" target="_blank">00:04:41.080</a></span> | <span class="t">policy space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=281" target="_blank">00:04:41.800</a></span> | <span class="t">And this summer, I'll be working at Daydream, which is an AI fashion tech startup in New York.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=286" target="_blank">00:04:46.560</a></span> | <span class="t">And so, yeah, so Div was unable to join us today, but he's working on his new agent startup</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=294" target="_blank">00:04:54.380</a></span> | <span class="t">called AGI Inc., currently on leave from a CS PhD here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=298" target="_blank">00:04:58.280</a></span> | <span class="t">He's passionate about, you know, robotics, AI agents, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=301" target="_blank">00:05:01.500</a></span> | <span class="t">And later this quarter, he'll likely be giving a lecture, actually, on everything to do with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=305" target="_blank">00:05:05.880</a></span> | <span class="t">AI agents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=306" target="_blank">00:05:06.500</a></span> | <span class="t">So, if you're interested in that, definitely look forward to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=309" target="_blank">00:05:09.040</a></span> | <span class="t">And previously, you know, he's worked at NVIDIA, Google, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=312" target="_blank">00:05:12.380</a></span> | <span class="t">And he's the one who sort of, you know, started this class in the first place.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=317" target="_blank">00:05:17.640</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=319" target="_blank">00:05:19.340</a></span> | <span class="t">So, I'll go over some of the course logistics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=322" target="_blank">00:05:22.200</a></span> | <span class="t">So, first announcement is we have a new website up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=325" target="_blank">00:05:25.180</a></span> | <span class="t">That's just cs25.stanford.edu.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=327" target="_blank">00:05:27.580</a></span> | <span class="t">And so, all of our updates and as well as the speaker lineup will be posted there in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=332" target="_blank">00:05:32.200</a></span> | <span class="t">coming weeks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=332" target="_blank">00:05:32.800</a></span> | <span class="t">That will also be the link to share our Zoom with people who are not Stanford-affiliated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=337" target="_blank">00:05:37.200</a></span> | <span class="t">or are on the wait list or have not been able to gain admission into the class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=340" target="_blank">00:05:40.660</a></span> | <span class="t">So, we encourage everyone to share this class with their network and ensure that anyone can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=346" target="_blank">00:05:46.020</a></span> | <span class="t">access it from Zoom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=347" target="_blank">00:05:47.480</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=348" target="_blank">00:05:48.000</a></span> | <span class="t">So, some takeaways from the course include a better understanding of transformers and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=352" target="_blank">00:05:52.880</a></span> | <span class="t">the underlying architecture of many of our large language models, guest speakers, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=358" target="_blank">00:05:58.060</a></span> | <span class="t">will be talking about applications in language, vision, biology, robotics, and more, exposure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=363" target="_blank">00:06:03.620</a></span> | <span class="t">to new research, especially from leading researchers all across the country, innovative methods that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=369" target="_blank">00:06:09.960</a></span> | <span class="t">are driving the next generation of models, as well as key limitations, open problems, and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=375" target="_blank">00:06:15.220</a></span> | <span class="t">future of AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=376" target="_blank">00:06:16.240</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=383" target="_blank">00:06:23.180</a></span> | <span class="t">Next, I'll give a really brief intro about transformers and how attention works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=387" target="_blank">00:06:27.340</a></span> | <span class="t">So, the first step for language is word embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=392" target="_blank">00:06:32.960</a></span> | <span class="t">So, words aren't numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=395" target="_blank">00:06:35.080</a></span> | <span class="t">So, we obviously can't just pass them into a model as is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=398" target="_blank">00:06:38.180</a></span> | <span class="t">So, the first step is converting them into dense vectors in a high-dimensional space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=402" target="_blank">00:06:42.020</a></span> | <span class="t">This is done through various methods, but the goal is to capture semantic similarity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=407" target="_blank">00:06:47.100</a></span> | <span class="t">Essentially, that cat and dog are more similar than cat and car, even though the latter is more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=412" target="_blank">00:06:52.680</a></span> | <span class="t">similar from a character standpoint.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=413" target="_blank">00:06:53.900</a></span> | <span class="t">Doing so enables visualization learning with transformer models or arithmetic, like I've shown,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=421" target="_blank">00:07:01.020</a></span> | <span class="t">like king minus man plus queen would approximately be queen in some embedding space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=425" target="_blank">00:07:05.560</a></span> | <span class="t">And classical methods for this are like word to vec, fast text, and many more these days.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=431" target="_blank">00:07:11.560</a></span> | <span class="t">But static embeddings, for instance, giving the word bank the same meaning in just bank as in riverbank,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=440" target="_blank">00:07:20.600</a></span> | <span class="t">have limitations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=442" target="_blank">00:07:22.460</a></span> | <span class="t">Therefore, the current standard is using contextual embeddings, which take into account the context and the sentence that a word is in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=450" target="_blank">00:07:30.160</a></span> | <span class="t">Self-attention can be applied to this to learn what to focus on for a given token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=457" target="_blank">00:07:37.240</a></span> | <span class="t">So, to do this, you learn three matrices, a query, key, and value, which together comprise the attention process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=466" target="_blank">00:07:46.100</a></span> | <span class="t">A quick analogy for this is imagine you're in a library looking for a book on a certain topic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=471" target="_blank">00:07:51.860</a></span> | <span class="t">This would be your query.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=472" target="_blank">00:07:52.900</a></span> | <span class="t">Now, let's say each book has some summary associated with it, a key.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=479" target="_blank">00:07:59.340</a></span> | <span class="t">You can match your query and key and get access to the book that you're looking for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=484" target="_blank">00:08:04.700</a></span> | <span class="t">The information inside the book would be your value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=487" target="_blank">00:08:07.260</a></span> | <span class="t">So, in attention, we do a soft match over the values to get info from, say, multiple books.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=494" target="_blank">00:08:14.980</a></span> | <span class="t">And this comprises the attention operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=500" target="_blank">00:08:20.060</a></span> | <span class="t">And, as you can see in this visualization, when you apply this to language, you can see that across different layers of the model, different words have connections to the rest of the words in the sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=514" target="_blank">00:08:34.220</a></span> | <span class="t">The next component is positional encodings or embeddings, which add order to the sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=519" target="_blank">00:08:39.860</a></span> | <span class="t">Without these, the model, since you have just linear multiplications here, would not know what the first or the last word in the sentence is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=529" target="_blank">00:08:49.060</a></span> | <span class="t">Therefore, you add some notion of order through, say, sinusoids.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=533" target="_blank">00:08:53.600</a></span> | <span class="t">Or in the simplest form, you could think that the first word would be a zero, the second one a one, and on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=538" target="_blank">00:08:58.480</a></span> | <span class="t">Beyond this is basically just scaling through multiple layers and multi-head attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=545" target="_blank">00:09:05.340</a></span> | <span class="t">More heads to tend to different parts of the sentence and more parameters means that you can capture more diverse relationships from your sequences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=554" target="_blank">00:09:14.100</a></span> | <span class="t">And this gives you the final transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=556" target="_blank">00:09:16.100</a></span> | <span class="t">Transformers today have overtaken pretty much every field, from LLMs like GPT-400, O3, Deep Seek, to Vision, with models that are getting increasingly better at segmentation and whatnot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=572" target="_blank">00:09:32.580</a></span> | <span class="t">Speech, biology, video, you'll see a lot of these applications throughout the quarter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=578" target="_blank">00:09:38.600</a></span> | <span class="t">With large language models, these are essentially just scaled-up versions of attention and the transformer architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=585" target="_blank">00:09:45.720</a></span> | <span class="t">You essentially just throw a large amount of data, general text data derived from the web, at these models, and they can learn very well to model through a next-token prediction objective language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=599" target="_blank">00:09:59.040</a></span> | <span class="t">And as you scale up, we've seen that emergent abilities pop up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=602" target="_blank">00:10:02.560</a></span> | <span class="t">So while at a smaller scale, you might not be able to do a certain task, once you get to a certain scale, you just have a peak in the ability to do that task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=611" target="_blank">00:10:11.780</a></span> | <span class="t">Some disadvantages, though, are that these models have very high computational costs and, therefore, also concerns like with climate and the carbon emissions they may produce.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=623" target="_blank">00:10:23.380</a></span> | <span class="t">And, like I was mentioning, with larger models, they're very good at generalizing to many abilities or tasks, and they're essentially plug-and-play with fewer zero-shot learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=640" target="_blank">00:10:40.260</a></span> | <span class="t">All right, so now I'll talk a bit more about pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=642" target="_blank">00:10:42.880</a></span> | <span class="t">So as Karan explained how the transformer works, but typically with a language model, especially a large language model, you typically divide it into two stages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=652" target="_blank">00:10:52.140</a></span> | <span class="t">Pre-training stage, where you sort of train the neural network from scratch, from randomized or initialized weights, randomly initialized weights, to give them more general capabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=661" target="_blank">00:11:01.640</a></span> | <span class="t">And a big portion of this is the data itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=664" target="_blank">00:11:04.900</a></span> | <span class="t">So the data is sort of the fundamental fuel that sort of allows your model to learn, because that's what the model is learning from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=672" target="_blank">00:11:12.000</a></span> | <span class="t">So your goal, typically, again, like I said with pre-training, is to train on a large amount of data to obtain some sort of general level of capabilities and overall knowledge or intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=684" target="_blank">00:11:24.160</a></span> | <span class="t">And this is arguably, again, the most important aspect of training, especially pre-training, especially because LLMs learn, again, based on statistical distributions, predicting the next token, given previous tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=696" target="_blank">00:11:36.500</a></span> | <span class="t">So to effectively learn this, you typically need a large amount of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=701" target="_blank">00:11:41.300</a></span> | <span class="t">So because of its importance, you know, how do we maximally leverage it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=705" target="_blank">00:11:45.240</a></span> | <span class="t">So, again, smart data strategies for pre-training is definitely one of the most important topics these days.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=714" target="_blank">00:11:54.460</a></span> | <span class="t">So I'll briefly touch upon two of the top projects I recently worked on, on two different scales.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=719" target="_blank">00:11:59.560</a></span> | <span class="t">The first is looking at, you know, what makes small, childlike data sets potentially effective for language learning, especially on the smaller scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=727" target="_blank">00:12:07.260</a></span> | <span class="t">And the second is looking at smart data strategies for training large models on billions or trillions of tokens, which is on the much larger scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=739" target="_blank">00:12:19.620</a></span> | <span class="t">So sort of why are humans able to learn so efficiently?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=743" target="_blank">00:12:23.800</a></span> | <span class="t">This kind of looks at, you know, like how human children learn and interact with the environment and learn language compared to a model like ChadGPT, which is a bit analogous to, you know, how the human brain learns language and learns in general compared to something like a neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=758" target="_blank">00:12:38.800</a></span> | <span class="t">So some potential key differences are that humans learn continuously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=762" target="_blank">00:12:42.500</a></span> | <span class="t">We're continually learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=764" target="_blank">00:12:44.180</a></span> | <span class="t">We don't just, you know, pre-train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=765" target="_blank">00:12:45.860</a></span> | <span class="t">We don't just sit in a chair, have someone read the whole internet to us, and then we kind of just stop learning from there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=770" target="_blank">00:12:50.600</a></span> | <span class="t">So that's unlike a lot of current models, which are more single-pass pre-training models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=776" target="_blank">00:12:56.260</a></span> | <span class="t">Further, we have more goal-based approaches to learning and interaction with the environment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=782" target="_blank">00:13:02.220</a></span> | <span class="t">That's a major reason we learn, whereas, again, these models are typically just pre-training on large amounts of data using next-token prediction or auto-regression.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=789" target="_blank">00:13:09.720</a></span> | <span class="t">Further, we learn through continuous multimodal or multisensory data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=793" target="_blank">00:13:13.800</a></span> | <span class="t">So it's not just text only.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=795" target="_blank">00:13:15.400</a></span> | <span class="t">We're subconsciously exposed to, you know, probably hundreds of senses that sort of guide the way we learn and sort of approach our daily lives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=803" target="_blank">00:13:23.680</a></span> | <span class="t">Further, I believe our brains are fundamentally different in that we learn probably in more structured or hierarchical manners.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=810" target="_blank">00:13:30.040</a></span> | <span class="t">For example, through compositionality rather than, again, simply next-token prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=814" target="_blank">00:13:34.220</a></span> | <span class="t">And the focus of this project in particular is more on the data differences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=818" target="_blank">00:13:38.420</a></span> | <span class="t">So, again, humans are exposed to, you know, dialogue from people we talk to, storybooks, especially children coming up, compared to, you know, large amounts of data on the internet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=832" target="_blank">00:13:52.060</a></span> | <span class="t">So this is a work that was published.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=834" target="_blank">00:13:54.060</a></span> | <span class="t">So why do we care about small models and training on small amounts of data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=839" target="_blank">00:13:59.140</a></span> | <span class="t">Well, this will really improve the efficiency of training and using large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=843" target="_blank">00:14:03.320</a></span> | <span class="t">And this will open the door to potential new use cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=846" target="_blank">00:14:06.100</a></span> | <span class="t">For example, models that can run on your phone that you can run locally and so forth for many different use cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=852" target="_blank">00:14:12.060</a></span> | <span class="t">Smaller models and train on less data are also more interpretable and easier to sort of control or align, whether it's for safety purposes, to reduce bias, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=861" target="_blank">00:14:21.820</a></span> | <span class="t">To ensure, you know, people are using them for safe reasons and you have appropriate guardrails in place.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=867" target="_blank">00:14:27.600</a></span> | <span class="t">This will also enhance the open source availability, allowing research and the usage of these models for more people around the world, rather than simply companies with large amounts of compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=878" target="_blank">00:14:38.020</a></span> | <span class="t">And in general, this might even allow us to more greatly understand the other direction, which is how humans are able to learn so effectively and efficiently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=889" target="_blank">00:14:49.360</a></span> | <span class="t">Yep, so this work is titled is Child Directed Speech Effective Training Data for Language Models, which I presented at EMNLP in Miami last November.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=898" target="_blank">00:14:58.080</a></span> | <span class="t">So again, the sort of hypothesis here is that children, you know, we sort of probably learn fundamentally different from LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=905" target="_blank">00:15:05.660</a></span> | <span class="t">This is why we're able to learn on several magnitudes less language data in particular than many of these large language models these days, which require trillions of tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=913" target="_blank">00:15:13.780</a></span> | <span class="t">Now, there's several hypotheses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=915" target="_blank">00:15:15.740</a></span> | <span class="t">One is the data we receive as humans is different fundamentally from LLMs, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=921" target="_blank">00:15:21.640</a></span> | <span class="t">Rather than just training on internet data, you know, we actually interact with people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=925" target="_blank">00:15:25.080</a></span> | <span class="t">We talk to people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=925" target="_blank">00:15:25.960</a></span> | <span class="t">We hear stories that our parents or teachers tell us and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=932" target="_blank">00:15:32.000</a></span> | <span class="t">The other is maybe the human brain just fundamentally learns different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=935" target="_blank">00:15:35.960</a></span> | <span class="t">So our learning algorithm is just different from large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=939" target="_blank">00:15:39.200</a></span> | <span class="t">And another is maybe it's the way or the structure in which we receive this data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=943" target="_blank">00:15:43.940</a></span> | <span class="t">So any data we receive is somewhat curricularized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=947" target="_blank">00:15:47.380</a></span> | <span class="t">We start off with simple data, simple language as a child.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=951" target="_blank">00:15:51.220</a></span> | <span class="t">And then, you know, learn more complex grammars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=953" target="_blank">00:15:53.680</a></span> | <span class="t">We hear more complex speech from our parents, coworkers, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=959" target="_blank">00:15:59.020</a></span> | <span class="t">Anything we do, whether it's learning math, you know, we start simple and then, you know, move on to more difficult problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=964" target="_blank">00:16:04.460</a></span> | <span class="t">Whereas language models, you typically don't care too much about ordering or curriculum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=968" target="_blank">00:16:08.300</a></span> | <span class="t">So there's multiple different hypotheses here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=970" target="_blank">00:16:10.740</a></span> | <span class="t">So in order to test some of these, what we did is we trained some small GPT-2 and Roberta models on five different data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=977" target="_blank">00:16:17.380</a></span> | <span class="t">One is Childess, which is a natural conversation data with children.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=982" target="_blank">00:16:22.600</a></span> | <span class="t">So this is transcribed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=983" target="_blank">00:16:23.540</a></span> | <span class="t">And then we collected a synthetic version called Tiny Dialogues, which I'll discuss more later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=988" target="_blank">00:16:28.120</a></span> | <span class="t">Baby LM, which is a diverse mixture of different types of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=992" target="_blank">00:16:32.100</a></span> | <span class="t">This includes Reddit data, Wikipedia data, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=994" target="_blank">00:16:34.640</a></span> | <span class="t">So this is closer to your typical large language model pre-training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=999" target="_blank">00:16:39.000</a></span> | <span class="t">And then we also did a bit of testing with Wikipedia as well as open subtitles, so movie and TV transcriptions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1005" target="_blank">00:16:45.480</a></span> | <span class="t">So we collected Tiny Dialogues, and this was inspired by the fact that, you know, a lot of, again, I said our learning as children is through conversations with other people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1015" target="_blank">00:16:55.980</a></span> | <span class="t">And conversations naturally lead to learning, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1018" target="_blank">00:16:58.680</a></span> | <span class="t">We talk to someone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1019" target="_blank">00:16:59.900</a></span> | <span class="t">They give us feedback.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1020" target="_blank">00:17:00.640</a></span> | <span class="t">We reflect on how the conversation went.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1022" target="_blank">00:17:02.380</a></span> | <span class="t">So it's both pure and self-reflection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1025" target="_blank">00:17:05.920</a></span> | <span class="t">Furthermore, conversations lead to not only learning of knowledge, but other things like ethics and morals.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1030" target="_blank">00:17:10.640</a></span> | <span class="t">For example, parents or teachers, you know, telling us as children, you know, what's right or wrong to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1035" target="_blank">00:17:15.580</a></span> | <span class="t">And there's many different types of conversations you can have with many different types of people, leading to a lot of diversity in learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1042" target="_blank">00:17:22.660</a></span> | <span class="t">So what we did is we collected a fully grammatical and curricularized conversation data set with a limited childlike restrictive vocabulary using GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1051" target="_blank">00:17:31.120</a></span> | <span class="t">And we collected different examples that differ by child age, the different participants in the conversation, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1059" target="_blank">00:17:39.720</a></span> | <span class="t">And here's just some examples of some data points in our collected data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1066" target="_blank">00:17:46.440</a></span> | <span class="t">So you see, as the age goes up, you know, the utterances or conversations become more complex.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1071" target="_blank">00:17:51.520</a></span> | <span class="t">They become longer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1072" target="_blank">00:17:52.300</a></span> | <span class="t">The participants also differ by age appropriately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1077" target="_blank">00:17:57.700</a></span> | <span class="t">So we also ran an experiment, a curriculum experiment, where we ordered either by ascending age order, you know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1086" target="_blank">00:18:06.420</a></span> | <span class="t">So the model will first see two-year-old conversations, and then five-year-old conversations, and then 10-year-old, and so forth, versus descending order.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1095" target="_blank">00:18:15.220</a></span> | <span class="t">Maybe it's possible a language model might actually learn somehow better from more complex examples first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1100" target="_blank">00:18:20.600</a></span> | <span class="t">And then, of course, the typical baseline of randomly shuffling all your data examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1104" target="_blank">00:18:24.680</a></span> | <span class="t">So we have some basic evaluation metrics targeted at fundamental capabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1110" target="_blank">00:18:30.340</a></span> | <span class="t">One is basic grammatical and syntactic knowledge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1113" target="_blank">00:18:33.260</a></span> | <span class="t">And there's another is a free word association metric called word similarity for assessing more semantic knowledge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1120" target="_blank">00:18:40.580</a></span> | <span class="t">So you see here from the different data sets that actually it seems like training on child-like data is worse than a heterogeneous mixture of just internet data like BabyLM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1129" target="_blank">00:18:49.320</a></span> | <span class="t">So both metrics degrade quite substantially, especially on child-like data sets, the more natural conversation data set between children and their caregivers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1139" target="_blank">00:18:59.380</a></span> | <span class="t">And you'll see in terms of curriculum, we don't see many substantial differences, no matter what order you sort of provide the examples into the model, which is, again, surprising.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1150" target="_blank">00:19:10.060</a></span> | <span class="t">Because as humans, you know, we sort of go from simple to more difficult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1152" target="_blank">00:19:12.920</a></span> | <span class="t">So looking more closely at sort of convergence behavior or loss curves, you'll see here that the training loss sort of has these sorts of cyclical pattern, depending on the sort of buckets you use for curriculum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1172" target="_blank">00:19:32.060</a></span> | <span class="t">But the validation loss, which is what you really care about, so the generalization and learning, it has the exact same trend no matter what order you feed the examples in, which is, again, a very interesting sort of finding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1183" target="_blank">00:19:43.500</a></span> | <span class="t">So overall, we see that diverse data sources like BabyLM seem to provide a better learning signal for language models than purely child-directed speech.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1191" target="_blank">00:19:51.800</a></span> | <span class="t">We do see, however, that our tiny dialogues data set noticeably outperforms the natural conversation data set, likely because that data set is very noisy, whereas ours is, again, synthetically collected by GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1202" target="_blank">00:20:02.820</a></span> | <span class="t">And, again, global developmental ordering using curriculum learning seems to have negligible impact on performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1208" target="_blank">00:20:08.740</a></span> | <span class="t">So overall, we can kind of sort of conclude that it's possible that other aspects of children's learning, not simply the data they're exposed to, are responsible for their efficient language learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1219" target="_blank">00:20:19.400</a></span> | <span class="t">For example, learning from other types of information, like multimodal information, or it's the fact that our learning algorithm in our brain is just fundamentally different and more data efficient than language modeling techniques.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1231" target="_blank">00:20:31.020</a></span> | <span class="t">So if you wish to learn more, we have our data sets released on Hugging Face, as well as GitHub, and the papers up on Archive, as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1243" target="_blank">00:20:43.860</a></span> | <span class="t">So now let's go bigger scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1245" target="_blank">00:20:45.560</a></span> | <span class="t">So we were investigating, you know, small models trained on small amounts of data similar to a human child.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1250" target="_blank">00:20:50.660</a></span> | <span class="t">Now what about current large models, billions of parameters trained on trillions of tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1255" target="_blank">00:20:55.040</a></span> | <span class="t">So I recently, during my last summer internship, I worked on a project with NVIDIA titled Maximize Your Data's Potential, Enhancing LLM Accuracy with Two-Phase Pre-Training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1265" target="_blank">00:21:05.860</a></span> | <span class="t">So this is to sort of optimize data selection, as well as training strategies and large scale pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1272" target="_blank">00:21:12.660</a></span> | <span class="t">So a lot of works like LLAMA highlighted the effectiveness of, you know, different sorts of data mixtures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1277" target="_blank">00:21:17.640</a></span> | <span class="t">But they don't really shed light into the exact mixtures and how these decisions were made.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1282" target="_blank">00:21:22.920</a></span> | <span class="t">Whereas we know, you know, data blending and ordering is crucial to effective LLM pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1289" target="_blank">00:21:29.040</a></span> | <span class="t">So can we shed more light on this, which is what our work does?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1292" target="_blank">00:21:32.020</a></span> | <span class="t">So firstly, we sort of formalize and systematically evaluate this concept of two-phase pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1297" target="_blank">00:21:37.200</a></span> | <span class="t">And we show that empirically it improves over continuous training, which is typically what's done with LLM training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1303" target="_blank">00:21:43.720</a></span> | <span class="t">And you just feed in all the data rather than separating it into, you know, particular buckets or a different schedule.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1309" target="_blank">00:21:49.960</a></span> | <span class="t">We also do a fine-grade analysis of data blending for these two pre-training phases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1314" target="_blank">00:21:54.580</a></span> | <span class="t">And we sort of have this notion of prototyping blends on smaller token counts before scaling up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1321" target="_blank">00:22:01.400</a></span> | <span class="t">So this two-phase pre-training approach, it's sort of inspired kind of, you know, by how pre-training and post-training works,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1328" target="_blank">00:22:08.180</a></span> | <span class="t">which is the first phase is on more general data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1331" target="_blank">00:22:11.100</a></span> | <span class="t">So this is to learn more broadly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1333" target="_blank">00:22:13.200</a></span> | <span class="t">So it's on more diverse data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1335" target="_blank">00:22:15.100</a></span> | <span class="t">And the second is to shift to more high-quality domain-specific data, such as math and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1340" target="_blank">00:22:20.480</a></span> | <span class="t">However, it's important to sort of balance between quality and diversity in both phases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1344" target="_blank">00:22:24.720</a></span> | <span class="t">as if you upweight any data set too much, it can lead to overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1348" target="_blank">00:22:28.480</a></span> | <span class="t">So firstly, does two-phase training actually help?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1353" target="_blank">00:22:33.980</a></span> | <span class="t">So we found that, you know, all our phase two blends or our two-phase pre-training experiments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1360" target="_blank">00:22:40.440</a></span> | <span class="t">outperform the baseline of simply just continuing training on a single phase.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1364" target="_blank">00:22:44.740</a></span> | <span class="t">And this is noticeably better than just the randomized mixture of both phases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1368" target="_blank">00:22:48.700</a></span> | <span class="t">as well as the natural data distribution compared to our sort of upsample data distribution for phase two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1374" target="_blank">00:22:54.800</a></span> | <span class="t">And we also showed that this is able to scale, both on model scale and data scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1380" target="_blank">00:23:00.500</a></span> | <span class="t">So if you blow up the token counts, as well as the model size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1383" target="_blank">00:23:03.000</a></span> | <span class="t">we show that performance further improves with our two-phase pre-training compared to a single phase.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1389" target="_blank">00:23:09.300</a></span> | <span class="t">So this kind of highlights also the effectiveness of prototyping on smaller data blends before scaling up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1396" target="_blank">00:23:16.260</a></span> | <span class="t">And furthermore, we investigated sort of the duration of phase two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1401" target="_blank">00:23:21.840</a></span> | <span class="t">So, you know, should we train on diverse data for a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1405" target="_blank">00:23:25.700</a></span> | <span class="t">and immediately switch to, you know, highly specialized data like math?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1408" target="_blank">00:23:28.600</a></span> | <span class="t">Or should we wait longer?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1410" target="_blank">00:23:30.040</a></span> | <span class="t">And what we found is performance improves up to a point around 40%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1413" target="_blank">00:23:33.220</a></span> | <span class="t">until there's diminishing returns likely from overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1415" target="_blank">00:23:35.900</a></span> | <span class="t">Because specialized data, you know, it's more specialized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1418" target="_blank">00:23:38.380</a></span> | <span class="t">It's more, there's typically a lower number of it, and it's less diverse compared to things like, you know, web crawl data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1424" target="_blank">00:23:44.880</a></span> | <span class="t">So too much of it can lead to detrimental or diminishing returns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1430" target="_blank">00:23:50.560</a></span> | <span class="t">So overall, we see a well-structured two-phase pre-training approach with careful data selection and management</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1436" target="_blank">00:23:56.300</a></span> | <span class="t">is essential for optimizing LLM performance while maintaining scalability and robustness across different downstream tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1443" target="_blank">00:24:03.500</a></span> | <span class="t">And in case you're interested, this paper is also pre-print is up on archive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1448" target="_blank">00:24:08.520</a></span> | <span class="t">So overall, I guess the overall takeaway from these two projects and what I wanted to get at is, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1454" target="_blank">00:24:14.960</a></span> | <span class="t">on the fact that data effectiveness, especially for pre-training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1458" target="_blank">00:24:18.740</a></span> | <span class="t">it's not just the amount of data, but it's about, you know, the quality of the data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1462" target="_blank">00:24:22.300</a></span> | <span class="t">the ordering and structure of data, and how exactly you use it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1464" target="_blank">00:24:24.880</a></span> | <span class="t">So for our first project, we saw there's negligible impact of global order in small-scale training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1470" target="_blank">00:24:30.500</a></span> | <span class="t">But we saw that phase-based training for larger scales is highly effective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1474" target="_blank">00:24:34.640</a></span> | <span class="t">And in general, smart data decisions are essential for models to generalize across tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1479" target="_blank">00:24:39.260</a></span> | <span class="t">So sort of takeaway is our research underscores that effective language modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1484" target="_blank">00:24:44.260</a></span> | <span class="t">isn't just about amassing data, but about smarter data organization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1488" target="_blank">00:24:48.000</a></span> | <span class="t">that harnesses its structure, quality, and characteristics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1490" target="_blank">00:24:50.860</a></span> | <span class="t">And by continuing to sort of refine data-centric approaches,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1494" target="_blank">00:24:54.140</a></span> | <span class="t">the future of LLM training promises smarter, more efficient, and highly adaptable models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1499" target="_blank">00:24:59.720</a></span> | <span class="t">So now we'll be moving to sort of the second stage after pre-training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1504" target="_blank">00:25:04.760</a></span> | <span class="t">which is post-training, which Chelsea will talk about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1508" target="_blank">00:25:08.500</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1509" target="_blank">00:25:09.240</a></span> | <span class="t">So we have a pre-trained model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1511" target="_blank">00:25:11.120</a></span> | <span class="t">Now what?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1512" target="_blank">00:25:12.120</a></span> | <span class="t">Like, how do we adapt to specific tasks and different domains?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1516" target="_blank">00:25:16.300</a></span> | <span class="t">So some major strategies include fine-tuning, for instance, like reinforcement learning with human feedback,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1523" target="_blank">00:25:23.560</a></span> | <span class="t">or some prompt-based methods, or some sort of, like, RAG architecture and retrieval-based methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1538" target="_blank">00:25:38.420</a></span> | <span class="t">So one major approach is called chain-of-thought reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1541" target="_blank">00:25:41.420</a></span> | <span class="t">I'm sure you all have heard of it by now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1543" target="_blank">00:25:43.800</a></span> | <span class="t">So it's essentially a prompting technique to think step-by-step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1548" target="_blank">00:25:48.000</a></span> | <span class="t">So it shows the intermediate steps provide guidance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1552" target="_blank">00:25:52.240</a></span> | <span class="t">And this is sort of similar to the way how humans think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1555" target="_blank">00:25:55.760</a></span> | <span class="t">We can imagine that we typically break down a problem into subsequent steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1561" target="_blank">00:26:01.320</a></span> | <span class="t">to help us better understand the problem itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1563" target="_blank">00:26:03.900</a></span> | <span class="t">And another benefit of chain-of-thought is that it allows some sort of interpretable window</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1570" target="_blank">00:26:10.900</a></span> | <span class="t">into the behavior of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1572" target="_blank">00:26:12.460</a></span> | <span class="t">And this can kind of suggest that there is more knowledge embedded in the model's weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1578" target="_blank">00:26:18.300</a></span> | <span class="t">than just prompting a response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1580" target="_blank">00:26:20.480</a></span> | <span class="t">So this here is an example of chain-of-thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1588" target="_blank">00:26:28.320</a></span> | <span class="t">On the left, we have it solve a problem in, like, a one-shot manner,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1593" target="_blank">00:26:33.220</a></span> | <span class="t">which turns out to get to the wrong answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1595" target="_blank">00:26:35.800</a></span> | <span class="t">And on the right over there, it produces a sequence of reasoning chains,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1600" target="_blank">00:26:40.920</a></span> | <span class="t">and ultimately it arrives at the correct answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1604" target="_blank">00:26:44.100</a></span> | <span class="t">So naturally, this brings up an extension of chain-of-thought, which is called a tree-of-thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1616" target="_blank">00:26:56.940</a></span> | <span class="t">And this is another prompting technique.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1618" target="_blank">00:26:58.940</a></span> | <span class="t">But instead of producing a singular reasoning path, as a chain-of-thought does,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1623" target="_blank">00:27:03.880</a></span> | <span class="t">it considers multiple reasoning trajectories and then uses some sort of self-evaluation process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1630" target="_blank">00:27:10.720</a></span> | <span class="t">to kind of decide on the final outputs, such as, like, majority voting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1635" target="_blank">00:27:15.240</a></span> | <span class="t">So in the picture, you can see that tree-of-thought kind of generates, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1639" target="_blank">00:27:19.260</a></span> | <span class="t">different reasoning paths and selects the best one at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1648" target="_blank">00:27:28.500</a></span> | <span class="t">So another way is through program-of-thought, and this basically generates code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1654" target="_blank">00:27:34.040</a></span> | <span class="t">as the intermediate reasoning steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1656" target="_blank">00:27:36.260</a></span> | <span class="t">And overall, what this does is that it offloads some sort of problem-solving technique</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1662" target="_blank">00:27:42.320</a></span> | <span class="t">to some code interpreter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1665" target="_blank">00:27:45.740</a></span> | <span class="t">So it formalizes language into programs to arrive at more precise answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1671" target="_blank">00:27:51.160</a></span> | <span class="t">So we have seen that this sort of problem decomposition seems helpful for different tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1685" target="_blank">00:28:05.200</a></span> | <span class="t">So one way is through Socratic questioning, which is basically using a self-questioning module</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1692" target="_blank">00:28:12.160</a></span> | <span class="t">to propose sub-problems related to the original and solves those in, like, a recursive sort of manner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1698" target="_blank">00:28:18.040</a></span> | <span class="t">So, for instance, if the question is, like, what fills the balloons,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1703" target="_blank">00:28:23.180</a></span> | <span class="t">this kind of leads to the next sub-question, which is, like, what can make a balloon float?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1707" target="_blank">00:28:27.700</a></span> | <span class="t">And then by decomposing the original problem into, like, subsequent problems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1712" target="_blank">00:28:32.680</a></span> | <span class="t">it can better solve at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1716" target="_blank">00:28:36.280</a></span> | <span class="t">So finally, another problem decomposition method is through computational graphs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1727" target="_blank">00:28:47.540</a></span> | <span class="t">So this basically formulates compositional tasks as a computation graph</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1732" target="_blank">00:28:52.820</a></span> | <span class="t">by breaking down the reasoning into different sub-procedures and nodes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1738" target="_blank">00:28:58.520</a></span> | <span class="t">So the key takeaway here is that transformers can solve compositional tasks by reducing reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1745" target="_blank">00:29:05.100</a></span> | <span class="t">into sub-graphs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1746" target="_blank">00:29:06.780</a></span> | <span class="t">And this is, like, without developing some sort of systematic problem-solving skill.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1752" target="_blank">00:29:12.260</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1753" target="_blank">00:29:13.120</a></span> | <span class="t">So Chelsea sort of touched on chain of thought and everything that sort of expands upon it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1757" target="_blank">00:29:17.740</a></span> | <span class="t">or improves it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1758" target="_blank">00:29:18.480</a></span> | <span class="t">And that's sort of mainly a prompting-based method for inference time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1762" target="_blank">00:29:22.640</a></span> | <span class="t">Next, I'll be talking more at reinforcement learning and feedback mechanisms,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1766" target="_blank">00:29:26.360</a></span> | <span class="t">which are typically used for things like further fine-tuning a pre-trained model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1770" target="_blank">00:29:30.240</a></span> | <span class="t">So the most popular is this thing called reinforcement learning with human feedback,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1774" target="_blank">00:29:34.160</a></span> | <span class="t">or RLHF.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1775" target="_blank">00:29:35.700</a></span> | <span class="t">So this trains a reward model directly from human feedback.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1778" target="_blank">00:29:38.640</a></span> | <span class="t">So what you sort of do is you take your pre-trained model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1781" target="_blank">00:29:41.000</a></span> | <span class="t">get it to generate several responses,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1782" target="_blank">00:29:42.500</a></span> | <span class="t">and then you typically take a pair of responses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1785" target="_blank">00:29:45.620</a></span> | <span class="t">and have humans sort of rate which one they prefer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1787" target="_blank">00:29:47.960</a></span> | <span class="t">And you can sort of train a reward model based on this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1791" target="_blank">00:29:51.240</a></span> | <span class="t">basically using a reinforcement learning optimization algorithm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1794" target="_blank">00:29:54.760</a></span> | <span class="t">such as PPO.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1795" target="_blank">00:29:55.500</a></span> | <span class="t">Now, there's an improvement to PPO called DPO, or direct preference optimization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1802" target="_blank">00:30:02.600</a></span> | <span class="t">So this sort of more directly trains the model to prefer outputs that humans rank higher</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1806" target="_blank">00:30:06.820</a></span> | <span class="t">compared to having a separate reward model, which is much more efficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1810" target="_blank">00:30:10.680</a></span> | <span class="t">So basically, it actually gets sort of, you can think of it as it sort of more closely ties the reward directly into the loss function itself by helping the LLM to maximize the likelihood of generating preferred responses and minimize the likelihood of the responses that the humans did not prefer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1831" target="_blank">00:30:31.580</a></span> | <span class="t">And there's a sort of extension to RLHF, which is called RLAIF.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1835" target="_blank">00:30:35.380</a></span> | <span class="t">So this is simply replacing the human with an AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1838" target="_blank">00:30:38.400</a></span> | <span class="t">So you typically have a pretty good LLM that's able to provide accurate preference judgments of which response it prefers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1846" target="_blank">00:30:46.180</a></span> | <span class="t">And this is less costly, basically, compared to human annotators.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1851" target="_blank">00:30:51.100</a></span> | <span class="t">And then you basically, you do the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1852" target="_blank">00:30:52.580</a></span> | <span class="t">You train a reward model based on the LLM's preferences instead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1858" target="_blank">00:30:58.220</a></span> | <span class="t">And they found that actually human evaluators found that RLAIF-tuned outputs were around similar to RLHF, showing that this is a more scalable and cost-efficient approach compared to human feedback.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1871" target="_blank">00:31:11.540</a></span> | <span class="t">But there's one sort of disadvantage here, which is it really depends on the capabilities or the sort of accuracy of judgments of the LLM you're using to provide your preferences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1881" target="_blank">00:31:21.520</a></span> | <span class="t">So if you're using one that is sort of incapable or very noisy, then that's going to hurt your post-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1890" target="_blank">00:31:30.580</a></span> | <span class="t">The next is this thing sort of very hot now, which was used in DeepSeq.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1897" target="_blank">00:31:37.420</a></span> | <span class="t">Both there are one as well as some other models like the math ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1901" target="_blank">00:31:41.480</a></span> | <span class="t">So this is called Group Relative Policy Optimization, or GRPO.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1905" target="_blank">00:31:45.640</a></span> | <span class="t">So this is a variant of the PPO optimization algorithm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1908" target="_blank">00:31:48.940</a></span> | <span class="t">But rather than ranking simply pairs of responses, it actually ranks a group of responses in a different order.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1917" target="_blank">00:31:57.920</a></span> | <span class="t">So this provides richer feedback, which is more fine-grained and is much more sort of efficient compared to simply ranking pairs of outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1925" target="_blank">00:32:05.880</a></span> | <span class="t">So this helps stabilize training, which is one reason DeepSeq is very...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1931" target="_blank">00:32:11.420</a></span> | <span class="t">Much more data and compute efficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1933" target="_blank">00:32:13.980</a></span> | <span class="t">And also, they saw that it improves even things like LLM reasoning, especially on things like math.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1940" target="_blank">00:32:20.760</a></span> | <span class="t">There's also been other variations of, you know, RLHF and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1948" target="_blank">00:32:28.220</a></span> | <span class="t">One is this thing called Kahneman-Tversky Optimization, not sure if I'm pronouncing that correctly, but KTO.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1954" target="_blank">00:32:34.380</a></span> | <span class="t">So this modifies the standard loss function typically used in post-training things to account for human biases, such as loss aversion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1963" target="_blank">00:32:43.380</a></span> | <span class="t">So as humans, you know, we typically care more about minimizing disastrous or negative outcomes than achieving positive ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1971" target="_blank">00:32:51.240</a></span> | <span class="t">We're more risk-averse in the most case, although it's very dependent on the person.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1975" target="_blank">00:32:55.720</a></span> | <span class="t">So they encourage the AI to sort of behave in a similar manner by avoiding negative outcomes, and this basically adjusts the training process to reflect this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1985" target="_blank">00:33:05.060</a></span> | <span class="t">And they show that this is able to sort of improve performance on different tasks, although it kind of depends on the task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1992" target="_blank">00:33:12.280</a></span> | <span class="t">But overall, it shows more sort of human-like behavior on particular tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=1996" target="_blank">00:33:16.380</a></span> | <span class="t">And these are just a subset of this sort of RLHF and sort of reinforcement learning and feedback-based algorithms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2004" target="_blank">00:33:24.960</a></span> | <span class="t">One I want to touch upon before I finish off is this thing called personalizing RLHF with the variational preference learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2012" target="_blank">00:33:32.540</a></span> | <span class="t">So the authors sort of saw that different demographics, you know, have different preferences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2017" target="_blank">00:33:37.340</a></span> | <span class="t">So typical RLHF sort of averages everything together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2021" target="_blank">00:33:41.640</a></span> | <span class="t">So what the authors do is they introduce a latent variable for every user preference profile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2026" target="_blank">00:33:46.600</a></span> | <span class="t">For example, a different demographic like children, adults, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2030" target="_blank">00:33:50.780</a></span> | <span class="t">And trains reward models conditioned on these sort of latent vectors or factors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2035" target="_blank">00:33:55.680</a></span> | <span class="t">So this leads to something they call pluralistic alignment, which is improving the reward accuracy for these particular demographics or subgroups.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2043" target="_blank">00:34:03.320</a></span> | <span class="t">So it enables a single model to sort of adapt its behavior to different preferences, preference profiles, and different demographics or groups of people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2052" target="_blank">00:34:12.320</a></span> | <span class="t">And now I'll hand it back to Chelsea to talk about, you know, self-improving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2059" target="_blank">00:34:19.840</a></span> | <span class="t">Alright, so yeah, let's talk a little bit about self-improving AI agents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2065" target="_blank">00:34:25.120</a></span> | <span class="t">So what exactly is an AI agent?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2068" target="_blank">00:34:28.240</a></span> | <span class="t">So it's essentially a system that perceives the environment, makes decisions, and takes actions towards achieving some sort of specific goal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2079" target="_blank">00:34:39.240</a></span> | <span class="t">And usually this goal is given by the human.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2082" target="_blank">00:34:42.280</a></span> | <span class="t">So for instance, like game playing, task solving, or like research assistance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2087" target="_blank">00:34:47.120</a></span> | <span class="t">And there's several components of an AI agent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2091" target="_blank">00:34:51.240</a></span> | <span class="t">So one, it's goal directed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2092" target="_blank">00:34:52.840</a></span> | <span class="t">Two, it can make its own sort of decisions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2096" target="_blank">00:34:56.980</a></span> | <span class="t">Three, it can act iteratively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2100" target="_blank">00:35:00.460</a></span> | <span class="t">Four, there's usually some sort of memory component to it and like state tracking component to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2107" target="_blank">00:35:07.760</a></span> | <span class="t">And finally, there's some agents that can use some tools, such as like API calls or like function calling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2115" target="_blank">00:35:15.000</a></span> | <span class="t">And finally, it can learn and adapt on its own.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2118" target="_blank">00:35:18.400</a></span> | <span class="t">Okay, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2125" target="_blank">00:35:25.760</a></span> | <span class="t">So self-improvement, basically models can reflect on their own outputs, leading to iterative improvements over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2135" target="_blank">00:35:35.380</a></span> | <span class="t">So this typically consists of several steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2138" target="_blank">00:35:38.840</a></span> | <span class="t">There's, you know, some sort of reflection of its own internal states.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2143" target="_blank">00:35:43.520</a></span> | <span class="t">There's an explanation of its own reasoning process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2147" target="_blank">00:35:47.600</a></span> | <span class="t">It can evaluate the quality of its own outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2151" target="_blank">00:35:51.620</a></span> | <span class="t">And finally, it can also simulate multi-step reasoning chains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2159" target="_blank">00:35:59.200</a></span> | <span class="t">So one technique is refinement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2162" target="_blank">00:36:02.220</a></span> | <span class="t">So this is where you have some sort of iterative prompting technique, where an LLM critiques and improves its own outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2170" target="_blank">00:36:10.760</a></span> | <span class="t">So it generates some sort of initial response and then refines it over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2176" target="_blank">00:36:16.440</a></span> | <span class="t">And this kind of uses feedback loops to sort of enhance the overall performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2181" target="_blank">00:36:21.700</a></span> | <span class="t">So an example would be like it generates some answer and then it evaluates itself for weaknesses and inconsistencies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2190" target="_blank">00:36:30.780</a></span> | <span class="t">And finally, it refines the response based on the own self-critique method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2199" target="_blank">00:36:39.320</a></span> | <span class="t">Another technique is called self-reflection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2202" target="_blank">00:36:42.460</a></span> | <span class="t">So this is where a model learns from past mistakes and adjusts future responses based on past failures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2209" target="_blank">00:36:49.320</a></span> | <span class="t">So there usually is some sort of like long-term memory component to this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2214" target="_blank">00:36:54.040</a></span> | <span class="t">And an example would be like the model first detects some sort of like weak response from its own outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2219" target="_blank">00:36:59.960</a></span> | <span class="t">And then it kind of reflects on its own mistakes and generates some sort of improved answer to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2226" target="_blank">00:37:06.620</a></span> | <span class="t">And over multiple iterations, accuracy and reasoning should improve over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2237" target="_blank">00:37:17.980</a></span> | <span class="t">Another technique is called React, which is essentially just combining reasoning with external actions, such as, you know, API calls or like retrievals from a database.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2248" target="_blank">00:37:28.500</a></span> | <span class="t">And this is basically some model that can interact dynamically with its environment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2253" target="_blank">00:37:33.540</a></span> | <span class="t">So it gets feedback from taking multiple action sequences and kind of incorporating that into its outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2263" target="_blank">00:37:43.300</a></span> | <span class="t">So, for instance, the model will generate a reasoning plan and then it will call some sort of external tool, such as like web search or some API call.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2273" target="_blank">00:37:53.040</a></span> | <span class="t">And then this model incorporates the retrieved data into its final response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2277" target="_blank">00:37:57.820</a></span> | <span class="t">And finally, this leads us to a framework called language agent tree search.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2287" target="_blank">00:38:07.940</a></span> | <span class="t">So, basically, what LATS is, is that it extends the React framework to incorporate multiple planning pathways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2294" target="_blank">00:38:14.060</a></span> | <span class="t">So you can kind of think this like analogous to chain of thought versus tree of thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2298" target="_blank">00:38:18.700</a></span> | <span class="t">It kind of gathers feedback from every path to improve the future search process, which is kind of like some sort of verbal reinforcement learning inspired technique.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2309" target="_blank">00:38:29.680</a></span> | <span class="t">And it uses Monte Carlo tree search to optimize planning trajectories where in the tree structure, every node represents a state and every edge represents an action that the agent can take.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2324" target="_blank">00:38:44.020</a></span> | <span class="t">So, an example would be like it generates n best new action sequences, and then it will just execute them all in parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2331" target="_blank">00:38:51.540</a></span> | <span class="t">Then it will use some sort of like self-reflection technique to score each one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2337" target="_blank">00:38:57.360</a></span> | <span class="t">And then overall, just continue exploring from the best state and update the probabilities of the past node.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2348" target="_blank">00:39:08.120</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2350" target="_blank">00:39:10.840</a></span> | <span class="t">Next, I'll be talking about a few other applications of transformers outside of language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2356" target="_blank">00:39:16.120</a></span> | <span class="t">I'll start with vision transformers, which have taken vision by storm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2361" target="_blank">00:39:21.220</a></span> | <span class="t">The methodology here is that, so as I talked about, transformers take in sequences, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2369" target="_blank">00:39:29.640</a></span> | <span class="t">But images aren't sequences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2372" target="_blank">00:39:32.420</a></span> | <span class="t">However, what the authors of the VIT paper came up with was to split an image up into patches, which can then be embedded to form a sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2382" target="_blank">00:39:42.820</a></span> | <span class="t">Passing this through a simple transformer yielded very good results, for instance, on classification, just by adding an MLP head to the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2391" target="_blank">00:39:51.680</a></span> | <span class="t">You might ask, why apply transformers to this problem when CNNs are such a mainstay in the field?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2401" target="_blank">00:40:01.020</a></span> | <span class="t">The main reason is that when you have a very large data set, say in the tens of millions of examples, transformers bring in less inductive biases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2409" target="_blank">00:40:09.960</a></span> | <span class="t">CNNs assume locality and that pixels are grouped together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2414" target="_blank">00:40:14.500</a></span> | <span class="t">Whereas with transformers and treating your images as sequences, you can see better results when you have enough data to train them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2424" target="_blank">00:40:24.560</a></span> | <span class="t">One common architecture that was impacted by this was CLIP, which uses VITs for its image encoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2432" target="_blank">00:40:32.000</a></span> | <span class="t">This is the basis of models like GPT-4.0 or other vision language models, and essentially works through contrastive learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2443" target="_blank">00:40:43.500</a></span> | <span class="t">So you take a data set of paired images and text pairs, and you train your model to align the encoded representations of both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2453" target="_blank">00:40:53.820</a></span> | <span class="t">So if you have an image of a cat and the word cat, then you can learn to align those embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2463" target="_blank">00:41:03.060</a></span> | <span class="t">And like I mentioned, these have been applied to vision language models like GPT-4 or 4.0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2468" target="_blank">00:41:08.220</a></span> | <span class="t">The way these are trained is you concatenate your encoded image and text, and you can train in different stages such that your model learns to take both and to account for its responses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2483" target="_blank">00:41:23.800</a></span> | <span class="t">And these have done very well on benchmarks and tasks, for instance, like test questions like I've shown here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2492" target="_blank">00:41:32.420</a></span> | <span class="t">Next, I'll talk about a bit of my work in neuroscience, which applies VITs to other kinds of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2502" target="_blank">00:41:42.740</a></span> | <span class="t">So a mainstay in my field is functional magnetic resonance imaging, or fMRI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2507" target="_blank">00:41:47.620</a></span> | <span class="t">Essentially, this captures the amount of oxygen that each voxel part of your brain is using at a given point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2514" target="_blank">00:41:54.420</a></span> | <span class="t">And this provides a very detailed proxy for the activity going on in your brain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2520" target="_blank">00:42:00.480</a></span> | <span class="t">It can be used to diagnose diseases and capture various amounts of data for better cognitive understanding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2530" target="_blank">00:42:10.560</a></span> | <span class="t">However, this is very high-dimensional.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2532" target="_blank">00:42:12.360</a></span> | <span class="t">You might have like a million or so voxels or 100,000 in the brain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2536" target="_blank">00:42:16.500</a></span> | <span class="t">So the first step to using this data with transformer models is usually averaging across like well-known regions or just grouping together voxels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2545" target="_blank">00:42:25.680</a></span> | <span class="t">And this gives you a more tractable, computationally tractable number of parcels that you can train on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2552" target="_blank">00:42:32.240</a></span> | <span class="t">A traditional tool in this field was just to use linear pairwise correlation maps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2559" target="_blank">00:42:39.260</a></span> | <span class="t">And just these were enough to get pretty good diagnoses of things like Parkinson's.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2564" target="_blank">00:42:44.240</a></span> | <span class="t">However, with the advent of tons of computer vision techniques, we can apply larger and more sophisticated models to these tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2572" target="_blank">00:42:52.560</a></span> | <span class="t">One cool large body of work in this area is divvying up the brain into different functional networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2582" target="_blank">00:43:02.040</a></span> | <span class="t">So let's say like your vision system or your daydreaming network or control, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2588" target="_blank">00:43:08.020</a></span> | <span class="t">And I'll get into how we use this to sort of guide our work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2594" target="_blank">00:43:14.840</a></span> | <span class="t">So like I mentioned, early ML models just took like linear correlation maps, so making lots of assumptions about the data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2601" target="_blank">00:43:21.940</a></span> | <span class="t">and just supplied typical like neural networks to the task for regression or classification tasks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2608" target="_blank">00:43:28.800</a></span> | <span class="t">or in some cases, graph-based analyses to try to get a deeper understanding of how the brain,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2614" target="_blank">00:43:34.740</a></span> | <span class="t">different parts of the brain interact with each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2619" target="_blank">00:43:39.160</a></span> | <span class="t">With computer vision, we can take our raw data and just throw that at a transformer model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2624" target="_blank">00:43:44.920</a></span> | <span class="t">And that does very well as a pre-training objective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2628" target="_blank">00:43:48.640</a></span> | <span class="t">So what we do is, let's say we have some number of ROIs across time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2633" target="_blank">00:43:53.720</a></span> | <span class="t">We can just mask out some portion of that data, pass the rest of the data through a transformer model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2641" target="_blank">00:44:01.420</a></span> | <span class="t">and have it predict this portion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2642" target="_blank">00:44:02.940</a></span> | <span class="t">You repeat this across a large data set and all of your ROIs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2647" target="_blank">00:44:07.660</a></span> | <span class="t">And this provides a very good self-supervised training objective for this task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2652" target="_blank">00:44:12.140</a></span> | <span class="t">So self-supervised essentially means that there is no paired label data here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2657" target="_blank">00:44:17.320</a></span> | <span class="t">We are essentially just using our raw data and posing our objective such that we can learn directly off of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2667" target="_blank">00:44:27.200</a></span> | <span class="t">Once you've trained this sort of model, you have these dense representations inside the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2673" target="_blank">00:44:33.320</a></span> | <span class="t">that can be applied downstream to various tasks, like predicting patient attributes or the risk of disease.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2679" target="_blank">00:44:39.340</a></span> | <span class="t">And you can also look at the weights that your model has learned to do analyses of brain networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2690" target="_blank">00:44:50.140</a></span> | <span class="t">So in brief, our approach essentially consists of taking the activity in the entire brain,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2695" target="_blank">00:44:55.480</a></span> | <span class="t">partitioning out some small region, let's say it's your vision system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2699" target="_blank">00:44:59.180</a></span> | <span class="t">You pass the unmasked portion into a transformer model, which learns to predict the mass portion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2707" target="_blank">00:45:07.100</a></span> | <span class="t">And you can compare this to your ground truth to provide your training objective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2716" target="_blank">00:45:16.600</a></span> | <span class="t">One key thing we use here is cross-attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2719" target="_blank">00:45:19.180</a></span> | <span class="t">So what we talked about before with language was self-attention,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2722" target="_blank">00:45:22.480</a></span> | <span class="t">wherein you're attending to the current sequence you're looking at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2727" target="_blank">00:45:27.180</a></span> | <span class="t">In cross-attention, you have two different sequences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2730" target="_blank">00:45:30.620</a></span> | <span class="t">Let's say in machine translation, you have one in English and in French.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2733" target="_blank">00:45:33.960</a></span> | <span class="t">And essentially, you apply attention between the two sequences instead of just on a single sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2743" target="_blank">00:45:43.600</a></span> | <span class="t">So our most basic architecture takes advantage of this through just a singular cross-attention decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2750" target="_blank">00:45:50.200</a></span> | <span class="t">Having a very small model makes for better interpretability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2754" target="_blank">00:45:54.020</a></span> | <span class="t">And like I mentioned, this model just learns to predict mass brain regions from unmasked ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2759" target="_blank">00:45:59.380</a></span> | <span class="t">Once we've done this, we can analyze, again, the attention weights to gain a deeper understanding of networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2765" target="_blank">00:46:05.940</a></span> | <span class="t">and also apply this to downstream tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2769" target="_blank">00:46:09.280</a></span> | <span class="t">So some modeling results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2770" target="_blank">00:46:10.780</a></span> | <span class="t">Here, I've plotted the brain activity from different patients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2774" target="_blank">00:46:14.960</a></span> | <span class="t">And you can see that the model does pretty well in matching the ground truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2779" target="_blank">00:46:19.880</a></span> | <span class="t">For two networks that I've shown here, the salience network, which is involved in your senses and decision-making,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2787" target="_blank">00:46:27.900</a></span> | <span class="t">and the default mode network, or DMN, which is responsible for, like, daydreaming or just recapitulating your brain information when you're not doing a certain task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2798" target="_blank">00:46:38.020</a></span> | <span class="t">On the bottom, we have the attention weights for this model, which I've split up by all of the other networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2806" target="_blank">00:46:46.280</a></span> | <span class="t">So, for instance, on the left, when predicting the salience network, we can see from our model that it is heavily dependent on the default mode and control networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2815" target="_blank">00:46:55.160</a></span> | <span class="t">So this gives us a better understanding of how different brain networks are connected to each other or how they might share information inside the brain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2823" target="_blank">00:47:03.460</a></span> | <span class="t">For other networks, though, like vision, these are more singular.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2828" target="_blank">00:47:08.940</a></span> | <span class="t">We can't predict them very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2830" target="_blank">00:47:10.220</a></span> | <span class="t">Or subcortical regions, say those involved in, like, memory, we also cannot predict very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2835" target="_blank">00:47:15.220</a></span> | <span class="t">So this is all well and cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2840" target="_blank">00:47:20.500</a></span> | <span class="t">We can predict brain activity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2841" target="_blank">00:47:21.800</a></span> | <span class="t">But what can we do with this model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2843" target="_blank">00:47:23.560</a></span> | <span class="t">If we simply replace one component of the model with a learnable token, which corresponds to predicting Parkinson's disease,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2853" target="_blank">00:47:33.240</a></span> | <span class="t">then we can use this model to, again, predict that ailment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2858" target="_blank">00:47:38.520</a></span> | <span class="t">So if you look on the right, after some fine-tuning on a labeled data set, we can see some clustering in the model's embedding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2865" target="_blank">00:47:45.800</a></span> | <span class="t">which corresponds to getting close to 70% accuracy in predicting this disease,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2872" target="_blank">00:47:52.240</a></span> | <span class="t">which is much higher than using, like, the correlation-based methods or linear assumptions I talked about earlier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2883" target="_blank">00:48:03.020</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2883" target="_blank">00:48:03.640</a></span> | <span class="t">So now that we have some background on these Transformer models and a couple of their applications,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2888" target="_blank">00:48:08.440</a></span> | <span class="t">let's talk about the future and what's next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2891" target="_blank">00:48:11.040</a></span> | <span class="t">So overall, these Transformer models can enable a lot more applications across every industry and sector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2897" target="_blank">00:48:17.680</a></span> | <span class="t">This includes generalist agents, as well as longer video understanding and generation across the finance and business sector,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2904" target="_blank">00:48:24.960</a></span> | <span class="t">domain-specific foundation models, like, for example, one could imagine a doctor GPT or a lawyer GPT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2911" target="_blank">00:48:31.980</a></span> | <span class="t">or an insert field GPT, as well as potential real-world impacts, like personalized education and tutoring systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2919" target="_blank">00:48:39.540</a></span> | <span class="t">advanced healthcare diagnostics, environmental monitoring and protection, real-time multilingual communication,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2926" target="_blank">00:48:46.220</a></span> | <span class="t">as well as an interactive environment and gaming, for example, non-playable characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2935" target="_blank">00:48:55.600</a></span> | <span class="t">What is missing, though?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2937" target="_blank">00:48:57.280</a></span> | <span class="t">What information might we need and what can we develop in the future?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2941" target="_blank">00:49:01.040</a></span> | <span class="t">Currently, we're missing reducing computation complexity, enhancing human controllability,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2949" target="_blank">00:49:09.920</a></span> | <span class="t">alignment with the language models of the human brain,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2953" target="_blank">00:49:13.260</a></span> | <span class="t">adaptive learning and generalization across different domains,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2957" target="_blank">00:49:17.600</a></span> | <span class="t">and finally, multi-sensory, multi-modal embodiment, like intuitive physics and common sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2962" target="_blank">00:49:22.880</a></span> | <span class="t">So these might, one might consider these barriers to developing artificial general intelligence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2968" target="_blank">00:49:28.720</a></span> | <span class="t">and these are some of the limitations of current Transformer models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2972" target="_blank">00:49:32.180</a></span> | <span class="t">Some other things that are missing include infinite and external memory, like neural Turing machines,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2980" target="_blank">00:49:40.480</a></span> | <span class="t">infinite self-improvement capabilities, like continual or lifelong learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2984" target="_blank">00:49:44.020</a></span> | <span class="t">This is another central tenet of human learning that we're not able to replicate at the moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2988" target="_blank">00:49:48.840</a></span> | <span class="t">Complete autonomy, including curiosity, desires and goals, and long-horizon decision-making,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=2995" target="_blank">00:49:55.040</a></span> | <span class="t">as well as emotional intelligence, social understanding, and, of course, ethical reasoning and value alignment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3000" target="_blank">00:50:00.900</a></span> | <span class="t">Right, so there's still a sort of plethora of remaining sort of weaknesses or challenges</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3010" target="_blank">00:50:10.100</a></span> | <span class="t">around Transformers, large language models, and AI in general these days.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3015" target="_blank">00:50:15.460</a></span> | <span class="t">So I'll touch upon a couple of them briefly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3017" target="_blank">00:50:17.920</a></span> | <span class="t">The first is, like I mentioned earlier, efficiency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3020" target="_blank">00:50:20.340</a></span> | <span class="t">Being able to minify or sort of have tiny LLMs or models that you can run on your phone,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3026" target="_blank">00:50:26.660</a></span> | <span class="t">on your smartwatch, and et cetera.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3028" target="_blank">00:50:28.280</a></span> | <span class="t">So that's a big trend these days, is using LLMs for everyday applications and purposes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3034" target="_blank">00:50:34.680</a></span> | <span class="t">And, again, you want to be able to run them quickly and easily on smaller devices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3039" target="_blank">00:50:39.980</a></span> | <span class="t">Right now, there is more and more work on smaller and more efficient open-source models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3044" target="_blank">00:50:44.720</a></span> | <span class="t">Things like DeepSeq, Llama, and Mistral.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3047" target="_blank">00:50:47.100</a></span> | <span class="t">But they're still somewhat large and a bit expensive, especially if you're looking to fine-tune.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3052" target="_blank">00:50:52.640</a></span> | <span class="t">They're still not accessible to everybody, especially on smaller devices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3056" target="_blank">00:50:56.960</a></span> | <span class="t">So in the future, again, we want to aim to have the ability to sort of fine-tune</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3061" target="_blank">00:51:01.060</a></span> | <span class="t">or run these models locally on whatever device you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3064" target="_blank">00:51:04.560</a></span> | <span class="t">The second is, as our models, as our LLMs scale up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3070" target="_blank">00:51:10.040</a></span> | <span class="t">trillions of parameters trained on trillions of tokens across the Internet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3075" target="_blank">00:51:15.540</a></span> | <span class="t">what happens is this makes it a huge black box that is difficult to understand or interpret.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3079" target="_blank">00:51:19.520</a></span> | <span class="t">It's hard to know what exactly is going on behind the scenes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3082" target="_blank">00:51:22.540</a></span> | <span class="t">When you ask it to solve X, Y, Z, and it comes up with answers A, B, C.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3086" target="_blank">00:51:26.320</a></span> | <span class="t">How exactly did it get there?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3087" target="_blank">00:51:27.420</a></span> | <span class="t">Why did it choose those answers instead?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3089" target="_blank">00:51:29.580</a></span> | <span class="t">And so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3090" target="_blank">00:51:30.560</a></span> | <span class="t">So more work on interpretability for LLMs will give us a better idea of what or how to improve them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3097" target="_blank">00:51:37.400</a></span> | <span class="t">These are ways of controlling them and better alignment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3101" target="_blank">00:51:41.620</a></span> | <span class="t">For example, being able to prevent them from producing certain outputs that might be unsafe or unethical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3108" target="_blank">00:51:48.620</a></span> | <span class="t">So there's this area which has gotten even more popular recently called mechanistic interpretability,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3112" target="_blank">00:51:52.840</a></span> | <span class="t">which is trying to understand how individual components or operations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3116" target="_blank">00:51:56.420</a></span> | <span class="t">even sometimes down to the individual node level, so very granular,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3121" target="_blank">00:52:01.160</a></span> | <span class="t">in an ML model contribute to its overall decision-making process,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3125" target="_blank">00:52:05.100</a></span> | <span class="t">with the goal, again, of sort of unpacking this black box for clear insight on how exactly they work behind the scenes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3132" target="_blank">00:52:12.220</a></span> | <span class="t">Next, I feel like we're approaching or we're already seeing diminishing returns with simply scaling up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3142" target="_blank">00:52:22.460</a></span> | <span class="t">So larger models on more data does not seem to be the be-all, NL solution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3147" target="_blank">00:52:27.120</a></span> | <span class="t">So one-size-fits-all and frozen pre-trained models have already started leading to diminishing returns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3151" target="_blank">00:52:31.940</a></span> | <span class="t">So again, pre-training performance, so the first sort of half, right, of training LLMs, it's likely saturating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3160" target="_blank">00:52:40.400</a></span> | <span class="t">Hence, there's been more focus on post-training methods, everything we've talked about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3164" target="_blank">00:52:44.080</a></span> | <span class="t">feedback and RL mechanisms, prompting methods like chain of thought, self-improvement and refinement and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3170" target="_blank">00:52:50.640</a></span> | <span class="t">However, all of these post-training mechanisms are going to be fundamentally limited by the overall performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3175" target="_blank">00:52:55.380</a></span> | <span class="t">or capabilities of the base model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3177" target="_blank">00:52:57.380</a></span> | <span class="t">So you can argue that the pre-training is fundamentally what gives the basis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3181" target="_blank">00:53:01.580</a></span> | <span class="t">or the foundational knowledge and capabilities to the model, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3184" target="_blank">00:53:04.980</a></span> | <span class="t">So we should not just stop investigating pre-training just because we're hitting scaling limits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3189" target="_blank">00:53:09.780</a></span> | <span class="t">Furthermore, too much post-training can actually lead to an issue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3193" target="_blank">00:53:13.480</a></span> | <span class="t">This is called catastrophic forgetting, where the model forgets stuff it's learned beforehand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3200" target="_blank">00:53:20.060</a></span> | <span class="t">For example, during pre-training, because you're overloading it with tons of new information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3204" target="_blank">00:53:24.800</a></span> | <span class="t">in a new domain or a new task during post-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3207" target="_blank">00:53:27.960</a></span> | <span class="t">So how do we break through this sort of scaling law limit?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3212" target="_blank">00:53:32.200</a></span> | <span class="t">Some potential things to investigate would be new architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3220" target="_blank">00:53:40.600</a></span> | <span class="t">There are different things like Mamba, state-space machines, those sort of architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3225" target="_blank">00:53:45.820</a></span> | <span class="t">And it would be good to see more investigation on even non-transformer architectures,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3230" target="_blank">00:53:50.540</a></span> | <span class="t">which is a bit ironic considering this class is Transformers United.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3233" target="_blank">00:53:53.220</a></span> | <span class="t">But we also always encourage more diversity and thinking outside the box.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3239" target="_blank">00:53:59.340</a></span> | <span class="t">So again, everything I talked about, high-quality data and smart data ordering and structuring strategies,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3245" target="_blank">00:54:05.560</a></span> | <span class="t">and overall improved training procedures, improved algorithms, loss functions, optimization algorithms, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3253" target="_blank">00:54:13.540</a></span> | <span class="t">Another goal, as we've mentioned several times, is to be able to bring these advanced capabilities to smaller models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3261" target="_blank">00:54:21.720</a></span> | <span class="t">Furthermore, we would still encourage more theoretical and interpretability research,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3266" target="_blank">00:54:26.280</a></span> | <span class="t">including things like cognitive science and neuroscience-inspired work,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3270" target="_blank">00:54:30.060</a></span> | <span class="t">which Karana and I have talked about some of that, that we've done recently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3275" target="_blank">00:54:35.260</a></span> | <span class="t">So the next step will be models that are not just larger, but ones that are more smarter and more adaptable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3280" target="_blank">00:54:40.700</a></span> | <span class="t">So again, there's this one major thing or major weakness that I think still bridges the gap between AI and humans,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3294" target="_blank">00:54:54.100</a></span> | <span class="t">which is sort of continual or lifelong learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3297" target="_blank">00:54:57.100</a></span> | <span class="t">So AI systems that can continuously improve by learning after deployment, after being pre-trained,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3302" target="_blank">00:55:02.100</a></span> | <span class="t">using implicit feedback, real-world experience, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3305" target="_blank">00:55:05.540</a></span> | <span class="t">So essentially, this is infinite and permanent sort of fundamental self-improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3310" target="_blank">00:55:10.160</a></span> | <span class="t">We're not just talking about RAG or retrieval, like putting knowledge in a retrieval database that you can retrieve at test time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3316" target="_blank">00:55:16.360</a></span> | <span class="t">but updating the brain or the weights of the model continuously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3320" target="_blank">00:55:20.180</a></span> | <span class="t">So this is similar to us, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3322" target="_blank">00:55:22.040</a></span> | <span class="t">So we're learning every day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3323" target="_blank">00:55:23.080</a></span> | <span class="t">I'm learning right now by talking to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3325" target="_blank">00:55:25.260</a></span> | <span class="t">I learn every time I talk to somebody else as I'm going through my daily life.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3328" target="_blank">00:55:28.660</a></span> | <span class="t">But these models, after they're frozen or pre-trained, that doesn't really happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3331" target="_blank">00:55:31.960</a></span> | <span class="t">The only way they truly learn or their brain or weights are updated is through fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3336" target="_blank">00:55:36.860</a></span> | <span class="t">And again, we don't do that, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3338" target="_blank">00:55:38.580</a></span> | <span class="t">We don't sit in a chair every three months and have someone reread the internet to us or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3343" target="_blank">00:55:43.720</a></span> | <span class="t">So again, this is almost wasted work, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3348" target="_blank">00:55:48.800</a></span> | <span class="t">So currently, during inference, the models are not actually learning and updating their weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3352" target="_blank">00:55:52.320</a></span> | <span class="t">When they're talking, when ChatGPT is talking to you, it's not truly updating its brain or weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3357" target="_blank">00:55:57.220</a></span> | <span class="t">So this is a very challenging problem, but in our opinion, it's likely one of the keys potentially to AGI or truly human-like AI systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3366" target="_blank">00:56:06.520</a></span> | <span class="t">So there's different current work that tries to tackle this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3371" target="_blank">00:56:11.100</a></span> | <span class="t">There's things like fine-tuning a smaller model based on traces from a larger model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3375" target="_blank">00:56:15.620</a></span> | <span class="t">Things like model distillation related to a lot of things like improvement and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3380" target="_blank">00:56:20.440</a></span> | <span class="t">But this is, again, not truly continual learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3383" target="_blank">00:56:23.600</a></span> | <span class="t">So some questions are, what mechanisms could potentially truly enable real lifelong learning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3391" target="_blank">00:56:31.560</a></span> | <span class="t">Will this be gradient updates, so, you know, actually updating the brain?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3394" target="_blank">00:56:34.660</a></span> | <span class="t">Will it be things like targeting particular nodes in the architecture?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3397" target="_blank">00:56:37.640</a></span> | <span class="t">Will it be having things like particular memory architectures or different parts of the neural network solely focused on sort of continuous updates and learning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3407" target="_blank">00:56:47.060</a></span> | <span class="t">Or even things like meta-learning and looking more at the broad scale of things or the broader scope?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3414" target="_blank">00:56:54.160</a></span> | <span class="t">So one line of work, which has seen a bit of traction, is model editing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3418" target="_blank">00:56:58.480</a></span> | <span class="t">So this is related to work on mechanistic interpretability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3421" target="_blank">00:57:01.540</a></span> | <span class="t">So this is, instead of updating, you know, the whole model, if we're given a new fact or a new data point, can we target specific nodes or neurons in the model that we should update?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3431" target="_blank">00:57:11.560</a></span> | <span class="t">So one work called Rank 1 Model Editing, or ROM, tries to do this through causal intervention mechanisms to determine, you know, which neuron activations most correspond to particular factual predictions and then updating them appropriately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3447" target="_blank">00:57:27.500</a></span> | <span class="t">But as you can possibly suspect, this has a lot of weaknesses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3451" target="_blank">00:57:31.220</a></span> | <span class="t">So firstly, this works mainly for knowledge-based things or simple facts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3455" target="_blank">00:57:35.940</a></span> | <span class="t">What if we want to update the actual skills or capabilities of a model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3459" target="_blank">00:57:39.840</a></span> | <span class="t">We want it to be better at math in general.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3462" target="_blank">00:57:42.160</a></span> | <span class="t">We want it to be better at advanced analogical reasoning, like humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3466" target="_blank">00:57:46.140</a></span> | <span class="t">Then something like model editing, based on factual predictions, doesn't seem like it'll work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3472" target="_blank">00:57:52.080</a></span> | <span class="t">The second is, these are targeting one fact at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3475" target="_blank">00:57:55.560</a></span> | <span class="t">So it's not easy to propagate these changes to other nodes based on related facts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3482" target="_blank">00:58:02.380</a></span> | <span class="t">For example, let's say the mother, like someone's mother, we want to update a fact about them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3489" target="_blank">00:58:09.860</a></span> | <span class="t">Then we should also update a fact about that person's brother because, you know, they have the same mother.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3495" target="_blank">00:58:15.240</a></span> | <span class="t">But, you know, this sort of approach will only update it for the original person in question, but not any of the relatives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3502" target="_blank">00:58:22.980</a></span> | <span class="t">So this is just one example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3504" target="_blank">00:58:24.080</a></span> | <span class="t">So there's a lot of other works which have spun out recently in continual learning, which is good that this sort of area has seen more work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3510" target="_blank">00:58:30.940</a></span> | <span class="t">So I will very briefly describe some of these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3515" target="_blank">00:58:35.940</a></span> | <span class="t">One is this thing called memet, which is directly related to what I just said about Rome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3520" target="_blank">00:58:40.760</a></span> | <span class="t">But it's mass editing of factual knowledge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3522" target="_blank">00:58:42.740</a></span> | <span class="t">So instead of a simple sort of fact or memory at a time, it's able to, you know, simultaneously modify thousands, even ones which might be related to each other, like I said, which is useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3533" target="_blank">00:58:53.160</a></span> | <span class="t">There's things like chem or continue evolving from mistakes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3536" target="_blank">00:58:56.880</a></span> | <span class="t">So it actually identifies the LNM mistakes, somewhat similar to what self-improvement Chelsea was talking about, but incrementally updates the model to self-improve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3545" target="_blank">00:59:05.360</a></span> | <span class="t">Just things like lifelong mixture of experts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3551" target="_blank">00:59:11.200</a></span> | <span class="t">So what it does, instead of having a simple fixed mixture of experts architecture, it continually adds new experts for different domains over time, while freezing potentially past experts, which are no longer useful or don't need to be updated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3565" target="_blank">00:59:25.520</a></span> | <span class="t">To avoid things like catastrophic forgetting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3568" target="_blank">00:59:28.000</a></span> | <span class="t">So this is a very smart sort of approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3570" target="_blank">00:59:30.380</a></span> | <span class="t">Another is called CLOB.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3571" target="_blank">00:59:31.960</a></span> | <span class="t">So this enables continual task learning using only prompting without updating model weights by summarizing past knowledge into a compressed prompt memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3580" target="_blank">00:59:40.680</a></span> | <span class="t">However, not a criticism of this work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3582" target="_blank">00:59:42.980</a></span> | <span class="t">But again, this is not technically updating the brain or the fundamental capabilities of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3589" target="_blank">00:59:49.400</a></span> | <span class="t">So this is more of a prompt-only approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3593" target="_blank">00:59:53.040</a></span> | <span class="t">And another one of these is called progressive prompts, which again, alerts a soft prompt vector for each task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3598" target="_blank">00:59:58.460</a></span> | <span class="t">And again, progressively compresses them and composes them together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3603" target="_blank">01:00:03.060</a></span> | <span class="t">So allowing LLMs to continually learn without weight updates or catastrophic forgetting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3609" target="_blank">01:00:09.920</a></span> | <span class="t">But again, my opinion is true continual learning would update the brain or the weights of the model in some way, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3616" target="_blank">01:00:16.800</a></span> | <span class="t">So thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3620" target="_blank">01:00:20.680</a></span> | <span class="t">That's mainly our lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3622" target="_blank">01:00:22.020</a></span> | <span class="t">So, you know, we gave a brief overview of transformers, how they work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3625" target="_blank">01:00:25.180</a></span> | <span class="t">Talked about pre-training and especially how data is important for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3629" target="_blank">01:00:29.080</a></span> | <span class="t">Various post-training techniques, feedback mechanisms, prompting mechanisms like chain of thought, self-improvement, some applications to neuroscience, vision, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3637" target="_blank">01:00:37.940</a></span> | <span class="t">And some remaining weaknesses like things like the lack of continual learning and data efficiency, being able to scale down and run these models on our phone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3647" target="_blank">01:00:47.500</a></span> | <span class="t">So before we send you guys off, I know we ended a bit early.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3651" target="_blank">01:00:51.860</a></span> | <span class="t">So this class going forwards, every week, in case you haven't attended, we'll have a speaker, typically from industry or academia, come in to talk about the state-of-the-art work they're doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3661" target="_blank">01:01:01.000</a></span> | <span class="t">And we have a cool lineup of speakers prepared for you guys for the remainder of the quarter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3665" target="_blank">01:01:05.240</a></span> | <span class="t">And some more logistical things, we'll be posting updates about lectures and so forth on our website through the mailing list, Discord, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3673" target="_blank">01:01:13.220</a></span> | <span class="t">So please join those if you haven't already.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3674" target="_blank">01:01:14.960</a></span> | <span class="t">Thank you, guys.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3676" target="_blank">01:01:16.020</a></span> | <span class="t">Hope you enjoyed the first lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3677" target="_blank">01:01:17.080</a></span> | <span class="t">And if anybody has any questions, feel free to come up and stay around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3680" target="_blank">01:01:20.360</a></span> | <span class="t">Thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3681" target="_blank">01:01:21.120</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3682" target="_blank">01:01:22.120</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JKbtWimlzAE&t=3683" target="_blank">01:01:23.120</a></span> | <span class="t">Thank you.</span></div></div></body></html>