<html><head><title>Rogue AI: Bioweapons, Cyberattacks, Military Force, Bargaining | Carl Shulman</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>Rogue AI: Bioweapons, Cyberattacks, Military Force, Bargaining | Carl Shulman</h2><a href="https://www.youtube.com/watch?v=_8mYbUK1Uyc" target="_blank"><img src="https://i.ytimg.com/vi_webp/_8mYbUK1Uyc/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=_8mYbUK1Uyc&t=0 target="_blank"">0:0</a> Bioweapons<br><a href="https://www.youtube.com/watch?v=_8mYbUK1Uyc&t=134 target="_blank"">2:14</a> Cyber attacks<br><a href="https://www.youtube.com/watch?v=_8mYbUK1Uyc&t=287 target="_blank"">4:47</a> AI takeover<br><a href="https://www.youtube.com/watch?v=_8mYbUK1Uyc&t=595 target="_blank"">9:55</a> Surveillance<br><h3>Transcript</h3><div class='max-width'><p>If you have an AI that produces bioweapons that could kill most humans in the world, then it's playing at the level of the superpowers in terms of mutually assured destruction. That can then play into any number of things. Like if you have an idea of, well, we'll just destroy the server firms.</p><p>Are you willing to destroy the server firms when the AI has demonstrated it has the capability to kill the overwhelming majority of the citizens of your country and every other country? And that might give a lot of pause to a human response. An AI could also release bioweapons that are likely to kill people soon, but not yet, while also having developed the countermeasures to those.</p><p>So that those who surrender to the AI will live while everyone else will die, and that will be visibly happening. And that is a plausible way in which a large number of humans could wind up surrendering themselves or their states to the AI authority. We see today with things like AlphaFold that advanced AI can really make tremendous strides in predicting protein folding and biodesign, even without ongoing experimental feedback.</p><p>And if we consider this world where AI cognitive abilities have been amped up to such an extreme, I think we should naturally expect we will have something much, much more potent than the AlphaFolds of today. And just skills that are at the extreme of human biosciences capability as well.</p><p>This would be a starting bargaining position of diplomatic relations with a power that has enough nuclear weapons to destroy your country. It's just different than negotiations with like, you know, a random rogue citizen engaged in criminal activity. This isn't enough on its own to take over everything, but it's enough to have a significant amount of influence over how the world goes.</p><p>It's enough to hold off a lot of countermeasures one might otherwise take. If you have AI that is able to hack the servers that it is operating on, if it inserts or exploits vulnerabilities to take those computers over, it can then change all of the procedures and programs that were supposed to be monitoring its behaviors.</p><p>And if we lose those procedures, then the AI can, or the AIs working together, can take any number of actions that are just blatantly unwelcome, blatantly hostile, blatantly steps towards takeover. Cyber attacks and cybersecurity, I would really highlight a lot. Because for many, many plans that involve a lot of physical actions, like at the point where AI is piloting robots to shoot people or has taken control of human nation states or territory, it has been doing a lot of things that it was not supposed to be doing.</p><p>And if humans were evaluating those actions and applying gradient descent, there would be negative feedback for this thing. No shooting the humans. So at some earlier point, our attempts to leash and control and direct and train the system's behavior had to have gone awry. And so all of those controls are operating in computers, and so the software that updates the weights of the neural network in response to data points or human feedback is running on those computers.</p><p>Our tools for interpretability to sort of examine the weights and activations of the AI, if we're eventually able to do like lie detection on it, for example, or try and understand what it's intending, that is software on computers. Building new technologies, building robots, constructing things with the AI's assistance, that can all proceed and appear like it's going well, appear like alignment has been nicely solved, appear like all the things are functioning well.</p><p>And there's some reason to do that, because there's only so many giant server farms that are identifiable. And so remaining hidden and unobtrusive could be an advantageous strategy if these AIs have subverted the system, just continuing to benefit from all of this effort on the part of humanity, and in particular, humanity, wherever these servers are located, to provide them with everything they need to build the further infrastructure.</p><p>If the thing just waits, and humans are constructing more fabs, more computers, more robots, if that's all happening with humans unaware that their computer systems are now systematically controlled by AIs hostile to them, and that their controlling countermeasures don't work, then humans are just going to be building an amount of robot, industrial, and military hardware that dwarfs human capabilities and directly human-controlled devices.</p><p>What the AI takeover looks like at that point can be just, you try to give an order to your largely automated military, and the order is not obeyed. And humans can't do anything against this largely automated military that's been constructed, potentially, in just recent months. Because of the extraordinary growth of industrial capability and technological capability and thus military capability, if one major power were left out of that expansion, it would be helpless before another one that had undergone it.</p><p>And so if you have that environment of distrust where leading powers or coalitions of powers decide they need to build up their industry or they want to have that military security to capture these industrial benefits, and especially if you have a negative-sum arms race kind of mentality that is not sufficiently concerned about the downsides of creating a massive robot industrial base, which could happen very quickly with the support of the AIs in doing it as we discussed, then you create all those robots and industry and they can either, even if you don't build a formal military, with that industrial capability could be controlled by AI.</p><p>It's all AI-operated anyway. Does it have to be that case? Presumably we wouldn't be so naive as to just give one instance of GPD-8 the root access to all the robots, right? I mean, in the scenario we've lost earlier on the cyber security front, so where the programming that is being loaded in, they were designed by AI systems that were ensuring they would be vulnerable from the bottom up.</p><p>There are also positive inducements that AI can offer. So we talked about the competitive situation. So if the great powers distrust one another and are sort of in a foolish prisoner's dilemma, increasing the risk that both of them are laid waste or overthrown by AI. If there's that amount of distrust, such that we fail to take adequate precautions on caution with AI alignment, then it's also plausible that the lagging powers that are not at the frontier of AI may be willing to trade quite a lot for access to the most recent and most extreme AI capabilities.</p><p>And so an AI that has escaped, has control of its servers, can offer its services. So if you imagine these AI that could cut deals with other countries and the possibility of, well, if you don't accept this deal, then the leading powers continue forward, or then some other country, some other government, some other organizations may accept this deal.</p><p>And so that's a source of a potentially enormous carrot that your misbehaving AI can offer because it embodies this intellectual property that is maybe worth as much as the planet and is in a position to trade or sell that in exchange for resources and backing and infrastructure that it needs.</p><p>So there can be the stick of apocalyptic doom, the carrot of cooperation, or the carrot of withholding destructive attack on a particular party, and then combine that with just superhuman performance at the art of making arguments, of cutting deals with much more data about their counterparties, probably a ton of secret information.</p><p>They may be able to threaten the lives of individual leaders with that level of cyber penetration. They could know where leaders are at a given time with the kind of illicit capabilities we were talking about earlier. They acquire a lot of illicit wealth and can coordinate some human actors if they could pull off things like targeted assassinations or the threat thereof, or a credible demonstration of the threat thereof.</p><p>Those could be very powerful incentives to an individual leader that they will die today unless they go along with this. Just as at the national level, they could fear their nation will be destroyed unless they go along with this. There's already a lot of concern about the application of AI for surveillance.</p><p>And again, we have billions of smartphones, there's enough cameras, there's enough microphones to monitor all humans. If an AI has control of territory at the high level, the government has surrendered to it. It has command of the skies, military dominance. Establishing control over individual humans can be a matter of just having the ability to exert hard power on that human, and then the kind of camera and microphone that are present in billions of smartphones.</p><p>Max Tegmark in his book Life 3.0 discusses among scenarios to avoid the possibility of devices with some fatal instruments, so a poison injector, an explosive that can be controlled remotely by an AI with a dead man switch. And so if individual humans are carrying with them a microphone and camera, and they have a dead man switch, then any rebellion is detected immediately and is fatal.</p><p>No, an insurgency or rebellion is just not going to work. Any human who is not already being encumbered in that way can be found with satellites and sensors tracked down and then die or be subjugated. Insurgency is not the way to avoid an AI takeover. No John Connor come from behind scenario is plausible.</p><p>If the thing was headed off, it was a lot earlier than</p></div></div></body></html>