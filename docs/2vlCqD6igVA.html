<html><head><title>Recsys Keynote: Improving Recommendation Systems & Search in the Age of LLMs - Eugene Yan, Amazon</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Recsys Keynote: Improving Recommendation Systems & Search in the Age of LLMs - Eugene Yan, Amazon</h2><a href="https://www.youtube.com/watch?v=2vlCqD6igVA"><img src="https://i.ytimg.com/vi_webp/2vlCqD6igVA/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=0">0:0</a> Introduction to Language Modeling in Recommendation Systems<br><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=91">1:31</a> Challenge 1: Hash-based Item IDs<br><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=134">2:14</a> Solution: Semantic IDs<br><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=337">5:37</a> Challenge 2: Data Augmentation and Quality<br><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=370">6:10</a> Solution: LLM-Augmented Synthetic Data<br><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=381">6:21</a> Indeed Case Study<br><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=637">10:37</a> Spotify Case Study<br><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=814">13:34</a> Challenge 3: Separate Systems and High Operational Costs<br><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=864">14:24</a> Solution: Unified Models<br><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=891">14:51</a> Netflix Case Study (Unicorn)<br><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1006">16:46</a> Etsy Case Study (Unified Embeddings)<br><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1226">20:26</a> Key Takeaways<br><br><div style="text-align: left;"><a href="./2vlCqD6igVA.html">Whisper Transcript</a> | <a href="./transcript_2vlCqD6igVA.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=0" target="_blank">00:00:00.500</a></span> | <span class="t">Hi everyone, thank you for joining us in today's REXIS, the inaugural REXIS track at the AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=19" target="_blank">00:00:19.960</a></span> | <span class="t">Engineer World's Fair. So today what I want to share about is what the future might look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=25" target="_blank">00:00:25.280</a></span> | <span class="t">like when we try to merge recommendation systems and language models. So my wife looked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=32" target="_blank">00:00:32.360</a></span> | <span class="t">at my slides and she's like, they're so plain. So therefore, I'll be giving a talk together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=36" target="_blank">00:00:36.800</a></span> | <span class="t">with Latte and Mochi. You might have seen Mochi wandering the halls around somewhere,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=40" target="_blank">00:00:40.280</a></span> | <span class="t">but there'll be a lot of doggos throughout these slides. I hope you enjoy. First, language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=45" target="_blank">00:00:45.100</a></span> | <span class="t">modeling techniques are not new in recommendation systems. I mean, it started with World2Vac in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=50" target="_blank">00:00:50.560</a></span> | <span class="t">2013. We started learning item embeddings across, from co-occurrences in user interaction sequences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=57" target="_blank">00:00:57.640</a></span> | <span class="t">And then after that, we started using GRU for REX. I don't know who here remembers recurrent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=62" target="_blank">00:01:02.160</a></span> | <span class="t">neural networks, gated recurrent units. Yeah. So those were very short term, and we predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=67" target="_blank">00:01:07.440</a></span> | <span class="t">the next item from a short set of sequences. Then of course, transformers and attention came</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=72" target="_blank">00:01:12.980</a></span> | <span class="t">about, and we became better on attention on long-range dependencies. So that's where we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=78" target="_blank">00:01:18.660</a></span> | <span class="t">started. Hey, you know, can we just process on everything in the user sequence, hundreds,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=83" target="_blank">00:01:23.100</a></span> | <span class="t">2,000 item IDs long, and try to learn from that? And of course, now, today in this track,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=89" target="_blank">00:01:29.160</a></span> | <span class="t">I wanted to share with you about three ideas that I think are worth thinking about. Semantic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=93" target="_blank">00:01:33.480</a></span> | <span class="t">IDs, data augmentation, and unified models. So the first challenge we have is hash-based item</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=100" target="_blank">00:01:40.580</a></span> | <span class="t">IDs. Who here works on recommendation systems? So you probably know that hash-based item IDs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=107" target="_blank">00:01:47.380</a></span> | <span class="t">actually don't encode the contents of the item itself. And then the problem is that every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=111" target="_blank">00:01:51.620</a></span> | <span class="t">time you have a new item, you suffer from the cold start problem, which is that all you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=116" target="_blank">00:01:56.000</a></span> | <span class="t">to relearn about this item all over again. And therefore, then there's also sparsity, right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=122" target="_blank">00:02:02.000</a></span> | <span class="t">whereby you have a long set of tail items that have maybe one or two interactions, or even up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=125" target="_blank">00:02:05.580</a></span> | <span class="t">10, but it's just not enough to learn. So recommendation systems have this issue of being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=129" target="_blank">00:02:09.880</a></span> | <span class="t">very popularity bias. And they just struggle with cold start and sparsity. So the solution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=134" target="_blank">00:02:14.880</a></span> | <span class="t">is semantic IDs that may even involve multimodal content. So here's an example of trainable multimodal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=142" target="_blank">00:02:22.300</a></span> | <span class="t">semantic IDs from Kuaishou. So Kuaishou is kind of like TikTok or Xia Hongsu, it's a short video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=147" target="_blank">00:02:27.980</a></span> | <span class="t">platform in China. I think it's the number two short video platform. You might have used their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=151" target="_blank">00:02:31.900</a></span> | <span class="t">text-to-video model, Kling, which they released sometime last year. So the problem they had,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=156" target="_blank">00:02:36.860</a></span> | <span class="t">you know, being a short video platform, users upload hundreds of millions of short videos every day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=162" target="_blank">00:02:42.220</a></span> | <span class="t">And it's really hard to learn from this short video. So how can we combine static content embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=167" target="_blank">00:02:47.660</a></span> | <span class="t">with dynamic user behavior? Here's how they did it with trainable multimodal semantic IDs. So I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=174" target="_blank">00:02:54.700</a></span> | <span class="t">going to go through each step here. So this is the Kuaishou model. It's a standard two tower network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=181" target="_blank">00:03:01.100</a></span> | <span class="t">On the left, this is the embedding layer for the user, which is a standard sequence of IDs and the user ID.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=190" target="_blank">00:03:10.060</a></span> | <span class="t">And on the right is the embedding layer for the item IDs. So these are fairly standard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=194" target="_blank">00:03:14.300</a></span> | <span class="t">What's new here is that they now take in content input. So all of these slides will be available</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=200" target="_blank">00:03:20.940</a></span> | <span class="t">online. Don't worry about it. I'll make it available right immediately after this. And to encode visual,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=207" target="_blank">00:03:27.740</a></span> | <span class="t">they use ResNet. To encode video descriptions, they use BERT. And to encode audio, they use VGG-ish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=214" target="_blank">00:03:34.940</a></span> | <span class="t">Now, the trick is this. When you have these encoder models, it's very hard to backpropagate and try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=221" target="_blank">00:03:41.420</a></span> | <span class="t">update these encoder model embeddings. So what did they do? Well, firstly, they took all these content</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=226" target="_blank">00:03:46.700</a></span> | <span class="t">embeddings, and then they just concatenated them together. I know it sounds crazy, right? But I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=231" target="_blank">00:03:51.260</a></span> | <span class="t">concatenated them together. Then they learn cluster IDs. So I think they shared in the paper, they had like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=238" target="_blank">00:03:58.060</a></span> | <span class="t">a hundred million short videos, and they learn just via k-means clustering, a thousand cluster IDs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=244" target="_blank">00:04:04.140</a></span> | <span class="t">So that's what you see over there in the model encoder, which is in the boxes at the bottom,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=248" target="_blank">00:04:08.940</a></span> | <span class="t">which is the cluster IDs. So above the cluster IDs, you have the non-trainable embeddings. Below that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=255" target="_blank">00:04:15.260</a></span> | <span class="t">you have the trainable cluster IDs, which are then all mapped to their own embedding table.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=260" target="_blank">00:04:20.460</a></span> | <span class="t">So the trick here is this. The model encoder, as you train a model, the model encoder learns to map</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=265" target="_blank">00:04:25.900</a></span> | <span class="t">the content space via the cluster IDs, which are mapped to the embedding table, to the behavioral space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=271" target="_blank">00:04:31.340</a></span> | <span class="t">So the output is this. These semantic IDs not only outperform regular hash-based IDs on clicks and likes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=280" target="_blank">00:04:40.460</a></span> | <span class="t">right? Like, that's pretty standard. But what they were able to do was they were able to increase</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=284" target="_blank">00:04:44.860</a></span> | <span class="t">co-start coverage, which is the, of a hundred videos that you share, how many of them are new,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=290" target="_blank">00:04:50.540</a></span> | <span class="t">they were able to increase it by 3.6%. And also increase co-start velocity, which is, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=295" target="_blank">00:04:55.900</a></span> | <span class="t">how many new videos were able to hit some threshold of views? And this, they did not share what a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=301" target="_blank">00:05:01.980</a></span> | <span class="t">threshold was, but being able to increase co-start and co-start velocity by these numbers are pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=307" target="_blank">00:05:07.020</a></span> | <span class="t">outstanding. So the, long story short, the benefits of semantic IDs, you can address co-start with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=313" target="_blank">00:05:13.500</a></span> | <span class="t">semantic ID itself, and now your recommendations understand content. So later in the talk,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=318" target="_blank">00:05:18.620</a></span> | <span class="t">we're going to see some amazing sharing from Pinterest and YouTube. And in the YouTube one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=324" target="_blank">00:05:24.460</a></span> | <span class="t">you see how they actually blend language models with semantic IDs, whereby it can actually explain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=331" target="_blank">00:05:31.420</a></span> | <span class="t">why you might like the semantic ID, because it understands the semantic ID, and it's able to give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=335" target="_blank">00:05:35.900</a></span> | <span class="t">human readable explanations, and vice versa. Now, next question, and I'm sure all of this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=342" target="_blank">00:05:42.220</a></span> | <span class="t">everyone here has this challenge. The lifeblood of machine learning is data, good quality data at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=349" target="_blank">00:05:49.340</a></span> | <span class="t">scale. And this is very essential for search, and of course recommendation systems, but search is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=354" target="_blank">00:05:54.780</a></span> | <span class="t">actually far more important. You need a lot of metadata, you need a lot of query expansion, synonyms,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=361" target="_blank">00:06:01.340</a></span> | <span class="t">you need spell checking, you need all sorts of metadata to attach to your search index. But this is very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=367" target="_blank">00:06:07.980</a></span> | <span class="t">costly and high effort to get. In the past, we used to do it with human annotations, or maybe you can try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=371" target="_blank">00:06:11.820</a></span> | <span class="t">to do it automatically. But LLMs have been outstanding at this. And I'm sure everyone here is sort of doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=377" target="_blank">00:06:17.980</a></span> | <span class="t">doing this to some extent, using LLMs for synthetic data and labels. But I want to share with you two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=382" target="_blank">00:06:22.540</a></span> | <span class="t">examples from Spotify and Indeed. Now the Indeed paper, I really like it a lot. So the problem that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=392" target="_blank">00:06:32.860</a></span> | <span class="t">were trying to face is that they were sending job recommendations to users via email. But some of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=399" target="_blank">00:06:39.340</a></span> | <span class="t">these job recommendations were bad. They were just not a good fit for the user, right? So they had poor user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=404" target="_blank">00:06:44.380</a></span> | <span class="t">experience and then users lost trust in the job recommendations. Imagine, and how they would indicate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=409" target="_blank">00:06:49.260</a></span> | <span class="t">that they lost trust was that these job recommendations are not a good fit for me, I'm just going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=413" target="_blank">00:06:53.340</a></span> | <span class="t">unsubscribe. Now the moment a user unsubscribes from your feed or for your newsletter, it's very, very, very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=418" target="_blank">00:06:58.780</a></span> | <span class="t">hard to get them back. Almost impossible. So while they had explicit negative feedback, thumbs up and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=424" target="_blank">00:07:04.380</a></span> | <span class="t">thumbs down, this was very sparse. How often would you actually give thumbs down feedback? Very sparse. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=429" target="_blank">00:07:09.100</a></span> | <span class="t">implicit feedback is often imprecise. What do I mean? If you get some recommendations, but you actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=434" target="_blank">00:07:14.220</a></span> | <span class="t">don't act on it, is it because you didn't like it? Or is it because it's not the right time? Or maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=439" target="_blank">00:07:19.740</a></span> | <span class="t">your wife works there and you don't want to work in the same company as your wife? So the solution they had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=445" target="_blank">00:07:25.260</a></span> | <span class="t">was a lightweight classifier to filter back racks. And I'll tell you why I really like this paper from Indeed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=451" target="_blank">00:07:31.180</a></span> | <span class="t">in the sense that they didn't just share their successes, but they shared the entire process and how they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=455" target="_blank">00:07:35.900</a></span> | <span class="t">get, how they got there. And it was fraught with challenges. Well, of course, the first thing that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=460" target="_blank">00:07:40.700</a></span> | <span class="t">makes me really like it a lot was that they started with evals. So they had their experts label job</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=467" target="_blank">00:07:47.900</a></span> | <span class="t">recommendations and user pairs. And from the user, you have their resume data, you have the activity data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=473" target="_blank">00:07:53.980</a></span> | <span class="t">and they tried to see, hey, you know, is this recommendation a good fit? Then they prompted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=479" target="_blank">00:07:59.820</a></span> | <span class="t">open LLMs, Mistral and LAMA2. Unfortunately, their performance was very poor. These models couldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=485" target="_blank">00:08:05.260</a></span> | <span class="t">really pay attention to what was in the resume and what was in the job description, even though they had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=490" target="_blank">00:08:10.780</a></span> | <span class="t">sufficient context length. And the output was just very generic. So to get it to work, they prompted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=497" target="_blank">00:08:17.580</a></span> | <span class="t">GPT-4. And GPT-4 worked really well. Specifically, GPT-4 had like 90% precision and recall. However,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=504" target="_blank">00:08:24.780</a></span> | <span class="t">it was very costly. They didn't share the actual cost, but it's too slow. It's 22 seconds. Okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=509" target="_blank">00:08:29.900</a></span> | <span class="t">if GPT-4 is too slow, what can we do? Let's try GPT-3.5. Unfortunately, GPT-3.5 had very poor precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=517" target="_blank">00:08:37.820</a></span> | <span class="t">What does this mean? In the sense that of the recommendations that it said were bad,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=524" target="_blank">00:08:44.620</a></span> | <span class="t">only 63% of them were actually bad. What this means is that they were throwing out 37% of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=530" target="_blank">00:08:50.860</a></span> | <span class="t">recommendations, which is one-third. And for a company that tries on recommendations and people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=534" target="_blank">00:08:54.860</a></span> | <span class="t">recruiting through your recommendations, throwing out one-third of them that are actually good is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=540" target="_blank">00:09:00.780</a></span> | <span class="t">quite a guardrail for them. This was their key metric here. And also, GPT-3. So what they did then is they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=547" target="_blank">00:09:07.500</a></span> | <span class="t">fine-tuned GPT-3.5. So you can see the entire journey, right? Open models, GPT-4, GPT-3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=553" target="_blank">00:09:13.180</a></span> | <span class="t">now fine-tuning GPT-3.5. GPT-3.5 got the precision they wanted, 0.3 precision. And you know it's one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=559" target="_blank">00:09:19.260</a></span> | <span class="t">quarter of GPT-4's cost and latency, right? But unfortunately, it's still too slow. It was about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=564" target="_blank">00:09:24.460</a></span> | <span class="t">6.7 seconds, and this would not work in an online filtering system. So therefore, what they did was they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=570" target="_blank">00:09:30.300</a></span> | <span class="t">distilled a lightweight classifier on the fine-tuned GPT-3.5 labels. And this lightweight classifier was able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=577" target="_blank">00:09:37.180</a></span> | <span class="t">achieve very high performance, specifically 0.86 AUCROC. I mean, the numbers may not make sense to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=584" target="_blank">00:09:44.700</a></span> | <span class="t">you, but suffice to say that in an industrial setting, this is pretty good. And of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=588" target="_blank">00:09:48.540</a></span> | <span class="t">they didn't mention the latency, but it was good enough for real-time filtering. I think less than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=591" target="_blank">00:09:51.900</a></span> | <span class="t">200 milliseconds or something. So the outcome of this was that they were able to reduce bad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=598" target="_blank">00:09:58.540</a></span> | <span class="t">recommendations. They were able to cut out bad recommendations by about 20%. So initially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=603" target="_blank">00:10:03.740</a></span> | <span class="t">they had hypothesized that by cutting down recommendations, even though they were bad,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=607" target="_blank">00:10:07.900</a></span> | <span class="t">you will get fewer subscriptions. It's just like sending out links, right? You might have links</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=611" target="_blank">00:10:11.900</a></span> | <span class="t">that are clickbait. Even though they are bad, people just click on it. And they thought that even if we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=615" target="_blank">00:10:15.580</a></span> | <span class="t">cut down recommendations, even if they were bad, we would get lower application rate. But this was not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=619" target="_blank">00:10:19.980</a></span> | <span class="t">the case. In fact, because the recommendations were now better, application rate actually went up by 4%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=627" target="_blank">00:10:27.260</a></span> | <span class="t">And unsubscribe rate went down by 5%. That's quite a lot. So essentially, what this means is that in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=632" target="_blank">00:10:32.380</a></span> | <span class="t">recommendations, quantity is not everything. Quality makes a big difference, and quality here moves the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=637" target="_blank">00:10:37.260</a></span> | <span class="t">needle quite a bit by 5%. The next example I want to share with you is Spotify. So who here knows that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=644" target="_blank">00:10:44.460</a></span> | <span class="t">Spotify has podcasts and audio books? Oh, okay. I guess you guys are not a target audience in this use case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=651" target="_blank">00:10:51.900</a></span> | <span class="t">So Spotify is really known for song and artists, and a lot of their users just search for songs and artists,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=657" target="_blank">00:10:57.180</a></span> | <span class="t">and they're very good at that. But when they started introducing podcasts and audio books,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=662" target="_blank">00:11:02.620</a></span> | <span class="t">how would you help your users know that, you know, these new items are available? And of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=666" target="_blank">00:11:06.940</a></span> | <span class="t">there's a huge co-start problem. Now it's not only co-start on item, it's now co-start on category.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=673" target="_blank">00:11:13.020</a></span> | <span class="t">How do you start growing a new category within your service? And of course, exploratory search was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=679" target="_blank">00:11:19.900</a></span> | <span class="t">essential to the business, right, for expanding beyond music. Spotify doesn't want to just do music,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=685" target="_blank">00:11:25.260</a></span> | <span class="t">songs. They just now want to be doing audio. So the solution to that is a query recommendation system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=692" target="_blank">00:11:32.780</a></span> | <span class="t">So how did they recommend, how first, how did they generate new queries? Well, they have a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=699" target="_blank">00:11:39.340</a></span> | <span class="t">ideas, which is, you know, extracted from catalog titles, playlist titles, you mine it from the search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=703" target="_blank">00:11:43.820</a></span> | <span class="t">logs, you just take the, you just take the artist and then you just add cover to it. And this is what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=709" target="_blank">00:11:49.340</a></span> | <span class="t">they use from existing data. Now you might be wondering like, where's the LLM in this? Well, the LLM is used to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=716" target="_blank">00:11:56.780</a></span> | <span class="t">generate natural language queries. So this might not be sexy, but this works really well, right? Take whatever you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=722" target="_blank">00:12:02.620</a></span> | <span class="t">have with conventional techniques that work really well, and use the LLM to augment it when you need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=727" target="_blank">00:12:07.100</a></span> | <span class="t">it. Don't use the LLM for everything at the start. So now they have these exploratory queries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=732" target="_blank">00:12:12.940</a></span> | <span class="t">When you search for something, you still get the immediate results hit, right? So you take all this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=740" target="_blank">00:12:20.940</a></span> | <span class="t">you add the immediate results, and then you rank these new queries. So this is why when you do a search,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=748" target="_blank">00:12:28.940</a></span> | <span class="t">this is the UX that you're probably going to get right now. I got this from a paper. It may have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=752" target="_blank">00:12:32.300</a></span> | <span class="t">changed recently. So you still see the item queries at the bottom. But at the top, with the query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=757" target="_blank">00:12:37.260</a></span> | <span class="t">recommendations, this is how Spotify informs users without having a banner. Now we have audio books,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=763" target="_blank">00:12:43.180</a></span> | <span class="t">now we have podcasts, right? You search for something, it actually informs you that we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=766" target="_blank">00:12:46.860</a></span> | <span class="t">these new categories. The benefit here is plus 9% exploratory queries. Essentially, one-tenth of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=774" target="_blank">00:12:54.460</a></span> | <span class="t">their users will now exploring their new products. So imagine that one-tenth every day exploring their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=781" target="_blank">00:13:01.420</a></span> | <span class="t">new products. How quickly would you be able to grow your new product category, right? It's actually 1.1 to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=787" target="_blank">00:13:07.820</a></span> | <span class="t">the power of N. It will grow pretty fast. Long story short, I don't have to tell you about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=793" target="_blank">00:13:13.020</a></span> | <span class="t">benefits of LLM augmented synthetic data, richer high quality data at scale, on the tail queries,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=799" target="_blank">00:13:19.660</a></span> | <span class="t">right? Even on the tail queries and the tail items, and it's far lower cost and effort than is even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=804" target="_blank">00:13:24.780</a></span> | <span class="t">possible with human annotation. So later, we also have a talk from Instacart, who will tell us about how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=810" target="_blank">00:13:30.380</a></span> | <span class="t">they use LLMs to improve their search system. Now the last thing I want to share is this challenge,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=820" target="_blank">00:13:40.460</a></span> | <span class="t">whereby right now, in a regular company, the system for ads, for recommendations, for search,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=829" target="_blank">00:13:49.340</a></span> | <span class="t">they're all separate systems. And even for recommendations, the model for homepage recommendations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=835" target="_blank">00:13:55.260</a></span> | <span class="t">the model for item recommendations, the model for ad-to-card recommendations, the model for the thank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=839" target="_blank">00:13:59.900</a></span> | <span class="t">you page recommendations, they may all be different models, right? So you can imagine this, you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=844" target="_blank">00:14:04.380</a></span> | <span class="t">going to have many, many models, but you're going to have, well, leadership expects you to keep the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=849" target="_blank">00:14:09.820</a></span> | <span class="t">same amount of headcount. So then how do you try to get around this, right? You have duplicative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=853" target="_blank">00:14:13.820</a></span> | <span class="t">engineering pipelines, there's a lot of maintenance costs, and improving one model doesn't naturally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=859" target="_blank">00:14:19.180</a></span> | <span class="t">transfer to the improvement in another model. So the solution for this is unified models, right? I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=865" target="_blank">00:14:25.580</a></span> | <span class="t">it works for vision, it works for language, so why not recommendation systems? And we've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=869" target="_blank">00:14:29.740</a></span> | <span class="t">doing this for a while, this is not new. And aside, maybe the text is too small, but this is a tweet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=875" target="_blank">00:14:35.900</a></span> | <span class="t">from Stripe, whereby they built a transformer-based payments fraud model, right? Even for payments,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=882" target="_blank">00:14:42.700</a></span> | <span class="t">the sequence of payments, you can build a foundation model, which is transformer-based.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=886" target="_blank">00:14:46.860</a></span> | <span class="t">So I want to share an example of the unified ranker for search and rexies and Netflix, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=893" target="_blank">00:14:53.420</a></span> | <span class="t">The problem I mentioned, they have teams, they are building bespoke models for search, similar video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=899" target="_blank">00:14:59.180</a></span> | <span class="t">recommendations and pre-query recommendations, like on the search page before you ever enter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=902" target="_blank">00:15:02.780</a></span> | <span class="t">a search grid. High operational costs, you know, missed opportunities from learning throughout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=906" target="_blank">00:15:06.540</a></span> | <span class="t">So their solution is a unified ranker, and they call it the unified contextual ranker,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=912" target="_blank">00:15:12.460</a></span> | <span class="t">which is unicorn. So you can see over here at the bottom, there's the user foundation model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=917" target="_blank">00:15:17.980</a></span> | <span class="t">and in it, you put in a user watch history. And then you also have the context and relevance model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=923" target="_blank">00:15:23.500</a></span> | <span class="t">where you put in the context of the videos and what they've watched.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=926" target="_blank">00:15:26.140</a></span> | <span class="t">Now, the thing about this unified model is that it takes in unified input, right? So now, if you are able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=934" target="_blank">00:15:34.300</a></span> | <span class="t">to find a data schema where all your use cases and all your features can use the same input, you can adopt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=941" target="_blank">00:15:41.420</a></span> | <span class="t">an approach like this, which is similar to multi-task learning. So the input would be the user ID,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=947" target="_blank">00:15:47.660</a></span> | <span class="t">the item ID, you know, the video or the drama or the series, the search query, if a search query exists,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=953" target="_blank">00:15:53.900</a></span> | <span class="t">the country and the task. So of course, they have many different tasks. In this example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=958" target="_blank">00:15:58.140</a></span> | <span class="t">in the paper, they have three different tasks, search pre-query and more like this. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=963" target="_blank">00:16:03.580</a></span> | <span class="t">what they did then was very smart imputation of missing items. So for example, if you are doing an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=971" target="_blank">00:16:11.260</a></span> | <span class="t">item-to-item recommendation, you're just done watching this video, you want to recommend the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=974" target="_blank">00:16:14.540</a></span> | <span class="t">video, you will have no search query. How would you impute it? Well, you just simply use the title of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=979" target="_blank">00:16:19.420</a></span> | <span class="t">current item and try to find similar items. The outcome of this is that this unified model was able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=986" target="_blank">00:16:26.300</a></span> | <span class="t">match or exceed the metrics of their specialized models on multiple tasks. Think about it. I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=992" target="_blank">00:16:32.940</a></span> | <span class="t">it doesn't seem very impressive, right? It may not seem very impressive. Match or exceed. It might seem,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=997" target="_blank">00:16:37.340</a></span> | <span class="t">we did all this work just to match. But imagine unifying all of it, like removing the tech debt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1002" target="_blank">00:16:42.620</a></span> | <span class="t">and building a better foundation for your future iterations. It's going to make you iterate faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1007" target="_blank">00:16:47.340</a></span> | <span class="t">The last example I want to share with you is unified embeddings at Etsy. So you might think that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1012" target="_blank">00:16:52.620</a></span> | <span class="t">embeddings are not very sexy, but this paper from Etsy is really outstanding in what they share in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1018" target="_blank">00:16:58.220</a></span> | <span class="t">this model architecture as well as their system. So the problem they had was,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1022" target="_blank">00:17:02.620</a></span> | <span class="t">how can you help users get better results from very specific queries or very broad queries?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1028" target="_blank">00:17:08.620</a></span> | <span class="t">And if you know that Etsy inventory is constantly changing. They don't have the same products all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1033" target="_blank">00:17:13.340</a></span> | <span class="t">throughout, right? It's very homegrown. So now you might be querying for something like Mother's Day gift,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1038" target="_blank">00:17:18.380</a></span> | <span class="t">that would almost match very few items. I think very few items would have Mother's Day gift in their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1043" target="_blank">00:17:23.900</a></span> | <span class="t">description on their title, right? And you know, lexical embedding, the other problem is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1048" target="_blank">00:17:28.300</a></span> | <span class="t">knowledge-based embeddings, like lexical embedding retrieval, don't account for user preferences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1053" target="_blank">00:17:33.260</a></span> | <span class="t">So how do you try to address this? The problem, how they address this is with unified embedding and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1059" target="_blank">00:17:39.660</a></span> | <span class="t">retrieval. So if you remember, at the start of my presentation, I talked about the Kuaishou two-tower model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1067" target="_blank">00:17:47.340</a></span> | <span class="t">right? There's the user tower, and then there's the item tower. We will see the same pattern again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1072" target="_blank">00:17:52.300</a></span> | <span class="t">And then over here, you see the product tower, right? This is the product encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1076" target="_blank">00:17:56.140</a></span> | <span class="t">So how they encode the product is that they use T5 models for text embeddings, right? Text item</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1081" target="_blank">00:18:01.820</a></span> | <span class="t">descriptions, as well as a query product log for query embeddings. What was the query that was made,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1087" target="_blank">00:18:07.740</a></span> | <span class="t">and what was the product that was eventually clicked or purchased. And then over here on the left,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1092" target="_blank">00:18:12.700</a></span> | <span class="t">you see the query encoder, which is the search query encoder. And they both share encoders for the tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1099" target="_blank">00:18:19.660</a></span> | <span class="t">which is actually the text tokens, the product category, which is a token of itself, and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1105" target="_blank">00:18:25.500</a></span> | <span class="t">user location. So what this means is that now your embedding is able to match user to the location</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1111" target="_blank">00:18:31.500</a></span> | <span class="t">of the product itself. And then of course, to personalize this, they encode the user preferences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1116" target="_blank">00:18:36.940</a></span> | <span class="t">via the query user scale effect, features at the bottom. Essentially, what were the queries that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1121" target="_blank">00:18:41.100</a></span> | <span class="t">user searched for, what did they buy previously, all their preferences. Now, this is, they also shared their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1126" target="_blank">00:18:46.860</a></span> | <span class="t">system architecture. And over here, this is the product encoder from the previous slide,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1131" target="_blank">00:18:51.340</a></span> | <span class="t">and the query encoder from the previous slide. But what's very interesting here is that they added a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1136" target="_blank">00:18:56.140</a></span> | <span class="t">quality vector, because they wanted to ensure that whatever was searched and retrieved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1141" target="_blank">00:19:01.420</a></span> | <span class="t">was actually of good quality in terms of ratings, freshness, and conversion rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1145" target="_blank">00:19:05.980</a></span> | <span class="t">And you know, what they did is they just simply concatenated this quality vector to the product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1150" target="_blank">00:19:10.780</a></span> | <span class="t">embedding vector. But when you do that, for the query vector, you have to expand the product vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1157" target="_blank">00:19:17.260</a></span> | <span class="t">by the same dimension, so that you can do a dot product, or cosine similarity. So essentially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1161" target="_blank">00:19:21.820</a></span> | <span class="t">they just slapped on a constant vector for the query embedding, and it just works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1167" target="_blank">00:19:27.340</a></span> | <span class="t">The result, 2.6% increase in conversion across an entire site. That's quite crazy. And more than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1174" target="_blank">00:19:34.220</a></span> | <span class="t">5% increase in search purchases. If you search for something, the purchase rate increases by 5%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1178" target="_blank">00:19:38.940</a></span> | <span class="t">This is very, very, these are very, very, very good results for e-commerce.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1183" target="_blank">00:19:43.820</a></span> | <span class="t">So the benefits of unified models, you simplify the system, whatever you build to improve one side of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1193" target="_blank">00:19:53.100</a></span> | <span class="t">the tower, improve your model, your unified model also improves other use cases that use these unified</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1199" target="_blank">00:19:59.260</a></span> | <span class="t">models. That said, there may also be the alignment tags. You may find that when you try to build this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1204" target="_blank">00:20:04.700</a></span> | <span class="t">try to compress all 12 use cases into a single unified model, you may need to split it up into maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1209" target="_blank">00:20:09.420</a></span> | <span class="t">two or three separate unified models, because that's just the alignment tags. We're trying to get better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1213" target="_blank">00:20:13.340</a></span> | <span class="t">one task actually makes the other task worse. We have a talk from LinkedIn in this afternoon blog,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1221" target="_blank">00:20:21.980</a></span> | <span class="t">the last talk of the blog, and then we also have a talk from Netflix, which we'll be sharing about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1225" target="_blank">00:20:25.820</a></span> | <span class="t">their unified model at the start of the next blog. All right, the three takeaways I have for you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1230" target="_blank">00:20:30.700</a></span> | <span class="t">think about it, consider it, semantic IDs, data augmentation, and unified models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=2vlCqD6igVA&t=1239" target="_blank">00:20:39.580</a></span> | <span class="t">And of course, stay tuned for the rest of the talks in this track. Okay, that's it. Thank you.</span></div></div></body></html>