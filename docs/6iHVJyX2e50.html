<html><head><title>Llama 2 in LangChain — FIRST Open Source Conversational Agent!</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Llama 2 in LangChain — FIRST Open Source Conversational Agent!</h2><a href="https://www.youtube.com/watch?v=6iHVJyX2e50"><img src="https://i.ytimg.com/vi/6iHVJyX2e50/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=0">0:0</a> Llama 2 Model<br><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=175">2:55</a> Getting Access to Llama 2<br><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=372">6:12</a> Initializing Llama 2 70B with Hugging Face<br><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=497">8:17</a> Quantization and GPU Memory Requirements<br><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=674">11:14</a> Loading Llama 2<br><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=785">13:5</a> Stopping Criteria<br><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=917">15:17</a> Initializing Text Generation Pipeline<br><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=985">16:25</a> Loading Llama 2 in LangChain<br><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1028">17:8</a> Creating Llama 2 Conversational Agent<br><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1186">19:46</a> Prompt Engineering with Llama 2 Chat<br><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1336">22:16</a> Llama 2 Conversational Agent<br><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1454">24:14</a> Future of Open Source LLMs<br><br><div style="text-align: left;"><a href="./6iHVJyX2e50.html">Whisper Transcript</a> | <a href="./transcript_6iHVJyX2e50.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">A few days ago MetaAI released LLAMA2. Now what's exciting about LLAMA2 is that it's open source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=8" target="_blank">00:00:08.560</a></span> | <span class="t">and it is currently the best performing open source model in a big variety of different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=16" target="_blank">00:00:16.000</a></span> | <span class="t">benchmarks. Now one of the things that I'm personally very excited about is when I see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=22" target="_blank">00:00:22.880</a></span> | <span class="t">these new open source models being released one of the first things I do is I try out as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=30" target="_blank">00:00:30.880</a></span> | <span class="t">conversational agent. That is a chatbot that is actually able to use tools and every single time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=39" target="_blank">00:00:39.200</a></span> | <span class="t">that I have tried this so far with other models I've been pretty disappointed. They either cannot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=46" target="_blank">00:00:46.800</a></span> | <span class="t">use tools at all or they're just very unreliable. So this "will it work as a conversational agent"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=55" target="_blank">00:00:55.040</a></span> | <span class="t">benchmark has just become my personal go-to when these new models are released. It's my way of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=61" target="_blank">00:01:01.760</a></span> | <span class="t">benchmarking where open source is compared to OpenAI models which generally speaking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=68" target="_blank">00:01:08.400</a></span> | <span class="t">GPT-3.5, Text to Image 0.0.3 and especially GPT-4. They are pretty capable as conversational agents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=77" target="_blank">00:01:17.040</a></span> | <span class="t">and what I find in real world use cases is that conversational agents are the future of how we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=85" target="_blank">00:01:25.200</a></span> | <span class="t">interact with large language models. Having a simple chatbot that just talks to us is great</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=91" target="_blank">00:01:31.600</a></span> | <span class="t">but it's limited. It doesn't have the flexibility in access to external information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=98" target="_blank">00:01:38.000</a></span> | <span class="t">that a conversational agent will have and it cannot use tools like you know a Python interpreter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=104" target="_blank">00:01:44.800</a></span> | <span class="t">that a conversational agent can use. So that for me is super important and finally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=112" target="_blank">00:01:52.800</a></span> | <span class="t">with LLAMA2 we have a model that has actually passed that test. I fairly quickly managed to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=120" target="_blank">00:02:00.400</a></span> | <span class="t">sort of prompt engineer my way to getting a LLAMA2 model, the fine-tuned chat version of LLAMA2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=128" target="_blank">00:02:08.080</a></span> | <span class="t">to work as a conversational agent which I think is pretty insane. So what I want to do in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=135" target="_blank">00:02:15.120</a></span> | <span class="t">video is show you how you can do the same. So we're going to take a look at the biggest LLAMA2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=141" target="_blank">00:02:21.440</a></span> | <span class="t">model. It's the 70B parameter model. We're going to quantize it so that we can fit it onto a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=146" target="_blank">00:02:26.320</a></span> | <span class="t">A100 GPU. I'm actually going to be running all this on Colab so you can actually go ahead and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=151" target="_blank">00:02:31.920</a></span> | <span class="t">run the same notebook. With this approach we're going to be able to fit that 70 billion parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=157" target="_blank">00:02:37.280</a></span> | <span class="t">model into at a minimum 35 gigabytes of GPU memory but actually after multiple interactions it kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=167" target="_blank">00:02:47.440</a></span> | <span class="t">of pushes its way up to more like 38 gigabytes which is still not that much for such a performing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=175" target="_blank">00:02:55.600</a></span> | <span class="t">model. Now let's just dive into how we can actually do this. So the first thing we're going to have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=181" target="_blank">00:03:01.280</a></span> | <span class="t">do is actually sign up and get access to these models. It's pretty straightforward, it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=187" target="_blank">00:03:07.280</a></span> | <span class="t">take that long. So what you can do for this is head on over to huggingface.co/meta-llama</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=194" target="_blank">00:03:14.800</a></span> | <span class="t">and you want to go over to the meta website here. So we click on that and we just want to request</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=202" target="_blank">00:03:22.720</a></span> | <span class="t">access to the next version of Llama. So you fill that out and for me I got a response almost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=210" target="_blank">00:03:30.160</a></span> | <span class="t">instantly through using two different emails and basically they're going to send you something like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=216" target="_blank">00:03:36.000</a></span> | <span class="t">this. So it's just okay you're all set, start building with Llama2. It also gives you model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=222" target="_blank">00:03:42.080</a></span> | <span class="t">weights that are available. This is not every single Llama2 model, there is also a 34 billion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=228" target="_blank">00:03:48.400</a></span> | <span class="t">parameter model which they have not finished testing yet so that hasn't been released just yet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=233" target="_blank">00:03:53.920</a></span> | <span class="t">but the one that we are going to be using is this Llama2-70b-chat. So on HuggingFace we need to go to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=242" target="_blank">00:04:02.800</a></span> | <span class="t">Llama2-70b-chat-hf. This is the model that we want to be using. So you'll see that there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=255" target="_blank">00:04:15.200</a></span> | <span class="t">this access Llama2 on HuggingFace. One thing you need to be aware of here is that, well actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=263" target="_blank">00:04:23.520</a></span> | <span class="t">it says it right here, your HuggingFace account and email address must match the email you provide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=268" target="_blank">00:04:28.400</a></span> | <span class="t">on the meta website. So a minute ago when we entered our details on the meta website make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=274" target="_blank">00:04:34.480</a></span> | <span class="t">sure you use the email that you also use on HuggingFace. So once you've done that you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=280" target="_blank">00:04:40.560</a></span> | <span class="t">click this, you can submit and as long as those emails line up you will get access fairly quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=288" target="_blank">00:04:48.960</a></span> | <span class="t">Now one thing that you will need is one we have to wait for that access to come through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=294" target="_blank">00:04:54.400</a></span> | <span class="t">but we also need to go down over to our profile, we go to settings and we need to get an access token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=304" target="_blank">00:05:04.400</a></span> | <span class="t">So this will allow us to download the model within our code. So you will actually need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=312" target="_blank">00:05:12.880</a></span> | <span class="t">create a new token. I'm just going to call this Meta Llama and we just need read permissions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=319" target="_blank">00:05:19.840</a></span> | <span class="t">So with that we generate a token and I'm just going to copy that. So this is a notebook that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=327" target="_blank">00:05:27.120</a></span> | <span class="t">we're going to be working through in this video. There will be a link to this at the top of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=332" target="_blank">00:05:32.000</a></span> | <span class="t">video right now so you can follow along if you like although I will just pre-warn you that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=338" target="_blank">00:05:38.320</a></span> | <span class="t">parts of this notebook can take a little bit of time particularly when you're downloading the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=344" target="_blank">00:05:44.160</a></span> | <span class="t">model. So with that in mind I wouldn't even necessarily recommend running this on Colab</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=349" target="_blank">00:05:49.840</a></span> | <span class="t">because you're going to have to re-download the model like every day that you use this which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=356" target="_blank">00:05:56.640</a></span> | <span class="t">not ideal and it's fairly expensive. So you should probably run this on your local computer if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=365" target="_blank">00:06:05.680</a></span> | <span class="t">have a good GPU or on a cloud service somewhere. So we come down to here you'll need to enter your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=377" target="_blank">00:06:17.280</a></span> | <span class="t">Hugging Face API key in here and let me just come down and show you what is happening. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=386" target="_blank">00:06:26.160</a></span> | <span class="t">there's a fair bit of code that is just kind of initializing the model here for us and as I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=391" target="_blank">00:06:31.840</a></span> | <span class="t">mentioned this download of the model, this download and initialization of the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=397" target="_blank">00:06:37.600</a></span> | <span class="t">does take a bit of time. So this has actually been running now for one hour and 10 minutes or a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=406" target="_blank">00:06:46.000</a></span> | <span class="t">little bit longer and I'm not expecting it to finish too soon although I'm hoping it will not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=413" target="_blank">00:06:53.200</a></span> | <span class="t">take too much longer. But essentially we're going to be waiting a while for the model to download</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=419" target="_blank">00:06:59.200</a></span> | <span class="t">but let's come up here and just kind of go through that code that we've used to initialize it first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=426" target="_blank">00:07:06.560</a></span> | <span class="t">Right so we're doing a pip install of all the libraries that we're going to be using.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=430" target="_blank">00:07:10.720</a></span> | <span class="t">We do need all of these okay Hugging Face Transformers then we have like these libraries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=437" target="_blank">00:07:17.360</a></span> | <span class="t">and these libraries are basically so we can run large language models and also optimize how we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=443" target="_blank">00:07:23.840</a></span> | <span class="t">running those. And we also have LangChain so later on in the notebook we're going to be using LangChain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=449" target="_blank">00:07:29.840</a></span> | <span class="t">to create that conversational agent. So come down to here what we need here is the large language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=458" target="_blank">00:07:38.800</a></span> | <span class="t">model, a tokenizer for the large language model and also a stopping criteria object which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=464" target="_blank">00:07:44.880</a></span> | <span class="t">more of an optional item I would say for this model. But let's talk about those the LLM at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=472" target="_blank">00:07:52.720</a></span> | <span class="t">first. So the LLM we have this model ID this is coming from Hugging Face so if we come up here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=481" target="_blank">00:08:01.280</a></span> | <span class="t">again we can type in llama2 and we see that there's all these different model IDs. The one that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=488" target="_blank">00:08:08.480</a></span> | <span class="t">using is this one here. Okay so we have our model ID here we're just checking that we have a GPU</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=496" target="_blank">00:08:16.800</a></span> | <span class="t">available. Here we have this bits and bytes config object. I've spoken about this in previous videos</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=504" target="_blank">00:08:24.880</a></span> | <span class="t">so I'm not going to go too into depth but essentially what we're doing here is we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=511" target="_blank">00:08:31.760</a></span> | <span class="t">minimizing the amount of GPU memory we need to store the model. Now this is a 70 billion parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=518" target="_blank">00:08:38.640</a></span> | <span class="t">model so let's just do some very quick maths here. So 70 billion parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=525" target="_blank">00:08:45.520</a></span> | <span class="t">Each of those parameters using the standard data type is 32 bits of information. Okay so the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=539" target="_blank">00:08:59.360</a></span> | <span class="t">standard data type is a float 32 so float 32 and that is 32 bits of information. Within each byte</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=550" target="_blank">00:09:10.000</a></span> | <span class="t">there is 8 bits of information so we can actually calculate how much memory we need to store that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=559" target="_blank">00:09:19.840</a></span> | <span class="t">model. Okay it is just the params by the data type divided by 8. Okay and that gives us this many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=570" target="_blank">00:09:30.240</a></span> | <span class="t">bytes of information which is 280 gigabytes which is a lot right that's many many GPUs many A100s</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=584" target="_blank">00:09:44.080</a></span> | <span class="t">single A100 I think is 40 gigabytes so yeah we need we need a few of those. Now by doing this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=593" target="_blank">00:09:53.440</a></span> | <span class="t">bits and bytes quantization we can minimize that so what we're essentially doing is switching from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=600" target="_blank">00:10:00.000</a></span> | <span class="t">a float 32 data type to an int 4 data type. Okay and that contains four bits of information. Okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=609" target="_blank">00:10:09.920</a></span> | <span class="t">so now each one of those parameters is not 32 bits it's four bits so let's calculate that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=617" target="_blank">00:10:17.920</a></span> | <span class="t">we have int 4 divided by 8 which gives us this so that is 35 gigabytes of information. Now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=628" target="_blank">00:10:28.720</a></span> | <span class="t">that's not precise because when we're doing this quantization method if we just converted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=636" target="_blank">00:10:36.240</a></span> | <span class="t">everything into int 4 basically we would lose a lot of performance. This works in a more intelligent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=641" target="_blank">00:10:41.600</a></span> | <span class="t">way by quantizing different parts of the model that essentially don't need quite as much precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=650" target="_blank">00:10:50.320</a></span> | <span class="t">Then the bits that do require more precision we convert into 16-bit floats so it will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=659" target="_blank">00:10:59.680</a></span> | <span class="t">a little bit more than 35 gigabytes essentially but we're going to be within that ballpark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=665" target="_blank">00:11:05.840</a></span> | <span class="t">So that's great and allows us to load this model onto a single A100 which is pretty incredible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=672" target="_blank">00:11:12.320</a></span> | <span class="t">Then what we need to do is we load the model config from Hogan Face Transformers because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=680" target="_blank">00:11:20.000</a></span> | <span class="t">we're downloading that from Hogan Face Transformers we need to make sure we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=682" target="_blank">00:11:22.800</a></span> | <span class="t">using our authorization token which you will need to set in here and then we're also going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=689" target="_blank">00:11:29.680</a></span> | <span class="t">download the LLAMA2 model itself. Now we need to have the Trust Remote code in there because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=697" target="_blank">00:11:37.360</a></span> | <span class="t">this is a big model and there is custom code that will allow us to load that model. You don't need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=704" target="_blank">00:11:44.720</a></span> | <span class="t">that for all models on Transformers but you do need it for this one. We have the config object</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=710" target="_blank">00:11:50.400</a></span> | <span class="t">which we just initialize up here and we also have the quantization config which we initialize up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=716" target="_blank">00:11:56.080</a></span> | <span class="t">here. Device map needs to be set to auto and we again need to pass in our authorization token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=724" target="_blank">00:12:04.640</a></span> | <span class="t">which we do here. Then after that we switch the model into evaluation mode which basically means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=730" target="_blank">00:12:10.720</a></span> | <span class="t">we're not training the model we're going to be using for inference or prediction. Then after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=736" target="_blank">00:12:16.640</a></span> | <span class="t">that we just wait. This is almost done now so I think it's just finished downloading the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=745" target="_blank">00:12:25.360</a></span> | <span class="t">and now we're going to need to wait for it to actually initialize the model from all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=751" target="_blank">00:12:31.200</a></span> | <span class="t">those downloaded shards that we just created. I will see you in a few minutes when that is finished.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=759" target="_blank">00:12:39.200</a></span> | <span class="t">Everything has now loaded and initialized so we can get on with the rest of the code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=767" target="_blank">00:12:47.120</a></span> | <span class="t">We need a tokenizer. Tokenizer just converts plaintext into basically what the model will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=774" target="_blank">00:12:54.640</a></span> | <span class="t">reading. I just need to make sure I define this and I can rerun that. Converts plaintext to tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=784" target="_blank">00:13:04.320</a></span> | <span class="t">which a model will read and then we come down to the stopping criteria for model. Now with smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=791" target="_blank">00:13:11.440</a></span> | <span class="t">models this is pretty important. With this model I would say less so but we can add this in anywhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=798" target="_blank">00:13:18.800</a></span> | <span class="t">as a precaution. Basically if we see that the model has generated these two items which are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=808" target="_blank">00:13:28.400</a></span> | <span class="t">basically this is from like a chat log so we'd have the assistant it would type a reply and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=814" target="_blank">00:13:34.800</a></span> | <span class="t">if it moves on to the next line and starts generating the text for the human response</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=819" target="_blank">00:13:39.040</a></span> | <span class="t">well it's generating too much text and we want to cut it off. We have that as a stopping criteria</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=826" target="_blank">00:13:46.240</a></span> | <span class="t">and we also have these three backticks. The reason we use these three backticks is because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=831" target="_blank">00:13:51.680</a></span> | <span class="t">when we are using Llama2 as a conversational agent we actually ask it to reply to everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=842" target="_blank">00:14:02.320</a></span> | <span class="t">in essentially markdown of a JSON output. So we'll have it reply to everything in this format.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=852" target="_blank">00:14:12.880</a></span> | <span class="t">Then in here we'll have like an action which is something like user calculator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=858" target="_blank">00:14:18.400</a></span> | <span class="t">and also the action input. So it would be like two plus two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=867" target="_blank">00:14:27.760</a></span> | <span class="t">So that is why we're using this or including this within the sub list. Essentially once we get to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=878" target="_blank">00:14:38.560</a></span> | <span class="t">here we want the chatbot to stop generating anything. As I said with this model it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=886" target="_blank">00:14:46.320</a></span> | <span class="t">seem to be that necessary so you can add it in there as a precaution but actually what I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=891" target="_blank">00:14:51.760</a></span> | <span class="t">to do is just skip that for now. I don't necessarily need that to be in there. If you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=898" target="_blank">00:14:58.240</a></span> | <span class="t">do want to include that in there what you'll need to do is just uncomment that and you'll have that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=904" target="_blank">00:15:04.640</a></span> | <span class="t">in there. I'm not going to initialize it with that. If we do see any issues then we'll go back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=913" target="_blank">00:15:13.520</a></span> | <span class="t">and run that with the stopping criteria included. This is just initializing the text generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=921" target="_blank">00:15:21.200</a></span> | <span class="t">pipeline with HuggingFace. We can now ask it to generate something. This is a question I've used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=928" target="_blank">00:15:28.000</a></span> | <span class="t">a few times in the past. We just want to make sure that it is actually working on the HuggingFace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=933" target="_blank">00:15:33.360</a></span> | <span class="t">side of things. Can this HuggingFace initiated model generate some text? It will take a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=940" target="_blank">00:15:40.640</a></span> | <span class="t">bit of time. As I said before this is exciting because it is finally able to at least at a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=949" target="_blank">00:15:49.760</a></span> | <span class="t">basic level act as a conversational agent. In terms of speed and hardware requirements it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=959" target="_blank">00:15:59.120</a></span> | <span class="t">not the most optimal solution. At least not yet. That's something that can be solved with more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=967" target="_blank">00:16:07.040</a></span> | <span class="t">optimized hardware or just kind of throwing a load of hardware at it at least on the time side of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=972" target="_blank">00:16:12.080</a></span> | <span class="t">things. That will take a little while to run and we see that we get this response which I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=980" target="_blank">00:16:20.480</a></span> | <span class="t">is relatively accurate. I haven't read through it but it looks pretty good. Then what we want to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=987" target="_blank">00:16:27.520</a></span> | <span class="t">is right now we have everything HuggingFace. We now want to transfer that over into LangChain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=992" target="_blank">00:16:32.320</a></span> | <span class="t">We're going to do that by initializing this HuggingFace pipeline object from LangChain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=999" target="_blank">00:16:39.520</a></span> | <span class="t">and initializing it with our pipeline that we initialized up here. Then we just treat that as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1007" target="_blank">00:16:47.600</a></span> | <span class="t">the LLM. We'll run that. We can then run this again and this will produce a pretty similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1016" target="_blank">00:16:56.000</a></span> | <span class="t">output to what we got up here. We can see we get kind of similar output. This is just telling us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1024" target="_blank">00:17:04.000</a></span> | <span class="t">the same sort of stuff but with more text. Now what I want to do, come down to here. We have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1031" target="_blank">00:17:11.040</a></span> | <span class="t">everything initialized in LangChain. Now what we can do is use all of the tooling that comes with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1037" target="_blank">00:17:17.680</a></span> | <span class="t">LangChain to initialize our conversational agent. Now conversational agent as I mentioned before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1043" target="_blank">00:17:23.280</a></span> | <span class="t">is conversational. That means it has some sort of conversational memory and it is also able to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1050" target="_blank">00:17:30.320</a></span> | <span class="t">tools. That is kind of the advantage of using a conversational agent versus just a standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1056" target="_blank">00:17:36.640</a></span> | <span class="t">chatbot. We initialize both of those. Conversational buffer window memory. This is going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1063" target="_blank">00:17:43.440</a></span> | <span class="t">remember the previous five interactions and we're also just going to load a LLM math tool. It's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1069" target="_blank">00:17:49.680</a></span> | <span class="t">calculator. We initialize both of those and then here we have what is an output parser. We don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1080" target="_blank">00:18:00.400</a></span> | <span class="t">need this for this model. You can have it in there as a precaution again if you like but for the most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1088" target="_blank">00:18:08.080</a></span> | <span class="t">part I've found that it doesn't actually need this with good prompting. Essentially what I would do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1094" target="_blank">00:18:14.000</a></span> | <span class="t">usually with this output parser is if the agent returns some text without the correct format, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1102" target="_blank">00:18:22.560</a></span> | <span class="t">without that JSON format that I mentioned earlier, I would assume that that's trying to respond</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1108" target="_blank">00:18:28.800</a></span> | <span class="t">directly to the user. All this output parser does is kind of reformats that into the correct JSON</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1116" target="_blank">00:18:36.080</a></span> | <span class="t">like response but as I said we can ignore it. We don't need it necessarily for at least the tools</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1123" target="_blank">00:18:43.680</a></span> | <span class="t">that we're using here. Maybe in a more complex scenario it might come in more use. If you did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1131" target="_blank">00:18:51.520</a></span> | <span class="t">want to use that you just uncomment that and run it but as mentioned let's skip that and just see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1138" target="_blank">00:18:58.560</a></span> | <span class="t">how the agent performs without it. Again it's just like a precaution. We initialize the agent here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1146" target="_blank">00:19:06.720</a></span> | <span class="t">We're using this chat conversational react description agent and this is kind of standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1154" target="_blank">00:19:14.000</a></span> | <span class="t">agent initialization parameters. What I want to show you here is the prompt that we initially use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1161" target="_blank">00:19:21.680</a></span> | <span class="t">Now this prompt doesn't work very well. One like this initial system prompt is super long. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1171" target="_blank">00:19:31.600</a></span> | <span class="t">not that useful. Then we have the user prompt template here which again is super long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1177" target="_blank">00:19:37.920</a></span> | <span class="t">and it doesn't work that well. I've modified those. One thing that is slightly different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1188" target="_blank">00:19:48.160</a></span> | <span class="t">or specific to LLAMA2 is the use of these special tokens. We have this which indicates the start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1195" target="_blank">00:19:55.600</a></span> | <span class="t">of some instructions, this which indicates the end of instructions, this indicates the start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1200" target="_blank">00:20:00.640</a></span> | <span class="t">of system message so that initial message that tells the chatbot or LLM how to behave and this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1207" target="_blank">00:20:07.040</a></span> | <span class="t">indicates the end of the system message. We initialize our system message and we include</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1214" target="_blank">00:20:14.400</a></span> | <span class="t">that sort of initialization of the system message in there. Then we go through we say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1221" target="_blank">00:20:21.200</a></span> | <span class="t">assistant is an expert JSON builder designed to assess a wide range of tasks. The intention here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1227" target="_blank">00:20:27.600</a></span> | <span class="t">is to really drill in the point that assistant needs to respond with JSON. We also mentioned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1234" target="_blank">00:20:34.880</a></span> | <span class="t">it needs to respond with the action and action input parameters. We can see an example of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1241" target="_blank">00:20:41.520</a></span> | <span class="t">in here. In this example I'm saying this is how to use a calculator. You need to say action</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1247" target="_blank">00:20:47.360</a></span> | <span class="t">calculator and what you would like to use with the calculator. Then we have some future examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1255" target="_blank">00:20:55.680</a></span> | <span class="t">in here. We have just responding directly to the user. We need to use this JSON format.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1263" target="_blank">00:21:03.520</a></span> | <span class="t">Using calculator again use the JSON format. We just go through and keep giving a few of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1271" target="_blank">00:21:11.440</a></span> | <span class="t">examples. At the end of system message we put that end of system message token. We can run that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1281" target="_blank">00:21:21.840</a></span> | <span class="t">and then we come down to here. This is another thing that they found in the paper is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1291" target="_blank">00:21:31.840</a></span> | <span class="t">LLAMA2 over multiple interactions seem to forget those initial instructions. All I'm doing here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1301" target="_blank">00:21:41.120</a></span> | <span class="t">is saying we have some instructions. I'm adding those instruction tags in there and I'm summarizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1306" target="_blank">00:21:46.800</a></span> | <span class="t">like giving a little reminder to LLAMA2. Respond to the following in JSON with action and action</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1311" target="_blank">00:21:51.760</a></span> | <span class="t">input values. We're just appending that or adding that to every user query which we can see here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1320" target="_blank">00:22:00.080</a></span> | <span class="t">Then we just modify the human message prompt template and what we end up with is this which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1328" target="_blank">00:22:08.800</a></span> | <span class="t">you can see down here. We're going to have that with every human message. Now we can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1338" target="_blank">00:22:18.400</a></span> | <span class="t">begin asking questions. I just ran this one. Hey, how are you today? We see that we get this output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1345" target="_blank">00:22:25.440</a></span> | <span class="t">Final answer. I'm good, thanks. How are you? That's pretty good. Let's try what is 4 to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1353" target="_blank">00:22:33.360</a></span> | <span class="t">power of 2.1. We see that's correctly using a calculator. It has the action input which is 4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1362" target="_blank">00:22:42.640</a></span> | <span class="t">to the power of 2.1 in Python. This interaction takes a little bit longer because there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1369" target="_blank">00:22:49.280</a></span> | <span class="t">multiple LLM calls happening here. The first LLM call produces the I need to use a calculator and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1375" target="_blank">00:22:55.760</a></span> | <span class="t">the input to that calculator. This is sent back to line train and this is executed in a Python</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1383" target="_blank">00:23:03.440</a></span> | <span class="t">interpreter. We get this answer from that. That is sent back to the assistant and based on that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1392" target="_blank">00:23:12.400</a></span> | <span class="t">final answer it knows that it can give the answer back to us. The action is final answer. It looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1399" target="_blank">00:23:19.680</a></span> | <span class="t">like the answer is this. That is the output that we get there. Now let's use our conversational</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1408" target="_blank">00:23:28.000</a></span> | <span class="t">history and ask it to multiply that previous number by 3. Let's run that. We can see the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1417" target="_blank">00:23:37.440</a></span> | <span class="t">first item, the calculator, it is being used correctly. We have that 18.379 multiplied by 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1425" target="_blank">00:23:45.280</a></span> | <span class="t">Again, it's going to take a little moment because it needs to get the answer and generate a new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1433" target="_blank">00:23:53.680</a></span> | <span class="t">LLM response based on that answer. Then we get our answer and we have this 55.13 and that's what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1443" target="_blank">00:24:03.760</a></span> | <span class="t">we get. This is pretty good. Now, I would say as you saw, these answers where it's going through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1451" target="_blank">00:24:11.920</a></span> | <span class="t">multiple steps, it's taking a minute for each one. A lot of that time seems to be spinning up a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1457" target="_blank">00:24:17.440</a></span> | <span class="t">Python interpreter. It's not fully on the LLM in this case, but it does take a little bit of time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1465" target="_blank">00:24:25.600</a></span> | <span class="t">Naturally, that is probably one of the biggest issues with using Longitude at the moment. It</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1471" target="_blank">00:24:31.360</a></span> | <span class="t">takes a lot of GPU memory to run it. That comes with high costs. Especially if you are running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1477" target="_blank">00:24:37.200</a></span> | <span class="t">it on a single GPU like we are with quantization, which slows the whole thing down, things are going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1483" target="_blank">00:24:43.280</a></span> | <span class="t">to take a little bit of time. Nonetheless, I think this looks really cool. What we've done here is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1490" target="_blank">00:24:50.400</a></span> | <span class="t">a very simple agent. It's just using a calculator. We're not stress testing this. Honestly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1499" target="_blank">00:24:59.680</a></span> | <span class="t">if we want to start using other tools, I think we might run into some issues that require a bit more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1506" target="_blank">00:25:06.560</a></span> | <span class="t">tweaking and prompt engineering than what I have done here. I'm optimistic that we can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1513" target="_blank">00:25:13.040</a></span> | <span class="t">use this for other tools. When you consider that even GPT 3.5, even that model is not that good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1523" target="_blank">00:25:23.600</a></span> | <span class="t">at just producing the JSON response when you use it as a conversational agent. It can, and it can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1531" target="_blank">00:25:31.760</a></span> | <span class="t">do it so reliably, but it's not perfect. The fact that LLM 2 and open source model that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1540" target="_blank">00:25:40.320</a></span> | <span class="t">fitting on a single GPU is at least somewhat comparable to one of the best large language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1548" target="_blank">00:25:48.160</a></span> | <span class="t">models in the world, I think that is pretty incredible. I'm very excited to see where this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1554" target="_blank">00:25:54.720</a></span> | <span class="t">goes. Naturally, LLM 2 has only been around for a few days as of me recording this. We're probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1562" target="_blank">00:26:02.560</a></span> | <span class="t">going to see a lot of new models built by the community on top of LLM 2 appear within probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1571" target="_blank">00:26:11.920</a></span> | <span class="t">the next few days from now, and especially in the coming weeks and months. I'll be very excited to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1579" target="_blank">00:26:19.920</a></span> | <span class="t">see where that goes. For now, I'm going to leave it there for this video. I hope this has all been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1587" target="_blank">00:26:27.040</a></span> | <span class="t">useful and interesting. Thank you very much for watching, and I will see you again in the next one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6iHVJyX2e50&t=1604" target="_blank">00:26:44.160</a></span> | <span class="t">[END]</span></div></div></body></html>