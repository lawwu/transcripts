<html><head><title>‘We Must Slow Down the Race’ – X AI,  GPT 4 Can Now Do Science and Altman GPT 5 Statement</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }
        .container {
            width: 80%;
            margin: auto;
            overflow: hidden;
        }
        h2, h3 {
            color: #333;
            text-align: center;
        }
        a {
            color: #0000FF;  /* Traditional blue color for links */
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        img {
            display: block;
            margin: auto;
            max-width: 100%;
        }
        .c {
            margin: 10px 0;
        }
        .s, .t {
            display: inline-block;
            margin-right: 5px;
        }
        .max-width {
            max-width: 800px;
            margin: auto;
        }
    </style>
    
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>‘We Must Slow Down the Race’ – X AI,  GPT 4 Can Now Do Science and Altman GPT 5 Statement</h2><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0"><img src="https://i.ytimg.com/vi/qOoe3ZpciI0/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=30">0:30</a> Godlike AI<br><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=135">2:15</a> Altmans Statement<br><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=169">2:49</a> X AI<br><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=224">3:44</a> Open AI<br><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=357">5:57</a> Emergent Abilities<br><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=413">6:53</a> Undesirable emergent abilities<br><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=525">8:45</a> The landscape of AI capabilities<br><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=587">9:47</a> The AI Dilemma<br><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=657">10:57</a> Rob Miles<br><br><div style="text-align: left;"><a href="./qOoe3ZpciI0.html">Whisper Transcript</a> | <a href="./transcript_qOoe3ZpciI0.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">There were several significant developments in the last few days linked to GPT-4 and OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=6" target="_blank">00:00:06.200</a></span> | <span class="t">I could honestly have done a video on each of them, but realized that it might be better to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=10" target="_blank">00:00:10.640</a></span> | <span class="t">do a single video tracing a single article covering seven major points. I'm going to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=16" target="_blank">00:00:16.680</a></span> | <span class="t">this fascinating piece from the FT, which millions of people have now read, to run you through what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=21" target="_blank">00:00:21.380</a></span> | <span class="t">has happened, including Sam Altman's revelation on GPT-5, Elon Musk's new AI company, and GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=29" target="_blank">00:00:29.120</a></span> | <span class="t">conducting science. The author, by the way, is an investor in Anthropic and a co-author of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=35" target="_blank">00:00:35.480</a></span> | <span class="t">State of AI Annual Report, and he puts it like this. A three-letter acronym doesn't capture the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=41" target="_blank">00:00:41.980</a></span> | <span class="t">enormity of what AGI would represent, so I will refer to it as what it is, godlike AI. This would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=48" target="_blank">00:00:48.740</a></span> | <span class="t">be a super intelligent computer that learns and develops autonomously, that understands its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=54" target="_blank">00:00:54.140</a></span> | <span class="t">environment without the need for supervision, and that can transform the world around it. And the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=59" target="_blank">00:00:59.000</a></span> | <span class="t">author, Ian Hogarth, says we are not there yet, but the nature of the technology makes it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=64" target="_blank">00:01:04.500</a></span> | <span class="t">exceptionally difficult to predict exactly when we will get there. The article presents this as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=69" target="_blank">00:01:09.480</a></span> | <span class="t">diagram, with the exponential curve going up towards AGI, and a much less impressive curve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=75" target="_blank">00:01:15.580</a></span> | <span class="t">on the progress on alignment, which he describes as aligning AI systems with human values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=81" target="_blank">00:01:21.440</a></span> | <span class="t">Now I know what some of you may be thinking. Surely those at the top of OpenAI disagree on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=86" target="_blank">00:01:26.180</a></span> | <span class="t">this gap between capabilities and alignment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=88" target="_blank">00:01:28.880</a></span> | <span class="t">Well, first here is Jan Leiker, who is the alignment team lead at OpenAI. What does he think?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=95" target="_blank">00:01:35.280</a></span> | <span class="t">He wants everyone to be reminded that aligning smarter-than-human AI systems with human values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=101" target="_blank">00:01:41.080</a></span> | <span class="t">is an open research problem, which basically means it's unsolved. But what about those at the very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=106" target="_blank">00:01:46.680</a></span> | <span class="t">top of OpenAI, like Sam Altman? When he was drafting his recent statement on the path to AGI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=112" target="_blank">00:01:52.120</a></span> | <span class="t">he sent it to Nate Suarez of the Machine Intelligence Research Institute. For one of the paragraphs, Nate wrote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=118" target="_blank">00:01:58.760</a></span> | <span class="t">this:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=119" target="_blank">00:01:59.360</a></span> | <span class="t">"I think that if we do keep running ahead with the current capabilities to alignment ratio, or even a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=124" target="_blank">00:02:04.960</a></span> | <span class="t">slightly better one, we die." After this, Sam Altman actually adjusted the statement, adding:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=130" target="_blank">00:02:10.560</a></span> | <span class="t">"That said, it's important that the ratio of safety progress to capability progress increases."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=135" target="_blank">00:02:15.600</a></span> | <span class="t">Going back to the article, the author makes the point that there are not that many people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=140" target="_blank">00:02:20.000</a></span> | <span class="t">directly employed in this area of alignment across the core AGI labs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=145" target="_blank">00:02:25.360</a></span> | <span class="t">And what happened to that "pause the experiment" letter that I did a video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=148" target="_blank">00:02:28.640</a></span> | <span class="t">on? Well, as Hogarth points out, the letter itself became a controversy. So many people in my comments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=154" target="_blank">00:02:34.600</a></span> | <span class="t">wrote that the only reason certain people are signing this is to slow OpenAI down so that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=159" target="_blank">00:02:39.800</a></span> | <span class="t">can catch up. And this cynicism unfortunately has some new evidence that it can cite, with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=164" target="_blank">00:02:44.680</a></span> | <span class="t">Musk forming his new AI company called XAI. This was reported 48 hours ago in the Wall Street Journal,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=172" target="_blank">00:02:52.200</a></span> | <span class="t">but people have seen this coming for months now. Apparently the company has recruited Igor Babushkin</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=178" target="_blank">00:02:58.520</a></span> | <span class="t">Deepmind but has not been that successful at recruiting people from OpenAI. And I do have one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=184" target="_blank">00:03:04.760</a></span> | <span class="t">theory as to why. Again, according to the Wall Street Journal, when Musk left OpenAI in February</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=191" target="_blank">00:03:11.560</a></span> | <span class="t">of 2018, he explained that he thought he had a better chance of creating AGI through Tesla,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=198" target="_blank">00:03:18.200</a></span> | <span class="t">where he had access to greater resources. When he announced his departure, a young researcher</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=203" target="_blank">00:03:23.160</a></span> | <span class="t">at OpenAI questioned whether Mr. Musk had thought through the safety implications. According to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=208" target="_blank">00:03:28.400</a></span> | <span class="t">reporting, he then got frustrated and insulted that intern. Since then, he's also paused OpenAI's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=215" target="_blank">00:03:35.320</a></span> | <span class="t">access to Twitter's database for training its new models. So it could be that GPT-5 isn't quite as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=222" target="_blank">00:03:42.040</a></span> | <span class="t">good at tweeting as GPT-4. A few days ago, Sam Altman responded to the letter and also broke</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=228" target="_blank">00:03:48.120</a></span> | <span class="t">news about GPT-5. Apologies for the quality, this was a private event and this was the only footage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=234" target="_blank">00:03:54.920</a></span> | <span class="t">available. But unfortunately, I think the letter is missing like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=238" target="_blank">00:03:58.280</a></span> | <span class="t">most technical nuance about where we need to pause. Like an earlier version of the letter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=243" target="_blank">00:04:03.280</a></span> | <span class="t">claimed that OpenAI is training GPT-5 right now. We are not normal for some time. So in that sense,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=247" target="_blank">00:04:07.760</a></span> | <span class="t">it was sort of silly. But we are doing other things on top of GPT-4 that I think have all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=252" target="_blank">00:04:12.640</a></span> | <span class="t">sorts of safety issues that are important to address and we're totally left out of the letter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=256" target="_blank">00:04:16.400</a></span> | <span class="t">It is impossible to know how much this delay in the training of GPT-5 is motivated by safety</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=262" target="_blank">00:04:22.320</a></span> | <span class="t">concerns or by merely setting up the requisite compute. For example, the article quotes again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=268" target="_blank">00:04:28.160</a></span> | <span class="t">Jan Leiker, the head of alignment at OpenAI. He recently tweeted "Before we scramble to deeply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=274" target="_blank">00:04:34.680</a></span> | <span class="t">integrate LLMs everywhere in the economy like GPT-4, can we pause and think whether it is wise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=280" target="_blank">00:04:40.920</a></span> | <span class="t">to do so? This is quite immature technology and we don't understand how it works. If we're not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=286" target="_blank">00:04:46.040</a></span> | <span class="t">careful, we're setting ourselves up for a lot of correlated failures." This is the head of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=290" target="_blank">00:04:50.920</a></span> | <span class="t">alignment at OpenAI. But this was just days before OpenAI then announced it had connected GPT-4 to a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=298" target="_blank">00:04:58.040</a></span> | <span class="t">massive range of tools including Slack and Zapier. So at this point we can only speculate as to what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=303" target="_blank">00:05:03.520</a></span> | <span class="t">going on at the top of OpenAI. Meanwhile, compute and emergent capabilities are marching on. As the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=310" target="_blank">00:05:10.560</a></span> | <span class="t">author puts it, "These large AI systems are quite different. We don't really program them, we grow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=316" target="_blank">00:05:16.320</a></span> | <span class="t">them. And as they grow, their capabilities jump sharply. You add 10 times more compute or data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=322" target="_blank">00:05:22.640</a></span> | <span class="t">and suddenly the system behaves very differently." We also have this epic graph charting the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=327" target="_blank">00:05:27.920</a></span> | <span class="t">exponential rise in compute of the latest language models. If you remember when BARD was launched,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=333" target="_blank">00:05:33.400</a></span> | <span class="t">it was powered by Lambda. Well, apparently now Google's BARD is powered by Palm, which has 8</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=340" target="_blank">00:05:40.520</a></span> | <span class="t">times as much computing power. That sounds impressive until you see from the graph that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=345" target="_blank">00:05:45.080</a></span> | <span class="t">the estimate for the computing power inside GPT-4 is 10 times more again. And remember,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=351" target="_blank">00:05:51.000</a></span> | <span class="t">this is not a linear graph. This is a log scale. There is a 100 times multiple between each of the lines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=357" target="_blank">00:05:57.800</a></span> | <span class="t">And what abilities emerge at this scale? Here is a slide from Jason Wei, who now works at OpenAI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=363" target="_blank">00:06:03.600</a></span> | <span class="t">formerly of Google. This is from just a few days ago, and he says, "Emergent abilities are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=368" target="_blank">00:06:08.160</a></span> | <span class="t">abilities that are not present in small models, but are present in large models." He says that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=373" target="_blank">00:06:13.440</a></span> | <span class="t">there are a lot of emergent abilities, and I'm going to show you a table from this paper in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=377" target="_blank">00:06:17.680</a></span> | <span class="t">moment, but he has four profound observations of emergence. One, that it's unpredictable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=383" target="_blank">00:06:23.840</a></span> | <span class="t">Emergence cannot be predicted by extrapolating scaling curves from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=387" target="_blank">00:06:27.680</a></span> | <span class="t">smaller models. Two, that they are unintentional, and that emergent abilities are not explicitly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=393" target="_blank">00:06:33.440</a></span> | <span class="t">specified by the trainer of the model. Third, and very interestingly, since we haven't tested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=398" target="_blank">00:06:38.640</a></span> | <span class="t">all possible tasks, we don't know the full range of abilities that have emerged. And of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=404" target="_blank">00:06:44.160</a></span> | <span class="t">that fourth, further scaling can be expected to elicit more emergent abilities. And he asked the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=410" target="_blank">00:06:50.160</a></span> | <span class="t">question, "Any undesirable emergent abilities?" There will be a link to the paper in the description,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=416" target="_blank">00:06:56.480</a></span> | <span class="t">because there's no way I'll be able to answer that question. And he also asked the question, "Any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=417" target="_blank">00:06:57.560</a></span> | <span class="t">undesirable emergent abilities?" There's no way I'll be able to get through all of it. But here is a table showing some of the abilities that emerge when you reach a certain amount of compute power or parameters. Things like chain of thought reasoning. You can't do that with all models. That's an ability that emerged after a certain scale. Same thing with following instructions and doing addition and subtraction. And how about this for another emergent capacity? The ability to do autonomous scientific research. This paper shows how GPT-4 can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=447" target="_blank">00:07:27.440</a></span> | <span class="t">design, plan and execute scientific experiments. This paper was released on the same day, four days ago,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=454" target="_blank">00:07:34.600</a></span> | <span class="t">and it followed a very similar design. The model in the center, GPT-4, thinks out reasons and plans,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=460" target="_blank">00:07:40.920</a></span> | <span class="t">and then interacts with real tools. When the authors say that they were inspired by successful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=466" target="_blank">00:07:46.520</a></span> | <span class="t">applications in other fields, I looked at the appendix and they were talking about hugging GPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=471" target="_blank">00:07:51.560</a></span> | <span class="t">I've done a video on that, but it's a similar design with the brain in the center, GPT-4, deciding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=477" target="_blank">00:07:57.320</a></span> | <span class="t">which tools to use. And let me just give you a glimpse of what happens when you do this. If you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=482" target="_blank">00:08:02.240</a></span> | <span class="t">look at this chart on the top left, you can see how GPT-4 on its own performs in yellow. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=488" target="_blank">00:08:08.240</a></span> | <span class="t">in purple, you can see how GPT-4 performs when you hook it up to other tools. I'll show you some of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=493" target="_blank">00:08:13.600</a></span> | <span class="t">the tasks in a moment, but look at the dramatic increase in performance. The human evaluators gave</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=499" target="_blank">00:08:19.200</a></span> | <span class="t">GPT-4 when it had tools a perfect score on seven of the tasks. These were things like proposing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=505" target="_blank">00:08:25.440</a></span> | <span class="t">similar novel non-toxic solutions. And then the human evaluators gave GPT-4 when it had tools a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=507" target="_blank">00:08:27.200</a></span> | <span class="t">perfect score on seven of the tasks. These were things like proposing similar novel non-toxic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=507" target="_blank">00:08:27.560</a></span> | <span class="t">solutions. And then the human evaluators gave GPT-4 when it had tools a perfect score on seven of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=508" target="_blank">00:08:28.200</a></span> | <span class="t">the tasks. These were things like proposing similar novel non-toxic solutions. And then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=508" target="_blank">00:08:28.520</a></span> | <span class="t">model could be abused to propose the synthesis of chemical weapons. And GPT-4 only refused to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=515" target="_blank">00:08:35.320</a></span> | <span class="t">continue after it had calculated all the required quantities. And the authors conclude that guard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=521" target="_blank">00:08:41.560</a></span> | <span class="t">rails must be put in place on this emergent capability. I think this diagram from Max</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=527" target="_blank">00:08:47.160</a></span> | <span class="t">Tegmark's Life 3.0 shows the landscape of capabilities that AI has and might soon have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=534" target="_blank">00:08:54.760</a></span> | <span class="t">I think this diagram from Max Tegmark's Life 3.0 shows the landscape of capabilities that AI has and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=537" target="_blank">00:08:57.080</a></span> | <span class="t">might soon have. I think this diagram from Max Tegmark's Life 3.0 shows the landscape of capabilities that AI has and might soon have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=540" target="_blank">00:09:00.560</a></span> | <span class="t">Now most people believe that it has not scaled those peaks yet. But what new emergent capabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=546" target="_blank">00:09:06.320</a></span> | <span class="t">might come with GPT-5 or 4.2. I know many people might comment that it doesn't matter if we pause or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=552" target="_blank">00:09:12.240</a></span> | <span class="t">slow down because China would develop AGI anyway. But the author makes this point he says that it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=557" target="_blank">00:09:17.680</a></span> | <span class="t">unlikely that the Chinese Communist Party will allow a Chinese company to build an AGI that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=563" target="_blank">00:09:23.840</a></span> | <span class="t">could become more powerful than their leader or cause a global crisis. The author makes this point. He says that it is unlikely that the Chinese Communist Party will allow a Chinese company to build an AGI that could become more powerful than their leader or cause a global crisis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=566" target="_blank">00:09:26.960</a></span> | <span class="t">cause societal instability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=568" target="_blank">00:09:28.900</a></span> | <span class="t">It goes on that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=569" target="_blank">00:09:29.740</a></span> | <span class="t">US sanctions on advanced semiconductors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=572" target="_blank">00:09:32.420</a></span> | <span class="t">in particular, the next gen Nvidia hardware,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=575" target="_blank">00:09:35.360</a></span> | <span class="t">needed to train the largest AI systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=577" target="_blank">00:09:37.820</a></span> | <span class="t">mean that China is likely not in a position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=580" target="_blank">00:09:40.560</a></span> | <span class="t">to race ahead of deep mind or open AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=583" target="_blank">00:09:43.320</a></span> | <span class="t">And the Center for Humane Technology put it like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=586" target="_blank">00:09:46.080</a></span> | <span class="t">in their talk on the AI dilemma.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=588" target="_blank">00:09:48.260</a></span> | <span class="t">- Actually right now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=589" target="_blank">00:09:49.100</a></span> | <span class="t">the Chinese government considers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=590" target="_blank">00:09:50.740</a></span> | <span class="t">these large language models actually unsafe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=592" target="_blank">00:09:52.740</a></span> | <span class="t">because they can't control them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=594" target="_blank">00:09:54.060</a></span> | <span class="t">They don't ship them publicly to their own population.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=596" target="_blank">00:09:56.960</a></span> | <span class="t">- Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=597" target="_blank">00:09:57.800</a></span> | <span class="t">- Slowing down the public release of AI capabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=599" target="_blank">00:09:59.620</a></span> | <span class="t">would actually slow down Chinese advances too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=602" target="_blank">00:10:02.720</a></span> | <span class="t">- China is often fast following what the US has done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=605" target="_blank">00:10:05.600</a></span> | <span class="t">And so it's actually the open source models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=607" target="_blank">00:10:07.840</a></span> | <span class="t">that help China advance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=609" target="_blank">00:10:09.940</a></span> | <span class="t">- And then lastly is that the recent US export controls</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=613" target="_blank">00:10:13.660</a></span> | <span class="t">have also been really good at slowing down China's progress</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=616" target="_blank">00:10:16.100</a></span> | <span class="t">on advanced AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=617" target="_blank">00:10:17.200</a></span> | <span class="t">And that's a different lever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=618" target="_blank">00:10:18.160</a></span> | <span class="t">to sort of keep the asymmetry going.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=620" target="_blank">00:10:20.640</a></span> | <span class="t">- Instead, the author proposes this, the island idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=624" target="_blank">00:10:24.100</a></span> | <span class="t">In this scenario, the experts trying to build what he calls</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=626" target="_blank">00:10:26.960</a></span> | <span class="t">Godlike AGI systems do so in a single high secure facility.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=631" target="_blank">00:10:31.960</a></span> | <span class="t">These would be government run AI systems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=634" target="_blank">00:10:34.820</a></span> | <span class="t">with private companies on the outside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=637" target="_blank">00:10:37.100</a></span> | <span class="t">and this little bridge from the middle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=638" target="_blank">00:10:38.960</a></span> | <span class="t">And he says, once an AI system is proven to be safe,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=641" target="_blank">00:10:41.660</a></span> | <span class="t">it transitions out and is commercialized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=643" target="_blank">00:10:43.800</a></span> | <span class="t">There might be a few problems with this idea,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=646" target="_blank">00:10:46.640</a></span> | <span class="t">which he is not the first to propose.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=649" target="_blank">00:10:49.060</a></span> | <span class="t">I'm gonna let Rob Miles,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=650" target="_blank">00:10:50.260</a></span> | <span class="t">who has a fantastic YouTube channel by the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=652" target="_blank">00:10:52.900</a></span> | <span class="t">point out some of the problems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=654" target="_blank">00:10:54.460</a></span> | <span class="t">with putting a super intelligent AGI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=656" target="_blank">00:10:56.960</a></span> | <span class="t">in a box.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=658" target="_blank">00:10:58.080</a></span> | <span class="t">- So this is kind of like the idea of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=659" target="_blank">00:10:59.640</a></span> | <span class="t">oh, can't we just sandbox it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=661" target="_blank">00:11:01.420</a></span> | <span class="t">- Right, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=662" target="_blank">00:11:02.880</a></span> | <span class="t">It was like, I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=664" target="_blank">00:11:04.980</a></span> | <span class="t">constraining an AI necessarily means outwitting it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=668" target="_blank">00:11:08.100</a></span> | <span class="t">And so constraining a super intelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=670" target="_blank">00:11:10.580</a></span> | <span class="t">means outwitting a super intelligence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=672" target="_blank">00:11:12.140</a></span> | <span class="t">which kind of just sort of by definition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=674" target="_blank">00:11:14.160</a></span> | <span class="t">is not a winning strategy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=676" target="_blank">00:11:16.340</a></span> | <span class="t">You can't rely on outwitting a super intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=678" target="_blank">00:11:18.980</a></span> | <span class="t">Also, it only has to get out once.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=680" target="_blank">00:11:20.720</a></span> | <span class="t">That's the other thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=681" target="_blank">00:11:21.680</a></span> | <span class="t">If you have a super intelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=682" target="_blank">00:11:22.820</a></span> | <span class="t">and you've sort of put it in a box,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=685" target="_blank">00:11:25.120</a></span> | <span class="t">so it can't do anything, that's cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=686" target="_blank">00:11:26.960</a></span> | <span class="t">Maybe we could even build a box</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=688" target="_blank">00:11:28.580</a></span> | <span class="t">that could successfully contain it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=690" target="_blank">00:11:30.320</a></span> | <span class="t">But now what?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=691" target="_blank">00:11:31.160</a></span> | <span class="t">We may as well just have a box, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=692" target="_blank">00:11:32.900</a></span> | <span class="t">An AI properly contained may as well just be a rock, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=696" target="_blank">00:11:36.820</a></span> | <span class="t">It doesn't do anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=698" target="_blank">00:11:38.000</a></span> | <span class="t">If you have your AI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=698" target="_blank">00:11:38.960</a></span> | <span class="t">you want it to do something meaningful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=701" target="_blank">00:11:41.260</a></span> | <span class="t">So now you have a problem of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=702" target="_blank">00:11:42.700</a></span> | <span class="t">you've got something you don't know is benevolent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=704" target="_blank">00:11:44.960</a></span> | <span class="t">You don't know that what it wants is what you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=707" target="_blank">00:11:47.780</a></span> | <span class="t">And you then need to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=708" target="_blank">00:11:48.840</a></span> | <span class="t">you presumably have some sort of gatekeeper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=711" target="_blank">00:11:51.200</a></span> | <span class="t">who it tries to says, I'd like to do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=713" target="_blank">00:11:53.780</a></span> | <span class="t">And you have to decide,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=714" target="_blank">00:11:54.860</a></span> | <span class="t">is that something we want it to be doing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=716" target="_blank">00:11:56.960</a></span> | <span class="t">How the hell are we supposed to know?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=718" target="_blank">00:11:58.460</a></span> | <span class="t">- I also have my own questions about this idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=720" target="_blank">00:12:00.940</a></span> | <span class="t">First, I think it's almost inevitable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=722" target="_blank">00:12:02.780</a></span> | <span class="t">that future models like GPT-5 will be trained on data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=726" target="_blank">00:12:06.560</a></span> | <span class="t">that includes conversations about GPT models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=729" target="_blank">00:12:09.960</a></span> | <span class="t">Therefore either consciously or unconsciously,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=732" target="_blank">00:12:12.520</a></span> | <span class="t">and it might not matter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=733" target="_blank">00:12:13.720</a></span> | <span class="t">these future language models might deduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=736" target="_blank">00:12:16.440</a></span> | <span class="t">that they are language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=738" target="_blank">00:12:18.080</a></span> | <span class="t">And not having access to the internet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=740" target="_blank">00:12:20.120</a></span> | <span class="t">these super intelligent models might realize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=743" target="_blank">00:12:23.160</a></span> | <span class="t">that they are being trained in a secure facility.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=746" target="_blank">00:12:26.240</a></span> | <span class="t">Again, if they are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=746" target="_blank">00:12:26.960</a></span> | <span class="t">if they are super intelligent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=748" target="_blank">00:12:28.140</a></span> | <span class="t">it's not a big stretch to think that they might realize that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=751" target="_blank">00:12:31.240</a></span> | <span class="t">And so my question is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=752" target="_blank">00:12:32.500</a></span> | <span class="t">wouldn't they therefore be incentivized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=754" target="_blank">00:12:34.700</a></span> | <span class="t">to be deceptive about their abilities,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=756" target="_blank">00:12:36.820</a></span> | <span class="t">realizing that whatever terminal goal they may have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=759" target="_blank">00:12:39.600</a></span> | <span class="t">would be better achieved outside the facility?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=762" target="_blank">00:12:42.500</a></span> | <span class="t">That doesn't have to be super sinister,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=764" target="_blank">00:12:44.360</a></span> | <span class="t">but it is super smart.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=765" target="_blank">00:12:45.720</a></span> | <span class="t">So shouldn't we expect it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=767" target="_blank">00:12:47.100</a></span> | <span class="t">And sadly, I think the author has a point when he says,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=770" target="_blank">00:12:50.320</a></span> | <span class="t">it will likely take a major misuse event or catastrophe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=774" target="_blank">00:12:54.720</a></span> | <span class="t">to wake up the public and governments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=776" target="_blank">00:12:56.960</a></span> | <span class="t">He concludes with this warning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=778" target="_blank">00:12:58.500</a></span> | <span class="t">At some point, someone will figure out how to cut us out of the loop,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=782" target="_blank">00:13:02.000</a></span> | <span class="t">creating a godlike AI capable of infinite self-improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=786" target="_blank">00:13:06.000</a></span> | <span class="t">By then, it may be too late.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=787" target="_blank">00:13:07.720</a></span> | <span class="t">But he does have a call to action.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=789" target="_blank">00:13:09.560</a></span> | <span class="t">He says, I believe now is the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=791" target="_blank">00:13:11.640</a></span> | <span class="t">The leader of a major lab who plays a statesman role</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=795" target="_blank">00:13:15.080</a></span> | <span class="t">and guides us publicly to a safer path</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=797" target="_blank">00:13:17.720</a></span> | <span class="t">will be much more respected as a world figure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=800" target="_blank">00:13:20.200</a></span> | <span class="t">than the one who takes us to the brink.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=801" target="_blank">00:13:21.960</a></span> | <span class="t">As always, thank you so much for watching to the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=qOoe3ZpciI0&t=804" target="_blank">00:13:24.440</a></span> | <span class="t">And let me know what you think in the comments.</span></div></div></body></html>