<html><head><title>Language Generation with OpenAI's GPT-2 in Python</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Language Generation with OpenAI's GPT-2 in Python</h2><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY"><img src="https://i.ytimg.com/vi/YvVQgvAz9dY/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./YvVQgvAz9dY.html">Whisper Transcript</a> | <a href="./transcript_YvVQgvAz9dY.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hi and welcome to the video. We're going to go through language generation using GPT-2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=5" target="_blank">00:00:05.920</a></span> | <span class="t">Now this is actually incredibly easy to do and we can build this entire model including the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=13" target="_blank">00:00:13.760</a></span> | <span class="t">imports, the tokenizer model, and outputting our generated text with just seven lines of code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=21" target="_blank">00:00:21.600</a></span> | <span class="t">which is pretty insane. Now the only libraries we need for this are PyTorch and Transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=29" target="_blank">00:00:29.040</a></span> | <span class="t">so we'll go ahead and import them now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=30" target="_blank">00:00:30.960</a></span> | <span class="t">Now all we need from the Transformers library are the GPT-2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=49" target="_blank">00:00:49.200</a></span> | <span class="t">LM head model and GPT-2 tokenizer, so we can initialize both of those as well now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=55" target="_blank">00:00:55.360</a></span> | <span class="t">And both will be from pre-trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=64" target="_blank">00:01:04.240</a></span> | <span class="t">So now we have initialized our tokenizer and model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=83" target="_blank">00:01:23.520</a></span> | <span class="t">We just need a sequence of text to feed in and get our model going.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=90" target="_blank">00:01:30.400</a></span> | <span class="t">So I've taken a snippet of text from the Wikipedia page of Winston Churchill, which is here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=99" target="_blank">00:01:39.200</a></span> | <span class="t">And it's just a small little snippet talking about when he took office during World War II.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=108" target="_blank">00:01:48.160</a></span> | <span class="t">Now from this, I've tested it briefly and it seems to give some pretty interesting results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=113" target="_blank">00:01:53.600</a></span> | <span class="t">So we will go ahead, use this, all we need to do is tokenize it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=119" target="_blank">00:01:59.760</a></span> | <span class="t">Now all we're doing here is taking each of these words, splitting them into tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=133" target="_blank">00:02:13.120</a></span> | <span class="t">so that would be a list where each word is its own item, so he began his premiership.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=141" target="_blank">00:02:21.760</a></span> | <span class="t">Each one of those would be a separate value within that list.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=145" target="_blank">00:02:25.600</a></span> | <span class="t">Once we have them in that tokenized format, our tokenizer will then convert them into numerical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=154" target="_blank">00:02:34.320</a></span> | <span class="t">IDs, which map to a word vector that's been trained to work with the GPT-2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=161" target="_blank">00:02:41.840</a></span> | <span class="t">Now, because we're using PyTorch, we just need to remember to return a PT tensors here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=168" target="_blank">00:02:48.080</a></span> | <span class="t">So now we have our inputs, we just need to feed them into our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=178" target="_blank">00:02:58.640</a></span> | <span class="t">So we can do that using model.generate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=185" target="_blank">00:03:05.680</a></span> | <span class="t">And we add our inputs. Now, we also need to tell PyTorch how long we want our generated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=195" target="_blank">00:03:15.520</a></span> | <span class="t">sequence to be. So all we do for that is add a max length. And this will act as the cutoff point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=204" target="_blank">00:03:24.400</a></span> | <span class="t">anything longer than this will simply be cut off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=211" target="_blank">00:03:31.360</a></span> | <span class="t">And now here we are just generating our output. We also need to pass this into the outputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=219" target="_blank">00:03:39.760</a></span> | <span class="t">variable here, so that we can actually read from it and decode it. So to decode our output IDs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=230" target="_blank">00:03:50.560</a></span> | <span class="t">because it will output numerical IDs representing words, just like we fed into it, we need to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=237" target="_blank">00:03:57.520</a></span> | <span class="t">the tokenizer decode method. And our output IDs are in the zero index of the outputs object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=251" target="_blank">00:04:11.520</a></span> | <span class="t">And we also want to skip any special tokens. So this would be stuff like end of sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=259" target="_blank">00:04:19.760</a></span> | <span class="t">tokens, padding tokens, unknown word tokens, and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=263" target="_blank">00:04:23.600</a></span> | <span class="t">And then we can print the text. Now, we can see here that it's basically just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=273" target="_blank">00:04:33.520</a></span> | <span class="t">going over and over again, saying the same things, which is not really what we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=277" target="_blank">00:04:37.840</a></span> | <span class="t">So this is a pretty common problem. And all we need to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=282" target="_blank">00:04:42.080</a></span> | <span class="t">to fix this is add another argument to our generate method here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=288" target="_blank">00:04:48.160</a></span> | <span class="t">So we simply do sample equals true. And then we can rerun this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=293" target="_blank">00:04:53.440</a></span> | <span class="t">And this looks pretty good now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=297" target="_blank">00:04:57.840</a></span> | <span class="t">So we can add more randomness and restrict the number of possible tokens for the model to use,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=307" target="_blank">00:05:07.840</a></span> | <span class="t">using the temperature and top k parameters, respectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=314" target="_blank">00:05:14.800</a></span> | <span class="t">Now, temperature acts as the amount of randomness input into the model. So a high temperature above</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=322" target="_blank">00:05:22.080</a></span> | <span class="t">one will create more random tokens than the default. Anything below one makes the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=329" target="_blank">00:05:29.200</a></span> | <span class="t">less random. So say if we put a stupidly high number, like five, we will probably get a pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=335" target="_blank">00:05:35.600</a></span> | <span class="t">weird output. Okay, so we can see here, initially skimming over, it doesn't look too bad. But then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=343" target="_blank">00:05:43.200</a></span> | <span class="t">when you start reading it, it's practically impossible to follow. There's no structure,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=348" target="_blank">00:05:48.720</a></span> | <span class="t">and there's just a couple of random words in there that are just completely irrelevant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=354" target="_blank">00:05:54.400</a></span> | <span class="t">Now, we can also see here, there's an end bracket, and there's a starting bracket that pairs with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=360" target="_blank">00:06:00.560</a></span> | <span class="t">And generally, it's just some really weird syntax. So we turn the temperature down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=369" target="_blank">00:06:09.200</a></span> | <span class="t">Maybe to 0.7, and we will actually decrease the randomness from the original model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=376" target="_blank">00:06:16.400</a></span> | <span class="t">Now, you can toy around with this and see what produces more interesting results. Generally,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=384" target="_blank">00:06:24.240</a></span> | <span class="t">higher temperature will create more creative outputs. And the other parameter we can also use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=391" target="_blank">00:06:31.360</a></span> | <span class="t">is the top k parameter. Now, top k limits the sample tokens to the top rated tokens that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=400" target="_blank">00:06:40.160</a></span> | <span class="t">model is predicting. So we can add 50, for example, and this will alter our output. Generally,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=408" target="_blank">00:06:48.400</a></span> | <span class="t">I've found top k tends to make the text a little more coherent. And I would assume this is because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=416" target="_blank">00:06:56.000</a></span> | <span class="t">it is sticking within a smaller space of possible tokens or words that it can output. So now here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=424" target="_blank">00:07:04.080</a></span> | <span class="t">we can see pretty understandable, logical text again. And we can see here, it mentions lord a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=431" target="_blank">00:07:11.920</a></span> | <span class="t">lot, which makes sense because this is Britain. So if we put the temperature back up to 1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=440" target="_blank">00:07:20.640</a></span> | <span class="t">we should get a slightly more random output again. And then here, we can see that there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=448" target="_blank">00:07:28.800</a></span> | <span class="t">a little more weird text coming in. So we have here that the first Australian prime minister</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=455" target="_blank">00:07:35.120</a></span> | <span class="t">was sacked by a labor minister, which obviously is a little bit strange. But it just shows that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=462" target="_blank">00:07:42.160</a></span> | <span class="t">we can add more randomness, or we can try and restrict our model to become more coherent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=468" target="_blank">00:07:48.560</a></span> | <span class="t">And we can do this super easily using the generate parameters. So with just a few lines of code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=476" target="_blank">00:07:56.480</a></span> | <span class="t">we built our model up and running and actually generating text incredibly easily. So I hope</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=483" target="_blank">00:08:03.840</a></span> | <span class="t">this has been insightful and useful. If you have any questions or suggestions, please just let me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=490" target="_blank">00:08:10.560</a></span> | <span class="t">know in the comments below. But thank you for watching, and I will see you next time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YvVQgvAz9dY&t=496" target="_blank">00:08:16.560</a></span> | <span class="t">time.</span></div></div></body></html>