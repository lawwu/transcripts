<html><head><title>Harnessing the Power of LLMs Locally: Mithun Hunsur</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Harnessing the Power of LLMs Locally: Mithun Hunsur</h2><a href="https://www.youtube.com/watch?v=MwqUYRQloGw"><img src="https://i.ytimg.com/vi/MwqUYRQloGw/sddefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=41">0:41</a> Overview<br><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=163">2:43</a> Cost<br><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=237">3:57</a> Quantization<br><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=340">5:40</a> Why LLMRS<br><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=529">8:49</a> Community Projects<br><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=680">11:20</a> Real World Example<br><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=764">12:44</a> Benefits<br><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=979">16:19</a> Outro<br><br><div style="text-align: left;"><a href="./MwqUYRQloGw.html">Whisper Transcript</a> | <a href="./transcript_MwqUYRQloGw.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=14" target="_blank">00:00:14.040</a></span> | <span class="t">Good day, everyone. Good to see you all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=16" target="_blank">00:00:16.880</a></span> | <span class="t">Today, I'm here to tell you how to harness the power of local LLMs using our Rust library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=23" target="_blank">00:00:23.400</a></span> | <span class="t">Quick intro. I'm a thorn, as you just heard, but I go by PhilpikesOnline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=27" target="_blank">00:00:27.680</a></span> | <span class="t">I hail from Australia, hence the accent, but I live in Sweden.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=30" target="_blank">00:00:30.960</a></span> | <span class="t">I do a lot of things for computers, but my day job is at Ambient where I build a game engine of the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=36" target="_blank">00:00:36.040</a></span> | <span class="t">Today, though, I'm here to talk to you about LLM.RS, a Rust library that I maintain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=42" target="_blank">00:00:42.120</a></span> | <span class="t">So, LLM.RS, or LLM between friends, I realize that I have to disambiguate when I started with Simon's newsletter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=50" target="_blank">00:00:50.120</a></span> | <span class="t">It's no one solution for local inference of LLMs, but what does that actually mean?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=55" target="_blank">00:00:55.360</a></span> | <span class="t">Well, most of the models we've discussed in this conference have been cloud models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=59" target="_blank">00:00:59.120</a></span> | <span class="t">You have ChatJPTs, your Clawds, your Bards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=62" target="_blank">00:01:02.200</a></span> | <span class="t">Local models offer another way, where you own the model and it runs on your computer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=67" target="_blank">00:01:07.640</a></span> | <span class="t">So let's quickly go over what that actually means.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=71" target="_blank">00:01:11.640</a></span> | <span class="t">First up, size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=73" target="_blank">00:01:13.640</a></span> | <span class="t">Model size can be used as a rough proxy for the intelligence of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=78" target="_blank">00:01:18.040</a></span> | <span class="t">Most of the models are really, really big.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=81" target="_blank">00:01:21.440</a></span> | <span class="t">You can see that it's dominating the right-hand side of the chart there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=84" target="_blank">00:01:24.520</a></span> | <span class="t">You have your GPT-3, your GPT-4, we'll get back to that, your GURF, your Palm 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=90" target="_blank">00:01:30.360</a></span> | <span class="t">These are all insanely big in comparison to the open-source models we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=93" target="_blank">00:01:33.800</a></span> | <span class="t">We're beginning to see some bigger models thanks to LLM and Falcon, but even they pale in comparison</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=98" target="_blank">00:01:38.880</a></span> | <span class="t">to what the bigger players can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=101" target="_blank">00:01:41.280</a></span> | <span class="t">This means the local models don't have the same capacity for intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=105" target="_blank">00:01:45.220</a></span> | <span class="t">However, a smaller, more focused model may be able to solve problems better than a large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=111" target="_blank">00:01:51.060</a></span> | <span class="t">general model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=112" target="_blank">00:01:52.400</a></span> | <span class="t">By the way, we don't actually know what size GPT-4 is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=115" target="_blank">00:01:55.320</a></span> | <span class="t">That's rumors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=116" target="_blank">00:01:56.960</a></span> | <span class="t">The only APN AI knows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=118" target="_blank">00:01:58.960</a></span> | <span class="t">Next, let's talk about speed and capacity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=123" target="_blank">00:02:03.580</a></span> | <span class="t">Cloud models run on specialized hardware with special configuration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=126" target="_blank">00:02:06.820</a></span> | <span class="t">Local models run on whatever hardware you can scrounge up, including rented hardware.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=131" target="_blank">00:02:11.160</a></span> | <span class="t">The further up the axis you go, the more speed and/or parallel inference you can do, but the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=135" target="_blank">00:02:15.400</a></span> | <span class="t">more inaccessible it becomes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=137" target="_blank">00:02:17.740</a></span> | <span class="t">This end?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=138" target="_blank">00:02:18.740</a></span> | <span class="t">A few hundred dollars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=139" target="_blank">00:02:19.740</a></span> | <span class="t">That end?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=140" target="_blank">00:02:20.740</a></span> | <span class="t">A few hundred million dollars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=144" target="_blank">00:02:24.160</a></span> | <span class="t">Next up, latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=146" target="_blank">00:02:26.240</a></span> | <span class="t">Cloud models need the full prompt before they can start inference and you have to wait for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=150" target="_blank">00:02:30.120</a></span> | <span class="t">the message back and forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=152" target="_blank">00:02:32.900</a></span> | <span class="t">Local models can give you a response immediately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=155" target="_blank">00:02:35.140</a></span> | <span class="t">You can feed the prompt as you go along.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=157" target="_blank">00:02:37.060</a></span> | <span class="t">This is very important for conversations where you want the model to be able to process what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=161" target="_blank">00:02:41.000</a></span> | <span class="t">you're saying as you say it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=164" target="_blank">00:02:44.220</a></span> | <span class="t">And of course, you can't escape talking about cost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=167" target="_blank">00:02:47.060</a></span> | <span class="t">The cloud vendors will charge you a per token price.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=170" target="_blank">00:02:50.440</a></span> | <span class="t">When running locally, it's entirely up to you how much it costs you to run the machine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=174" target="_blank">00:02:54.520</a></span> | <span class="t">If the running cost of your model is less than the cost of running your workload through the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=178" target="_blank">00:02:58.400</a></span> | <span class="t">cloud, you're going to make a profit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=180" target="_blank">00:03:00.460</a></span> | <span class="t">And if you're running on a machine you already own, well, that's basically free, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=186" target="_blank">00:03:06.980</a></span> | <span class="t">With the cloud, you have to use the models they offer you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=190" target="_blank">00:03:10.340</a></span> | <span class="t">Some vendors offer fine-tuning, but they often charge more than just using the regular model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=196" target="_blank">00:03:16.020</a></span> | <span class="t">and they often charge you for the process of fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=198" target="_blank">00:03:18.780</a></span> | <span class="t">This means it's not often cost-effective to actually do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=202" target="_blank">00:03:22.700</a></span> | <span class="t">With local models, the sky's the limit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=205" target="_blank">00:03:25.120</a></span> | <span class="t">There are hundreds, potentially thousands, of custom models that can suit any need you have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=210" target="_blank">00:03:30.700</a></span> | <span class="t">Knowledge retrieval, storytelling, conversation, tool use, you name it, someone's already done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=215" target="_blank">00:03:35.900</a></span> | <span class="t">it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=216" target="_blank">00:03:36.900</a></span> | <span class="t">But if you haven't, fine-tuning the existing model for your own use is easy enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=221" target="_blank">00:03:41.020</a></span> | <span class="t">Special shout-out to Axlodl over there, which makes it easy to fine-tune models of any architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=227" target="_blank">00:03:47.240</a></span> | <span class="t">And of course, privacy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=231" target="_blank">00:03:51.480</a></span> | <span class="t">There are some questions you don't want to ask the internet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=234" target="_blank">00:03:54.080</a></span> | <span class="t">Local models let you privately embarrass yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=236" target="_blank">00:03:56.840</a></span> | <span class="t">Now, you might be wondering how it's actually possible to run these models locally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=242" target="_blank">00:04:02.880</a></span> | <span class="t">That, my friends, is possible with the power of quantisation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=246" target="_blank">00:04:06.300</a></span> | <span class="t">If each model is billions of parameters, and those parameters are like individual numbers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=251" target="_blank">00:04:11.120</a></span> | <span class="t">how could you possibly run them on consumer hardware when there's only so much memory available</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=255" target="_blank">00:04:15.660</a></span> | <span class="t">for a given performance level?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=257" target="_blank">00:04:17.840</a></span> | <span class="t">Well, we can use quantisation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=260" target="_blank">00:04:20.620</a></span> | <span class="t">Quantisation lets you lossly compress a model while maintaining the majority of its maths.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=264" target="_blank">00:04:24.120</a></span> | <span class="t">We can take the original model here in blue and squish it down to something much smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=268" target="_blank">00:04:28.460</a></span> | <span class="t">using one of these green formats.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=270" target="_blank">00:04:30.480</a></span> | <span class="t">This is a secret sauce that makes it viable to run models locally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=275" target="_blank">00:04:35.040</a></span> | <span class="t">Smaller models aren't just easier to store.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=277" target="_blank">00:04:37.700</a></span> | <span class="t">They can also run faster as a computer can process more of the model at any given moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=284" target="_blank">00:04:44.760</a></span> | <span class="t">But that's enough about local models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=286" target="_blank">00:04:46.800</a></span> | <span class="t">You've probably already heard much of that already.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=289" target="_blank">00:04:49.420</a></span> | <span class="t">Let's talk about the actual library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=292" target="_blank">00:04:52.200</a></span> | <span class="t">It all started with this man who built something you may have heard of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=296" target="_blank">00:04:56.000</a></span> | <span class="t">Of course, I'm referring to Lama CPP, and that's what it looked like on day one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=299" target="_blank">00:04:59.760</a></span> | <span class="t">Look at the mere 98 stars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=301" target="_blank">00:05:01.360</a></span> | <span class="t">How pedestrian compared to today where it's 42,000 stars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=306" target="_blank">00:05:06.260</a></span> | <span class="t">But let's go back to March when I first saw it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=308" target="_blank">00:05:08.700</a></span> | <span class="t">When I saw it, I had but one idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=311" target="_blank">00:05:11.300</a></span> | <span class="t">It's time to reroute it in Rust for both the meme and because I wanted to use it for other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=316" target="_blank">00:05:16.540</a></span> | <span class="t">things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=317" target="_blank">00:05:17.540</a></span> | <span class="t">Well, I said I wanted to do it, and I did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=321" target="_blank">00:05:21.340</a></span> | <span class="t">But to the right here, set to 22 was also working on the same problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=325" target="_blank">00:05:25.100</a></span> | <span class="t">And, well, there was just one catch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=327" target="_blank">00:05:27.900</a></span> | <span class="t">He beat me to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=328" target="_blank">00:05:28.980</a></span> | <span class="t">He beat me to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=329" target="_blank">00:05:29.980</a></span> | <span class="t">Completely beat me to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=330" target="_blank">00:05:30.980</a></span> | <span class="t">I'm not afraid to admit it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=332" target="_blank">00:05:32.340</a></span> | <span class="t">Luckily, we came together, managed our projects, and I ended up as the maintainer of the resulting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=337" target="_blank">00:05:37.720</a></span> | <span class="t">project and that's how LLM was born.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=341" target="_blank">00:05:41.440</a></span> | <span class="t">So you might be wondering why.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=344" target="_blank">00:05:44.140</a></span> | <span class="t">If Lama CPP exists, why use LMRS?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=347" target="_blank">00:05:47.220</a></span> | <span class="t">Well, with LLM.RS, I had six principles in mind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=351" target="_blank">00:05:51.280</a></span> | <span class="t">It must be a library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=353" target="_blank">00:05:53.360</a></span> | <span class="t">When I first started in March, Lama CPP was not a library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=356" target="_blank">00:05:56.720</a></span> | <span class="t">It was an application, and that made it impossible to reuse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=360" target="_blank">00:06:00.180</a></span> | <span class="t">It must not be coupled to an application.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=362" target="_blank">00:06:02.660</a></span> | <span class="t">You must be able to customize this behavior, you must be able to go in and change every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=366" target="_blank">00:06:06.280</a></span> | <span class="t">little bit of it to make it work for your application, and we shouldn't make any assumptions about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=370" target="_blank">00:06:10.840</a></span> | <span class="t">how it's going to be used.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=373" target="_blank">00:06:13.120</a></span> | <span class="t">It should support a multitude of model architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=375" target="_blank">00:06:15.700</a></span> | <span class="t">Of course, Lama CPP supports Lama and now Falcon, but clearly there are more out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=381" target="_blank">00:06:21.760</a></span> | <span class="t">Next up, it should be Rust native.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=383" target="_blank">00:06:23.360</a></span> | <span class="t">It should feel like using a Rust library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=385" target="_blank">00:06:25.380</a></span> | <span class="t">It should not feel like using a library with bindings, and it should work how you expect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=388" target="_blank">00:06:28.940</a></span> | <span class="t">a Rust library to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=390" target="_blank">00:06:30.740</a></span> | <span class="t">Next up, backends.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=392" target="_blank">00:06:32.540</a></span> | <span class="t">It should support all possible kinds of backends, you can write on your CPU, your GPU, or of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=397" target="_blank">00:06:37.620</a></span> | <span class="t">your ML-powered toaster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=398" target="_blank">00:06:38.620</a></span> | <span class="t">I'm sure that's going to be a thing, but we were going to see it coming, I swear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=402" target="_blank">00:06:42.900</a></span> | <span class="t">And finally, platforms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=404" target="_blank">00:06:44.720</a></span> | <span class="t">It should work the same whether it's on Windows, Linux, Mac OS, or something else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=409" target="_blank">00:06:49.760</a></span> | <span class="t">You shouldn't have to change it significantly to make it work, because deployment has always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=413" target="_blank">00:06:53.920</a></span> | <span class="t">been an issue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=415" target="_blank">00:06:55.920</a></span> | <span class="t">Today, I'm proud to say we support a myriad of architectures, including the darlings of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=420" target="_blank">00:07:00.720</a></span> | <span class="t">the movement, Lama and Falcon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=422" target="_blank">00:07:02.880</a></span> | <span class="t">These architectures all use the same interface, so you don't have to worry about changing your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=426" target="_blank">00:07:06.260</a></span> | <span class="t">code to use a different model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=428" target="_blank">00:07:08.440</a></span> | <span class="t">This is made possible by the concerted efforts by code contributors, Lucas and Dan, who couldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=434" target="_blank">00:07:14.260</a></span> | <span class="t">have done this without, as well as many others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=437" target="_blank">00:07:17.100</a></span> | <span class="t">Here's some sample code for the library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=440" target="_blank">00:07:20.080</a></span> | <span class="t">I won't go too much into it, because it's quite dense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=442" target="_blank">00:07:22.680</a></span> | <span class="t">But the idea is that you load a model right there on the top, because it's actually quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=446" target="_blank">00:07:26.780</a></span> | <span class="t">small, and with that model, you create sessions which track an ongoing use of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=451" target="_blank">00:07:31.340</a></span> | <span class="t">You can have as many of these as you would like, but they do have a memory cost, so you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=454" target="_blank">00:07:34.640</a></span> | <span class="t">want to be careful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=455" target="_blank">00:07:35.960</a></span> | <span class="t">Once you have a session, you can pass a prompt in and infer with the model to determine what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=460" target="_blank">00:07:40.420</a></span> | <span class="t">comes next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=461" target="_blank">00:07:41.540</a></span> | <span class="t">You can keep reusing the same session, which is very useful for conversation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=464" target="_blank">00:07:44.980</a></span> | <span class="t">You don't need to keep refeeding the context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=467" target="_blank">00:07:47.580</a></span> | <span class="t">The last argument of the function is the callback.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=471" target="_blank">00:07:51.040</a></span> | <span class="t">That's where you actually get the tokens out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=474" target="_blank">00:07:54.080</a></span> | <span class="t">It's worth noting that the function itself is actually a helper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=477" target="_blank">00:07:57.040</a></span> | <span class="t">All it does is call the model in a loop with some boundary conditions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=480" target="_blank">00:08:00.640</a></span> | <span class="t">If you want to change the logic in some significant way, you can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=484" target="_blank">00:08:04.700</a></span> | <span class="t">We're not going to start from doing that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=486" target="_blank">00:08:06.700</a></span> | <span class="t">One last thing about this, though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=488" target="_blank">00:08:08.280</a></span> | <span class="t">You see all the calls to default there?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=489" target="_blank">00:08:09.740</a></span> | <span class="t">Those are all customisation points.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=491" target="_blank">00:08:11.740</a></span> | <span class="t">You can change pretty much anything about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=493" target="_blank">00:08:13.320</a></span> | <span class="t">You can change how the model is loaded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=495" target="_blank">00:08:15.120</a></span> | <span class="t">You can change how it will do the inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=496" target="_blank">00:08:16.960</a></span> | <span class="t">You can change how it will sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=498" target="_blank">00:08:18.620</a></span> | <span class="t">The entire point is you have the control you need to make the thing you need to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=503" target="_blank">00:08:23.740</a></span> | <span class="t">Here's a quick demo of the library working with Lama 7 billion on my MacBook CPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=511" target="_blank">00:08:31.460</a></span> | <span class="t">It's reasonably fast, but it could be faster, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=515" target="_blank">00:08:35.500</a></span> | <span class="t">Well, thanks to the power of GPU acceleration, we have something that's much more usable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=524" target="_blank">00:08:44.500</a></span> | <span class="t">And believe me, it's even faster than Nvidia GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=531" target="_blank">00:08:51.040</a></span> | <span class="t">Now let's talk about what you can actually do with the library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=534" target="_blank">00:08:54.380</a></span> | <span class="t">Let's start with three community projects to begin with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=536" target="_blank">00:08:56.600</a></span> | <span class="t">First we've got local AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=538" target="_blank">00:08:58.140</a></span> | <span class="t">Local AI is a simple app that you can install to do inference locally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=543" target="_blank">00:09:03.260</a></span> | <span class="t">There's nothing magical about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=544" target="_blank">00:09:04.500</a></span> | <span class="t">It's just exactly what it says.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=546" target="_blank">00:09:06.140</a></span> | <span class="t">I think that's really wonderful because it means anyone can download this app and be able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=552" target="_blank">00:09:12.060</a></span> | <span class="t">to use local models without having to think about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=554" target="_blank">00:09:14.340</a></span> | <span class="t">Next up, LMChain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=555" target="_blank">00:09:15.340</a></span> | <span class="t">It's a LangChain, but for Rust.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=558" target="_blank">00:09:18.160</a></span> | <span class="t">And of course, it supports inference with the library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=560" target="_blank">00:09:20.420</a></span> | <span class="t">And finally, we have Flonium, which is a flowchart-based application where you can build your own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=564" target="_blank">00:09:24.380</a></span> | <span class="t">workflows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=565" target="_blank">00:09:25.380</a></span> | <span class="t">I think we've seen a few of those at this conference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=568" target="_blank">00:09:28.180</a></span> | <span class="t">And you can combine and create nodes to build the workflow you need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=572" target="_blank">00:09:32.340</a></span> | <span class="t">And of course, it supports the library as an inference engine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=576" target="_blank">00:09:36.520</a></span> | <span class="t">Now I wouldn't be a very good library author if I didn't actually test my own library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=580" target="_blank">00:09:40.880</a></span> | <span class="t">So I'm going to go through three applications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=583" target="_blank">00:09:43.520</a></span> | <span class="t">The first two approves the concept.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=585" target="_blank">00:09:45.340</a></span> | <span class="t">The first is LMChain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=586" target="_blank">00:09:46.520</a></span> | <span class="t">It's a Discord bot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=589" target="_blank">00:09:49.360</a></span> | <span class="t">You can see it's exactly what you'd expect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=591" target="_blank">00:09:51.400</a></span> | <span class="t">You give it a prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=592" target="_blank">00:09:52.920</a></span> | <span class="t">It will give you a response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=594" target="_blank">00:09:54.800</a></span> | <span class="t">Any hitches you see come from Discord limits, not from the actual inference itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=598" target="_blank">00:09:58.940</a></span> | <span class="t">You can see...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=599" target="_blank">00:09:59.940</a></span> | <span class="t">Bam!</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=600" target="_blank">00:10:00.940</a></span> | <span class="t">All there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=603" target="_blank">00:10:03.940</a></span> | <span class="t">When an issue is a request for generation, it goes through this process here where the request</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=609" target="_blank">00:10:09.700</a></span> | <span class="t">goes through a generation thread with a channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=612" target="_blank">00:10:12.760</a></span> | <span class="t">That channel is then used to create a response task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=616" target="_blank">00:10:16.940</a></span> | <span class="t">And then that response task is responsible for sending the responses to the user.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=622" target="_blank">00:10:22.180</a></span> | <span class="t">Now, the interesting thing is these sessions are created and thrown away immediately with each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=627" target="_blank">00:10:27.120</a></span> | <span class="t">query.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=628" target="_blank">00:10:28.120</a></span> | <span class="t">But you don't need to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=629" target="_blank">00:10:29.400</a></span> | <span class="t">If you keep them around, you can actually use them for conversation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=633" target="_blank">00:10:33.740</a></span> | <span class="t">And just to illustrate, this is just like the request response workflow you would use for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=637" target="_blank">00:10:37.280</a></span> | <span class="t">anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=638" target="_blank">00:10:38.080</a></span> | <span class="t">If I just take what I had there, drop the Discord bit and add in HTTP, you can see request generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=644" target="_blank">00:10:44.520</a></span> | <span class="t">response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=645" target="_blank">00:10:45.520</a></span> | <span class="t">Easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=646" target="_blank">00:10:46.520</a></span> | <span class="t">Next up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=647" target="_blank">00:10:47.520</a></span> | <span class="t">Alpa.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=648" target="_blank">00:10:48.520</a></span> | <span class="t">I love using GitHub Copilot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=650" target="_blank">00:10:50.520</a></span> | <span class="t">But it's only available in my code editor and it requires an internet connection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=653" target="_blank">00:10:53.580</a></span> | <span class="t">Alpa is my attempt to solve this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=656" target="_blank">00:10:56.300</a></span> | <span class="t">It is order complete anywhere in your system just by taking what's left of your cursor and passing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=663" target="_blank">00:11:03.080</a></span> | <span class="t">to a model to type in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=664" target="_blank">00:11:04.860</a></span> | <span class="t">And, of course, you can use any model including a model to fine-tune in my own writing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=668" target="_blank">00:11:08.480</a></span> | <span class="t">Ask me how I know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=669" target="_blank">00:11:09.480</a></span> | <span class="t">Alpa is also quite simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=672" target="_blank">00:11:12.680</a></span> | <span class="t">In fact, it is so simple I don't really need to cover it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=674" target="_blank">00:11:14.880</a></span> | <span class="t">Listen for input, copy the input into a prompt, start generating, type out response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=680" target="_blank">00:11:20.740</a></span> | <span class="t">Easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=681" target="_blank">00:11:21.740</a></span> | <span class="t">Now, the first two examples are pretty simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=684" target="_blank">00:11:24.580</a></span> | <span class="t">They are proofs of concept.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=686" target="_blank">00:11:26.020</a></span> | <span class="t">But now I want to talk about an actual use case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=688" target="_blank">00:11:28.540</a></span> | <span class="t">This is a real-world data extraction task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=690" target="_blank">00:11:30.740</a></span> | <span class="t">Over the last few years, I have been working on a project to make a timeline from the dates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=694" target="_blank">00:11:34.780</a></span> | <span class="t">of Wikipedia, because there are millions of pages and they all have dates, and you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=698" target="_blank">00:11:38.400</a></span> | <span class="t">build a world history from it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=700" target="_blank">00:11:40.400</a></span> | <span class="t">However, these dates are often unstructured and more or less impossible to pass using traditional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=704" target="_blank">00:11:44.480</a></span> | <span class="t">means.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=705" target="_blank">00:11:45.480</a></span> | <span class="t">Like, yes, you can try using regex to extract the dates, but you can't get the context out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=709" target="_blank">00:11:49.120</a></span> | <span class="t">in any meaningful sense, and there are some dates here that don't make any sense at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=713" target="_blank">00:11:53.900</a></span> | <span class="t">So that's why, as is the theme of this conference, I threw a large language model at it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=719" target="_blank">00:11:59.520</a></span> | <span class="t">However, GPT-3 and 4 aren't perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=721" target="_blank">00:12:01.520</a></span> | <span class="t">Even after rounds of prompt engineering, you can see I tried here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=724" target="_blank">00:12:04.620</a></span> | <span class="t">And handling millions of dates is just too expensive and slow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=728" target="_blank">00:12:08.680</a></span> | <span class="t">So I decided I'd fine-tune my own model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=730" target="_blank">00:12:10.520</a></span> | <span class="t">So I generate a representative data set using GPT-3, build a tool to go through the data set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=735" target="_blank">00:12:15.140</a></span> | <span class="t">so pick out any data point, fix it up, and then correct the errors, build a new data set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=740" target="_blank">00:12:20.560</a></span> | <span class="t">and train a new model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=742" target="_blank">00:12:22.840</a></span> | <span class="t">So I did that using Axolotl, which I mentioned earlier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=745" target="_blank">00:12:25.280</a></span> | <span class="t">Again, check out Axolotl for all your fine-tuning needs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=747" target="_blank">00:12:27.140</a></span> | <span class="t">Highly recommended.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=748" target="_blank">00:12:28.640</a></span> | <span class="t">And now I have a small, fast, consistent model that I can pass any data to - sorry,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=752" target="_blank">00:12:32.140</a></span> | <span class="t">any date to, and get back a structured representation, which I can, of course, immediately pass using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=757" target="_blank">00:12:37.400</a></span> | <span class="t">Rust.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=758" target="_blank">00:12:38.780</a></span> | <span class="t">And I can treat that as a black box.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=760" target="_blank">00:12:40.400</a></span> | <span class="t">So I have a function there, fn-pass, pass some dates, get some dates back, simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=764" target="_blank">00:12:44.460</a></span> | <span class="t">Now, let's quickly talk about the benefits of using local models and the library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=770" target="_blank">00:12:50.500</a></span> | <span class="t">First off, deployments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=772" target="_blank">00:12:52.000</a></span> | <span class="t">Show of hands, who's had to deal with Python deployment hell?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=776" target="_blank">00:12:56.180</a></span> | <span class="t">Can't see hell even.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=778" target="_blank">00:12:58.580</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=779" target="_blank">00:12:59.580</a></span> | <span class="t">Yeah, I know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=780" target="_blank">00:13:00.580</a></span> | <span class="t">It's awful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=781" target="_blank">00:13:01.580</a></span> | <span class="t">You spend hours just trying to sort out your conda, your pip, your pipen, it's awful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=786" target="_blank">00:13:06.520</a></span> | <span class="t">With the library, you inherit Rust's excellent cross-platform support and build system, making</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=791" target="_blank">00:13:11.360</a></span> | <span class="t">it easier to ship self-enclosed support to your platform, no more on making your users install</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=796" target="_blank">00:13:16.160</a></span> | <span class="t">Torch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=797" target="_blank">00:13:17.160</a></span> | <span class="t">As you might imagine, this unlocks the use of desktop applications with models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=801" target="_blank">00:13:21.860</a></span> | <span class="t">Next up, the ecosystem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=803" target="_blank">00:13:23.720</a></span> | <span class="t">Rust has one of the strongest ecosystems of any native language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=807" target="_blank">00:13:27.620</a></span> | <span class="t">You can combine these libraries with LLMs to build all kinds of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=811" target="_blank">00:13:31.700</a></span> | <span class="t">It's what let me build a Discord bot, a system order completion utility, a data ingestion pipeline</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=816" target="_blank">00:13:36.120</a></span> | <span class="t">with a data set, a utility explorer, all in the same language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=820" target="_blank">00:13:40.120</a></span> | <span class="t">And I think if you use LMRS, you can do the same thing with your task as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=825" target="_blank">00:13:45.500</a></span> | <span class="t">Of course, you also have control over how the model generates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=828" target="_blank">00:13:48.100</a></span> | <span class="t">I alluded to this earlier, but you can choose exactly how it samples tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=832" target="_blank">00:13:52.020</a></span> | <span class="t">Normally, when you use a cloud model, you have to get back the logits, the probabilities, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=836" target="_blank">00:13:56.840</a></span> | <span class="t">those probabilities are limited.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=838" target="_blank">00:13:58.900</a></span> | <span class="t">You have to keep going back and forth, and that's slow and expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=842" target="_blank">00:14:02.180</a></span> | <span class="t">With this, you can directly control what you are sampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=846" target="_blank">00:14:06.220</a></span> | <span class="t">Finally, let's talk about the innovation in the space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=850" target="_blank">00:14:10.040</a></span> | <span class="t">If you're here, you probably know there's a paper almost every single day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=853" target="_blank">00:14:13.800</a></span> | <span class="t">It's impossible to keep up with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=854" target="_blank">00:14:14.800</a></span> | <span class="t">Trust me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=855" target="_blank">00:14:15.800</a></span> | <span class="t">I've tried.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=856" target="_blank">00:14:16.800</a></span> | <span class="t">But the use of local models means you can try this out before anyone else can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=860" target="_blank">00:14:20.040</a></span> | <span class="t">You can go through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=861" target="_blank">00:14:21.040</a></span> | <span class="t">You can try out some of these papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=862" target="_blank">00:14:22.040</a></span> | <span class="t">You can be like, oh, wow, that's actually a worthwhile improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=864" target="_blank">00:14:24.260</a></span> | <span class="t">And eventually, the cloud providers will provide them, but in the meantime, the controller remains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=867" target="_blank">00:14:27.760</a></span> | <span class="t">with you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=868" target="_blank">00:14:28.760</a></span> | <span class="t">However, it's time to talk about the problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=872" target="_blank">00:14:32.420</a></span> | <span class="t">There ain't no such thing as a free lunch, except for a conference, of course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=878" target="_blank">00:14:38.040</a></span> | <span class="t">Let's talk about hardware again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=880" target="_blank">00:14:40.080</a></span> | <span class="t">I mentioned earlier that you can pretty much run these things on almost any hardware, but that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=885" target="_blank">00:14:45.440</a></span> | <span class="t">kind of a lie.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=886" target="_blank">00:14:46.440</a></span> | <span class="t">You still need some kind of power.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=888" target="_blank">00:14:48.820</a></span> | <span class="t">You can only get so much out of your 10-year-old computer, your smartphone, or your Raspberry</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=893" target="_blank">00:14:53.140</a></span> | <span class="t">Pi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=894" target="_blank">00:14:54.140</a></span> | <span class="t">We're finding clever ways to improve this, like smaller models and better inferencing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=897" target="_blank">00:14:57.920</a></span> | <span class="t">but it's still something to be aware of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=899" target="_blank">00:14:59.800</a></span> | <span class="t">Next, as with all things, the fast, cheap, good tryout applies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=904" target="_blank">00:15:04.280</a></span> | <span class="t">You can make all kinds of trade-offs here, and you see I've listed a couple of them here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=908" target="_blank">00:15:08.120</a></span> | <span class="t">but fundamentally, you have to choose what are you willing to sacrifice in order to serve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=912" target="_blank">00:15:12.360</a></span> | <span class="t">your application?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=913" target="_blank">00:15:13.720</a></span> | <span class="t">Are you willing to go for a bigger model to get better quality?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=916" target="_blank">00:15:16.080</a></span> | <span class="t">Better quality results at the cost of speed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=918" target="_blank">00:15:18.460</a></span> | <span class="t">These are all decisions you have to make, and they're not always obvious.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=922" target="_blank">00:15:22.780</a></span> | <span class="t">It's something you have to think about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=925" target="_blank">00:15:25.780</a></span> | <span class="t">Next, there's no other way of putting this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=928" target="_blank">00:15:28.060</a></span> | <span class="t">The ecosystem churns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=930" target="_blank">00:15:30.460</a></span> | <span class="t">Innovation is a double-head sword.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=931" target="_blank">00:15:31.460</a></span> | <span class="t">When those changes come in, they can often break your existing workflows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=935" target="_blank">00:15:35.200</a></span> | <span class="t">I've helped alleviate this, to some extent, using the GGU file format, which helps data-guise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=940" target="_blank">00:15:40.100</a></span> | <span class="t">but it's still a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=941" target="_blank">00:15:41.160</a></span> | <span class="t">Some days, you will just wake up, try your application with a new model, and it just won't work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=945" target="_blank">00:15:45.840</a></span> | <span class="t">There's nothing you can do except deal with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=948" target="_blank">00:15:48.840</a></span> | <span class="t">Finally, a lot of the models in this space are open source.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=953" target="_blank">00:15:53.460</a></span> | <span class="t">They're free for use personally, but they have very strange clauses and exceptions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=957" target="_blank">00:15:57.540</a></span> | <span class="t">For most of us, this doesn't matter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=959" target="_blank">00:15:59.540</a></span> | <span class="t">You can just use the model personally, but it's a reminder that even though these models are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=963" target="_blank">00:16:03.220</a></span> | <span class="t">free, they're not capital F-free, luckily, there's been some recent change in the space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=968" target="_blank">00:16:08.160</a></span> | <span class="t">with Mistral and Stable LM giving you strong performance of a small size and being completely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=974" target="_blank">00:16:14.140</a></span> | <span class="t">unburdened, but it's still a problem, and they're still much smaller than the big ones,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=978" target="_blank">00:16:18.540</a></span> | <span class="t">like Lama and Falcon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=980" target="_blank">00:16:20.540</a></span> | <span class="t">Unfortunately, I've got to wrap things up here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=982" target="_blank">00:16:22.720</a></span> | <span class="t">There's only so much you can talk about in 18 minutes, I'm afraid.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=986" target="_blank">00:16:26.360</a></span> | <span class="t">Local models are great, and I'd like to think our library is too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=989" target="_blank">00:16:29.980</a></span> | <span class="t">They're getting easier to run day by day with smaller, more powerful models, however, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=994" target="_blank">00:16:34.120</a></span> | <span class="t">situation isn't perfect, and there isn't always one obvious solution for your problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=998" target="_blank">00:16:38.860</a></span> | <span class="t">Thanks for listening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=999" target="_blank">00:16:39.860</a></span> | <span class="t">You can contact me by email or by Mastodon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1002" target="_blank">00:16:42.660</a></span> | <span class="t">The library can be found at, you guessed it, llm.rs, or by scanning the QR code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1007" target="_blank">00:16:47.060</a></span> | <span class="t">Finally, we're always looking for contributors, if you're interested in LMs or Rust, feel free</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1011" target="_blank">00:16:51.280</a></span> | <span class="t">to reach out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1012" target="_blank">00:16:52.280</a></span> | <span class="t">Sponsorships are also very welcome, because they help me try out new hardware, which is always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1015" target="_blank">00:16:55.820</a></span> | <span class="t">necessary, and if you want to chat in person, I'll be hanging around the conference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1019" target="_blank">00:16:59.600</a></span> | <span class="t">I'll see you later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1020" target="_blank">00:17:00.220</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1021" target="_blank">00:17:01.220</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1021" target="_blank">00:17:01.220</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1021" target="_blank">00:17:01.220</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1021" target="_blank">00:17:01.220</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1022" target="_blank">00:17:02.220</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1022" target="_blank">00:17:02.220</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1023" target="_blank">00:17:03.220</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1023" target="_blank">00:17:03.220</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1023" target="_blank">00:17:03.220</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1023" target="_blank">00:17:03.220</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1023" target="_blank">00:17:03.220</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=MwqUYRQloGw&t=1024" target="_blank">00:17:04.220</a></span> | <span class="t">We'll see you next time.</span></div></div></body></html>