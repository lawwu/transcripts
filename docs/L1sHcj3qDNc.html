<html><head><title>Torch Tutorial (Alex Wiltschko, Twitter)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Torch Tutorial (Alex Wiltschko, Twitter)</h2><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc"><img src="https://i.ytimg.com/vi_webp/L1sHcj3qDNc/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=0">0:0</a> <Untitled Chapter 1><br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=468">7:48</a> TORCH - ARITHMETIC<br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=482">8:2</a> TORCH - BOOLEAN OPS<br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=486">8:6</a> TORCH - SPECIAL FUNCTIONS<br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=501">8:21</a> TORCH - RANDOM NUMBERS & PLOTTING<br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=678">11:18</a> TORCH - WHERE DOES IT FIT? is for research or production? It can be for both But mostly used for research<br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=985">16:25</a> TRAINING CYCLE<br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1457">24:17</a> AUTOMATIC DIFFERENTIATION IS THE ABSTRACTION FOR GRADIENT-BASED ML<br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1534">25:34</a> FORWARD MODE (SYMBOLIC VIEW)<br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1727">28:47</a> REVERSE MODE (SYMBOLIC VIEW)<br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1739">28:59</a> REVERSE MODE (PROGRAM VIEW) Right-to-left evaluation of partial derivatives the right thing to do for optimization<br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1979">32:59</a> AUTOGRAD EXAMPLES<br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2448">40:48</a> SO WHAT DIFFERENTIATES N.NET LIBRARIES? What is the graph?<br><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2529">42:9</a> NEURAL NET THREE WAYS<br><br><div style="text-align: left;"><a href="./L1sHcj3qDNc.html">Whisper Transcript</a> | <a href="./transcript_L1sHcj3qDNc.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">So I'm going to tell you about machine learning with Torch and with Torch Autograd.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=4" target="_blank">00:00:04.160</a></span> | <span class="t">So the description of the talk isn't entirely correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=7" target="_blank">00:00:07.880</a></span> | <span class="t">I'm going to do practical stuff for the first half.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=11" target="_blank">00:00:11.040</a></span> | <span class="t">And then what I want to do is dive into Torch Autograd and some of the concepts that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=16" target="_blank">00:00:16.180</a></span> | <span class="t">behind it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=17" target="_blank">00:00:17.180</a></span> | <span class="t">And those concepts also happen to be shared amongst all deep learning libraries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=21" target="_blank">00:00:21.540</a></span> | <span class="t">So I really want to give you a perspective of the common thread that links all deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=25" target="_blank">00:00:25.920</a></span> | <span class="t">software you could possibly use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=28" target="_blank">00:00:28.200</a></span> | <span class="t">And then also talk a bit about what makes each of the libraries different and why there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=31" target="_blank">00:00:31.400</a></span> | <span class="t">-- I will hypothesize why there's so many and the different choices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=36" target="_blank">00:00:36.920</a></span> | <span class="t">So one thing I want to try -- there's been a lot of questions and we've gone over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=41" target="_blank">00:00:41.160</a></span> | <span class="t">But if there's not questions that go over time in the room, there's a lot of people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=45" target="_blank">00:00:45.160</a></span> | <span class="t">watching online.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=46" target="_blank">00:00:46.640</a></span> | <span class="t">And if there's extra time, we'll, of course, prioritize people here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=50" target="_blank">00:00:50.040</a></span> | <span class="t">But if you ask a question with the #DLschool hashtag or if you tweet at me directly, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=54" target="_blank">00:00:54.440</a></span> | <span class="t">will try to answer those questions from online and I'll certainly answer them offline as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=58" target="_blank">00:00:58.560</a></span> | <span class="t">well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=59" target="_blank">00:00:59.680</a></span> | <span class="t">So ask if you're watching at home.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=62" target="_blank">00:01:02.040</a></span> | <span class="t">Maybe that will kind of increase meaningful participation for people watching through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=66" target="_blank">00:01:06.080</a></span> | <span class="t">the stream that aren't here today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=68" target="_blank">00:01:08.480</a></span> | <span class="t">A lot of this material was developed with Sumit Chintala at Facebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=72" target="_blank">00:01:12.280</a></span> | <span class="t">He's kind of the czar of the Torch ecosystem these days.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=76" target="_blank">00:01:16.520</a></span> | <span class="t">And Hugo La Rochelle, who you heard from yesterday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=78" target="_blank">00:01:18.720</a></span> | <span class="t">And also Ryan Adams, who's at Twitter with us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=82" target="_blank">00:01:22.880</a></span> | <span class="t">And all this material is available on this GitHub repository that you got actually on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=89" target="_blank">00:01:29.400</a></span> | <span class="t">a printed sheet for installing Torch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=92" target="_blank">00:01:32.800</a></span> | <span class="t">So all the examples that I'll show you will be in one notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=96" target="_blank">00:01:36.960</a></span> | <span class="t">And then there's a separate notebook, which I actually won't reference in the talk, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=99" target="_blank">00:01:39.880</a></span> | <span class="t">a full end-to-end walkthrough of how to train a convolutional neural network on CIFAR-10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=105" target="_blank">00:01:45.840</a></span> | <span class="t">So that's kind of a self-paced tutorial notebook that you can work through on your own time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=109" target="_blank">00:01:49.760</a></span> | <span class="t">But I'm going to focus on the basics, on the fundamentals, and hopefully give you some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=114" target="_blank">00:01:54.160</a></span> | <span class="t">of the concepts and vocabulary that you can use to really dive into Torch on your own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=118" target="_blank">00:01:58.480</a></span> | <span class="t">time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=119" target="_blank">00:01:59.640</a></span> | <span class="t">So let's get going.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=121" target="_blank">00:02:01.080</a></span> | <span class="t">So Torch is an array programming language for Lua.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=125" target="_blank">00:02:05.360</a></span> | <span class="t">So it's like NumPy, it's like MATLAB, but it's in the Lua language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=128" target="_blank">00:02:08.880</a></span> | <span class="t">So Torch is to Lua, as NumPy is to Python.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=133" target="_blank">00:02:13.160</a></span> | <span class="t">So what you can do in Torch, you can do in any language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=137" target="_blank">00:02:17.080</a></span> | <span class="t">This is the absolute minimum basics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=138" target="_blank">00:02:18.880</a></span> | <span class="t">You can grab strings and print them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=141" target="_blank">00:02:21.560</a></span> | <span class="t">You can put things in associative data types.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=144" target="_blank">00:02:24.840</a></span> | <span class="t">In Python, there's tuples and lists and sets and dictionaries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=148" target="_blank">00:02:28.680</a></span> | <span class="t">In Lua, there's just one data type called a table.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=152" target="_blank">00:02:32.280</a></span> | <span class="t">So you'll see that a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=153" target="_blank">00:02:33.280</a></span> | <span class="t">But you can do all those things that I mentioned before with a table.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=156" target="_blank">00:02:36.560</a></span> | <span class="t">And you've got for loops and if statements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=160" target="_blank">00:02:40.360</a></span> | <span class="t">The core type of Torch is the tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=163" target="_blank">00:02:43.320</a></span> | <span class="t">Just like in NumPy, when you have the nd array, which is a way of shaping sets of numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=168" target="_blank">00:02:48.680</a></span> | <span class="t">into matrices or tensors, we have the tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=173" target="_blank">00:02:53.200</a></span> | <span class="t">And you can fill it up with random numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=174" target="_blank">00:02:54.680</a></span> | <span class="t">You can multiply them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=176" target="_blank">00:02:56.280</a></span> | <span class="t">Standard stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=177" target="_blank">00:02:57.280</a></span> | <span class="t">But the tensor is the core data type of Torch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=180" target="_blank">00:03:00.720</a></span> | <span class="t">We've got plotting functionality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=182" target="_blank">00:03:02.680</a></span> | <span class="t">Going over at a very high level, I'll show you some more specific code in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=186" target="_blank">00:03:06.720</a></span> | <span class="t">So you can do all the kind of standard stuff that you'd do in any other array-based language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=192" target="_blank">00:03:12.320</a></span> | <span class="t">There's all the tensor functions that you'd like to use, including all the linear algebra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=197" target="_blank">00:03:17.640</a></span> | <span class="t">and convolutions and, you know, blast functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=201" target="_blank">00:03:21.320</a></span> | <span class="t">And I'm leaving this link here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=202" target="_blank">00:03:22.880</a></span> | <span class="t">When the slides get uploaded, you can follow this and kind of dive into the documentation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=206" target="_blank">00:03:26.680</a></span> | <span class="t">and see exactly what kind of tools you have at your disposal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=211" target="_blank">00:03:31.480</a></span> | <span class="t">In the notebook, in the itorch notebook, which is something that Sumith put together, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=216" target="_blank">00:03:36.760</a></span> | <span class="t">can prepend any Torch function with a question mark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=219" target="_blank">00:03:39.320</a></span> | <span class="t">And that gives you the help for that function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=221" target="_blank">00:03:41.760</a></span> | <span class="t">So it makes it really nice to discover functionality in the Torch library, in the notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=229" target="_blank">00:03:49.880</a></span> | <span class="t">So why is it in Lua?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=231" target="_blank">00:03:51.920</a></span> | <span class="t">It's kind of maybe a strange, maybe esoteric language to write things in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=238" target="_blank">00:03:58.080</a></span> | <span class="t">Lua is unreasonably fast for how convenient it is to use, especially a flavor of Lua called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=245" target="_blank">00:04:05.480</a></span> | <span class="t">LuaJIT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=246" target="_blank">00:04:06.480</a></span> | <span class="t">For loops in LuaJIT are basically the same speed as C.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=250" target="_blank">00:04:10.560</a></span> | <span class="t">So this for loop here is actually in production code in master in Torch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=256" target="_blank">00:04:16.040</a></span> | <span class="t">It's not C code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=258" target="_blank">00:04:18.120</a></span> | <span class="t">But this is perfectly fast enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=260" target="_blank">00:04:20.220</a></span> | <span class="t">So that's a really nice aspect of Lua, is you can depend on super high performance C</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=266" target="_blank">00:04:26.040</a></span> | <span class="t">code, and then on top of it, you've got this very convenient glue layer, but you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=269" target="_blank">00:04:29.800</a></span> | <span class="t">pay much of a speed penalty to use that glue layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=272" target="_blank">00:04:32.520</a></span> | <span class="t">So that's one of the reasons why we've used Lua.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=275" target="_blank">00:04:35.420</a></span> | <span class="t">Another advantage that some people might see as a plus is the language itself is quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=278" target="_blank">00:04:38.680</a></span> | <span class="t">small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=279" target="_blank">00:04:39.680</a></span> | <span class="t">There's 10,000 lines of C code that define the whole language of Lua.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=283" target="_blank">00:04:43.560</a></span> | <span class="t">So you can really sit down with the manual in an afternoon and understand most of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=287" target="_blank">00:04:47.920</a></span> | <span class="t">language on your own that same day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=292" target="_blank">00:04:52.120</a></span> | <span class="t">Another aspect which is pretty critical for deep learning, but also for other fields,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=296" target="_blank">00:04:56.320</a></span> | <span class="t">is that it's really easy to interoperate with C libraries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=299" target="_blank">00:04:59.600</a></span> | <span class="t">It was designed originally to be embedded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=302" target="_blank">00:05:02.400</a></span> | <span class="t">So Lua was a language that was designed to run inside of another C program, but have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=306" target="_blank">00:05:06.640</a></span> | <span class="t">a little scripting layer inside of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=308" target="_blank">00:05:08.560</a></span> | <span class="t">So it's very easy to call into C. It's very easy for C to call into Lua.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=312" target="_blank">00:05:12.720</a></span> | <span class="t">So this is another reason why it's kind of an appropriate choice for deep learning libraries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=318" target="_blank">00:05:18.360</a></span> | <span class="t">The FFI call signature and the idea has been copied into many other languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=325" target="_blank">00:05:25.200</a></span> | <span class="t">So C, FFI, and Python is a Python version of the Lua FFI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=330" target="_blank">00:05:30.240</a></span> | <span class="t">Julia has something similar as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=334" target="_blank">00:05:34.060</a></span> | <span class="t">And as I mentioned, it was originally designed to be embedded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=336" target="_blank">00:05:36.540</a></span> | <span class="t">And it's in all kinds of crazy places that you maybe wouldn't expect Lua to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=340" target="_blank">00:05:40.680</a></span> | <span class="t">So in World of Warcraft, all the graphics are in C++ or whatever they wrote it in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=344" target="_blank">00:05:44.520</a></span> | <span class="t">But like the boss battles or the quests.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=346" target="_blank">00:05:46.240</a></span> | <span class="t">So like when you go give the gem to the blacksmith or whatever and they give you back the magic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=350" target="_blank">00:05:50.680</a></span> | <span class="t">sword, the scripting of those events happens in Lua.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=353" target="_blank">00:05:53.280</a></span> | <span class="t">And if you write scripts for World of Warcraft to make your own quests, that's Lua.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=357" target="_blank">00:05:57.760</a></span> | <span class="t">Adobe Lightroom is a photo processing app.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=360" target="_blank">00:06:00.560</a></span> | <span class="t">All the image processing is done in C++, but all the UI and everything was done in Lua.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=365" target="_blank">00:06:05.320</a></span> | <span class="t">So again, it was used to bind together high-performance code with kind of a scripting layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=370" target="_blank">00:06:10.960</a></span> | <span class="t">And Redis and Nginx, which are kind of workhorses in the field of web development, are both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=375" target="_blank">00:06:15.560</a></span> | <span class="t">scriptable with Lua.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=378" target="_blank">00:06:18.320</a></span> | <span class="t">And in fact, if you go to GitHub pages, like mypage.github.io, if somebody's hosting a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=383" target="_blank">00:06:23.240</a></span> | <span class="t">web page on GitHub, that's served in part by Lua.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=387" target="_blank">00:06:27.680</a></span> | <span class="t">The apocryphal story of why it was originally chosen, maybe you could correct me, is Clemence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=393" target="_blank">00:06:33.120</a></span> | <span class="t">Barabay was trying to build an embedded machine learning application, some device he could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=398" target="_blank">00:06:38.560</a></span> | <span class="t">wear on his bike helmet and classify the world with the CNN when he was a Yon student.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=403" target="_blank">00:06:43.240</a></span> | <span class="t">And he was trying to do this with Python.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=405" target="_blank">00:06:45.160</a></span> | <span class="t">And it's incredibly frustrating to get Python to run on embedded chips.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=409" target="_blank">00:06:49.160</a></span> | <span class="t">Maybe it's easier now with Raspberry Pi, but that just wasn't the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=412" target="_blank">00:06:52.240</a></span> | <span class="t">And then he stumbled upon Lua, and it turns out people had been building Lua into embedded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=416" target="_blank">00:06:56.040</a></span> | <span class="t">applications for years before that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=417" target="_blank">00:06:57.880</a></span> | <span class="t">And so that kind of was the snowballing effect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=420" target="_blank">00:07:00.040</a></span> | <span class="t">So that's the hearsay for how we arrived at Lua.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=423" target="_blank">00:07:03.960</a></span> | <span class="t">But maybe there's another story.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=427" target="_blank">00:07:07.100</a></span> | <span class="t">Another really nice feature of Torch is we have first-class support for GPU computation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=435" target="_blank">00:07:15.440</a></span> | <span class="t">interactive GPU computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=437" target="_blank">00:07:17.140</a></span> | <span class="t">So it's very, very easy to get some data from the CPU to the GPU, and then everything that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=442" target="_blank">00:07:22.520</a></span> | <span class="t">you do with that data happens on the GPU without you having to worry about writing CUDA kernels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=446" target="_blank">00:07:26.800</a></span> | <span class="t">So this has been a feature of Torch, which is becoming maybe a little bit less unique</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=451" target="_blank">00:07:31.840</a></span> | <span class="t">now, but this was a pretty solid feature when it first came out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=456" target="_blank">00:07:36.400</a></span> | <span class="t">So interactive GPU computing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=459" target="_blank">00:07:39.080</a></span> | <span class="t">And I'll go very quickly over some of the basic features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=462" target="_blank">00:07:42.040</a></span> | <span class="t">And all of these examples, again, are in a notebook, which you can do kind of at your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=465" target="_blank">00:07:45.740</a></span> | <span class="t">own pace if you'd like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=468" target="_blank">00:07:48.140</a></span> | <span class="t">So there's all the basic arithmetic, like creating matrices and doing arithmetic between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=473" target="_blank">00:07:53.560</a></span> | <span class="t">them, taking maxes of numbers and arrays, clamping, building tensors out of ranges,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=482" target="_blank">00:08:02.240</a></span> | <span class="t">Boolean operations over entire arrays, special functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=487" target="_blank">00:08:07.200</a></span> | <span class="t">This is supported through a wrapper around the Cepheys library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=491" target="_blank">00:08:11.200</a></span> | <span class="t">This is what NumPy uses to support things like tanh and atan2 and other kinds of functions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=496" target="_blank">00:08:16.840</a></span> | <span class="t">that I guess are in the special class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=501" target="_blank">00:08:21.500</a></span> | <span class="t">And then Sumith, again, has wrapped the bokeh.js library, which is originally just for Python,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=508" target="_blank">00:08:28.200</a></span> | <span class="t">but it provides really nice and beautiful plots in the iTorch notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=512" target="_blank">00:08:32.480</a></span> | <span class="t">And so we can, you know, draw random numbers from our favorite distributions and make nice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=516" target="_blank">00:08:36.840</a></span> | <span class="t">histograms of these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=517" target="_blank">00:08:37.880</a></span> | <span class="t">So you can do nice data exploration in the iTorch notebook along with deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=523" target="_blank">00:08:43.520</a></span> | <span class="t">So one feature that is attractive to some folks, but just an interesting feature of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=529" target="_blank">00:08:49.440</a></span> | <span class="t">the Torch ecosystem, is that although there's a lot of industry support, it is not industry</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=534" target="_blank">00:08:54.140</a></span> | <span class="t">owned.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=535" target="_blank">00:08:55.260</a></span> | <span class="t">So at Twitter and at Facebook AI Research and at NVIDIA, we all contribute a lot to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=540" target="_blank">00:09:00.460</a></span> | <span class="t">the Torch community, but we don't own it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=543" target="_blank">00:09:03.820</a></span> | <span class="t">We can't really steer it to go one way or the other definitively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=547" target="_blank">00:09:07.780</a></span> | <span class="t">And there's a ton of other people that participate academically in this ecosystem, and that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=551" target="_blank">00:09:11.660</a></span> | <span class="t">a really nice feature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=555" target="_blank">00:09:15.020</a></span> | <span class="t">And along with -- I guess because of the really nice habits of people in deep learning, when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=561" target="_blank">00:09:21.760</a></span> | <span class="t">a paper comes out, there's often a high quality code implementation that follows it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=566" target="_blank">00:09:26.680</a></span> | <span class="t">Not always, but very often, at least compared with other fields.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=570" target="_blank">00:09:30.780</a></span> | <span class="t">And Torch is one of the environments in which you'll often see high quality implementations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=575" target="_blank">00:09:35.540</a></span> | <span class="t">of really cutting edge stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=577" target="_blank">00:09:37.240</a></span> | <span class="t">So if you just browse through GitHub and you kind of follow researchers on GitHub, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=582" target="_blank">00:09:42.360</a></span> | <span class="t">can see really high quality implementations of image captioning, of neural style transfer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=587" target="_blank">00:09:47.880</a></span> | <span class="t">so you can just clone this GitHub repository and run this yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=592" target="_blank">00:09:52.520</a></span> | <span class="t">Seek to seek models, kind of whatever is the state of the art, there's usually a Torch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=596" target="_blank">00:09:56.600</a></span> | <span class="t">implementation of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=598" target="_blank">00:09:58.720</a></span> | <span class="t">Some of the recent work in generating very realistic synthetic images with generative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=603" target="_blank">00:10:03.860</a></span> | <span class="t">adversarial networks also has great Torch code implementing it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=607" target="_blank">00:10:07.960</a></span> | <span class="t">So given that there's this active community on GitHub in deep learning for Torch, how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=616" target="_blank">00:10:16.720</a></span> | <span class="t">does that stack up against other communities?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=618" target="_blank">00:10:18.840</a></span> | <span class="t">Just to give you some context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=619" target="_blank">00:10:19.980</a></span> | <span class="t">So the Python data science community is pretty enormous, and its focuses are also very varied.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=628" target="_blank">00:10:28.340</a></span> | <span class="t">If you enter into the data science community in Torch and Lua, you'll likely find deep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=633" target="_blank">00:10:33.820</a></span> | <span class="t">learning people, but not a lot of other people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=636" target="_blank">00:10:36.220</a></span> | <span class="t">So its strength in deep learning compared to its size is actually quite enormous.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=640" target="_blank">00:10:40.900</a></span> | <span class="t">And for those that are kind of thinking of switching between Python and Lua and giving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=644" target="_blank">00:10:44.120</a></span> | <span class="t">Torch a try, the effort to switch from Python to Lua, you can probably do that in a day</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=649" target="_blank">00:10:49.200</a></span> | <span class="t">if you've tried some Python programming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=651" target="_blank">00:10:51.240</a></span> | <span class="t">So I was a Python programmer for a while, and getting started on Lua took me maybe a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=655" target="_blank">00:10:55.920</a></span> | <span class="t">couple days, and I was actually productive at work in maybe a week or so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=660" target="_blank">00:11:00.160</a></span> | <span class="t">But you can actually run your code and understand and write new things pretty quickly if you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=664" target="_blank">00:11:04.080</a></span> | <span class="t">worked in a scripting language like MATLAB or Python.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=666" target="_blank">00:11:06.480</a></span> | <span class="t">So if you're intimidated or waiting to try it, you should just dive in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=670" target="_blank">00:11:10.480</a></span> | <span class="t">So how does Torch compare to other deep learning libraries specifically, as opposed to languages?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=676" target="_blank">00:11:16.200</a></span> | <span class="t">The first thing I'll say is there's really no silver bullet right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=679" target="_blank">00:11:19.660</a></span> | <span class="t">There are a lot of deep learning libraries out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=682" target="_blank">00:11:22.040</a></span> | <span class="t">I'd say TensorFlow is by far the largest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=685" target="_blank">00:11:25.880</a></span> | <span class="t">And this is a plot that was made by a colleague of Sumit's, and I wish it kind of had confidence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=692" target="_blank">00:11:32.140</a></span> | <span class="t">intervals on it, because it's not strictly that these are, like, you know, points in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=696" target="_blank">00:11:36.920</a></span> | <span class="t">deep learning space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=699" target="_blank">00:11:39.320</a></span> | <span class="t">But maybe this is a good guess of where things kind of fit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=702" target="_blank">00:11:42.400</a></span> | <span class="t">It seems as if TensorFlow was engineered to be very good in an industrial production setting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=706" target="_blank">00:11:46.840</a></span> | <span class="t">and it seems like it's really fulfilling that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=708" target="_blank">00:11:48.960</a></span> | <span class="t">Theano seems to have always had a research goal in mind and has been really awesome in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=714" target="_blank">00:11:54.080</a></span> | <span class="t">the research community for some time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=716" target="_blank">00:11:56.320</a></span> | <span class="t">Torch tends to be more towards research than industry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=718" target="_blank">00:11:58.800</a></span> | <span class="t">I think Twitter maybe has pulled it a little bit towards production.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=722" target="_blank">00:12:02.440</a></span> | <span class="t">We maybe are the only example -- I'd love to learn of others, but we're maybe the only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=725" target="_blank">00:12:05.520</a></span> | <span class="t">example of a large company that uses Torch in production to serve models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=730" target="_blank">00:12:10.640</a></span> | <span class="t">So every piece of media that comes in to Twitter goes through a Torch model at this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=735" target="_blank">00:12:15.420</a></span> | <span class="t">So we're really dealing with an enormous amount of data in a live setting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=741" target="_blank">00:12:21.840</a></span> | <span class="t">The development of Torch, just to give you a sense of how we think about how it was built</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=746" target="_blank">00:12:26.640</a></span> | <span class="t">and how we're extending it, there's some kind of tenets of our core philosophy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=751" target="_blank">00:12:31.520</a></span> | <span class="t">Really the first is things should be -- this isn't necessarily good or bad, but this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=755" target="_blank">00:12:35.600</a></span> | <span class="t">our choice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=756" target="_blank">00:12:36.840</a></span> | <span class="t">Whenever you hit enter on a particular line in your iTorch notebook or on the command</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=760" target="_blank">00:12:40.640</a></span> | <span class="t">line, you should get an answer back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=763" target="_blank">00:12:43.680</a></span> | <span class="t">And this is something that we've tried to stick to pretty tightly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=767" target="_blank">00:12:47.000</a></span> | <span class="t">So no compilation time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=769" target="_blank">00:12:49.360</a></span> | <span class="t">Imperative programming, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=770" target="_blank">00:12:50.360</a></span> | <span class="t">So just write your code and, you know, each line of code executes something and passes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=774" target="_blank">00:12:54.900</a></span> | <span class="t">it to the next line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=778" target="_blank">00:12:58.200</a></span> | <span class="t">In minimal abstraction -- what I mean by minimal abstraction is if you want to reason about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=781" target="_blank">00:13:01.960</a></span> | <span class="t">how your code is performing, it shouldn't take you that many jumps to go to the C code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=786" target="_blank">00:13:06.160</a></span> | <span class="t">that's actually being run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=787" target="_blank">00:13:07.280</a></span> | <span class="t">In fact, it usually is one or two jumps from the file that defines the function that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=791" target="_blank">00:13:11.880</a></span> | <span class="t">care about to the actual C code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=793" target="_blank">00:13:13.800</a></span> | <span class="t">So if you want to reason about performance or really understand what's going on, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=797" target="_blank">00:13:17.040</a></span> | <span class="t">quite easy to do so in Torch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=801" target="_blank">00:13:21.360</a></span> | <span class="t">I want to take a little bit of a detour and tell you about how Torch thinks about its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=807" target="_blank">00:13:27.080</a></span> | <span class="t">objects, how it thinks about the tensor, because this can help you also reason about performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=811" target="_blank">00:13:31.200</a></span> | <span class="t">A lot of the reason why people come to Torch is to build high-performance models very quickly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=815" target="_blank">00:13:35.800</a></span> | <span class="t">and easily.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=817" target="_blank">00:13:37.680</a></span> | <span class="t">So I mentioned tensors before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=819" target="_blank">00:13:39.880</a></span> | <span class="t">So a tensor is an n-dimensional array.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=824" target="_blank">00:13:44.600</a></span> | <span class="t">And a tensor is actually just a pointer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=826" target="_blank">00:13:46.600</a></span> | <span class="t">It's a view into your data that's sitting in memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=831" target="_blank">00:13:51.480</a></span> | <span class="t">So it's just a shape.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=833" target="_blank">00:13:53.120</a></span> | <span class="t">It's a view into what's actually being stored in your RAM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=837" target="_blank">00:13:57.120</a></span> | <span class="t">It's stored in a row major way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=838" target="_blank">00:13:58.920</a></span> | <span class="t">So that means if I go to the first element of my tensor in memory and I move over one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=844" target="_blank">00:14:04.360</a></span> | <span class="t">I'm moving over one in a row and not one in a column.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=848" target="_blank">00:14:08.080</a></span> | <span class="t">Column major memory storage does exist.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=851" target="_blank">00:14:11.280</a></span> | <span class="t">It's just less common today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=852" target="_blank">00:14:12.440</a></span> | <span class="t">So you'll often see row major.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=854" target="_blank">00:14:14.120</a></span> | <span class="t">So this tensor is defined by its link to some storage and its size, 4 by 6, and its stride,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=860" target="_blank">00:14:20.440</a></span> | <span class="t">6 by 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=861" target="_blank">00:14:21.440</a></span> | <span class="t">And 6 by 1 means if I move one down in the column direction, I actually have to skip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=866" target="_blank">00:14:26.520</a></span> | <span class="t">six elements in memory, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=868" target="_blank">00:14:28.800</a></span> | <span class="t">Whereas the 1 here means if I move over one in the second axis, the row axis, I just have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=873" target="_blank">00:14:33.640</a></span> | <span class="t">to go over one in memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=876" target="_blank">00:14:36.280</a></span> | <span class="t">So if I take a slice of this tensor using the select command, so I select along the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=881" target="_blank">00:14:41.840</a></span> | <span class="t">first dimension, the third element, what it gives me back is a new tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=886" target="_blank">00:14:46.160</a></span> | <span class="t">It doesn't give me new memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=887" target="_blank">00:14:47.400</a></span> | <span class="t">This is a thing that happens a lot in Torch, is you'll deal with views into memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=892" target="_blank">00:14:52.760</a></span> | <span class="t">You won't do memory copies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=894" target="_blank">00:14:54.080</a></span> | <span class="t">So you're usually working with kind of the raw data in RAM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=899" target="_blank">00:14:59.120</a></span> | <span class="t">And so this creates a new tensor with the size of 6 because there's six elements, a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=902" target="_blank">00:15:02.160</a></span> | <span class="t">stride of 1 because we've pulled out a row, not a column, and an offset of 13.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=906" target="_blank">00:15:06.280</a></span> | <span class="t">That means I have to go 13 elements from the beginning of the original storage to find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=909" target="_blank">00:15:09.840</a></span> | <span class="t">that piece of memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=912" target="_blank">00:15:12.640</a></span> | <span class="t">So if I pull out a column, then something different happens, which is I still have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=917" target="_blank">00:15:17.480</a></span> | <span class="t">size of 4 here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=919" target="_blank">00:15:19.040</a></span> | <span class="t">And my stride is now 6 because in order to grab each element of the column, I have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=923" target="_blank">00:15:23.200</a></span> | <span class="t">skip 6.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=924" target="_blank">00:15:24.760</a></span> | <span class="t">And then the offset of 3 is because I grabbed the third element there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=928" target="_blank">00:15:28.240</a></span> | <span class="t">So that's kind of a view of the memory model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=931" target="_blank">00:15:31.280</a></span> | <span class="t">And if we actually run something like this, like we instantiate a tensor of double values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=940" target="_blank">00:15:40.400</a></span> | <span class="t">inside of the tensor and fill it with uniform distribution and print it, we can see the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=947" target="_blank">00:15:47.320</a></span> | <span class="t">values here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=948" target="_blank">00:15:48.320</a></span> | <span class="t">And then if you grab a slice B and print it, it's just this row.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=952" target="_blank">00:15:52.760</a></span> | <span class="t">And then we can fill B with just some number and print it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=956" target="_blank">00:15:56.040</a></span> | <span class="t">Now it's filled with that number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=957" target="_blank">00:15:57.040</a></span> | <span class="t">And if we go back and print A, we've actually overwritten the values there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=961" target="_blank">00:16:01.040</a></span> | <span class="t">So this is something you see a lot in Torch, is working on one big piece of shared memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=967" target="_blank">00:16:07.320</a></span> | <span class="t">And as I mentioned before, working with CUDA is really, really easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=971" target="_blank">00:16:11.440</a></span> | <span class="t">So if you just require a CUTORCH, which is installed automatically if you have a CUDA</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=975" target="_blank">00:16:15.960</a></span> | <span class="t">GPU using the instructions on the GitHub repository, you can instantiate a tensor on the GPU and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=983" target="_blank">00:16:23.520</a></span> | <span class="t">do the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=984" target="_blank">00:16:24.880</a></span> | <span class="t">And it will just work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=986" target="_blank">00:16:26.680</a></span> | <span class="t">So now I want to talk a bit about the frameworks that you'll use to actually train neural networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=992" target="_blank">00:16:32.720</a></span> | <span class="t">in Torch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=994" target="_blank">00:16:34.080</a></span> | <span class="t">So this is a schematic kind of cartoon of how we-- of the pieces we typically need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=999" target="_blank">00:16:39.640</a></span> | <span class="t">train a neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1000" target="_blank">00:16:40.840</a></span> | <span class="t">So we've got our data stored on a hard drive or on a big distributed file system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1006" target="_blank">00:16:46.520</a></span> | <span class="t">And we have some system for loading that data off of that file system, which goes into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1012" target="_blank">00:16:52.200</a></span> | <span class="t">nice queue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1013" target="_blank">00:16:53.360</a></span> | <span class="t">And then some training code which orchestrates a neural network, so the thing actually making</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1017" target="_blank">00:16:57.840</a></span> | <span class="t">the prediction, a cost function, which is a measure of how good our neural network is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1021" target="_blank">00:17:01.800</a></span> | <span class="t">at any point in our training, and an optimizer, which is going to take the gradient of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1026" target="_blank">00:17:06.840</a></span> | <span class="t">cost with respect to the parameters in the neural network and try to make the neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1030" target="_blank">00:17:10.240</a></span> | <span class="t">network better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1031" target="_blank">00:17:11.640</a></span> | <span class="t">So in the Torch ecosystem, we've got some packages that tackle each one of these separately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1038" target="_blank">00:17:18.240</a></span> | <span class="t">So I won't talk about threads here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1040" target="_blank">00:17:20.080</a></span> | <span class="t">There's actually several different libraries that will do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1042" target="_blank">00:17:22.200</a></span> | <span class="t">There's actually several different libraries that will do each one of these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1045" target="_blank">00:17:25.040</a></span> | <span class="t">But this one is maybe the most common or the easiest to start with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1049" target="_blank">00:17:29.480</a></span> | <span class="t">And NN here will cover both the specification of the neural network and the cost function,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1054" target="_blank">00:17:34.120</a></span> | <span class="t">as well as the mechanisms to push data through the neural network and the cost function and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1058" target="_blank">00:17:38.320</a></span> | <span class="t">pull the gradients back from the cost to the parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1061" target="_blank">00:17:41.420</a></span> | <span class="t">And then the optimizer, which is-- we've heard mentioned several times today, stochastic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1064" target="_blank">00:17:44.960</a></span> | <span class="t">gradient descent or Adam or AdaGrad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1067" target="_blank">00:17:47.800</a></span> | <span class="t">So let me talk about NN first, give you a flavor of how it works and what the pieces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1073" target="_blank">00:17:53.600</a></span> | <span class="t">are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1075" target="_blank">00:17:55.600</a></span> | <span class="t">So NN is a package for building feedforward neural networks, mostly feedforward neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1083" target="_blank">00:18:03.160</a></span> | <span class="t">networks, by clicking Lego blocks together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1086" target="_blank">00:18:06.260</a></span> | <span class="t">So you might start with your input and then click together a fully connected layer, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1089" target="_blank">00:18:09.680</a></span> | <span class="t">then another fully connected layer, and then maybe some output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1093" target="_blank">00:18:13.200</a></span> | <span class="t">So here, I've defined a sequential container, which is going to be a container for all my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1098" target="_blank">00:18:18.660</a></span> | <span class="t">Lego blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1100" target="_blank">00:18:20.480</a></span> | <span class="t">And then I might click in a spatial convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1103" target="_blank">00:18:23.180</a></span> | <span class="t">So I'm going to be working with images, maybe, a non-linearity, some max pooling, some other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1108" target="_blank">00:18:28.820</a></span> | <span class="t">layers, as well, to kind of complete the whole neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1113" target="_blank">00:18:33.920</a></span> | <span class="t">And then I might add a log soft max at the end to compute class probabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1118" target="_blank">00:18:38.360</a></span> | <span class="t">So this is kind of the structure that you'll build neural networks with in NN, is define</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1123" target="_blank">00:18:43.000</a></span> | <span class="t">a container and then one by one add pieces down a processing hierarchy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1128" target="_blank">00:18:48.920</a></span> | <span class="t">And I mentioned the sequential container, which is starting from inputs and then proceeding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1132" target="_blank">00:18:52.040</a></span> | <span class="t">linearly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1133" target="_blank">00:18:53.040</a></span> | <span class="t">There's two other types of containers that you might use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1136" target="_blank">00:18:56.200</a></span> | <span class="t">But generally, NN shines when your architecture is linear, not when it's got some crazy branches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1142" target="_blank">00:19:02.120</a></span> | <span class="t">or anything like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1146" target="_blank">00:19:06.320</a></span> | <span class="t">There's not a lot of API to the NN package.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1148" target="_blank">00:19:08.520</a></span> | <span class="t">So if you learn these couple functions, which will be in the slides for later if you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1152" target="_blank">00:19:12.980</a></span> | <span class="t">to refer to them back, you'll understand all the mechanisms that you need to know to push</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1157" target="_blank">00:19:17.560</a></span> | <span class="t">data through a neural network and then to push it through a criterion or a loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1162" target="_blank">00:19:22.680</a></span> | <span class="t">and then to pull those gradients back in order to make a gradient update to your model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1167" target="_blank">00:19:27.040</a></span> | <span class="t">So these are really the APIs, the levers that you need to know to kind of drive your neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1172" target="_blank">00:19:32.240</a></span> | <span class="t">network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1173" target="_blank">00:19:33.240</a></span> | <span class="t">And, of course, we have a CUDA back end for NN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1177" target="_blank">00:19:37.400</a></span> | <span class="t">So in the same way that you'll just call CUDA on some data, you can call CUDA on a container.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1182" target="_blank">00:19:42.600</a></span> | <span class="t">And that will move the whole model onto the GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1185" target="_blank">00:19:45.400</a></span> | <span class="t">And then anything that you do with that model will occur on the GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1188" target="_blank">00:19:48.520</a></span> | <span class="t">So it's kind of a one-liner to start training models on a graphics processor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1195" target="_blank">00:19:55.120</a></span> | <span class="t">So for doing feedforward neural networks, NN is pretty great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1198" target="_blank">00:19:58.960</a></span> | <span class="t">But for starting to try weirder architectures, like Richard Socher yesterday mentioned, a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1205" target="_blank">00:20:05.280</a></span> | <span class="t">pretty complicated NLP model that starts with glove vectors, which are kind of like shallow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1210" target="_blank">00:20:10.040</a></span> | <span class="t">neural networks and then a recursive neural network and then a tension mechanism and all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1214" target="_blank">00:20:14.000</a></span> | <span class="t">these things were interacting in strange ways, that's actually pretty hard to specify in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1218" target="_blank">00:20:18.320</a></span> | <span class="t">NN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1219" target="_blank">00:20:19.560</a></span> | <span class="t">At Twitter, we have a package called Torch Autograd, which makes these kinds of gluing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1224" target="_blank">00:20:24.120</a></span> | <span class="t">different model pieces together really easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1226" target="_blank">00:20:26.840</a></span> | <span class="t">And, in fact, the pieces can be as small as addition, division, multiplication, and subtraction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1232" target="_blank">00:20:32.760</a></span> | <span class="t">So you can glue together any size piece of computation and still get a correct model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1236" target="_blank">00:20:36.960</a></span> | <span class="t">out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1237" target="_blank">00:20:37.960</a></span> | <span class="t">And we'll talk about that in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1240" target="_blank">00:20:40.320</a></span> | <span class="t">The Optin package is what you need in order to train models with stochastic gradient descent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1245" target="_blank">00:20:45.340</a></span> | <span class="t">or Autograd or Autodelta, whatever your optimizer is that you favor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1250" target="_blank">00:20:50.520</a></span> | <span class="t">The API is pretty straightforward, but maybe a little bit different for people kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1255" target="_blank">00:20:55.800</a></span> | <span class="t">coming from the Python world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1257" target="_blank">00:20:57.080</a></span> | <span class="t">It's got a bit of a functional approach, where it will actually -- you'll pass a function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1262" target="_blank">00:21:02.880</a></span> | <span class="t">to Optin that will evaluate your neural network and pass back the gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1268" target="_blank">00:21:08.480</a></span> | <span class="t">So that's just something to be aware of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1269" target="_blank">00:21:09.520</a></span> | <span class="t">It's a little bit of a different style.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1272" target="_blank">00:21:12.160</a></span> | <span class="t">Another gotcha with Optin that you might run into and you'll see in some of the notebooks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1278" target="_blank">00:21:18.760</a></span> | <span class="t">that are online is your parameters should be linear in memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1283" target="_blank">00:21:23.040</a></span> | <span class="t">So if you want to optimize two neural networks that are interacting in some way, you actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1287" target="_blank">00:21:27.480</a></span> | <span class="t">need to first bring their parameters together into one tensor and then pass that to Optin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1291" target="_blank">00:21:31.760</a></span> | <span class="t">It's just something to be aware of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1295" target="_blank">00:21:35.120</a></span> | <span class="t">So I want to talk for the rest of the talk about Torch Autograd, but also about some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1300" target="_blank">00:21:40.600</a></span> | <span class="t">of the ideas that are behind Torch Autograd and how those link all the deep learning libraries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1304" target="_blank">00:21:44.980</a></span> | <span class="t">that you possibly could choose.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1307" target="_blank">00:21:47.760</a></span> | <span class="t">So first I want to take a step back and say that -- just appreciate the wonderful stable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1313" target="_blank">00:21:53.040</a></span> | <span class="t">abstractions that we have in scientific computing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1316" target="_blank">00:21:56.560</a></span> | <span class="t">So Fortran, you know, back in '57 -- I don't think anybody uses Fortran '57, but people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1321" target="_blank">00:22:01.400</a></span> | <span class="t">might actually still use Fortran '90.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1323" target="_blank">00:22:03.400</a></span> | <span class="t">The idea of an array didn't exist on a computer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1329" target="_blank">00:22:09.160</a></span> | <span class="t">And it really took some pretty crazy thinking, I think, to build a system that made array</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1333" target="_blank">00:22:13.200</a></span> | <span class="t">something we take for granted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1335" target="_blank">00:22:15.920</a></span> | <span class="t">Same with linear algebra.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1337" target="_blank">00:22:17.520</a></span> | <span class="t">Over about a 20-year period, starting in the late '70s, people decided, oh, maybe we should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1342" target="_blank">00:22:22.280</a></span> | <span class="t">think about linear algebra in a systematic way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1344" target="_blank">00:22:24.880</a></span> | <span class="t">And now we don't really worry about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1346" target="_blank">00:22:26.320</a></span> | <span class="t">If you want to multiply two matrices, that used to be a PhD's worth of work to do that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1351" target="_blank">00:22:31.800</a></span> | <span class="t">at scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1352" target="_blank">00:22:32.840</a></span> | <span class="t">And now we just -- we don't even actually import BLAST.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1356" target="_blank">00:22:36.320</a></span> | <span class="t">There's so many wrappers of BLAST that we don't even think about this anymore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1359" target="_blank">00:22:39.360</a></span> | <span class="t">So this is another abstraction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1360" target="_blank">00:22:40.560</a></span> | <span class="t">And also the idea that we should have all of the routines that we would possibly want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1364" target="_blank">00:22:44.400</a></span> | <span class="t">to call in one place available that we don't have to write, that was kind of invented,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1369" target="_blank">00:22:49.520</a></span> | <span class="t">I would say, by MATLAB in the mid '80s and then really popularized in the open source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1374" target="_blank">00:22:54.480</a></span> | <span class="t">community by NumPy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1376" target="_blank">00:22:56.160</a></span> | <span class="t">And we should take them for granted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1377" target="_blank">00:22:57.960</a></span> | <span class="t">We should totally forget about them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1380" target="_blank">00:23:00.160</a></span> | <span class="t">Because they make us faster, they make us better for us to assume these things will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1383" target="_blank">00:23:03.400</a></span> | <span class="t">work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1384" target="_blank">00:23:04.920</a></span> | <span class="t">So machine learning has other abstractions besides these computational ones that we take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1389" target="_blank">00:23:09.480</a></span> | <span class="t">for granted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1391" target="_blank">00:23:11.640</a></span> | <span class="t">All gradient-based optimization, that includes neural nets as a subset, relies on automatic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1397" target="_blank">00:23:17.800</a></span> | <span class="t">differentiation to calculate those gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1402" target="_blank">00:23:22.520</a></span> | <span class="t">And I like this definition from Barak Perlmutter, automatic differentiation mechanically calculates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1407" target="_blank">00:23:27.680</a></span> | <span class="t">derivatives as functions expressed as computer programs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1411" target="_blank">00:23:31.400</a></span> | <span class="t">So it doesn't derive things I write on a piece of paper with a pencil.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1414" target="_blank">00:23:34.760</a></span> | <span class="t">It derives computer programs at machine precision and with complexity guarantees.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1420" target="_blank">00:23:40.360</a></span> | <span class="t">Those last two clauses differentiate it from finite differences where you take the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1424" target="_blank">00:23:44.680</a></span> | <span class="t">to a program, you perturb it slightly, and you measure the gradient that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1427" target="_blank">00:23:47.920</a></span> | <span class="t">That's a very bad way to measure gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1431" target="_blank">00:23:51.520</a></span> | <span class="t">It's numerically very unstable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1432" target="_blank">00:23:52.680</a></span> | <span class="t">And it's not symbolic differentiation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1434" target="_blank">00:23:54.760</a></span> | <span class="t">So it's not writing down the symbolic expression of a neural network, putting it in Mathematica</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1438" target="_blank">00:23:58.720</a></span> | <span class="t">or Maple, and then asking for the derivative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1442" target="_blank">00:24:02.320</a></span> | <span class="t">Because your expression might go from this to this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1445" target="_blank">00:24:05.480</a></span> | <span class="t">So you get expression swell when you do naive symbolic differentiation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1448" target="_blank">00:24:08.920</a></span> | <span class="t">And you don't get that with automatic differentiation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1452" target="_blank">00:24:12.880</a></span> | <span class="t">So automatic differentiation, I would say, is the abstraction for gradient-based machine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1459" target="_blank">00:24:19.200</a></span> | <span class="t">learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1461" target="_blank">00:24:21.140</a></span> | <span class="t">It's been rediscovered several times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1463" target="_blank">00:24:23.680</a></span> | <span class="t">There's a review by Woodrow and Lehr.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1466" target="_blank">00:24:26.560</a></span> | <span class="t">I think the first implementation where it actually operates on a computer program was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1472" target="_blank">00:24:32.040</a></span> | <span class="t">by Bert Spielpetting in 1980, although it has been described back in 1964 by Wengert.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1481" target="_blank">00:24:41.240</a></span> | <span class="t">In neural networks, RumbleHeart is the one that I suppose popularized it as backpropagation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1486" target="_blank">00:24:46.760</a></span> | <span class="t">although backpropagation is a special case of autodiff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1490" target="_blank">00:24:50.680</a></span> | <span class="t">This I think is important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1491" target="_blank">00:24:51.680</a></span> | <span class="t">In nuclear science and computational fluid dynamics and in weather modeling, these people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1497" target="_blank">00:24:57.080</a></span> | <span class="t">have been using autodiff for years, decades.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1499" target="_blank">00:24:59.760</a></span> | <span class="t">And their tools in many ways are much more sophisticated than we have in machine learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1503" target="_blank">00:25:03.600</a></span> | <span class="t">There's a lot of ideas that we have yet to import from people that model the weather</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1509" target="_blank">00:25:09.000</a></span> | <span class="t">that would really benefit our ability to train larger and larger models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1514" target="_blank">00:25:14.480</a></span> | <span class="t">And I would clarify that our abstraction in machine learning is actually reverse mode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1519" target="_blank">00:25:19.160</a></span> | <span class="t">automatic differentiation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1521" target="_blank">00:25:21.000</a></span> | <span class="t">There's two different types, two extremes I should say, forward mode and reverse mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1525" target="_blank">00:25:25.560</a></span> | <span class="t">You never hear about forward mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1527" target="_blank">00:25:27.040</a></span> | <span class="t">And you never hear about forward mode in machine learning because it's a very bad idea to try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1530" target="_blank">00:25:30.840</a></span> | <span class="t">forward mode in machine learning, and I'll show you why.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1533" target="_blank">00:25:33.480</a></span> | <span class="t">So here is a cat picture from the internet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1537" target="_blank">00:25:37.720</a></span> | <span class="t">And my job at my job is to decide that that is in fact a cat picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1541" target="_blank">00:25:41.680</a></span> | <span class="t">This is actually something that we do do at Twitter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1545" target="_blank">00:25:45.640</a></span> | <span class="t">What I am doing is passing this cat through successive layers of transformations and eventually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1550" target="_blank">00:25:50.400</a></span> | <span class="t">producing a probability over classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1552" target="_blank">00:25:52.640</a></span> | <span class="t">I'm getting it wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1553" target="_blank">00:25:53.680</a></span> | <span class="t">My classifier thinks it's a dog, so I'd like to train my neural net to think it's a cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1558" target="_blank">00:25:58.600</a></span> | <span class="t">So I have a loss, a gradient of my loss, and I have it with respect to my parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1565" target="_blank">00:26:05.040</a></span> | <span class="t">And this is my gradient that will let me update my parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1568" target="_blank">00:26:08.560</a></span> | <span class="t">And it is composed of multiple pieces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1571" target="_blank">00:26:11.000</a></span> | <span class="t">And using the chain rule, I know that I can fold this together to actually compute the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1574" target="_blank">00:26:14.580</a></span> | <span class="t">loss I want, which is the gradient of the loss with respect to the parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1578" target="_blank">00:26:18.160</a></span> | <span class="t">The issue is I can do it either left to right or right to left.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1581" target="_blank">00:26:21.920</a></span> | <span class="t">So going from left to right looks like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1585" target="_blank">00:26:25.120</a></span> | <span class="t">Whoops, that was very fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1587" target="_blank">00:26:27.920</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1588" target="_blank">00:26:28.920</a></span> | <span class="t">I'll do two big matrix-matrix multiplies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1591" target="_blank">00:26:31.680</a></span> | <span class="t">So this is bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1593" target="_blank">00:26:33.280</a></span> | <span class="t">This is not good because we have these huge matrix-matrix products that we're keeping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1596" target="_blank">00:26:36.960</a></span> | <span class="t">around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1598" target="_blank">00:26:38.040</a></span> | <span class="t">It's actually worse than this, and I'll show you in another view of forward mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1602" target="_blank">00:26:42.420</a></span> | <span class="t">So say I have a computer program, so no longer a symbolic representation of a neural net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1606" target="_blank">00:26:46.340</a></span> | <span class="t">This is just some computer program.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1608" target="_blank">00:26:48.520</a></span> | <span class="t">And let's say I'd like to optimize A. A is the single parameter of my neural net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1612" target="_blank">00:26:52.660</a></span> | <span class="t">It's a very silly, trivial example, but I think it will help illustrate the point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1617" target="_blank">00:26:57.040</a></span> | <span class="t">So I can execute this program and look at all of the arithmetic operations that occur</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1621" target="_blank">00:27:01.900</a></span> | <span class="t">and build what's called a trace.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1624" target="_blank">00:27:04.220</a></span> | <span class="t">So I'll define, say, A is 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1627" target="_blank">00:27:07.020</a></span> | <span class="t">I'll define B as 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1629" target="_blank">00:27:09.200</a></span> | <span class="t">C is 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1630" target="_blank">00:27:10.240</a></span> | <span class="t">And then I'll start executing the code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1632" target="_blank">00:27:12.000</a></span> | <span class="t">I'm actually going to look if B is greater than C and choose a branch to operate on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1636" target="_blank">00:27:16.560</a></span> | <span class="t">but then ignore it in my trace.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1638" target="_blank">00:27:18.620</a></span> | <span class="t">So I've chosen one of those branches, which is the first, because B is greater than C.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1644" target="_blank">00:27:24.060</a></span> | <span class="t">And I have some output value D, and I'll return the output value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1648" target="_blank">00:27:28.940</a></span> | <span class="t">So this is a trace execution of my program given some inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1652" target="_blank">00:27:32.460</a></span> | <span class="t">So to calculate in forward mode the derivative of my output D with respect to A, I'll define</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1658" target="_blank">00:27:38.680</a></span> | <span class="t">A as 3 and then initialize a gradient of A with respect to itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1662" target="_blank">00:27:42.660</a></span> | <span class="t">And the idea is I eventually want the derivative of D with respect to A, and I'll build it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1667" target="_blank">00:27:47.160</a></span> | <span class="t">up sequentially.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1668" target="_blank">00:27:48.160</a></span> | <span class="t">DA, DA, and then I'll do DBDA, and then DCDA, and DDDA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1672" target="_blank">00:27:52.540</a></span> | <span class="t">So I'm moving from the left to the right, building up my gradient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1676" target="_blank">00:27:56.380</a></span> | <span class="t">I can't do much about the derivative of B with respect to A right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1681" target="_blank">00:28:01.620</a></span> | <span class="t">So I'll define C and the derivative of C with respect to A. And then I have my value D.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1687" target="_blank">00:28:07.460</a></span> | <span class="t">And then I can define my target value, which is the gradient of D with respect to A.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1691" target="_blank">00:28:11.860</a></span> | <span class="t">So if I wanted the gradient of D with respect to B-- so if I had a two-parameter neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1697" target="_blank">00:28:17.940</a></span> | <span class="t">network and I wanted to optimize both at once-- I would have to execute this whole thing again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1702" target="_blank">00:28:22.180</a></span> | <span class="t">and initialize this guy here as DBDB as 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1707" target="_blank">00:28:27.340</a></span> | <span class="t">So if you have a million parameters in your neural network, or tens of millions, you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1710" target="_blank">00:28:30.940</a></span> | <span class="t">to do a million evaluations of forward mode, or tens of millions of evaluations of forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1715" target="_blank">00:28:35.620</a></span> | <span class="t">mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1716" target="_blank">00:28:36.620</a></span> | <span class="t">It's a very bad idea to try forward mode automatic differentiation on neural network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1720" target="_blank">00:28:40.460</a></span> | <span class="t">and that's why you've probably never heard of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1722" target="_blank">00:28:42.980</a></span> | <span class="t">So now you can forget about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1726" target="_blank">00:28:46.420</a></span> | <span class="t">But the alternative is reverse mode, and that's starting from the right to the left.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1732" target="_blank">00:28:52.600</a></span> | <span class="t">So now I've got this nice matrix vector products, which are much smaller, and the complexity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1737" target="_blank">00:28:57.540</a></span> | <span class="t">is much better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1739" target="_blank">00:28:59.100</a></span> | <span class="t">And there's an interesting difference when I actually go to do this in computer code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1743" target="_blank">00:29:03.460</a></span> | <span class="t">And you'll see these words are closer together, and that's because for reverse mode, I actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1750" target="_blank">00:29:10.580</a></span> | <span class="t">have to evaluate the whole program before I can start deriving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1754" target="_blank">00:29:14.260</a></span> | <span class="t">Because I'm starting with the derivative of D with respect to D, and then decrementing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1758" target="_blank">00:29:18.640</a></span> | <span class="t">derivative of D with respect to C, with respect to B, with respect to A. So I'm going the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1762" target="_blank">00:29:22.820</a></span> | <span class="t">other way, but I have to have all the information first before I start that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1766" target="_blank">00:29:26.620</a></span> | <span class="t">So now I can initialize derivative of D with respect to D, and I can walk backwards and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1772" target="_blank">00:29:32.980</a></span> | <span class="t">return both the value and the gradient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1777" target="_blank">00:29:37.260</a></span> | <span class="t">What's really nice about this is you'll notice here, I actually have all the information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1780" target="_blank">00:29:40.580</a></span> | <span class="t">I need to calculate the derivatives of D with respect to these other parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1784" target="_blank">00:29:44.860</a></span> | <span class="t">So that's why we really like reverse mode autodiff, aka back propagation for neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1789" target="_blank">00:29:49.660</a></span> | <span class="t">nets, is if you have a million of these guys, you really want to be ready to compute them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1793" target="_blank">00:29:53.740</a></span> | <span class="t">all at once.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1794" target="_blank">00:29:54.740</a></span> | <span class="t">And doing these with matrices is a very efficient thing to do on the computer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1798" target="_blank">00:29:58.480</a></span> | <span class="t">So we've implemented this, trace-based automatic differentiation, in a package called autograd.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1803" target="_blank">00:30:03.920</a></span> | <span class="t">And this is the entirety of a neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1807" target="_blank">00:30:07.400</a></span> | <span class="t">So this is how you'd specify and train a neural network in autograd.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1811" target="_blank">00:30:11.660</a></span> | <span class="t">So I'll initialize my parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1813" target="_blank">00:30:13.400</a></span> | <span class="t">They'll just be some random numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1816" target="_blank">00:30:16.400</a></span> | <span class="t">And then here is my neural network function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1819" target="_blank">00:30:19.240</a></span> | <span class="t">I'm multiplying my image that I'm passing in by my weight matrix, and adding a bias,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1824" target="_blank">00:30:24.600</a></span> | <span class="t">non-linearity, doing it again, and then returning some probabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1829" target="_blank">00:30:29.400</a></span> | <span class="t">And I have a loss, which will take in an image and return a prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1834" target="_blank">00:30:34.000</a></span> | <span class="t">So just using this function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1835" target="_blank">00:30:35.800</a></span> | <span class="t">And then I'll just take the mean squared error, or the sum squared error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1841" target="_blank">00:30:41.060</a></span> | <span class="t">In order to get the gradients of this function, the derivative of the loss with respect to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1845" target="_blank">00:30:45.040</a></span> | <span class="t">these parameters, all I have to do is import this autograd package, and then call grad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1850" target="_blank">00:30:50.240</a></span> | <span class="t">on this function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1852" target="_blank">00:30:52.680</a></span> | <span class="t">This returns a new function that returns the gradients of my original function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1858" target="_blank">00:30:58.860</a></span> | <span class="t">So it's what's called a higher order function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1861" target="_blank">00:31:01.680</a></span> | <span class="t">Its inputs and its outputs are a function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1864" target="_blank">00:31:04.760</a></span> | <span class="t">So whenever you see that nabla, that upside down triangle, the grad triangle, this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1869" target="_blank">00:31:09.440</a></span> | <span class="t">the coding equivalent of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1873" target="_blank">00:31:13.280</a></span> | <span class="t">And then to train, we'll just call our D loss function on our parameters, our image, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1878" target="_blank">00:31:18.120</a></span> | <span class="t">our label, which I'm just pretending like you already have a system to get here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1881" target="_blank">00:31:21.720</a></span> | <span class="t">And we have our gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1883" target="_blank">00:31:23.080</a></span> | <span class="t">And then we're updating with stochastic gradient descent here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1886" target="_blank">00:31:26.920</a></span> | <span class="t">So it's a very thin-- it's really just this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1890" target="_blank">00:31:30.240</a></span> | <span class="t">This is the interface with which you talk with autograd.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1894" target="_blank">00:31:34.880</a></span> | <span class="t">So what's actually happening?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1896" target="_blank">00:31:36.620</a></span> | <span class="t">So here's my simple function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1898" target="_blank">00:31:38.980</a></span> | <span class="t">As we evaluate it, we're actually keeping track of everything that you're doing in order</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1903" target="_blank">00:31:43.240</a></span> | <span class="t">to be able to reverse it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1904" target="_blank">00:31:44.400</a></span> | <span class="t">So we're actually building that trace list that I described before and keeping track</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1908" target="_blank">00:31:48.000</a></span> | <span class="t">of it internally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1909" target="_blank">00:31:49.240</a></span> | <span class="t">So we'll start on line-- I guess that's 5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1911" target="_blank">00:31:51.680</a></span> | <span class="t">So we'll multiply some things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1914" target="_blank">00:31:54.680</a></span> | <span class="t">We'll keep track of the fact you multiplied and the inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1917" target="_blank">00:31:57.800</a></span> | <span class="t">We'll keep track of the addition and the inputs and also the output of addition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1921" target="_blank">00:32:01.640</a></span> | <span class="t">We'll keep track of inputs, outputs, and the function every time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1924" target="_blank">00:32:04.840</a></span> | <span class="t">And we'll kind of walk down this function and build your compute graph just in time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1929" target="_blank">00:32:09.400</a></span> | <span class="t">So as you're running your code, we're learning what you've done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1933" target="_blank">00:32:13.600</a></span> | <span class="t">And the way we track that-- and I won't go into details-- we actually replace every function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1937" target="_blank">00:32:17.160</a></span> | <span class="t">in Torch with like a spy function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1939" target="_blank">00:32:19.640</a></span> | <span class="t">So instead of just running Torch.sum, our spy function says, oh, I hear you're running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1944" target="_blank">00:32:24.400</a></span> | <span class="t">Torch.sum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1945" target="_blank">00:32:25.560</a></span> | <span class="t">Let me remember the parameters you gave me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1947" target="_blank">00:32:27.860</a></span> | <span class="t">Let me run sum on those parameters, remember the output, and then return it like nothing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1951" target="_blank">00:32:31.800</a></span> | <span class="t">happened.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1952" target="_blank">00:32:32.800</a></span> | <span class="t">But internally, we're remembering all those things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1957" target="_blank">00:32:37.080</a></span> | <span class="t">And the way we do this to actually compute the gradients is we're walking back this list</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1961" target="_blank">00:32:41.140</a></span> | <span class="t">like I described before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1962" target="_blank">00:32:42.960</a></span> | <span class="t">And every time we get to a point where we need to calculate a partial derivative, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1966" target="_blank">00:32:46.360</a></span> | <span class="t">look it up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1967" target="_blank">00:32:47.360</a></span> | <span class="t">And we've written all of the partial derivatives for Torch functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1972" target="_blank">00:32:52.360</a></span> | <span class="t">And really, every neural network library is going to do this at some level of granularity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1977" target="_blank">00:32:57.640</a></span> | <span class="t">So let me walk you through another couple examples just to show you what it could do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1981" target="_blank">00:33:01.500</a></span> | <span class="t">So this is kind of a pretty vanilla one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1984" target="_blank">00:33:04.380</a></span> | <span class="t">We can add and multiply scalars and get the correct gradient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1989" target="_blank">00:33:09.280</a></span> | <span class="t">This is where things get a little bit more interesting if there's an if statement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1992" target="_blank">00:33:12.580</a></span> | <span class="t">So this control flow can be a little bit difficult or awkward in a lot of existing deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1997" target="_blank">00:33:17.040</a></span> | <span class="t">libraries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=1999" target="_blank">00:33:19.160</a></span> | <span class="t">Because we just listen to what arithmetic functions get run, we ignore control flow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2004" target="_blank">00:33:24.400</a></span> | <span class="t">So we just go right through this stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2006" target="_blank">00:33:26.720</a></span> | <span class="t">So we can get the correct gradient even with if statements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2011" target="_blank">00:33:31.560</a></span> | <span class="t">We actually care about tensors when we're doing optimization or machine learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2016" target="_blank">00:33:36.440</a></span> | <span class="t">So everything I've shown you that works with scalars also works with tensors just as easily.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2021" target="_blank">00:33:41.240</a></span> | <span class="t">This is in the notebook that is on the GitHub repository if you want to play with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2026" target="_blank">00:33:46.080</a></span> | <span class="t">This is where things get a little bit interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2028" target="_blank">00:33:48.200</a></span> | <span class="t">For loops also work just fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2029" target="_blank">00:33:49.680</a></span> | <span class="t">And not just for loops that have a fixed length, which is something that is perhaps easy to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2033" target="_blank">00:33:53.120</a></span> | <span class="t">unroll.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2034" target="_blank">00:33:54.120</a></span> | <span class="t">But for loops whose duration can depend on data you just computed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2038" target="_blank">00:33:58.820</a></span> | <span class="t">Or while loops whose stopping condition can depend on a computation that occurs in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2042" target="_blank">00:34:02.960</a></span> | <span class="t">while loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2043" target="_blank">00:34:03.960</a></span> | <span class="t">We don't really care.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2044" target="_blank">00:34:04.960</a></span> | <span class="t">We're building your graph dynamically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2046" target="_blank">00:34:06.560</a></span> | <span class="t">And when it's done, when you've returned some value, we'll calculate the derivatives of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2050" target="_blank">00:34:10.240</a></span> | <span class="t">the graph that we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2052" target="_blank">00:34:12.880</a></span> | <span class="t">You can turn any for loop into a recursive function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2055" target="_blank">00:34:15.780</a></span> | <span class="t">This is kind of wacky.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2056" target="_blank">00:34:16.780</a></span> | <span class="t">I don't know how you would actually use this in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2059" target="_blank">00:34:19.440</a></span> | <span class="t">But you can cook up a lot of crazy things you might try with Autograd and they just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2063" target="_blank">00:34:23.000</a></span> | <span class="t">work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2064" target="_blank">00:34:24.000</a></span> | <span class="t">So here we have a function f.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2065" target="_blank">00:34:25.700</a></span> | <span class="t">If b is at some stopping condition, we'll return a.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2068" target="_blank">00:34:28.280</a></span> | <span class="t">Otherwise we'll call f.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2070" target="_blank">00:34:30.360</a></span> | <span class="t">And we're going to differentiate this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2072" target="_blank">00:34:32.800</a></span> | <span class="t">So we're going to differentiate a fully recursive function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2076" target="_blank">00:34:36.760</a></span> | <span class="t">And it works just fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2080" target="_blank">00:34:40.640</a></span> | <span class="t">Another aspect which is coming up more and more as papers are coming out that basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2084" target="_blank">00:34:44.780</a></span> | <span class="t">disrespect the sanctity of the partial, you know, of the derivative of the gradient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2089" target="_blank">00:34:49.800</a></span> | <span class="t">People are computing synthetic gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2092" target="_blank">00:34:52.080</a></span> | <span class="t">They're adding, they're clipping to gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2095" target="_blank">00:34:55.340</a></span> | <span class="t">People are messing with kind of the internals of back propagation or of autodiff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2100" target="_blank">00:35:00.720</a></span> | <span class="t">It's actually pretty easy to start to engage with in Autograd.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2104" target="_blank">00:35:04.840</a></span> | <span class="t">So say I'm going to sum the floor of a to the third power.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2109" target="_blank">00:35:09.920</a></span> | <span class="t">So the floor operation is piecewise constant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2112" target="_blank">00:35:12.200</a></span> | <span class="t">So the derivative is zero almost everywhere except for where it's undefined.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2116" target="_blank">00:35:16.440</a></span> | <span class="t">Why would I want to do this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2118" target="_blank">00:35:18.480</a></span> | <span class="t">For instance, if you wanted to build a differentiable JPEG encoder or differentiable MPEG encoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2123" target="_blank">00:35:23.700</a></span> | <span class="t">in compression algorithms like that, there's often a quantization step that will floor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2128" target="_blank">00:35:28.880</a></span> | <span class="t">around or truncate numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2131" target="_blank">00:35:31.280</a></span> | <span class="t">And if you wanted to differentiate through that to build like a neural JPEG algorithm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2134" target="_blank">00:35:34.520</a></span> | <span class="t">or something, you need to pass gradients through something that ordinarily does not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2138" target="_blank">00:35:38.400</a></span> | <span class="t">And so if we look at what the gradient is, it's zero everywhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2142" target="_blank">00:35:42.040</a></span> | <span class="t">I won't go into the details, but you can ask Autograd to use your own gradient for anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2146" target="_blank">00:35:46.920</a></span> | <span class="t">So if you have a new module that you want to define, and either you've written high-performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2150" target="_blank">00:35:50.660</a></span> | <span class="t">code for it and you want to use it, or you want to redefine or overwrite the gradients</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2155" target="_blank">00:35:55.880</a></span> | <span class="t">that we have, there's a pretty easy mechanism for doing that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2159" target="_blank">00:35:59.360</a></span> | <span class="t">And then when you call your special.floor, you can propagate gradients through it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2163" target="_blank">00:36:03.080</a></span> | <span class="t">And here I was just saying basically ignore the gradient of floor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2166" target="_blank">00:36:06.260</a></span> | <span class="t">So this is a toy example, but there are real places where you have a non-differentiable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2171" target="_blank">00:36:11.660</a></span> | <span class="t">bottleneck inside of your compute graph, and you want to either hop over it or find some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2175" target="_blank">00:36:15.820</a></span> | <span class="t">approximation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2177" target="_blank">00:36:17.200</a></span> | <span class="t">And Autograd has a mechanism for very easily plugging those types of things in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2182" target="_blank">00:36:22.280</a></span> | <span class="t">So that's a bit of what Autograd is and what it can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2185" target="_blank">00:36:25.940</a></span> | <span class="t">And I want to turn our attention to how Autograd relates to other deep learning libraries and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2191" target="_blank">00:36:31.140</a></span> | <span class="t">maybe how they're common and how they're similar and how they're different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2198" target="_blank">00:36:38.140</a></span> | <span class="t">So one big difference that I found between different deep learning libraries is the level</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2204" target="_blank">00:36:44.420</a></span> | <span class="t">of granularity at which you are allowed to specify your neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2209" target="_blank">00:36:49.140</a></span> | <span class="t">So there's a lot of libraries where you say you get a convnet or you get a feedforward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2213" target="_blank">00:36:53.820</a></span> | <span class="t">neural network, and that's it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2215" target="_blank">00:36:55.660</a></span> | <span class="t">So the menu is two items long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2218" target="_blank">00:36:58.480</a></span> | <span class="t">And that's fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2219" target="_blank">00:36:59.480</a></span> | <span class="t">But I think Andre really hit it on the head where if you want to solve a problem, don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2222" target="_blank">00:37:02.340</a></span> | <span class="t">be a hero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2223" target="_blank">00:37:03.340</a></span> | <span class="t">Use somebody else's network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2224" target="_blank">00:37:04.340</a></span> | <span class="t">So maybe this is VGG that you've downloaded from the model zoo or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2229" target="_blank">00:37:09.060</a></span> | <span class="t">So this is the don't be a hero regime on the left.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2231" target="_blank">00:37:11.940</a></span> | <span class="t">In the middle, there's a lot of really convenient neural net-specific libraries like TorchNN</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2237" target="_blank">00:37:17.900</a></span> | <span class="t">and Keras and Lasagna.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2239" target="_blank">00:37:19.900</a></span> | <span class="t">And you get to put together big layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2242" target="_blank">00:37:22.760</a></span> | <span class="t">And you don't really get to see what's inside those layers, but you get to click together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2245" target="_blank">00:37:25.900</a></span> | <span class="t">linear layers or convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2247" target="_blank">00:37:27.940</a></span> | <span class="t">And usually that's kind of what you want to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2250" target="_blank">00:37:30.760</a></span> | <span class="t">And on the far end of the spectrum, the things you can click together are the numeric functions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2257" target="_blank">00:37:37.000</a></span> | <span class="t">in your kind of host scientific computing library, right, like add, multiply, subtract.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2262" target="_blank">00:37:42.740</a></span> | <span class="t">And these are features of projects like Autograd and Theano and TensorFlow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2268" target="_blank">00:37:48.700</a></span> | <span class="t">And the reason why these boundaries are made is because the developers have chosen to give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2272" target="_blank">00:37:52.800</a></span> | <span class="t">you partial derivatives at these interfaces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2276" target="_blank">00:37:56.240</a></span> | <span class="t">So this is how they've defined their APIs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2278" target="_blank">00:37:58.720</a></span> | <span class="t">These are the interfaces across which you as a user cannot pass.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2282" target="_blank">00:38:02.880</a></span> | <span class="t">If you want a new one of these modules for the type on the left or the type in the middle,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2289" target="_blank">00:38:09.820</a></span> | <span class="t">you have to go in and build a whole new model and actually implement the partial derivatives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2295" target="_blank">00:38:15.540</a></span> | <span class="t">But with the types of libraries on the right, you can build your own modules by composing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2302" target="_blank">00:38:22.100</a></span> | <span class="t">primitive operations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2303" target="_blank">00:38:23.740</a></span> | <span class="t">So that's one difference that you can find.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2306" target="_blank">00:38:26.700</a></span> | <span class="t">In practice, how these things are implemented under the hood usually means this is the totally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2312" target="_blank">00:38:32.860</a></span> | <span class="t">shrink-wrapped stuff and maybe they implemented this whole thing by hand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2316" target="_blank">00:38:36.740</a></span> | <span class="t">Usually these guys in the middle are wrappers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2319" target="_blank">00:38:39.260</a></span> | <span class="t">They're wrapping some other library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2321" target="_blank">00:38:41.260</a></span> | <span class="t">And the guys on the right are usually actually implementing automatic differentiation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2325" target="_blank">00:38:45.340</a></span> | <span class="t">So Autograd and Theano and TensorFlow all implement autodiff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2329" target="_blank">00:38:49.560</a></span> | <span class="t">And the guys in the middle are taking advantage of that to make more convenient wrappers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2335" target="_blank">00:38:55.500</a></span> | <span class="t">So another aspect that's different is how these graphs are built.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2339" target="_blank">00:38:59.140</a></span> | <span class="t">So I'll remind you, in Autograd, we build these things just in time by listening to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2343" target="_blank">00:39:03.500</a></span> | <span class="t">what you're doing and recording it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2346" target="_blank">00:39:06.020</a></span> | <span class="t">But that's not how all neural network libraries are built.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2349" target="_blank">00:39:09.340</a></span> | <span class="t">And this is an axis along which I think that they are differentiated meaningfully.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2353" target="_blank">00:39:13.900</a></span> | <span class="t">So there's a lot of libraries that build these graphs explicitly, where you say, I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2358" target="_blank">00:39:18.260</a></span> | <span class="t">to click this Lego block into this Lego block, where I'm going to give you this YAML specification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2362" target="_blank">00:39:22.100</a></span> | <span class="t">file.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2363" target="_blank">00:39:23.820</a></span> | <span class="t">The graph is totally static and you really have no opportunity for compiler optimizations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2369" target="_blank">00:39:29.060</a></span> | <span class="t">there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2370" target="_blank">00:39:30.060</a></span> | <span class="t">And then there are the just-in-time libraries, so Autograd and Chainer is another one, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2375" target="_blank">00:39:35.180</a></span> | <span class="t">you get any graph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2376" target="_blank">00:39:36.620</a></span> | <span class="t">The graph can be anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2377" target="_blank">00:39:37.620</a></span> | <span class="t">It can change from sample to sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2380" target="_blank">00:39:40.020</a></span> | <span class="t">The length of the graph can be determined by the compute that occurs in the graph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2384" target="_blank">00:39:44.280</a></span> | <span class="t">You have very little opportunity for compiler optimizations there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2387" target="_blank">00:39:47.220</a></span> | <span class="t">So speed can be an issue sometimes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2388" target="_blank">00:39:48.780</a></span> | <span class="t">And in the middle, there's ahead-of-time libraries like TensorFlow and Theano, where you construct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2393" target="_blank">00:39:53.140</a></span> | <span class="t">your graph using a domain-specific language, you hand it off to their runtime, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2397" target="_blank">00:39:57.580</a></span> | <span class="t">they can do crazy stuff to make it faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2399" target="_blank">00:39:59.980</a></span> | <span class="t">The problem with that is it can be awkward to work with -- I guess it got cut off -- it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2403" target="_blank">00:40:03.900</a></span> | <span class="t">can be awkward to work with control flow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2406" target="_blank">00:40:06.460</a></span> | <span class="t">And I think there's a reason why it can be awkward to work with control flow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2410" target="_blank">00:40:10.420</a></span> | <span class="t">And it's because of the types of graphs that these libraries are actually manipulating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2415" target="_blank">00:40:15.100</a></span> | <span class="t">So we say compute graph a lot, we say data flow graph a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2418" target="_blank">00:40:18.780</a></span> | <span class="t">Data flow graph has a pretty restricted meaning, and it means that the nodes in your graph</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2425" target="_blank">00:40:25.940</a></span> | <span class="t">do computation and the edges are data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2428" target="_blank">00:40:28.580</a></span> | <span class="t">And there's no room for control flow in a graph that is a data flow graph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2432" target="_blank">00:40:32.740</a></span> | <span class="t">So static data flow is the type of graph that NNNCafe use, because all the ops are the nodes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2438" target="_blank">00:40:38.740</a></span> | <span class="t">and the edges are just the data, and the graph can't change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2443" target="_blank">00:40:43.100</a></span> | <span class="t">Limited data flow, just-in-time compiled data flow like Autograd and Chainer has the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2447" target="_blank">00:40:47.100</a></span> | <span class="t">characteristics, but the graph can change from iteration to iteration, because we wait</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2450" target="_blank">00:40:50.540</a></span> | <span class="t">until you're done computing the forward pass to build the graph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2454" target="_blank">00:40:54.080</a></span> | <span class="t">In the middle, there's kind of a hybrid, and I don't know what to call that graph type.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2459" target="_blank">00:40:59.220</a></span> | <span class="t">The ops are nodes, the edges are data, but then there's special information that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2462" target="_blank">00:41:02.940</a></span> | <span class="t">runtime gets in order to expand control flow or for loops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2466" target="_blank">00:41:06.340</a></span> | <span class="t">So scan in Theano is an instance of this, where the Theano runtime has special information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2471" target="_blank">00:41:11.860</a></span> | <span class="t">that allows it to make scan work, but it's kind of, it's conspiring with the graph data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2477" target="_blank">00:41:17.220</a></span> | <span class="t">type to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2479" target="_blank">00:41:19.060</a></span> | <span class="t">There's actually another graph type that naturally expresses control flow and data flow together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2484" target="_blank">00:41:24.260</a></span> | <span class="t">that I haven't seen implemented in a deep learning library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2488" target="_blank">00:41:28.020</a></span> | <span class="t">It's called C of nodes from Cliff Clicks thesis in the mid-90s.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2492" target="_blank">00:41:32.940</a></span> | <span class="t">It seems like a really natural thing to try, and maybe that's something that comes up in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2496" target="_blank">00:41:36.740</a></span> | <span class="t">the future, but that's kind of a big question mark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2499" target="_blank">00:41:39.400</a></span> | <span class="t">Maybe one of you will try that out and see how well it works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2503" target="_blank">00:41:43.720</a></span> | <span class="t">So in practice, this level of granularity can sometimes slow us down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2510" target="_blank">00:41:50.880</a></span> | <span class="t">Having to work with addition and multiplication can be nice if you want to try crazy stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2516" target="_blank">00:41:56.560</a></span> | <span class="t">but if you know you want to make a convnet, why don't you just rush all the way over to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2519" target="_blank">00:41:59.920</a></span> | <span class="t">the left?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2520" target="_blank">00:42:00.920</a></span> | <span class="t">If you want to take, you know, inception and add another layer, you want to use the type</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2525" target="_blank">00:42:05.520</a></span> | <span class="t">in the middle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2527" target="_blank">00:42:07.000</a></span> | <span class="t">And Autograd allows you to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2529" target="_blank">00:42:09.160</a></span> | <span class="t">So I'll just kind of walk through writing a neural net three ways very quickly and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2533" target="_blank">00:42:13.280</a></span> | <span class="t">close for questions shortly thereafter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2536" target="_blank">00:42:16.400</a></span> | <span class="t">So using the fully granular approach, there's a lot of text on the screen, but the top half</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2540" target="_blank">00:42:20.800</a></span> | <span class="t">is basically let's instantiate our parameters the way that we want to, and then here, just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2545" target="_blank">00:42:25.560</a></span> | <span class="t">like I've showed you in previous slides, let's do a multiply and let's do an addition and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2549" target="_blank">00:42:29.560</a></span> | <span class="t">put it through nonlinearity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2550" target="_blank">00:42:30.560</a></span> | <span class="t">We're being very explicit, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2551" target="_blank">00:42:31.980</a></span> | <span class="t">So we're breaking all the abstraction boundaries and we're just using primitive operations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2556" target="_blank">00:42:36.380</a></span> | <span class="t">We can use the layer-based approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2557" target="_blank">00:42:37.900</a></span> | <span class="t">So in Autograd, we have a facility to turn all of the NN modules, of which there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2562" target="_blank">00:42:42.020</a></span> | <span class="t">a lot, maybe an exhaustive list for what you'd want to use for standard deep learning applications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2568" target="_blank">00:42:48.500</a></span> | <span class="t">You can turn them into functions and then just use them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2570" target="_blank">00:42:50.820</a></span> | <span class="t">So linear one on the linear parameters and your input and some activation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2575" target="_blank">00:42:55.480</a></span> | <span class="t">You can go through your neural network this way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2577" target="_blank">00:42:57.840</a></span> | <span class="t">So you can use a layer-based approach if you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2581" target="_blank">00:43:01.120</a></span> | <span class="t">And if you just want neural network, just a feedforward neural network, we've got a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2585" target="_blank">00:43:05.800</a></span> | <span class="t">couple of these kind of standard models just ready to go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2588" target="_blank">00:43:08.560</a></span> | <span class="t">So you can just say, give me a neural network, give me a Logsoft max and a loss, and let</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2593" target="_blank">00:43:13.280</a></span> | <span class="t">me glue these guys together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2595" target="_blank">00:43:15.160</a></span> | <span class="t">So you can do it any of those three ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2600" target="_blank">00:43:20.560</a></span> | <span class="t">Autograd at Twitter has had a pretty cool impact.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2603" target="_blank">00:43:23.880</a></span> | <span class="t">We use NN for a lot of stuff and we use Autograd as well, but being able to reach for Autograd</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2608" target="_blank">00:43:28.640</a></span> | <span class="t">to try something totally crazy and just knowing that you're going to get the right gradients</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2612" target="_blank">00:43:32.320</a></span> | <span class="t">has really accelerated the pace of high-risk, potentially high-payoff attempts that we make.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2617" target="_blank">00:43:37.520</a></span> | <span class="t">So one crazy thing you might want to try is experiment with loss functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2621" target="_blank">00:43:41.000</a></span> | <span class="t">So instead of, I have 100 image classes and I want to have my convolutional neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2627" target="_blank">00:43:47.560</a></span> | <span class="t">be good at classifying those 100 image classes, maybe you have a taxonomy of classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2632" target="_blank">00:43:52.480</a></span> | <span class="t">Maybe you have a vehicle and then a bus, a car, and a motorcycle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2636" target="_blank">00:43:56.600</a></span> | <span class="t">If you guess any one of those, you kind of want partial credit for vehicle, or if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2639" target="_blank">00:43:59.720</a></span> | <span class="t">guess motorcycle, you want partial credit for car.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2642" target="_blank">00:44:02.760</a></span> | <span class="t">So building that kind of a tree loss is actually really straightforward in Autograd, and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2646" target="_blank">00:44:06.680</a></span> | <span class="t">can do that in just one sitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2648" target="_blank">00:44:08.760</a></span> | <span class="t">But it might be more complicated to do that in other libraries where you have to crack</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2651" target="_blank">00:44:11.880</a></span> | <span class="t">open the abstraction barrier, write your own partial derivatives, glue it back together,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2656" target="_blank">00:44:16.320</a></span> | <span class="t">and then use that module that you've built.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2660" target="_blank">00:44:20.000</a></span> | <span class="t">We've trained models that are in production in Autograd.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2663" target="_blank">00:44:23.560</a></span> | <span class="t">So this is something that's battle-tested to a sense, and is running on a large amount</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2668" target="_blank">00:44:28.200</a></span> | <span class="t">of media at Twitter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2669" target="_blank">00:44:29.200</a></span> | <span class="t">In a sense, Autograd doesn't actually matter when you're running in production, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2673" target="_blank">00:44:33.560</a></span> | <span class="t">you have your function definition for your prediction of your neural network, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2678" target="_blank">00:44:38.040</a></span> | <span class="t">the gradient part just goes away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2680" target="_blank">00:44:40.120</a></span> | <span class="t">So all the fancy stuff where we place torch with our secret listener functions, all that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2684" target="_blank">00:44:44.160</a></span> | <span class="t">just goes away and you just have some numerical code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2686" target="_blank">00:44:46.800</a></span> | <span class="t">So there's actually no speed penalty at test time at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2689" target="_blank">00:44:49.960</a></span> | <span class="t">We have an optimized mode, which does a little bit of compiler stuff, still a work in progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2695" target="_blank">00:44:55.280</a></span> | <span class="t">But for the average model, it's as fast, sometimes faster than NN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2699" target="_blank">00:44:59.840</a></span> | <span class="t">And for really complicated stuff, if you wrote that by hand, it would probably be faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2704" target="_blank">00:45:04.400</a></span> | <span class="t">But the time to first model fit using Autograd is dramatically reduced, because you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2709" target="_blank">00:45:09.280</a></span> | <span class="t">have to worry about correctness.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2712" target="_blank">00:45:12.080</a></span> | <span class="t">So this is a big wall of text, but it's meant to put in your head some ideas of things from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2718" target="_blank">00:45:18.640</a></span> | <span class="t">automatic differentiation from that world that we don't have yet, that we really want,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2724" target="_blank">00:45:24.160</a></span> | <span class="t">to be able to train models faster and better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2727" target="_blank">00:45:27.000</a></span> | <span class="t">So the first is checkpointing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2728" target="_blank">00:45:28.760</a></span> | <span class="t">This is not checkpointing where you save your model every 10 iterations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2731" target="_blank">00:45:31.660</a></span> | <span class="t">This is checkpointing where, on your forward pass, in normal reverse mode automatic differentiation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2738" target="_blank">00:45:38.600</a></span> | <span class="t">you have to remember every single piece of computation you do, because you might need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2741" target="_blank">00:45:41.760</a></span> | <span class="t">it to calculate the derivatives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2743" target="_blank">00:45:43.640</a></span> | <span class="t">In checkpointing, you just delete them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2745" target="_blank">00:45:45.420</a></span> | <span class="t">You let them go away, because you think that some of those might actually be easier to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2749" target="_blank">00:45:49.200</a></span> | <span class="t">recompute than to store.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2751" target="_blank">00:45:51.380</a></span> | <span class="t">So for pointwise nonlinearities, for instance, it might be easier, once you've loaded your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2754" target="_blank">00:45:54.940</a></span> | <span class="t">data, just to recompute the ReLU, as opposed to saving the result of ReLU and loading that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2759" target="_blank">00:45:59.300</a></span> | <span class="t">back in again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2761" target="_blank">00:46:01.740</a></span> | <span class="t">Mixing forward and reverse mode is something that you can imagine being important for kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2766" target="_blank">00:46:06.760</a></span> | <span class="t">of complicated architectures, although I don't really know how much impact that would have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2770" target="_blank">00:46:10.420</a></span> | <span class="t">So in the chain rule, you can either go from left to right, or you could start in the middle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2773" target="_blank">00:46:13.720</a></span> | <span class="t">and go out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2774" target="_blank">00:46:14.720</a></span> | <span class="t">You can do all kinds of crazy stuff if you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2777" target="_blank">00:46:17.360</a></span> | <span class="t">And we really just do reverse mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2779" target="_blank">00:46:19.920</a></span> | <span class="t">For diamond-shaped graphs, where your computation explodes out and then comes back in, that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2785" target="_blank">00:46:25.500</a></span> | <span class="t">might be useful to start with forward mode and then finish with reverse mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2788" target="_blank">00:46:28.820</a></span> | <span class="t">Or in hourglass, you might want to start with reverse mode and end with forward mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2794" target="_blank">00:46:34.820</a></span> | <span class="t">Stencils are a generalization of convolutions that people use a lot in computer graphics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2801" target="_blank">00:46:41.220</a></span> | <span class="t">Basically calculating really efficient derivatives of image processing, just general image processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2806" target="_blank">00:46:46.520</a></span> | <span class="t">algorithms is under active investigation in the graphics world and in the computer vision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2811" target="_blank">00:46:51.560</a></span> | <span class="t">world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2812" target="_blank">00:46:52.560</a></span> | <span class="t">So these are two references that are kind of neat papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2815" target="_blank">00:46:55.980</a></span> | <span class="t">Source-to-source transformations is something that hasn't really made it-- it basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2819" target="_blank">00:46:59.840</a></span> | <span class="t">has kind of been dormant for about 10 or 15 years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2823" target="_blank">00:47:03.260</a></span> | <span class="t">So the gold standard used to be, you take a piece of code as text, and you output another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2828" target="_blank">00:47:08.060</a></span> | <span class="t">piece of code as text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2829" target="_blank">00:47:09.940</a></span> | <span class="t">What we're doing now in deep learning is we're always building runtimes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2833" target="_blank">00:47:13.460</a></span> | <span class="t">We're always building some domain-specific layer that depends on you actually running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2837" target="_blank">00:47:17.380</a></span> | <span class="t">code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2838" target="_blank">00:47:18.380</a></span> | <span class="t">It used to be that you would just read that text and kind of like a compiler, spit out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2842" target="_blank">00:47:22.380</a></span> | <span class="t">the gradient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2843" target="_blank">00:47:23.980</a></span> | <span class="t">This was the gold standard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2845" target="_blank">00:47:25.380</a></span> | <span class="t">It might not be now, but I think it's worth reinvestigating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2848" target="_blank">00:47:28.820</a></span> | <span class="t">And then higher-order gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2850" target="_blank">00:47:30.240</a></span> | <span class="t">So Hessian vector products and kind of Hessian-based optimization maybe doesn't always have full</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2856" target="_blank">00:47:36.140</a></span> | <span class="t">payoff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2857" target="_blank">00:47:37.140</a></span> | <span class="t">I actually don't recall hearing anything about this at this school so far, because it's very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2862" target="_blank">00:47:42.540</a></span> | <span class="t">expensive and difficult to do, expensive computationally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2866" target="_blank">00:47:46.580</a></span> | <span class="t">Hessian is just if you take the grad of f, it gives you the gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2868" target="_blank">00:47:48.860</a></span> | <span class="t">If you want the second derivative, so you take grad of grad of f.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2872" target="_blank">00:47:52.900</a></span> | <span class="t">So there's efficient ways to do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2875" target="_blank">00:47:55.060</a></span> | <span class="t">It's still kind of an open problem, but there are libraries out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2878" target="_blank">00:47:58.380</a></span> | <span class="t">The Python version of Autograd does this well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2880" target="_blank">00:48:00.540</a></span> | <span class="t">DiffSharp and Hype both also do this as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2883" target="_blank">00:48:03.960</a></span> | <span class="t">So to kind of close out, you should just try it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2886" target="_blank">00:48:06.980</a></span> | <span class="t">It's really easy to get it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2888" target="_blank">00:48:08.060</a></span> | <span class="t">If you have Anaconda, if you use Python, we've made it so that Lua is fully installable with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2894" target="_blank">00:48:14.740</a></span> | <span class="t">Anaconda.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2895" target="_blank">00:48:15.740</a></span> | <span class="t">So if you're already using it, it's very, very easy to get all of the tools that I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2900" target="_blank">00:48:20.020</a></span> | <span class="t">showed you today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2901" target="_blank">00:48:21.820</a></span> | <span class="t">And that's kind of the single line to interface with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2904" target="_blank">00:48:24.660</a></span> | <span class="t">And if you have any questions, you can find me on Twitter or email or GitHub, but I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2910" target="_blank">00:48:30.220</a></span> | <span class="t">happy to answer any questions that you have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2912" target="_blank">00:48:32.140</a></span> | <span class="t">[ Applause ]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2912" target="_blank">00:48:32.140</a></span> | <span class="t">>> We have plenty of time for questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2919" target="_blank">00:48:39.140</a></span> | <span class="t">>> Oh, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2924" target="_blank">00:48:44.140</a></span> | <span class="t">I have no idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2931" target="_blank">00:48:51.140</a></span> | <span class="t">>> Hi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2934" target="_blank">00:48:54.140</a></span> | <span class="t">Thanks for the great talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2943" target="_blank">00:49:03.140</a></span> | <span class="t">I was wondering what's the state of the data visualization facilities in Lua compared to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2955" target="_blank">00:49:15.140</a></span> | <span class="t">say, Python.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2956" target="_blank">00:49:16.500</a></span> | <span class="t">>> If I'm frank, it's not as good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2958" target="_blank">00:49:18.740</a></span> | <span class="t">Python has been at this for, you know, five, ten years, really actively building matplotlib</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2963" target="_blank">00:49:23.980</a></span> | <span class="t">and, you know, seaborn and all these other libraries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2967" target="_blank">00:49:27.540</a></span> | <span class="t">And in Lua, we're importing other people's work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2969" target="_blank">00:49:29.740</a></span> | <span class="t">So bokeh.js is really the best that I've seen so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2973" target="_blank">00:49:33.260</a></span> | <span class="t">And that's something you can use in the notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2975" target="_blank">00:49:35.100</a></span> | <span class="t">So you have the full suite of that particular library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2980" target="_blank">00:49:40.140</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2982" target="_blank">00:49:42.340</a></span> | <span class="t">>> Hi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2984" target="_blank">00:49:44.660</a></span> | <span class="t">Thanks for the talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2990" target="_blank">00:49:50.300</a></span> | <span class="t">Is it possible to convert a model train with Torch into a C model that's deployable in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2997" target="_blank">00:49:57.260</a></span> | <span class="t">like, you know, production?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2998" target="_blank">00:49:58.260</a></span> | <span class="t">>> Yeah, for sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=2999" target="_blank">00:49:59.820</a></span> | <span class="t">We just run Torch in production.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3001" target="_blank">00:50:01.540</a></span> | <span class="t">We use a Lua model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3002" target="_blank">00:50:02.540</a></span> | <span class="t">But you want to run it in C. So the whole layer of Torch that's actually doing the work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3009" target="_blank">00:50:09.040</a></span> | <span class="t">is in C. And calling Torch from C, I don't have a specific website I can point you to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3015" target="_blank">00:50:15.260</a></span> | <span class="t">But you can very easily call and execute a Lua script from C. It's like three or four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3020" target="_blank">00:50:20.100</a></span> | <span class="t">lines of code in C.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3021" target="_blank">00:50:21.100</a></span> | <span class="t">>> Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3022" target="_blank">00:50:22.100</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3023" target="_blank">00:50:23.100</a></span> | <span class="t">>> I'd like to follow up the question about C just now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3033" target="_blank">00:50:33.500</a></span> | <span class="t">Like, just, like, if I want to compile -- I mean, I want to have Torch into my C++ code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3039" target="_blank">00:50:39.140</a></span> | <span class="t">what kind of overhead do I see?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3040" target="_blank">00:50:40.140</a></span> | <span class="t">Do I see a lot of overhead?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3041" target="_blank">00:50:41.140</a></span> | <span class="t">Just now you mentioned you saw, like, I have a 10,000 line Lua just-in-time compiler that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3046" target="_blank">00:50:46.940</a></span> | <span class="t">I need to add in there; right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3049" target="_blank">00:50:49.660</a></span> | <span class="t">Or can I avoid that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3051" target="_blank">00:50:51.220</a></span> | <span class="t">Because, for example, I think about if I'm going to put Lua in an embedded system that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3055" target="_blank">00:50:55.220</a></span> | <span class="t">have limited amount of resource of anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3058" target="_blank">00:50:58.780</a></span> | <span class="t">>> During inference time -- sorry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3061" target="_blank">00:51:01.180</a></span> | <span class="t">During inference time, there's no appreciable overhead, if I'm understanding your question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3066" target="_blank">00:51:06.540</a></span> | <span class="t">right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3067" target="_blank">00:51:07.540</a></span> | <span class="t">So you are importing a Lua.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3069" target="_blank">00:51:09.980</a></span> | <span class="t">So in your C code, you're going to basically say, Lua, please run this Lua script.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3074" target="_blank">00:51:14.720</a></span> | <span class="t">And that's going to call out into other C code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3077" target="_blank">00:51:17.220</a></span> | <span class="t">So all this overhead I talked about with Autograd, that's training time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3081" target="_blank">00:51:21.520</a></span> | <span class="t">That doesn't exist at test time at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3083" target="_blank">00:51:23.820</a></span> | <span class="t">>> So during test time, but the thing is I still need to have Lua compiled into my C</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3088" target="_blank">00:51:28.460</a></span> | <span class="t">code; right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3089" target="_blank">00:51:29.460</a></span> | <span class="t">>> Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3090" target="_blank">00:51:30.460</a></span> | <span class="t">So this is something people have been doing for, like, 15, 20 years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3092" target="_blank">00:51:32.980</a></span> | <span class="t">It's pretty mature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3093" target="_blank">00:51:33.980</a></span> | <span class="t">So Lua is in, like, microwaves, for instance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3097" target="_blank">00:51:37.540</a></span> | <span class="t">People have done very embedded applications of Lua.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3101" target="_blank">00:51:41.220</a></span> | <span class="t">I think the binary for Lua is, like, I don't want to -- it's, like, kilobytes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3106" target="_blank">00:51:46.540</a></span> | <span class="t">That's very, very small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3107" target="_blank">00:51:47.540</a></span> | <span class="t">There's 10,000 lines of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3108" target="_blank">00:51:48.540</a></span> | <span class="t">So when it compiles down, it's small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3115" target="_blank">00:51:55.700</a></span> | <span class="t">So there's a question from the Twitters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3118" target="_blank">00:51:58.300</a></span> | <span class="t">It says, I'm using a combination of Keras and TensorFlow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3122" target="_blank">00:52:02.060</a></span> | <span class="t">Why should I use Torch or Autograd?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3126" target="_blank">00:52:06.260</a></span> | <span class="t">If you're happy, then, you know, that's great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3129" target="_blank">00:52:09.660</a></span> | <span class="t">I guess -- so people tend to reach for Torch when they would like to be able to reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3136" target="_blank">00:52:16.860</a></span> | <span class="t">very easily about performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3139" target="_blank">00:52:19.580</a></span> | <span class="t">The kind of -- the more of a compiler infrastructure that gets added to a deep learning environment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3144" target="_blank">00:52:24.980</a></span> | <span class="t">the harder it can be for the end user, right, away from the people that originally made</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3149" target="_blank">00:52:29.460</a></span> | <span class="t">the library, it can be harder for the end user to reason why is this slow, why is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3152" target="_blank">00:52:32.980</a></span> | <span class="t">not working.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3153" target="_blank">00:52:33.980</a></span> | <span class="t">You might eventually see some GitHub issue later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3156" target="_blank">00:52:36.480</a></span> | <span class="t">Why is my network slow in these conditions, and then it gets closed a year after you had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3160" target="_blank">00:52:40.140</a></span> | <span class="t">to have shipped your project.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3161" target="_blank">00:52:41.140</a></span> | <span class="t">I mean, these things can happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3162" target="_blank">00:52:42.520</a></span> | <span class="t">It's not the fault of anybody.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3163" target="_blank">00:52:43.520</a></span> | <span class="t">It's just that Torch was designed to basically be a thin layer over C code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3169" target="_blank">00:52:49.360</a></span> | <span class="t">So if that's something that you care about, Torch is a really good thing to work for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3172" target="_blank">00:52:52.460</a></span> | <span class="t">If Keras and TensorFlow is working great for you, then keep deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3175" target="_blank">00:52:55.660</a></span> | <span class="t">You know, that's awesome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3176" target="_blank">00:52:56.660</a></span> | <span class="t">So...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3177" target="_blank">00:52:57.660</a></span> | <span class="t">I'm trying to see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3178" target="_blank">00:52:58.660</a></span> | <span class="t">Maybe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3179" target="_blank">00:52:59.660</a></span> | <span class="t">It's hard to filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3194" target="_blank">00:53:14.440</a></span> | <span class="t">Where will the slides be posted?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3196" target="_blank">00:53:16.660</a></span> | <span class="t">It's not a deep learning question, but...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3200" target="_blank">00:53:20.580</a></span> | <span class="t">They will be posted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3201" target="_blank">00:53:21.580</a></span> | <span class="t">That's the answer to that question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3202" target="_blank">00:53:22.580</a></span> | <span class="t">>> I have a question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3206" target="_blank">00:53:26.220</a></span> | <span class="t">How do I access through...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3209" target="_blank">00:53:29.640</a></span> | <span class="t">So normally all the web services in production generally are in other...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3213" target="_blank">00:53:33.180</a></span> | <span class="t">In a fast-based application in Python or Java-based web services, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3218" target="_blank">00:53:38.620</a></span> | <span class="t">Or maybe in the cell phone through Android, which is also Java, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3223" target="_blank">00:53:43.340</a></span> | <span class="t">So how do you call these models which were trained in Torch?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3227" target="_blank">00:53:47.580</a></span> | <span class="t">How would you actually access those?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3228" target="_blank">00:53:48.580</a></span> | <span class="t">>> There's a couple different ways you can do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3231" target="_blank">00:53:51.460</a></span> | <span class="t">If you're using a feedforward neural network, writing the Java code to do the matrix multiplies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3238" target="_blank">00:53:58.460</a></span> | <span class="t">can be pretty straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3239" target="_blank">00:53:59.900</a></span> | <span class="t">We've actually done that before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3241" target="_blank">00:54:01.340</a></span> | <span class="t">Or it's just simpler to just write the deep learning code, load in the weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3244" target="_blank">00:54:04.620</a></span> | <span class="t">We'll serialize it however it needs to be loaded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3247" target="_blank">00:54:07.620</a></span> | <span class="t">That's one approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3248" target="_blank">00:54:08.620</a></span> | <span class="t">It's kind of hacking short-term.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3250" target="_blank">00:54:10.460</a></span> | <span class="t">At Twitter, we've engineered a system where we actually have Lua virtual machines running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3256" target="_blank">00:54:16.540</a></span> | <span class="t">inside of Java, and we talk over the JNI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3260" target="_blank">00:54:20.080</a></span> | <span class="t">So we have a more permanent solution for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3263" target="_blank">00:54:23.320</a></span> | <span class="t">But if you're using standard model architectures, you might try to serialize your weights and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3268" target="_blank">00:54:28.620</a></span> | <span class="t">then use the native deep learning library that exists to load up those weights and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3272" target="_blank">00:54:32.900</a></span> | <span class="t">run for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3273" target="_blank">00:54:33.900</a></span> | <span class="t">And with some debugging, I think that's a perfectly fair approach, if you have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3278" target="_blank">00:54:38.120</a></span> | <span class="t">split between testing and kind of deployment where you're constrained by language or environment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3283" target="_blank">00:54:43.660</a></span> | <span class="t">>> That's generally the thing that, you know...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3285" target="_blank">00:54:45.660</a></span> | <span class="t">I mean, you do basically just serialize your model and then try to read it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3291" target="_blank">00:54:51.120</a></span> | <span class="t">What about the latency, actually?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3292" target="_blank">00:54:52.360</a></span> | <span class="t">So related to this...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3294" target="_blank">00:54:54.300</a></span> | <span class="t">So when you serialize that hackish way, at least you can get that latency thing solved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3299" target="_blank">00:54:59.260</a></span> | <span class="t">out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3300" target="_blank">00:55:00.260</a></span> | <span class="t">But is there any plan, basically, to have interfaces available for other languages so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3304" target="_blank">00:55:04.900</a></span> | <span class="t">that you don't have to do this extra step of serializing and then loading it into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3312" target="_blank">00:55:12.060</a></span> | <span class="t">different language?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3313" target="_blank">00:55:13.060</a></span> | <span class="t">Because if you don't, like in your case, you were mentioning that in Twitter you have Lua</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3322" target="_blank">00:55:22.620</a></span> | <span class="t">available inside your Java JVM, access through the JVM using JNI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3328" target="_blank">00:55:28.780</a></span> | <span class="t">So what impact does it have on the latency for those models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3333" target="_blank">00:55:33.780</a></span> | <span class="t">>> And by latency, you mean time to ship the model, not the latency of how long it takes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3338" target="_blank">00:55:38.740</a></span> | <span class="t">to make a prediction?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3339" target="_blank">00:55:39.740</a></span> | <span class="t">>> Predictions, basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3341" target="_blank">00:55:41.420</a></span> | <span class="t">That's going to be very engineering dependent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3343" target="_blank">00:55:43.500</a></span> | <span class="t">So if you're calling Torch from C code, the latency is not appreciable over if you're just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3348" target="_blank">00:55:48.700</a></span> | <span class="t">running Lua code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3350" target="_blank">00:55:50.300</a></span> | <span class="t">And that can be extremely fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3352" target="_blank">00:55:52.940</a></span> | <span class="t">If you're going through some wrapper, like through the JNI or something like that, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3355" target="_blank">00:55:55.660</a></span> | <span class="t">will incur an overhead, and you should just try to pick the interfaces that reduce that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3360" target="_blank">00:56:00.940</a></span> | <span class="t">as much, even if you incur engineering overhead to do so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3364" target="_blank">00:56:04.380</a></span> | <span class="t">I don't know if that answers your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3366" target="_blank">00:56:06.740</a></span> | <span class="t">>> So do you have any numbers that basically you have seen in the past, you know, the latency</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3371" target="_blank">00:56:11.500</a></span> | <span class="t">numbers?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3372" target="_blank">00:56:12.500</a></span> | <span class="t">>> I'm a little bit distant from the service side, so I can't give you -- I just don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3376" target="_blank">00:56:16.060</a></span> | <span class="t">know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3377" target="_blank">00:56:17.940</a></span> | <span class="t">But generally, I think what I can say that's fair is we're constrained by machine learning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3384" target="_blank">00:56:24.380</a></span> | <span class="t">you know, model complexity latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3386" target="_blank">00:56:26.940</a></span> | <span class="t">We are not constrained by overhead of, like, figuring out how to actually get those predictions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3392" target="_blank">00:56:32.420</a></span> | <span class="t">like to an HTTP request, for instance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3394" target="_blank">00:56:34.500</a></span> | <span class="t">That's not constraining.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3395" target="_blank">00:56:35.500</a></span> | <span class="t">>> Yeah, like TensorFlow has TensorFlow serving, which is kind of sort of solving this problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3402" target="_blank">00:56:42.540</a></span> | <span class="t">>> Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3403" target="_blank">00:56:43.540</a></span> | <span class="t">>> Is there anything in line?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3404" target="_blank">00:56:44.540</a></span> | <span class="t">Do you know?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3405" target="_blank">00:56:45.540</a></span> | <span class="t">>> Not that I'm aware of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3407" target="_blank">00:56:47.100</a></span> | <span class="t">Again, the Torch community is not centralized, and so people could be working on a totally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3411" target="_blank">00:56:51.780</a></span> | <span class="t">awesome, you know, complement to the TensorFlow server, but I am not aware of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3419" target="_blank">00:56:59.820</a></span> | <span class="t">>> Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3420" target="_blank">00:57:00.820</a></span> | <span class="t">>> Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3421" target="_blank">00:57:01.820</a></span> | <span class="t">We are going to take a short break of 15 minutes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3425" target="_blank">00:57:05.780</a></span> | <span class="t">Let's thank Alex again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3426" target="_blank">00:57:06.780</a></span> | <span class="t">[ Applause ]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3427" target="_blank">00:57:07.780</a></span> | <span class="t">>> Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3428" target="_blank">00:57:08.780</a></span> | <span class="t">>> Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3429" target="_blank">00:57:09.780</a></span> | <span class="t">>> Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=L1sHcj3qDNc&t=3429" target="_blank">00:57:09.780</a></span> | <span class="t">[ Applause ]</span></div></div></body></html>