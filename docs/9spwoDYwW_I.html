<html><head><title>Lesson 7: Deep Learning 2019 - Resnets from scratch; U-net; Generative (adversarial) networks</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 7: Deep Learning 2019 - Resnets from scratch; U-net; Generative (adversarial) networks</h2><a href="https://www.youtube.com/watch?v=9spwoDYwW_I"><img src="https://i.ytimg.com/vi/9spwoDYwW_I/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=0">0:0</a> <Untitled Chapter 1><br><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=503">8:23</a> add a bit of random padding<br><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=661">11:1</a> start out creating a simple cnn<br><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1632">27:12</a> create your own variations of resnet blocks<br><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3403">56:43</a> create a generator learner<br><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4366">72:46</a> print out a sample after every epoch<br><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5117">85:17</a> using the pre-trained model<br><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6993">116:33</a> add skip connections<br><br><div style="text-align: left;"><a href="./9spwoDYwW_I.html">Whisper Transcript</a> | <a href="./transcript_9spwoDYwW_I.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Wellcome to lesson seven, the last lesson of part one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=8" target="_blank">00:00:08.760</a></span> | <span class="t">This will be a pretty intense lesson.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=13" target="_blank">00:00:13.440</a></span> | <span class="t">And so don't let that bother you, because partly what I want to do is to kind of give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=18" target="_blank">00:00:18.520</a></span> | <span class="t">you enough things to think about to keep you busy until part two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=24" target="_blank">00:00:24.200</a></span> | <span class="t">And so, in fact, some of the things we cover today, I'm not going to tell you about some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=28" target="_blank">00:00:28.720</a></span> | <span class="t">of the details, I'll just point out a few things where I'll say like, okay, that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=31" target="_blank">00:00:31.840</a></span> | <span class="t">not talking about yet, that we're not talking about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=34" target="_blank">00:00:34.360</a></span> | <span class="t">And so then come back in part two to get the details on some of these extra pieces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=40" target="_blank">00:00:40.280</a></span> | <span class="t">So today will be a lot of material.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=44" target="_blank">00:00:44.900</a></span> | <span class="t">Pretty quickly might require a few viewings to fully understand at all, a few experiments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=50" target="_blank">00:00:50.280</a></span> | <span class="t">and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=51" target="_blank">00:00:51.280</a></span> | <span class="t">And that's kind of intentional.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=52" target="_blank">00:00:52.280</a></span> | <span class="t">I'm going to give you stuff to keep you amused for a couple of months.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=59" target="_blank">00:00:59.520</a></span> | <span class="t">Wanted to start by showing some cool work done by a couple of students, Reshma and Npata01,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=67" target="_blank">00:01:07.520</a></span> | <span class="t">who have developed an Android and an iOS app.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=72" target="_blank">00:01:12.120</a></span> | <span class="t">And so check out Reshma's post on the forum about that, because they have a demonstration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=77" target="_blank">00:01:17.760</a></span> | <span class="t">of how to create both Android and iOS apps that are actually on the Play Store and on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=83" target="_blank">00:01:23.080</a></span> | <span class="t">the Apple App Store.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=85" target="_blank">00:01:25.760</a></span> | <span class="t">So that's pretty cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=87" target="_blank">00:01:27.480</a></span> | <span class="t">First ones I know of that are on the App Store that are using fast AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=92" target="_blank">00:01:32.000</a></span> | <span class="t">And let me also say a huge thank you to Reshma for all of the work she does, both for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=96" target="_blank">00:01:36.180</a></span> | <span class="t">fast AI community and the machine learning community, or generally, and also the women</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=101" target="_blank">00:01:41.000</a></span> | <span class="t">in machine learning community in particular.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=103" target="_blank">00:01:43.560</a></span> | <span class="t">She does a lot of fantastic work, including providing lots of fantastic documentation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=109" target="_blank">00:01:49.440</a></span> | <span class="t">and tutorials and community organizing and so many other things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=113" target="_blank">00:01:53.340</a></span> | <span class="t">So thank you, Reshma, and congrats on getting this app out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=124" target="_blank">00:02:04.200</a></span> | <span class="t">We have lots of Lesson 7 notebooks today, as you see, and we're going to start with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=129" target="_blank">00:02:09.120</a></span> | <span class="t">the one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=133" target="_blank">00:02:13.740</a></span> | <span class="t">So the first notebook we're going to look at is Lesson 7 ResNet MNIST.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=138" target="_blank">00:02:18.480</a></span> | <span class="t">And what I want to do is look at some of the stuff we started talking about last week around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=143" target="_blank">00:02:23.560</a></span> | <span class="t">convolutions and convolutional neural networks and start building on top of them to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=148" target="_blank">00:02:28.600</a></span> | <span class="t">a fairly modern deep learning architecture, largely from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=154" target="_blank">00:02:34.000</a></span> | <span class="t">When I say from scratch, I'm not going to re-implement things we already know how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=157" target="_blank">00:02:37.000</a></span> | <span class="t">implement but kind of use the pre-existing PyTorch bits of those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=162" target="_blank">00:02:42.640</a></span> | <span class="t">So we're going to use the MNIST dataset, which -- so urls.mnist has the whole MNIST dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=169" target="_blank">00:02:49.880</a></span> | <span class="t">Often we've done stuff with a subset of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=172" target="_blank">00:02:52.540</a></span> | <span class="t">So in there, there's a training folder and a testing folder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=177" target="_blank">00:02:57.440</a></span> | <span class="t">And as I read this in, I'm going to show some more details about pieces of the Datablocks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=182" target="_blank">00:03:02.000</a></span> | <span class="t">API so that you see how to kind of see what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=185" target="_blank">00:03:05.540</a></span> | <span class="t">Similarly with the Datablocks API, we've kind of said blah, blah, blah, blah, blah, and done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=189" target="_blank">00:03:09.600</a></span> | <span class="t">it all in one cell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=190" target="_blank">00:03:10.600</a></span> | <span class="t">But let's do them one cell at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=192" target="_blank">00:03:12.320</a></span> | <span class="t">So the first thing you say is what kind of item list do you have?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=196" target="_blank">00:03:16.640</a></span> | <span class="t">So in this case, it's an item list of images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=199" target="_blank">00:03:19.680</a></span> | <span class="t">And then where are you getting the list of file names from?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=202" target="_blank">00:03:22.520</a></span> | <span class="t">In this case, by looking in a folder recursively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=206" target="_blank">00:03:26.520</a></span> | <span class="t">And that's where it's coming from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=208" target="_blank">00:03:28.880</a></span> | <span class="t">You can pass in arguments that end up going to pillow, because pillow or PIL is the thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=213" target="_blank">00:03:33.080</a></span> | <span class="t">that actually opens that for us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=215" target="_blank">00:03:35.680</a></span> | <span class="t">And in this case, these are black and white rather than RGB.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=219" target="_blank">00:03:39.480</a></span> | <span class="t">So you have to use PILO's convert mode equals L. For more details, refer to the Python imaging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=225" target="_blank">00:03:45.360</a></span> | <span class="t">library documentation to see what their convert modes are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=228" target="_blank">00:03:48.960</a></span> | <span class="t">But this one is going to be grayscale, which is what MNIST is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=234" target="_blank">00:03:54.840</a></span> | <span class="t">So inside an item list is an items attribute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=238" target="_blank">00:03:58.880</a></span> | <span class="t">And the items attribute is kind of the thing that you gave it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=242" target="_blank">00:04:02.920</a></span> | <span class="t">It's the thing that it's going to use to create your items.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=245" target="_blank">00:04:05.480</a></span> | <span class="t">So in this case, the thing you gave it really is a list of file names.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=248" target="_blank">00:04:08.360</a></span> | <span class="t">That's what it got from the folder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=253" target="_blank">00:04:13.600</a></span> | <span class="t">When you show images, normally it shows them in RGB.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=257" target="_blank">00:04:17.960</a></span> | <span class="t">And so in this case, we want to use a binary color map.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=260" target="_blank">00:04:20.360</a></span> | <span class="t">So in FastAI, you can set a default color map.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=263" target="_blank">00:04:23.240</a></span> | <span class="t">For more information about Cmap and color maps, refer to the mapplotlib documentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=268" target="_blank">00:04:28.380</a></span> | <span class="t">And so this will set the default color map for FastAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=272" target="_blank">00:04:32.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=273" target="_blank">00:04:33.280</a></span> | <span class="t">So our image item list contains 70,000 items.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=276" target="_blank">00:04:36.400</a></span> | <span class="t">And it's a bunch of images that are 1 by 28 by 28.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=280" target="_blank">00:04:40.440</a></span> | <span class="t">Remember that PyTorch puts channel first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=282" target="_blank">00:04:42.640</a></span> | <span class="t">So they're 1 channel, 28 by 28.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=285" target="_blank">00:04:45.200</a></span> | <span class="t">You might think, why aren't they just 28 by 28 matrices rather than a 1 by 28 by 28 rank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=291" target="_blank">00:04:51.840</a></span> | <span class="t">3 tensor?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=293" target="_blank">00:04:53.400</a></span> | <span class="t">It's just easier that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=294" target="_blank">00:04:54.800</a></span> | <span class="t">All the conv2d stuff and so forth works on rank 3 tensors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=300" target="_blank">00:05:00.320</a></span> | <span class="t">So you want to include that unit access at the start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=304" target="_blank">00:05:04.240</a></span> | <span class="t">And so FastAI will do that for you even when it's reading 1 channel images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=311" target="_blank">00:05:11.100</a></span> | <span class="t">So the dot items attribute contains the thing that's kind of read to build the image, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=316" target="_blank">00:05:16.760</a></span> | <span class="t">in this case is the file name.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=318" target="_blank">00:05:18.720</a></span> | <span class="t">But if you just index into an item list directly, you'll get the actual image object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=323" target="_blank">00:05:23.400</a></span> | <span class="t">And so the actual image object has a show method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=325" target="_blank">00:05:25.920</a></span> | <span class="t">And so there's the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=328" target="_blank">00:05:28.120</a></span> | <span class="t">So once you've got an image item list, you then split it into training versus validation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=333" target="_blank">00:05:33.720</a></span> | <span class="t">You nearly always want validation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=335" target="_blank">00:05:35.420</a></span> | <span class="t">If you don't, you can actually use the dot no split method to create a kind of empty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=340" target="_blank">00:05:40.880</a></span> | <span class="t">validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=342" target="_blank">00:05:42.800</a></span> | <span class="t">You can't skip it entirely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=344" target="_blank">00:05:44.580</a></span> | <span class="t">You have to say how to split.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=346" target="_blank">00:05:46.120</a></span> | <span class="t">And one of the options is no split.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=348" target="_blank">00:05:48.920</a></span> | <span class="t">And so remember, that's always the order.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=350" target="_blank">00:05:50.440</a></span> | <span class="t">First create your item list, then decide how to split.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=353" target="_blank">00:05:53.440</a></span> | <span class="t">In this case, we're going to do it based on folders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=358" target="_blank">00:05:58.000</a></span> | <span class="t">In this case, the validation folder for MNIST is called testing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=364" target="_blank">00:06:04.520</a></span> | <span class="t">So in FastAI parlance, we use the same kind of parlance that Kaggle does, which is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=369" target="_blank">00:06:09.180</a></span> | <span class="t">training set is what you train on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=371" target="_blank">00:06:11.680</a></span> | <span class="t">The validation set has labels, and you do it for testing that your model's working.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=376" target="_blank">00:06:16.460</a></span> | <span class="t">The test set doesn't have labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=379" target="_blank">00:06:19.520</a></span> | <span class="t">And you use it for doing inference or submitting to a competition or sending it off to somebody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=385" target="_blank">00:06:25.060</a></span> | <span class="t">who's held out those labels for vendor testing or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=389" target="_blank">00:06:29.880</a></span> | <span class="t">So just because a folder in your data set is called testing doesn't mean it's a test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=394" target="_blank">00:06:34.120</a></span> | <span class="t">set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=395" target="_blank">00:06:35.120</a></span> | <span class="t">This one has labels, so it's a validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=399" target="_blank">00:06:39.520</a></span> | <span class="t">So if you want to do inference on lots of things at a time rather than one thing at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=403" target="_blank">00:06:43.720</a></span> | <span class="t">a time, you want to use the test equals in FastAI to say this is stuff which has no labels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=411" target="_blank">00:06:51.320</a></span> | <span class="t">that I'm just using for inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=416" target="_blank">00:06:56.480</a></span> | <span class="t">My split data is a training set and a validation set, as you can see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=422" target="_blank">00:07:02.680</a></span> | <span class="t">So inside the training set, there's a folder for each class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=429" target="_blank">00:07:09.140</a></span> | <span class="t">So now we can take that split data and say label from folder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=433" target="_blank">00:07:13.920</a></span> | <span class="t">So first you create the item list, then you split it, then you label it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=438" target="_blank">00:07:18.200</a></span> | <span class="t">And so you can see now we have an X and a Y, and the Y are category objects.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=446" target="_blank">00:07:26.080</a></span> | <span class="t">Category object is just a class, basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=450" target="_blank">00:07:30.280</a></span> | <span class="t">So if you index into a label list, such as ll.train as a label list, you will get back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=459" target="_blank">00:07:39.760</a></span> | <span class="t">an independent variable, independent variable, X and Y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=462" target="_blank">00:07:42.520</a></span> | <span class="t">So in this case, the X will be an image object, which I can show, and the Y will be a category</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=467" target="_blank">00:07:47.960</a></span> | <span class="t">object which I can print.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=471" target="_blank">00:07:51.360</a></span> | <span class="t">That's the number eight category, and there's the eight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=476" target="_blank">00:07:56.880</a></span> | <span class="t">Next thing we can do is to add transforms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=479" target="_blank">00:07:59.840</a></span> | <span class="t">In this case, we're not going to use the normal get transforms function because we're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=485" target="_blank">00:08:05.360</a></span> | <span class="t">digit recognition, and digit recognition, you wouldn't want to flip it left or right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=489" target="_blank">00:08:09.840</a></span> | <span class="t">that would change the meaning of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=491" target="_blank">00:08:11.480</a></span> | <span class="t">You wouldn't want to rotate it too much, that would change the meaning of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=494" target="_blank">00:08:14.800</a></span> | <span class="t">Also because these images are so small, doing zooms and stuff is going to make them so fuzzy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=498" target="_blank">00:08:18.880</a></span> | <span class="t">as to be unreadable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=500" target="_blank">00:08:20.280</a></span> | <span class="t">So normally for small images of digits like this, you just add a bit of random padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=505" target="_blank">00:08:25.940</a></span> | <span class="t">So I'll use the random padding function, which actually returns two transforms, the bit that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=512" target="_blank">00:08:32.240</a></span> | <span class="t">does the padding and the bit that does the random crop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=514" target="_blank">00:08:34.480</a></span> | <span class="t">So you have to use star to, say, put both these transforms in this list.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=519" target="_blank">00:08:39.400</a></span> | <span class="t">So now we can call transform.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=521" target="_blank">00:08:41.920</a></span> | <span class="t">This empty array here is referring to the validation set transforms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=525" target="_blank">00:08:45.560</a></span> | <span class="t">So no transforms for the validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=529" target="_blank">00:08:49.280</a></span> | <span class="t">Now we've got a transformed, labeled list.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=533" target="_blank">00:08:53.320</a></span> | <span class="t">We can pick a batch size and choose data bunch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=537" target="_blank">00:08:57.040</a></span> | <span class="t">We can choose normalize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=539" target="_blank">00:08:59.440</a></span> | <span class="t">In this case, we're not using a pre-trained model, so there's no reason to use image net</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=543" target="_blank">00:09:03.720</a></span> | <span class="t">stats here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=545" target="_blank">00:09:05.960</a></span> | <span class="t">And so if you call normalize like this, without passing in stats, it will grab a batch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=553" target="_blank">00:09:13.200</a></span> | <span class="t">data at random and use that to decide what normalization stats to use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=558" target="_blank">00:09:18.500</a></span> | <span class="t">That's a good idea if you're not using a pre-trained model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=564" target="_blank">00:09:24.040</a></span> | <span class="t">So we've got a data bunch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=565" target="_blank">00:09:25.840</a></span> | <span class="t">And so in that data bunch is a data set, which we've seen already.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=573" target="_blank">00:09:33.880</a></span> | <span class="t">But what is interesting is that the training data set now has data augmentation because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=577" target="_blank">00:09:37.480</a></span> | <span class="t">we've got transforms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=579" target="_blank">00:09:39.220</a></span> | <span class="t">So plot multi is a fast AI function that will plot the result of calling some function for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=585" target="_blank">00:09:45.320</a></span> | <span class="t">each of this row by column grid.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=587" target="_blank">00:09:47.960</a></span> | <span class="t">So in this case, my function is just grab the first image from the training set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=593" target="_blank">00:09:53.160</a></span> | <span class="t">And because each time you grab something from the training set, it's going to load it from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=596" target="_blank">00:09:56.640</a></span> | <span class="t">disk and it's going to transform it on the fly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=601" target="_blank">00:10:01.320</a></span> | <span class="t">So people sometimes ask like, how many transformed versions of the image do you create?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=607" target="_blank">00:10:07.320</a></span> | <span class="t">And the answer is kind of infinite.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=609" target="_blank">00:10:09.480</a></span> | <span class="t">Each time we grab one thing from the data set, we do a random transform on the fly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=615" target="_blank">00:10:15.320</a></span> | <span class="t">So potentially everyone will look a little bit different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=619" target="_blank">00:10:19.080</a></span> | <span class="t">So you can see here, if we plot the result of that lots of times, we get eights in slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=624" target="_blank">00:10:24.280</a></span> | <span class="t">different positions because we did random padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=628" target="_blank">00:10:28.680</a></span> | <span class="t">You can always grab a batch of data then from the data bunch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=633" target="_blank">00:10:33.000</a></span> | <span class="t">Because remember, a data bunch has data loaders, and data loaders are things that you grab</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=637" target="_blank">00:10:37.560</a></span> | <span class="t">a batch at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=639" target="_blank">00:10:39.580</a></span> | <span class="t">And so you can then grab an X batch and a Y batch, look at their shape, batch size by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=644" target="_blank">00:10:44.840</a></span> | <span class="t">channel by row by column.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=647" target="_blank">00:10:47.560</a></span> | <span class="t">All fast AI data bunches have a show batch, which will show you what's in it in some sensible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=654" target="_blank">00:10:54.960</a></span> | <span class="t">way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=655" target="_blank">00:10:55.960</a></span> | <span class="t">Okay, so that's a quick walkthrough of the data block API stuff to grab our data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=662" target="_blank">00:11:02.120</a></span> | <span class="t">So let's start out creating a simple CNN, simple confident.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=668" target="_blank">00:11:08.340</a></span> | <span class="t">So the input is 28 by 28.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=672" target="_blank">00:11:12.960</a></span> | <span class="t">So let's define -- I like to define when I'm creating architectures a function which kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=678" target="_blank">00:11:18.700</a></span> | <span class="t">of does the things that I do again and again and again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=680" target="_blank">00:11:20.880</a></span> | <span class="t">I don't want to call it with the same arguments because I'll forget, I'll make a mistake.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=684" target="_blank">00:11:24.520</a></span> | <span class="t">So in this case, all of my convolutions are going to be kernel size three, stride two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=690" target="_blank">00:11:30.480</a></span> | <span class="t">padding one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=691" target="_blank">00:11:31.480</a></span> | <span class="t">So let's just create a simple function to do a conv with those parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=694" target="_blank">00:11:34.720</a></span> | <span class="t">So each time I have a convolution, it's skipping over one pixel, so it's doing jumping two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=703" target="_blank">00:11:43.320</a></span> | <span class="t">steps each time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=705" target="_blank">00:11:45.240</a></span> | <span class="t">So that means that each time we have a convolution, it's going to halve the grid size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=710" target="_blank">00:11:50.100</a></span> | <span class="t">So I've put a comment here showing what the new grid size is after each one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=714" target="_blank">00:11:54.960</a></span> | <span class="t">So after the first convolution, we have one channel coming in, because remember it's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=720" target="_blank">00:12:00.200</a></span> | <span class="t">grayscale image with one channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=722" target="_blank">00:12:02.440</a></span> | <span class="t">And then how many channels coming out, whatever you like, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=726" target="_blank">00:12:06.320</a></span> | <span class="t">So remember you always get to pick how many filters you create regardless of whether it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=731" target="_blank">00:12:11.560</a></span> | <span class="t">a fully connected layer, in which case it's just the width of the matrix you're multiplying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=736" target="_blank">00:12:16.760</a></span> | <span class="t">by, or in this case with a 2D conv, it's just how many filters do you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=743" target="_blank">00:12:23.880</a></span> | <span class="t">So I picked eight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=745" target="_blank">00:12:25.040</a></span> | <span class="t">And so after this, it's stride two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=746" target="_blank">00:12:26.520</a></span> | <span class="t">So the 28 by 28 image is now a 14 by 14 feature map with eight channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=753" target="_blank">00:12:33.460</a></span> | <span class="t">So specifically, therefore, it's an eight by 14 by 14 tensor of activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=761" target="_blank">00:12:41.280</a></span> | <span class="t">Then we'll do batch norm, then we'll do relu.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=763" target="_blank">00:12:43.700</a></span> | <span class="t">So the number of input filters to the next conv has to equal the number of output filters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=767" target="_blank">00:12:47.960</a></span> | <span class="t">from the previous conv, and we can just keep increasing the number of channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=773" target="_blank">00:12:53.360</a></span> | <span class="t">Because we're doing stride two, it's going to keep decreasing the grid size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=778" target="_blank">00:12:58.040</a></span> | <span class="t">Notice here it goes from seven to four, because if you're doing a stride two conv over seven,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=784" target="_blank">00:13:04.260</a></span> | <span class="t">it's going to be kind of math.ceiling of seven divided by two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=791" target="_blank">00:13:11.600</a></span> | <span class="t">Batch norm, relu, conv, we're now down to two by two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=795" target="_blank">00:13:15.200</a></span> | <span class="t">Batch norm, relu, conv, we're now down to one by one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=798" target="_blank">00:13:18.960</a></span> | <span class="t">So after this, we have a picture map of, let's see, ten by one by one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=812" target="_blank">00:13:32.960</a></span> | <span class="t">Does that make sense?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=814" target="_blank">00:13:34.880</a></span> | <span class="t">We've got a grid size of one now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=816" target="_blank">00:13:36.540</a></span> | <span class="t">So it's not a vector of length ten.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=820" target="_blank">00:13:40.240</a></span> | <span class="t">It's a rank three tensor of ten by one by one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=826" target="_blank">00:13:46.120</a></span> | <span class="t">So our loss functions expect generally a vector, not a rank three tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=831" target="_blank">00:13:51.800</a></span> | <span class="t">So you can chuck flatten at the end, and flatten just means remove any unit axes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=839" target="_blank">00:13:59.360</a></span> | <span class="t">So that will make it now just a vector of length ten, which is what we always expect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=846" target="_blank">00:14:06.040</a></span> | <span class="t">So that's how we can create a CNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=850" target="_blank">00:14:10.260</a></span> | <span class="t">So then we can return that into a learner by passing in the data and the model and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=854" target="_blank">00:14:14.960</a></span> | <span class="t">loss function and, if optionally, some metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=859" target="_blank">00:14:19.260</a></span> | <span class="t">So we're going to use cross entropy as usual.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=862" target="_blank">00:14:22.240</a></span> | <span class="t">So we can then call learn.summary and confirm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=864" target="_blank">00:14:24.700</a></span> | <span class="t">After that first conv, we're down to 14 by 14.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=868" target="_blank">00:14:28.480</a></span> | <span class="t">And after the second conv, 7 by 7 and 4 by 4, 2 by 2, 1 by 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=876" target="_blank">00:14:36.160</a></span> | <span class="t">The flatten comes out calling it a lambda, but that, as you can see, gets rid of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=880" target="_blank">00:14:40.040</a></span> | <span class="t">one by one, and it's now just a length ten vector for each item in the batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=886" target="_blank">00:14:46.500</a></span> | <span class="t">So a 128 by 10 matrix for the whole mini batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=891" target="_blank">00:14:51.440</a></span> | <span class="t">So just to confirm that this is working okay, we can grab that mini batch of X that we created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=898" target="_blank">00:14:58.280</a></span> | <span class="t">earlier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=899" target="_blank">00:14:59.280</a></span> | <span class="t">That's our mini batch of X. Pop it onto the GPU and call the model directly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=905" target="_blank">00:15:05.320</a></span> | <span class="t">Remember any PyTorch module we can pretend it's a function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=909" target="_blank">00:15:09.820</a></span> | <span class="t">And that gives us back, as we hoped, a 128 by 10 result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=914" target="_blank">00:15:14.880</a></span> | <span class="t">So that's how you can directly get some predictions out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=917" target="_blank">00:15:17.880</a></span> | <span class="t">We already have a 98.6% accurate ConvNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=929" target="_blank">00:15:29.040</a></span> | <span class="t">And this is trained from scratch, of course, it's not pre-trained, we literally created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=932" target="_blank">00:15:32.520</a></span> | <span class="t">our own architecture, it's about the simplest possible architecture you can imagine, 18</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=936" target="_blank">00:15:36.440</a></span> | <span class="t">seconds to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=937" target="_blank">00:15:37.440</a></span> | <span class="t">So that's how easy it is to create a pretty accurate digit detector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=942" target="_blank">00:15:42.800</a></span> | <span class="t">So let's refactor that a little rather than saying Conv Batch Norm Relu all the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=951" target="_blank">00:15:51.520</a></span> | <span class="t">Fast AI already has something called Conv_Layer, which lets you create Conv Batch Norm Relu</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=958" target="_blank">00:15:58.240</a></span> | <span class="t">combinations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=960" target="_blank">00:16:00.240</a></span> | <span class="t">And it has various other options to do other tweaks to it, but the basic version is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=964" target="_blank">00:16:04.960</a></span> | <span class="t">exactly what I just showed you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=966" target="_blank">00:16:06.520</a></span> | <span class="t">So we can refactor that like so, so that's exactly the same neural net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=974" target="_blank">00:16:14.280</a></span> | <span class="t">And so let's just train it a little bit longer, and it's actually 99.1% accurate if we train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=980" target="_blank">00:16:20.280</a></span> | <span class="t">it for all of a minute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=982" target="_blank">00:16:22.200</a></span> | <span class="t">So that's cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=985" target="_blank">00:16:25.080</a></span> | <span class="t">So how can we improve this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=988" target="_blank">00:16:28.240</a></span> | <span class="t">Well what we really want to do is create a deeper network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=993" target="_blank">00:16:33.980</a></span> | <span class="t">And it's a very easy way to create a deeper network would be after every stride two Conv,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1000" target="_blank">00:16:40.280</a></span> | <span class="t">add a stride one Conv, because the stride one Conv doesn't change the feature map size at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1005" target="_blank">00:16:45.440</a></span> | <span class="t">all, so you can add as many as you like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1009" target="_blank">00:16:49.320</a></span> | <span class="t">But there's a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1013" target="_blank">00:16:53.280</a></span> | <span class="t">There's a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1014" target="_blank">00:16:54.280</a></span> | <span class="t">And the problem was pointed out in this paper, very, very, very influential paper, called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1018" target="_blank">00:16:58.680</a></span> | <span class="t">Deep Residual Learning for Image Recognition by Kaiming He and colleagues then at Microsoft</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1025" target="_blank">00:17:05.360</a></span> | <span class="t">Research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1026" target="_blank">00:17:06.360</a></span> | <span class="t">And they did something interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1027" target="_blank">00:17:07.760</a></span> | <span class="t">They said, let's look at the training error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1029" target="_blank">00:17:09.680</a></span> | <span class="t">So forget generalization even.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1031" target="_blank">00:17:11.520</a></span> | <span class="t">Let's just look at the training error of a network trained on CIFAR-10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1037" target="_blank">00:17:17.920</a></span> | <span class="t">And let's try one network with 20 layers, just basic three by three Convs, just basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1042" target="_blank">00:17:22.960</a></span> | <span class="t">the same network I just showed you, but without batch norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1048" target="_blank">00:17:28.800</a></span> | <span class="t">So I trained 20 layer one and a 56 layer one on the training set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1054" target="_blank">00:17:34.760</a></span> | <span class="t">So the 56 layer one has a lot more parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1057" target="_blank">00:17:37.040</a></span> | <span class="t">It's got a lot more of these stride one Convs in the middle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1060" target="_blank">00:17:40.560</a></span> | <span class="t">So the one with more parameters should seriously overfit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1065" target="_blank">00:17:45.060</a></span> | <span class="t">So you would expect the 56 layer one to zip down to zero-ish training error pretty quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1071" target="_blank">00:17:51.360</a></span> | <span class="t">And that is not what happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1072" target="_blank">00:17:52.360</a></span> | <span class="t">It is worse than the shallower network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1075" target="_blank">00:17:55.760</a></span> | <span class="t">So when you see something weird happen, really good researchers don't go, oh, no, it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1081" target="_blank">00:18:01.920</a></span> | <span class="t">working.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1082" target="_blank">00:18:02.920</a></span> | <span class="t">They go, that's interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1085" target="_blank">00:18:05.500</a></span> | <span class="t">So Kaiming He said, that's interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1089" target="_blank">00:18:09.480</a></span> | <span class="t">What's going on?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1091" target="_blank">00:18:11.600</a></span> | <span class="t">And he said, I don't know, but what I do know is this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1096" target="_blank">00:18:16.520</a></span> | <span class="t">I could take this 56 layer network and make a new version of it, which is identical, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1104" target="_blank">00:18:24.320</a></span> | <span class="t">has to be at least as good as the 20 layer network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1107" target="_blank">00:18:27.680</a></span> | <span class="t">And here's how.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1109" target="_blank">00:18:29.920</a></span> | <span class="t">Every two convolutions, I'm going to add together the input to those two convolutions, add it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1118" target="_blank">00:18:38.840</a></span> | <span class="t">together with the result of those two convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1124" target="_blank">00:18:44.700</a></span> | <span class="t">So in other words, he's saying, instead of saying output equals conv2 of conv1 of x, instead,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1139" target="_blank">00:18:59.680</a></span> | <span class="t">he's saying output equals x plus conv2 of conv1 of x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1149" target="_blank">00:19:09.720</a></span> | <span class="t">So that 56 layers worth of convolutions in that, his theory has to be at least as good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1160" target="_blank">00:19:20.800</a></span> | <span class="t">as the 20 layer version because it could always just set conv2 and conv1 to a bunch of zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1168" target="_blank">00:19:28.480</a></span> | <span class="t">weights for everything except for the first 20 layers because the x, the input, could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1175" target="_blank">00:19:35.200</a></span> | <span class="t">just go straight through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1178" target="_blank">00:19:38.000</a></span> | <span class="t">So this thing here is, as you see, called an identity connection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1183" target="_blank">00:19:43.500</a></span> | <span class="t">It's the identity function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1186" target="_blank">00:19:46.000</a></span> | <span class="t">Nothing happens at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1187" target="_blank">00:19:47.260</a></span> | <span class="t">It's also known as a skip connection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1189" target="_blank">00:19:49.760</a></span> | <span class="t">So that was a theory, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1191" target="_blank">00:19:51.400</a></span> | <span class="t">That's what the paper describes as the intuition behind this is what would happen if we created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1197" target="_blank">00:19:57.400</a></span> | <span class="t">something which has to train at least as well as a 20 layer neural network because it kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1203" target="_blank">00:20:03.200</a></span> | <span class="t">of contains that 20 layer neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1205" target="_blank">00:20:05.280</a></span> | <span class="t">It's literally a path you can just skip over all the convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1211" target="_blank">00:20:11.120</a></span> | <span class="t">And so what happens?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1213" target="_blank">00:20:13.760</a></span> | <span class="t">And what happened was he won ImageNet that year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1217" target="_blank">00:20:17.960</a></span> | <span class="t">He easily won ImageNet that year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1220" target="_blank">00:20:20.280</a></span> | <span class="t">And in fact, even today, we had that record-breaking result on ImageNet speed training ourselves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1229" target="_blank">00:20:29.760</a></span> | <span class="t">In the last year, we used this, too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1233" target="_blank">00:20:33.440</a></span> | <span class="t">ResNet has been revolutionary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1237" target="_blank">00:20:37.680</a></span> | <span class="t">And here's a trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1239" target="_blank">00:20:39.720</a></span> | <span class="t">If you're interested in doing some research, some novel research, any time you find some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1245" target="_blank">00:20:45.680</a></span> | <span class="t">model for anything, whether it's medical image segmentation or some kind of GAN or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1254" target="_blank">00:20:54.120</a></span> | <span class="t">and it was written a couple of years ago, they might have forgotten to put ResNets in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1259" target="_blank">00:20:59.960</a></span> | <span class="t">Resblocks, this is what we normally call a resblock.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1264" target="_blank">00:21:04.080</a></span> | <span class="t">They might have forgotten to put resblocks in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1265" target="_blank">00:21:05.920</a></span> | <span class="t">So replace their convolutional path with a bunch of resblocks, and you'll almost always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1272" target="_blank">00:21:12.680</a></span> | <span class="t">get better results faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1274" target="_blank">00:21:14.000</a></span> | <span class="t">It's a good trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1277" target="_blank">00:21:17.040</a></span> | <span class="t">So at NeurIPS, which Rachel and I and David all just came back from and Sylvain, we saw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1284" target="_blank">00:21:24.200</a></span> | <span class="t">a new presentation where they actually figured out how to visualize the loss surface of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1292" target="_blank">00:21:32.440</a></span> | <span class="t">neural net, which is really cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1294" target="_blank">00:21:34.240</a></span> | <span class="t">This is a fantastic paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1295" target="_blank">00:21:35.960</a></span> | <span class="t">And anybody who's watching this, lesson seven, is at a point where they will understand most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1301" target="_blank">00:21:41.840</a></span> | <span class="t">of the most important concepts in this paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1304" target="_blank">00:21:44.120</a></span> | <span class="t">You can read this now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1305" target="_blank">00:21:45.760</a></span> | <span class="t">You won't necessarily get all of it, but I'm sure you'll get enough to find it interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1311" target="_blank">00:21:51.060</a></span> | <span class="t">And so the big picture was this one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1314" target="_blank">00:21:54.000</a></span> | <span class="t">Here's what happens if you draw a picture where kind of X and Y here are two projections</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1320" target="_blank">00:22:00.600</a></span> | <span class="t">of the weight space, and Z is the loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1324" target="_blank">00:22:04.940</a></span> | <span class="t">And so as you move through the weight space, a 56 layer neural network without skip connections</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1331" target="_blank">00:22:11.520</a></span> | <span class="t">is very, very bumpy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1333" target="_blank">00:22:13.680</a></span> | <span class="t">And that's why this got nowhere, because it just got stuck in all these hills and valleys.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1341" target="_blank">00:22:21.400</a></span> | <span class="t">The exact same network with identity connections, with skip connections, has this lost landscape.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1349" target="_blank">00:22:29.540</a></span> | <span class="t">So it's kind of interesting how Herr recognized back in 2015, this shouldn't happen here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1359" target="_blank">00:22:39.880</a></span> | <span class="t">a way that must fix it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1361" target="_blank">00:22:41.240</a></span> | <span class="t">And it took three years before people were able to say, oh, this is kind of why it fixed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1367" target="_blank">00:22:47.480</a></span> | <span class="t">it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1368" target="_blank">00:22:48.480</a></span> | <span class="t">With the batch norm discussion we had a couple of weeks ago, people realizing a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1373" target="_blank">00:22:53.360</a></span> | <span class="t">after the fact sometimes what's going on and why it helps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1377" target="_blank">00:22:57.860</a></span> | <span class="t">So in our code, we can create a res block in just the way I described.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1390" target="_blank">00:23:10.200</a></span> | <span class="t">We create an nn.module, we create two conf layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1394" target="_blank">00:23:14.120</a></span> | <span class="t">Where a conf layer is conf2d, batch norm, relu, sorry, conf2d, relu, batch norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1403" target="_blank">00:23:23.800</a></span> | <span class="t">So create two of those and then in forward we go conf1 of X, conf2 of that, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1409" target="_blank">00:23:29.200</a></span> | <span class="t">add X.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1413" target="_blank">00:23:33.560</a></span> | <span class="t">There's a res block function already in fast AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1416" target="_blank">00:23:36.520</a></span> | <span class="t">So you can just call res block instead, and you just pass in something saying how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1422" target="_blank">00:23:42.320</a></span> | <span class="t">filters do you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1426" target="_blank">00:23:46.000</a></span> | <span class="t">So there's the res block that I defined in our notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1431" target="_blank">00:23:51.160</a></span> | <span class="t">And so with that res block we can now take every one of those, I've just copied the previous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1437" target="_blank">00:23:57.000</a></span> | <span class="t">CNN, and after every conf2, except the last one, I added a res block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1443" target="_blank">00:24:03.240</a></span> | <span class="t">So this has now got three times as many layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1446" target="_blank">00:24:06.580</a></span> | <span class="t">So it should be able to do more compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1449" target="_blank">00:24:09.120</a></span> | <span class="t">But it shouldn't be any harder to optimize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1452" target="_blank">00:24:12.280</a></span> | <span class="t">So what happens?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1454" target="_blank">00:24:14.000</a></span> | <span class="t">Well, let's just refactor it one more time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1456" target="_blank">00:24:16.960</a></span> | <span class="t">Since I go conf2 res block so many times, let's just pop that into a mini sequential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1463" target="_blank">00:24:23.160</a></span> | <span class="t">model here, and so I can refactor that like so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1466" target="_blank">00:24:26.840</a></span> | <span class="t">Keep refactoring your architectures if you're trying novel architectures because you'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1470" target="_blank">00:24:30.040</a></span> | <span class="t">make less mistakes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1471" target="_blank">00:24:31.840</a></span> | <span class="t">Very few people do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1472" target="_blank">00:24:32.880</a></span> | <span class="t">Most research code you look at is clunky as all hell, and people often make mistakes in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1478" target="_blank">00:24:38.680</a></span> | <span class="t">that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1479" target="_blank">00:24:39.680</a></span> | <span class="t">So don't do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1480" target="_blank">00:24:40.680</a></span> | <span class="t">You're all coders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1482" target="_blank">00:24:42.760</a></span> | <span class="t">So use your coding skills to make life easier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1487" target="_blank">00:24:47.800</a></span> | <span class="t">So there's my ResNet-ish architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1494" target="_blank">00:24:54.440</a></span> | <span class="t">And I'll find, as usual, fit for a while.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1500" target="_blank">00:25:00.320</a></span> | <span class="t">And I get 99.54.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1505" target="_blank">00:25:05.120</a></span> | <span class="t">So that's interesting because we've trained this literally from scratch with an architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1511" target="_blank">00:25:11.000</a></span> | <span class="t">we built from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1512" target="_blank">00:25:12.200</a></span> | <span class="t">I didn't look up this architecture anywhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1514" target="_blank">00:25:14.200</a></span> | <span class="t">It was just the first thing that came to mind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1517" target="_blank">00:25:17.520</a></span> | <span class="t">But in terms of where that puts us, 0.45% error is around about the state of the art</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1524" target="_blank">00:25:24.360</a></span> | <span class="t">for this data set as of three or four years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1528" target="_blank">00:25:28.600</a></span> | <span class="t">Now, you know, today MNIST is considered a kind of trivially easy data set, so I'm not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1534" target="_blank">00:25:34.760</a></span> | <span class="t">saying, like, wow, we've broken some records here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1537" target="_blank">00:25:37.400</a></span> | <span class="t">People have got beyond 0.45% error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1540" target="_blank">00:25:40.040</a></span> | <span class="t">But what I'm saying is that, you know, we can't -- this kind of ResNet is a genuinely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1549" target="_blank">00:25:49.720</a></span> | <span class="t">extremely useful network still today, and this is really all we use in our fast ImageNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1556" target="_blank">00:25:56.080</a></span> | <span class="t">training still.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1557" target="_blank">00:25:57.080</a></span> | <span class="t">And one of the reasons as well is that it's so popular, so the vendors of the library</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1562" target="_blank">00:26:02.580</a></span> | <span class="t">spend a lot of time optimizing it, so things tend to work fast, whereas some more modern-style</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1570" target="_blank">00:26:10.760</a></span> | <span class="t">architectures using things like separable or grouped convolutions tend not to actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1575" target="_blank">00:26:15.380</a></span> | <span class="t">train very quickly in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1579" target="_blank">00:26:19.580</a></span> | <span class="t">If you look at the definition of ResBlock in the fast AI code, you'll see it looks a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1585" target="_blank">00:26:25.360</a></span> | <span class="t">bit different to this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1587" target="_blank">00:26:27.740</a></span> | <span class="t">And that's because I've created something called a merge layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1590" target="_blank">00:26:30.800</a></span> | <span class="t">And a merge layer is something which in the forward -- just skip dense for a moment -- the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1596" target="_blank">00:26:36.120</a></span> | <span class="t">forward says x plus x dot a ridge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1601" target="_blank">00:26:41.240</a></span> | <span class="t">So you can see there's something ResNet-ish going on here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1604" target="_blank">00:26:44.400</a></span> | <span class="t">What is x dot a ridge?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1605" target="_blank">00:26:45.800</a></span> | <span class="t">Well, if you create a special kind of sequential model called a sequential EX -- so this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1611" target="_blank">00:26:51.120</a></span> | <span class="t">like fast AI's sequential extended -- it's just like a normal sequential model, but we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1616" target="_blank">00:26:56.640</a></span> | <span class="t">store the input in x dot a ridge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1621" target="_blank">00:27:01.400</a></span> | <span class="t">And so this here, sequential EX, conv layer, conv layer, merge layer, will do exactly the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1629" target="_blank">00:27:09.880</a></span> | <span class="t">same as this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1632" target="_blank">00:27:12.600</a></span> | <span class="t">So you can create your own variations of ResNet blocks very easily with just sequential EX</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1638" target="_blank">00:27:18.600</a></span> | <span class="t">and merge layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1642" target="_blank">00:27:22.200</a></span> | <span class="t">So there's something else here, which is when you create your merge layer, you can optionally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1646" target="_blank">00:27:26.160</a></span> | <span class="t">set dense equals true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1648" target="_blank">00:27:28.660</a></span> | <span class="t">What happens if you do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1649" target="_blank">00:27:29.660</a></span> | <span class="t">Well, if you do, it doesn't go x plus x dot a ridge, it goes cat x comma x dot a ridge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1656" target="_blank">00:27:36.120</a></span> | <span class="t">In other words, rather than putting a plus in this connection, it does a concatenate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1663" target="_blank">00:27:43.940</a></span> | <span class="t">So that's pretty interesting, because what happens is that you have your input coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1671" target="_blank">00:27:51.760</a></span> | <span class="t">into your Res block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1673" target="_blank">00:27:53.720</a></span> | <span class="t">And once you use concatenate instead of plus, it's not called a Res block anymore, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1678" target="_blank">00:27:58.080</a></span> | <span class="t">called a dense block, and it's not called a ResNet anymore, it's called a dense net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1682" target="_blank">00:28:02.600</a></span> | <span class="t">So the dense net was invented about a year after the ResNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1687" target="_blank">00:28:07.520</a></span> | <span class="t">And if you read the dense net paper, it can sound incredibly complex and different, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1691" target="_blank">00:28:11.240</a></span> | <span class="t">actually it's literally identical, but plus here is replaced with cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1697" target="_blank">00:28:17.320</a></span> | <span class="t">So you have your input coming into your dense block, right, and you've got a few convolutions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1702" target="_blank">00:28:22.160</a></span> | <span class="t">in here, and then you've got some output coming out, and then you've got your identity connection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1708" target="_blank">00:28:28.440</a></span> | <span class="t">And remember, it doesn't plus, it concats, so if this is the channel axis, it gets a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1713" target="_blank">00:28:33.640</a></span> | <span class="t">little bit bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1715" target="_blank">00:28:35.840</a></span> | <span class="t">And then so we do another dense block, and at the end of that we have all of this coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1723" target="_blank">00:28:43.160</a></span> | <span class="t">in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1724" target="_blank">00:28:44.160</a></span> | <span class="t">So at the end of that we have the result of the convolution as per usual, but this time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1732" target="_blank">00:28:52.140</a></span> | <span class="t">the identity block is that big, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1737" target="_blank">00:28:57.400</a></span> | <span class="t">So you can see that what happens is that with dense blocks it's getting bigger and bigger</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1741" target="_blank">00:29:01.600</a></span> | <span class="t">and bigger, and kind of interestingly the exact input is still here, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1749" target="_blank">00:29:09.160</a></span> | <span class="t">So actually, no matter how deep you get, the original input pixels are still there, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1754" target="_blank">00:29:14.040</a></span> | <span class="t">the original layer one features are still there, and the original layer two features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1756" target="_blank">00:29:16.880</a></span> | <span class="t">are still there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1757" target="_blank">00:29:17.880</a></span> | <span class="t">So as you can imagine, dense nets are very memory intensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1764" target="_blank">00:29:24.040</a></span> | <span class="t">There are ways to manage this, from time to time you can have a regular convolution that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1768" target="_blank">00:29:28.920</a></span> | <span class="t">squishes your channels back down, but they are memory intensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1772" target="_blank">00:29:32.760</a></span> | <span class="t">But they have very few parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1776" target="_blank">00:29:36.600</a></span> | <span class="t">So for dealing with small data sets, you should definitely experiment with dense blocks and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1783" target="_blank">00:29:43.640</a></span> | <span class="t">dense nets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1785" target="_blank">00:29:45.480</a></span> | <span class="t">They tend to work really well on small data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1789" target="_blank">00:29:49.160</a></span> | <span class="t">Also, because it's possible to kind of keep those original input pixels all the way down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1793" target="_blank">00:29:53.480</a></span> | <span class="t">the path, they work really well for segmentation, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1796" target="_blank">00:29:56.920</a></span> | <span class="t">Because for segmentation, you kind of want to be able to reconstruct the original resolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1803" target="_blank">00:30:03.140</a></span> | <span class="t">of your picture, so having all of those original pixels still there is super helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1814" target="_blank">00:30:14.640</a></span> | <span class="t">So that's res nets, and one of the main reasons, other than the fact that res nets are awesome,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1822" target="_blank">00:30:22.520</a></span> | <span class="t">to tell you about them, is that these skip connections are useful in other places as well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1828" target="_blank">00:30:28.640</a></span> | <span class="t">and they're particularly useful in other places and other ways of designing architectures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1832" target="_blank">00:30:32.960</a></span> | <span class="t">for segmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1835" target="_blank">00:30:35.280</a></span> | <span class="t">So in building this lesson, I always kind of, I keep trying to take old papers and saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1843" target="_blank">00:30:43.000</a></span> | <span class="t">like I'm mentioning, what would that person have done if they had access to all the modern</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1847" target="_blank">00:30:47.400</a></span> | <span class="t">techniques we have now?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1848" target="_blank">00:30:48.400</a></span> | <span class="t">And I try to kind of rebuild them in a more modern style.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1851" target="_blank">00:30:51.600</a></span> | <span class="t">So I've been really rebuilding this next architecture we're going to look at, called a UNET, in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1856" target="_blank">00:30:56.440</a></span> | <span class="t">a more modern style recently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1859" target="_blank">00:30:59.260</a></span> | <span class="t">And I got to the point now, I keep showing you this semantic segmentation paper with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1866" target="_blank">00:31:06.760</a></span> | <span class="t">the state of the art for CAMVID, which was 91.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1871" target="_blank">00:31:11.120</a></span> | <span class="t">This week I got it up to 94.1 using the architecture I'm about to show you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1877" target="_blank">00:31:17.540</a></span> | <span class="t">So we keep pushing this further and further and further.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1881" target="_blank">00:31:21.440</a></span> | <span class="t">And it really was all about adding all of the modern tricks, many of which I'll show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1890" target="_blank">00:31:30.400</a></span> | <span class="t">you today, some of which we'll see in part two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1895" target="_blank">00:31:35.040</a></span> | <span class="t">So what we're going to do to get there is we're going to use this UNET.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1899" target="_blank">00:31:39.620</a></span> | <span class="t">So we've used a UNET before, I've improved it a bit since then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1905" target="_blank">00:31:45.480</a></span> | <span class="t">So we've used a UNET before, we used it when we did the CAMVID segmentation, but we didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1909" target="_blank">00:31:49.000</a></span> | <span class="t">understand what it was doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1911" target="_blank">00:31:51.260</a></span> | <span class="t">So we're now in a position where we can understand what it was doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1918" target="_blank">00:31:58.900</a></span> | <span class="t">And so the first thing we need to do is kind of understand the basic idea of how you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1923" target="_blank">00:32:03.600</a></span> | <span class="t">do segmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1926" target="_blank">00:32:06.800</a></span> | <span class="t">So if we go back to our CAMVID notebook, in our CAMVID notebook you'll remember that basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1937" target="_blank">00:32:17.000</a></span> | <span class="t">what we were doing is we were taking these photos and adding a class to every single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1942" target="_blank">00:32:22.920</a></span> | <span class="t">pixel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1943" target="_blank">00:32:23.920</a></span> | <span class="t">And so when you go data.showbatch for something which is a segmentation item list, it will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1950" target="_blank">00:32:30.240</a></span> | <span class="t">automatically show you these color-coded pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1955" target="_blank">00:32:35.840</a></span> | <span class="t">So here's the thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1958" target="_blank">00:32:38.680</a></span> | <span class="t">In order to color-code this as a pedestrian, but this as a bicyclist, it needs to know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1967" target="_blank">00:32:47.780</a></span> | <span class="t">what it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1968" target="_blank">00:32:48.780</a></span> | <span class="t">It needs to actually know that's what a pedestrian looks like, and it needs to know that's exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1972" target="_blank">00:32:52.320</a></span> | <span class="t">where the pedestrian is, and this is the arm of the pedestrian and not part of their shopping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1975" target="_blank">00:32:55.440</a></span> | <span class="t">basket.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1976" target="_blank">00:32:56.440</a></span> | <span class="t">It needs to really understand a lot about this picture to do this task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1981" target="_blank">00:33:01.940</a></span> | <span class="t">And it really does do this task, like when you look at the results of our top model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1990" target="_blank">00:33:10.040</a></span> | <span class="t">I can't see a single pixel by looking at it by eye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1993" target="_blank">00:33:13.720</a></span> | <span class="t">I know there's a few wrong, but I can't see the ones that are wrong, it's that accurate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1998" target="_blank">00:33:18.560</a></span> | <span class="t">So how does it do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=1999" target="_blank">00:33:19.640</a></span> | <span class="t">So the way that we're doing it to get these really, really good results is, not surprisingly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2007" target="_blank">00:33:27.320</a></span> | <span class="t">using pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2009" target="_blank">00:33:29.260</a></span> | <span class="t">So we start with a ResNet-34, and you can see that here, unet-learner data, models.resnet-34.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2020" target="_blank">00:33:40.920</a></span> | <span class="t">And if you don't say pre-trained equals false, by default, you get pre-trained equals true,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2025" target="_blank">00:33:45.640</a></span> | <span class="t">because why not?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2028" target="_blank">00:33:48.860</a></span> | <span class="t">So we start with a ResNet-34, which starts with a big image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2037" target="_blank">00:33:57.360</a></span> | <span class="t">So in this case, this is from the unet paper now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2039" target="_blank">00:33:59.960</a></span> | <span class="t">They're images, they started with one channel by 572 by 572.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2045" target="_blank">00:34:05.040</a></span> | <span class="t">This is for medical imaging segmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2048" target="_blank">00:34:08.500</a></span> | <span class="t">So after your stride 2 conv, they're doubling the number of channels to 128, and they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2055" target="_blank">00:34:15.200</a></span> | <span class="t">halving the size, so they're now down to 280 by 280.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2059" target="_blank">00:34:19.740</a></span> | <span class="t">In this original unet paper, they didn't add any padding, so they lost a pixel on each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2064" target="_blank">00:34:24.480</a></span> | <span class="t">side each time they did a conv.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2066" target="_blank">00:34:26.080</a></span> | <span class="t">That's why you're losing these two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2067" target="_blank">00:34:27.960</a></span> | <span class="t">So basically half the size, and then half the size, and then half the size, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2073" target="_blank">00:34:33.000</a></span> | <span class="t">half the size, until they're down to 28 by 28, with 1024 channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2079" target="_blank">00:34:39.760</a></span> | <span class="t">So that's what the unet's downsampling path, this is called the downsampling path look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2086" target="_blank">00:34:46.320</a></span> | <span class="t">like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2087" target="_blank">00:34:47.320</a></span> | <span class="t">Hours is just a ResNet-34.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2090" target="_blank">00:34:50.720</a></span> | <span class="t">So you can see it here, learn.summary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2095" target="_blank">00:34:55.480</a></span> | <span class="t">This is literally a ResNet-34.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2101" target="_blank">00:35:01.080</a></span> | <span class="t">So you can see that the size keeps halving, channels keep going up, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2108" target="_blank">00:35:08.160</a></span> | <span class="t">So eventually, you've got down to a point where if you use a unit architecture, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2113" target="_blank">00:35:13.400</a></span> | <span class="t">28 by 28 with 1024 channels, with a ResNet architecture, with a 224 pixel input, it would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2120" target="_blank">00:35:20.640</a></span> | <span class="t">be 512 channels by 7 by 7.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2124" target="_blank">00:35:24.720</a></span> | <span class="t">So it's a pretty small grid size on this feature map.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2129" target="_blank">00:35:29.480</a></span> | <span class="t">Somehow we've got to end up with something which is the same size as our original picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2137" target="_blank">00:35:37.640</a></span> | <span class="t">So how do we do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2138" target="_blank">00:35:38.840</a></span> | <span class="t">How do you do computation which increases the grid size?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2144" target="_blank">00:35:44.800</a></span> | <span class="t">Well, we don't have a way to do that in our current bag of tricks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2149" target="_blank">00:35:49.340</a></span> | <span class="t">We can use a stride 1 conv to do computation and keep grid size or a stride 2 conv to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2156" target="_blank">00:35:56.160</a></span> | <span class="t">computation and halve the grid size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2158" target="_blank">00:35:58.680</a></span> | <span class="t">So how do we double the grid size?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2160" target="_blank">00:36:00.440</a></span> | <span class="t">We do a stride half conv, also known as a deconvolution, also known as a transposed convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2171" target="_blank">00:36:11.320</a></span> | <span class="t">There is a fantastic paper called A Guide to Convolution Arithmetic for Deep Learning that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2176" target="_blank">00:36:16.240</a></span> | <span class="t">shows a great picture of exactly what does a 3 by 3 kernel stride half conv look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2183" target="_blank">00:36:23.080</a></span> | <span class="t">And it's literally this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2184" target="_blank">00:36:24.300</a></span> | <span class="t">If you have a 2 by 2 input, so the blue squares are the 2 by 2 input, you add not only two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2192" target="_blank">00:36:32.040</a></span> | <span class="t">pixels of padding all around the outside, but you also add a pixel of padding between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2200" target="_blank">00:36:40.760</a></span> | <span class="t">every pixel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2203" target="_blank">00:36:43.440</a></span> | <span class="t">And so now if we put this 3 by 3 kernel here and then here and then here, you see how the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2209" target="_blank">00:36:49.160</a></span> | <span class="t">3 by 3 kernel is just moving across it in the usual way?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2212" target="_blank">00:36:52.160</a></span> | <span class="t">You will end up going from a 2 by 2 output to a 5 by 5 output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2219" target="_blank">00:36:59.000</a></span> | <span class="t">So if you only added one pixel of padding around the outside, you would end up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2223" target="_blank">00:37:03.200</a></span> | <span class="t">a 3 by 3 output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2227" target="_blank">00:37:07.560</a></span> | <span class="t">So sorry, 4 by 4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2230" target="_blank">00:37:10.600</a></span> | <span class="t">So this is how you can increase the resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2238" target="_blank">00:37:18.240</a></span> | <span class="t">This was the way people did it until maybe a year or two ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2247" target="_blank">00:37:27.200</a></span> | <span class="t">It's another trick for improving things you find online, because this is actually a dumb</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2251" target="_blank">00:37:31.880</a></span> | <span class="t">way to do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2252" target="_blank">00:37:32.880</a></span> | <span class="t">And it's kind of obvious it's a dumb way to do it for a couple of reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2255" target="_blank">00:37:35.440</a></span> | <span class="t">One is that, have a look at this, nearly all of those pixels are white.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2260" target="_blank">00:37:40.440</a></span> | <span class="t">They're nearly all zeros.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2262" target="_blank">00:37:42.480</a></span> | <span class="t">So what a waste.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2264" target="_blank">00:37:44.200</a></span> | <span class="t">What a waste of time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2265" target="_blank">00:37:45.580</a></span> | <span class="t">What a waste of computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2267" target="_blank">00:37:47.080</a></span> | <span class="t">There's just nothing going on there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2269" target="_blank">00:37:49.320</a></span> | <span class="t">Also, this one, when you get down to that 3 by 3 area, 2 out of the 9 pixels are non-white,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2280" target="_blank">00:38:00.600</a></span> | <span class="t">but this one, 1 out of the 9 are non-white.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2283" target="_blank">00:38:03.560</a></span> | <span class="t">So there's different amounts of information going into different parts of your convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2289" target="_blank">00:38:09.120</a></span> | <span class="t">So it just doesn't make any sense to kind of throw away information like this and to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2295" target="_blank">00:38:15.280</a></span> | <span class="t">do all this unnecessary computation and have different parts of the convolution having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2298" target="_blank">00:38:18.840</a></span> | <span class="t">access to different amounts of information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2302" target="_blank">00:38:22.240</a></span> | <span class="t">So what people generally do nowadays is something really simple, which is if you have, let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2309" target="_blank">00:38:29.320</a></span> | <span class="t">say, a 2 by 2 input, these are your pixel values, A, B, C, and D, and you want to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2319" target="_blank">00:38:39.480</a></span> | <span class="t">a 4 by 4, why not just do this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2326" target="_blank">00:38:46.160</a></span> | <span class="t">A, A, A, A, B, B, B, B, C, C, C, C, C, D, D, D, D.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2335" target="_blank">00:38:55.640</a></span> | <span class="t">So I've now upscaled from 2 by 2 to 4 by 4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2338" target="_blank">00:38:58.960</a></span> | <span class="t">I haven't done any interesting computation, but now on top of that, I could just do a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2345" target="_blank">00:39:05.360</a></span> | <span class="t">stride 1 convolution, and now I have done some computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2349" target="_blank">00:39:09.240</a></span> | <span class="t">So an up sample, this is called nearest neighbor interpolation, nearest neighbor interpolation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2360" target="_blank">00:39:20.760</a></span> | <span class="t">So you can just do, and that's super fast, which is nice, so you can do a nearest neighbor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2364" target="_blank">00:39:24.480</a></span> | <span class="t">interpolation and then a stride 1 conv, and now you've got some computation, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2369" target="_blank">00:39:29.840</a></span> | <span class="t">actually kind of using, you know, there's no zeros here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2374" target="_blank">00:39:34.280</a></span> | <span class="t">This is kind of nice because it gets a mixture of A's and B's, which is kind of what you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2377" target="_blank">00:39:37.480</a></span> | <span class="t">would want and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2380" target="_blank">00:39:40.920</a></span> | <span class="t">Another approach is instead of using nearest neighbor interpolation, you can use bilinear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2385" target="_blank">00:39:45.040</a></span> | <span class="t">interpolation, which basically means instead of copying A to all those different cells,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2390" target="_blank">00:39:50.440</a></span> | <span class="t">you take a kind of a weighted average of the cells around it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2393" target="_blank">00:39:53.840</a></span> | <span class="t">So for example, if you were, you know, looking at what should go here, you would kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2400" target="_blank">00:40:00.440</a></span> | <span class="t">go like, oh, it's about 3 A's, 2 C's, 1 D, and 2 B's, and you could have taken the average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2407" target="_blank">00:40:07.800</a></span> | <span class="t">Not exactly, but roughly just a weighted average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2410" target="_blank">00:40:10.920</a></span> | <span class="t">Bilinear interpolation you'll find in any, you know, all over the place, it's a pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2414" target="_blank">00:40:14.360</a></span> | <span class="t">standard technique.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2416" target="_blank">00:40:16.280</a></span> | <span class="t">Any time you look at a picture on your computer screen and change its size, it's doing bilinear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2421" target="_blank">00:40:21.080</a></span> | <span class="t">interpolation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2422" target="_blank">00:40:22.080</a></span> | <span class="t">So you can do that, and then a Strad1Conf.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2426" target="_blank">00:40:26.200</a></span> | <span class="t">So that was what people were using, well, that's what people still tend to use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2431" target="_blank">00:40:31.360</a></span> | <span class="t">That's as much as I'm going to teach you this part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2434" target="_blank">00:40:34.360</a></span> | <span class="t">In part two, we'll actually learn what the FastAI library is actually doing behind the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2439" target="_blank">00:40:39.120</a></span> | <span class="t">scenes, which is something called a pixel shuffle, also known as sub-pixel convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2444" target="_blank">00:40:44.900</a></span> | <span class="t">It's not dramatically more complex, but complex enough that I won't cover it today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2448" target="_blank">00:40:48.720</a></span> | <span class="t">There's the same basic idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2449" target="_blank">00:40:49.800</a></span> | <span class="t">All of these things is something which is basically letting us do a convolution that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2454" target="_blank">00:40:54.760</a></span> | <span class="t">ends up with something that's twice the size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2457" target="_blank">00:40:57.960</a></span> | <span class="t">And so that gives us our upsampling path.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2462" target="_blank">00:41:02.640</a></span> | <span class="t">So that lets us go from 28 by 28 to 54 by 54 and keep on doubling the size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2471" target="_blank">00:41:11.280</a></span> | <span class="t">So that's good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2474" target="_blank">00:41:14.240</a></span> | <span class="t">And that was it until UNET came along.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2479" target="_blank">00:41:19.560</a></span> | <span class="t">That's what people did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2481" target="_blank">00:41:21.140</a></span> | <span class="t">And it didn't work real well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2482" target="_blank">00:41:22.760</a></span> | <span class="t">Which is not surprising, because in this 28 by 28 feature map, how the hell is it going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2488" target="_blank">00:41:28.680</a></span> | <span class="t">to have enough information to reconstruct a 572 by 572 output space?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2495" target="_blank">00:41:35.620</a></span> | <span class="t">That's a really tough ask.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2497" target="_blank">00:41:37.800</a></span> | <span class="t">So you tended to end up with these things that lacked fine detail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2505" target="_blank">00:41:45.120</a></span> | <span class="t">So what Olaf Rolleberger and et al. did was they said, hey, let's add a skip connection,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2516" target="_blank">00:41:56.520</a></span> | <span class="t">an identity connection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2518" target="_blank">00:41:58.300</a></span> | <span class="t">And amazingly enough, this was before resnets existed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2522" target="_blank">00:42:02.800</a></span> | <span class="t">So this was like a really big leap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2526" target="_blank">00:42:06.720</a></span> | <span class="t">Really impressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2528" target="_blank">00:42:08.080</a></span> | <span class="t">And so but rather than adding a skip connection that skipped every two convolutions, they added</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2534" target="_blank">00:42:14.560</a></span> | <span class="t">skip connections where these gray lines are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2537" target="_blank">00:42:17.680</a></span> | <span class="t">In other words, they added a skip connection from the same part of the downsampling path</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2542" target="_blank">00:42:22.440</a></span> | <span class="t">to the same sized bit in the upsampling path.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2546" target="_blank">00:42:26.960</a></span> | <span class="t">And they didn't add.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2548" target="_blank">00:42:28.320</a></span> | <span class="t">That's why you can see the white and the blue next to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2550" target="_blank">00:42:30.960</a></span> | <span class="t">They didn't add.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2551" target="_blank">00:42:31.960</a></span> | <span class="t">They concatenated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2553" target="_blank">00:42:33.440</a></span> | <span class="t">So basically these are like dense blocks, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2556" target="_blank">00:42:36.880</a></span> | <span class="t">But the skip connections are skipping over larger and larger amounts of the architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2562" target="_blank">00:42:42.960</a></span> | <span class="t">So that over here, you've literally got nearly the input pixels themselves coming into the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2573" target="_blank">00:42:53.280</a></span> | <span class="t">computation of these last couple of layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2575" target="_blank">00:42:55.920</a></span> | <span class="t">And so that's going to make it super handy for resolving the fine details in these segmentation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2580" target="_blank">00:43:00.960</a></span> | <span class="t">tasks because you've literally got all of the fine details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2584" target="_blank">00:43:04.600</a></span> | <span class="t">On the downside, you don't have very many layers of computation going on here, just four.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2591" target="_blank">00:43:11.480</a></span> | <span class="t">So you better hope that by that stage, you've done all the computation necessary to figure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2595" target="_blank">00:43:15.760</a></span> | <span class="t">out, is this a bicyclist or is this a pedestrian?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2598" target="_blank">00:43:18.920</a></span> | <span class="t">But you can then add on top of that something saying like, is this exact pixel where their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2603" target="_blank">00:43:23.800</a></span> | <span class="t">nose finishes or is that the start of the tree?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2607" target="_blank">00:43:27.900</a></span> | <span class="t">So that works out really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2611" target="_blank">00:43:31.300</a></span> | <span class="t">And that's a unit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2614" target="_blank">00:43:34.640</a></span> | <span class="t">So this is the unit code from FastAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2619" target="_blank">00:43:39.600</a></span> | <span class="t">And the key thing that comes in is the encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2624" target="_blank">00:43:44.240</a></span> | <span class="t">The encoder refers to that part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2631" target="_blank">00:43:51.440</a></span> | <span class="t">In other words, in our case, a ResNet-34.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2636" target="_blank">00:43:56.480</a></span> | <span class="t">In most cases, they have this specific older-style architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2641" target="_blank">00:44:01.040</a></span> | <span class="t">But like I said, replace any older-style architecture bits with ResNet bits and life improves,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2646" target="_blank">00:44:06.400</a></span> | <span class="t">particularly if they're pre-trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2648" target="_blank">00:44:08.440</a></span> | <span class="t">So that certainly happened for us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2649" target="_blank">00:44:09.880</a></span> | <span class="t">So we start with our encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2651" target="_blank">00:44:11.080</a></span> | <span class="t">So our layers of our unit is an encoder, then batch norm, then ReLU, and then middle conv,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2657" target="_blank">00:44:17.880</a></span> | <span class="t">which is just conv layer, comma, conv layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2660" target="_blank">00:44:20.920</a></span> | <span class="t">Remember conv layer is a conv ReLU batch norm in FastAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2666" target="_blank">00:44:26.680</a></span> | <span class="t">And so the middle conv is these two extra steps here at the bottom, just doing a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2673" target="_blank">00:44:33.360</a></span> | <span class="t">of computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2674" target="_blank">00:44:34.360</a></span> | <span class="t">It's kind of nice to add more layers of computation where you can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2678" target="_blank">00:44:38.960</a></span> | <span class="t">So encoder, batch norm, ReLU, and then two convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2682" target="_blank">00:44:42.120</a></span> | <span class="t">And then we enumerate through these indexes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2685" target="_blank">00:44:45.960</a></span> | <span class="t">What are these indexes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2686" target="_blank">00:44:46.960</a></span> | <span class="t">I haven't included the code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2688" target="_blank">00:44:48.160</a></span> | <span class="t">But these are basically -- we figure out what is the layer number where each of these strived</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2695" target="_blank">00:44:55.280</a></span> | <span class="t">two convs occurs, and we just store it in an array of indexes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2699" target="_blank">00:44:59.480</a></span> | <span class="t">So then we can loop through that, and we can basically say for each one of those points,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2704" target="_blank">00:45:04.600</a></span> | <span class="t">create a unit block, telling us how many up-sampling channels there are and how many cross-connection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2711" target="_blank">00:45:11.400</a></span> | <span class="t">These things here are called cross-connections, or at least that's what I call them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2716" target="_blank">00:45:16.920</a></span> | <span class="t">So that's really the main works going on in the unit block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2722" target="_blank">00:45:22.720</a></span> | <span class="t">As I said, there's quite a few tweaks we do, as well as the fact we use a much better encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2727" target="_blank">00:45:27.280</a></span> | <span class="t">We also use some tweaks in all of our up-sampling using this pixel shuffle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2731" target="_blank">00:45:31.440</a></span> | <span class="t">We use another tweak called ICNR.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2734" target="_blank">00:45:34.200</a></span> | <span class="t">And then another tweak, which I just did in the last week, is to not just take the result</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2739" target="_blank">00:45:39.040</a></span> | <span class="t">of the convolutions and pass it across, but we actually grab the input pixels and make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2743" target="_blank">00:45:43.760</a></span> | <span class="t">them another cross-connection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2745" target="_blank">00:45:45.720</a></span> | <span class="t">That's what this last cross is here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2748" target="_blank">00:45:48.000</a></span> | <span class="t">You can see we're literally appending a res block with the original inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2752" target="_blank">00:45:52.880</a></span> | <span class="t">So you can see our merge layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2757" target="_blank">00:45:57.000</a></span> | <span class="t">So really all the work's going on in unit block, and unit block has to store the activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2765" target="_blank">00:46:05.720</a></span> | <span class="t">at each of these down-sampling points.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2768" target="_blank">00:46:08.120</a></span> | <span class="t">And the way to do that, as we learned in the last lesson, is with hooks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2773" target="_blank">00:46:13.140</a></span> | <span class="t">So we put hooks into the ResNet-34 to store the activations each time there's a Strive2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2780" target="_blank">00:46:20.920</a></span> | <span class="t">conv.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2781" target="_blank">00:46:21.920</a></span> | <span class="t">And so you can see here we grab the hook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2785" target="_blank">00:46:25.760</a></span> | <span class="t">And we grab the result of the stored value in that hook, and we literally just go torch.cat,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2792" target="_blank">00:46:32.120</a></span> | <span class="t">so we concatenate the up-sampled convolution with the result of the hook, which we chuck</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2804" target="_blank">00:46:44.440</a></span> | <span class="t">through batch norm, and then we do two convolutions to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2808" target="_blank">00:46:48.560</a></span> | <span class="t">And actually, you know, something you could play with at home is pretty obvious here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2813" target="_blank">00:46:53.640</a></span> | <span class="t">Any time you see two convolutions like this, there's an obvious question is, what if we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2816" target="_blank">00:46:56.800</a></span> | <span class="t">used a ResNet block instead?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2819" target="_blank">00:46:59.020</a></span> | <span class="t">So you could try replacing those two comms with a ResNet block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2822" target="_blank">00:47:02.420</a></span> | <span class="t">You might find you get even better results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2824" target="_blank">00:47:04.000</a></span> | <span class="t">And then the kind of things I look for when I look at an architecture is like, oh, two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2828" target="_blank">00:47:08.840</a></span> | <span class="t">comms in a row probably should be a ResNet block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2834" target="_blank">00:47:14.720</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2836" target="_blank">00:47:16.260</a></span> | <span class="t">So that's UNET, and it's amazing to think it preceded ResNet, it preceded DenseNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2849" target="_blank">00:47:29.240</a></span> | <span class="t">It wasn't even published in a major machine learning venue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2852" target="_blank">00:47:32.640</a></span> | <span class="t">It was actually published in MICHI, which is a specialized medical image computing conference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2859" target="_blank">00:47:39.600</a></span> | <span class="t">For years, actually, it was largely unknown outside of the medical imaging community.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2864" target="_blank">00:47:44.420</a></span> | <span class="t">And actually, what happened was Kaggle competitions for segmentation kept on being easily won</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2871" target="_blank">00:47:51.240</a></span> | <span class="t">by people using UNETs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2872" target="_blank">00:47:52.240</a></span> | <span class="t">And that was the first time I saw it getting noticed outside the medical imaging community.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2876" target="_blank">00:47:56.080</a></span> | <span class="t">And then, gradually, a few people in the academic machine learning community started noticing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2880" target="_blank">00:48:00.480</a></span> | <span class="t">and now everybody loves UNET, which I'm glad, because it's just awesome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2889" target="_blank">00:48:09.320</a></span> | <span class="t">So identity connections, regardless of whether they're a plus style or a concat style, are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2898" target="_blank">00:48:18.880</a></span> | <span class="t">incredibly useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2900" target="_blank">00:48:20.120</a></span> | <span class="t">They can basically get us close to the state of the art on lots of important tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2907" target="_blank">00:48:27.680</a></span> | <span class="t">So I want to use them on another task now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2911" target="_blank">00:48:31.440</a></span> | <span class="t">And so the next task I want to look at is image restoration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2916" target="_blank">00:48:36.120</a></span> | <span class="t">So image restoration refers to starting with an image, and this time, we're not going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2921" target="_blank">00:48:41.240</a></span> | <span class="t">create a segmentation mask, but we're going to try and create a better image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2927" target="_blank">00:48:47.440</a></span> | <span class="t">And there's lots of versions of better-- there could be different image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2930" target="_blank">00:48:50.680</a></span> | <span class="t">So the kind of things we can do with this image generation would be take a low res image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2935" target="_blank">00:48:55.800</a></span> | <span class="t">make it high res, take a black and white image, make it color, take an image where something's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2941" target="_blank">00:49:01.480</a></span> | <span class="t">being cut out of it and try and replace the cut out thing, take a photo and try and turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2947" target="_blank">00:49:07.160</a></span> | <span class="t">it into what looks like a line drawing, take a photo and try and make it look like a Monet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2951" target="_blank">00:49:11.240</a></span> | <span class="t">painting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2952" target="_blank">00:49:12.240</a></span> | <span class="t">These are all examples of kind of image to image generation tasks, which you'll know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2955" target="_blank">00:49:15.840</a></span> | <span class="t">how to do after this part of the class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2961" target="_blank">00:49:21.040</a></span> | <span class="t">So in our case, we're going to try to do image restoration, which is going to start with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2967" target="_blank">00:49:27.600</a></span> | <span class="t">low resolution, poor quality JPEGs with writing written over the top of them, and get them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2975" target="_blank">00:49:35.520</a></span> | <span class="t">to replace them with high resolution, good quality pictures in which the text has been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2981" target="_blank">00:49:41.240</a></span> | <span class="t">removed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2985" target="_blank">00:49:45.440</a></span> | <span class="t">Two questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2986" target="_blank">00:49:46.440</a></span> | <span class="t">OK, let's go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=2991" target="_blank">00:49:51.680</a></span> | <span class="t">Why do you concat before calling conv2, conv1, not after?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3000" target="_blank">00:50:00.320</a></span> | <span class="t">Because if you did conv1-- if you did your comms before you concat, then there's no way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3006" target="_blank">00:50:06.440</a></span> | <span class="t">for the channels of the two parts to interact with each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3011" target="_blank">00:50:11.240</a></span> | <span class="t">You don't get any-- so remember, in a 2D conv, it's really 3D, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3018" target="_blank">00:50:18.320</a></span> | <span class="t">It's moving across two dimensions, but in each case, it's doing a dot product of all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3025" target="_blank">00:50:25.720</a></span> | <span class="t">three dimensions of a rank 3 tensor, row by column by channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3030" target="_blank">00:50:30.440</a></span> | <span class="t">So generally speaking, we want as much interaction as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3035" target="_blank">00:50:35.000</a></span> | <span class="t">We want to say this part of the downsampling path and this part of the upsampling path,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3040" target="_blank">00:50:40.520</a></span> | <span class="t">if you look at the combination of them, you find these interesting things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3043" target="_blank">00:50:43.480</a></span> | <span class="t">So generally, you want to have as many interactions going on as possible in each computation that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3051" target="_blank">00:50:51.120</a></span> | <span class="t">you do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3055" target="_blank">00:50:55.480</a></span> | <span class="t">How does concatenating every layer together in a dense net work when the size of the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3059" target="_blank">00:50:59.960</a></span> | <span class="t">feature maps is changing through the layers?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3066" target="_blank">00:51:06.760</a></span> | <span class="t">That's a great question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3067" target="_blank">00:51:07.760</a></span> | <span class="t">So, if you have a stride 2 conv, you can't keep dense netting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3074" target="_blank">00:51:14.920</a></span> | <span class="t">That's what actually happens in a dense net, is you kind of go like dense block growing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3079" target="_blank">00:51:19.040</a></span> | <span class="t">dense block growing, dense block growing, so you're getting more and more channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3082" target="_blank">00:51:22.000</a></span> | <span class="t">And then you do a stride 2 conv without a dense block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3087" target="_blank">00:51:27.360</a></span> | <span class="t">And so now, it's kind of gone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3089" target="_blank">00:51:29.600</a></span> | <span class="t">And then you just do a few more dense blocks and then it's gone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3092" target="_blank">00:51:32.280</a></span> | <span class="t">So in practice, a dense block doesn't actually keep all the information all the way through,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3098" target="_blank">00:51:38.920</a></span> | <span class="t">but just up into every one of these stride 2 convs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3105" target="_blank">00:51:45.400</a></span> | <span class="t">And there's kind of various ways of doing these bottlenecking layers where you're basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3108" target="_blank">00:51:48.880</a></span> | <span class="t">saying, hey, let's reset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3112" target="_blank">00:51:52.160</a></span> | <span class="t">It also helps us keep memory under control because at that point we can decide how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3115" target="_blank">00:51:55.320</a></span> | <span class="t">channels we actually want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3118" target="_blank">00:51:58.320</a></span> | <span class="t">Good questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3119" target="_blank">00:51:59.320</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3120" target="_blank">00:52:00.320</a></span> | <span class="t">So, in order to create something which can turn crappy images into nice images, we need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3129" target="_blank">00:52:09.960</a></span> | <span class="t">a data set containing nice versions of images and crappy versions of the same images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3135" target="_blank">00:52:15.080</a></span> | <span class="t">So the easiest way to do that is to start with some nice images and Crapify them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3140" target="_blank">00:52:20.000</a></span> | <span class="t">And so the way to Crapify them is to create a function called Crapify, which contains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3144" target="_blank">00:52:24.680</a></span> | <span class="t">your Crapification logic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3147" target="_blank">00:52:27.200</a></span> | <span class="t">So my Crapification logic, you can pick your own, is that I open up my nice image, I resize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3154" target="_blank">00:52:34.360</a></span> | <span class="t">it to be really small, 96 by 96 pixels, with bilinear interpolation, I then pick a random</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3162" target="_blank">00:52:42.400</a></span> | <span class="t">number between 10 and 70, I draw that number into my image at some random location, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3171" target="_blank">00:52:51.720</a></span> | <span class="t">then I save that image with a JPEG quality of that random number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3176" target="_blank">00:52:56.760</a></span> | <span class="t">And a JPEG quality of 10 is like absolute rubbish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3181" target="_blank">00:53:01.840</a></span> | <span class="t">A JPEG quality of 70 is not bad at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3186" target="_blank">00:53:06.120</a></span> | <span class="t">So I end up with high quality images, low quality images that look something like these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3195" target="_blank">00:53:15.340</a></span> | <span class="t">And so you can see this one, you know, there's the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3198" target="_blank">00:53:18.760</a></span> | <span class="t">And this is after transformations, that's why it's been flipped.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3202" target="_blank">00:53:22.520</a></span> | <span class="t">And you won't always see the image because we're zooming into them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3206" target="_blank">00:53:26.360</a></span> | <span class="t">So a lot of the time the image is cropped out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3210" target="_blank">00:53:30.600</a></span> | <span class="t">So yeah, it's trying to figure out how to take this incredibly JPEG artifacty thing with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3214" target="_blank">00:53:34.800</a></span> | <span class="t">text written over the top and turn it into this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3218" target="_blank">00:53:38.240</a></span> | <span class="t">So I'm using the Oxford Pets dataset, again, the same one we used in lesson one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3223" target="_blank">00:53:43.220</a></span> | <span class="t">So there's nothing more high quality than pictures of dogs and cats, I think we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3226" target="_blank">00:53:46.360</a></span> | <span class="t">all agree with that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3229" target="_blank">00:53:49.400</a></span> | <span class="t">The Crapification process can take a while, but fast.ai has a function called parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3236" target="_blank">00:53:56.200</a></span> | <span class="t">And if you pass parallel a function name and a list of things to run that function on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3241" target="_blank">00:54:01.580</a></span> | <span class="t">it will run that function on them all in parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3245" target="_blank">00:54:05.320</a></span> | <span class="t">So this actually can run pretty quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3252" target="_blank">00:54:12.040</a></span> | <span class="t">The way you write this function is where you get to do all the interesting stuff in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3256" target="_blank">00:54:16.160</a></span> | <span class="t">assignment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3259" target="_blank">00:54:19.000</a></span> | <span class="t">Try and think of an interesting Crapification which does something that you want to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3263" target="_blank">00:54:23.240</a></span> | <span class="t">So if you want to colorize black and white images, you would replace it with black and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3268" target="_blank">00:54:28.100</a></span> | <span class="t">white.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3269" target="_blank">00:54:29.100</a></span> | <span class="t">If you want something which can take large cut out blocks of image and replace them with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3275" target="_blank">00:54:35.820</a></span> | <span class="t">hallucinated image, add a big black box to these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3280" target="_blank">00:54:40.600</a></span> | <span class="t">If you want something which can take old family photo scans that have been folded up and have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3285" target="_blank">00:54:45.400</a></span> | <span class="t">crinkles in, try and find a way of adding dust prints and crinkles and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3292" target="_blank">00:54:52.040</a></span> | <span class="t">Something that you don't include in Crapify, your model won't learn to fix because every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3298" target="_blank">00:54:58.960</a></span> | <span class="t">time it sees that in your photos, the input and output will be the same, so it won't consider</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3302" target="_blank">00:55:02.960</a></span> | <span class="t">that to be something worthy of fixing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3309" target="_blank">00:55:09.760</a></span> | <span class="t">So we now want to create a model which can take an input photo that looks like that and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3317" target="_blank">00:55:17.480</a></span> | <span class="t">output something that looks like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3319" target="_blank">00:55:19.840</a></span> | <span class="t">So obviously what we want to do is use a unit, because we already know that units can do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3324" target="_blank">00:55:24.080</a></span> | <span class="t">exactly that kind of thing, and we just need to pass the unit that data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3330" target="_blank">00:55:30.480</a></span> | <span class="t">So our data is just literally the file names from each of those two folders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3337" target="_blank">00:55:37.600</a></span> | <span class="t">Do some transforms, databunch, normalize, or use ImageNet stats because we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3343" target="_blank">00:55:43.240</a></span> | <span class="t">to use a pre-trained model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3345" target="_blank">00:55:45.380</a></span> | <span class="t">Why are we using a pre-trained model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3346" target="_blank">00:55:46.960</a></span> | <span class="t">Well, because like if you're going to get rid of this 46, you need to know what probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3352" target="_blank">00:55:52.080</a></span> | <span class="t">was there, and to know what probably was there, you need to know what this is a picture of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3355" target="_blank">00:55:55.880</a></span> | <span class="t">Because otherwise, how can you possibly know what it ought to look like?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3359" target="_blank">00:55:59.080</a></span> | <span class="t">So let's use a pre-trained model that knows about these kinds of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3364" target="_blank">00:56:04.620</a></span> | <span class="t">So we create our unit with that data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3367" target="_blank">00:56:07.400</a></span> | <span class="t">The architecture is ResNet 34.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3372" target="_blank">00:56:12.720</a></span> | <span class="t">These three things are important and interesting and useful, but I'm going to leave them to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3377" target="_blank">00:56:17.080</a></span> | <span class="t">part two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3378" target="_blank">00:56:18.460</a></span> | <span class="t">For now, you should always include them when you use a unit for this kind of problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3386" target="_blank">00:56:26.920</a></span> | <span class="t">And so now we're going to-- and this whole thing I'm calling a generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3390" target="_blank">00:56:30.200</a></span> | <span class="t">It's going to generate-- this is generative modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3394" target="_blank">00:56:34.320</a></span> | <span class="t">There's not a really formal definition, but it's basically something where the thing we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3397" target="_blank">00:56:37.280</a></span> | <span class="t">outputting is like a real object, in this case, an image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3401" target="_blank">00:56:41.640</a></span> | <span class="t">It's not just a number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3404" target="_blank">00:56:44.000</a></span> | <span class="t">So we're going to create a generator learner, which is this unit learner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3409" target="_blank">00:56:49.280</a></span> | <span class="t">And then we can fit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3411" target="_blank">00:56:51.480</a></span> | <span class="t">We're using MSC loss, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3413" target="_blank">00:56:53.480</a></span> | <span class="t">So in other words, what's the mean squared error between the actual pixel value that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3417" target="_blank">00:56:57.360</a></span> | <span class="t">it should be and the pixel value that we predicted?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3419" target="_blank">00:56:59.760</a></span> | <span class="t">MSC loss normally expects two vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3424" target="_blank">00:57:04.280</a></span> | <span class="t">In our case, we have two images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3426" target="_blank">00:57:06.300</a></span> | <span class="t">So we have a version called MSC loss flat, which simply flattens out those images into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3431" target="_blank">00:57:11.240</a></span> | <span class="t">a big long vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3433" target="_blank">00:57:13.860</a></span> | <span class="t">There's never any reason not to use this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3435" target="_blank">00:57:15.860</a></span> | <span class="t">Even if you do have a vector, it works fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3437" target="_blank">00:57:17.360</a></span> | <span class="t">If you don't have a vector, it'll also work fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3440" target="_blank">00:57:20.340</a></span> | <span class="t">So we're already down to 0.05 mean squared error on the pixel values, which is not bad,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3446" target="_blank">00:57:26.720</a></span> | <span class="t">after 1 minute 35.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3449" target="_blank">00:57:29.540</a></span> | <span class="t">Like all things in fast AI, pretty much, because we are doing transfer learning by default,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3454" target="_blank">00:57:34.680</a></span> | <span class="t">when you create this, it'll freeze the pre-trained part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3460" target="_blank">00:57:40.200</a></span> | <span class="t">And the pre-trained part of a unit is this part, the down sampling part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3466" target="_blank">00:57:46.000</a></span> | <span class="t">That's where the resonant is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3467" target="_blank">00:57:47.220</a></span> | <span class="t">So let's unfreeze that and train a little more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3473" target="_blank">00:57:53.760</a></span> | <span class="t">And look at that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3475" target="_blank">00:57:55.620</a></span> | <span class="t">So with four minutes of training, we've got something which is basically doing a perfect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3483" target="_blank">00:58:03.800</a></span> | <span class="t">job of removing numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3487" target="_blank">00:58:07.600</a></span> | <span class="t">It's certainly not doing a good job of up sampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3493" target="_blank">00:58:13.120</a></span> | <span class="t">But it's definitely doing a nice-- sometimes when it removes a number, it maybe leaves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3496" target="_blank">00:58:16.680</a></span> | <span class="t">a little bit of JPEG artifact.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3498" target="_blank">00:58:18.360</a></span> | <span class="t">But it's certainly doing something pretty useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3501" target="_blank">00:58:21.120</a></span> | <span class="t">And so if all we wanted to do was kind of watermark removal, we'd be finished.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3508" target="_blank">00:58:28.320</a></span> | <span class="t">We're not finished, because we actually want this thing to look more like this thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3514" target="_blank">00:58:34.920</a></span> | <span class="t">So how are we going to do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3518" target="_blank">00:58:38.600</a></span> | <span class="t">The problem, the reason that we're not making as much progress with that as we'd like is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3523" target="_blank">00:58:43.400</a></span> | <span class="t">that our loss function doesn't really describe what we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3527" target="_blank">00:58:47.160</a></span> | <span class="t">Because actually, the mean squared error between the pixels of this and this is actually very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3533" target="_blank">00:58:53.680</a></span> | <span class="t">small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3534" target="_blank">00:58:54.680</a></span> | <span class="t">And if you actually think about it, most of the pixels are very nearly the right color.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3539" target="_blank">00:58:59.920</a></span> | <span class="t">But we're missing the texture of the pillow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3542" target="_blank">00:59:02.520</a></span> | <span class="t">And we're missing the eyeballs entirely, pretty much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3545" target="_blank">00:59:05.880</a></span> | <span class="t">And we're missing the texture of the fur.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3548" target="_blank">00:59:08.800</a></span> | <span class="t">So we want some loss function that does a better job than pixel mean squared error loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3556" target="_blank">00:59:16.880</a></span> | <span class="t">of saying like, is this a good quality picture of this thing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3563" target="_blank">00:59:23.660</a></span> | <span class="t">So there's a fairly general way of answering that question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3569" target="_blank">00:59:29.560</a></span> | <span class="t">And it's something called a generative adversarial network, or GaN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3576" target="_blank">00:59:36.720</a></span> | <span class="t">And a GaN tries to solve this problem by using a loss function which actually calls another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3584" target="_blank">00:59:44.880</a></span> | <span class="t">model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3586" target="_blank">00:59:46.320</a></span> | <span class="t">And let me describe it to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3592" target="_blank">00:59:52.760</a></span> | <span class="t">So we've got our crappy image, and we've already created a generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3597" target="_blank">00:59:57.520</a></span> | <span class="t">It's not a great one, but it's not terrible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3599" target="_blank">00:59:59.960</a></span> | <span class="t">And that's creating predictions like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3608" target="_blank">01:00:08.160</a></span> | <span class="t">We have a high res image like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3612" target="_blank">01:00:12.220</a></span> | <span class="t">And we can compare the high res image to the prediction with pixel MSE.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3620" target="_blank">01:00:20.000</a></span> | <span class="t">We could also train another model, which we would variously call either the discriminator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3626" target="_blank">01:00:26.600</a></span> | <span class="t">or the critic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3627" target="_blank">01:00:27.600</a></span> | <span class="t">They both mean the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3628" target="_blank">01:00:28.960</a></span> | <span class="t">I'll call it a critic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3631" target="_blank">01:00:31.120</a></span> | <span class="t">We could try and build a binary classification model that takes all the pairs of the generated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3637" target="_blank">01:00:37.680</a></span> | <span class="t">image and the real high res image and tries to classify, learn to classify, which is which.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3645" target="_blank">01:00:45.360</a></span> | <span class="t">So look at some picture and say like, hey, what do you think?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3650" target="_blank">01:00:50.320</a></span> | <span class="t">Is that a high res cat or is that a generated cat?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3652" target="_blank">01:00:52.720</a></span> | <span class="t">How about this one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3653" target="_blank">01:00:53.720</a></span> | <span class="t">Is that a high res cat or a generated cat?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3655" target="_blank">01:00:55.200</a></span> | <span class="t">So just a regular standard binary cross-entropy classifier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3661" target="_blank">01:01:01.300</a></span> | <span class="t">So we know how to do that already.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3664" target="_blank">01:01:04.480</a></span> | <span class="t">So if we had one of those, we could now fine-tune the generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3671" target="_blank">01:01:11.580</a></span> | <span class="t">And rather than using pixel MSE as the loss, the loss could be how good are we at fooling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3678" target="_blank">01:01:18.060</a></span> | <span class="t">the critic?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3679" target="_blank">01:01:19.840</a></span> | <span class="t">So can we create generated images that the critic thinks are real?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3687" target="_blank">01:01:27.720</a></span> | <span class="t">So that would be a very good plan, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3690" target="_blank">01:01:30.840</a></span> | <span class="t">Because if it can do that, if the loss function is am I fooling the critic, then it's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3696" target="_blank">01:01:36.840</a></span> | <span class="t">to learn to create images which the critic can't tell whether they're real or fake.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3703" target="_blank">01:01:43.760</a></span> | <span class="t">So we could do that for a while, train a few batches, but the critic isn't that great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3712" target="_blank">01:01:52.280</a></span> | <span class="t">The reason the critic isn't that great is because it wasn't that hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3715" target="_blank">01:01:55.160</a></span> | <span class="t">Like these images are really shitty, so it's really easy to tell the difference, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3719" target="_blank">01:01:59.320</a></span> | <span class="t">So after we train the generator a little bit more using the critic as the loss function,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3725" target="_blank">01:02:05.680</a></span> | <span class="t">the generator is going to get really good at fooling the critic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3729" target="_blank">01:02:09.600</a></span> | <span class="t">So now we're going to stop training the generator and we'll train the critic some more on these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3734" target="_blank">01:02:14.560</a></span> | <span class="t">newly generated images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3736" target="_blank">01:02:16.800</a></span> | <span class="t">So now that the generator's better, it's now a tougher task for the critic to decide which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3741" target="_blank">01:02:21.600</a></span> | <span class="t">is real and which is fake, so we'll train that a little bit more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3745" target="_blank">01:02:25.880</a></span> | <span class="t">And then once we've done that, and the critic's now pretty good at recognising the difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3749" target="_blank">01:02:29.040</a></span> | <span class="t">between the better generated images and the originals, we'll go back and we'll fine-tune</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3754" target="_blank">01:02:34.480</a></span> | <span class="t">the generator some more using the better discriminator, the better critic, as the loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3760" target="_blank">01:02:40.040</a></span> | <span class="t">And so we'll just go ping pong, ping pong, backwards and forwards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3764" target="_blank">01:02:44.360</a></span> | <span class="t">That's a GAN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3765" target="_blank">01:02:45.360</a></span> | <span class="t">Well, that's our version of a GAN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3769" target="_blank">01:02:49.080</a></span> | <span class="t">I don't know if anybody's written this before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3772" target="_blank">01:02:52.840</a></span> | <span class="t">We've created a new version of a GAN, which is kind of a lot like the original GANs, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3777" target="_blank">01:02:57.840</a></span> | <span class="t">we have this neat trick where we pre-train the generator and we pre-train the critic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3783" target="_blank">01:03:03.920</a></span> | <span class="t">I mean, GANs have been kind of in the news a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3787" target="_blank">01:03:07.280</a></span> | <span class="t">They're a pretty fashionable tool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3789" target="_blank">01:03:09.460</a></span> | <span class="t">And if you've seen them, you may have heard that they're a real pain to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3794" target="_blank">01:03:14.900</a></span> | <span class="t">But it turns out we realise that really most of the pain of training them was at the start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3800" target="_blank">01:03:20.160</a></span> | <span class="t">If you don't have a pre-trained generator and you don't have a pre-trained critic, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3804" target="_blank">01:03:24.280</a></span> | <span class="t">it's basically the blind leading the blind, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3807" target="_blank">01:03:27.720</a></span> | <span class="t">You're basically like the critics, well, the generator's trying to generate something which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3811" target="_blank">01:03:31.300</a></span> | <span class="t">falls a critic, but the critic doesn't know anything at all, so it's basically got nothing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3814" target="_blank">01:03:34.760</a></span> | <span class="t">to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3815" target="_blank">01:03:35.760</a></span> | <span class="t">And then the critics kind of try to decide whether the generated images are real or not,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3819" target="_blank">01:03:39.000</a></span> | <span class="t">and that gets really obvious, so that just does it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3821" target="_blank">01:03:41.320</a></span> | <span class="t">And so they kind of like don't go anywhere for ages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3826" target="_blank">01:03:46.360</a></span> | <span class="t">And then once they finally start picking up steam, they go along pretty quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3830" target="_blank">01:03:50.420</a></span> | <span class="t">So if you can find a way to generate things without using a GAN, like mean squared error</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3836" target="_blank">01:03:56.800</a></span> | <span class="t">pixel loss, and discriminate things without using a GAN, like predict on that first generator,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3843" target="_blank">01:04:03.360</a></span> | <span class="t">you can make a lot of progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3845" target="_blank">01:04:05.040</a></span> | <span class="t">So let's create the critic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3848" target="_blank">01:04:08.040</a></span> | <span class="t">So to create just a totally standard fast.ai binary classification model, we need two folders,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3855" target="_blank">01:04:15.760</a></span> | <span class="t">one folder containing high-res images, one folder containing generated images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3860" target="_blank">01:04:20.680</a></span> | <span class="t">We already have the folder with the high-res images, so we just have to save our generated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3864" target="_blank">01:04:24.480</a></span> | <span class="t">images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3866" target="_blank">01:04:26.180</a></span> | <span class="t">So here's a tiny, tiny bit of code that does that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3870" target="_blank">01:04:30.400</a></span> | <span class="t">We're going to create a directory called imagegen, pop it into a variable called pathgen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3877" target="_blank">01:04:37.560</a></span> | <span class="t">We've got a little function called save preds that takes a data loader, and we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3881" target="_blank">01:04:41.960</a></span> | <span class="t">to grab all of the file names, because remember that in an item list, the dot items contains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3886" target="_blank">01:04:46.960</a></span> | <span class="t">the file names, if it's an image item list.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3890" target="_blank">01:04:50.340</a></span> | <span class="t">So here's the file names in that data loader's data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3895" target="_blank">01:04:55.080</a></span> | <span class="t">And so now let's go through each batch of the data loader, and let's grab a batch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3900" target="_blank">01:05:00.640</a></span> | <span class="t">predictions for that batch, and then reconstruct equals true, means it's actually going to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3906" target="_blank">01:05:06.680</a></span> | <span class="t">fast.ai image objects for each of those, each thing in the batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3912" target="_blank">01:05:12.000</a></span> | <span class="t">And so then we'll go through each of those predictions and save them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3916" target="_blank">01:05:16.000</a></span> | <span class="t">And the name we'll save it with is the name of the original file, but we're going to pop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3921" target="_blank">01:05:21.160</a></span> | <span class="t">it into our new directory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3924" target="_blank">01:05:24.160</a></span> | <span class="t">So that's it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3926" target="_blank">01:05:26.880</a></span> | <span class="t">That's how you save predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3928" target="_blank">01:05:28.320</a></span> | <span class="t">And so you can see I'm kind of increasingly not just using stuff that's already in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3933" target="_blank">01:05:33.480</a></span> | <span class="t">fast.ai library, but trying to show you how to write stuff yourself, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3938" target="_blank">01:05:38.400</a></span> | <span class="t">And generally it doesn't require heaps of code to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3941" target="_blank">01:05:41.920</a></span> | <span class="t">And so if you come back to part two, this is what, you know, lots of part two were kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3947" target="_blank">01:05:47.080</a></span> | <span class="t">of like here's how you use things inside the library, and of course here's how we wrote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3951" target="_blank">01:05:51.800</a></span> | <span class="t">the library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3952" target="_blank">01:05:52.800</a></span> | <span class="t">So increasingly writing our own code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3956" target="_blank">01:05:56.240</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3957" target="_blank">01:05:57.520</a></span> | <span class="t">So save those predictions, and then let's just do a PIL.image.open on the first one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3963" target="_blank">01:06:03.800</a></span> | <span class="t">and yep, there it is, okay?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3965" target="_blank">01:06:05.300</a></span> | <span class="t">So there's an example of a generated image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3968" target="_blank">01:06:08.120</a></span> | <span class="t">So now I can train a critic in the usual way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3973" target="_blank">01:06:13.320</a></span> | <span class="t">It's really annoying to have to restart Jupyter Notebook to reclaim GPU memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3978" target="_blank">01:06:18.440</a></span> | <span class="t">So one easy way to handle this is if you just set something that you knew was using a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3982" target="_blank">01:06:22.580</a></span> | <span class="t">of GPU to none, like this learner, and then just go gc.collect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3988" target="_blank">01:06:28.080</a></span> | <span class="t">That tells Python to do memory garbage collection, and after that you'll generally be fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=3996" target="_blank">01:06:36.920</a></span> | <span class="t">You'll be able to use all of your GPU memory again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4000" target="_blank">01:06:40.340</a></span> | <span class="t">If you're using Nvidia SMI to actually look at your GPU memory, you won't see it clear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4005" target="_blank">01:06:45.620</a></span> | <span class="t">because PyTorch still has a kind of allocated cache, but it makes it available.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4011" target="_blank">01:06:51.700</a></span> | <span class="t">So you should find this is how you can avoid restarting your Notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4015" target="_blank">01:06:55.160</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4016" target="_blank">01:06:56.160</a></span> | <span class="t">So we're going to create a critic, it's just an image item list from folder in the totally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4020" target="_blank">01:07:00.520</a></span> | <span class="t">usual way, and the classes will be the image gen and images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4027" target="_blank">01:07:07.960</a></span> | <span class="t">We'll do a random split because we want to know how well we're doing with a critic to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4031" target="_blank">01:07:11.120</a></span> | <span class="t">have a validation set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4032" target="_blank">01:07:12.800</a></span> | <span class="t">We just label it from folder in the usual way, add some transforms, databunch, normalize,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4037" target="_blank">01:07:17.880</a></span> | <span class="t">so it's a totally standard object classifier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4042" target="_blank">01:07:22.280</a></span> | <span class="t">Okay, so we've got a totally standard classifier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4050" target="_blank">01:07:30.040</a></span> | <span class="t">So here's what some of it looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4051" target="_blank">01:07:31.900</a></span> | <span class="t">So here's one from the real images, generated images, generated images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4058" target="_blank">01:07:38.080</a></span> | <span class="t">So it's going to try and figure out which class is which.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4062" target="_blank">01:07:42.720</a></span> | <span class="t">Okay, so we're going to use binary cross-entropy as usual, however, we're not going to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4075" target="_blank">01:07:55.560</a></span> | <span class="t">a ResNet here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4079" target="_blank">01:07:59.200</a></span> | <span class="t">And the reason we'll get into it in more detail in part two, but basically when you're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4083" target="_blank">01:08:03.720</a></span> | <span class="t">a GAN, you need to be particularly careful that the generator and the critic can't kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4094" target="_blank">01:08:14.440</a></span> | <span class="t">of both push in the same direction and increase the weights out of control.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4099" target="_blank">01:08:19.940</a></span> | <span class="t">So we have to use something called spectral normalization to make GANs work nowadays.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4104" target="_blank">01:08:24.720</a></span> | <span class="t">We'll learn about that in part two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4107" target="_blank">01:08:27.400</a></span> | <span class="t">So if you say GAN critic, that will give you a binary classifier suitable for GANs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4114" target="_blank">01:08:34.960</a></span> | <span class="t">I strongly suspect we probably can use a ResNet here, we just have to create a pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4119" target="_blank">01:08:39.320</a></span> | <span class="t">ResNet with spectral norm, hope to do that pretty soon, we'll see how we go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4124" target="_blank">01:08:44.160</a></span> | <span class="t">But as of now, this is kind of the best approach, there's this thing called GAN critic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4131" target="_blank">01:08:51.680</a></span> | <span class="t">And again, critic uses a slightly different way of averaging the different parts of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4141" target="_blank">01:09:01.620</a></span> | <span class="t">image when it does the loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4143" target="_blank">01:09:03.220</a></span> | <span class="t">So any time you're doing a GAN at the moment, you have to wrap your loss function with adaptive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4147" target="_blank">01:09:07.600</a></span> | <span class="t">loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4148" target="_blank">01:09:08.600</a></span> | <span class="t">Again, we'll look at the details in part two, for now, just know this is what you have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4152" target="_blank">01:09:12.480</a></span> | <span class="t">do and it'll work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4154" target="_blank">01:09:14.700</a></span> | <span class="t">So other than that, slightly odd loss function and that slightly odd architecture, everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4159" target="_blank">01:09:19.280</a></span> | <span class="t">else is the same, we can call that to create our critic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4164" target="_blank">01:09:24.080</a></span> | <span class="t">Because we have this slightly different architecture and slightly different loss function, we did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4167" target="_blank">01:09:27.920</a></span> | <span class="t">a slightly different metric, this is the equivalent GAN version of accuracy, the critics, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4174" target="_blank">01:09:34.320</a></span> | <span class="t">then we can train it, and you can see it's 98% accurate at recognizing that kind of crappy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4182" target="_blank">01:09:42.480</a></span> | <span class="t">thing from that kind of nice thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4184" target="_blank">01:09:44.280</a></span> | <span class="t">And of course, we don't see the numbers here anymore, right, because these are the generated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4188" target="_blank">01:09:48.040</a></span> | <span class="t">images, the generator already knows how to get rid of those numbers that are written</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4192" target="_blank">01:09:52.920</a></span> | <span class="t">on top.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4194" target="_blank">01:09:54.600</a></span> | <span class="t">So let's finish up this GAN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4198" target="_blank">01:09:58.160</a></span> | <span class="t">Now that we have pre-trained the generator and pre-trained the critic, we now need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4204" target="_blank">01:10:04.680</a></span> | <span class="t">get it to ping-pong between training a little bit of each.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4208" target="_blank">01:10:08.240</a></span> | <span class="t">And the amount of time you spend on each of those things and the learning rates you use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4214" target="_blank">01:10:14.440</a></span> | <span class="t">is still a little bit on the fussy side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4217" target="_blank">01:10:17.480</a></span> | <span class="t">So we've created a GAN learner for you, which you just pass in your generator and your critic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4227" target="_blank">01:10:27.400</a></span> | <span class="t">which we've just simply loaded here from the ones we just trained, and it will go ahead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4233" target="_blank">01:10:33.800</a></span> | <span class="t">and when you go learn.fit, it will do that for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4237" target="_blank">01:10:37.360</a></span> | <span class="t">It will figure out how much time to train the generator and then when to switch to training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4240" target="_blank">01:10:40.800</a></span> | <span class="t">the discriminator, the critic, and it will go back and forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4245" target="_blank">01:10:45.200</a></span> | <span class="t">These weights here is that what we actually do is we don't only use the critic as the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4250" target="_blank">01:10:50.880</a></span> | <span class="t">loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4251" target="_blank">01:10:51.880</a></span> | <span class="t">If we only use the critic as the loss function, the GAN could get very good at creating pictures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4257" target="_blank">01:10:57.520</a></span> | <span class="t">that look like real pictures, but they actually have nothing to do with the original photo</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4264" target="_blank">01:11:04.860</a></span> | <span class="t">at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4265" target="_blank">01:11:05.860</a></span> | <span class="t">So we actually add together the pixel loss and the critic loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4270" target="_blank">01:11:10.560</a></span> | <span class="t">And so those two losses are kind of on different scales.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4275" target="_blank">01:11:15.240</a></span> | <span class="t">So we multiply the pixel loss by something between about 50 and about 200.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4281" target="_blank">01:11:21.280</a></span> | <span class="t">Again, something in that range generally works pretty well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4287" target="_blank">01:11:27.700</a></span> | <span class="t">Something else with GANs, GANs hate momentum when you're training them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4293" target="_blank">01:11:33.040</a></span> | <span class="t">It kind of doesn't make sense to train them with momentum because you keep switching between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4296" target="_blank">01:11:36.320</a></span> | <span class="t">generator and critic, so it's kind of tough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4299" target="_blank">01:11:39.140</a></span> | <span class="t">Maybe there are ways to use momentum, but I'm not sure anybody's figured it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4303" target="_blank">01:11:43.000</a></span> | <span class="t">This number here, when you create an atom optimizer, is where the momentum goes, so you should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4307" target="_blank">01:11:47.900</a></span> | <span class="t">set that to zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4308" target="_blank">01:11:48.900</a></span> | <span class="t">So anyway, if you're doing GANs, use these hyperparameters, it should work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4320" target="_blank">01:12:00.120</a></span> | <span class="t">So that's what GAN learner does, and so then you can go fit, and it trains for a while.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4325" target="_blank">01:12:05.680</a></span> | <span class="t">And one of the tough things about GANs is that these loss numbers, they're meaningless.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4334" target="_blank">01:12:14.360</a></span> | <span class="t">You can't expect them to go down, because as the generator gets better, it gets harder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4340" target="_blank">01:12:20.040</a></span> | <span class="t">for the discriminator, the critic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4342" target="_blank">01:12:22.720</a></span> | <span class="t">Then as the critic gets better, it gets harder for the generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4345" target="_blank">01:12:25.560</a></span> | <span class="t">So the numbers should stay about the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4351" target="_blank">01:12:31.480</a></span> | <span class="t">So that's one of the tough things about training GANs, is it's kind of hard to know how are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4355" target="_blank">01:12:35.960</a></span> | <span class="t">they doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4356" target="_blank">01:12:36.960</a></span> | <span class="t">So the only way to know how are they doing is to actually take a look at the results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4361" target="_blank">01:12:41.400</a></span> | <span class="t">from time to time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4363" target="_blank">01:12:43.200</a></span> | <span class="t">And so if you put show image equals true here, it will actually print out a sample after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4368" target="_blank">01:12:48.920</a></span> | <span class="t">every epoch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4369" target="_blank">01:12:49.920</a></span> | <span class="t">I haven't put that in the notebook because it makes it too big for the repo, but you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4374" target="_blank">01:12:54.320</a></span> | <span class="t">can try that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4375" target="_blank">01:12:55.680</a></span> | <span class="t">So I've just put the results at the bottom, and here it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4381" target="_blank">01:13:01.000</a></span> | <span class="t">So pretty beautiful, I would say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4385" target="_blank">01:13:05.880</a></span> | <span class="t">We already knew how to get rid of the numbers, but we now don't really have that kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4389" target="_blank">01:13:09.800</a></span> | <span class="t">artifact of where it used to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4392" target="_blank">01:13:12.240</a></span> | <span class="t">And it's definitely sharpening up this little kitty cat quite nicely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4402" target="_blank">01:13:22.000</a></span> | <span class="t">It's not great, always.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4403" target="_blank">01:13:23.720</a></span> | <span class="t">There's some weird kind of noise going on here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4408" target="_blank">01:13:28.560</a></span> | <span class="t">It's certainly a lot better than the horrible original.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4412" target="_blank">01:13:32.320</a></span> | <span class="t">This is a tough job to turn that into that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4416" target="_blank">01:13:36.440</a></span> | <span class="t">But there are some really obvious problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4420" target="_blank">01:13:40.120</a></span> | <span class="t">Like here, these things ought to be eyeballs, and they're not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4426" target="_blank">01:13:46.080</a></span> | <span class="t">So why aren't they?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4428" target="_blank">01:13:48.000</a></span> | <span class="t">Well, our critic doesn't know anything about eyeballs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4432" target="_blank">01:13:52.000</a></span> | <span class="t">And even if it did, it wouldn't know that eyeballs are particularly important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4436" target="_blank">01:13:56.560</a></span> | <span class="t">We care about eyes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4437" target="_blank">01:13:57.760</a></span> | <span class="t">Like when we see a cat without eyes, it's a lot less cute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4442" target="_blank">01:14:02.600</a></span> | <span class="t">I mean, I'm more of a dog person, but it just doesn't know that this is a feature that matters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4458" target="_blank">01:14:18.520</a></span> | <span class="t">Particularly because the critic, remember, is not a pre-trained network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4461" target="_blank">01:14:21.440</a></span> | <span class="t">So I kind of suspect that if we replace the critic with a pre-trained network that's been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4466" target="_blank">01:14:26.160</a></span> | <span class="t">pre-trained on ImageNet but is also compatible with GANs, it might do a better job here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4471" target="_blank">01:14:31.760</a></span> | <span class="t">But it's definitely a shortcoming of this approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4476" target="_blank">01:14:36.880</a></span> | <span class="t">So we're going to have a break.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4479" target="_blank">01:14:39.640</a></span> | <span class="t">Question first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4480" target="_blank">01:14:40.640</a></span> | <span class="t">And then we'll have a break.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4482" target="_blank">01:14:42.120</a></span> | <span class="t">And then after the break, I will show you how to find the cat's eyeballs again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4488" target="_blank">01:14:48.880</a></span> | <span class="t">For what kind of problems do you not want to use UNETs?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4496" target="_blank">01:14:56.480</a></span> | <span class="t">Well, UNETs are for when the size of your output is similar to the size of your input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4505" target="_blank">01:15:05.880</a></span> | <span class="t">and kind of aligned with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4508" target="_blank">01:15:08.880</a></span> | <span class="t">There's no point kind of having cross-connections if that level of spatial resolution in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4513" target="_blank">01:15:13.480</a></span> | <span class="t">output isn't necessary or useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4516" target="_blank">01:15:16.600</a></span> | <span class="t">So any kind of generative modeling and segmentation is generative modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4523" target="_blank">01:15:23.440</a></span> | <span class="t">It's generating a picture which is a mask of the original objects.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4529" target="_blank">01:15:29.840</a></span> | <span class="t">So probably anything where you want that resolution of the output to be of the same kind of fidelity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4537" target="_blank">01:15:37.640</a></span> | <span class="t">as resolution of the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4539" target="_blank">01:15:39.080</a></span> | <span class="t">Obviously, something like a classifier makes no sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4542" target="_blank">01:15:42.160</a></span> | <span class="t">In a classifier, you just want the downsampling path, because at the end, you just want a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4548" target="_blank">01:15:48.160</a></span> | <span class="t">single number, which is like, is it a dog or a cat, or what kind of pet is it, or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4553" target="_blank">01:15:53.760</a></span> | <span class="t">Great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4554" target="_blank">01:15:54.760</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4555" target="_blank">01:15:55.760</a></span> | <span class="t">So let's get back together at 5 past 8.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4560" target="_blank">01:16:00.160</a></span> | <span class="t">Just before we leave GANs, I'll just mention there's another notebook you might be interested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4563" target="_blank">01:16:03.920</a></span> | <span class="t">in looking at, which is lesson 7wGAN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4569" target="_blank">01:16:09.920</a></span> | <span class="t">When GANs started a few years ago, people generally used them to kind of create images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4578" target="_blank">01:16:18.000</a></span> | <span class="t">out of thin air, which I personally don't think is a particularly useful or interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4583" target="_blank">01:16:23.840</a></span> | <span class="t">thing to do, but it's kind of a good, I don't know, it's a good research exercise, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4590" target="_blank">01:16:30.000</a></span> | <span class="t">So we implemented this wGAN paper, which was kind of really the first one to do a somewhat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4596" target="_blank">01:16:36.680</a></span> | <span class="t">adequate job, somewhat easily, and so you can see how to do that with the fast AI library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4603" target="_blank">01:16:43.280</a></span> | <span class="t">It's kind of interesting, because the dataset we use is this Lsun bedrooms dataset, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4611" target="_blank">01:16:51.120</a></span> | <span class="t">we've provided in our URLs, which just, as you can see, has bedrooms, lots and lots and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4617" target="_blank">01:16:57.160</a></span> | <span class="t">lots of bedrooms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4619" target="_blank">01:16:59.560</a></span> | <span class="t">And the approach, you'll see in the pros here that Sylvain wrote, the approach that we use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4628" target="_blank">01:17:08.520</a></span> | <span class="t">in this case is to just say, can we create a bedroom?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4634" target="_blank">01:17:14.160</a></span> | <span class="t">And so what we actually do is that the input to the generator isn't an image that we clean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4642" target="_blank">01:17:22.960</a></span> | <span class="t">up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4643" target="_blank">01:17:23.960</a></span> | <span class="t">We actually feed to the generator random noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4647" target="_blank">01:17:27.820</a></span> | <span class="t">And so then the generator's task is, can you turn random noise into something which the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4653" target="_blank">01:17:33.300</a></span> | <span class="t">critic can't tell the difference between that output and a real bedroom?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4658" target="_blank">01:17:38.860</a></span> | <span class="t">And so we're not doing any pre-training here or any of the stuff that makes this kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4662" target="_blank">01:17:42.360</a></span> | <span class="t">fast and easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4668" target="_blank">01:17:48.360</a></span> | <span class="t">So this is a very traditional approach, but you can still see, you still just go, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4672" target="_blank">01:17:52.200</a></span> | <span class="t">know, gan learner, and there's actually a wGAN version, which is, you know, this kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4676" target="_blank">01:17:56.160</a></span> | <span class="t">of older style approach, but you just pass in the data and the generator and the critic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4680" target="_blank">01:18:00.160</a></span> | <span class="t">in the usual way, and you call fit, and you'll see, in this case we have a show image on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4688" target="_blank">01:18:08.400</a></span> | <span class="t">you know, after epoch one, it's not creating great bedrooms or two or three, and you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4692" target="_blank">01:18:12.720</a></span> | <span class="t">really see that in the early days of these kinds of gans, it doesn't do a great job of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4696" target="_blank">01:18:16.400</a></span> | <span class="t">anything, but eventually after, you know, a couple of hours of training, producing somewhat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4706" target="_blank">01:18:26.440</a></span> | <span class="t">like bedroom-ish things, you know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4709" target="_blank">01:18:29.440</a></span> | <span class="t">So anyway, it's a notebook you can have a play with, and it's a bit of fun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4715" target="_blank">01:18:35.520</a></span> | <span class="t">So I was very excited when we got fast.ai to the point in the last week or so that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4727" target="_blank">01:18:47.720</a></span> | <span class="t">had gans working in a way where kind of API-wise, they're far more concise and more flexible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4733" target="_blank">01:18:53.720</a></span> | <span class="t">than any other library that exists, but also kind of disappointed with they take a long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4739" target="_blank">01:18:59.840</a></span> | <span class="t">time to train, and the outputs are still like so-so, and so the next step was like, well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4744" target="_blank">01:19:04.880</a></span> | <span class="t">can we get rid of gans entirely?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4747" target="_blank">01:19:07.920</a></span> | <span class="t">So the first step with that, I mean, obviously, the thing we really want to do is come up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4752" target="_blank">01:19:12.040</a></span> | <span class="t">with a better loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4753" target="_blank">01:19:13.040</a></span> | <span class="t">We want a loss function that does a good job of saying this is a high-quality image without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4759" target="_blank">01:19:19.480</a></span> | <span class="t">having to go over all the gan trouble, and preferably it also doesn't just say it's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4763" target="_blank">01:19:23.640</a></span> | <span class="t">high-quality image, but it's an image which actually looks like the thing it's meant to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4769" target="_blank">01:19:29.200</a></span> | <span class="t">So the real trick here comes back to this paper from a couple of years ago, perceptual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4773" target="_blank">01:19:33.720</a></span> | <span class="t">losses for real-time style transfer and super resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4777" target="_blank">01:19:37.600</a></span> | <span class="t">Justin Johnson at our, created this thing they call perceptual losses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4782" target="_blank">01:19:42.080</a></span> | <span class="t">It's a nice paper, but I hate this term because they're nothing particularly perceptual about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4787" target="_blank">01:19:47.080</a></span> | <span class="t">them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4788" target="_blank">01:19:48.080</a></span> | <span class="t">I would call them feature losses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4789" target="_blank">01:19:49.080</a></span> | <span class="t">So in the fastai library, you'll see this referred to as feature losses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4793" target="_blank">01:19:53.800</a></span> | <span class="t">And it shares something with gans, which is that after we go through our generator, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4799" target="_blank">01:19:59.920</a></span> | <span class="t">they call the image transform net, and you can see it's got this kind of unit shaped</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4803" target="_blank">01:20:03.720</a></span> | <span class="t">thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4804" target="_blank">01:20:04.720</a></span> | <span class="t">They didn't actually use units because at the time this came out, nobody in the machine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4807" target="_blank">01:20:07.920</a></span> | <span class="t">learning world much knew about units.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4809" target="_blank">01:20:09.800</a></span> | <span class="t">Nowadays, of course, we use units.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4812" target="_blank">01:20:12.960</a></span> | <span class="t">But anyway, something unit-ish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4815" target="_blank">01:20:15.600</a></span> | <span class="t">I should mention, like, in these architectures where you have a downsampling path followed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4821" target="_blank">01:20:21.080</a></span> | <span class="t">by the upsampling path, the downsampling path is very often called the encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4827" target="_blank">01:20:27.000</a></span> | <span class="t">As you saw in our code, actually, we called that the encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4830" target="_blank">01:20:30.200</a></span> | <span class="t">And the upsampling path is very often called the decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4835" target="_blank">01:20:35.080</a></span> | <span class="t">In generative models, generally, including generative text models, neural translation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4841" target="_blank">01:20:41.760</a></span> | <span class="t">stuff like that, they tend to be called the encoder and the decoder, two pieces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4845" target="_blank">01:20:45.880</a></span> | <span class="t">So we have this generator, and we want a loss function that says, you know, is the thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4852" target="_blank">01:20:52.920</a></span> | <span class="t">that it's created like the thing that we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4856" target="_blank">01:20:56.320</a></span> | <span class="t">And so the way they do that is they take the prediction -- remember Y hat is what we normally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4860" target="_blank">01:21:00.680</a></span> | <span class="t">use for a prediction from a model -- we take the prediction and we put it through a pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4866" target="_blank">01:21:06.760</a></span> | <span class="t">image net network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4869" target="_blank">01:21:09.080</a></span> | <span class="t">So at the time that this came out, the pre-trained image network they were using was VGG.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4875" target="_blank">01:21:15.120</a></span> | <span class="t">People still -- it's kind of old now, but people still tend to use it because it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4879" target="_blank">01:21:19.260</a></span> | <span class="t">fine for this process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4883" target="_blank">01:21:23.320</a></span> | <span class="t">So they take the prediction and they put it through VGG, the pre-trained image net network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4888" target="_blank">01:21:28.200</a></span> | <span class="t">It doesn't matter too much which one it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4890" target="_blank">01:21:30.960</a></span> | <span class="t">And so normally the output of that would tell you, hey, is this generated thing, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4896" target="_blank">01:21:36.840</a></span> | <span class="t">a dog or a cat or an airplane or a fire engine or whatever, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4902" target="_blank">01:21:42.200</a></span> | <span class="t">But in the process of getting to that final classification, it goes through lots of different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4906" target="_blank">01:21:46.640</a></span> | <span class="t">layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4907" target="_blank">01:21:47.640</a></span> | <span class="t">And in this case, they've color-coded all the layers with the same grid size in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4912" target="_blank">01:21:52.040</a></span> | <span class="t">feature map with the same color.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4913" target="_blank">01:21:53.640</a></span> | <span class="t">So every time we switch colors, we're switching grid size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4916" target="_blank">01:21:56.520</a></span> | <span class="t">So there's a strive to conv, or in VGG's case they still used to use max pooling layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4921" target="_blank">01:22:01.400</a></span> | <span class="t">which kind of similar idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4924" target="_blank">01:22:04.840</a></span> | <span class="t">And so what we could do is say, hey, let's not take the final output of the VGG model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4930" target="_blank">01:22:10.080</a></span> | <span class="t">on this generated image, but let's take something in the middle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4937" target="_blank">01:22:17.000</a></span> | <span class="t">Let's take the activations of some layer in the middle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4940" target="_blank">01:22:20.960</a></span> | <span class="t">So those activations might be a feature map of like 256 channels by 28 by 28, say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4950" target="_blank">01:22:30.500</a></span> | <span class="t">And so those kind of 28 by 28 grid cells will kind of roughly semantically say things like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4955" target="_blank">01:22:35.280</a></span> | <span class="t">hey, in this part of that 28 by 28 grid, is there something that looks kind of furry?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4960" target="_blank">01:22:40.400</a></span> | <span class="t">Or is there something that looks kind of shiny?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4962" target="_blank">01:22:42.280</a></span> | <span class="t">Or is there something that looks kind of circular?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4963" target="_blank">01:22:43.440</a></span> | <span class="t">Or is there something that kind of looks like an eyeball or whatever?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4967" target="_blank">01:22:47.000</a></span> | <span class="t">So what we do is that we then take the target, so the actual Y value, and we put it through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4973" target="_blank">01:22:53.480</a></span> | <span class="t">the same pre-trained VGG network, and we pull out the activations at the same layer, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4978" target="_blank">01:22:58.040</a></span> | <span class="t">then we do a mean squared error comparison.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4981" target="_blank">01:23:01.000</a></span> | <span class="t">So it'll say, OK, in the real image, grid cell 1, 1 of that 28 by 28 feature map is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4991" target="_blank">01:23:11.760</a></span> | <span class="t">furry and blue and round shaped, and in the generated image, it's furry and blue and not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=4999" target="_blank">01:23:19.320</a></span> | <span class="t">round shaped.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5000" target="_blank">01:23:20.320</a></span> | <span class="t">So it's kind of like an OK match.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5003" target="_blank">01:23:23.620</a></span> | <span class="t">So that ought to go a long way towards fixing our eyeball problem, because in this case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5010" target="_blank">01:23:30.040</a></span> | <span class="t">the feature map is going to say, there's eyeballs here-- sorry, here-- but there isn't here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5016" target="_blank">01:23:36.240</a></span> | <span class="t">So do a better job of that, please.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5018" target="_blank">01:23:38.080</a></span> | <span class="t">Make better eyeballs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5019" target="_blank">01:23:39.580</a></span> | <span class="t">So that's the idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5021" target="_blank">01:23:41.140</a></span> | <span class="t">So that's what we call feature losses, or Johnson et al. called perceptual losses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5032" target="_blank">01:23:52.760</a></span> | <span class="t">So to do that, we're going to use the Lesson 7 Super Res notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5042" target="_blank">01:24:02.800</a></span> | <span class="t">And this time, the task we're going to do is kind of the same as the previous task,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5048" target="_blank">01:24:08.000</a></span> | <span class="t">but I wrote this notebook a little bit before the GAN notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5051" target="_blank">01:24:11.800</a></span> | <span class="t">Before I came up with the idea of putting text on it and having a random JPEG quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5056" target="_blank">01:24:16.260</a></span> | <span class="t">So JPEG quality is always 60.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5058" target="_blank">01:24:18.720</a></span> | <span class="t">There's no text written on top, and it's 96 by 96.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5063" target="_blank">01:24:23.640</a></span> | <span class="t">And it's before I realized what a great word "crapify" is, so it's called resize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5069" target="_blank">01:24:29.100</a></span> | <span class="t">So here's our crappy images and our original images, kind of a similar task to what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5076" target="_blank">01:24:36.600</a></span> | <span class="t">had before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5078" target="_blank">01:24:38.240</a></span> | <span class="t">So I'm going to try and create a loss function which does this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5087" target="_blank">01:24:47.380</a></span> | <span class="t">So the first thing I do is I define a base loss function, which is basically like, how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5094" target="_blank">01:24:54.640</a></span> | <span class="t">am I going to compare the pixels and the features?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5097" target="_blank">01:24:57.240</a></span> | <span class="t">And the choices mainly are like MSE or L1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5102" target="_blank">01:25:02.120</a></span> | <span class="t">Doesn't matter too much, which you choose.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5103" target="_blank">01:25:03.840</a></span> | <span class="t">I tend to like L1 better than MSE, actually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5106" target="_blank">01:25:06.560</a></span> | <span class="t">So I picked L1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5108" target="_blank">01:25:08.240</a></span> | <span class="t">So any time you see base loss, we mean L1 loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5112" target="_blank">01:25:12.320</a></span> | <span class="t">You could use MSE loss as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5115" target="_blank">01:25:15.040</a></span> | <span class="t">So let's create a VGG model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5117" target="_blank">01:25:17.340</a></span> | <span class="t">So just using the pre-trained model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5120" target="_blank">01:25:20.280</a></span> | <span class="t">In VGG, there's an attribute called dot_features, which contains the convolutional part of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5126" target="_blank">01:25:26.200</a></span> | <span class="t">model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5127" target="_blank">01:25:27.200</a></span> | <span class="t">So here's the convolutional part of the VGG model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5130" target="_blank">01:25:30.680</a></span> | <span class="t">Because we don't need the head, because we only want the intermediate activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5135" target="_blank">01:25:35.840</a></span> | <span class="t">So then we'll chuck that on the GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5137" target="_blank">01:25:37.340</a></span> | <span class="t">We'll put it into eval mode, because we're not training it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5141" target="_blank">01:25:41.120</a></span> | <span class="t">And we'll turn off requires_grad, because we don't want to update the weights of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5145" target="_blank">01:25:45.840</a></span> | <span class="t">model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5146" target="_blank">01:25:46.840</a></span> | <span class="t">We're just using it for inference, for the loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5150" target="_blank">01:25:50.840</a></span> | <span class="t">So then let's enumerate through all the children of that model and find all of the max pooling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5155" target="_blank">01:25:55.760</a></span> | <span class="t">layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5156" target="_blank">01:25:56.760</a></span> | <span class="t">Because in the VGG model, that's where the grid size changes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5161" target="_blank">01:26:01.320</a></span> | <span class="t">And as you can see from this picture, we kind of want to grab features from every time just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5167" target="_blank">01:26:07.160</a></span> | <span class="t">before the grid size changes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5169" target="_blank">01:26:09.080</a></span> | <span class="t">So we grab layer i minus 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5171" target="_blank">01:26:11.320</a></span> | <span class="t">So that's the layer before it changes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5173" target="_blank">01:26:13.280</a></span> | <span class="t">So there's our list of layer numbers just before the max pooling layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5181" target="_blank">01:26:21.160</a></span> | <span class="t">And so all of those are values, not surprisingly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5187" target="_blank">01:26:27.200</a></span> | <span class="t">So those are where we want to grab some features from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5191" target="_blank">01:26:31.480</a></span> | <span class="t">So we put that in blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5192" target="_blank">01:26:32.480</a></span> | <span class="t">It's just a list of IDs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5194" target="_blank">01:26:34.360</a></span> | <span class="t">So here's our feature_loss class, which is going to implement this idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5200" target="_blank">01:26:40.140</a></span> | <span class="t">So basically, when we call the feature_loss class, we're going to pass it some pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5206" target="_blank">01:26:46.920</a></span> | <span class="t">model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5207" target="_blank">01:26:47.920</a></span> | <span class="t">And so that's going to be called m_feet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5210" target="_blank">01:26:50.360</a></span> | <span class="t">That's the model which contains the features which we want to generate for-- want our feature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5215" target="_blank">01:26:55.040</a></span> | <span class="t">loss on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5216" target="_blank">01:26:56.160</a></span> | <span class="t">So we can go ahead and grab all of the layers from that network that we want the features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5224" target="_blank">01:27:04.960</a></span> | <span class="t">for to create the losses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5227" target="_blank">01:27:07.760</a></span> | <span class="t">So we're going to need to hook all of those outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5230" target="_blank">01:27:10.360</a></span> | <span class="t">Because remember, that's how we grab intermediate layers in PyTorch is by hooking them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5235" target="_blank">01:27:15.760</a></span> | <span class="t">So this is going to contain our hooked outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5242" target="_blank">01:27:22.160</a></span> | <span class="t">So now, in the forward of feature_loss, we're going to make features passing in the target.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5248" target="_blank">01:27:28.960</a></span> | <span class="t">So this is our actual Y, which is just going to call that VGG model and go through all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5253" target="_blank">01:27:33.760</a></span> | <span class="t">of the stored activations and just grab a copy of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5259" target="_blank">01:27:39.320</a></span> | <span class="t">And so we're going to do that both for the target, call that out_feet, and for the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5263" target="_blank">01:27:43.960</a></span> | <span class="t">So that's the output of a generator in_feet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5268" target="_blank">01:27:48.520</a></span> | <span class="t">And so now, let's calculate the L1 loss between the pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5275" target="_blank">01:27:55.700</a></span> | <span class="t">Because we still want the pixel loss a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5278" target="_blank">01:27:58.140</a></span> | <span class="t">And then let's also go through all of those layers features and get the L1 loss on them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5288" target="_blank">01:28:08.000</a></span> | <span class="t">So we're basically going through every one of these end of each block and grabbing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5294" target="_blank">01:28:14.720</a></span> | <span class="t">activations and getting the L1 on each one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5299" target="_blank">01:28:19.360</a></span> | <span class="t">So that's going to end up in this list called feature_losses, which I then sum them all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5307" target="_blank">01:28:27.380</a></span> | <span class="t">up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5308" target="_blank">01:28:28.880</a></span> | <span class="t">And by the way, the reason I do it as a list is because we've got this nice little callback</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5313" target="_blank">01:28:33.180</a></span> | <span class="t">that if you put them into a thing called .metrics in your loss function, it'll print out all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5318" target="_blank">01:28:38.240</a></span> | <span class="t">of the separate layer loss amounts for you, which is super handy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5326" target="_blank">01:28:46.880</a></span> | <span class="t">So that's it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5327" target="_blank">01:28:47.880</a></span> | <span class="t">That's our perceptual loss or feature_loss class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5331" target="_blank">01:28:51.060</a></span> | <span class="t">And so now we can just go ahead and train a unit in the usual way with our data and our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5335" target="_blank">01:28:55.160</a></span> | <span class="t">pre-trained architecture, which is a ResNet-34, passing in our loss function, which is using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5340" target="_blank">01:29:00.680</a></span> | <span class="t">our pre-trained VGG model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5342" target="_blank">01:29:02.920</a></span> | <span class="t">And this is that callback I mentioned, loss_metrics, which is going to print out all the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5346" target="_blank">01:29:06.880</a></span> | <span class="t">layers losses for us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5349" target="_blank">01:29:09.760</a></span> | <span class="t">These are two things that we'll learn about in part two of the course, but you should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5352" target="_blank">01:29:12.720</a></span> | <span class="t">use them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5353" target="_blank">01:29:13.720</a></span> | <span class="t">LR_find.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5354" target="_blank">01:29:14.720</a></span> | <span class="t">I just created a little function called do_fit that does fit one cycle and then saves the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5360" target="_blank">01:29:20.000</a></span> | <span class="t">model and then shows the results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5363" target="_blank">01:29:23.020</a></span> | <span class="t">So as per usual, because we're using a pre-trained network in our UNet, we start with frozen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5369" target="_blank">01:29:29.240</a></span> | <span class="t">layers for the downsampling path, train for a while, and as you can see, we get not only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5374" target="_blank">01:29:34.720</a></span> | <span class="t">the loss, but also the pixel loss and the loss at each of our feature layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5380" target="_blank">01:29:40.000</a></span> | <span class="t">And then also something we'll learn about in part two called gram_loss, which I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5385" target="_blank">01:29:45.560</a></span> | <span class="t">think anybody's used for SuperRes before as far as I know, but as you'll see, it turns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5390" target="_blank">01:29:50.680</a></span> | <span class="t">out great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5392" target="_blank">01:29:52.160</a></span> | <span class="t">So that's eight minutes, so much faster than a GAN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5395" target="_blank">01:29:55.960</a></span> | <span class="t">And already, as you can see, this is our output, modeled output, pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5401" target="_blank">01:30:01.500</a></span> | <span class="t">So then we unfreeze and train some more, and it's a little bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5407" target="_blank">01:30:07.720</a></span> | <span class="t">And then let's switch up to double the size, and so we need to also halve the batch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5412" target="_blank">01:30:12.360</a></span> | <span class="t">to avoid running a GPU memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5414" target="_blank">01:30:14.880</a></span> | <span class="t">And freeze again and train some more, so it's now taking half an hour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5420" target="_blank">01:30:20.280</a></span> | <span class="t">Even better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5421" target="_blank">01:30:21.680</a></span> | <span class="t">And then unfreeze and train some more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5424" target="_blank">01:30:24.320</a></span> | <span class="t">So all in all, we've done about an hour and 20 minutes of training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5428" target="_blank">01:30:28.800</a></span> | <span class="t">And look at that!</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5431" target="_blank">01:30:31.040</a></span> | <span class="t">It's done it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5433" target="_blank">01:30:33.920</a></span> | <span class="t">It knows that eyes are important, so it's really made an effort.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5436" target="_blank">01:30:36.920</a></span> | <span class="t">It knows that fur is important, so it's really made an effort.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5439" target="_blank">01:30:39.780</a></span> | <span class="t">So it started with something with JPEG artifacts around the ears and all this mess and eyes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5447" target="_blank">01:30:47.920</a></span> | <span class="t">that are just kind of vague, light blue things, and it really created a lot of texture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5453" target="_blank">01:30:53.880</a></span> | <span class="t">This cat is clearly kind of like looking over the top of one of those little clawing frames</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5459" target="_blank">01:30:59.480</a></span> | <span class="t">covered in fuzz, so it actually recognized that this thing is probably kind of a carpety</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5464" target="_blank">01:31:04.440</a></span> | <span class="t">material that's created a carpety material for us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5467" target="_blank">01:31:07.680</a></span> | <span class="t">So I mean, that's just remarkable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5472" target="_blank">01:31:12.080</a></span> | <span class="t">So talking of remarkable, we can now - so I've never seen outputs like this before without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5483" target="_blank">01:31:23.360</a></span> | <span class="t">again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5484" target="_blank">01:31:24.520</a></span> | <span class="t">So I was just so excited when we were able to generate this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5487" target="_blank">01:31:27.400</a></span> | <span class="t">And so quickly, one GPU, hour and a half.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5491" target="_blank">01:31:31.200</a></span> | <span class="t">So if you create your own krapification functions and train this model, you'll build stuff that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5497" target="_blank">01:31:37.120</a></span> | <span class="t">nobody's built before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5498" target="_blank">01:31:38.120</a></span> | <span class="t">Because like nobody else's that I know of is doing it this way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5502" target="_blank">01:31:42.560</a></span> | <span class="t">So there are huge opportunities, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5504" target="_blank">01:31:44.680</a></span> | <span class="t">So check this out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5505" target="_blank">01:31:45.680</a></span> | <span class="t">What we can now do is we can now, instead of starting with our low res, I actually stored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5513" target="_blank">01:31:53.440</a></span> | <span class="t">another set at size 256, which are called medium res.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5517" target="_blank">01:31:57.600</a></span> | <span class="t">So let's see what happens if we upsize a medium res.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5521" target="_blank">01:32:01.560</a></span> | <span class="t">So we're going to grab our medium res data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5525" target="_blank">01:32:05.440</a></span> | <span class="t">And here is our medium res stored photo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5533" target="_blank">01:32:13.040</a></span> | <span class="t">And so can we improve this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5534" target="_blank">01:32:14.480</a></span> | <span class="t">So you can see there's still a lot of room for improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5536" target="_blank">01:32:16.860</a></span> | <span class="t">Like you see the lashes here are very pixelated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5541" target="_blank">01:32:21.920</a></span> | <span class="t">Size where there should be hair here is just kind of fuzzy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5544" target="_blank">01:32:24.880</a></span> | <span class="t">So watch this area as I hit down on my keyboard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5547" target="_blank">01:32:27.880</a></span> | <span class="t">Bump.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5548" target="_blank">01:32:28.880</a></span> | <span class="t">Look at that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5550" target="_blank">01:32:30.360</a></span> | <span class="t">It's done it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5551" target="_blank">01:32:31.360</a></span> | <span class="t">You know, it's taken a medium res image and it's made a totally clear thing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5557" target="_blank">01:32:37.120</a></span> | <span class="t">You know, the furs reappeared.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5558" target="_blank">01:32:38.960</a></span> | <span class="t">Look at the eyeball.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5559" target="_blank">01:32:39.960</a></span> | <span class="t">Let's go back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5561" target="_blank">01:32:41.360</a></span> | <span class="t">The eyeball here is just kind of a general blue thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5566" target="_blank">01:32:46.040</a></span> | <span class="t">Here it's added all the right texture, you know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5569" target="_blank">01:32:49.780</a></span> | <span class="t">So I just think this is super exciting, you know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5574" target="_blank">01:32:54.080</a></span> | <span class="t">Here's a model I trained in an hour and a half using standard stuff that you've all learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5579" target="_blank">01:32:59.840</a></span> | <span class="t">about a unit, a pre-trained model, feature loss function, and we've got something which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5585" target="_blank">01:33:05.680</a></span> | <span class="t">can turn that into that or, you know, this absolute mess into this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5594" target="_blank">01:33:14.680</a></span> | <span class="t">And like it's really exciting to think what could you do with that, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5599" target="_blank">01:33:19.660</a></span> | <span class="t">So one of the inspirations here has been a guy called Jason Antich.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5606" target="_blank">01:33:26.840</a></span> | <span class="t">And Jason was a student in the course last year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5614" target="_blank">01:33:34.160</a></span> | <span class="t">And what he did very sensibly was decide to focus basically nearly quit his job and work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5624" target="_blank">01:33:44.080</a></span> | <span class="t">four days a week or really six days a week on studying deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5627" target="_blank">01:33:47.760</a></span> | <span class="t">And as you should do, he created a kind of capstone project.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5631" target="_blank">01:33:51.240</a></span> | <span class="t">And his project was to combine GANs and feature losses together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5637" target="_blank">01:33:57.320</a></span> | <span class="t">And his crepification approach was to take color pictures and make them black and white.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5645" target="_blank">01:34:05.200</a></span> | <span class="t">So he took the whole of ImageNet, created a black and white ImageNet, and then trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5648" target="_blank">01:34:08.720</a></span> | <span class="t">a model to recolorize it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5650" target="_blank">01:34:10.720</a></span> | <span class="t">And he's put this up as de-oldify.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5652" target="_blank">01:34:12.920</a></span> | <span class="t">And now he's got these actual old photos from the 19th century that he's turning into color.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5660" target="_blank">01:34:20.640</a></span> | <span class="t">And like what this is doing is incredible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5664" target="_blank">01:34:24.520</a></span> | <span class="t">Like look at this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5665" target="_blank">01:34:25.520</a></span> | <span class="t">The model thought, oh, that's probably some kind of copper kettle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5668" target="_blank">01:34:28.340</a></span> | <span class="t">So I'll make it like copper colored.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5670" target="_blank">01:34:30.100</a></span> | <span class="t">And oh, these pictures are on the wall.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5672" target="_blank">01:34:32.240</a></span> | <span class="t">They're probably like different colors to the wall.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5674" target="_blank">01:34:34.720</a></span> | <span class="t">And maybe that looks a bit like a mirror.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5678" target="_blank">01:34:38.200</a></span> | <span class="t">Maybe it would be reflecting stuff outside, you know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5682" target="_blank">01:34:42.720</a></span> | <span class="t">These things might be vegetables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5684" target="_blank">01:34:44.400</a></span> | <span class="t">Vegetables are often red.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5685" target="_blank">01:34:45.400</a></span> | <span class="t">You know, let's make them red.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5688" target="_blank">01:34:48.400</a></span> | <span class="t">It's extraordinary what it's done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5691" target="_blank">01:34:51.600</a></span> | <span class="t">And you could totally do this, too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5693" target="_blank">01:34:53.560</a></span> | <span class="t">Like you can take our feature loss and our GAN loss and combine them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5698" target="_blank">01:34:58.640</a></span> | <span class="t">So I'm very grateful to Jason, because he's helped us build this lesson.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5703" target="_blank">01:35:03.400</a></span> | <span class="t">And it's been really nice, because we've been able to help him, too, because he hadn't realized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5708" target="_blank">01:35:08.520</a></span> | <span class="t">that he can use all this pre-training and stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5710" target="_blank">01:35:10.480</a></span> | <span class="t">And so hopefully you'll see De-oldify in the next couple of weeks be even better at de-oldification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5716" target="_blank">01:35:16.560</a></span> | <span class="t">But hopefully you all can now add other kinds of de-crapification methods as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5723" target="_blank">01:35:23.840</a></span> | <span class="t">So I like every course, if possible, to show something totally new, because then every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5733" target="_blank">01:35:33.600</a></span> | <span class="t">student has a chance to basically build things that have never been built before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5736" target="_blank">01:35:36.920</a></span> | <span class="t">So this is kind of that thing, you know, but between the much better segmentation results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5742" target="_blank">01:35:42.460</a></span> | <span class="t">and these much simpler and faster de-crapification results, I think you can build some really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5747" target="_blank">01:35:47.180</a></span> | <span class="t">cool stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5748" target="_blank">01:35:48.180</a></span> | <span class="t">Did you have a question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5755" target="_blank">01:35:55.040</a></span> | <span class="t">Is it possible to use similar ideas to UNET and GANs for NLP?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5759" target="_blank">01:35:59.960</a></span> | <span class="t">For example, if I want to tag the verbs and nouns in a sentence or create a really good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5763" target="_blank">01:36:03.840</a></span> | <span class="t">Shakespeare generator?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5767" target="_blank">01:36:07.680</a></span> | <span class="t">Yeah, pretty much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5770" target="_blank">01:36:10.120</a></span> | <span class="t">We don't fully know yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5771" target="_blank">01:36:11.920</a></span> | <span class="t">It's a pretty new area, but there's a lot of opportunities there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5775" target="_blank">01:36:15.160</a></span> | <span class="t">And we'll be looking at some in a moment, actually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5784" target="_blank">01:36:24.000</a></span> | <span class="t">So I actually tried training this -- well, I actually tried testing this on this -- remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5790" target="_blank">01:36:30.040</a></span> | <span class="t">this picture I showed you with a slide last lesson?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5793" target="_blank">01:36:33.320</a></span> | <span class="t">And it's a really rubbishy-looking picture, and I thought, what would happen if we tried</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5796" target="_blank">01:36:36.440</a></span> | <span class="t">running this just through the exact same model and it changed it from that to that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5803" target="_blank">01:36:43.720</a></span> | <span class="t">So I thought that was a really good example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5805" target="_blank">01:36:45.480</a></span> | <span class="t">You can see something it didn't do, which is this weird discoloration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5809" target="_blank">01:36:49.280</a></span> | <span class="t">It didn't fix it, because I didn't crepify things with weird discoloration, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5813" target="_blank">01:36:53.520</a></span> | <span class="t">So if you want to create really good image restoration, like I say, you need really good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5817" target="_blank">01:36:57.640</a></span> | <span class="t">crepification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5820" target="_blank">01:37:00.160</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5821" target="_blank">01:37:01.480</a></span> | <span class="t">So here's what we've learned so far, right, in the course, some of the main things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5828" target="_blank">01:37:08.200</a></span> | <span class="t">So we've learned that neural nets consist of sandwich layers of affine functions, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5835" target="_blank">01:37:15.680</a></span> | <span class="t">are basically matrix multiplications, slightly more general version, and nonlinearities, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5840" target="_blank">01:37:20.520</a></span> | <span class="t">ReLU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5841" target="_blank">01:37:21.520</a></span> | <span class="t">And we learned that the results of those calculations are called activations, and the things that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5846" target="_blank">01:37:26.640</a></span> | <span class="t">go into those calculations that we learn are called parameters, and that the parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5851" target="_blank">01:37:31.520</a></span> | <span class="t">are initially, randomly initialized, or we copy them over from a pre-trained model, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5856" target="_blank">01:37:36.480</a></span> | <span class="t">then we train them with SGD or faster versions, and we learned that convolutions are a particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5862" target="_blank">01:37:42.720</a></span> | <span class="t">affine function that work great for autocorrelated data, so things like images and stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5868" target="_blank">01:37:48.560</a></span> | <span class="t">We learned about batch norm, dropout data orientation and weight decay as ways of regularizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5874" target="_blank">01:37:54.600</a></span> | <span class="t">models, and also batch norm helps train models more quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5877" target="_blank">01:37:57.640</a></span> | <span class="t">And then today we've learned about res/dense blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5882" target="_blank">01:38:02.760</a></span> | <span class="t">We've learned a lot about image classification and regression, embeddings, categorical and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5887" target="_blank">01:38:07.400</a></span> | <span class="t">continuous variables, collaborative filtering, language models and NLP classification, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5893" target="_blank">01:38:13.360</a></span> | <span class="t">then kind of segmentation unit and GANs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5895" target="_blank">01:38:15.820</a></span> | <span class="t">So go over these things and make sure that you feel comfortable with each of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5901" target="_blank">01:38:21.880</a></span> | <span class="t">If you've only watched this series once, you definitely won't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5906" target="_blank">01:38:26.140</a></span> | <span class="t">People normally watch it three times or so to really understand the detail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5912" target="_blank">01:38:32.520</a></span> | <span class="t">So one thing that doesn't get here is RNNs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5918" target="_blank">01:38:38.540</a></span> | <span class="t">So that's the last thing we're going to do, RNNs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5922" target="_blank">01:38:42.200</a></span> | <span class="t">So RNNs, I'm going to introduce a little kind of diagrammatic method here to explain RNNs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5928" target="_blank">01:38:48.160</a></span> | <span class="t">And the diagrammatic method, I'll start by showing you a basic neural net with a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5931" target="_blank">01:38:51.800</a></span> | <span class="t">hidden layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5933" target="_blank">01:38:53.800</a></span> | <span class="t">Square means an input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5936" target="_blank">01:38:56.960</a></span> | <span class="t">So that'll be batch size by number of inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5941" target="_blank">01:39:01.040</a></span> | <span class="t">So kind of, you know, batch size by number of inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5950" target="_blank">01:39:10.040</a></span> | <span class="t">An arrow means a layer, broadly defined, such as matrix product followed by value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5956" target="_blank">01:39:16.840</a></span> | <span class="t">A circle is activation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5961" target="_blank">01:39:21.840</a></span> | <span class="t">So in this case, we have one set of hidden activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5965" target="_blank">01:39:25.660</a></span> | <span class="t">And so given that the input was number of inputs, this here is a matrix of number of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5972" target="_blank">01:39:32.440</a></span> | <span class="t">inputs by number of activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5974" target="_blank">01:39:34.580</a></span> | <span class="t">So the output will be batch size by number of activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5978" target="_blank">01:39:38.960</a></span> | <span class="t">It's really important you know how to calculate these shapes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5981" target="_blank">01:39:41.480</a></span> | <span class="t">So go learn.summary lots to see all the shapes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5987" target="_blank">01:39:47.200</a></span> | <span class="t">So then here's another arrow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5988" target="_blank">01:39:48.620</a></span> | <span class="t">So that means it's another layer, matrix product followed by non-linearity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5991" target="_blank">01:39:51.880</a></span> | <span class="t">In this case, we're going to the output, so we use softmax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5995" target="_blank">01:39:55.840</a></span> | <span class="t">And then triangle means an output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=5999" target="_blank">01:39:59.680</a></span> | <span class="t">And so this matrix product will be number of activations by number of classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6003" target="_blank">01:40:03.240</a></span> | <span class="t">So our output is batch size by number of classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6006" target="_blank">01:40:06.160</a></span> | <span class="t">So let's reuse that key, remember, triangle output, circle is activations, hidden state,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6016" target="_blank">01:40:16.440</a></span> | <span class="t">we also call that, and rectangle is input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6020" target="_blank">01:40:20.420</a></span> | <span class="t">So let's now imagine that we wanted to get a big document, split it into sets of three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6027" target="_blank">01:40:27.840</a></span> | <span class="t">words at a time, and grab each set of three words and then try to predict the third word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6034" target="_blank">01:40:34.480</a></span> | <span class="t">using the first two words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6036" target="_blank">01:40:36.560</a></span> | <span class="t">So if we had the data set in place, we could grab word one as an input, chuck it through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6042" target="_blank">01:40:42.080</a></span> | <span class="t">an embedding, create some activations, pass that through a matrix product and non-linearity,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6053" target="_blank">01:40:53.960</a></span> | <span class="t">grab the second word, put it through an embedding, and then we could either add those two things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6060" target="_blank">01:41:00.160</a></span> | <span class="t">together or concatenate them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6062" target="_blank">01:41:02.080</a></span> | <span class="t">Generally speaking, when you see kind of two sets of activations coming together in a diagram,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6068" target="_blank">01:41:08.400</a></span> | <span class="t">you normally have a choice of concatenate or add.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6073" target="_blank">01:41:13.200</a></span> | <span class="t">And that's going to create a second bunch of activations, and then you can put it through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6076" target="_blank">01:41:16.640</a></span> | <span class="t">one more fully connected layer and softmax to create an output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6083" target="_blank">01:41:23.160</a></span> | <span class="t">So that would be a totally standard, fully connected neural net with one very minor tweak,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6089" target="_blank">01:41:29.520</a></span> | <span class="t">which is concatenating or adding at this point, which we could use to try to predict the third</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6094" target="_blank">01:41:34.900</a></span> | <span class="t">word from pairs of two words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6101" target="_blank">01:41:41.120</a></span> | <span class="t">So remember, arrows represent layer operations, and I removed in this one the specifics of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6108" target="_blank">01:41:48.520</a></span> | <span class="t">what they are because they're always an affine function followed by a non-linearity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6116" target="_blank">01:41:56.760</a></span> | <span class="t">Let's go further. What if we wanted to predict word four using words one and two and three?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6123" target="_blank">01:42:03.080</a></span> | <span class="t">It's basically the same picture as last time, except with one extra input and one extra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6126" target="_blank">01:42:06.980</a></span> | <span class="t">circle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6127" target="_blank">01:42:07.980</a></span> | <span class="t">But I want to point something out, which is each time we go from rectangle to circle,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6135" target="_blank">01:42:15.720</a></span> | <span class="t">we're doing the same thing. We're doing an embedding, which is just a particular kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6140" target="_blank">01:42:20.320</a></span> | <span class="t">of matrix multiply, where you have a one-hot encoded input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6144" target="_blank">01:42:24.740</a></span> | <span class="t">Each time we go from circle to circle, we're basically taking one piece of hidden state,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6151" target="_blank">01:42:31.000</a></span> | <span class="t">one set of activations, and turning it into another set of activations by saying we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6154" target="_blank">01:42:34.920</a></span> | <span class="t">now at the next word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6157" target="_blank">01:42:37.280</a></span> | <span class="t">And then when we go from circle to triangle, we're doing something else again, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6161" target="_blank">01:42:41.000</a></span> | <span class="t">we're saying let's convert the hidden state, these activations, into an output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6166" target="_blank">01:42:46.360</a></span> | <span class="t">So it would make sense, so you can see I've colored each of those arrows differently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6170" target="_blank">01:42:50.680</a></span> | <span class="t">So each of those arrows should probably use the same weight matrix, because it's doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6176" target="_blank">01:42:56.440</a></span> | <span class="t">the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6177" target="_blank">01:42:57.800</a></span> | <span class="t">So why would you have a different set of embeddings for each word, or a different set of -- a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6182" target="_blank">01:43:02.320</a></span> | <span class="t">different matrix to multiply by to go from this hidden state to this hidden state versus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6186" target="_blank">01:43:06.680</a></span> | <span class="t">this one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6188" target="_blank">01:43:08.800</a></span> | <span class="t">So this is what we're going to build. So we're now going to jump into human numbers, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6202" target="_blank">01:43:22.080</a></span> | <span class="t">is less than seven human numbers, and this is the dataset that I created, which literally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6205" target="_blank">01:43:25.960</a></span> | <span class="t">just contains all the numbers from one to 9,999 written out in English.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6211" target="_blank">01:43:31.880</a></span> | <span class="t">And we're going to try and create a language model that can predict the next word in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6216" target="_blank">01:43:36.320</a></span> | <span class="t">document. It's just a toy example for this purpose.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6221" target="_blank">01:43:41.240</a></span> | <span class="t">So in this case, we only have one document, and that one document is the list of numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6227" target="_blank">01:43:47.320</a></span> | <span class="t">So we can use a text list to create an item list with text in for the training and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6232" target="_blank">01:43:52.200</a></span> | <span class="t">validation. In this case, the validation set is the numbers from 8,000 onwards, and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6236" target="_blank">01:43:56.640</a></span> | <span class="t">training set is 1 to 8,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6239" target="_blank">01:43:59.600</a></span> | <span class="t">We can combine them together, turn that into a data bunch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6244" target="_blank">01:44:04.660</a></span> | <span class="t">So we only have one document. So train zero is the document. Grab its dot text. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6249" target="_blank">01:44:09.200</a></span> | <span class="t">how you grab the contents of a text list, and here are the first 80 characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6255" target="_blank">01:44:15.080</a></span> | <span class="t">It starts with a special token, XXBOS. Anything starting with XX is a special fast AI token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6261" target="_blank">01:44:21.080</a></span> | <span class="t">BOS is the beginning of stream token. It basically says this is the start of a document. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6266" target="_blank">01:44:26.480</a></span> | <span class="t">very helpful in NLP to know when documents start so that your models can learn to recognize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6271" target="_blank">01:44:31.920</a></span> | <span class="t">them. The validation set contains 13,000 tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6276" target="_blank">01:44:36.360</a></span> | <span class="t">so 13,000 words or punctuation marks, because everything between spaces is a separate token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6284" target="_blank">01:44:44.640</a></span> | <span class="t">The batch size that we asked for was 64. And then by default, it uses something called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6294" target="_blank">01:44:54.640</a></span> | <span class="t">BPT-T of 70. BPT-T, as we briefly mentioned, stands for backprop through time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6301" target="_blank">01:45:01.440</a></span> | <span class="t">That's the sequence length. So with each of our 64 document segments, we split it up into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6312" target="_blank">01:45:12.080</a></span> | <span class="t">lists of 70 words that we look at at one time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6315" target="_blank">01:45:15.840</a></span> | <span class="t">So what we do is we grab this for the validation set, an entire string of 13,000 tokens, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6324" target="_blank">01:45:24.040</a></span> | <span class="t">then we split it into 64 roughly equal sized sections. People very, very, very often think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6332" target="_blank">01:45:32.440</a></span> | <span class="t">I'm saying something different. I did not say they are of length 64. They're not. They're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6338" target="_blank">01:45:38.120</a></span> | <span class="t">64 equally sized roughly segments. So we take the first 1/64 of the document, piece one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6346" target="_blank">01:45:46.160</a></span> | <span class="t">1/64, piece two. And then for each of those 1/64 of the document, we then split those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6356" target="_blank">01:45:56.960</a></span> | <span class="t">into pieces of length 70. So each batch -- so let's now say, okay, for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6364" target="_blank">01:46:04.720</a></span> | <span class="t">those 13,000 tokens, how many batches are there? Well, divide by batch size and divide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6370" target="_blank">01:46:10.080</a></span> | <span class="t">by 70. So there's about 2.9 batches. So there's going to be three batches. So let's grab an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6376" target="_blank">01:46:16.760</a></span> | <span class="t">iterator for our data loader, grab one, two, three batches, the X and the Y, and let's add</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6383" target="_blank">01:46:23.840</a></span> | <span class="t">up the number of elements, and we get back slightly less than this because there's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6388" target="_blank">01:46:28.920</a></span> | <span class="t">little bit left over at the end that doesn't quite make up a full batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6394" target="_blank">01:46:34.360</a></span> | <span class="t">So this is the kind of stuff you should play around with a lot, lots of shapes and sizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6397" target="_blank">01:46:37.920</a></span> | <span class="t">and stuff and iterators. As you can see, it's 95 by 64. I claimed it was going to be 70 by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6405" target="_blank">01:46:45.680</a></span> | <span class="t">64. That's because our data loader for language models slightly randomizes, BPTT, just to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6413" target="_blank">01:46:53.800</a></span> | <span class="t">give you a bit more kind of shuffling, get a bit more randomization. It helps the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6420" target="_blank">01:47:00.600</a></span> | <span class="t">And so here you can see the first batch of X. Remember, we've numericalized all these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6430" target="_blank">01:47:10.280</a></span> | <span class="t">And here's the first batch of Y. And you'll see here, this is 2, 18, 10, 11, 8. This is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6435" target="_blank">01:47:15.800</a></span> | <span class="t">18, 10, 11, 8. So this one is offset by 1 from here because that's what we want to do with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6443" target="_blank">01:47:23.120</a></span> | <span class="t">a language model. We want to predict the next word. So after 2 should come 18. And after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6450" target="_blank">01:47:30.160</a></span> | <span class="t">18 should come 10. You can grab the vocab for this data set. And a vocab has a textify.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6459" target="_blank">01:47:39.000</a></span> | <span class="t">So if we look at the same thing but with textify, that'll just look it up in the vocab. So here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6463" target="_blank">01:47:43.880</a></span> | <span class="t">you can see XXBOS 8001. Whereas in the Y, there's no XXBOS. It's just 8001. So after XXBOS is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6472" target="_blank">01:47:52.440</a></span> | <span class="t">8, after 8 is 1, after 1000 is 1. And so then after we get 8023 comes X2. And look at this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6483" target="_blank">01:48:03.520</a></span> | <span class="t">We're always looking at column 0. So this is the first batch, the first mini-batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6488" target="_blank">01:48:08.720</a></span> | <span class="t">Comes 8024 and then X3 all the way up to 8040. And so then we can go right back to the start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6498" target="_blank">01:48:18.880</a></span> | <span class="t">but look at batch 1. So index 1, which is batch number 2. And now we can continue. A</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6505" target="_blank">01:48:25.600</a></span> | <span class="t">slight skip from 8040 to 8046. That's because the last mini-batch wasn't quite complete.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6512" target="_blank">01:48:32.240</a></span> | <span class="t">So what this means is that every mini-batch joins up with the previous mini-batch. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6521" target="_blank">01:48:41.840</a></span> | <span class="t">you can go straight from X1, 0 to X2, 0. It continues. 8023, 8024, right? And so if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6530" target="_blank">01:48:50.320</a></span> | <span class="t">look at the same thing for colon, comma, 1, you'll also see they join up. So all the mini-batches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6537" target="_blank">01:48:57.060</a></span> | <span class="t">join up. So that's the data. We can do show batch to see it. And here is our model which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6549" target="_blank">01:49:09.040</a></span> | <span class="t">is doing this. So this is just the code copied over. So it contains one embedding, i.e. the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6565" target="_blank">01:49:25.640</a></span> | <span class="t">green arrow, one hidden to hidden brown arrow layer, and one hidden to output. So each colored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6575" target="_blank">01:49:35.800</a></span> | <span class="t">arrow has a single matrix. And so then in the forward pass, we take our first input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6585" target="_blank">01:49:45.000</a></span> | <span class="t">X0, and put it through input to hidden, the green arrow, create our first set of activations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6592" target="_blank">01:49:52.120</a></span> | <span class="t">which we call H. Assuming that there is a second word, because sometimes we might be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6598" target="_blank">01:49:58.320</a></span> | <span class="t">at the end of a batch where there isn't a second word, assuming there is a second word,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6602" target="_blank">01:50:02.160</a></span> | <span class="t">then we would add to H the result of X1, put through the green arrow. Remember that's IH.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6611" target="_blank">01:50:11.920</a></span> | <span class="t">And then we would say, okay, our new H is the result of those two added together, put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6620" target="_blank">01:50:20.600</a></span> | <span class="t">through our hidden to hidden, orange arrow, and then relu then batch it on. And then for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6625" target="_blank">01:50:25.360</a></span> | <span class="t">the second word, do exactly the same thing. And then finally, blue arrow, put it through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6630" target="_blank">01:50:30.840</a></span> | <span class="t">H0. So that's how we convert our diagram to code. So nothing new here at all. So now let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6642" target="_blank">01:50:42.960</a></span> | <span class="t">do -- so we can check that in the learner and we can train it, 46%. Let's take this code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6649" target="_blank">01:50:49.720</a></span> | <span class="t">and recognize it's pretty awful. There's a lot of duplicate code. And as coders, when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6655" target="_blank">01:50:55.040</a></span> | <span class="t">we see duplicate code, what do we do? We refactor. So we should refactor this into a loop. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6661" target="_blank">01:51:01.760</a></span> | <span class="t">here we are. We've refactored it into a loop. So now we're going for each X, I and X and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6666" target="_blank">01:51:06.800</a></span> | <span class="t">doing it in the loop. Guess what? That's an RNN. An RNN is just a refactoring. It's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6676" target="_blank">01:51:16.320</a></span> | <span class="t">anything new. This is now an RNN. And let's refactor our diagram from this to this. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6687" target="_blank">01:51:27.360</a></span> | <span class="t">is the same diagram. But I've just replaced it with my loop. Does the same thing. So here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6696" target="_blank">01:51:36.520</a></span> | <span class="t">it is. It's got exactly the same in it. Literally exactly the same. Just popped a loop here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6701" target="_blank">01:51:41.400</a></span> | <span class="t">Before I start, I just have to make sure I've got a bunch of zeros to add to. And of course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6707" target="_blank">01:51:47.600</a></span> | <span class="t">I get exactly the same result when I train it. Okay. So next thing that you might think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6713" target="_blank">01:51:53.760</a></span> | <span class="t">then -- and one nice thing about the loop, though, is now this will work even if I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6717" target="_blank">01:51:57.280</a></span> | <span class="t">not predicting the fourth word from the previous three but the ninth word from the previous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6721" target="_blank">01:52:01.560</a></span> | <span class="t">eight. It will work for any arbitrarily length long sequence, which is nice. So let's up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6727" target="_blank">01:52:07.120</a></span> | <span class="t">the BPTT to 20 since we can now. And let's now say, okay, instead of just predicting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6739" target="_blank">01:52:19.400</a></span> | <span class="t">the nth word from the previous n minus 1, let's try to predict the second word from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6745" target="_blank">01:52:25.760</a></span> | <span class="t">the first and the third from the second and the fourth from the third and so forth. Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6749" target="_blank">01:52:29.920</a></span> | <span class="t">previously -- look at our loss function. Previously we were comparing the result of our model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6755" target="_blank">01:52:35.440</a></span> | <span class="t">to just the last word of the sequence. It's very wasteful because there's a lot of words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6759" target="_blank">01:52:39.560</a></span> | <span class="t">in the sequence. So let's compare every word in X to every word in Y. So to do that, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6766" target="_blank">01:52:46.720</a></span> | <span class="t">need to change this so it's not just one triangle at the end of the loop. But the triangle is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6772" target="_blank">01:52:52.440</a></span> | <span class="t">inside this, right? So that in other words, after every loop, predict, loop, predict,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6780" target="_blank">01:53:00.360</a></span> | <span class="t">loop, predict. So here's this code. It's the same as the previous code but now I've created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6788" target="_blank">01:53:08.120</a></span> | <span class="t">an array. And every time I go through the loop, I append HOH to the array. So now for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6795" target="_blank">01:53:15.960</a></span> | <span class="t">n inputs, I create n outputs. So I'm predicting after every word. Previously I had 46%. Now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6803" target="_blank">01:53:23.640</a></span> | <span class="t">I have 40%. Why is it worse? Well, it's worse because now, like when I'm trying to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6811" target="_blank">01:53:31.080</a></span> | <span class="t">the second word, I only have one word of state to use. Right? So like when I'm looking at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6817" target="_blank">01:53:37.400</a></span> | <span class="t">the third word, I only have two words of state to use. So it's a much harder problem for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6822" target="_blank">01:53:42.200</a></span> | <span class="t">it to solve. So the obvious way to fix this then would -- you know, the key problem is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6827" target="_blank">01:53:47.640</a></span> | <span class="t">here. I go H equals torch.zeros, like I reset my state to zero every time I start another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6834" target="_blank">01:53:54.360</a></span> | <span class="t">BPTT sequence. Well, let's not do that. Let's keep H. Right? And we can because remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6841" target="_blank">01:54:01.240</a></span> | <span class="t">each batch connects to the previous batch. It's not shuffled like happens in image classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6849" target="_blank">01:54:09.000</a></span> | <span class="t">So let's take this exact model and replicate it again. But let's move the creation of H</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6853" target="_blank">01:54:13.440</a></span> | <span class="t">into the constructor. Okay. There it is. So it's now self.h. So this is now exactly the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6860" target="_blank">01:54:20.160</a></span> | <span class="t">same code. But at the end, let's put the new H back into self.h. So it's now doing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6865" target="_blank">01:54:25.800</a></span> | <span class="t">same thing, but it's not throwing away that state. And so therefore now we actually get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6873" target="_blank">01:54:33.160</a></span> | <span class="t">above the original. We get all the way up to 54% accuracy. So this is what a real RNN</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6881" target="_blank">01:54:41.720</a></span> | <span class="t">looks like. You always want to keep that state. But just keep remembering there's nothing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6888" target="_blank">01:54:48.720</a></span> | <span class="t">different about an RNN. It's a totally normal, fully connected neural net. It's just that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6892" target="_blank">01:54:52.840</a></span> | <span class="t">you've got a loop you refactored. What you could do, though, is at the end of your -- every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6903" target="_blank">01:55:03.120</a></span> | <span class="t">loop, you could not just spit out an output, but you could spit it out into another RNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6907" target="_blank">01:55:07.920</a></span> | <span class="t">So you could have an RNN going into an RNN. And that's nice because we've now got more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6912" target="_blank">01:55:12.160</a></span> | <span class="t">layers of computation. You would expect that to work better. Well, to get there, let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6918" target="_blank">01:55:18.960</a></span> | <span class="t">do some more refactoring. So let's take this code and replace it with the equivalent built-in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6925" target="_blank">01:55:25.720</a></span> | <span class="t">PyTorch code, which is -- you just say that. So nn.rn basically says do the loop for me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6933" target="_blank">01:55:33.000</a></span> | <span class="t">We've still got the same embedding, the same output, the same batch norm, the same initialization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6939" target="_blank">01:55:39.880</a></span> | <span class="t">of H, but we just got rid of the loop. So one of the nice things about RNN is that you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6945" target="_blank">01:55:45.680</a></span> | <span class="t">now say how many layers you want. So this is the same accuracy, of course. So here I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6953" target="_blank">01:55:53.280</a></span> | <span class="t">got to do it with two layers. But here's the thing. When you think about this, right, think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6960" target="_blank">01:56:00.480</a></span> | <span class="t">about it without the loop. It looks like this, right? It's like -- it keeps on going -- and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6966" target="_blank">01:56:06.360</a></span> | <span class="t">we've got a BPTT of 20, so there's 20 layers of this. And we know from that visualizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6973" target="_blank">01:56:13.320</a></span> | <span class="t">the lost landscapes paper that deep networks have awful, bumpy, lost surfaces. So when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6980" target="_blank">01:56:20.680</a></span> | <span class="t">you start creating long time scales and multiple layers, these things get impossible to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6991" target="_blank">01:56:31.520</a></span> | <span class="t">So there's a few tricks you can do. One thing is you can add skip connections, of course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=6997" target="_blank">01:56:37.640</a></span> | <span class="t">But what people normally do is instead they put inside -- instead of just adding these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7003" target="_blank">01:56:43.280</a></span> | <span class="t">together, they actually use a little mini neural net to decide how much of the green</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7008" target="_blank">01:56:48.680</a></span> | <span class="t">arrow to keep and how much of the orange arrow to keep. And when you do that, you get something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7013" target="_blank">01:56:53.640</a></span> | <span class="t">that's either called a GIU or an LSTM depending on the details of that little neural net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7019" target="_blank">01:56:59.200</a></span> | <span class="t">And we'll learn about the details of those neural nets in part two. They really don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7022" target="_blank">01:57:02.600</a></span> | <span class="t">matter, though, frankly. So we can now say let's create a GIU instead, so it's just like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7027" target="_blank">01:57:07.920</a></span> | <span class="t">what we had before, but it'll handle longer sequences in deeper networks. Let's use two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7033" target="_blank">01:57:13.560</a></span> | <span class="t">layers, and we're up to 75%. Okay. So that's RNNs. And the main reason I wanted to show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7047" target="_blank">01:57:27.960</a></span> | <span class="t">it to you was to remove the last remaining piece of magic. And this is one of the least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7055" target="_blank">01:57:35.360</a></span> | <span class="t">magical things we have in deep learning. It's just a refactored, fully connected network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7060" target="_blank">01:57:40.800</a></span> | <span class="t">So don't let RNNs ever put you off. And with this approach where you basically have a sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7068" target="_blank">01:57:48.760</a></span> | <span class="t">of N inputs and a sequence of N outputs we've been using for language modeling, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7073" target="_blank">01:57:53.360</a></span> | <span class="t">use that for other tasks, right? For example, the sequence of outputs could be for every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7078" target="_blank">01:57:58.440</a></span> | <span class="t">word. There could be something saying is this something that is sensitive and I want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7081" target="_blank">01:58:01.980</a></span> | <span class="t">anonymize or not? You know, so like is this private data or not? Or it could be a part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7088" target="_blank">01:58:08.560</a></span> | <span class="t">of speech tag for that word. Or it could be something saying, you know, how should that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7095" target="_blank">01:58:15.840</a></span> | <span class="t">word be formatted? Or whatever. And so these are called sequence labeling tasks, and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7101" target="_blank">01:58:21.360</a></span> | <span class="t">you can use this same approach for pretty much any sequence labeling task. Or you can do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7106" target="_blank">01:58:26.960</a></span> | <span class="t">what I did in the earlier lesson, which is once you finish building your language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7113" target="_blank">01:58:33.360</a></span> | <span class="t">you can throw away the kind of this HO bit and instead pop there a standard classification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7122" target="_blank">01:58:42.480</a></span> | <span class="t">head and then you can now do NLP classification, which as you saw earlier will give you state-of-the-art</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7129" target="_blank">01:58:49.160</a></span> | <span class="t">results even on long documents. So this is a super valuable technique and not remotely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7137" target="_blank">01:58:57.600</a></span> | <span class="t">magical. Okay, so that's it, right? That's deep learning or at least, you know, the kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7145" target="_blank">01:59:05.880</a></span> | <span class="t">of the practical pieces from my point of view. Having watched this one time, you won't get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7157" target="_blank">01:59:17.120</a></span> | <span class="t">it all. And I don't recommend that you do watch this so slowly that you get it all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7161" target="_blank">01:59:21.560</a></span> | <span class="t">first time, but you go back and look at it again, take your time, and there'll be bits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7167" target="_blank">01:59:27.200</a></span> | <span class="t">that you go like, "Oh, now I see what he's saying," and then you'll be able to implement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7171" target="_blank">01:59:31.080</a></span> | <span class="t">things you couldn't implement before and you'll be able to dig in more than you before. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7174" target="_blank">01:59:34.560</a></span> | <span class="t">definitely go back and do it again. And as you do, write code, not just for yourself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7180" target="_blank">01:59:40.640</a></span> | <span class="t">but put it on GitHub. It doesn't matter if you think it's great code or not. The fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7185" target="_blank">01:59:45.640</a></span> | <span class="t">that you're writing code and sharing it is impressive, and the feedback you'll get if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7191" target="_blank">01:59:51.880</a></span> | <span class="t">you tell people on the forum, "Hey, I wrote this code. It's not great, but it's my first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7197" target="_blank">01:59:57.120</a></span> | <span class="t">effort. Anything you see, jump out at you," people will say like, "Oh, that bit was done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7202" target="_blank">02:00:02.320</a></span> | <span class="t">well. Hey, but did you know for this bit you could have used this library and saved you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7205" target="_blank">02:00:05.760</a></span> | <span class="t">some time?" You'll learn a lot by interacting with your peers. As you've noticed, I've started</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7212" target="_blank">02:00:12.520</a></span> | <span class="t">introducing more and more papers. Now, part two will be a lot of papers, and so it's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7217" target="_blank">02:00:17.320</a></span> | <span class="t">good time to start reading some of the papers that have been introduced in this section.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7224" target="_blank">02:00:24.160</a></span> | <span class="t">All the bits that say derivation and theorems and lemmas, you can skip them. I do. They add</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7229" target="_blank">02:00:29.520</a></span> | <span class="t">almost nothing to your understanding of practical deep learning. But the bits that say why are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7236" target="_blank">02:00:36.600</a></span> | <span class="t">we solving this problem, and what are the results, and so forth are really interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7242" target="_blank">02:00:42.540</a></span> | <span class="t">And then try and write English prose. Not English prose that you want to be read by Jeff Hinton</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7251" target="_blank">02:00:51.200</a></span> | <span class="t">and Yann LeCun, but English prose that you want to be read by you as of six months ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7256" target="_blank">02:00:56.560</a></span> | <span class="t">Because there's a lot more people in the audience of you as of six months ago than there is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7262" target="_blank">02:01:02.360</a></span> | <span class="t">of Jeffrey Hinton and Yann LeCun. That's the person you best understand. You know what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7267" target="_blank">02:01:07.600</a></span> | <span class="t">they need. Go and get help and help others. Tell us about your success stories. But perhaps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7276" target="_blank">02:01:16.360</a></span> | <span class="t">the most important one is get together with others. People's learning works much better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7280" target="_blank">02:01:20.860</a></span> | <span class="t">if you've got that social experience. So start a book club, get involved in meetups, create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7287" target="_blank">02:01:27.640</a></span> | <span class="t">study groups, and build things. And again, it doesn't have to be amazing. Just build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7296" target="_blank">02:01:36.880</a></span> | <span class="t">something that you think the world would be a little bit better if that existed. Or you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7301" target="_blank">02:01:41.700</a></span> | <span class="t">think it would be kind of slightly delightful to your two-year-old to see that thing. Or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7306" target="_blank">02:01:46.600</a></span> | <span class="t">you just want to show it to your brother the next time they come around to see what you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7309" target="_blank">02:01:49.120</a></span> | <span class="t">doing. Whatever. Just finish something. Finish something. And then try and make it a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7317" target="_blank">02:01:57.320</a></span> | <span class="t">better. So for example, something I just saw this afternoon is the Elon Musk tweet generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7329" target="_blank">02:02:09.320</a></span> | <span class="t">So looking at lots of older tweets, creating a language model from Elon Musk, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7334" target="_blank">02:02:14.520</a></span> | <span class="t">creating new tweets such as humanity will also have an option to publish on its own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7339" target="_blank">02:02:19.640</a></span> | <span class="t">journey as an alien civilization. It will always, like all human beings, Mars is no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7345" target="_blank">02:02:25.680</a></span> | <span class="t">longer possible. AI will definitely be the central intelligence agency. Okay. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7351" target="_blank">02:02:31.680</a></span> | <span class="t">is great. I love this. And I love that Dave Smith wrote and said, "These are my first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7357" target="_blank">02:02:37.920</a></span> | <span class="t">ever commits. Thanks for teaching a finance guy how to build an app in eight weeks." Right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7363" target="_blank">02:02:43.560</a></span> | <span class="t">So I think this is awesome. And I think clearly a lot of care and passion is being put into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7370" target="_blank">02:02:50.520</a></span> | <span class="t">this project. Will it systematically change the future direction of society as a whole?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7379" target="_blank">02:02:59.720</a></span> | <span class="t">Maybe not. But maybe Elon will look at this and think, "Oh, maybe I need to rethink my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7385" target="_blank">02:03:05.380</a></span> | <span class="t">method of prose." I don't know. I think it's great. And so, yeah. Create something. Put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7392" target="_blank">02:03:12.240</a></span> | <span class="t">it out there. Put a bit of yourself into it. Or get involved in fast AI. The fast AI project,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7400" target="_blank">02:03:20.120</a></span> | <span class="t">there's a lot going on. You know, you can help with documentation and tests, which might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7404" target="_blank">02:03:24.760</a></span> | <span class="t">sound boring, but you'd be surprised how incredibly not boring it is to, like, take a piece of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7408" target="_blank">02:03:28.780</a></span> | <span class="t">code that hasn't been properly documented and research it and understand it and ask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7413" target="_blank">02:03:33.640</a></span> | <span class="t">Silver and I on the forum what's going on. Why did you write it this way? We'll send</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7417" target="_blank">02:03:37.240</a></span> | <span class="t">you off to the papers that we were implementing. You know, writing a test requires deeply understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7422" target="_blank">02:03:42.200</a></span> | <span class="t">that part of the machine learning world to understand how it's meant to work. So that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7426" target="_blank">02:03:46.800</a></span> | <span class="t">always interesting. Staz Beckman has created this nice dev projects index which you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7433" target="_blank">02:03:53.060</a></span> | <span class="t">go on to the forum in the fast AI dev section and find actually the dev project section</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7439" target="_blank">02:03:59.060</a></span> | <span class="t">and find, like, here's some stuff going on that you might want to get involved in. Or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7442" target="_blank">02:04:02.680</a></span> | <span class="t">maybe there's stuff you want to exist. You can add your own. Create a study group. Dean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7447" target="_blank">02:04:07.280</a></span> | <span class="t">has already created a study group for San Francisco starting in January. This is how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7450" target="_blank">02:04:10.720</a></span> | <span class="t">easy it is to create a study group. Go on the forum, find your little time zone subcategory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7455" target="_blank">02:04:15.920</a></span> | <span class="t">and add a post saying let's create a study group. But make sure you give people a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7462" target="_blank">02:04:22.000</a></span> | <span class="t">Google sheet to sign up, some way to actually do something. A great example is Pierre who's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7468" target="_blank">02:04:28.380</a></span> | <span class="t">been doing a fantastic job in Brazil of running study groups for the last couple of parts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7474" target="_blank">02:04:34.400</a></span> | <span class="t">of the course and he keeps posting these pictures of people having a good time and learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7480" target="_blank">02:04:40.000</a></span> | <span class="t">deep learning together, creating wikis together, creating projects together. Great experience.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7487" target="_blank">02:04:47.100</a></span> | <span class="t">And then come back for part two, right, where we'll be looking at all of this interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7493" target="_blank">02:04:53.400</a></span> | <span class="t">stuff in particular going deep into the fast AI code base to understand how did we build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7498" target="_blank">02:04:58.080</a></span> | <span class="t">it exactly. We'll actually go through, as we were building it, we created notebooks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7503" target="_blank">02:05:03.400</a></span> | <span class="t">of like here is where we were at each stage. So we're actually going to see the software</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7506" target="_blank">02:05:06.920</a></span> | <span class="t">development process itself. We'll talk about the process of doing research, how to read</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7511" target="_blank">02:05:11.760</a></span> | <span class="t">academic papers, how to turn math into code, and then a whole bunch of additional types</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7517" target="_blank">02:05:17.080</a></span> | <span class="t">of models that we haven't seen yet. So it'll be kind of like going beyond practical deep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7521" target="_blank">02:05:21.800</a></span> | <span class="t">learning into actually cutting edge research. So we've got five minutes to take some questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7531" target="_blank">02:05:31.140</a></span> | <span class="t">We had an AMA going on online and so we're going to have time for a couple of the highest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7537" target="_blank">02:05:37.200</a></span> | <span class="t">ranked AMA questions from the community. And the first one is by Jeremy's request, although</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7542" target="_blank">02:05:42.160</a></span> | <span class="t">it's not the highest ranked. What's your typical day like? How do you manage your time across</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7547" target="_blank">02:05:47.160</a></span> | <span class="t">so many things that you do? Yeah, I thought that I hear that all the time. So I thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7554" target="_blank">02:05:54.160</a></span> | <span class="t">I should answer it. And I think I've got a few votes. Because I think people who come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7561" target="_blank">02:06:01.880</a></span> | <span class="t">to our study group are always shocked at how disorganized and incompetent I am. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7569" target="_blank">02:06:09.120</a></span> | <span class="t">I often hear people saying like, oh, wow, I thought you were like this deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7572" target="_blank">02:06:12.720</a></span> | <span class="t">role model and I'd get to see how to be like you. And now I'm not sure what to be like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7576" target="_blank">02:06:16.240</a></span> | <span class="t">you at all. So yeah, it's for me, it's all about just having a good time with it. I never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7586" target="_blank">02:06:26.160</a></span> | <span class="t">really have many plans. I just try to finish what I start. If you're not having fun with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7592" target="_blank">02:06:32.400</a></span> | <span class="t">it, it's really, really hard to continue because there's a lot of frustration in deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7596" target="_blank">02:06:36.720</a></span> | <span class="t">because it's not like writing a web app, where it's like, you know, authentication check,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7601" target="_blank">02:06:41.840</a></span> | <span class="t">you know, backend service watchdog check. Okay, user credentials check. You know, like you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7611" target="_blank">02:06:51.200</a></span> | <span class="t">making progress. Where else for stuff like this and stuff that we've been doing the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7615" target="_blank">02:06:55.960</a></span> | <span class="t">couple of weeks, it's just like, it's not working. It's not working. It's not working.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7620" target="_blank">02:07:00.760</a></span> | <span class="t">No, that also didn't work. That also didn't work until oh, my God, it's amazing. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7625" target="_blank">02:07:05.360</a></span> | <span class="t">a cat. That's kind of what it is, right? So you don't get that regular feedback. So yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7631" target="_blank">02:07:11.360</a></span> | <span class="t">you know, you got to have fun with it. And so, so my, yeah, my day is kind of, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7639" target="_blank">02:07:19.560</a></span> | <span class="t">I mean, the other thing I'll do, I'll say I don't, I don't do any meetings. I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7644" target="_blank">02:07:24.320</a></span> | <span class="t">do phone calls. I don't do coffees. I don't watch TV. I don't play computer games. I spend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7649" target="_blank">02:07:29.920</a></span> | <span class="t">a lot of time with my family, a lot of time exercising and a lot of time reading and coding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7656" target="_blank">02:07:36.600</a></span> | <span class="t">and doing things I like. So, you know, I think, you know, the main thing is just finish, finish</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7665" target="_blank">02:07:45.440</a></span> | <span class="t">something like properly finish it. So when you get to that point where you think you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7670" target="_blank">02:07:50.120</a></span> | <span class="t">80% of the way through, but you haven't quite created a read me yet and the install process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7674" target="_blank">02:07:54.600</a></span> | <span class="t">is still a bit clunky and you know, this is what 99% of GitHub projects look like. You'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7679" target="_blank">02:07:59.320</a></span> | <span class="t">see the read me says to do, you know, complete baseline experiments, document, blah, blah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7686" target="_blank">02:08:06.880</a></span> | <span class="t">blah. It's like, don't be that person. Like just do something properly and finish it and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7693" target="_blank">02:08:13.080</a></span> | <span class="t">maybe get some other people around you to work with you so that you're all doing it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7696" target="_blank">02:08:16.000</a></span> | <span class="t">together and you know, get it done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7702" target="_blank">02:08:22.360</a></span> | <span class="t">What are the up and coming deep learning machine learning things that you are most excited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7706" target="_blank">02:08:26.200</a></span> | <span class="t">about? Also, you've mentioned last year that you are not a believer in reinforcement learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7711" target="_blank">02:08:31.280</a></span> | <span class="t">Do you still feel the same way?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7713" target="_blank">02:08:33.160</a></span> | <span class="t">Yeah, I still feel exactly the same way as I did three years ago when we started this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7718" target="_blank">02:08:38.200</a></span> | <span class="t">which is it's all about transfer learning. It's underappreciated. It's under researched.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7724" target="_blank">02:08:44.200</a></span> | <span class="t">Every time we put transfer learning into anything, we make it much better. You know, our academic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7730" target="_blank">02:08:50.640</a></span> | <span class="t">paper on transfer learning for NLP has, you know, helped be one piece of kind of changing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7735" target="_blank">02:08:55.800</a></span> | <span class="t">the direction of NLP this year. It's made it all the way to the New York Times, just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7740" target="_blank">02:09:00.440</a></span> | <span class="t">a stupid, obvious little thing that we threw together. So I remain excited about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7746" target="_blank">02:09:06.160</a></span> | <span class="t">I remain unexcited about reinforcement learning for most things. I don't see it used by normal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7752" target="_blank">02:09:12.760</a></span> | <span class="t">people for normal things, for nearly anything. It's an incredibly inefficient way to solve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7757" target="_blank">02:09:17.720</a></span> | <span class="t">problems which are often solved more simply and more quickly in other ways. It probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7762" target="_blank">02:09:22.480</a></span> | <span class="t">has maybe a role in the world, but a limited one and not in most people's day-to-day work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7779" target="_blank">02:09:39.040</a></span> | <span class="t">For someone planning to take part two in 2019, what would you recommend doing learning practicing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7783" target="_blank">02:09:43.840</a></span> | <span class="t">until the part two course starts?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7788" target="_blank">02:09:48.200</a></span> | <span class="t">Just code. Yeah, just code all the time. I know it's perfectly possible I hear from people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7793" target="_blank">02:09:53.000</a></span> | <span class="t">who get to this point of the course and they haven't actually written any code yet. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7796" target="_blank">02:09:56.920</a></span> | <span class="t">if that's you, it's okay. You know, you just go through and do it again and this time do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7801" target="_blank">02:10:01.920</a></span> | <span class="t">code and look at the shapes of your inputs and look at your outputs and make sure you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7808" target="_blank">02:10:08.680</a></span> | <span class="t">know how to grab a mini batch and look at its main and standard deviation and plot it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7815" target="_blank">02:10:15.080</a></span> | <span class="t">There's so much material that we've covered. If you can get to a point where you can rebuild</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7823" target="_blank">02:10:23.960</a></span> | <span class="t">those notebooks from scratch without too much cheating, when I say from scratch, I mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7830" target="_blank">02:10:30.960</a></span> | <span class="t">using the first AI library, not from scratch from scratch, you'll be in the top echelon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7838" target="_blank">02:10:38.400</a></span> | <span class="t">of practitioners because you'll be able to do all of these things yourself and that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7841" target="_blank">02:10:41.800</a></span> | <span class="t">really, really rare. And that'll put you in a great position for part two. Should we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7847" target="_blank">02:10:47.240</a></span> | <span class="t">one more?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7848" target="_blank">02:10:48.240</a></span> | <span class="t">Nine o'clock. We always do one more. Where do you see the fast AI library going in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7853" target="_blank">02:10:53.200</a></span> | <span class="t">future, say in five years?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7856" target="_blank">02:10:56.040</a></span> | <span class="t">Well, like I said, I don't make plans. I just piss around. So, I mean, our only plan for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7865" target="_blank">02:11:05.640</a></span> | <span class="t">fast AI as an organization is to make deep learning accessible as a tool for normal people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7875" target="_blank">02:11:15.400</a></span> | <span class="t">to use for normal stuff. So, as long as we need to code, we failed at that. So, the big</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7882" target="_blank">02:11:22.000</a></span> | <span class="t">goal, because 99.8% of the world can't code. So, the main goal would be to get to a point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7890" target="_blank">02:11:30.120</a></span> | <span class="t">where it's not a library but it's a piece of software that doesn't require code. It certainly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7894" target="_blank">02:11:34.280</a></span> | <span class="t">shouldn't require a goddamn lengthy, hard-working course like this one. So, I want to get rid</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7901" target="_blank">02:11:41.840</a></span> | <span class="t">of the course. I want to get rid of the code. I want to make it so you can just do useful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7906" target="_blank">02:11:46.160</a></span> | <span class="t">stuff quickly and easily. So, that's maybe five years? Yeah, maybe longer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7912" target="_blank">02:11:52.640</a></span> | <span class="t">All right. Well, I hope to see you all back here for part two. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7915" target="_blank">02:11:55.720</a></span> | <span class="t">[applause]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7916" target="_blank">02:11:56.720</a></span> | <span class="t">[end of transcript]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7916" target="_blank">02:11:56.720</a></span> | <span class="t">[applause]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7917" target="_blank">02:11:57.720</a></span> | <span class="t">[end of transcript]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7917" target="_blank">02:11:57.720</a></span> | <span class="t">[applause]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7918" target="_blank">02:11:58.720</a></span> | <span class="t">[end of transcript]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7918" target="_blank">02:11:58.720</a></span> | <span class="t">[applause]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7919" target="_blank">02:11:59.720</a></span> | <span class="t">[end of transcript]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7919" target="_blank">02:11:59.720</a></span> | <span class="t">[applause]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7920" target="_blank">02:12:00.720</a></span> | <span class="t">[end of transcript]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7921" target="_blank">02:12:01.720</a></span> | <span class="t">[end of transcript]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7921" target="_blank">02:12:01.720</a></span> | <span class="t">(audience applauds)</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=9spwoDYwW_I&t=7924" target="_blank">02:12:04.720</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>