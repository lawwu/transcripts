<html><head><title>Lesson 22: Deep Learning Foundations to Stable Diffusion</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 22: Deep Learning Foundations to Stable Diffusion</h2><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM"><img src="https://i.ytimg.com/vi/6Bta1tXRUfM/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=30">0:30</a> Cosine Schedule (22_cosine)<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=365">6:5</a> Sampling<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=577">9:37</a> Summary / Notation<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=642">10:42</a> Predicting the noise level of noisy Fashion MNIST images<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=777">12:57</a> Why .logit() when predicting alpha bar t<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=890">14:50</a> Random baseline<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1000">16:40</a> mse_loss why .flatten()<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1050">17:30</a> Model & results<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1143">19:3</a> Why are we trying to predict the noise level?<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1210">20:10</a> Training diffusion without t - first attempt<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1378">22:58</a> Why it isn’t working?<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1622">27:2</a> Debugging (summary)<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1769">29:29</a> Bug in ddpm - paper that cast some light on the issue<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2320">38:40</a> Karras (Elucidating the Design Space of Diffusion - Based Generative Models)<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2987">49:47</a> Picture of target images<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3168">52:48</a> Scaling problem - (scalings)<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3582">59:42</a> Training and predictions of modified model<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3829">63:49</a> Sampling<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3965">66:5</a> Sampling: Problems of composition<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4060">67:40</a> Sampling: Rationale for rho selection<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4180">69:40</a> Sampling: Denosing<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4526">75:26</a> Sampling: Heun’s method fid: 0.972<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4740">79:0</a> Sampling: LMS sampler<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4800">80:0</a> Kerras Summary<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4980">83:0</a> Comparison of different approaches<br><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5100">85:0</a> Next lessons<br><br><div style="text-align: left;"><a href="./6Bta1tXRUfM.html">Whisper Transcript</a> | <a href="./transcript_6Bta1tXRUfM.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">All right. Hi, gang. And here we are in Lesson 21, joined by the legends themselves, Johnno</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=9" target="_blank">00:00:09.200</a></span> | <span class="t">and Tanishk. Hello.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=11" target="_blank">00:00:11.720</a></span> | <span class="t">Hello.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=12" target="_blank">00:00:12.940</a></span> | <span class="t">And today, you'll be shocked to hear that we are going to look at a Jupiter notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=25" target="_blank">00:00:25.160</a></span> | <span class="t">We're going to look at notebook 22. This is pretty quick. Just, you know, improvement,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=37" target="_blank">00:00:37.520</a></span> | <span class="t">pretty simple improvement to our DDPM/DDIM implementation for fashion MNIST. And this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=53" target="_blank">00:00:53.000</a></span> | <span class="t">is all the same so far, but what I've done is I've made one quite significant change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=63" target="_blank">00:01:03.120</a></span> | <span class="t">And some of the changes we'll be making today are all about making life simpler. And they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=68" target="_blank">00:01:08.320</a></span> | <span class="t">kind of reflecting the way the papers have been taking things. And it's interesting to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=74" target="_blank">00:01:14.000</a></span> | <span class="t">see how the papers have not only made things better, they made things simpler. And so one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=81" target="_blank">00:01:21.880</a></span> | <span class="t">of the things that I've noticed in recent papers is that there's no longer a concept</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=89" target="_blank">00:01:29.200</a></span> | <span class="t">of n steps, which is something we've always had before, and it always bothered me a bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=96" target="_blank">00:01:36.000</a></span> | <span class="t">this capital T thing. You know, this T over T, it's basically saying this is time step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=104" target="_blank">00:01:44.480</a></span> | <span class="t">number, say 500 out of 1000, so it's time step 0.5. Why not just call it 0.5? And the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=115" target="_blank">00:01:55.920</a></span> | <span class="t">answer is, well, we can. So we talked last time about the cosine scheduler. We didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=121" target="_blank">00:02:01.400</a></span> | <span class="t">end up using it because I came up with an idea which was, you know, simpler and nearly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=128" target="_blank">00:02:08.760</a></span> | <span class="t">the same, which is just to change our beta max. But in this next notebook, I decided let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=134" target="_blank">00:02:14.880</a></span> | <span class="t">use the cosine scheduler, but let's try to get rid of the n steps thing and the capital</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=141" target="_blank">00:02:21.560</a></span> | <span class="t">T thing. So here is A bar again. And now I've got rid of the capital T. So now I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=150" target="_blank">00:02:30.120</a></span> | <span class="t">to assume that your time step is between 0 and 1, and it basically represents what percentage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=157" target="_blank">00:02:37.320</a></span> | <span class="t">of the way through the diffusion process are you? So 0 would be all noise, and 1 would be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=162" target="_blank">00:02:42.840</a></span> | <span class="t">- well, no, sorry, the other way around - 0 would be all clean, and 1 would be all noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=167" target="_blank">00:02:47.400</a></span> | <span class="t">So how far through the forward diffusion process? So other than that, this is exactly the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=173" target="_blank">00:02:53.540</a></span> | <span class="t">equation we've already seen. And I realized something else, which is kind of fun, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=176" target="_blank">00:02:56.800</a></span> | <span class="t">is you can take the inverse of that. So you can calculate T. So we would basically first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=190" target="_blank">00:03:10.060</a></span> | <span class="t">take the square root, and we would then take the inverse cos, and we would then divide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=201" target="_blank">00:03:21.680</a></span> | <span class="t">by 2 over pi, or times pi over 2. So we can both - so it's interesting now we don't - the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=210" target="_blank">00:03:30.840</a></span> | <span class="t">alpha bar is not something we look up in a list, it's something we calculate with a function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=217" target="_blank">00:03:37.160</a></span> | <span class="t">from a float. And so yeah, interestingly, that means we can also calculate T from an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=222" target="_blank">00:03:42.280</a></span> | <span class="t">alpha bar. So Noisify has changed a little. So now when we get the alpha bar through our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=232" target="_blank">00:03:52.120</a></span> | <span class="t">time step, we don't look it up, we just call the function. And now the time step is a random</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=240" target="_blank">00:04:00.920</a></span> | <span class="t">float between 0 and 1, actually between 0 and 1.999, which actually I'm sure there's a function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=249" target="_blank">00:04:09.920</a></span> | <span class="t">I could have chosen to do a float in this range, but I just tapped it because I was lazy. Couldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=254" target="_blank">00:04:14.960</a></span> | <span class="t">be bothered hooking it up. Other than that, Noisify is exactly the same. So we're still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=262" target="_blank">00:04:22.440</a></span> | <span class="t">returning the xt, the time step, which is now a float, and the noise. That's the thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=270" target="_blank">00:04:30.960</a></span> | <span class="t">we're going to try and predict, dependent variable, this tuple there as our inputs to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=275" target="_blank">00:04:35.520</a></span> | <span class="t">the model. All right, so here is what that looks like. So now when we look at our input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=284" target="_blank">00:04:44.600</a></span> | <span class="t">to our unit training process, you can see we've got a T of 0.05, so 5% of the way through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=291" target="_blank">00:04:51.840</a></span> | <span class="t">the forward diffusion process, it looks like this, and 65% through it looks like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=298" target="_blank">00:04:58.000</a></span> | <span class="t">So now the time step and basically the process is more of a kind of a continuous time step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=308" target="_blank">00:05:08.200</a></span> | <span class="t">and a continuous process. Rather before we were having these discrete time steps here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=313" target="_blank">00:05:13.280</a></span> | <span class="t">we get just any random value that could be between 0 and 1. I think, yeah, that's also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=318" target="_blank">00:05:18.720</a></span> | <span class="t">something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=319" target="_blank">00:05:19.720</a></span> | <span class="t">Yeah, we should kind of get this more convenient, you know, to have...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=322" target="_blank">00:05:22.240</a></span> | <span class="t">Yeah, it is convenient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=323" target="_blank">00:05:23.240</a></span> | <span class="t">To have a function to call. Yeah, I find this life a little bit easier. So the model's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=331" target="_blank">00:05:31.640</a></span> | <span class="t">same, the callbacks are the same, the fitting process is the same. And so something which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=339" target="_blank">00:05:39.400</a></span> | <span class="t">is kind of fun is that we could now, we can, when we do now, create a little denoise function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=346" target="_blank">00:05:46.680</a></span> | <span class="t">So we can take, you know, this batch of data that we generated, the noisified data, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=354" target="_blank">00:05:54.160</a></span> | <span class="t">here it is again, and we can denoise it. So we know the T for each element, obviously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=363" target="_blank">00:06:03.880</a></span> | <span class="t">So remember T is different for each element now. And we can therefore calculate the alpha</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=371" target="_blank">00:06:11.720</a></span> | <span class="t">bar for each element. And then we can just undo the noisification to get the denoised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=379" target="_blank">00:06:19.280</a></span> | <span class="t">version. And so if we do that, there's what we get. And so this is great, right? It shows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=385" target="_blank">00:06:25.360</a></span> | <span class="t">you what actually happens when we run a single step of the model on variatingly, partially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=393" target="_blank">00:06:33.960</a></span> | <span class="t">noised images. And this is something you don't see very often because I guess not many people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=399" target="_blank">00:06:39.120</a></span> | <span class="t">are working in these kind of interactive notebook environments where it's really easy to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=402" target="_blank">00:06:42.640</a></span> | <span class="t">this kind of thing. But I think this is really helpful to get a sense of like, okay, if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=406" target="_blank">00:06:46.600</a></span> | <span class="t">25% of the way through the forward diffusion process, this is what it looks like when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=411" target="_blank">00:06:51.800</a></span> | <span class="t">undo that. If you're 95% of the way through it, this is what happens when you undo that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=419" target="_blank">00:06:59.800</a></span> | <span class="t">So you can see here, it's basically like, oh, I don't really know what the hell's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=423" target="_blank">00:07:03.160</a></span> | <span class="t">on, so at least a noisy mess. Yeah, I guess my feeling from looking at this is, I'm impressed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=435" target="_blank">00:07:15.720</a></span> | <span class="t">you know, like this 45% noise thing, it looks all noise to me. It's found the long-sleeved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=444" target="_blank">00:07:24.400</a></span> | <span class="t">top. And yeah, it's actually pretty close to the real one. I looked it up, or you might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=451" target="_blank">00:07:31.400</a></span> | <span class="t">see it later, it's a little bit more of a pattern here, but it even gives a sense of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=455" target="_blank">00:07:35.320</a></span> | <span class="t">the pattern. So it shows you how impressive this is. So this is 35%. You can kind of see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=461" target="_blank">00:07:41.040</a></span> | <span class="t">there's a shoe there, but it's really picked up the shoe nicely. So these are very impressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=467" target="_blank">00:07:47.040</a></span> | <span class="t">models in one step, in my opinion. So, okay, so sampling is basically the same, except</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=481" target="_blank">00:08:01.640</a></span> | <span class="t">now rather than starting with using the range function to create our timesteps, we use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=489" target="_blank">00:08:09.360</a></span> | <span class="t">lin space to create our timesteps. So our timesteps start at, you know, if we did 1000, it would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=497" target="_blank">00:08:17.560</a></span> | <span class="t">be 0.999, and they end at 0, and then they're just linearly spaced with this number of steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=504" target="_blank">00:08:24.520</a></span> | <span class="t">So other than that, you know, a bar we now calculate, and the next a bar is going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=513" target="_blank">00:08:33.160</a></span> | <span class="t">be whatever the current step is, minus 1 over steps. So if you're doing 100 steps, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=520" target="_blank">00:08:40.520</a></span> | <span class="t">you'd be minus 0.01. So this is just stepping through linearly. And yeah, that's actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=531" target="_blank">00:08:51.680</a></span> | <span class="t">it for changes. So if we just do DDIM for 100 steps, you know, that works really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=544" target="_blank">00:09:04.000</a></span> | <span class="t">We get a fit of 3, which is actually quite a bit better than we had on 100 steps for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=553" target="_blank">00:09:13.160</a></span> | <span class="t">our previous DDIM. So this definitely seems like a good sampling, sampling, sampling approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=561" target="_blank">00:09:21.280</a></span> | <span class="t">And I know Jono's going to talk a bit more shortly about, you know, some of the things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=566" target="_blank">00:09:26.760</a></span> | <span class="t">that can make better sampling approaches, but yeah, definitely we can see it making</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=571" target="_blank">00:09:31.960</a></span> | <span class="t">a difference here. Did you guys have anything you wanted to say about this before we move</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=576" target="_blank">00:09:36.600</a></span> | <span class="t">on?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=577" target="_blank">00:09:37.600</a></span> | <span class="t">No, but it is a nice transition towards some of the other things we'll be looking at to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=582" target="_blank">00:09:42.880</a></span> | <span class="t">start thinking about how do we frame this. And it's also good, like the idea, so the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=588" target="_blank">00:09:48.280</a></span> | <span class="t">original DDPM paper has this 1,000 time steps, and a lot of people followed that. But the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=593" target="_blank">00:09:53.680</a></span> | <span class="t">idea that you don't have to be bound to that, and maybe it is worth breaking that convention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=597" target="_blank">00:09:57.520</a></span> | <span class="t">I know Tanish made that meme about, you know, this 15 competing different standards connotation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=603" target="_blank">00:10:03.160</a></span> | <span class="t">But yeah, sometimes it's helpful to reframe it, okay, time goes from 0 to 1. That can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=607" target="_blank">00:10:07.400</a></span> | <span class="t">simplify some things. It complicates others, but yeah, it's nice to think how you can reframe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=612" target="_blank">00:10:12.480</a></span> | <span class="t">stuff sometimes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=613" target="_blank">00:10:13.480</a></span> | <span class="t">In fact, where we will head today by the time we get to notebook 23, we will see, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=621" target="_blank">00:10:21.560</a></span> | <span class="t">even simpler notation. And yeah, simpler notation generally comes. I think what happens is over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=627" target="_blank">00:10:27.600</a></span> | <span class="t">time people understand better what's the essence of the problem and the approach, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=635" target="_blank">00:10:35.040</a></span> | <span class="t">that gets reflected in the notation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=640" target="_blank">00:10:40.680</a></span> | <span class="t">So okay, so the next one I wanted to share is something which is an idea we've been working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=647" target="_blank">00:10:47.120</a></span> | <span class="t">on for a while, and it's some new research. So partly, I guess this is an interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=652" target="_blank">00:10:52.880</a></span> | <span class="t">like insight into how we do research. So this is 22 noise pred. And the basic idea of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=662" target="_blank">00:11:02.440</a></span> | <span class="t">was, well, actually, I've got to take you through it to see what the basic idea is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=666" target="_blank">00:11:06.480</a></span> | <span class="t">So what I'm going to do is I'm going to create, okay, so fashion MNIST as before, but I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=673" target="_blank">00:11:13.120</a></span> | <span class="t">going to create a different kind of model. I'm not going to create a model that predicts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=677" target="_blank">00:11:17.480</a></span> | <span class="t">the noise given the noised image in t. Instead, I'm going to try to create a model which predicts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=686" target="_blank">00:11:26.600</a></span> | <span class="t">t given the noised image. So why did I want to do that? Well, partly, well, entirely because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=694" target="_blank">00:11:34.000</a></span> | <span class="t">I was curious. I felt like when I looked at something like this, I thought it was pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=701" target="_blank">00:11:41.380</a></span> | <span class="t">obvious roughly how much noise each image had. And so I thought, why are we passing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=710" target="_blank">00:11:50.280</a></span> | <span class="t">noise when we call the model? Why are we passing in the noised image and the amount of noise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=715" target="_blank">00:11:55.640</a></span> | <span class="t">or the t? Given that I would have thought the model could figure out how much noise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=719" target="_blank">00:11:59.560</a></span> | <span class="t">there is. So I wanted to check my contention, which is that the model could figure out how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=724" target="_blank">00:12:04.520</a></span> | <span class="t">much noise there is. So I thought, okay, well, let's create a model that would try and figure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=728" target="_blank">00:12:08.200</a></span> | <span class="t">out how much noise there is. So I created a different noisify now, and this noisify grabs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=737" target="_blank">00:12:17.160</a></span> | <span class="t">an alpha bar t randomly. And it's just a random number between 0 and 1. You don't want 1 per</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=752" target="_blank">00:12:32.600</a></span> | <span class="t">item in the batch. And so then after just randomly grabbing an alpha bar t, we then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=758" target="_blank">00:12:38.800</a></span> | <span class="t">noisify in the usual way. But now our independent variable is the noised image and the dependent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=765" target="_blank">00:12:45.080</a></span> | <span class="t">variable is alpha bar t. And so we've got to try to create a model that can predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=768" target="_blank">00:12:48.920</a></span> | <span class="t">alpha bar t given a noised image. Okay, so everything else is the same as usual. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=777" target="_blank">00:12:57.280</a></span> | <span class="t">so we can see an example. You've got alpha bar t.squeeze.logit. Oh, yeah, that's true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=784" target="_blank">00:13:04.320</a></span> | <span class="t">So the alpha bar t goes between 0 and 1. So we've got a choice. Like, I mean, we don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=792" target="_blank">00:13:12.080</a></span> | <span class="t">have to do anything. But normally, if you've got something between 0 and 1, you might consider</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=796" target="_blank">00:13:16.400</a></span> | <span class="t">putting a sigmoid at the end of your model. But I felt like the difference between 0.999</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=804" target="_blank">00:13:24.080</a></span> | <span class="t">and 0.99 is very significant. So if we do log it, then we don't need the sigmoid at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=813" target="_blank">00:13:33.440</a></span> | <span class="t">end anymore. It will naturally cover the full range of kind of-- it ought to be centered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=819" target="_blank">00:13:39.280</a></span> | <span class="t">at 0. It would have covered all the normal kind of range of numbers. And it also will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=824" target="_blank">00:13:44.060</a></span> | <span class="t">treat equal ratios as equally important at both ends of the spectrum. So that was my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=831" target="_blank">00:13:51.800</a></span> | <span class="t">hypothesis was that using logit would be better. I did test it and it was actually very dramatically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=836" target="_blank">00:13:56.880</a></span> | <span class="t">better. So without this logit here, my model didn't work well at all. And so this is like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=841" target="_blank">00:14:01.760</a></span> | <span class="t">an example of where thinking about these details is really important. Because if I hadn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=847" target="_blank">00:14:07.040</a></span> | <span class="t">have done this, then I would have come away from this bit of research thinking like, oh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=850" target="_blank">00:14:10.720</a></span> | <span class="t">I was wrong. We can't predict noise amount. Yeah. So thanks for pointing that out, China.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=857" target="_blank">00:14:17.280</a></span> | <span class="t">Yeah. So that's why in this example of a mini batch, you can see that the numbers can be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=863" target="_blank">00:14:23.280</a></span> | <span class="t">negative or positive. So 0 would represent alpha bar of 0.5. So here, 3.05 is not very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=871" target="_blank">00:14:31.120</a></span> | <span class="t">noise at all, or else negative 1 is pretty noisy. So the idea is that, yeah, given this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=880" target="_blank">00:14:40.400</a></span> | <span class="t">image, you would have to try to predict 3.05. So one thing I was kind of curious about is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=889" target="_blank">00:14:49.680</a></span> | <span class="t">like, it's always useful to know is like, what's the baseline? Like, what counts as good? Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=894" target="_blank">00:14:54.120</a></span> | <span class="t">often people will say to me like, oh, I created a model and the MSE was 2.6. And I'll be like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=899" target="_blank">00:14:59.760</a></span> | <span class="t">well, is that good? Well, it's the best I can do, but is it good? Like, or is it better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=905" target="_blank">00:15:05.440</a></span> | <span class="t">than random or is it better than predicting the average? So in this case, I was just like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=912" target="_blank">00:15:12.080</a></span> | <span class="t">okay, well, what if we just predicted? Actually, this is slightly out of date. I should have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=916" target="_blank">00:15:16.440</a></span> | <span class="t">said 0 here rather than 0.5, but never mind close enough. So this is before I did the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=924" target="_blank">00:15:24.040</a></span> | <span class="t">logit thing. So I basically was looking at like, what's the loss if you just always predicted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=934" target="_blank">00:15:34.760</a></span> | <span class="t">a constant, which as I said, I should have put 0 here, haven't updated it. And so it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=941" target="_blank">00:15:41.760</a></span> | <span class="t">like, oh, that would give you a loss of 3.5. Or another way to do it is you could just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=949" target="_blank">00:15:49.560</a></span> | <span class="t">put MSE here and then look at the MSE loss between 0.5 and your various, just a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=960" target="_blank">00:16:00.320</a></span> | <span class="t">mini batch, mini batch of alphabets, logits. Yeah, so we wanted to get some, if we're getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=970" target="_blank">00:16:10.880</a></span> | <span class="t">something that's about 3, then we basically haven't done any better than random. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=976" target="_blank">00:16:16.760</a></span> | <span class="t">in this case, this model, it doesn't actually have anything to learn. It always returns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=983" target="_blank">00:16:23.260</a></span> | <span class="t">the same thing. So we can just call fit with trade equals false just to find the loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=988" target="_blank">00:16:28.480</a></span> | <span class="t">So this is just a couple of ways of getting quickly finding a loss for a baseline naive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=994" target="_blank">00:16:34.400</a></span> | <span class="t">model. One thing that thankfully PyTorch will warn you about is if you try to use MSE and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1008" target="_blank">00:16:48.800</a></span> | <span class="t">your inputs and targets have different shapes, it will broadcast and give you probably not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1013" target="_blank">00:16:53.720</a></span> | <span class="t">the result you would expect, and it will give you a warning. So one way to avoid that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1018" target="_blank">00:16:58.480</a></span> | <span class="t">just to use dot flatten on each. So this kind of flattened MSE is useful to avoid the warning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1029" target="_blank">00:17:09.200</a></span> | <span class="t">and also avoid getting weird errors or weird results. So we use that for our loss. So the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1035" target="_blank">00:17:15.560</a></span> | <span class="t">model's the model that we always use. So it's kind of nice. We just use our same old model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1042" target="_blank">00:17:22.320</a></span> | <span class="t">Same changes. Even though we're doing something totally different. Oh, well, okay, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1051" target="_blank">00:17:31.360</a></span> | <span class="t">not quite true. One difference is that our output, we just have one output now, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1055" target="_blank">00:17:35.600</a></span> | <span class="t">this is now a regression model. It's just trying to predict a single number. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1059" target="_blank">00:17:39.880</a></span> | <span class="t">our learner now uses MSE as a loss. Everything else is the same as usual. So we could go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1068" target="_blank">00:17:48.240</a></span> | <span class="t">ahead and trade it. And you can see, okay, the loss is already much better than 3, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1071" target="_blank">00:17:51.680</a></span> | <span class="t">we're definitely learning something. And we end up with a 0.075 mean squared error. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1081" target="_blank">00:18:01.080</a></span> | <span class="t">pretty good considering, you know, there's a pretty wide range of numbers we're trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1085" target="_blank">00:18:05.800</a></span> | <span class="t">to predict here. So I've got to save that as noise prediction on sigma. So save that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1094" target="_blank">00:18:14.920</a></span> | <span class="t">model. And so we can take a look at how it's doing by grabbing our one batch of noise images,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1105" target="_blank">00:18:25.120</a></span> | <span class="t">putting it through our T model. Actually, it's really an alpha bar model, but never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1109" target="_blank">00:18:29.960</a></span> | <span class="t">mind, call it a T model. And then we can take a look to see what it's predicted for each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1115" target="_blank">00:18:35.120</a></span> | <span class="t">one. And we can compare it to the actual for each one. And so you can see here it said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1122" target="_blank">00:18:42.240</a></span> | <span class="t">oh, I think this is about 0.91. And actually, it is 0.91. I said, oh, here it looks like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1127" target="_blank">00:18:47.760</a></span> | <span class="t">about 0.36. And yeah, it is actually 0.36. So, you know, you can see overall 0.72. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1134" target="_blank">00:18:54.120</a></span> | <span class="t">actually 0.72. Well, those are exactly right. This one's 0.02 off. But yeah, my hypothesis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1139" target="_blank">00:18:59.760</a></span> | <span class="t">was correct, which is that we, you know, we can predict the thing that we were putting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1146" target="_blank">00:19:06.480</a></span> | <span class="t">in manually as input. So there's a couple of reasons I was interested in checking this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1152" target="_blank">00:19:12.820</a></span> | <span class="t">out. You know, the first was just like, well, yeah, wouldn't it be simpler if we weren't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1159" target="_blank">00:19:19.040</a></span> | <span class="t">passing in the T each time? You know, why not pass in the T each time? But it also felt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1164" target="_blank">00:19:24.600</a></span> | <span class="t">like it would open up a wider range of kind of how we can do sampling. The idea of doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1171" target="_blank">00:19:31.700</a></span> | <span class="t">sampling by like precisely controlling the amount of noise that you try to remove each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1177" target="_blank">00:19:37.720</a></span> | <span class="t">time and then assuming you can remove exactly that amount of noise each time feels limited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1185" target="_blank">00:19:45.000</a></span> | <span class="t">to me. So I want to try to remove this constraint. So having, yeah, built this model, I thought,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1196" target="_blank">00:19:56.560</a></span> | <span class="t">okay, well, you know, which is basically like, okay, I think we don't need to pass T in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1201" target="_blank">00:20:01.180</a></span> | <span class="t">Let's try it. So what I then did is I replicated the 22 cosine notebook. I just copied it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1206" target="_blank">00:20:06.720</a></span> | <span class="t">pasted it in here. But I made a couple of changes. The first is that Noisify doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1216" target="_blank">00:20:16.440</a></span> | <span class="t">return T anymore. So there's no way to cheat. We don't know what T is. And so that means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1225" target="_blank">00:20:25.440</a></span> | <span class="t">that the unit now doesn't have T, so it's actually going to pass zero every time. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1233" target="_blank">00:20:33.400</a></span> | <span class="t">it has no ability to learn from T because it doesn't get T. So it doesn't really matter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1238" target="_blank">00:20:38.840</a></span> | <span class="t">what we pass in. We could have changed the unit to like remove the conditioning on T.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1246" target="_blank">00:20:46.260</a></span> | <span class="t">But for research, this is just as good, you know, for finding out. And it's good to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1251" target="_blank">00:20:51.600</a></span> | <span class="t">lazy when doing research. There's no point doing something a fancy way where you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1255" target="_blank">00:20:55.080</a></span> | <span class="t">do it a quick and easy way before you even know if it's going to work. So yeah, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1260" target="_blank">00:21:00.700</a></span> | <span class="t">the only change. So we can then train the model and we can check the loss. So the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1266" target="_blank">00:21:06.880</a></span> | <span class="t">here is 0.034. And previously it was 0.033. So interestingly, you know, maybe it's a tiny</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1281" target="_blank">00:21:21.080</a></span> | <span class="t">bit worse at that, you know, but it's very close. Okay, so we'll save that model. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1291" target="_blank">00:21:31.600</a></span> | <span class="t">then for sampling, I've got exactly the same DDIM step as usual. And my sampling is exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1303" target="_blank">00:21:43.360</a></span> | <span class="t">the same as usual, except now, when I call the model, I have no T to pass in. So we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1313" target="_blank">00:21:53.720</a></span> | <span class="t">pass in this. I mean, I still know T because I'm still using the usual sampling approach,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1322" target="_blank">00:22:02.560</a></span> | <span class="t">but I'm not passing it to the model. And yeah, we can sample. And what happens is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1331" target="_blank">00:22:11.360</a></span> | <span class="t">pretty garbage. 22 is our fit. And as you can see here, you know, some of the images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1344" target="_blank">00:22:24.720</a></span> | <span class="t">are still really noisy. So I totally failed. And so that's always a little discouraging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1354" target="_blank">00:22:34.720</a></span> | <span class="t">when you think something's going to work and it doesn't. But my reaction to that is like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1359" target="_blank">00:22:39.280</a></span> | <span class="t">if I think something's going to work and it doesn't is to think, well, I'm just going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1363" target="_blank">00:22:43.040</a></span> | <span class="t">to have to do a better job of it. You know, it ought to work. So I tried something different,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1371" target="_blank">00:22:51.840</a></span> | <span class="t">which is I thought like, okay, since we're not passing in the T, then we're basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1382" target="_blank">00:23:02.700</a></span> | <span class="t">saying like, how much noise should you be removing? It doesn't know exactly. So it might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1388" target="_blank">00:23:08.320</a></span> | <span class="t">remove a little bit more noise that we want or a little bit less noise than we want. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1393" target="_blank">00:23:13.000</a></span> | <span class="t">we know from the testing we did that sometimes it's out by like, in this case, 0.02. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1403" target="_blank">00:23:23.000</a></span> | <span class="t">I guess if you're out consistently, sometimes it's got to end up not removing all the noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1409" target="_blank">00:23:29.860</a></span> | <span class="t">So the change I made was to the DDAM step, which is here. And let me just copy this and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1419" target="_blank">00:23:39.880</a></span> | <span class="t">get rid of the commented out sections just to make it a bit easier to read. Okay. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1430" target="_blank">00:23:50.320</a></span> | <span class="t">the DDAM step, this is the normal DDAM step. Okay. And so step one is the same. So don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1436" target="_blank">00:23:56.320</a></span> | <span class="t">worry about that because it's the same as we've seen before. But what I did was I actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1442" target="_blank">00:24:02.240</a></span> | <span class="t">used my T model. So I passed the noised image into my T model, which is actually an alpha</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1448" target="_blank">00:24:08.900</a></span> | <span class="t">bar model, to get the predicted alpha bar. And this is remember the predicted alpha bar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1455" target="_blank">00:24:15.640</a></span> | <span class="t">for each image, because we know from here that sometimes, so sometimes it did a pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1460" target="_blank">00:24:20.860</a></span> | <span class="t">good job, right? But sometimes it didn't. So I felt like, okay, we need a predicted alpha</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1466" target="_blank">00:24:26.480</a></span> | <span class="t">bar for each image. What I then discovered is sometimes that could be really too low.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1479" target="_blank">00:24:39.100</a></span> | <span class="t">So what I wanted to make sure is it wasn't too crazy. So I then found the median for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1483" target="_blank">00:24:43.760</a></span> | <span class="t">a mini batch of all the predicted alpha bars, and I clamped it to not be too far away from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1489" target="_blank">00:24:49.360</a></span> | <span class="t">the median. And so then what I did when I did my X naught hat is rather than using alpha</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1498" target="_blank">00:24:58.400</a></span> | <span class="t">bar T, I used the estimated alpha bar T for each image, clamped to be not too far away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1506" target="_blank">00:25:06.720</a></span> | <span class="t">from the median. And so this way it was updating it based on the amount of noise that actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1512" target="_blank">00:25:12.520</a></span> | <span class="t">seems to be left behind, rather than the assumed amount of noise that should be left behind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1519" target="_blank">00:25:19.240</a></span> | <span class="t">you know, if we assume it's removed the correct amount. And then everything else is the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1526" target="_blank">00:25:26.800</a></span> | <span class="t">So when I did that, say, whoa, made all the difference. And here it is. They are beautiful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1538" target="_blank">00:25:38.360</a></span> | <span class="t">pieces of clothing. So 3.88 versus 3.2. That's possibly close enough, like I'd have to run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1553" target="_blank">00:25:53.760</a></span> | <span class="t">it a few times, you know, my guess is maybe it's a tiny bit worse, but it's pretty close.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1560" target="_blank">00:26:00.360</a></span> | <span class="t">But like this definitely gives me some encouragement that, you know, even though this is like something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1570" target="_blank">00:26:10.400</a></span> | <span class="t">I just did in a couple of days, where else the kind of the with T approaches have been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1573" target="_blank">00:26:13.980</a></span> | <span class="t">developed since 2015, and we're now in 2023. You know, I would expect it's quite likely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1581" target="_blank">00:26:21.280</a></span> | <span class="t">that these kind of like, no, no T approaches could eventually surpass the T based approaches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1595" target="_blank">00:26:35.080</a></span> | <span class="t">And like one thing that definitely makes me think there's room to improve is if I plot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1599" target="_blank">00:26:39.880</a></span> | <span class="t">the fit or the kid, or each sample during the reverse diffusion process, it actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1605" target="_blank">00:26:45.080</a></span> | <span class="t">gets worse for a while. I'm like, okay, well, that's, that's a bad sign. I have no idea</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1610" target="_blank">00:26:50.320</a></span> | <span class="t">why that's happening. But it's a sign that, you know, if we could improve each step that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1615" target="_blank">00:26:55.600</a></span> | <span class="t">one would assume we could get better than 3.8. So yeah, Tanishko, do you have any thoughts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1623" target="_blank">00:27:03.740</a></span> | <span class="t">about that, or questions or comments or maybe to just like, to highlight that the research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1632" target="_blank">00:27:12.440</a></span> | <span class="t">process a little bit, it wasn't like this linear thing of like, Oh, here's this issue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1637" target="_blank">00:27:17.280</a></span> | <span class="t">Not for me as well as we thought. Oh, here's the fix. We just scrapped this. You know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1642" target="_blank">00:27:22.300</a></span> | <span class="t">this was like multiple days of like, discussing and like Jeremy saying, like, you know, I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1646" target="_blank">00:27:26.760</a></span> | <span class="t">taking my hair out. Do you guys have any ideas? And Oh, what about this? And Oh, and I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1650" target="_blank">00:27:30.360</a></span> | <span class="t">in the team paper, they do this clamping, maybe that'll help. You know, so there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1653" target="_blank">00:27:33.240</a></span> | <span class="t">a lot of back and forth. And also a lot of like, you saw that code that was commented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1656" target="_blank">00:27:36.640</a></span> | <span class="t">out there, prints, xt.min, xt.max, alphabar, pred, you know, just like seeing, oh, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1663" target="_blank">00:27:43.760</a></span> | <span class="t">you know, my average prediction is about what I would expect. But sometimes the middle of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1666" target="_blank">00:27:46.520</a></span> | <span class="t">the max goes, you know, 2, 3, 8, 16, 150, 212 million, infinity, you know, maybe like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1674" target="_blank">00:27:54.640</a></span> | <span class="t">one or two little values that would just skyrocket out. Yeah, and so that kind of like, debugging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1680" target="_blank">00:28:00.160</a></span> | <span class="t">and exploring and printing things out. And actually, our initial discussions about this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1685" target="_blank">00:28:05.800</a></span> | <span class="t">idea, I kind of said to you guys, before lesson one of part two, I said, like, it feels to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1692" target="_blank">00:28:12.600</a></span> | <span class="t">me like we shouldn't need the t thing. And so it's actually been like, mumbling away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1697" target="_blank">00:28:17.520</a></span> | <span class="t">in the background for the months. Yeah, yeah. And I guess I mean, we should also mention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1704" target="_blank">00:28:24.960</a></span> | <span class="t">we have tried this, like a friend of ours trained a no T version of stable diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1708" target="_blank">00:28:28.960</a></span> | <span class="t">for us. And we did the same sort of thing. I trained a pretty bad T predictor and it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1714" target="_blank">00:28:34.160</a></span> | <span class="t">sort of generates samples. So we're not like focusing on that large scale stuff yet. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1719" target="_blank">00:28:39.840</a></span> | <span class="t">it is fun to like, every now and again, got this idea from fashion in this, we are trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1724" target="_blank">00:28:44.480</a></span> | <span class="t">these out on some bigger models and seeing, okay, this does seem like maybe it'll work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1728" target="_blank">00:28:48.920</a></span> | <span class="t">And to down the line that future plan is to say that's actually, you know, spend the time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1732" target="_blank">00:28:52.400</a></span> | <span class="t">train a proper model, and see, yeah, see how well that does. If it's interesting, you say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1737" target="_blank">00:28:57.120</a></span> | <span class="t">a friend of ours, we can be more specific. It's Robert, one of the two lead authors of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1741" target="_blank">00:29:01.640</a></span> | <span class="t">the stable diffusion paper who actually has been fine tuning a real stale stable diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1747" target="_blank">00:29:07.480</a></span> | <span class="t">model, which is without T and it's looking super encouraging. So yeah, that'll be fun</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1756" target="_blank">00:29:16.600</a></span> | <span class="t">to play with with this new, you know, we'll have to train a T predictor for that. See</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1762" target="_blank">00:29:22.160</a></span> | <span class="t">how it looks. Yeah. All right. So I guess the other area we've been talking about kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1772" target="_blank">00:29:32.080</a></span> | <span class="t">of doing some research on is this weird thing that came up over the last two weeks where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1779" target="_blank">00:29:39.680</a></span> | <span class="t">our bug in the DDPM implementation, where we accidentally weren't doing it from minus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1785" target="_blank">00:29:45.600</a></span> | <span class="t">one to one for the input range, it turned out that actually being from minus one to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1790" target="_blank">00:29:50.760</a></span> | <span class="t">one wasn't a very good idea anyway. And so we ended up centering it as being from minus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1798" target="_blank">00:29:58.460</a></span> | <span class="t">point five to point five, and John O and Tanishk have managed to actually find a paper. Well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1806" target="_blank">00:30:06.800</a></span> | <span class="t">I say find a paper, a paper has come out in the last 24 hours, which has coincidentally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1815" target="_blank">00:30:15.160</a></span> | <span class="t">cast some light on this and has also cited a paper that we weren't aware of, which was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1821" target="_blank">00:30:21.080</a></span> | <span class="t">not released in the last 24 hours. So John O, are you going to tell us a bit about that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1825" target="_blank">00:30:25.120</a></span> | <span class="t">Yeah, sure. I can do that. So it's funny, this was such perfect timing because I actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1831" target="_blank">00:30:31.600</a></span> | <span class="t">got up early this morning planning to run with the different input scalings and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1836" target="_blank">00:30:36.720</a></span> | <span class="t">cosine schedule that Jeremy was showing and some of the other schedulers we look at. I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1840" target="_blank">00:30:40.000</a></span> | <span class="t">thought it might be nice for the lesson to have a little plot of like, what is the fit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1844" target="_blank">00:30:44.440</a></span> | <span class="t">with these different solvers and input scalings, but it was going to be a lot of work. I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1848" target="_blank">00:30:48.080</a></span> | <span class="t">not looking forward to doing the groundwork. And then Tanishk sent me this paper, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1852" target="_blank">00:30:52.120</a></span> | <span class="t">AK had just tweeted out because he reviews anything that comes up on archive every day</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1856" target="_blank">00:30:56.640</a></span> | <span class="t">on the importance of noise scheduling for diffusion models. And this is by a researcher</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1861" target="_blank">00:31:01.000</a></span> | <span class="t">at the Google Brain team, who's also done a really cool recent paper on something called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1865" target="_blank">00:31:05.560</a></span> | <span class="t">a recurrent interface network outside of the scope of this lesson, but also worth checking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1869" target="_blank">00:31:09.680</a></span> | <span class="t">out. Yeah, so this paper they're hoping to study this noise scheduling and the strategies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1876" target="_blank">00:31:16.340</a></span> | <span class="t">that you take for that. And they want to show that number one, those scheduling is crucial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1880" target="_blank">00:31:20.320</a></span> | <span class="t">for performance and the optimal one depends on the tasks. When increasing the image size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1885" target="_blank">00:31:25.320</a></span> | <span class="t">the noise scheduling that you want changes and scaling the input data by some factor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1891" target="_blank">00:31:31.960</a></span> | <span class="t">is a good strategy for working with this. And that's the big thing we've been talking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1895" target="_blank">00:31:35.800</a></span> | <span class="t">about, right? Yeah, that's what we've been doing where we said, oh, do we scale from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1899" target="_blank">00:31:39.320</a></span> | <span class="t">minus 0.5 to 0.5 or minus 1 to 1 or do we normalize? And so they demonstrate the effectiveness</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1905" target="_blank">00:31:45.160</a></span> | <span class="t">by training a really good high resolution model on image met, so class condition model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1911" target="_blank">00:31:51.320</a></span> | <span class="t">That's correct. Yeah, amazing samples. They'll show one later. So I really like this paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1916" target="_blank">00:31:56.760</a></span> | <span class="t">It's very short and concise, and it just gets all the information across. And so they introduced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1921" target="_blank">00:32:01.960</a></span> | <span class="t">us here. We have this noising process on noiseifier function where we have square root of something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1927" target="_blank">00:32:07.600</a></span> | <span class="t">times x plus square root of 1 minus that something times the noise. And here they use gamma,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1933" target="_blank">00:32:13.800</a></span> | <span class="t">gamma of t, which is often used for the continuous time case. So instead of the alpha bar and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1938" target="_blank">00:32:18.400</a></span> | <span class="t">the beta bar scheduled for 1,000 times tapes, there'll be some function gamma of t that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1942" target="_blank">00:32:22.720</a></span> | <span class="t">tells you what your alpha bar should be. Okay, so that's our function is actually called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1947" target="_blank">00:32:27.400</a></span> | <span class="t">a bar, but it's the same thing. Yeah, same thing. It takes in a time set from 0 to 1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1952" target="_blank">00:32:32.720</a></span> | <span class="t">and then that's used to noise the image. Interestingly, what they're showing here actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1957" target="_blank">00:32:37.040</a></span> | <span class="t">is something that we had discovered, and I've been complaining about that my DTAMs with an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1964" target="_blank">00:32:44.200</a></span> | <span class="t">eater of less than one weren't working, which is to say when I added extra noise to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1969" target="_blank">00:32:49.200</a></span> | <span class="t">image, it wasn't working. And what they're showing here is like, oh yeah, duh, if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1975" target="_blank">00:32:55.560</a></span> | <span class="t">use a smaller image, then adding extra noise is probably not a good idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1981" target="_blank">00:33:01.240</a></span> | <span class="t">Yeah. And so they use a lot of reference in this paper to like information being destroyed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1987" target="_blank">00:33:07.520</a></span> | <span class="t">and signal to noise ratios. And that's really helpful for thinking about because it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1991" target="_blank">00:33:11.920</a></span> | <span class="t">something that's obvious, but at 64 by 64 pixels, adjacent pixels might have much less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=1997" target="_blank">00:33:17.600</a></span> | <span class="t">in common versus the same amount of noise added at a much higher resolution, the noise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2002" target="_blank">00:33:22.800</a></span> | <span class="t">kind of averages out and you can still see a lot of the image. So yeah, that's one thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2006" target="_blank">00:33:26.800</a></span> | <span class="t">they highlight is that the same noise level for different image sizes, it might be a harder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2012" target="_blank">00:33:32.200</a></span> | <span class="t">or easier task. And so they investigate some strategies for this. They look at the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2017" target="_blank">00:33:37.600</a></span> | <span class="t">noise schedule functions. So we've seen the original version from the DTDM paper. We've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2024" target="_blank">00:33:44.080</a></span> | <span class="t">seen the cosine schedule and we've seen, I think we might look at, or the next thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2030" target="_blank">00:33:50.600</a></span> | <span class="t">that Jamie's going to show us, a sigmoid based schedule. So they show the continuous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2035" target="_blank">00:33:55.680</a></span> | <span class="t">time versions of that and they plot how you can change various parameters to get these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2039" target="_blank">00:33:59.660</a></span> | <span class="t">different gamma functions or in our case, the alpha bar, where we starting at all image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2048" target="_blank">00:34:08.560</a></span> | <span class="t">no noise at t equals zero, moving to all noise, no image at t equals one. But the path that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2054" target="_blank">00:34:14.280</a></span> | <span class="t">you take is going to be different for these different classes of functions and parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2059" target="_blank">00:34:19.760</a></span> | <span class="t">And the signal to noise ratio, that's what this or the log signal to noise ratio is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2064" target="_blank">00:34:24.980</a></span> | <span class="t">to change over that time as well. And so that's one of the knobs we can tweak. We're saying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2070" target="_blank">00:34:30.040</a></span> | <span class="t">our diffusion model isn't training that well, we think it might be related to the noise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2073" target="_blank">00:34:33.780</a></span> | <span class="t">schedule and so on. One of the things you could do is try different noise schedules,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2077" target="_blank">00:34:37.080</a></span> | <span class="t">either changing the parameters in one class of noise schedule or switching from a linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2082" target="_blank">00:34:42.240</a></span> | <span class="t">to a cosine to a sigmoid. And then the second strategy is kind of what we were doing in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2087" target="_blank">00:34:47.640</a></span> | <span class="t">those experiments, which is just to add some scaling factor to exit error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2091" target="_blank">00:34:51.600</a></span> | <span class="t">Well, we were accidentally using b of 0.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2099" target="_blank">00:34:59.040</a></span> | <span class="t">Exactly. And so that's the second dial that you can tweak is to say keeping your noise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2103" target="_blank">00:35:03.960</a></span> | <span class="t">schedule fixed, maybe you just scale x zero, which is going to change the ratio of signal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2108" target="_blank">00:35:08.680</a></span> | <span class="t">to noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2109" target="_blank">00:35:09.680</a></span> | <span class="t">And that's what I think there's four in C there is what we were accidentally doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2114" target="_blank">00:35:14.600</a></span> | <span class="t">Yes. Yeah, exactly. And so see if we can get to Oh, yeah. So that again, changes the signal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2123" target="_blank">00:35:23.560</a></span> | <span class="t">to noise for different scalings you get. And so that's fine. So they have a compound, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2128" target="_blank">00:35:28.840</a></span> | <span class="t">have a strategy that combines some of those things. And this is the important part, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2132" target="_blank">00:35:32.320</a></span> | <span class="t">do their experiments. And so they have a nice table of investigating different schedules,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2139" target="_blank">00:35:39.520</a></span> | <span class="t">cosine schedules and sigmoid schedules. And in bold are the best results. And you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2143" target="_blank">00:35:43.640</a></span> | <span class="t">see for 64 by 64 images versus 128 versus 256, the best schedule is not necessarily always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2150" target="_blank">00:35:50.200</a></span> | <span class="t">the same. And so that's like important finding number one, depending on what your data looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2156" target="_blank">00:35:56.640</a></span> | <span class="t">like using a different noise schedule might be optimal. There's no one true best schedule.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2161" target="_blank">00:36:01.840</a></span> | <span class="t">There's no one bad value of, you know, beta min and beta max, that's just magically the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2166" target="_blank">00:36:06.280</a></span> | <span class="t">best. Likewise, for this input scaling at different sizes, with whatever schedules they tested,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2176" target="_blank">00:36:16.520</a></span> | <span class="t">and different values were kind of optimal. And so, yeah, it's just a really great illustration,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2185" target="_blank">00:36:25.000</a></span> | <span class="t">I guess that this is another design choice that's implicit or explicitly part of your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2190" target="_blank">00:36:30.720</a></span> | <span class="t">diffusion model training and sampling is how are you dealing with this, this noise schedule,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2194" target="_blank">00:36:34.960</a></span> | <span class="t">what schedule are you following, what scaling are you doing with your inputs. And by using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2199" target="_blank">00:36:39.480</a></span> | <span class="t">this thinking and doing these experiments, and they come up with a kind of rule of thumb</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2203" target="_blank">00:36:43.800</a></span> | <span class="t">for how to scale the image based on image size, they show that they can, as they increase</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2209" target="_blank">00:36:49.400</a></span> | <span class="t">the resolution, they can still maintain really good performance. Where previously it was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2213" target="_blank">00:36:53.600</a></span> | <span class="t">quite hard to train a really large resolution pixel space model, and they're able to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2220" target="_blank">00:37:00.280</a></span> | <span class="t">that, they get some advantage from their fancy recurrent interface network, but still, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2226" target="_blank">00:37:06.080</a></span> | <span class="t">kind of cool that they can say, look, we get state of the art, high quality, 512 by 512</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2233" target="_blank">00:37:13.360</a></span> | <span class="t">or 1024 by 1024 samples on class-conditioned image net. And using this approach to really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2240" target="_blank">00:37:20.760</a></span> | <span class="t">like consider how well do you train, how many steps do we need to take, one of the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2244" target="_blank">00:37:24.720</a></span> | <span class="t">things in this table is that they compare to previous approaches. Oh, we used, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2249" target="_blank">00:37:29.440</a></span> | <span class="t">a third of the training steps and for the same other settings, and we get better performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2255" target="_blank">00:37:35.420</a></span> | <span class="t">Just because we've chosen that input scaling better. And yeah, so that's the paper, really,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2261" target="_blank">00:37:41.080</a></span> | <span class="t">really nice, great work to the team. And that was very useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2265" target="_blank">00:37:45.440</a></span> | <span class="t">I love that you got up in the morning and thought, oh, it's going to be a hassle training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2273" target="_blank">00:37:53.720</a></span> | <span class="t">all these different models I need to train for different input scalings and different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2278" target="_blank">00:37:58.600</a></span> | <span class="t">sampling approaches. I just look at Twitter first, and then you looked at Twitter and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2284" target="_blank">00:38:04.120</a></span> | <span class="t">there was a paper saying like, hey, we just did a bunch of experiments for different noise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2289" target="_blank">00:38:09.080</a></span> | <span class="t">schedules and input scaling. Yeah, does your life always work that way each other? It seems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2294" target="_blank">00:38:14.760</a></span> | <span class="t">quite blessed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2295" target="_blank">00:38:15.760</a></span> | <span class="t">Yeah, it's very lucky like that. Yeah. You wait long enough, someone else will do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2302" target="_blank">00:38:22.600</a></span> | <span class="t">That's why it shows that the time when the UK starts posting on Twitter, it's like my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2306" target="_blank">00:38:26.460</a></span> | <span class="t">favourite hour of the day for all the papers to be posted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2312" target="_blank">00:38:32.040</a></span> | <span class="t">Oh, well, thank you for that. So let me switch to notebook 23. Because this notebook is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2334" target="_blank">00:38:54.200</a></span> | <span class="t">an implementation of some ideas from this paper that everybody tends to just call it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2341" target="_blank">00:39:01.120</a></span> | <span class="t">Keras because there's other people. But I will do it anyway, Keras paper. And the reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2351" target="_blank">00:39:11.560</a></span> | <span class="t">we're going to look at this is because in this paper, the authors actually take a much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2362" target="_blank">00:39:22.840</a></span> | <span class="t">more explicit look at the question of input scaling. Their approach was not apparently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2372" target="_blank">00:39:32.000</a></span> | <span class="t">to accidentally put a bug in their code, and then take it out, find it worked worse, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2376" target="_blank">00:39:36.800</a></span> | <span class="t">then just put it back in again. Their approach was actually to think, how should things be?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2382" target="_blank">00:39:42.920</a></span> | <span class="t">So that's an interesting approach to doing things, and I guess it works for them. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2386" target="_blank">00:39:46.480</a></span> | <span class="t">that's fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2387" target="_blank">00:39:47.480</a></span> | <span class="t">I think our approach is more infighting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2389" target="_blank">00:39:49.920</a></span> | <span class="t">Yeah, exactly. Our approach is much more fun because you never quite know what's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2394" target="_blank">00:39:54.000</a></span> | <span class="t">to happen. And so, yeah, in their approach, they actually tried to say, like, OK, given</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2401" target="_blank">00:40:01.960</a></span> | <span class="t">all the things that are coming into our model, how can we have them all nicely balanced?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2409" target="_blank">00:40:09.520</a></span> | <span class="t">So we will skip back and forth between the notebook and the paper. So the start of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2416" target="_blank">00:40:16.760</a></span> | <span class="t">is all the same, except now we are actually going to do it minus one to one because we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2423" target="_blank">00:40:23.080</a></span> | <span class="t">not going to rely on accidental bugs anymore, but instead we're going to rely on the Keras</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2426" target="_blank">00:40:26.520</a></span> | <span class="t">papers carefully designed scaling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2433" target="_blank">00:40:33.080</a></span> | <span class="t">I say that, except that I put a bug in this notebook as well. One of the things that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2443" target="_blank">00:40:43.200</a></span> | <span class="t">in the Keras paper is what is the standard deviation of the actual data, which I calculated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2450" target="_blank">00:40:50.760</a></span> | <span class="t">for a batch. However, this used to say minus 0.5. I used to do the minus 0.5 to 0.5 thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2458" target="_blank">00:40:58.720</a></span> | <span class="t">And so this is actually the standard deviation of the data before I, when it was still minus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2463" target="_blank">00:41:03.480</a></span> | <span class="t">0.5. So this is actually half the real standard deviation. For reasons I don't yet understand,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2470" target="_blank">00:41:10.720</a></span> | <span class="t">this is giving me better scaled results. So this actually should be 0.66. So there's still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2478" target="_blank">00:41:18.040</a></span> | <span class="t">a bug here and the bug still seems to work better. So we still got some mysteries involved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2482" target="_blank">00:41:22.720</a></span> | <span class="t">So we're going to leave this. So it's actually, it's actually not 0.33, it's actually 0.66.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2487" target="_blank">00:41:27.640</a></span> | <span class="t">Okay, so the basic idea of this, actually I'll come back. Well, let me have a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2500" target="_blank">00:41:40.400</a></span> | <span class="t">think. Yeah, okay. Now we'll start here. The basic idea of this paper is to say, you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2509" target="_blank">00:41:49.600</a></span> | <span class="t">what, sometimes maybe predicting the noise is a bad idea. And so like you can either</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2521" target="_blank">00:42:01.880</a></span> | <span class="t">try and predict the noise or you can try and predict the clean image and each of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2528" target="_blank">00:42:08.120</a></span> | <span class="t">can be a better idea in different situations. If you're given something which is nearly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2532" target="_blank">00:42:12.520</a></span> | <span class="t">pure noise, you know, the model's given something which is nearly pure noise and is then asked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2538" target="_blank">00:42:18.160</a></span> | <span class="t">to predict the noise. That's basically a waste of time, because the whole thing's noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2546" target="_blank">00:42:26.140</a></span> | <span class="t">If you do the opposite, which is you try to get it predict the clean image. Well, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2550" target="_blank">00:42:30.640</a></span> | <span class="t">if you give it a clean image that's nearly clean and try to predict the clean image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2553" target="_blank">00:42:33.680</a></span> | <span class="t">that's nearly a waste of time as well. So you want something which is like, regardless</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2558" target="_blank">00:42:38.440</a></span> | <span class="t">of how noisy the image is, you want it to be kind of like an equally difficult problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2562" target="_blank">00:42:42.640</a></span> | <span class="t">to solve. And so what Keras do is they, they basically use this new thing called CSKIP,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2577" target="_blank">00:42:57.440</a></span> | <span class="t">which is a number, which is basically saying like, you know what we should do for the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2584" target="_blank">00:43:04.040</a></span> | <span class="t">target is not just predict the noise all the time, not just predict the clean image all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2590" target="_blank">00:43:10.000</a></span> | <span class="t">the time, but predict kind of a looped version of one or the other depending on how noisy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2596" target="_blank">00:43:16.840</a></span> | <span class="t">it is. So here y is the clean image and n is the noise. So y plus n is the noised image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2615" target="_blank">00:43:35.000</a></span> | <span class="t">And so if CSKIP was 0, then we would be predicting the clean image. And if CSKIP was 1, we would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2624" target="_blank">00:43:44.800</a></span> | <span class="t">be predicting y minus y, we would be predicting the noise. And so you can decide by picking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2633" target="_blank">00:43:53.080</a></span> | <span class="t">a different CSKIP whether you're predicting the clean image or the noise. And so, as you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2638" target="_blank">00:43:58.440</a></span> | <span class="t">can see from the way they've written it, they make this a function. They make it a function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2642" target="_blank">00:44:02.080</a></span> | <span class="t">of sigma. Now, this is where we got to a point now where we've kind of got a fairly, a much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2648" target="_blank">00:44:08.760</a></span> | <span class="t">simpler notation. There's no more alpha bars, no more alphas, no more betas, no more beta</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2653" target="_blank">00:44:13.600</a></span> | <span class="t">bars. There's just a single thing called sigma. Unfortunately, sigma is the same thing as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2659" target="_blank">00:44:19.980</a></span> | <span class="t">alpha bar used to be, right? So we've simplified it, but we've also made things more confusing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2664" target="_blank">00:44:24.920</a></span> | <span class="t">by using an existing symbol for something totally different. So this is alpha bar. Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2670" target="_blank">00:44:30.680</a></span> | <span class="t">So there's going to be a function that says, depending on how much noise there is, we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2677" target="_blank">00:44:37.280</a></span> | <span class="t">either predict the noise or we'll predict the clean image or we'll predict something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2682" target="_blank">00:44:42.720</a></span> | <span class="t">between the two. So in the paper, they showed this chart where they basically said like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2693" target="_blank">00:44:53.960</a></span> | <span class="t">okay, let's look at the loss to see how good are we with a trained model at predicting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2702" target="_blank">00:45:02.840</a></span> | <span class="t">when sigma is really low. So when there's very small alpha bar, or when sigma is in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2712" target="_blank">00:45:12.040</a></span> | <span class="t">the middle or when sigma is really high. And they basically said, you know what, when it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2717" target="_blank">00:45:17.520</a></span> | <span class="t">nearly all noise or nearly no noise, you know, we're basically not able to do anything at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2724" target="_blank">00:45:24.240</a></span> | <span class="t">all. You know, we're basically good at doing things when there's a medium amount of noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2732" target="_blank">00:45:32.640</a></span> | <span class="t">So when deciding, okay, what, what sigmas are we going to send to this thing? The first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2738" target="_blank">00:45:38.040</a></span> | <span class="t">thing we need to do is to, is to figure out some sigmas. And they said, okay, well, let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2744" target="_blank">00:45:44.440</a></span> | <span class="t">pick a distribution of sigmas that matches this red curve here, as you can see. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2751" target="_blank">00:45:51.840</a></span> | <span class="t">this is a normally distributed curve where this is on a log scale. So this is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2761" target="_blank">00:46:01.000</a></span> | <span class="t">a log normal curve. So to get the sigmas that they're going to use, they picked a normally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2766" target="_blank">00:46:06.980</a></span> | <span class="t">distributed random number and then they expect it. And this is called a log normal distribution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2774" target="_blank">00:46:14.400</a></span> | <span class="t">And so they used a mean of minus 1.2 and a standard deviation of 1.2. So that means that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2784" target="_blank">00:46:24.120</a></span> | <span class="t">about one third of the time, they're going to be getting a number that's bigger than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2791" target="_blank">00:46:31.080</a></span> | <span class="t">zero here. And e to the zero is one. So about one third of the time, they're going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2798" target="_blank">00:46:38.620</a></span> | <span class="t">picking sigmas that are bigger than one. And so here's a histogram I drew of the sigmas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2807" target="_blank">00:46:47.640</a></span> | <span class="t">that we're going to be using. And so it's nearly always less than five, but sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2815" target="_blank">00:46:55.960</a></span> | <span class="t">it's way out here. And so it's quite hard to read these histograms. So this really nice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2821" target="_blank">00:47:01.440</a></span> | <span class="t">library called Seaborn, which is built on top of Matplotlib, has some more sophisticated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2827" target="_blank">00:47:07.560</a></span> | <span class="t">and often nicer looking plots. And one of them they have is called a KDE plot, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2832" target="_blank">00:47:12.200</a></span> | <span class="t">is a kernel density plot. It's a histogram, but it's smooth. And so I clipped it at 10</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2840" target="_blank">00:47:20.040</a></span> | <span class="t">so that you could see it better. So you can basically see that the vast majority of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2843" target="_blank">00:47:23.680</a></span> | <span class="t">time it's going to be somewhere about 0.4 or 0.5, but sometimes it's going to be really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2849" target="_blank">00:47:29.560</a></span> | <span class="t">big. So our Noisify is going to pick a sigma using that log-normal distribution. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2862" target="_blank">00:47:42.840</a></span> | <span class="t">we're going to get the noise as usual, but now we're going to calculate C skip, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2871" target="_blank">00:47:51.120</a></span> | <span class="t">Because we're going to do that thing we just saw. We're going to find something between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2876" target="_blank">00:47:56.520</a></span> | <span class="t">the plain image and the noised input. So what do we use for C skip? We calculate it here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2890" target="_blank">00:48:10.560</a></span> | <span class="t">And so what we do is we say what's the total amount of variance at some level of sigma?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2897" target="_blank">00:48:17.640</a></span> | <span class="t">Well it's going to be sigma squared, that's the definition of the variance of the noise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2903" target="_blank">00:48:23.000</a></span> | <span class="t">but we also have the sigma of the data itself, right? So if we add those two together we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2908" target="_blank">00:48:28.880</a></span> | <span class="t">get the total variance. And so what the Keras paper said to do is to do the variance of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2919" target="_blank">00:48:39.600</a></span> | <span class="t">the data divided by the total variance and use that for C skip. So that means that if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2928" target="_blank">00:48:48.520</a></span> | <span class="t">your total variance is really big, so in other words it's got a lot of noise, then C skip's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2934" target="_blank">00:48:54.300</a></span> | <span class="t">going to be really small. So if you've got a lot of noise then this bit here will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2940" target="_blank">00:49:00.000</a></span> | <span class="t">really small. So that means if there's a lot of noise try to predict the original image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2946" target="_blank">00:49:06.360</a></span> | <span class="t">right? That makes sense because predicting the noise would be too easy. If there's hardly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2950" target="_blank">00:49:10.900</a></span> | <span class="t">any noise then this will be, total variance will be really small, right? So C skip will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2957" target="_blank">00:49:17.520</a></span> | <span class="t">be really big and so if there's hardly any noise then try to predict the noise. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2965" target="_blank">00:49:25.040</a></span> | <span class="t">that's basically what this C skip does. So it's a kind of slightly weird idea is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2971" target="_blank">00:49:31.760</a></span> | <span class="t">our target, the thing we're trying to do actually is not the input image, sorry the original</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2978" target="_blank">00:49:38.960</a></span> | <span class="t">image, it's not the noise but it's somewhere between the two. And I've found the easiest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2983" target="_blank">00:49:43.080</a></span> | <span class="t">way to understand that is to draw a picture of it. So here is some examples of noised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2989" target="_blank">00:49:49.560</a></span> | <span class="t">input, right? With various sigma's, remember sigma is alpha bar, right? So here's an example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=2998" target="_blank">00:49:58.480</a></span> | <span class="t">with very little noise, 0.06. And so in this case the target is predict the noise, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3007" target="_blank">00:50:07.560</a></span> | <span class="t">So that's the hard thing to do is predict the noise. Whereas here's an example, 4.53</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3014" target="_blank">00:50:14.400</a></span> | <span class="t">which is nearly all noise. So for nearly all noise the target is predict the image, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3022" target="_blank">00:50:22.560</a></span> | <span class="t">And then for something which is a little bit between the two like here, 0.64, the target</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3028" target="_blank">00:50:28.240</a></span> | <span class="t">is predict some of the noise and some of the image. So that's the idea of Paris. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3038" target="_blank">00:50:38.080</a></span> | <span class="t">what this does is it's making the problem to be solved by the unit equally difficult</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3047" target="_blank">00:50:47.400</a></span> | <span class="t">regardless of what sigma is. It doesn't solve our input scaling problem, it solves our kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3055" target="_blank">00:50:55.440</a></span> | <span class="t">of difficulty scaling problem. To solve the input scaling problem they do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3062" target="_blank">00:51:02.160</a></span> | <span class="t">I just want to make one quick note. And so like this sort of idea of like is also interpolating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3068" target="_blank">00:51:08.720</a></span> | <span class="t">between the noise and the image is this similar to what's called the B-objectives as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3075" target="_blank">00:51:15.440</a></span> | <span class="t">So there's also a similar kind of it's yeah, it's very quite similar to what Keras and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3079" target="_blank">00:51:19.120</a></span> | <span class="t">Dell has, but that's also not been used in a lot of different models. Like for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3084" target="_blank">00:51:24.400</a></span> | <span class="t">Stable Diffusion 2.0 was trained with this sort of B-objective. So people are using this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3089" target="_blank">00:51:29.440</a></span> | <span class="t">sort of methodology and getting good results. And yeah, so it's an actual practical thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3095" target="_blank">00:51:35.600</a></span> | <span class="t">that people are doing. So yeah, I just want to make a note of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3098" target="_blank">00:51:38.840</a></span> | <span class="t">Yeah, as is the case of basically all papers created by Nvidia researchers, of which this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3106" target="_blank">00:51:46.360</a></span> | <span class="t">is one. It flies under the radar and everybody ignores it. The V-objective paper came from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3114" target="_blank">00:51:54.280</a></span> | <span class="t">the senior author was Jim Salomons, which is Google, right? Yeah. And so anything from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3120" target="_blank">00:52:00.160</a></span> | <span class="t">Google and OpenAI everybody listens to. So yeah, although Keras I think has done the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3124" target="_blank">00:52:04.880</a></span> | <span class="t">more complete version of this, and in fact the V-objective was almost like mentioned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3132" target="_blank">00:52:12.680</a></span> | <span class="t">in passing in the distillation paper. But yeah, that's the one that everybody has ended</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3137" target="_blank">00:52:17.520</a></span> | <span class="t">up looking at. But I think this is the more...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3139" target="_blank">00:52:19.960</a></span> | <span class="t">Yeah, I think what happened with the V-objective is not many people get attention to it. I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3144" target="_blank">00:52:24.960</a></span> | <span class="t">think folks like Kat and Robin and these sorts of folks are actually paying attention to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3149" target="_blank">00:52:29.280</a></span> | <span class="t">that V-objective in that Google brain paper. But then also this paper did a much more principled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3155" target="_blank">00:52:35.040</a></span> | <span class="t">analysis of this sort of thing. So yeah, I think it's very interesting how sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3160" target="_blank">00:52:40.160</a></span> | <span class="t">even these sort of side notes in papers that maybe people don't pay much attention to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3165" target="_blank">00:52:45.080</a></span> | <span class="t">they can actually be quite important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3167" target="_blank">00:52:47.120</a></span> | <span class="t">Yeah. Yeah. So, okay. So the noised input as usual is the input image plus the noise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3174" target="_blank">00:52:54.000</a></span> | <span class="t">times the sigma. But then, and then as we discussed, we decide how to kind of decide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3181" target="_blank">00:53:01.760</a></span> | <span class="t">what our target is. But then we actually take that noised input and we scale it up or down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3189" target="_blank">00:53:09.520</a></span> | <span class="t">by this number. And the target, we also scale up or down by this number. And those are both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3198" target="_blank">00:53:18.440</a></span> | <span class="t">calculated in this thing as well. So here's C out and here's C in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3208" target="_blank">00:53:28.080</a></span> | <span class="t">Now I just wanted to show one example of where these numbers come from because for a while</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3212" target="_blank">00:53:32.200</a></span> | <span class="t">they all seem pretty mysterious to me and I felt like I'd never be smart enough to understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3216" target="_blank">00:53:36.320</a></span> | <span class="t">them, particularly because they were explained in the mathematical appendix of this paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3221" target="_blank">00:53:41.760</a></span> | <span class="t">which are always the bits I don't understand, until I actually try to and then it tends</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3225" target="_blank">00:53:45.960</a></span> | <span class="t">to turn out they're not so bad after all, which was certainly the case here, which?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3236" target="_blank">00:53:56.000</a></span> | <span class="t">I think it was B something, I think. So B6, I think? Is that the one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3244" target="_blank">00:54:04.880</a></span> | <span class="t">So in appendix B6, which does look pretty terrifying, but if you actually look at, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3254" target="_blank">00:54:14.600</a></span> | <span class="t">what we're just looking at, C in, it's like how do they calculate? So C in is this. Now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3261" target="_blank">00:54:21.360</a></span> | <span class="t">this is the variance of the noise, this is the variance of the data, add them together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3266" target="_blank">00:54:26.240</a></span> | <span class="t">to get the total variance, square roots, the total standard deviation. So it's just the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3271" target="_blank">00:54:31.240</a></span> | <span class="t">inverse of the total standard deviation, which is what we have here. Where does that come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3276" target="_blank">00:54:36.440</a></span> | <span class="t">from? Well, they just said, you know what? The inputs for a model should have unit variance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3285" target="_blank">00:54:45.000</a></span> | <span class="t">Now we know that. We've done that to dare in this course. So they said, right. So well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3293" target="_blank">00:54:53.760</a></span> | <span class="t">the inputs to the model is the, the clean data plus the noise times some number we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3303" target="_blank">00:55:03.520</a></span> | <span class="t">going to calculate and we want that to be one. Okay. So the variance of the plane images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3314" target="_blank">00:55:14.660</a></span> | <span class="t">plus the noise is equal to the variance of the clean images plus the variance of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3320" target="_blank">00:55:20.600</a></span> | <span class="t">noise. Okay. So if we want that to be, if we want variance to be one, then divide both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3331" target="_blank">00:55:31.040</a></span> | <span class="t">sides by this and take the square root. And that tells us that our multiplier has to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3336" target="_blank">00:55:36.840</a></span> | <span class="t">one over this. That's it. So it's like literally, you know, classical math. The only bit you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3345" target="_blank">00:55:45.440</a></span> | <span class="t">have to know is that the variance of three things added together is the variance of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3351" target="_blank">00:55:51.960</a></span> | <span class="t">two things added together, which is not rocket science either.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3357" target="_blank">00:55:57.320</a></span> | <span class="t">And in this context, like why we want to do this, when we looked at those sigma's that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3362" target="_blank">00:56:02.120</a></span> | <span class="t">you're putting like the distribution, you've got some that are fairly low, but you've also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3365" target="_blank">00:56:05.440</a></span> | <span class="t">got some where the standard deviation sigma is like 40, right? So the variance is super</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3369" target="_blank">00:56:09.760</a></span> | <span class="t">high. Yes. And so we don't want to feed something with standard deviation 40 into our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3374" target="_blank">00:56:14.800</a></span> | <span class="t">You would like it to be closer to unit variance. So we're thinking, okay, well, if you divide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3378" target="_blank">00:56:18.360</a></span> | <span class="t">by roughly 40, that would scare it down. But then we've also got some extra variance from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3382" target="_blank">00:56:22.920</a></span> | <span class="t">our data. It's just like 40 plus space of the data of a little bit. We want to scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3390" target="_blank">00:56:30.040</a></span> | <span class="t">back down by that to get unit variance. Yeah. I mean, I love this paper because it's basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3394" target="_blank">00:56:34.440</a></span> | <span class="t">just doing what we spent weeks doing of like, I feel like everything that we've done that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3401" target="_blank">00:56:41.920</a></span> | <span class="t">improved every model has always been one thing, which is, can we get mean zero variance one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3411" target="_blank">00:56:51.360</a></span> | <span class="t">inputs to our model and for all of our activations? And then the only other thing is include enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3420" target="_blank">00:57:00.200</a></span> | <span class="t">compute by adding enough layers and enough activations. Those two things seem to be all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3425" target="_blank">00:57:05.960</a></span> | <span class="t">that matters. Basically, well, I guess ResNet's added an extra cool little thing to that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3431" target="_blank">00:57:11.960</a></span> | <span class="t">which is to make it even smoother by giving this kind of like identity path. So yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3441" target="_blank">00:57:21.600</a></span> | <span class="t">basically trying to make things as smooth as possible and as equal everywhere as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3450" target="_blank">00:57:30.880</a></span> | <span class="t">So yeah, this is what they've done. So they did that for the inputs, and then they've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3454" target="_blank">00:57:34.360</a></span> | <span class="t">also done it for the outputs and for the outputs, it's basically the same idea. They have basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3463" target="_blank">00:57:43.840</a></span> | <span class="t">the same kind of analysis to show that. And so with this, so now, yeah, we've basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3471" target="_blank">00:57:51.920</a></span> | <span class="t">we've got our noised input, we've got the linear version somewhere between X0 and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3480" target="_blank">00:58:00.120</a></span> | <span class="t">noised input, we've got the scaling of the output and we've got the scaling of the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3485" target="_blank">00:58:05.440</a></span> | <span class="t">So now for the inputs to our model, we're going to have the scaled noise, we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3491" target="_blank">00:58:11.680</a></span> | <span class="t">to have the sigma and we're going to have the target, which is somewhere between the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3497" target="_blank">00:58:17.920</a></span> | <span class="t">image and the noise. And so, yeah, so I've never seen anybody draw a picture of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3506" target="_blank">00:58:26.200</a></span> | <span class="t">before. So it was really cool when being in a notebook, being able to see like, oh, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3510" target="_blank">00:58:30.800</a></span> | <span class="t">what they're doing. So yeah, have a good look at this notebook to see exactly what's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3516" target="_blank">00:58:36.680</a></span> | <span class="t">on because I think it gives you a really good intuition around what problem it's trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3521" target="_blank">00:58:41.400</a></span> | <span class="t">to solve. So then I actually checked the noised input has a standard deviation of 1, the main's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3528" target="_blank">00:58:48.640</a></span> | <span class="t">not 0 and of course, why would it be? We didn't do anything. The only thing Keras cared about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3533" target="_blank">00:58:53.440</a></span> | <span class="t">was having the variance 1. We could easily adjust the input and output to have a mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3539" target="_blank">00:58:59.780</a></span> | <span class="t">of 0 as well. And that's something I think we or somebody should try because I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3544" target="_blank">00:59:04.400</a></span> | <span class="t">it does seem to help a bit as we saw with that generalised value stuff we did, but it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3549" target="_blank">00:59:09.120</a></span> | <span class="t">less important than the variance. And so same with the target, it's got the 1. And yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3554" target="_blank">00:59:14.320</a></span> | <span class="t">this is where if I change this to the correct value, which is 0.66, then actually it's slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3561" target="_blank">00:59:21.440</a></span> | <span class="t">further away from 1, both here and here, quite a lot further away. And maybe that's because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3566" target="_blank">00:59:26.440</a></span> | <span class="t">actually the data is, well, we know the data is not Gaussian distributed. Pixel data definitely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3572" target="_blank">00:59:32.240</a></span> | <span class="t">isn't Gaussian distributed. So this bug turned out better. Okay. So the unit's the same,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3581" target="_blank">00:59:41.080</a></span> | <span class="t">the initialisation's the same. This is all the same. Train it for a while. We can't compare</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3587" target="_blank">00:59:47.200</a></span> | <span class="t">the losses because our target's different. But what we can do is we can create a denoise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3595" target="_blank">00:59:55.440</a></span> | <span class="t">that just takes the thing that, as per usual, the thing we had in noisify, right? And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3604" target="_blank">01:00:04.600</a></span> | <span class="t">for x0, it's going to multiply by c out and then add c skip by noised input. Here it is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3610" target="_blank">01:00:10.440</a></span> | <span class="t">multiply by c out, add noised input, c skip. Okay, so we can denoise. So let's grab our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3621" target="_blank">01:00:21.360</a></span> | <span class="t">sigmas from the actual batch we had. Let's calculate c skip c out and c in for the sigmas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3627" target="_blank">01:00:27.840</a></span> | <span class="t">in our mini batch. Let's use the model to predict the target given the noised input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3636" target="_blank">01:00:36.920</a></span> | <span class="t">and the sigmas, and then denoise it. And so here's our noised input, which we've already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3644" target="_blank">01:00:44.120</a></span> | <span class="t">seen, and here's our predictions. And these are absolutely remarkable, in my opinion. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3656" target="_blank">01:00:56.480</a></span> | <span class="t">Like this one here, I can barely see it. You know, it's really found, look at the shirt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3661" target="_blank">01:01:01.720</a></span> | <span class="t">There's a shirt here. It's actually really finding the little thing on the front. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3664" target="_blank">01:01:04.960</a></span> | <span class="t">let me show you, here's what it should look like, right? And in cases where the sigma's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3672" target="_blank">01:01:12.520</a></span> | <span class="t">pretty high, like here, you can see it's really like saying, like, I don't know, maybe it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3678" target="_blank">01:01:18.080</a></span> | <span class="t">shoes, but it could be something else. Is it shoes? Yeah, it wasn't shoes. But at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3683" target="_blank">01:01:23.600</a></span> | <span class="t">it's kind of got the, you know, the bulk of the pixels in the right spot. Yeah, something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3690" target="_blank">01:01:30.400</a></span> | <span class="t">like this one is 4.5, has no idea what it is. It's like, oh, maybe it's shoes, maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3695" target="_blank">01:01:35.240</a></span> | <span class="t">it's pants. You know, it turns out it is shoes. Yeah. So I think that's fascinating how well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3703" target="_blank">01:01:43.920</a></span> | <span class="t">it can do. And then the other thing I did, which I thought was fun, was I just created,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3713" target="_blank">01:01:53.080</a></span> | <span class="t">so I just, you did a sigma of 80, which is actually what they do when they're doing sampling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3717" target="_blank">01:01:57.520</a></span> | <span class="t">from pure noise. That's what they consider the pure noise level. So I just created some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3723" target="_blank">01:02:03.020</a></span> | <span class="t">pure noise and denoised it just for one step. And so here's what happens when you denoise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3731" target="_blank">01:02:11.400</a></span> | <span class="t">it for one step. And you can see it's kind of overlaid all the possibilities. It's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3736" target="_blank">01:02:16.560</a></span> | <span class="t">I can see a pair of shoes here, a pair of pants here at top here. And sometimes it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3742" target="_blank">01:02:22.320</a></span> | <span class="t">kind of like more confident that the noise is actually a pair of pants. And sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3747" target="_blank">01:02:27.440</a></span> | <span class="t">it's more confident that it's actually shoes. But you can really get a sense of how like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3752" target="_blank">01:02:32.520</a></span> | <span class="t">from pure noise, it starts to make a call about like what this noise is actually covering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3759" target="_blank">01:02:39.760</a></span> | <span class="t">up. And this is also the bit which I feel is like, I'm the least convinced about when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3768" target="_blank">01:02:48.160</a></span> | <span class="t">it comes to diffusion models. This first step of going from like pure noise to something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3776" target="_blank">01:02:56.960</a></span> | <span class="t">and like trying to have a good mix of all the possible somethings, I'm, I don't know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3782" target="_blank">01:03:02.160</a></span> | <span class="t">it feels a bit hand-waving to me. It clearly works quite well, but I'm not sure if it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3785" target="_blank">01:03:05.680</a></span> | <span class="t">like we're getting the full range of possibilities. And I feel like some of the papers we're starting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3792" target="_blank">01:03:12.520</a></span> | <span class="t">to see are starting to say like, you know what, maybe this is not quite the right approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3797" target="_blank">01:03:17.240</a></span> | <span class="t">And maybe later in the course, we'll look at some of the ones that look at what we call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3801" target="_blank">01:03:21.880</a></span> | <span class="t">VQ models and tokenized stuff. Anyway, I thought this is pretty interesting to see these pictures,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3810" target="_blank">01:03:30.560</a></span> | <span class="t">which I don't think, yeah, I've never seen any pictures like this before. So I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3815" target="_blank">01:03:35.080</a></span> | <span class="t">this is a fun result from doing all this stuff in notebooks step by step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3822" target="_blank">01:03:42.080</a></span> | <span class="t">Okay, so sampling. So one of the nice things with this is the sampling becomes much, much,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3832" target="_blank">01:03:52.160</a></span> | <span class="t">much simpler. And so, and I should mention a lot of the code that I'm using, particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3841" target="_blank">01:04:01.360</a></span> | <span class="t">in the sampling section is heavily inspired by, and some of it's actually copied and pasted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3846" target="_blank">01:04:06.400</a></span> | <span class="t">from Kat's K-diffusion repo, which is, I think I mentioned before, some of the nicest generative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3857" target="_blank">01:04:17.160</a></span> | <span class="t">modeling code or maybe the nicest generative modeling code I've ever seen. It's really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3862" target="_blank">01:04:22.480</a></span> | <span class="t">great. So before we talk about the actual sampling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3867" target="_blank">01:04:27.600</a></span> | <span class="t">the first thing we need to talk about is what sigma do we use at each reverse time step?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3874" target="_blank">01:04:34.400</a></span> | <span class="t">And in the past, we've always, well, nearly always done something, which I think has always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3879" target="_blank">01:04:39.200</a></span> | <span class="t">felt is sketchy as all hell, which is we've just linearly gone down the sigmas or the alpha</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3886" target="_blank">01:04:46.480</a></span> | <span class="t">bars or the t's. So here, when we're sampling in the previous notebook, we used lin space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3892" target="_blank">01:04:52.340</a></span> | <span class="t">So I always felt like that was questionable. And I felt like at the start, you probably,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3899" target="_blank">01:04:59.040</a></span> | <span class="t">like it was just noise anyway. So who cared? Who cares? So I, in DDPMv3, I experimented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3907" target="_blank">01:05:07.880</a></span> | <span class="t">with something that I thought intuitively made more sense. I don't know if you remember this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3913" target="_blank">01:05:13.360</a></span> | <span class="t">one, but I actually said, oh, let's, for the first 100 times steps, let's actually only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3920" target="_blank">01:05:20.160</a></span> | <span class="t">run the model every 10 times. And then for the next 100, let's run it nine times. The</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3924" target="_blank">01:05:24.520</a></span> | <span class="t">next 100, let's run it every eight times. So basically at the start, be much less careful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3930" target="_blank">01:05:30.360</a></span> | <span class="t">And so Keras actually ran a whole bunch of experiments and they said, yeah, you know what?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3941" target="_blank">01:05:41.040</a></span> | <span class="t">At the start of training, you know, you can start with a high sigma, but then like step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3947" target="_blank">01:05:47.200</a></span> | <span class="t">to a much lower sigma in the next step and then a much lower sigma in the next step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3951" target="_blank">01:05:51.680</a></span> | <span class="t">And then the longer, the more you train step by smaller and smaller steps so that you spend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3957" target="_blank">01:05:57.440</a></span> | <span class="t">a lot more time fine-tuning carefully at the end and not very much time at the start. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3967" target="_blank">01:06:07.860</a></span> | <span class="t">this has its own problems. And in fact, a paper just came out today, which we probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3972" target="_blank">01:06:12.060</a></span> | <span class="t">won't talk about today, but maybe another time, which talked about the problems is that in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3976" target="_blank">01:06:16.320</a></span> | <span class="t">these very early steps, this is the bit where you're trying to create a composition that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3981" target="_blank">01:06:21.600</a></span> | <span class="t">makes sense. Now for fashion MNIST, we don't have much composing to do. It's just a piece</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3986" target="_blank">01:06:26.400</a></span> | <span class="t">of clothing. But if you're trying to do an astronaut riding a horse, you know, you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3991" target="_blank">01:06:31.520</a></span> | <span class="t">got to think about how all those pieces fit together. And this is where that happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=3996" target="_blank">01:06:36.040</a></span> | <span class="t">And so I do worry that with the Keras approach is what's not giving that maybe enough time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4001" target="_blank">01:06:41.160</a></span> | <span class="t">But as I've said, that's really the same as this step. That whole piece feels a bit wrong</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4007" target="_blank">01:06:47.240</a></span> | <span class="t">to me. But aside from that, I think this makes a lot of sense, which is that, yeah, the sampling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4014" target="_blank">01:06:54.080</a></span> | <span class="t">you should jump, you know, by big steps early on and small steps later on and make sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4019" target="_blank">01:06:59.720</a></span> | <span class="t">that the fine details are just so. So that's what this function does, is it creates this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4026" target="_blank">01:07:06.800</a></span> | <span class="t">plot. Now it's this schedule of reverse diffusion sigma steps. It's a bit of a weird function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4037" target="_blank">01:07:17.680</a></span> | <span class="t">in that it's the rowth root of sigma, where row is seven. So the seventh root of sigma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4046" target="_blank">01:07:26.580</a></span> | <span class="t">is basically what it's scaling on. But the answer to why it's that is because they tried</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4053" target="_blank">01:07:33.280</a></span> | <span class="t">it and it turned out to work pretty well. Do you guys remember where this was?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4062" target="_blank">01:07:42.480</a></span> | <span class="t">This is a truncation error analysis, D1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4068" target="_blank">01:07:48.280</a></span> | <span class="t">That's very. So this image here, so thanks for telling me where this is, shows fed as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4083" target="_blank">01:08:03.640</a></span> | <span class="t">a function of row. So it's basically what the whatth root are we taking? And they basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4090" target="_blank">01:08:10.680</a></span> | <span class="t">said, like, if you take the fifth root up, it seems to work well, basically. So, yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4099" target="_blank">01:08:19.600</a></span> | <span class="t">so that's a perfectly good way to do things is just to try things and see what works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4104" target="_blank">01:08:24.400</a></span> | <span class="t">And you'll notice they tried things just like we love on small data sets. Not as small as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4108" target="_blank">01:08:28.520</a></span> | <span class="t">us because we're the king of small data sets, but small ish, so far 10, the image net 64.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4115" target="_blank">01:08:35.200</a></span> | <span class="t">That's the way to do things. I saw, like, I might have even been the CEO of Hugging Face</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4120" target="_blank">01:08:40.980</a></span> | <span class="t">the other day, tweet something saying only people with huge amounts of GPUs can do research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4125" target="_blank">01:08:45.360</a></span> | <span class="t">now. And I think it totally misunderstands how research is done, which is research is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4129" target="_blank">01:08:49.240</a></span> | <span class="t">done on very small data sets. That's that's the actual research. And then when you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4135" target="_blank">01:08:55.400</a></span> | <span class="t">all done, you scale it up at the end. I think we're kind of pushing the envelope in terms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4142" target="_blank">01:09:02.220</a></span> | <span class="t">of like, yeah, how how much can you do? And yeah, we've, like, we covered this kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4152" target="_blank">01:09:12.360</a></span> | <span class="t">main substantive path of diffusion models history, step by step, showing every improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4159" target="_blank">01:09:19.340</a></span> | <span class="t">and seeing clear improvements across all the papers using nothing but fashioned MNIST running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4164" target="_blank">01:09:24.160</a></span> | <span class="t">on a single GPU in like 15 minutes of training or something per model. So, yeah, definitely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4170" target="_blank">01:09:30.080</a></span> | <span class="t">you don't need lots of models. Anyway, OK, so this is the sigma we're going to jump to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4177" target="_blank">01:09:37.960</a></span> | <span class="t">So the denoising is going to involve calculating the C skip, C out and C in and calling our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4184" target="_blank">01:09:44.400</a></span> | <span class="t">model with the C in scaled data and the sigma and then scaling it with C out and then doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4193" target="_blank">01:09:53.120</a></span> | <span class="t">the C skip. OK, so that's just undoing the Noisify. So check this out. This is all that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4200" target="_blank">01:10:00.360</a></span> | <span class="t">required to do one step of denoising for the simplest kind of scheduler, which sorry, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4207" target="_blank">01:10:07.240</a></span> | <span class="t">simplest kind of sampler, which is called Euler. So we basically say, OK, what's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4211" target="_blank">01:10:11.400</a></span> | <span class="t">sigma at time step I? What's the sigma 2 at time step I? And now when I'm talking about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4219" target="_blank">01:10:19.120</a></span> | <span class="t">at time step, I'm really talking about like the step from this function. Right. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4224" target="_blank">01:10:24.560</a></span> | <span class="t">is this is the sampling step. Yeah. OK, so then denoise using the function and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4235" target="_blank">01:10:35.840</a></span> | <span class="t">say, OK, well, just send back whatever you were given plus move a little bit in the direction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4243" target="_blank">01:10:43.680</a></span> | <span class="t">of the denoised image. So the direction is X minus denoised. So that's the noise. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4249" target="_blank">01:10:49.880</a></span> | <span class="t">the gradient as we discussed right back in the first lesson of this part. So we'll take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4254" target="_blank">01:10:54.840</a></span> | <span class="t">the noise. If we divide it by sigma, we get a slope. It's how much noise is there per</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4261" target="_blank">01:11:01.400</a></span> | <span class="t">sigma. And then the amount that we're stepping is sigma 2 minus sigma 1. So take that slope</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4268" target="_blank">01:11:08.960</a></span> | <span class="t">and multiply it by the change. Right. So that's the distance to travel towards the noise at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4278" target="_blank">01:11:18.880</a></span> | <span class="t">this fraction. You know, or you could also think of it this way. And I know this is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4283" target="_blank">01:11:23.080</a></span> | <span class="t">very obvious algebraic change. But if we move this over here, you could also think of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4291" target="_blank">01:11:31.040</a></span> | <span class="t">as being, oh, of the total amount of noise, the change in sigma we're doing, what percentage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4297" target="_blank">01:11:37.840</a></span> | <span class="t">is that? OK, well, that's the amount we should step. So there's two ways of thinking about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4303" target="_blank">01:11:43.760</a></span> | <span class="t">the same thing. So again, this is just, you know, high school math. Well, I mean, actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4316" target="_blank">01:11:56.160</a></span> | <span class="t">my seven-year-old daughter has done all these things. It's plus minus divided in times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4323" target="_blank">01:12:03.840</a></span> | <span class="t">So we're going to need to do this once per sampling step. So here's a thing called sample,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4333" target="_blank">01:12:13.000</a></span> | <span class="t">which does that. It's going to go through each sampling step, call our sampler, which initially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4341" target="_blank">01:12:21.520</a></span> | <span class="t">we're going to do sample Euler. Right. With that information, add it to our list of results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4350" target="_blank">01:12:30.920</a></span> | <span class="t">and do it again. So that's it. That's all the sampling is. And of course, we need to grab</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4357" target="_blank">01:12:37.160</a></span> | <span class="t">our list of sigmas to start with. So I think that's pretty cool. And at the very start,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4363" target="_blank">01:12:43.960</a></span> | <span class="t">we need to create our pure noise image. And so the amount of noise we start with is got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4369" target="_blank">01:12:49.000</a></span> | <span class="t">a sigma of 80. OK, so if we call sample using sample Euler and we get back some very nice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4382" target="_blank">01:13:02.400</a></span> | <span class="t">looking images and believe it or not, our fed is 1.98. So this extremely simple sampler,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4393" target="_blank">01:13:13.240</a></span> | <span class="t">three lines of code plus a loop has given us a bit of 1.98, which is clearly substantially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4410" target="_blank">01:13:30.520</a></span> | <span class="t">better than our coastline. Now we can improve it from there. So one potential improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4418" target="_blank">01:13:38.640</a></span> | <span class="t">is to you might have noticed we added no new noise at all. This is a deterministic scheduler.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4426" target="_blank">01:13:46.520</a></span> | <span class="t">There's no rand anywhere here. So we can do something called an ancestral Euler sampler,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4434" target="_blank">01:13:54.280</a></span> | <span class="t">which does add rand. So we basically do the denoising in the usual way, but then we also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4442" target="_blank">01:14:02.600</a></span> | <span class="t">add some rand. And so what we do need to make sure is given that we're adding a certain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4447" target="_blank">01:14:07.080</a></span> | <span class="t">amount of randomness, we need to remove that amount of randomness from the step that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4453" target="_blank">01:14:13.240</a></span> | <span class="t">take. So I won't go into the details, but basically there's a way of calculating how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4462" target="_blank">01:14:22.160</a></span> | <span class="t">much new randomness and how much just going back in the existing direction do we do. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4469" target="_blank">01:14:29.080</a></span> | <span class="t">so there's the amount in the existing direction and there's the amount in the new random direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4475" target="_blank">01:14:35.240</a></span> | <span class="t">And you can just pass in eta, which is just going to, when we pass it into here, is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4484" target="_blank">01:14:44.040</a></span> | <span class="t">to scale that. So if we scale it by half, so basically half of it is new noise and half</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4493" target="_blank">01:14:53.720</a></span> | <span class="t">of it is going in the direction that we thought we should go, that makes it better still.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4499" target="_blank">01:14:59.800</a></span> | <span class="t">Again with 100 steps. And just make sure I'm comparing to the same, yep, 100 steps. Okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4506" target="_blank">01:15:06.880</a></span> | <span class="t">so that's fair, like with like. Okay, so that's adding a bit of extra noise. Now then, something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4517" target="_blank">01:15:17.120</a></span> | <span class="t">that I think we might have mentioned back in the first lesson of this part is something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4524" target="_blank">01:15:24.840</a></span> | <span class="t">called Heun's method. And Heun's method does something which we can pictorially see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4534" target="_blank">01:15:34.640</a></span> | <span class="t">to decide where to go, which is basically we say, okay, where are we right now? What's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4540" target="_blank">01:15:40.160</a></span> | <span class="t">the, you know, at our current point, what's the direction? So we take the tangent line,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4546" target="_blank">01:15:46.080</a></span> | <span class="t">the slope, right? That's basically all it does is it takes a slope. It says, oh, here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4549" target="_blank">01:15:49.960</a></span> | <span class="t">a slope, you know. Okay, and so if we take that slope, and that would take us to a new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4565" target="_blank">01:16:05.880</a></span> | <span class="t">spot, and then at that new spot, we can then calculate a slope at the new spot as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4576" target="_blank">01:16:16.840</a></span> | <span class="t">And at the new spot, the slope is something else. So that's it here, right? And then you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4585" target="_blank">01:16:25.960</a></span> | <span class="t">say, like, okay, well, let's go halfway between the two. And let's actually follow that line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4592" target="_blank">01:16:32.520</a></span> | <span class="t">And so basically, it's saying, like, okay, each of these slopes is going to be inaccurate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4598" target="_blank">01:16:38.080</a></span> | <span class="t">But what we could do is calculate the slope of where we are, the slope of where we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4601" target="_blank">01:16:41.400</a></span> | <span class="t">going, and then go halfway between the two. It's, I actually found it easier to look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4607" target="_blank">01:16:47.200</a></span> | <span class="t">in code personally. I'm just going to delete a whole bunch of stuff that's totally irrelevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4613" target="_blank">01:16:53.280</a></span> | <span class="t">to this conversation. So take a look at this compared to Euler. So here's our Euler, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4625" target="_blank">01:17:05.400</a></span> | <span class="t">So we're going to do the same first line exactly the same, right? Then the denoising is exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4630" target="_blank">01:17:10.960</a></span> | <span class="t">the same. And then this step here is exactly the same. I've actually just done it in multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4637" target="_blank">01:17:17.120</a></span> | <span class="t">steps for no particular reason. And then you say, okay, well, if this is the last step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4645" target="_blank">01:17:25.720</a></span> | <span class="t">then we're done. So actually, the last step is Euler. But then what we do is we then say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4651" target="_blank">01:17:31.640</a></span> | <span class="t">well, that's okay, for an Euler step, this is where we'd go. Well, what does that look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4659" target="_blank">01:17:39.080</a></span> | <span class="t">like if we denoise it? So this calls the model the second time, right? And where would that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4664" target="_blank">01:17:44.080</a></span> | <span class="t">take us if we took an Euler step there? And so here, if we took an Euler step there, what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4670" target="_blank">01:17:50.420</a></span> | <span class="t">the slope? And so what we then do is we say, oh, okay, well, it's just, just like in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4675" target="_blank">01:17:55.640</a></span> | <span class="t">picture, let's take the average. Okay, so let's take the average and then use that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4686" target="_blank">01:18:06.880</a></span> | <span class="t">the step. So that's all the HUIN sampler does is just takes the average of the slope where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4693" target="_blank">01:18:13.280</a></span> | <span class="t">we're at and the slope where the Euler method would have taken us. And so if we now so notice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4700" target="_blank">01:18:20.240</a></span> | <span class="t">that it called the model twice for a single step. So to be fair, since we've been taking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4705" target="_blank">01:18:25.080</a></span> | <span class="t">100 steps with Euler, we should take 50 steps with HUIN, right? Because it's going to call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4709" target="_blank">01:18:29.400</a></span> | <span class="t">the model twice. And still that is now whoa, we beat one, which is pretty amazing. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4718" target="_blank">01:18:38.360</a></span> | <span class="t">so we could keep going, check this out, we could even go down to 20. This is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4721" target="_blank">01:18:41.520</a></span> | <span class="t">doing 40 model evaluations and this is better than our best Euler, which is pretty crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4727" target="_blank">01:18:47.600</a></span> | <span class="t">Now, something which you might have noticed is kind of weird about this or kind of silly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4732" target="_blank">01:18:52.600</a></span> | <span class="t">about this is we're calling the model twice just in order to average them. But we already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4740" target="_blank">01:19:00.120</a></span> | <span class="t">have two model results, like without calling it twice, because we could have just looked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4744" target="_blank">01:19:04.760</a></span> | <span class="t">at the previous time step. And so something called the LMS sampler does that instead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4756" target="_blank">01:19:16.920</a></span> | <span class="t">And so the LMS sampler, if I call it with 20, it actually literally does 20 evaluations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4762" target="_blank">01:19:22.640</a></span> | <span class="t">and actually it beats Euler with 100 evaluations. And so LMS, I won't go into the details too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4769" target="_blank">01:19:29.560</a></span> | <span class="t">much. It didn't actually fit into my little sampling very well. So basically largely copied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4773" target="_blank">01:19:33.480</a></span> | <span class="t">and pasted the cat's code. But the key thing it does is look, it gets the current sigma,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4779" target="_blank">01:19:39.280</a></span> | <span class="t">it does the denoising, it calculates the slope, and it stores the slope in a list, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4788" target="_blank">01:19:48.640</a></span> | <span class="t">And then it grabs the first one from the list. So it's kind of keeping a list of up to, in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4798" target="_blank">01:19:58.960</a></span> | <span class="t">this case, four at a time. And so it then uses up to the last four to basically, yes, kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4807" target="_blank">01:20:07.920</a></span> | <span class="t">of the curvature of this and take the next step. So that's pretty smart. And yeah, I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4820" target="_blank">01:20:20.160</a></span> | <span class="t">if you wanted to do super fast sampling, it seems like a pretty good way to do it. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4826" target="_blank">01:20:26.360</a></span> | <span class="t">I think, Johnno, you're telling me that, or maybe it's Pedro was saying that currently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4832" target="_blank">01:20:32.120</a></span> | <span class="t">people have started to move away. This was very popular, but people started to move towards</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4836" target="_blank">01:20:36.280</a></span> | <span class="t">a new sampler, which is a bit similar called the DPM++ sampler, something like that. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4843" target="_blank">01:20:43.320</a></span> | <span class="t">Yeah. Yeah. Yeah. But I think it's the same idea. I think it kind of keeps a, I said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4851" target="_blank">01:20:51.200</a></span> | <span class="t">keep a list of recent results and use that. I'll have to check it more closely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4857" target="_blank">01:20:57.480</a></span> | <span class="t">I'll have to look at the code. Yeah. That's a similar idea. It's like, if it's done more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4861" target="_blank">01:21:01.360</a></span> | <span class="t">than one step, then it's using some history to the next thing. Yeah. This history and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4867" target="_blank">01:21:07.760</a></span> | <span class="t">thing doesn't make a huge amount of sense, I guess, from that perspective. I mean, still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4874" target="_blank">01:21:14.080</a></span> | <span class="t">works very well. This makes more sense. So then we can compare if we use an actual mini</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4878" target="_blank">01:21:18.920</a></span> | <span class="t">match of data, we get about 0.5. So yeah, I feel like this is quite a stunning result</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4893" target="_blank">01:21:33.240</a></span> | <span class="t">to get close to, very close to real data, this in terms of fit, really with 40 model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4904" target="_blank">01:21:44.160</a></span> | <span class="t">evaluations and the entire, nearly the entire thing here is by making sure we've got unit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4914" target="_blank">01:21:54.440</a></span> | <span class="t">variance, inputs, unit variance, outputs, and kind of equally difficult problems to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4919" target="_blank">01:21:59.760</a></span> | <span class="t">solve in our loss function. Yeah. Thus having that different schedule for sampling. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4926" target="_blank">01:22:06.240</a></span> | <span class="t">completely unrelated to the training schedule. I think that was one of the big things with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4929" target="_blank">01:22:09.760</a></span> | <span class="t">Karas et al's paper was they also could apply this to like, oh, existing diffusion models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4935" target="_blank">01:22:15.360</a></span> | <span class="t">that have been trained by other papers. We can use our sampler and in fewer steps get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4939" target="_blank">01:22:19.160</a></span> | <span class="t">better results without any of the other changes. And yeah, I mean, they do a little bit of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4945" target="_blank">01:22:25.680</a></span> | <span class="t">rearranging equations to get the other papers versions into their C skip C and C out framework.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4954" target="_blank">01:22:34.240</a></span> | <span class="t">But then yeah, it's really nice that these ideas can be applied to, so for example, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4958" target="_blank">01:22:38.640</a></span> | <span class="t">think stable diffusion, especially version one was trained DDPM style training, Epsilon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4964" target="_blank">01:22:44.720</a></span> | <span class="t">objective, whatever. But you can now get these different samplers and different sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4970" target="_blank">01:22:50.400</a></span> | <span class="t">schedules and things like that and use that to sample it and do it in 15, 20 steps and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4976" target="_blank">01:22:56.680</a></span> | <span class="t">get pretty nice samples. Yeah. And another nice thing about this paper is they, in fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4988" target="_blank">01:23:08.400</a></span> | <span class="t">the name of the paper elucidating the design space of diffusion based models. They looked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4994" target="_blank">01:23:14.960</a></span> | <span class="t">at various different papers and approaches and trying to set like, oh, you know what?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=4999" target="_blank">01:23:19.080</a></span> | <span class="t">These are all doing the same thing when we kind of parameterize things in this way. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5005" target="_blank">01:23:25.320</a></span> | <span class="t">if you fill in these parameters, you get this paper and these parameters, you get that paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5009" target="_blank">01:23:29.760</a></span> | <span class="t">And then so we found a better set of parameters, which it was very nice to code because, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5022" target="_blank">01:23:42.360</a></span> | <span class="t">know, it really actually ended up simplifying things a whole lot. And so if you look through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5028" target="_blank">01:23:48.520</a></span> | <span class="t">the notebook carefully, which I hope everybody will, you'll see, you know, that the code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5036" target="_blank">01:23:56.240</a></span> | <span class="t">is really there and simple compared to all the previous ones, in my opinion. Like, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5044" target="_blank">01:24:04.680</a></span> | <span class="t">feel like every notebook we've done from DDPM onwards, the code's got easier to understand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5053" target="_blank">01:24:13.320</a></span> | <span class="t">And just to again clarify like how this connects with some of the previous papers that we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5059" target="_blank">01:24:19.200</a></span> | <span class="t">looked at. So like, for example, with the DDIM, the deterministic, that's again, the sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5064" target="_blank">01:24:24.520</a></span> | <span class="t">of deterministic approach that's similar to the Euler method sampler that we were just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5070" target="_blank">01:24:30.800</a></span> | <span class="t">looking at, which was completely deterministic. And then some of something like the Euler</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5075" target="_blank">01:24:35.520</a></span> | <span class="t">ancestral that we were looking at is similar to the standard DDPM approach with that was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5083" target="_blank">01:24:43.680</a></span> | <span class="t">kind of a more stochastic approach. So again, there's just all those sorts of connections</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5088" target="_blank">01:24:48.760</a></span> | <span class="t">that then are kind of nice to see, again, the sorts of connections between the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5092" target="_blank">01:24:52.880</a></span> | <span class="t">papers and how they change it, how they can be expressed in this common framework.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5097" target="_blank">01:24:57.840</a></span> | <span class="t">Yeah. Thanks, Tanish. So we definitely now are at the point where we can show you the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5109" target="_blank">01:25:09.040</a></span> | <span class="t">unit next time. And so I think we're, unless any of us come up with interesting new insights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5118" target="_blank">01:25:18.060</a></span> | <span class="t">on the unconditional diffusion sampling, training and sampling process, we might be putting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5128" target="_blank">01:25:28.160</a></span> | <span class="t">that aside for a while, and instead we're going to be looking at creating a good quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5134" target="_blank">01:25:34.880</a></span> | <span class="t">unit from scratch. And we're going to look at a different data set to do that as we start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5146" target="_blank">01:25:46.600</a></span> | <span class="t">into scale things up a bit, as Jono mentioned in the last lesson. So we're going to be using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5150" target="_blank">01:25:50.720</a></span> | <span class="t">a 64 by 64 pixel image net subset called tiny image net. So we'll start looking at some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5159" target="_blank">01:25:59.120</a></span> | <span class="t">three channel images. So I'm sure we're all sick of looking at black and white shoes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5165" target="_blank">01:26:05.800</a></span> | <span class="t">So now we get to look at shift dwellings and trolley buses and koala bears and yeah, 200</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5177" target="_blank">01:26:17.980</a></span> | <span class="t">different things. So that'll be nice. Yeah. All right. Well, thank you, Jono. Thank you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5184" target="_blank">01:26:24.800</a></span> | <span class="t">Tanish. That was fun as always. And yeah, next time we'll be lesson 22. Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5192" target="_blank">01:26:32.160</a></span> | <span class="t">Oh, listen to me. Hey, this was lesson 22. Oh, no way. Okay. You're right. See ya. Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6Bta1tXRUfM&t=5200" target="_blank">01:26:40.080</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>