<html><head><title>Stanford XCS224U: NLU I Analysis Methods for NLU, Part 2: Probing I Spring 2023</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford XCS224U: NLU I Analysis Methods for NLU, Part 2: Probing I Spring 2023</h2><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c"><img src="https://i.ytimg.com/vi/lZqsLuAjZ4c/sddefault.jpg?sqp=-oaymwEmCIAFEOAD8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGB4gZSgsMA8=&rs=AOn4CLDiXm-rtPYNYaYJpnBxBlvrwrtG9A" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=13">0:13</a> Overview<br><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=114">1:54</a> Recipe for probing<br><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=172">2:52</a> Core method<br><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=282">4:42</a> Probing or learning a new model?<br><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=341">5:41</a> Control tasks and probe selectivity<br><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=441">7:21</a> Simple example<br><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=584">9:44</a> From probing to multi-task training<br><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=637">10:37</a> Unsupervised probes<br><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=663">11:3</a> Summary<br><br><div style="text-align: left;"><a href="./lZqsLuAjZ4c.html">Whisper Transcript</a> | <a href="./transcript_lZqsLuAjZ4c.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Welcome back everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=6" target="_blank">00:00:06.100</a></span> | <span class="t">This is part 2 in our series on analysis methods for NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=10" target="_blank">00:00:10.140</a></span> | <span class="t">We've come to our first method and that is probing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=13" target="_blank">00:00:13.040</a></span> | <span class="t">Here's an overview of how probing works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=15" target="_blank">00:00:15.380</a></span> | <span class="t">The core idea is that we're going to use supervised models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=18" target="_blank">00:00:18.580</a></span> | <span class="t">those are our probe models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=20" target="_blank">00:00:20.120</a></span> | <span class="t">to determine what is latently encoded in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=22" target="_blank">00:00:22.560</a></span> | <span class="t">the hidden representations of our target models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=25" target="_blank">00:00:25.380</a></span> | <span class="t">the ones that we actually care about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=27" target="_blank">00:00:27.320</a></span> | <span class="t">Probing is often applied in the context of so-called Bertology,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=31" target="_blank">00:00:31.520</a></span> | <span class="t">and I think Tenny et al 2019 is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=33" target="_blank">00:00:33.520</a></span> | <span class="t">a really foundational contribution in this space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=36" target="_blank">00:00:36.040</a></span> | <span class="t">As I mentioned before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=37" target="_blank">00:00:37.200</a></span> | <span class="t">I think this was really eye-opening about the extent to which Bert</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=40" target="_blank">00:00:40.480</a></span> | <span class="t">is inducing interesting structure about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=42" target="_blank">00:00:42.960</a></span> | <span class="t">language from its training regimes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=46" target="_blank">00:00:46.100</a></span> | <span class="t">Probing can be a source of valuable insights, I believe,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=49" target="_blank">00:00:49.880</a></span> | <span class="t">but we do need to proceed with caution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=51" target="_blank">00:00:51.680</a></span> | <span class="t">and there are really two cautionary notes here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=53" target="_blank">00:00:53.880</a></span> | <span class="t">First, a very powerful probe might lead you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=57" target="_blank">00:00:57.160</a></span> | <span class="t">to see things that aren't in your target model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=59" target="_blank">00:00:59.560</a></span> | <span class="t">but rather just stored in your probe model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=62" target="_blank">00:01:02.520</a></span> | <span class="t">It is after all a supervised model that you trained in some way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=66" target="_blank">00:01:06.280</a></span> | <span class="t">Second, and maybe more importantly for the current unit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=70" target="_blank">00:01:10.000</a></span> | <span class="t">probes cannot tell us about whether the information that we identify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=73" target="_blank">00:01:13.640</a></span> | <span class="t">has any causal relationship with the target models input-output behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=78" target="_blank">00:01:18.240</a></span> | <span class="t">This is really concerning for me because what we're looking for from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=81" target="_blank">00:01:21.960</a></span> | <span class="t">analysis methods is insights about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=84" target="_blank">00:01:24.320</a></span> | <span class="t">the causal mechanisms that guide model behaviors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=87" target="_blank">00:01:27.680</a></span> | <span class="t">If probing falls short on offering us those causal insights,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=91" target="_blank">00:01:31.640</a></span> | <span class="t">it's really intrinsically limited as an analysis method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=96" target="_blank">00:01:36.080</a></span> | <span class="t">I'm going to focus for this screencast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=99" target="_blank">00:01:39.000</a></span> | <span class="t">on supervised probes to keep things simple,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=101" target="_blank">00:01:41.120</a></span> | <span class="t">but I will mention unsupervised probes near the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=104" target="_blank">00:01:44.800</a></span> | <span class="t">They don't suffer from the concern that they're overly powerful,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=108" target="_blank">00:01:48.200</a></span> | <span class="t">but they do, I think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=109" target="_blank">00:01:49.480</a></span> | <span class="t">still fall short when it comes to offering causal insights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=113" target="_blank">00:01:53.680</a></span> | <span class="t">Let's start with a recipe for probing to be careful about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=118" target="_blank">00:01:58.680</a></span> | <span class="t">The first step is that you state a hypothesis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=121" target="_blank">00:02:01.280</a></span> | <span class="t">about an aspect of the target model's internal structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=124" target="_blank">00:02:04.360</a></span> | <span class="t">You could hypothesize that it stores information about part of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=127" target="_blank">00:02:07.840</a></span> | <span class="t">speech or named entities or dependency parses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=131" target="_blank">00:02:11.720</a></span> | <span class="t">You name it, the hypothesis space is open.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=135" target="_blank">00:02:15.040</a></span> | <span class="t">You then need to choose a supervised task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=138" target="_blank">00:02:18.440</a></span> | <span class="t">that is a proxy for the internal structure of interest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=141" target="_blank">00:02:21.360</a></span> | <span class="t">If you're going to look for part of speech,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=143" target="_blank">00:02:23.140</a></span> | <span class="t">you need a part of speech dataset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=144" target="_blank">00:02:24.880</a></span> | <span class="t">and you're going to be dependent on that dataset when it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=147" target="_blank">00:02:27.400</a></span> | <span class="t">comes to actually defining the probe itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=150" target="_blank">00:02:30.440</a></span> | <span class="t">Then you identify a place in the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=153" target="_blank">00:02:33.640</a></span> | <span class="t">a set of hidden representations where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=155" target="_blank">00:02:35.720</a></span> | <span class="t">you believe the structure will be encoded,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=158" target="_blank">00:02:38.280</a></span> | <span class="t">and you train a supervised probe on the chosen site.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=161" target="_blank">00:02:41.960</a></span> | <span class="t">Then the extent to which your probe is successful is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=165" target="_blank">00:02:45.700</a></span> | <span class="t">your estimate of the degree to which you were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=167" target="_blank">00:02:47.640</a></span> | <span class="t">right about the underlying hypothesis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=170" target="_blank">00:02:50.680</a></span> | <span class="t">But there are some caveats there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=172" target="_blank">00:02:52.720</a></span> | <span class="t">Let's first walk through the core method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=174" target="_blank">00:02:54.800</a></span> | <span class="t">What I have on the slide now is a very cartoonish look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=178" target="_blank">00:02:58.920</a></span> | <span class="t">a BERT-like model with three layers and you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=182" target="_blank">00:03:02.000</a></span> | <span class="t">these inputs have come in and we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=184" target="_blank">00:03:04.840</a></span> | <span class="t">target the hidden representation H to start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=187" target="_blank">00:03:07.920</a></span> | <span class="t">Let's suppose that's the site that we chose to probe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=191" target="_blank">00:03:11.400</a></span> | <span class="t">What we're going to do is fit a small linear model on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=195" target="_blank">00:03:15.360</a></span> | <span class="t">that internal representation using some task labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=199" target="_blank">00:03:19.280</a></span> | <span class="t">The way that actually plays out in practice is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=201" target="_blank">00:03:21.920</a></span> | <span class="t">instructive. We're going to run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=204" target="_blank">00:03:24.080</a></span> | <span class="t">the BERT model on the current input and we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=206" target="_blank">00:03:26.720</a></span> | <span class="t">grab the vector representation there and use it to start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=210" target="_blank">00:03:30.720</a></span> | <span class="t">building a little supervised learning dataset where this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=214" target="_blank">00:03:34.660</a></span> | <span class="t">some vector and this is a task label for our input example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=219" target="_blank">00:03:39.160</a></span> | <span class="t">Then we run the BERT model again on a different sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=222" target="_blank">00:03:42.700</a></span> | <span class="t">We get a different vector representation at our target site,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=226" target="_blank">00:03:46.520</a></span> | <span class="t">and that also contributes to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=228" target="_blank">00:03:48.200</a></span> | <span class="t">our supervised learning dataset with a new task label.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=231" target="_blank">00:03:51.360</a></span> | <span class="t">We do it again for a different input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=233" target="_blank">00:03:53.960</a></span> | <span class="t">We get a different vector and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=235" target="_blank">00:03:55.980</a></span> | <span class="t">another task label and so forth and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=238" target="_blank">00:03:58.880</a></span> | <span class="t">We continue this process for maybe tens of thousands of examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=242" target="_blank">00:04:02.600</a></span> | <span class="t">whatever we've got available to us in our probe dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=246" target="_blank">00:04:06.280</a></span> | <span class="t">Then we fit a small linear model on this XY pair.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=250" target="_blank">00:04:10.900</a></span> | <span class="t">Notice that we have used the BERT model simply as a engine for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=255" target="_blank">00:04:15.820</a></span> | <span class="t">grabbing these vector representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=258" target="_blank">00:04:18.560</a></span> | <span class="t">that we use for our probe model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=261" target="_blank">00:04:21.000</a></span> | <span class="t">Of course, I chose a single representation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=265" target="_blank">00:04:25.240</a></span> | <span class="t">but more commonly with BERT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=266" target="_blank">00:04:26.600</a></span> | <span class="t">we're doing this layer-wise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=268" target="_blank">00:04:28.160</a></span> | <span class="t">You could decide that the entire layer here encodes part of speech,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=271" target="_blank">00:04:31.360</a></span> | <span class="t">and then you would build up a dataset consisting of lists of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=274" target="_blank">00:04:34.040</a></span> | <span class="t">these vectors with their associated lists of labels and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=277" target="_blank">00:04:37.040</a></span> | <span class="t">train a part of speech tagging model on that basis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=279" target="_blank">00:04:39.920</a></span> | <span class="t">and that would be your probe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=281" target="_blank">00:04:41.920</a></span> | <span class="t">The first question that arises for probing is really pressing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=286" target="_blank">00:04:46.160</a></span> | <span class="t">Are we probing the target model or are we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=288" target="_blank">00:04:48.560</a></span> | <span class="t">simply learning a new model that is the probe model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=291" target="_blank">00:04:51.320</a></span> | <span class="t">Probes in the current sense are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=293" target="_blank">00:04:53.320</a></span> | <span class="t">supervised models whose inputs are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=295" target="_blank">00:04:55.360</a></span> | <span class="t">frozen parameters of the model we're probing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=298" target="_blank">00:04:58.440</a></span> | <span class="t">We use the BERT model as a engine for creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=301" target="_blank">00:05:01.720</a></span> | <span class="t">these feature representations that were the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=303" target="_blank">00:05:03.960</a></span> | <span class="t">to a separate modeling process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=306" target="_blank">00:05:06.920</a></span> | <span class="t">This is very hard to distinguish from simply fitting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=309" target="_blank">00:05:09.820</a></span> | <span class="t">a supervised model as usual with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=311" target="_blank">00:05:11.880</a></span> | <span class="t">some particular choice of featurization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=314" target="_blank">00:05:14.600</a></span> | <span class="t">the site that we chose based on how BERT did its calculations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=319" target="_blank">00:05:19.000</a></span> | <span class="t">Based on 1 and 2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=321" target="_blank">00:05:21.080</a></span> | <span class="t">we know that at least some of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=322" target="_blank">00:05:22.880</a></span> | <span class="t">the information that we're identifying is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=325" target="_blank">00:05:25.220</a></span> | <span class="t">likely stored in the probe model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=327" target="_blank">00:05:27.120</a></span> | <span class="t">not in the target model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=329" target="_blank">00:05:29.120</a></span> | <span class="t">Of course, more powerful probes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=331" target="_blank">00:05:31.760</a></span> | <span class="t">might find more information in the target model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=334" target="_blank">00:05:34.480</a></span> | <span class="t">but that's only because they're storing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=336" target="_blank">00:05:36.480</a></span> | <span class="t">more information in the probe parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=338" target="_blank">00:05:38.380</a></span> | <span class="t">They have a greater capacity to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=341" target="_blank">00:05:41.640</a></span> | <span class="t">To help address this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=343" target="_blank">00:05:43.520</a></span> | <span class="t">Hewitt and Liang introduced the notion of probe selectivity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=347" target="_blank">00:05:47.280</a></span> | <span class="t">This is just going to help us calibrate to some extent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=350" target="_blank">00:05:50.160</a></span> | <span class="t">how much information was actually in the target model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=353" target="_blank">00:05:53.760</a></span> | <span class="t">The first step here is to define a control task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=356" target="_blank">00:05:56.620</a></span> | <span class="t">This would be a random task with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=358" target="_blank">00:05:58.760</a></span> | <span class="t">the same input-output structure as your target task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=362" target="_blank">00:06:02.160</a></span> | <span class="t">For example, for word sense classification,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=364" target="_blank">00:06:04.440</a></span> | <span class="t">you could just assign words,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=365" target="_blank">00:06:05.960</a></span> | <span class="t">random fixed senses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=368" target="_blank">00:06:08.440</a></span> | <span class="t">For part of speech tagging,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=369" target="_blank">00:06:09.980</a></span> | <span class="t">you could assign words to random fixed tags,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=372" target="_blank">00:06:12.800</a></span> | <span class="t">maybe keeping the same tag distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=375" target="_blank">00:06:15.320</a></span> | <span class="t">as your underlying part of speech dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=378" target="_blank">00:06:18.040</a></span> | <span class="t">Or for parsing, you could assign edges</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=380" target="_blank">00:06:20.680</a></span> | <span class="t">randomly using some simple strategies to give you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=383" target="_blank">00:06:23.360</a></span> | <span class="t">tree structures that are very different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=385" target="_blank">00:06:25.240</a></span> | <span class="t">presumably from the ones in your gold dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=388" target="_blank">00:06:28.240</a></span> | <span class="t">Then selectivity as a metric for probes is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=391" target="_blank">00:06:31.600</a></span> | <span class="t">just the difference between probe performance on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=394" target="_blank">00:06:34.220</a></span> | <span class="t">the task and probe performance on the control task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=398" target="_blank">00:06:38.040</a></span> | <span class="t">You've baked in how well your model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=400" target="_blank">00:06:40.560</a></span> | <span class="t">can do on a random task. That's the idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=404" target="_blank">00:06:44.320</a></span> | <span class="t">Hewitt and Liang offer this summary picture,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=407" target="_blank">00:06:47.420</a></span> | <span class="t">which essentially shows that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=409" target="_blank">00:06:49.300</a></span> | <span class="t">the most reliable probes in terms of giving you insights,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=412" target="_blank">00:06:52.320</a></span> | <span class="t">will be very small ones here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=414" target="_blank">00:06:54.260</a></span> | <span class="t">This is a model with just two hidden units.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=416" target="_blank">00:06:56.920</a></span> | <span class="t">That gives you very high selectivity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=418" target="_blank">00:06:58.900</a></span> | <span class="t">There is likely to be a very large difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=421" target="_blank">00:07:01.640</a></span> | <span class="t">between performance on your task and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=423" target="_blank">00:07:03.780</a></span> | <span class="t">the performance of this control model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=425" target="_blank">00:07:05.680</a></span> | <span class="t">when the model is very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=427" target="_blank">00:07:07.720</a></span> | <span class="t">On the other hand, if you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=429" target="_blank">00:07:09.360</a></span> | <span class="t">a very powerful probe model with many parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=432" target="_blank">00:07:12.760</a></span> | <span class="t">you'll have low selectivity because that model has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=435" target="_blank">00:07:15.280</a></span> | <span class="t">such a great capacity to simply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=437" target="_blank">00:07:17.440</a></span> | <span class="t">memorize aspects of the dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=440" target="_blank">00:07:20.680</a></span> | <span class="t">Let's move now to the second concern I have,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=444" target="_blank">00:07:24.440</a></span> | <span class="t">which is about causal inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=446" target="_blank">00:07:26.040</a></span> | <span class="t">To build this argument,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=447" target="_blank">00:07:27.480</a></span> | <span class="t">let's use a simple example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=449" target="_blank">00:07:29.600</a></span> | <span class="t">We imagine that we have a small neural network that takes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=453" target="_blank">00:07:33.080</a></span> | <span class="t">in three numbers as inputs and perfectly computes their sum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=457" target="_blank">00:07:37.080</a></span> | <span class="t">When 1, 3, 5 comes in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=458" target="_blank">00:07:38.880</a></span> | <span class="t">it does its internal magic and it outputs 9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=462" target="_blank">00:07:42.120</a></span> | <span class="t">We'll presume that it does that calculation perfectly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=464" target="_blank">00:07:44.880</a></span> | <span class="t">for all triples of integers coming in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=467" target="_blank">00:07:47.960</a></span> | <span class="t">The question is, how does it manage this feat?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=471" target="_blank">00:07:51.120</a></span> | <span class="t">How does this model work?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=472" target="_blank">00:07:52.600</a></span> | <span class="t">You might have a hypothesis that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=475" target="_blank">00:07:55.000</a></span> | <span class="t">does it in a compositional way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=477" target="_blank">00:07:57.240</a></span> | <span class="t">where the first two inputs, x and y,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=479" target="_blank">00:07:59.480</a></span> | <span class="t">come together to form an intermediate variable S1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=482" target="_blank">00:08:02.840</a></span> | <span class="t">The third one is copied into an internal state w,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=486" target="_blank">00:08:06.460</a></span> | <span class="t">and then S1 and w are modular representations that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=490" target="_blank">00:08:10.140</a></span> | <span class="t">added together to form the output representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=493" target="_blank">00:08:13.860</a></span> | <span class="t">That's a hypothesis about how this model might work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=496" target="_blank">00:08:16.900</a></span> | <span class="t">Now the question is, can we use probing to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=499" target="_blank">00:08:19.100</a></span> | <span class="t">reliably assess that hypothesis?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=502" target="_blank">00:08:22.340</a></span> | <span class="t">Let's suppose we have this neural network and what we decide is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=505" target="_blank">00:08:25.860</a></span> | <span class="t">that L1 probably computes the input z.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=510" target="_blank">00:08:30.060</a></span> | <span class="t">Let's suppose we fit a probe model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=512" target="_blank">00:08:32.180</a></span> | <span class="t">it could be a simple identity probe,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=513" target="_blank">00:08:33.940</a></span> | <span class="t">and the probe says, yes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=515" target="_blank">00:08:35.660</a></span> | <span class="t">L1 always perfectly encodes the identity of the third input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=520" target="_blank">00:08:40.580</a></span> | <span class="t">Suppose we continue that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=522" target="_blank">00:08:42.280</a></span> | <span class="t">we probe L2 and we find that it always perfectly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=525" target="_blank">00:08:45.540</a></span> | <span class="t">computes x plus y according to our very simple probe model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=530" target="_blank">00:08:50.260</a></span> | <span class="t">That might look like evidence for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=532" target="_blank">00:08:52.640</a></span> | <span class="t">the hypothesis that we started with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=534" target="_blank">00:08:54.360</a></span> | <span class="t">You say, "Aha, it's a bit counterintuitive because L1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=537" target="_blank">00:08:57.660</a></span> | <span class="t">encodes z and L2 x, y,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=540" target="_blank">00:09:00.280</a></span> | <span class="t">so it's out of order,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=541" target="_blank">00:09:01.740</a></span> | <span class="t">but nonetheless, the model is obeying my hypothesis."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=546" target="_blank">00:09:06.860</a></span> | <span class="t">But the probes have misled you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=549" target="_blank">00:09:09.280</a></span> | <span class="t">Here is a look at the full internal structure of this model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=552" target="_blank">00:09:12.260</a></span> | <span class="t">This is all the weight parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=553" target="_blank">00:09:13.860</a></span> | <span class="t">Again, this model performs our task perfectly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=556" target="_blank">00:09:16.780</a></span> | <span class="t">but the point is that L2 has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=558" target="_blank">00:09:18.700</a></span> | <span class="t">no impact at all on the output behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=561" target="_blank">00:09:21.940</a></span> | <span class="t">One way to see that is to look at the output vector of weights,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=565" target="_blank">00:09:25.540</a></span> | <span class="t">L2 is just zeroed out as part of this computation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=568" target="_blank">00:09:28.860</a></span> | <span class="t">no causal impact.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=570" target="_blank">00:09:30.260</a></span> | <span class="t">The probe said it stored x plus y,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=573" target="_blank">00:09:33.180</a></span> | <span class="t">and it might be doing that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=574" target="_blank">00:09:34.500</a></span> | <span class="t">In fact, it is doing that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=575" target="_blank">00:09:35.940</a></span> | <span class="t">but not in a way that tells us about the input-output behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=579" target="_blank">00:09:39.980</a></span> | <span class="t">The probe in that deep way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=582" target="_blank">00:09:42.140</a></span> | <span class="t">in that causal way, misled us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=585" target="_blank">00:09:45.020</a></span> | <span class="t">The final goalposts that I set up was,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=588" target="_blank">00:09:48.180</a></span> | <span class="t">do we have a path to improving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=589" target="_blank">00:09:49.940</a></span> | <span class="t">models from the analysis method that we've chosen?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=593" target="_blank">00:09:53.300</a></span> | <span class="t">Here I have a mixed answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=595" target="_blank">00:09:55.100</a></span> | <span class="t">There does seem to be a path from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=596" target="_blank">00:09:56.660</a></span> | <span class="t">probing to what you might call multi-task training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=599" target="_blank">00:09:59.340</a></span> | <span class="t">where I'm training this model to do addition,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=601" target="_blank">00:10:01.820</a></span> | <span class="t">and in addition, I train it so that this representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=605" target="_blank">00:10:05.220</a></span> | <span class="t">here encodes z and this one encodes x plus y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=608" target="_blank">00:10:08.660</a></span> | <span class="t">We can certainly have such objectives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=611" target="_blank">00:10:11.100</a></span> | <span class="t">I think it's an open question whether or not it actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=613" target="_blank">00:10:13.820</a></span> | <span class="t">induces the modularity that we're interested in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=617" target="_blank">00:10:17.820</a></span> | <span class="t">But the really deep concern for me is just that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=620" target="_blank">00:10:20.460</a></span> | <span class="t">still here we don't get causal guarantees.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=623" target="_blank">00:10:23.260</a></span> | <span class="t">We can do the multi-task training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=624" target="_blank">00:10:24.780</a></span> | <span class="t">but that does not guarantee that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=627" target="_blank">00:10:27.060</a></span> | <span class="t">the structure we induced, whatever it's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=629" target="_blank">00:10:29.500</a></span> | <span class="t">is actually shaping performance on the core task,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=632" target="_blank">00:10:32.620</a></span> | <span class="t">in this case of adding numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=634" target="_blank">00:10:34.580</a></span> | <span class="t">We have to proceed with caution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=636" target="_blank">00:10:36.980</a></span> | <span class="t">Finally, a quick note, I mentioned unsupervised probes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=640" target="_blank">00:10:40.380</a></span> | <span class="t">There's wonderful work in this space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=642" target="_blank">00:10:42.260</a></span> | <span class="t">using a variety of different methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=644" target="_blank">00:10:44.540</a></span> | <span class="t">Here are some references to really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=646" target="_blank">00:10:46.420</a></span> | <span class="t">formative entries into that literature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=649" target="_blank">00:10:49.060</a></span> | <span class="t">Again, I think these techniques do not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=651" target="_blank">00:10:51.060</a></span> | <span class="t">suffer from the concerns about probe power,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=653" target="_blank">00:10:53.340</a></span> | <span class="t">because they don't have their own parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=655" target="_blank">00:10:55.980</a></span> | <span class="t">typically, but they do,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=658" target="_blank">00:10:58.540</a></span> | <span class="t">I think, suffer that limitation about causal inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=662" target="_blank">00:11:02.420</a></span> | <span class="t">Let's wrap up with our scorecard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=664" target="_blank">00:11:04.980</a></span> | <span class="t">Remember, probing can characterize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=666" target="_blank">00:11:06.980</a></span> | <span class="t">representations really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=668" target="_blank">00:11:08.420</a></span> | <span class="t">We use the supervised probe for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=670" target="_blank">00:11:10.340</a></span> | <span class="t">That's a smiley face.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=671" target="_blank">00:11:11.820</a></span> | <span class="t">But probes cannot offer causal inferences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=675" target="_blank">00:11:15.100</a></span> | <span class="t">I put a thinking emoji under</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=677" target="_blank">00:11:17.780</a></span> | <span class="t">improved models because it's unclear to me whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=680" target="_blank">00:11:20.540</a></span> | <span class="t">multi-task training is really a viable general way of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=684" target="_blank">00:11:24.300</a></span> | <span class="t">moving from probes to better models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=lZqsLuAjZ4c&t=687" target="_blank">00:11:27.780</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>