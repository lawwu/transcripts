<html><head><title>Elon Musk: Regulation of AI Safety</title></head><body><a href="index.html">back to index</a><h2>Elon Musk: Regulation of AI Safety</h2><a href="https://www.youtube.com/watch?v=9OmE4jEVIfQ"><img src="https://i.ytimg.com/vi_webp/9OmE4jEVIfQ/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./9OmE4jEVIfQ.html">Whisper Transcript</a> | <a href="./transcript_9OmE4jEVIfQ.html">Transcript Only Page</a></div><br><h3>Transcript</h3><div style="max-width: 600px;"><p>So, on a darker topic, you've expressed serious concern about existential threats of AI. It's perhaps one of the greatest challenges our civilization faces, but since I would say we're kind of an optimistic descendants of apes, perhaps we can find several paths of escaping the harm of AI. So if I can give you three options, maybe you can comment which do you think is the most promising. So one is scaling up efforts on AI safety and beneficial AI research in hope of finding an algorithmic or maybe a policy solution. Two is becoming a multi-planetary species as quickly as possible. And three is merging with AI and riding the wave of that increasing intelligence as it continuously improves. What do you think is most promising, most interesting as a civilization that we should invest in? I think there's a tremendous amount of investment going on in AI. Where there's a lack of investment is in AI safety. And there should be, in my view, a government agency that oversees anything related to AI to confirm that it does not represent a public safety risk. Just as there is a regulatory authority for the Food and Drug Administration, there's the NHTSA for automotive safety, there's the FAA for aircraft safety. We generally come to the conclusion that it is important to have a government referee or a referee that is serving the public interest in ensuring that things are safe when there's a potential danger to the public. I would argue that AI is unequivocally something that has potential to be dangerous to the public and therefore should have a regulatory agency just as other things that are dangerous to the public have a regulatory agency. But let me tell you, the problem with this is that it governs very slowly. And the rate of, usually the way a regulatory agency comes into being is that something terrible happens. There's a huge public outcry. And years after that, there's a regulatory agency or a rule put in place. Take something like seatbelts. It was known for a decade or more that seatbelts would have a massive impact on safety and save so many lives and serious injuries. And the car industry fought the requirement to put seatbelts in tooth and nail. That's crazy. And hundreds of thousands of people probably died because of that. And they said people wouldn't buy cars if they had seatbelts, which is obviously absurd. Or look at the tobacco industry and how long they fought anything about smoking. That's part of why I helped make that movie, Thank You For Smoking. You can sort of see just how pernicious it can be when you have these companies effectively achieve regulatory capture of government. People in the AI community refer to the advent of digital superintelligence as a singularity. That is not to say that it is good or bad, but that it is very difficult to predict what will happen after that point. And that there's some probability it will be bad, some probability it will be good. But obviously I want to affect that probability and have it be more good than bad.</p></div></body></html>