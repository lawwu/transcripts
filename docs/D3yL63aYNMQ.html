<html><head><title>Stanford XCS224U: NLU I Information Retrieval, Part 2: Classical IR I Spring 2023</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford XCS224U: NLU I Information Retrieval, Part 2: Classical IR I Spring 2023</h2><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ"><img src="https://i.ytimg.com/vi/D3yL63aYNMQ/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./D3yL63aYNMQ.html">Whisper Transcript</a> | <a href="./transcript_D3yL63aYNMQ.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Welcome back everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=6" target="_blank">00:00:06.000</a></span> | <span class="t">This is part two in our series on information retrieval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=8" target="_blank">00:00:08.800</a></span> | <span class="t">We're going to briefly review classical IR approaches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=11" target="_blank">00:00:11.680</a></span> | <span class="t">It will be a brief overview because our focus in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=14" target="_blank">00:00:14.040</a></span> | <span class="t">this course is on neural information retrieval,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=16" target="_blank">00:00:16.120</a></span> | <span class="t">but I did want to cover these classical ideas because they're very powerful,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=20" target="_blank">00:00:20.280</a></span> | <span class="t">and classical IR systems could very well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=22" target="_blank">00:00:22.760</a></span> | <span class="t">be important components in models that you develop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=25" target="_blank">00:00:25.920</a></span> | <span class="t">The standard starting point for classical IR is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=29" target="_blank">00:00:29.000</a></span> | <span class="t">the term document matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=30" target="_blank">00:00:30.560</a></span> | <span class="t">I've got a fragment of a real term document matrix on the slide here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=34" target="_blank">00:00:34.240</a></span> | <span class="t">The terms are along the rows,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=36" target="_blank">00:00:36.200</a></span> | <span class="t">the documents go along the columns,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=38" target="_blank">00:00:38.440</a></span> | <span class="t">and the cells record the number of times that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=40" target="_blank">00:00:40.760</a></span> | <span class="t">each word appeared in each one of these documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=43" target="_blank">00:00:43.360</a></span> | <span class="t">These are standardly very large,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=45" target="_blank">00:00:45.740</a></span> | <span class="t">very sparse matrices, but they encode latently a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=49" target="_blank">00:00:49.600</a></span> | <span class="t">information about which documents are relevant to which query terms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=54" target="_blank">00:00:54.480</a></span> | <span class="t">TF-IDF is a common approach to massaging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=59" target="_blank">00:00:59.440</a></span> | <span class="t">those term document values to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=61" target="_blank">00:01:01.840</a></span> | <span class="t">more information about relevance from the matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=64" target="_blank">00:01:04.640</a></span> | <span class="t">Here's how TF-IDF works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=66" target="_blank">00:01:06.120</a></span> | <span class="t">We begin from a corpus of documents D.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=69" target="_blank">00:01:09.000</a></span> | <span class="t">Term frequency is actually internal to each one of these documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=72" target="_blank">00:01:12.960</a></span> | <span class="t">TF of a word given a document is simply the number of times that that word appears in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=77" target="_blank">00:01:17.560</a></span> | <span class="t">the document divided by the total length of the document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=81" target="_blank">00:01:21.300</a></span> | <span class="t">so a standard relative frequency value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=84" target="_blank">00:01:24.080</a></span> | <span class="t">Document frequency is a function of words and our entire corpus,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=89" target="_blank">00:01:29.160</a></span> | <span class="t">and we're simply counting the number of documents that contain the target word,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=92" target="_blank">00:01:32.840</a></span> | <span class="t">regardless of how frequent the word is in each one of those documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=95" target="_blank">00:01:35.800</a></span> | <span class="t">Simple occurrence, the number of documents that contains the target word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=100" target="_blank">00:01:40.160</a></span> | <span class="t">Then inverse document frequency is just the log of the total size of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=104" target="_blank">00:01:44.600</a></span> | <span class="t">our corpus divided by the document frequency value that we calculated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=109" target="_blank">00:01:49.400</a></span> | <span class="t">Then TF-IDF is simply the product of the TF and the IDF values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=114" target="_blank">00:01:54.840</a></span> | <span class="t">Here's a little worked example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=117" target="_blank">00:01:57.200</a></span> | <span class="t">I have a term document matrix on the slide in the left here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=121" target="_blank">00:02:01.600</a></span> | <span class="t">We calculate the IDF values,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=123" target="_blank">00:02:03.500</a></span> | <span class="t">those are given on the right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=125" target="_blank">00:02:05.000</a></span> | <span class="t">and then the term frequency values are given at the bottom of the slide,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=128" target="_blank">00:02:08.680</a></span> | <span class="t">and then we get the product of those for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=130" target="_blank">00:02:10.600</a></span> | <span class="t">the TF-IDF values down in the lower right here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=133" target="_blank">00:02:13.580</a></span> | <span class="t">I think you can start to see some noteworthy patterns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=136" target="_blank">00:02:16.200</a></span> | <span class="t">For example, the term C is in relatively few documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=141" target="_blank">00:02:21.280</a></span> | <span class="t">just two of them, and it's relatively frequent in both of those documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=145" target="_blank">00:02:25.680</a></span> | <span class="t">and as a result, it has high TF-IDF values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=149" target="_blank">00:02:29.040</a></span> | <span class="t">We could also look at term D here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=151" target="_blank">00:02:31.200</a></span> | <span class="t">It occurs in only one document and is relatively infrequent in that document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=156" target="_blank">00:02:36.520</a></span> | <span class="t">As a result of occurring in only one document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=159" target="_blank">00:02:39.040</a></span> | <span class="t">it ends up with a pretty high TF-IDF value because its IDF value is so high,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=163" target="_blank">00:02:43.960</a></span> | <span class="t">even though its term frequency is low.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=166" target="_blank">00:02:46.280</a></span> | <span class="t">Correspondingly, term A here gets a TF-IDF value of zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=172" target="_blank">00:02:52.820</a></span> | <span class="t">It was highly frequent in document 4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=176" target="_blank">00:02:56.040</a></span> | <span class="t">but it occurs in all of the documents and therefore ends up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=179" target="_blank">00:02:59.720</a></span> | <span class="t">an IDF value of zero and therefore TF-IDF value of zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=183" target="_blank">00:03:03.560</a></span> | <span class="t">It gives you a sense for how these values combine to give us TF-IDF.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=188" target="_blank">00:03:08.940</a></span> | <span class="t">Let's actually break down the scoring in a little bit more of a systematic way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=192" target="_blank">00:03:12.840</a></span> | <span class="t">starting with the IDF values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=194" target="_blank">00:03:14.920</a></span> | <span class="t">For IDF, we do have a little bit of a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=197" target="_blank">00:03:17.720</a></span> | <span class="t">If we have a word that occurs in no documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=200" target="_blank">00:03:20.680</a></span> | <span class="t">then the IDF value is undefined because we need to divide by zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=205" target="_blank">00:03:25.240</a></span> | <span class="t">What I've done here is simply stipulate that that's a zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=209" target="_blank">00:03:29.040</a></span> | <span class="t">If a word appears in just one document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=212" target="_blank">00:03:32.240</a></span> | <span class="t">it gets a maximal IDF value,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=215" target="_blank">00:03:35.200</a></span> | <span class="t">and the IDF values drop off steadily as the word appears in more and more documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=220" target="_blank">00:03:40.320</a></span> | <span class="t">all the way up to appearing in every document</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=222" target="_blank">00:03:42.720</a></span> | <span class="t">given the little corpus of 10 documents that we're imagining,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=225" target="_blank">00:03:45.640</a></span> | <span class="t">and that too is an IDF value of zero as we saw on the previous slide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=230" target="_blank">00:03:50.280</a></span> | <span class="t">The idea here is that by the time you have a word that appears in every document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=234" target="_blank">00:03:54.180</a></span> | <span class="t">it's simply not informative about which documents are relevant,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=237" target="_blank">00:03:57.660</a></span> | <span class="t">and so its IDF value should be minimized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=240" target="_blank">00:04:00.840</a></span> | <span class="t">Here's a slide showing selected TF-IDF values,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=244" target="_blank">00:04:04.480</a></span> | <span class="t">and I think the pattern is very clear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=246" target="_blank">00:04:06.180</a></span> | <span class="t">TF-IDF reaches its maximal values for terms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=249" target="_blank">00:04:09.920</a></span> | <span class="t">that occur very frequently in very few documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=253" target="_blank">00:04:13.880</a></span> | <span class="t">and correspondingly, TF-IDF values are at their lowest for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=257" target="_blank">00:04:17.840</a></span> | <span class="t">words that are very infrequent in very many documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=262" target="_blank">00:04:22.040</a></span> | <span class="t">Those are the tiny bubbles up here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=263" target="_blank">00:04:23.660</a></span> | <span class="t">That's the core behavior of TF-IDF.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=266" target="_blank">00:04:26.800</a></span> | <span class="t">What we're really looking for is words that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=269" target="_blank">00:04:29.400</a></span> | <span class="t">truly distinguishing indicators of particular documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=274" target="_blank">00:04:34.840</a></span> | <span class="t">To calculate relevant scores for a given query which might contain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=278" target="_blank">00:04:38.900</a></span> | <span class="t">multiple terms, the standard approach is simply to sum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=282" target="_blank">00:04:42.440</a></span> | <span class="t">over whatever weighting we're using for the term document matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=286" target="_blank">00:04:46.760</a></span> | <span class="t">For example, if weight here is TF-IDF,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=289" target="_blank">00:04:49.240</a></span> | <span class="t">we simply sum over the TF-IDF values for every word in our query,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=293" target="_blank">00:04:53.360</a></span> | <span class="t">and that gives us a relevant score for the entire user query.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=298" target="_blank">00:04:58.320</a></span> | <span class="t">BM25 is arguably the most famous classical IR approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=305" target="_blank">00:05:05.560</a></span> | <span class="t">BM25 stands for Best Match Attempt 25,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=309" target="_blank">00:05:09.180</a></span> | <span class="t">which suggests a lot of exploration of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=311" target="_blank">00:05:11.020</a></span> | <span class="t">the different hyperparameters of this model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=313" target="_blank">00:05:13.200</a></span> | <span class="t">looking for a solution that was best,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=315" target="_blank">00:05:15.200</a></span> | <span class="t">and this has indeed turned out to be an enduringly good solution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=319" target="_blank">00:05:19.380</a></span> | <span class="t">With BM25, you're going to see that this is a enhanced version of TF-IDF.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=325" target="_blank">00:05:25.120</a></span> | <span class="t">We begin from smoothed IDF values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=327" target="_blank">00:05:27.840</a></span> | <span class="t">These are essentially the IDF values that I just showed you with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=331" target="_blank">00:05:31.340</a></span> | <span class="t">a little bit of an adjustment to handle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=333" target="_blank">00:05:33.260</a></span> | <span class="t">the undefinedness case that we briefly worried about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=336" target="_blank">00:05:36.900</a></span> | <span class="t">The next component is scoring,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=339" target="_blank">00:05:39.280</a></span> | <span class="t">and this is analogous to term frequency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=341" target="_blank">00:05:41.920</a></span> | <span class="t">You can see in this definition that term frequency is an important component.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=345" target="_blank">00:05:45.840</a></span> | <span class="t">We also have two hyperparameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=347" target="_blank">00:05:47.860</a></span> | <span class="t">K and B, which I'm going to talk about in a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=350" target="_blank">00:05:50.940</a></span> | <span class="t">But just to round this out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=352" target="_blank">00:05:52.600</a></span> | <span class="t">the BM25 weight is a combination of those adjusted IDF values and the scoring values,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=359" target="_blank">00:05:59.180</a></span> | <span class="t">which are analogous somewhat to term frequency and TF-IDF.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=363" target="_blank">00:06:03.760</a></span> | <span class="t">The definitions are different and we're going to dive into them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=366" target="_blank">00:06:06.560</a></span> | <span class="t">but at a high level, you can see it's a product of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=368" target="_blank">00:06:08.580</a></span> | <span class="t">two very similar values to the ones we had for TF-IDF.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=372" target="_blank">00:06:12.840</a></span> | <span class="t">Let's take a look at the individual components in a bit more detail,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=376" target="_blank">00:06:16.580</a></span> | <span class="t">starting with IDF.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=377" target="_blank">00:06:17.900</a></span> | <span class="t">What I have on the slide here is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=379" target="_blank">00:06:19.680</a></span> | <span class="t">the IDF plot that I showed you previously from the TF-IDF definitions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=384" target="_blank">00:06:24.260</a></span> | <span class="t">and then I have the BM25 variant of that at the bottom here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=387" target="_blank">00:06:27.580</a></span> | <span class="t">What I've done is just emphasize that this S value here is standardly set at 0.5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=393" target="_blank">00:06:33.360</a></span> | <span class="t">but we could in principle adjust it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=395" target="_blank">00:06:35.940</a></span> | <span class="t">Here are a few values for that value S.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=399" target="_blank">00:06:39.960</a></span> | <span class="t">The standard value is the one in purple, that's 0.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=403" target="_blank">00:06:43.120</a></span> | <span class="t">You can see that the result is that we very closely match</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=406" target="_blank">00:06:46.540</a></span> | <span class="t">the standard IDF values throughout the entire space of document frequency values,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=411" target="_blank">00:06:51.400</a></span> | <span class="t">with the exception that we give a very high value,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=413" target="_blank">00:06:53.820</a></span> | <span class="t">incidentally, to words that appear in no documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=417" target="_blank">00:06:57.340</a></span> | <span class="t">That won't turn out to be relevant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=419" target="_blank">00:06:59.020</a></span> | <span class="t">What really happens as we adjust S is we're adjusting things at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=422" target="_blank">00:07:02.940</a></span> | <span class="t">that really degenerate part of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=425" target="_blank">00:07:05.700</a></span> | <span class="t">this overall space for words that appear in no documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=428" target="_blank">00:07:08.840</a></span> | <span class="t">Once we get into words appearing in documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=430" target="_blank">00:07:10.980</a></span> | <span class="t">the values track pretty closely,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=433" target="_blank">00:07:13.100</a></span> | <span class="t">with maybe the exception that if you set S very high,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=436" target="_blank">00:07:16.040</a></span> | <span class="t">you get real differences in the lowest part of this spectrum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=440" target="_blank">00:07:20.440</a></span> | <span class="t">But by and large, if we set it at 0.5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=442" target="_blank">00:07:22.900</a></span> | <span class="t">we're just reproducing the IDF values that we had from the earlier definitions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=447" target="_blank">00:07:27.420</a></span> | <span class="t">The scoring function is more nuanced as a result of having lots of hyperparameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=451" target="_blank">00:07:31.780</a></span> | <span class="t">Let's break this down a little bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=453" target="_blank">00:07:33.500</a></span> | <span class="t">see if we can get some analytic insights into what's happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=457" target="_blank">00:07:37.040</a></span> | <span class="t">The scoring function is repeated at the bottom here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=459" target="_blank">00:07:39.680</a></span> | <span class="t">and I've highlighted in orange a term that plays the role of penalizing long documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=465" target="_blank">00:07:45.600</a></span> | <span class="t">Then this plot should help us see precisely how that plays out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=469" target="_blank">00:07:49.100</a></span> | <span class="t">Let's imagine that we're looking at a document that has length 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=472" target="_blank">00:07:52.820</a></span> | <span class="t">I have the term frequency values along the x-axis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=476" target="_blank">00:07:56.060</a></span> | <span class="t">and the BM25 scoring values along the y-axis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=480" target="_blank">00:08:00.060</a></span> | <span class="t">If I am looking at a document that has average,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=484" target="_blank">00:08:04.100</a></span> | <span class="t">sorry, if the corpus has average document length of 10,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=486" target="_blank">00:08:06.920</a></span> | <span class="t">that's the purple line here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=488" target="_blank">00:08:08.460</a></span> | <span class="t">and that's the same length as our example document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=491" target="_blank">00:08:11.880</a></span> | <span class="t">As our example document becomes long relative to the average length with 5 and 3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=496" target="_blank">00:08:16.900</a></span> | <span class="t">you can see that the scoring values systematically go down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=500" target="_blank">00:08:20.980</a></span> | <span class="t">To summarize, as our target document is long relative to the average,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=506" target="_blank">00:08:26.120</a></span> | <span class="t">the scores are diminished.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=507" target="_blank">00:08:27.740</a></span> | <span class="t">The overall effect of this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=509" target="_blank">00:08:29.400</a></span> | <span class="t">as I said, is to penalize long documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=511" target="_blank">00:08:31.860</a></span> | <span class="t">The intuition there is that long documents might just,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=515" target="_blank">00:08:35.300</a></span> | <span class="t">as a result of being long,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=516" target="_blank">00:08:36.860</a></span> | <span class="t">contain more terms, and therefore,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=519" target="_blank">00:08:39.340</a></span> | <span class="t">on average, we should trust the terms they do contain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=522" target="_blank">00:08:42.380</a></span> | <span class="t">less as evidence for our overall relevance scoring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=526" target="_blank">00:08:46.540</a></span> | <span class="t">That's the penalty for long documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=529" target="_blank">00:08:49.980</a></span> | <span class="t">Now, let's dive into the role of B.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=532" target="_blank">00:08:52.940</a></span> | <span class="t">The function of that hyperparameter B is to control</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=536" target="_blank">00:08:56.260</a></span> | <span class="t">the amount of the penalty that we give to long documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=540" target="_blank">00:09:00.620</a></span> | <span class="t">Let's break that down a little bit over here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=542" target="_blank">00:09:02.820</a></span> | <span class="t">Again, we have a target document of length 10,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=545" target="_blank">00:09:05.740</a></span> | <span class="t">that's our example, and we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=547" target="_blank">00:09:07.560</a></span> | <span class="t">an average document length of 5 over here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=550" target="_blank">00:09:10.640</a></span> | <span class="t">You can see that as we increase B from 0.1 to 1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=554" target="_blank">00:09:14.380</a></span> | <span class="t">the overall effect is to diminish the scores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=557" target="_blank">00:09:17.300</a></span> | <span class="t">Higher values of B mean more of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=560" target="_blank">00:09:20.220</a></span> | <span class="t">a penalty given to long documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=563" target="_blank">00:09:23.340</a></span> | <span class="t">because that reduces the score even more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=565" target="_blank">00:09:25.780</a></span> | <span class="t">Over on the right here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=567" target="_blank">00:09:27.400</a></span> | <span class="t">if our example document has length 10,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=572" target="_blank">00:09:32.180</a></span> | <span class="t">which is the same as the average document length for our corpus,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=575" target="_blank">00:09:35.740</a></span> | <span class="t">then the value of B makes no difference as a result of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=578" target="_blank">00:09:38.540</a></span> | <span class="t">the fact that there's no penalty even to apply in these cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=582" target="_blank">00:09:42.420</a></span> | <span class="t">It's really just for long documents relative to the average that B is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=586" target="_blank">00:09:46.860</a></span> | <span class="t">controlling the amount of penalty that we apply in those cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=591" target="_blank">00:09:51.380</a></span> | <span class="t">Then what about K? What is the effect of K?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=594" target="_blank">00:09:54.720</a></span> | <span class="t">It appears here in the scoring function,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=596" target="_blank">00:09:56.820</a></span> | <span class="t">the overall effect is to flatten out higher frequencies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=600" target="_blank">00:10:00.860</a></span> | <span class="t">I think one way to get a grip on this is to think about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=603" target="_blank">00:10:03.880</a></span> | <span class="t">the extreme situation in which you have set K very, very low.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=607" target="_blank">00:10:07.800</a></span> | <span class="t">This would be a non-standard value for K.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=610" target="_blank">00:10:10.500</a></span> | <span class="t">In the situation where you set it very low,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=613" target="_blank">00:10:13.240</a></span> | <span class="t">what you essentially do is turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=615" target="_blank">00:10:15.060</a></span> | <span class="t">the scoring function into an indicator function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=617" target="_blank">00:10:17.500</a></span> | <span class="t">You can see that we get a register of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=619" target="_blank">00:10:19.740</a></span> | <span class="t">a scoring value if the word is in the document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=622" target="_blank">00:10:22.720</a></span> | <span class="t">and then it simply flattens out over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=624" target="_blank">00:10:24.740</a></span> | <span class="t">all the different values for term frequency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=627" target="_blank">00:10:27.060</a></span> | <span class="t">It's like you appeared,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=628" target="_blank">00:10:28.580</a></span> | <span class="t">and then I don't care how many times you appeared,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=631" target="_blank">00:10:31.140</a></span> | <span class="t">I'm hardly going to adjust the scoring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=633" target="_blank">00:10:33.820</a></span> | <span class="t">Then as you make K larger,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=636" target="_blank">00:10:36.540</a></span> | <span class="t">you get less and less of a dramatic effect like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=639" target="_blank">00:10:39.340</a></span> | <span class="t">You care more and more about whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=641" target="_blank">00:10:41.340</a></span> | <span class="t">the word appears frequently in the documents or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=643" target="_blank">00:10:43.900</a></span> | <span class="t">This red line is really an extreme case where you've decided not to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=646" target="_blank">00:10:46.860</a></span> | <span class="t">care very much about the different values of relative frequency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=650" target="_blank">00:10:50.780</a></span> | <span class="t">A more standard value for K is 1.2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=653" target="_blank">00:10:53.600</a></span> | <span class="t">and that's giving this modest diminishing amount.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=656" target="_blank">00:10:56.460</a></span> | <span class="t">As you get terms that are really frequent in documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=659" target="_blank">00:10:59.460</a></span> | <span class="t">you flatten out the scoring function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=662" target="_blank">00:11:02.460</a></span> | <span class="t">That's the overall effect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=664" target="_blank">00:11:04.100</a></span> | <span class="t">Flattening out higher frequencies with the value of K,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=667" target="_blank">00:11:07.180</a></span> | <span class="t">controlling how much flattening you decide to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=670" target="_blank">00:11:10.900</a></span> | <span class="t">With those components in place,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=674" target="_blank">00:11:14.180</a></span> | <span class="t">we can return to our classic inverted index from information retrieval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=678" target="_blank">00:11:18.260</a></span> | <span class="t">That's an inverted index in the sense that we go from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=680" target="_blank">00:11:20.460</a></span> | <span class="t">terms to documents rather than documents to terms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=683" target="_blank">00:11:23.600</a></span> | <span class="t">Have our query come in, we do our term lookup.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=686" target="_blank">00:11:26.180</a></span> | <span class="t">Previously, I showed you this as simply a list of documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=689" target="_blank">00:11:29.260</a></span> | <span class="t">but now of course with something like BM25 or TF-IDF,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=692" target="_blank">00:11:32.420</a></span> | <span class="t">we can augment this with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=694" target="_blank">00:11:34.140</a></span> | <span class="t">pre-computed scores or document frequency values,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=697" target="_blank">00:11:37.900</a></span> | <span class="t">and with pre-computed IDF values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=700" target="_blank">00:11:40.460</a></span> | <span class="t">We have all the ingredients we need for a given query to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=703" target="_blank">00:11:43.540</a></span> | <span class="t">do full-on document scoring very efficiently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=706" target="_blank">00:11:46.580</a></span> | <span class="t">That is one essential ingredient for why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=709" target="_blank">00:11:49.300</a></span> | <span class="t">these classical approaches are so massively scalable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=713" target="_blank">00:11:53.460</a></span> | <span class="t">That's it for what I wanted to cover on classical IR,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=718" target="_blank">00:11:58.100</a></span> | <span class="t">but I'd be remiss if I didn't mention a few obvious topics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=721" target="_blank">00:12:01.060</a></span> | <span class="t">that are explored in detail in this literature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=723" target="_blank">00:12:03.520</a></span> | <span class="t">We could of course do query and document expansion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=726" target="_blank">00:12:06.340</a></span> | <span class="t">We could augment what the user gives us and what's in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=728" target="_blank">00:12:08.540</a></span> | <span class="t">our corpus with additional information and maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=730" target="_blank">00:12:10.740</a></span> | <span class="t">metadata that would help us with relevant scoring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=734" target="_blank">00:12:14.100</a></span> | <span class="t">We could move to phrase-level search.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=736" target="_blank">00:12:16.020</a></span> | <span class="t">I've focused on unigrams,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=737" target="_blank">00:12:17.540</a></span> | <span class="t">but of course that's not a necessary restriction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=739" target="_blank">00:12:19.740</a></span> | <span class="t">We could think about n-grams and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=741" target="_blank">00:12:21.700</a></span> | <span class="t">even more sophisticated notions of linguistic units.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=745" target="_blank">00:12:25.220</a></span> | <span class="t">We haven't talked at all about term dependence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=747" target="_blank">00:12:27.620</a></span> | <span class="t">We've assumed that all the terms in a document are independent of each other,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=750" target="_blank">00:12:30.980</a></span> | <span class="t">but if you think about bigrams like New York,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=754" target="_blank">00:12:34.000</a></span> | <span class="t">that's obviously an unhappy approximation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=756" target="_blank">00:12:36.920</a></span> | <span class="t">We should be thinking about how all these terms have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=759" target="_blank">00:12:39.560</a></span> | <span class="t">their own internal statistical dependencies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=762" target="_blank">00:12:42.320</a></span> | <span class="t">and bring that into the search functionality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=764" target="_blank">00:12:44.960</a></span> | <span class="t">We could also, and this is really important,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=766" target="_blank">00:12:46.800</a></span> | <span class="t">think about different document fields.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=768" target="_blank">00:12:48.720</a></span> | <span class="t">Documents are not homogenous and words that appear in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=771" target="_blank">00:12:51.320</a></span> | <span class="t">the title might have a different relevance value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=773" target="_blank">00:12:53.900</a></span> | <span class="t">inherently than words that appear in the body of a document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=777" target="_blank">00:12:57.040</a></span> | <span class="t">We would want our best classical search technologies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=780" target="_blank">00:13:00.500</a></span> | <span class="t">and our best search technologies in general</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=782" target="_blank">00:13:02.440</a></span> | <span class="t">to be sensitive to those distinctions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=784" target="_blank">00:13:04.920</a></span> | <span class="t">Then of course a big gap in what I've showed so far is link analysis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=789" target="_blank">00:13:09.180</a></span> | <span class="t">We could think about how the documents in our corpus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=792" target="_blank">00:13:12.060</a></span> | <span class="t">inform an implicit graph based on how they hyperlink with each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=796" target="_blank">00:13:16.120</a></span> | <span class="t">We know from modern search that that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=798" target="_blank">00:13:18.720</a></span> | <span class="t">a crucial factor in shaping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=800" target="_blank">00:13:20.720</a></span> | <span class="t">relevance and having the best documents come to the top.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=803" target="_blank">00:13:23.240</a></span> | <span class="t">I have left that out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=804" target="_blank">00:13:24.360</a></span> | <span class="t">but it's obviously incredibly important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=807" target="_blank">00:13:27.640</a></span> | <span class="t">Then of course finally,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=810" target="_blank">00:13:30.220</a></span> | <span class="t">learning to rank, that is learn functionality for what's relevant given</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=814" target="_blank">00:13:34.260</a></span> | <span class="t">queries is an important feature of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=816" target="_blank">00:13:36.580</a></span> | <span class="t">the neural IR models that we're going to discuss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=819" target="_blank">00:13:39.640</a></span> | <span class="t">I have not introduced that in the context of classical IR,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=823" target="_blank">00:13:43.080</a></span> | <span class="t">but we could have learned ranking functions that would go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=826" target="_blank">00:13:46.380</a></span> | <span class="t">beyond the simple a priori calculations of things like TF-IDF and BM25.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=834" target="_blank">00:13:54.320</a></span> | <span class="t">Finally, there are lots of tools out there that would help you with classical IR.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=839" target="_blank">00:13:59.240</a></span> | <span class="t">Elasticsearch is widely deployed, very robust,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=842" target="_blank">00:14:02.360</a></span> | <span class="t">mature search technology, highly scalable, lots of features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=846" target="_blank">00:14:06.320</a></span> | <span class="t">PySereny and PrimeQA are research repositories that could also be really useful to you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=851" target="_blank">00:14:11.680</a></span> | <span class="t">if you want to think about setting up classical IR models as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=855" target="_blank">00:14:15.320</a></span> | <span class="t">baselines or as using them in components in larger systems that might have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=860" target="_blank">00:14:20.040</a></span> | <span class="t">a small role for neural IR models as re-rankers of results that come from a very fast,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=866" target="_blank">00:14:26.880</a></span> | <span class="t">very robust classical IR system that's a common mode to operate in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=871" target="_blank">00:14:31.240</a></span> | <span class="t">that gives you highly scalable solutions where the neural models that we'll talk about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=874" target="_blank">00:14:34.960</a></span> | <span class="t">later play the role of refining the core results returned by the classical model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=D3yL63aYNMQ&t=880" target="_blank">00:14:40.840</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>