<html><head><title>OpenThoughts: Data Recipes for Reasoning Models — Ryan Marten, Bespoke Labs</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>OpenThoughts: Data Recipes for Reasoning Models — Ryan Marten, Bespoke Labs</h2><a href="https://www.youtube.com/watch?v=liG97YXaTSA"><img src="https://i.ytimg.com/vi_webp/liG97YXaTSA/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=0">0:0</a> Introduction to the problem of open-source reasoning in AI models.<br><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=69">1:9</a> The effectiveness of Supervised Fine-Tuning (SFT) for reasoning.<br><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=218">3:38</a> Introduction to OpenThoughts 3 and its performance.<br><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=472">7:52</a> Key learnings from the data recipe development.<br><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=694">11:34</a> Guidance on adapting the dataset recipe to specific domains.<br><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=915">15:15</a> Call for open collaboration and where to find the project's resources<br><br><div style="text-align: left;"><a href="./liG97YXaTSA.html">Whisper Transcript</a> | <a href="./transcript_liG97YXaTSA.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">I'm Ryan. I'm a founding engineer at Bespoke Labs, and today I'm going to talk to you about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=19" target="_blank">00:00:19.740</a></span> | <span class="t">OpenThoughts, which is our project to create the best open source reasoning data sets. I'll be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=26" target="_blank">00:00:26.880</a></span> | <span class="t">switching tack a little bit from our earlier discussions on reasoning and RL and focus on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=33" target="_blank">00:00:33.100</a></span> | <span class="t">the reasoning part, and you'll see why. So just so we're on the same page, we've talked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=38" target="_blank">00:00:38.700</a></span> | <span class="t">a lot about reasoning, but what's actually going on here? So I like this graph from Jason,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=43" target="_blank">00:00:43.880</a></span> | <span class="t">which shows this incredible performance that's happened in the last several months where models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=49" target="_blank">00:00:49.900</a></span> | <span class="t">are getting much, much, much better on certain benchmarks. And if you look at that, this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=54" target="_blank">00:00:54.980</a></span> | <span class="t">reasoning. This is test time scaling. I think everyone here is quite familiar with this, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=58" target="_blank">00:00:58.600</a></span> | <span class="t">it seems that certain tasks like Amy, which are competitive math problems, really respond</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=65" target="_blank">00:01:05.080</a></span> | <span class="t">to models when they're able to think step by step and do these long chain of thoughts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=72" target="_blank">00:01:12.100</a></span> | <span class="t">So let's go back to DeepSeq R1. Now, DeepSeq R1 was really impressive for a lot of people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=77" target="_blank">00:01:17.800</a></span> | <span class="t">for a lot of reasons, and RL was a big part of that. But I was also particularly interested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=83" target="_blank">00:01:23.480</a></span> | <span class="t">because DeepSeq R1, at the end of the day, is an SFT model. So the final weights that they've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=89" target="_blank">00:01:29.980</a></span> | <span class="t">released are actually from DeepSeq v3 base, which is fine-tuned on 800k SFT examples, 600k of which are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=99" target="_blank">00:01:39.340</a></span> | <span class="t">reasoning. Of course, you can see here that RL was a big part of it, and RL was used heavily to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=106" target="_blank">00:01:46.220</a></span> | <span class="t">that model which generated this data. But at the end, it was SFT and a little bit of RL for alignment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=112" target="_blank">00:01:52.860</a></span> | <span class="t">So this was really interesting and surprising. And the other thing that was really interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=116" target="_blank">00:01:56.940</a></span> | <span class="t">and surprising to us was these small reasoning models that DeepSeq released, which were incredibly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=122" target="_blank">00:02:02.700</a></span> | <span class="t">strong. And this, for us, was a huge motivation to try to do this ourselves. And why is that interesting?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=132" target="_blank">00:02:12.780</a></span> | <span class="t">Because if we go back to here, no additional detail was really given on these data sets here. So if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=140" target="_blank">00:02:20.220</a></span> | <span class="t">want to create strong reasoning models, we now sort of have a training recipe, but we don't have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=145" target="_blank">00:02:25.420</a></span> | <span class="t">data recipe. That's the missing link. Okay. I want to also include a slide here on why is it interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=152" target="_blank">00:02:32.940</a></span> | <span class="t">to train your own reasoning models. So I'm partially taking this from Amir's talk yesterday on open source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=159" target="_blank">00:02:39.660</a></span> | <span class="t">and enterprise, which I really liked. But there's these main points: performance, privacy, speeding cost,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=165" target="_blank">00:02:45.260</a></span> | <span class="t">and then ownership and destiny. I think using reasoning is a great tool to solve a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=172" target="_blank">00:02:52.700</a></span> | <span class="t">And you shouldn't limit yourself in your toolbox if you're trying to solve a specific domain task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=179" target="_blank">00:02:59.420</a></span> | <span class="t">So as we talked about before, RL is a great tool in this toolbox to tackle reasoning tasks. But we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=185" target="_blank">00:03:05.900</a></span> | <span class="t">going to see here that SFT is, as Nathan put this morning, extremely easy and extremely effective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=191" target="_blank">00:03:11.180</a></span> | <span class="t">Okay, great. Now, the missing link. How do we actually solve for this reasoning data recipe?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=198" target="_blank">00:03:18.380</a></span> | <span class="t">There's all these questions that we had when we started. How much data do you really need?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=203" target="_blank">00:03:23.260</a></span> | <span class="t">What data curation steps are necessary? What are the optimal choices for each step in that data creation pipeline?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=211" target="_blank">00:03:31.820</a></span> | <span class="t">And then, how do you even go about figuring all this out? And this is the meat of the Open Thoughts project.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=218" target="_blank">00:03:38.060</a></span> | <span class="t">So today, we're excited to announce Open Thoughts 3, which is hot off the presses, just came out two hours</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=224" target="_blank">00:03:44.220</a></span> | <span class="t">ago, which is our latest and greatest version of our reasoning data sets. And...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=229" target="_blank">00:03:49.260</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=232" target="_blank">00:03:52.060</a></span> | <span class="t">Thank you. And now, this is the state-of-the-art reasoning data set recipe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=239" target="_blank">00:03:59.740</a></span> | <span class="t">So you can see here, these graphs are showing accuracy on three of these reasoning benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=246" target="_blank">00:04:06.540</a></span> | <span class="t">AIME, which is competitive math. LiveCodebench is competitive code. And GPQA Diamond, which is our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=252" target="_blank">00:04:12.140</a></span> | <span class="t">science questions. On the y-axis, you see accuracy is going up. On the x-axis, you see the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=259" target="_blank">00:04:19.100</a></span> | <span class="t">scale is going up. So we heard before that scaling is difficult, particularly difficult with RL. The</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=264" target="_blank">00:04:24.860</a></span> | <span class="t">good news is for SFT, scaling is quite easier. You can see here, we compare to other Open Reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=271" target="_blank">00:04:31.500</a></span> | <span class="t">data sets. So Nematron Nano, NVIDIA released this great model, Nematron Nano. It's an AP model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=276" target="_blank">00:04:36.940</a></span> | <span class="t">and they also released the data set to train on it. So we compared directly by training on the same base</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=281" target="_blank">00:04:41.580</a></span> | <span class="t">model between our data set, which is our data set recipe, and the Nematron Nano data, which is the NVIDIA</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=288" target="_blank">00:04:48.060</a></span> | <span class="t">recipe. And you can see here, there's a significant gap. So we've shifted this scaling curve upwards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=293" target="_blank">00:04:53.420</a></span> | <span class="t">Great. So yeah, this is the state-of-the-art 7b open data reasoning model. You can see we've had,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=301" target="_blank">00:05:01.420</a></span> | <span class="t">we have measured across the domains of interest of science, code, and math, and then a couple held up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=306" target="_blank">00:05:06.140</a></span> | <span class="t">benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=309" target="_blank">00:05:09.420</a></span> | <span class="t">So our original goal was to reproduce, to find the missing link for the DeepSeq</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=314" target="_blank">00:05:14.700</a></span> | <span class="t">Distil models. And you can see here, we've crushed that goal. So we're significantly outperforming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=320" target="_blank">00:05:20.860</a></span> | <span class="t">the DeepSeq R1 Quen 7b model, which we started off trying to reproduce. And then compared to the Nematron</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=328" target="_blank">00:05:28.460</a></span> | <span class="t">Nano model, which is trained on a different base model, we are also outperforming on some benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=334" target="_blank">00:05:34.700</a></span> | <span class="t">and similarly competitive on some others. So okay, let's actually talk about how we achieve this. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=339" target="_blank">00:05:39.500</a></span> | <span class="t">is the interesting part for you. So we go back to the scaling graph. You can see, once again, on the x</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=347" target="_blank">00:05:47.180</a></span> | <span class="t">axis, we're scaling dataset size. So this is a huge method to increase accuracy. And the thing here is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=357" target="_blank">00:05:57.580</a></span> | <span class="t">it gets more and more expensive, exponentially more expensive as you keep going.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=361" target="_blank">00:06:01.100</a></span> | <span class="t">And then vertically, you can see that we've shifted the scaling curve up. So this is what I was talking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=368" target="_blank">00:06:08.780</a></span> | <span class="t">about before. This is the improving the dataset recipe. So given a fixed dataset recipe, you can always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=373" target="_blank">00:06:13.900</a></span> | <span class="t">scale it larger and you can always have higher performance. But if you want to push your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=378" target="_blank">00:06:18.700</a></span> | <span class="t">performance to the absolute maximum, the real question is, how do I create the best dataset? And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=384" target="_blank">00:06:24.140</a></span> | <span class="t">therefore, what is the best recipe for the dataset? Okay, so enough teasing here. Let's go into the meat of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=391" target="_blank">00:06:31.820</a></span> | <span class="t">it. So this is how we approach this problem. We broke down the dataset pipeline into sourcing questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=399" target="_blank">00:06:39.900</a></span> | <span class="t">mixing different sources of questions, filtering those questions, filtering out the highest quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=405" target="_blank">00:06:45.020</a></span> | <span class="t">questions, generating answers with a teacher model. So that's distillation, and then filtering out bad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=411" target="_blank">00:06:51.180</a></span> | <span class="t">answers. And lastly, at the end of this entire experimentation, we looked at what are the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=417" target="_blank">00:06:57.260</a></span> | <span class="t">teacher models? Which teacher model should we select? So through this entire pipeline, we've come down to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=422" target="_blank">00:07:02.380</a></span> | <span class="t">this final dataset recipe. Now, this was a ton of work. This is a screenshot of our Hugging Face page. So you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=428" target="_blank">00:07:08.780</a></span> | <span class="t">can see, created over 5,000 datasets and almost 3,000 models. For this project, it was only around 1,000</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=436" target="_blank">00:07:16.380</a></span> | <span class="t">experiments. But just to give you an idea of how rigorously we looked at the different decisions in each of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=442" target="_blank">00:07:22.140</a></span> | <span class="t">these steps of the pipeline. And also, I think this is interesting because it peels back the curtain a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=446" target="_blank">00:07:26.780</a></span> | <span class="t">bit on maybe what the frontier labs are doing. Finding signal at the smallest scale possible,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=453" target="_blank">00:07:33.500</a></span> | <span class="t">and trying out as many things as possible, and empirically choosing the best, and then scaling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=458" target="_blank">00:07:38.780</a></span> | <span class="t">And often, sometimes when you scale, you see, okay, what was the best of the small scale? It doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=463" target="_blank">00:07:43.580</a></span> | <span class="t">actually work. But if you're lucky, and you've done good science, then your YOLO run will be the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=470" target="_blank">00:07:50.540</a></span> | <span class="t">possible, right? Okay. So these are the key learnings that we had from our dataset recipe. And this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=479" target="_blank">00:07:59.900</a></span> | <span class="t">what you can take away. So the first thing is that, pretty surprising, sampling multiple answers, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=487" target="_blank">00:08:07.180</a></span> | <span class="t">multiple reasoning traces per question in your dataset, works really, really well. The performance does not go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=495" target="_blank">00:08:15.260</a></span> | <span class="t">down at a fixed scale. If you take a fixed scale of questions, say 30k questions, or 30k examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=503" target="_blank">00:08:23.260</a></span> | <span class="t">And of those, if you take just 30k questions, and you only sample once per question, that performs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=510" target="_blank">00:08:30.700</a></span> | <span class="t">pretty similarly to if you took 1/16, so 30k over 16, and then for each, you sampled 16 times, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=520" target="_blank">00:08:40.860</a></span> | <span class="t">quite cool. So this allows you, this is really cool, because this allows you to scale by 16x, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=525" target="_blank">00:08:45.500</a></span> | <span class="t">more than an order of magnitude. And if you remember the graph from before, that corresponds to a pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=530" target="_blank">00:08:50.300</a></span> | <span class="t">large increase in accuracy. The other surprising thing that we found was that a better model in terms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=537" target="_blank">00:08:57.900</a></span> | <span class="t">of its own performance on evaluation benchmarks does not necessarily mean it's a better teacher model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=543" target="_blank">00:09:03.420</a></span> | <span class="t">I think a good way to think about this is a brilliant researcher who's maybe a terrible lecturer, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=548" target="_blank">00:09:08.860</a></span> | <span class="t">We found specifically, QUEN32B was a stronger teacher model than DeepSeq R1. So we switched to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=557" target="_blank">00:09:17.180</a></span> | <span class="t">that in our recipe, even though previously, everyone has been using R1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=561" target="_blank">00:09:21.340</a></span> | <span class="t">We also found that the sources of data that had synthetic questions were actually quite good. Some of the top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=570" target="_blank">00:09:30.620</a></span> | <span class="t">sources that we selected were entirely synthetic and better than sources, say, that scraped from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=575" target="_blank">00:09:35.740</a></span> | <span class="t">forums or had humans manually write things. And this is also really good news because synthetic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=581" target="_blank">00:09:41.900</a></span> | <span class="t">question generation is scalable. So once again, we go back to the x-axis and we can push even further,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=587" target="_blank">00:09:47.180</a></span> | <span class="t">which is accuracy boost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=589" target="_blank">00:09:49.340</a></span> | <span class="t">So question filtering also works well. Here we filtered questions by asking a language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=600" target="_blank">00:10:00.700</a></span> | <span class="t">how difficult is this question, and then taking only the hardest questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=604" target="_blank">00:10:04.060</a></span> | <span class="t">We also had a language model try to answer that question and looked at the length of that answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=611" target="_blank">00:10:11.100</a></span> | <span class="t">So these are sort of proxies for the same thing. You can imagine that if a problem is a lot harder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=615" target="_blank">00:10:15.900</a></span> | <span class="t">then a language model will think more and it will produce more text. So its answer will be longer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=621" target="_blank">00:10:21.100</a></span> | <span class="t">And these things worked better than embeddings-based approaches or fast text classifiers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=627" target="_blank">00:10:27.260</a></span> | <span class="t">which is interesting as so much that those approaches were typical for pre-training. So it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=633" target="_blank">00:10:33.340</a></span> | <span class="t">seems that the filtering for data and post-training is quite different than pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=639" target="_blank">00:10:39.180</a></span> | <span class="t">Okay, some things that didn't work that were also quite interesting. Through our experiments,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=643" target="_blank">00:10:43.100</a></span> | <span class="t">you saw that choosing a smaller number of high-quality sources was much better than trying to optimize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=647" target="_blank">00:10:47.580</a></span> | <span class="t">for diversity by going for a larger number of sources. That's very counterintuitive, right? You'd think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=652" target="_blank">00:10:52.540</a></span> | <span class="t">okay, I'm always going to go for higher diversity, but this is actually not what we saw.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=656" target="_blank">00:10:56.140</a></span> | <span class="t">The last thing that was interesting is that people talk a lot about verification, which is obviously very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=662" target="_blank">00:11:02.060</a></span> | <span class="t">important for RL. And we actually see for SFT and distillation, it didn't seem that filtering based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=668" target="_blank">00:11:08.540</a></span> | <span class="t">off of the answer or verifying the answer really helped it all. This is quite surprising. And I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=674" target="_blank">00:11:14.700</a></span> | <span class="t">there's some good research in the literature about maybe why this is, because if you have the hardest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=681" target="_blank">00:11:21.660</a></span> | <span class="t">problem, it might be still helpful, even if you have an incorrect answer to that hardest problem,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=687" target="_blank">00:11:27.020</a></span> | <span class="t">keeping it in and seeing how the teacher model attempts. It's not just the final output that matters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=692" target="_blank">00:11:32.460</a></span> | <span class="t">Okay, great. Okay, so those are all the amazing learnings that we had for Open Thoughts 3, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=699" target="_blank">00:11:39.100</a></span> | <span class="t">super excited to share. But now you're probably thinking, okay, they've done a thousand experiments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=704" target="_blank">00:11:44.060</a></span> | <span class="t">I don't want to do a thousand experiments. I still want to create reasoning models. How do I adapt this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=709" target="_blank">00:11:49.180</a></span> | <span class="t">if I want to create specialized reasoning models? So I guess the first thing I would say is, be aware</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=715" target="_blank">00:11:55.980</a></span> | <span class="t">that based off of your domain, these exact choices might be a little bit different. I would suggest,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=720" target="_blank">00:12:00.860</a></span> | <span class="t">okay, start with our recipe and then iterate on it. If you have capacity and compute, try a couple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=726" target="_blank">00:12:06.460</a></span> | <span class="t">different choices for each step in the pipeline. And I think a good example of this is we studied each step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=731" target="_blank">00:12:11.820</a></span> | <span class="t">in the pipeline differently by domain. So we studied it distinctly for code, science, and math. And we saw,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=738" target="_blank">00:12:18.380</a></span> | <span class="t">for example, in the question filtering, which I talked about before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=741" target="_blank">00:12:21.180</a></span> | <span class="t">using difficulty labels worked well for code questions. But for math and science, it was a response</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=748" target="_blank">00:12:28.940</a></span> | <span class="t">length. And if you think about that for a second, it makes sense because the response length for coding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=755" target="_blank">00:12:35.020</a></span> | <span class="t">questions are very different, right? For Amy math, it's literally just a number between zero and a thousand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=761" target="_blank">00:12:41.500</a></span> | <span class="t">So the answer is not, it's not considering a large portion of the length. But you can imagine there's very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=767" target="_blank">00:12:47.500</a></span> | <span class="t">coding questions in which the answer is still a lot of lines of code. So yeah, this is one thing to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=772" target="_blank">00:12:52.940</a></span> | <span class="t">aware of. The other thing which I talked about previously is synthetic question generation. Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=778" target="_blank">00:12:58.060</a></span> | <span class="t">it works so well, and if your specialized domain, if you're, if you don't have a lot of data for your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=784" target="_blank">00:13:04.220</a></span> | <span class="t">particular problem, then go ahead, transform that existing data into questions, expand it, throw those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=790" target="_blank">00:13:10.940</a></span> | <span class="t">as in context examples, and just generate more data. So yeah, we built an open source library for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=796" target="_blank">00:13:16.380</a></span> | <span class="t">this. It's called curator, and you can you can try that out. And then lastly, I feel like everyone says</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=801" target="_blank">00:13:21.660</a></span> | <span class="t">this, but it can't be said enough. The evaluation is paramount. If you don't know how well your models are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=807" target="_blank">00:13:27.980</a></span> | <span class="t">doing or improving, then you cannot make good principled decisions about your data set recipe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=813" target="_blank">00:13:33.580</a></span> | <span class="t">We spent a lot of time on this. We also have this open source library on GitHub called Evalchemy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=818" target="_blank">00:13:38.700</a></span> | <span class="t">which takes care of this and also takes care of the sharding and parallelism. And the key thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=826" target="_blank">00:13:46.060</a></span> | <span class="t">here is for very small evaluation sets, if you if you only have a handful of questions, you should run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=831" target="_blank">00:13:51.340</a></span> | <span class="t">your model on those evaluation sets many times an average. So going back again to AME competitive math</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=837" target="_blank">00:13:57.740</a></span> | <span class="t">questions, there's only 30 per year. So for our evaluations, we gave the model those 30 questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=845" target="_blank">00:14:05.900</a></span> | <span class="t">10 times, and then we averaged to get the final signal to determine which data strategies were working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=853" target="_blank">00:14:13.020</a></span> | <span class="t">better than others, because otherwise, there's too much noise. Okay, this is also very, very interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=858" target="_blank">00:14:18.140</a></span> | <span class="t">and surprising and promising for you if you're specializing. It seems that you can actually surpass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=864" target="_blank">00:14:24.620</a></span> | <span class="t">the teacher in some domains with distillation. This is this is super cool. Usually you think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=868" target="_blank">00:14:28.860</a></span> | <span class="t">about only RL can push the frontier. Distillation is just about catching up to the teacher. But no,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=873" target="_blank">00:14:33.980</a></span> | <span class="t">that's not the case. So we have an example. It's in our paper where we looked at the legal reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=879" target="_blank">00:14:39.740</a></span> | <span class="t">domain. So the problem of classifying Supreme Court decisions. What we did is we took 2k unique questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=887" target="_blank">00:14:47.980</a></span> | <span class="t">we sampled five answers per question, and then we did do verification here, which which did matter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=895" target="_blank">00:14:55.900</a></span> | <span class="t">So we threw away any questions, any answers that were incorrect. And when you fine tune the 7b model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=902" target="_blank">00:15:02.780</a></span> | <span class="t">it surpasses R1, which is a very strong reasoning model and also a very huge reasoning model. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=908" target="_blank">00:15:08.620</a></span> | <span class="t">is very exciting. There's a lot more research and also application to be done here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=913" target="_blank">00:15:13.340</a></span> | <span class="t">Okay, cool. So everything's open. It's open thoughts and open thoughts means open. Go out and build. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=922" target="_blank">00:15:22.940</a></span> | <span class="t">have all of our detailed paper. It's just out this morning. We've got the weights data set. We have a ton of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=929" target="_blank">00:15:29.500</a></span> | <span class="t">repos for code for data generation, for evaluation and synthetic data. So check those out. This is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=939" target="_blank">00:15:39.100</a></span> | <span class="t">team. It was a huge group of people, a lot of work over many months. I think we're all very proud of what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=944" target="_blank">00:15:44.940</a></span> | <span class="t">we did. But there's lots of people to recognize here. If you scan that QR code, it goes to the tweet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=950" target="_blank">00:15:50.540</a></span> | <span class="t">and everything about the open thoughts project is linked in from there. Yeah. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=955" target="_blank">00:15:55.420</a></span> | <span class="t">All right. Thank you so much, Ryan. That was fascinating. It looks like we're already getting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=967" target="_blank">00:16:07.020</a></span> | <span class="t">we have at least one question lined up. Again, we have time for maybe a couple of questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=971" target="_blank">00:16:11.020</a></span> | <span class="t">So if you have questions, please line up and we'll do it. Actually, before we get to those questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=976" target="_blank">00:16:16.940</a></span> | <span class="t">I will say as people are leaving, we are going to be back here at two o'clock. We've got an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=983" target="_blank">00:16:23.500</a></span> | <span class="t">excellent afternoon planned on this track. We've got Nathan Lambert. We've got the, we've got Christian</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=988" target="_blank">00:16:28.460</a></span> | <span class="t">Segeti, who's the co-founder of X. And it's going to be a really great track at two o'clock back in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=993" target="_blank">00:16:33.100</a></span> | <span class="t">room. Also, one more thing, if you do have questions for any of the speakers from this morning, hopefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=998" target="_blank">00:16:38.620</a></span> | <span class="t">they're going to be able to stick around. Don't let them go to lunch. They're going to be there. They're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1001" target="_blank">00:16:41.420</a></span> | <span class="t">sitting up here at the front. So swarm them as soon as we're done. But for now, let's, let's get a couple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1004" target="_blank">00:16:44.620</a></span> | <span class="t">questions for, uh, go ahead. Um, yes, over there. Uh, thank you. Great talk. So, uh, two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1010" target="_blank">00:16:50.380</a></span> | <span class="t">One is, um, if you're just using SFT on this data, what's the difference between this and regular SFT?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1016" target="_blank">00:16:56.220</a></span> | <span class="t">This is just regular SFT. Oh, yeah. Oh, okay. So then how is regular SFT able to make the models like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1023" target="_blank">00:17:03.260</a></span> | <span class="t">think longer? Because I thought for the reason models, they have like a thinking block and they think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1028" target="_blank">00:17:08.140</a></span> | <span class="t">you know, hours and minutes. Exactly. So how do you, how do you, how does SFT make it think for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1033" target="_blank">00:17:13.100</a></span> | <span class="t">hours? So you're, you're doing supervised fine tuning on the questions and the answers also contain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1039" target="_blank">00:17:19.100</a></span> | <span class="t">the thinking. So the model learns to use its context window and produce these long thinking traces. So it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1045" target="_blank">00:17:25.180</a></span> | <span class="t">it can do this. People call SFT imitation. Um, but it, it can learn to learn this format in the same way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1051" target="_blank">00:17:31.980</a></span> | <span class="t">Yeah. Thanks. All right. We'll take one from this side. Um, great presentation, Ryan. Uh, one question. Uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1059" target="_blank">00:17:39.340</a></span> | <span class="t">why do you think, um, a smaller model like when 32B was a better teacher than a deep seek R1? What was your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1067" target="_blank">00:17:47.340</a></span> | <span class="t">insight in figuring out that like a good professor makes a bad lecturer? Yeah, that's a great question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1073" target="_blank">00:17:53.420</a></span> | <span class="t">Um, I think this is saying we need to investigate more, but you can see that, uh, when you look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1078" target="_blank">00:17:58.940</a></span> | <span class="t">charts of the length of reasoning traces, you can see the distributions are different. So, uh, it might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1084" target="_blank">00:18:04.940</a></span> | <span class="t">be the case that you're using more of your context window, using more tokens, more steps. It also might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1089" target="_blank">00:18:09.180</a></span> | <span class="t">be the case that you just have a better formatted response, better output. Um, this is like in another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1096" target="_blank">00:18:16.060</a></span> | <span class="t">great open research, research question. Interesting. I'll also say on this point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1099" target="_blank">00:18:19.500</a></span> | <span class="t">we also tried Claude as a teacher, which is like a very, as a good, strong model. And it was just a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1104" target="_blank">00:18:24.060</a></span> | <span class="t">terrible teacher. Um, so there's the, it, it, it, yeah, it's interesting what can, what actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1109" target="_blank">00:18:29.180</a></span> | <span class="t">creates a good teacher. Yeah. All right. We'll take one more very brief question from this side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1113" target="_blank">00:18:33.900</a></span> | <span class="t">And then those of you still waiting on questions, um, after, uh, after we have closed this up, it's warming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1119" target="_blank">00:18:39.740</a></span> | <span class="t">So, uh, great talk around. Um, we're doing similar kind of thing, but I just had a question. Do you guys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1124" target="_blank">00:18:44.780</a></span> | <span class="t">have any like pattern map as to in the reasoning chain of thought when things don't work at what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1131" target="_blank">00:18:51.260</a></span> | <span class="t">level, you know, in the evil, do you find out that things are not working or it's not reasoning correctly?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1137" target="_blank">00:18:57.580</a></span> | <span class="t">Is there a pattern map or something that you have in your open source?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1140" target="_blank">00:19:00.220</a></span> | <span class="t">Sorry, I didn't catch that. Is there a, so if there are five steps of reasoning to reach a final conclusion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1146" target="_blank">00:19:06.220</a></span> | <span class="t">uh, at what step does the reasoning go awry?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1148" target="_blank">00:19:08.700</a></span> | <span class="t">Yeah, this is, this is a great question. We don't do this fine grained analysis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1152" target="_blank">00:19:12.620</a></span> | <span class="t">but there is a ton in the literature about this, um, where, yeah, there's a sort of critical step where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1158" target="_blank">00:19:18.140</a></span> | <span class="t">it gets, gets things wrong. Um, there, we did like the simplest thing possible, right? You could also go in and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1164" target="_blank">00:19:24.220</a></span> | <span class="t">try to do more complicated things. Um, at evaluation time where you're doing interventions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1170" target="_blank">00:19:30.540</a></span> | <span class="t">to, uh, maybe detect steps that have gone awry and, and, and change, or you can do this in the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1177" target="_blank">00:19:37.340</a></span> | <span class="t">when you're creating the data set. So you could potentially rewrite things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1180" target="_blank">00:19:40.300</a></span> | <span class="t">but everything that we tried in terms of like messing with the reasoning trace, it wasn't helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1185" target="_blank">00:19:45.500</a></span> | <span class="t">Um, so yeah, I think there's still more to explore there. There's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=liG97YXaTSA&t=1189" target="_blank">00:19:49.980</a></span> | <span class="t">this is really just the start of everything in reasoning.</span></div></div></body></html>