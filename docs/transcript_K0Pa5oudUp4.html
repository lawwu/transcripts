<html><head><title>AI Nationalization is Inevitable – Leopold Aschenbrenner</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>AI Nationalization is Inevitable – Leopold Aschenbrenner</h2><a href="https://www.youtube.com/watch?v=K0Pa5oudUp4" target="_blank"><img src="https://i.ytimg.com/vi/K0Pa5oudUp4/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Transcript</h3><div class='max-width'><p>I wish the thing we use the ASI for is to cure the diseases and do all the good in the world. But it is my prediction that in the endgame, what will be at stake will not just be cool products, but whether liberal democracy survives, whether the CCP survives, what the world order for the next century will be.</p><p>And when that is at stake, forces will be activated that are way beyond what we're talking about now. And in this crazy race at the end, the national security implications will be the most important. Sort of like World War II, it's like, yeah, nuclear energy had its day. But in the initial period when this technology was first discovered, you had to stabilize the situation, you had to get nukes, you had to do it right.</p><p>And then the civilian applications had their day. I think people talk about AGI, and they're always just talking about the private AI labs. And I think I just really want to challenge that assumption. It just seems pretty likely to me, as we've talked about, for reasons we've talked about, that the national security state is going to get involved.</p><p>And I think there's a lot of ways this could look like. Is it like nationalization? Is it a public-private partnership? Is it a kind of defense contractor-like relationship? Is it a sort of government project that suits up all the people? And so there's a spectrum there. But I think people are just vastly underrating the chances of this more or less looking like a government project.</p><p>When we have literal superintelligence on our cluster, and you have a billion superintelligence scientists, and they can hack everything, they can Stuxnet the Chinese data centers, they're starting to build the robo-armies, you really think they'll be a private company? And the government would be like, "Oh my god, what is going on?" Even backing up, why do we want to win against China?</p><p>We want to win against China because we don't want a top-down authoritarian system to win. Now, if the way to beat that is that the most important technology that humanity will have has to be controlled by a top-down government, what was the point? So let's run our cards with privatization.</p><p>That's the way we get to the classic liberal market-based system we want for the ESIs. Yeah. All right. So a lot to talk about here. Maybe I'll start a bit about actually looking at what the private world would look like. And I think this is part of where the "there's no alternative" comes from.</p><p>And then let's look at what the government project looks like, what checks and balances look like, and so on. All right. Private world. First of all, a lot of people right now talk about open source. And I think there's this misconception that AGI development is going to be like, "Oh, it's going to be some beautiful decentralized thing and some giddy community of coders who gets to collaborate on it." That's not how it's going to look like.</p><p>A hundred-billion-dollar, trillion-dollar cluster, it's not going to be that many people that have it. The algorithms, it's like right now, open source is kind of good because people just use the stuff that was published. And so basically, the algorithms were published. Or as Mistral, they just kind of leave DeepMind and take all the secrets with them and they just kind of replicate it.</p><p>But that's not going to continue to be in the case. And so, the open source alternative... Also, people say stuff like, "1026 flops, it'll be in my phone." No, it won't. It's like Moore's Law is really slow. AI chips are getting better. But the hundred-billion-dollar computer will not cost a thousand dollars within your lifetime or whatever, aside from AI.</p><p>So anyway, it's going to be two or three big players on the private world. And so look, a few things. So first of all, you talk about the enormous power that superintelligence will have and that the government will have. I think it's pretty plausible that the alternative world is that one AI company has that power.</p><p>And specifically, if we're talking about lead, it's like, "What? No, no, no. OpenAI has a six-month lead." So then you're talking about basically the most powerful weapon ever, and you're kind of making this radical bet on a private company CEO as the benevolent dictator. No, no. Not necessarily. Any other thing that's privatized, we don't count on that being benevolent.</p><p>Look, think of, for example, somebody who manufactures industrial fertilizer. The person with this factory, if they went back to an ancient civilization, they could blow up Rome. They could probably blow up Washington, D.C. And I think people underrate that there are actually a lot of private actors who have the ability to...</p><p>There's a lot of people who control the water supply or whatever, and we can count on cooperation and market-based incentives to basically keep a balance of power. I gather things are proceeding really fast, but we have a lot of historical evidence that this is the thing that works best.</p><p>I mean, what do we do with nukes, right? The way we keep the nukes in check is not like a sort of beefed-up Second Amendment, where each state has their own little nuclear arsenal, and Dario and Sam have their own little nuclear arsenal. No, no. It's institutions. It's constitutions.</p><p>It's laws. It's courts. I'm not sure that this sort of balance of power analogy holds. In fact, the government having the biggest guns was sort of an enormous civilizational achievement, like Landfrieden in the Holy Roman Empire. If somebody from the town over committed a crime on you, you didn't start a big battle between the two towns.</p><p>No, you take it to a court of the Holy Roman Empire, and they would decide. It's a big achievement. Now, the thing about the industrial fertilizer, I think the key difference is speed and offense-defense balance issues, right? It's like 20th century, and 10 years, and a few years. That is an incredibly scary period, and it is incredibly scary because you're going through just this enormous array of destructive technology and this enormous amount of basically military advance.</p><p>You would have gone from bayonets and horses to tank armies and fighter jets in a couple of years, and then to nukes and ICBMs just in a matter of years. It is that speed that creates-- I think, basically, the way I think about it is there's going to be this initial just incredibly volatile, incredibly dangerous period, and somehow, we have to make it through that.</p><p>That's going to be incredibly challenging. That's where you need the government project. If you can make it through that, then you go to, now, the situation has been stabilized. We don't face this imminent national security threat. It's like, yes, there were WMDs that came along the way, but either we've managed to have a stable offense-defense balance.</p><p>I think bioweapons initially are a huge issue. An attacker can just create 1,000 different synthetic viruses and spread them, and it's going to be really hard for you to make a defense against each. But maybe at some point, you figure out the universal defense against every possible virus, and then you're in a stable situation again on the offense-defense balance.</p><p>Or you do the thing you do with planes, where there's certain capabilities that the private sector isn't allowed to have, and you've figured out what's going on, restrict those, and then you can let the civilian uses run free. I'm skeptical of this because there's-- Sorry. The other important thing is, I talked about this, maybe it's one company with all this power.</p><p>I think it is unprecedented because it's like the industrial fertilizer guy cannot overthrow the US government. I think it's quite plausible that the AI company with superintelligence can overthrow the US government. But there'll be multiple AI companies, right? And I buy that one of them could be ahead. So it's not obvious that it'll be multiple.</p><p>I think it's, again, if there's a six-month lead, maybe there's two or three. I agree. But if there's two or three, then what you have is just a crazy race between these two or three companies. It's like, whatever, Demis and Sam, they're just like, "I don't want to let the other one win." And they're both developing their nuclear arsenals and the robot.</p><p>It's just like, also, come on, the government is not going to let these people-- are they going to let-- is Dario going to be the one developing the super hacking Stuxnet and deploying against the Chinese data center? The other issue, though, is it won't just-- if it's two or three, it won't just be two or three.</p><p>There'll be two or three, and it'll be China and Russia and North Korea. Because in the private lab world, there is no way they'll have security that is good enough. Okay, I agree that I'm worried if, let's say, Amr Dario have a one-year lead on ASI in that world, then I'm concerned about this being privatized.</p><p>But in that exact same world, I'm very concerned about Donald Trump having the capability. And potentially, if we're living in a world where the takeoff is slower than you anticipate, in that world, I'm like, very much, I want the private companies. So in no part of this matrix, this is obviously true that the government-led project is better than the private project.</p><p>Let's talk about the government project a little bit and checks and balances. In some sense, I think my argument is a sort of Birkin argument, which is like, American checks and balances have held for over 200 years and through crazy technological revolutions. The US military could kill every civilian in the United States.</p><p>But you're going to make that argument, the private-public balance of power has held for hundreds of years, and then like-- Corporate-- but yeah, why has it held? Because the government has the biggest guns. And has never before has a single CEO or a random nonprofit board had the ability to launch nukes.</p><p>The United States National Security State is going to be intimately involved with this. And this will-- the labs, whether-- and I think, again, the government-- a lot of what I think is the government project looks like it is basically a joint venture between the cloud providers, between some of the labs and the government.</p><p>And so I think there is no world in which the government isn't intimately involved in this crazy period. At the very least, basically, the intelligence agencies need to be running security for these labs. So they're already kind of like-- they're controlling everything. They're controlling access to everything. Then they're going to be like-- probably, again, if we're in this really volatile international situation, a lot of the initial applications, it'll suck.</p><p>It's not what I want to use ASI for. We'll be trying to somehow stabilize this crazy situation. Somehow, we need to prevent proliferation of some crazy new WMDs and the undermining of mutually assured destruction to North Korea and Russia and China. And so I think-- I basically think your world-- I think there's much more spectrum than you're acknowledging here.</p><p>And I think, basically, the world in which it's private labs is extremely heavy government involvement. And really, what we're debating is what form of government project. But it is going to look much more like the national security state than anything it does look like, like a startup, as it is right now.</p><p>Look, I think something like that makes sense. I would be-- if it's like the Manhattan Project, then I'm very worried, where it's like this is part of the US military, where if it's more like, "Listen, you've got to talk to Jake Sullivan before you run the next training run." It's like Lockheed Martin, Skunk Word's part of the US military.</p><p>It's like, they call the shots. Yeah, I don't think that's great. I think that's bad. I think it would be bad if that happened with ASI. What is the alternative? Okay, so it's closer to my end of the spectrum where, yeah, you do have to talk to Jake Sullivan before you can launch the next training cluster.</p><p>Yeah. But there's many companies who are still going for it. Yeah. And the government will be intimately involved in the security. But the AI is still broadly deployed, and alignment works in the sense that you can make sure that it's not-- the system level prompt is like, you can't help people make bioweapons or something.</p><p>Sure, sure, sure. I mean, I expect the AIs to be broadly deployed. I mean, first of all-- Even if it's a government project? Yeah, I mean, look, I think, first of all, like, I think the Meadows of the world, you know, open sourcing their AIs, you know, that are two years behind or whatever, yeah, super valuable role.</p><p>They're going to like, you know, and so there's going to be some question of like, either the offense-defense balance is fine. And so like, even if they open source two-year-old AIs, it's fine. Or it's like, there's some restrictions on the most extreme dual-use capabilities. Like, you know, you don't let private companies sell kind of crazy weapons.</p><p>And that's great, and that will help with the diffusion. I mean, I think the sort of alignment angle during the intelligence explosion, it's going to, you know, it's not a process of like, years of bureaucracy, and then you can kind of write some standards. I think it looks much more like basically a war.</p><p>And like, you have a fog of war. It's like, look, it's like, is it safe to do the next oom? You know, and it's like, ah, you know, like, you know, we're like three ooms into the intelligence explosion. We don't really understand what's going on anymore. You know, the, you know, like a bunch of our like, generalization scaling curves are like, kind of looking not great.</p><p>You know, some of our like, automated AI researchers that are doing alignment are saying it's fine, but we don't quite trust them. In this test, you know, the like, the AIs started doing naughty things, and ah, but then we like, hammered it out, and then it was fine. And like, ah, should we, should we go ahead?</p><p>Should we take, you know, another six months? Also, by the way, you know, like, China just stole the weights, or we, you know, they're about to like, deploy the robo army. Like, what do we do? I think it's this, I think it is this crazy situation, um, and um, you know, basically, you, you are relying much more on kind of like, a sane chain of command than you are on sort of some like, you know, deliberative regulatory scheme.</p><p>I wish you had, you were able to do the deliberative regulatory scheme. And this is the thing about the private companies too. I don't think, you know, they all claim they're going to do safety, but I think it's really rough when you're in the commercial race and they're startups, you know, and startups, startups are startups.</p><p>You know, I think they're not fit to handle WMDs.</p></div></div></body></html>