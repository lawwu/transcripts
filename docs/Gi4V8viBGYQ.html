<html><head><title>How to defend your sites from AI bots — David Mytton, Arcjet</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>How to defend your sites from AI bots — David Mytton, Arcjet</h2><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ"><img src="https://i.ytimg.com/vi_webp/Gi4V8viBGYQ/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./Gi4V8viBGYQ.html">Whisper Transcript</a> | <a href="./transcript_Gi4V8viBGYQ.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=0" target="_blank">00:00:00.040</a></span> | <span class="t">Hi everyone. So my name is David. I'm the founder of Artjet. We provide a security SDK for developers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=21" target="_blank">00:00:21.780</a></span> | <span class="t">So everything I'm going to be talking to you about today is what we've been building for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=25" target="_blank">00:00:25.800</a></span> | <span class="t">the last few years, but how you can do it yourself. So if you haven't had bots visiting your website</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=33" target="_blank">00:00:33.620</a></span> | <span class="t">and felt the pain, then you might be thinking, well, is this really a problem? Well, as you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=38" target="_blank">00:00:38.460</a></span> | <span class="t">just heard in the introduction, almost 50% of web traffic today is automated clients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=45" target="_blank">00:00:45.600</a></span> | <span class="t">And that varies depending on the industry. In gaming, that's almost 60% of all traffic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=50" target="_blank">00:00:50.100</a></span> | <span class="t">is automated. And that's before the agent revolution has really kicked off. This isn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=56" target="_blank">00:00:56.380</a></span> | <span class="t">a new problem. It's been going on since the invention of the internet. And there are bots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=62" target="_blank">00:01:02.160</a></span> | <span class="t">that you want to visit your website, like Googlebot, but there are also a lot of malicious crawlers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=68" target="_blank">00:01:08.140</a></span> | <span class="t">And this causes a problem. The first incident you might experience is around expensive requests.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=76" target="_blank">00:01:16.100</a></span> | <span class="t">So think through what happens on your website. If it's a static site, then maybe it's not doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=81" target="_blank">00:01:21.020</a></span> | <span class="t">much on your infrastructure. But if you're generating any content from a database or you're reading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=86" target="_blank">00:01:26.280</a></span> | <span class="t">some dynamic content in some way, then each request is going to cost something, particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=91" target="_blank">00:01:31.920</a></span> | <span class="t">if you're using a serverless platform, paying per request. If you have huge numbers of automated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=96" target="_blank">00:01:36.720</a></span> | <span class="t">clients coming in, making requests, making hundreds of thousands of requests, then this starts to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=101" target="_blank">00:01:41.320</a></span> | <span class="t">build up as a cost problem, and also being able to deal with that on your infrastructure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=108" target="_blank">00:01:48.700</a></span> | <span class="t">These clients can also be requesting all the assets. So downloading large files, that's going to start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=113" target="_blank">00:01:53.240</a></span> | <span class="t">eating into your bandwidth costs and eating into the available resources you have to serve legitimate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=119" target="_blank">00:01:59.040</a></span> | <span class="t">users on your site. This can show up as a denial of service attack. So your service just might not be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=126" target="_blank">00:02:06.440</a></span> | <span class="t">available to others, and even the largest website doesn't have infinite resources. Serverless means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=133" target="_blank">00:02:13.960</a></span> | <span class="t">that you don't have to think about that for the most part, but where you're actually handling it is part of the billing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=139" target="_blank">00:02:19.560</a></span> | <span class="t">This has been a problem for decades. And so the real question is, well, is AI making this worse?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=149" target="_blank">00:02:29.400</a></span> | <span class="t">And we see complaints in the media, websites talking about the traffic that they're getting, and there's just an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=156" target="_blank">00:02:36.280</a></span> | <span class="t">automatic assumption that this is AI. And on the face of it, there's no real evidence that that is the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=161" target="_blank">00:02:41.720</a></span> | <span class="t">But when you start looking into the details about the kind of requests that these sites are seeing, then AI is making it worse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=168" target="_blank">00:02:48.920</a></span> | <span class="t">So, for instance, Diaspora, which is an online open source community, they saw that 24% of their traffic was from GPTBot,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=178" target="_blank">00:02:58.440</a></span> | <span class="t">which is OpenAI's crawler. And then ReadTheDocs, which is an online documentation platform for code projects.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=188" target="_blank">00:03:08.440</a></span> | <span class="t">And they found that by blocking all AI crawlers, they reduce their bandwidth from 800 gigabytes a day to 200</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=195" target="_blank">00:03:15.160</a></span> | <span class="t">gigabytes a day. And even Wikipedia is having this problem. They're spending up to 35% of their traffic just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=202" target="_blank">00:03:22.840</a></span> | <span class="t">serving automated clients. And they're seeing this increasing significantly and attributing that to AI crawlers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=209" target="_blank">00:03:29.480</a></span> | <span class="t">So AI is making this worse. Scrapers are coming onto sites and pulling down the content,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=216" target="_blank">00:03:36.280</a></span> | <span class="t">and they're not behaving nicely. They're not doing it in a gradual way. And they're making hundreds of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=221" target="_blank">00:03:41.400</a></span> | <span class="t">thousands of requests and just pulling down content without following the rules.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=226" target="_blank">00:03:46.040</a></span> | <span class="t">In the old days, we had this idea of good bots and bad bots. And the challenge was always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=233" target="_blank">00:03:53.320</a></span> | <span class="t">distinguishing between them. If you want your website to show up in a search index like Google,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=239" target="_blank">00:03:59.000</a></span> | <span class="t">then Google has to know about your site, has to visit and understand your site. But you get a benefit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=243" target="_blank">00:04:03.880</a></span> | <span class="t">from that because you're going to appear in the search index and you're going to get traffic as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=247" target="_blank">00:04:07.720</a></span> | <span class="t">result. And so most people consider Google to be a good bot. And then there's the bad bots,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=254" target="_blank">00:04:14.040</a></span> | <span class="t">which are obviously bad. Scrapers come into your site, downloading all the images, downloading all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=258" target="_blank">00:04:18.120</a></span> | <span class="t">content, downloading files. It was very easy to understand that those are the bad bots. But in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=264" target="_blank">00:04:24.440</a></span> | <span class="t">middle, we've got these AI crawlers. And sometimes they're good, sometimes they're bad. And it depends on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=270" target="_blank">00:04:30.040</a></span> | <span class="t">on sometimes your philosophical approach to AI, but also what you want from your website. Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=276" target="_blank">00:04:36.600</a></span> | <span class="t">the first kinds of AI bots we were seeing were for training, just to build up the models. And in theory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=282" target="_blank">00:04:42.920</a></span> | <span class="t">there's no benefit to the site owner for that because it's just being built into the model. You're not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=286" target="_blank">00:04:46.920</a></span> | <span class="t">necessarily getting any traffic. But things have started to change with multiple bots coming from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=293" target="_blank">00:04:53.560</a></span> | <span class="t">different AI providers. So for instance, with OpenAI, they have at least four different types of bots.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=299" target="_blank">00:04:59.640</a></span> | <span class="t">So the first one is the OpenAI search bot. This is kind of classic Google bot type crawler, which will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=307" target="_blank">00:05:07.560</a></span> | <span class="t">come to your site. It will understand what's going on and it will index it so that when someone makes a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=312" target="_blank">00:05:12.440</a></span> | <span class="t">query into ChatGPT using the search functionality, you show up in OpenAI's index. Now, in most cases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=319" target="_blank">00:05:19.160</a></span> | <span class="t">you're going to want that. It's going to do the same thing as Google. You're going to appear in a search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=322" target="_blank">00:05:22.840</a></span> | <span class="t">index. You're probably going to get citations. And that wasn't the case at the very beginning, but now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=328" target="_blank">00:05:28.440</a></span> | <span class="t">you're getting citations. And this is becoming a real source of traffic for sites and for services. People</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=334" target="_blank">00:05:34.440</a></span> | <span class="t">are getting signups as a result. And so there's a win-win. It's the same as the old Google crawlers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=339" target="_blank">00:05:39.640</a></span> | <span class="t">Then there's ChatGPT user. And this is a little more nuanced. It's where ChatGPT may show up to your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=347" target="_blank">00:05:47.560</a></span> | <span class="t">website as a result of a real-time query that a user is making. Maybe you drop the actual URL into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=353" target="_blank">00:05:53.800</a></span> | <span class="t">the chat and ask it to summarize the content. Or it's a documentation link and you want to understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=358" target="_blank">00:05:58.840</a></span> | <span class="t">how to implement something and it's going out and getting that content. It's not used for training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=363" target="_blank">00:06:03.480</a></span> | <span class="t">but it may not cite the response. But if you've given it the URL, then perhaps you're a legitimate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=370" target="_blank">00:06:10.760</a></span> | <span class="t">user. And so maybe you do want that because it's actually your users making use of LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=375" target="_blank">00:06:15.720</a></span> | <span class="t">And then there's GPT bot, which is the one that we saw was taking up a huge amount of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=380" target="_blank">00:06:20.440</a></span> | <span class="t">traffic on Wikipedia and Diaspora. And this is the original one that is part of the training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=386" target="_blank">00:06:26.920</a></span> | <span class="t">It doesn't benefit you directly. You're being brought into the model. And there's often no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=392" target="_blank">00:06:32.520</a></span> | <span class="t">citation as a result. These are kind of the three crawler bots that you might see on your site.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=398" target="_blank">00:06:38.360</a></span> | <span class="t">And then what we're seeing more of now is the computer use operator type bots, which are acting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=404" target="_blank">00:06:44.840</a></span> | <span class="t">on behalf of a real person, possibly with a web browser that's running in a VM that is taking an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=411" target="_blank">00:06:51.240</a></span> | <span class="t">action as an agent, an autonomous agent. And this becomes challenging to understand, well, do you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=416" target="_blank">00:06:56.280</a></span> | <span class="t">that or not? Maybe it's a legitimate use case. Maybe the agent is doing triage of your inbox. Maybe Google</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=422" target="_blank">00:07:02.360</a></span> | <span class="t">would want that if it's Gmail. But if you've asked an agent to go out and buy 500 concert tickets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=428" target="_blank">00:07:08.200</a></span> | <span class="t">so you can then go and sell them for a profit, that's probably something you don't want to allow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=433" target="_blank">00:07:13.160</a></span> | <span class="t">And so understanding being able to detect these is really challenging. The open AI crawlers identify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=438" target="_blank">00:07:18.760</a></span> | <span class="t">themselves as such. You can verify that. And so you can allow or block them. But something like operator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=444" target="_blank">00:07:24.920</a></span> | <span class="t">just shows up as a Chrome browser. And it's much more challenging to understand and detect that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=450" target="_blank">00:07:30.440</a></span> | <span class="t">So let's walk through some of the defenses that you can implement and to decide as a site owner how you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=458" target="_blank">00:07:38.280</a></span> | <span class="t">can control the kind of traffic that's coming to your site. So the first one of these is it's not really a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=463" target="_blank">00:07:43.560</a></span> | <span class="t">defense because it's entirely voluntary. Everyone's probably heard of robots.txt. It's how you can describe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=469" target="_blank">00:07:49.960</a></span> | <span class="t">the structure of your website and tell different crawlers what you want them to do. You can allow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=475" target="_blank">00:07:55.240</a></span> | <span class="t">or disallow. You can control particular crawlers. And this gives you a good understanding of your own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=482" target="_blank">00:08:02.120</a></span> | <span class="t">site to think through the steps that you want to take to allow or disallow. But it's entirely voluntary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=487" target="_blank">00:08:07.080</a></span> | <span class="t">Crawlers don't have to follow it, but the good ones will. Google bot will follow this, as will all the search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=493" target="_blank">00:08:13.160</a></span> | <span class="t">crawlers. Open AI claims to follow it and does for the most part as well. But for the types of bots that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=499" target="_blank">00:08:19.160</a></span> | <span class="t">causing these problems, they're not following this. And in some cases, they're actually using this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=504" target="_blank">00:08:24.360</a></span> | <span class="t">to find pages on your site that you've disallowed other bots to go to and deliberately going out and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=509" target="_blank">00:08:29.240</a></span> | <span class="t">getting that content. Even so, this is a good place to start because it helps you start to think through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=514" target="_blank">00:08:34.840</a></span> | <span class="t">what you want different bots to be doing on your site.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=517" target="_blank">00:08:37.800</a></span> | <span class="t">Every request that comes into your site is going to identify itself. This is a required HTTP header</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=527" target="_blank">00:08:47.000</a></span> | <span class="t">and it's just a string. It is a name that the crawler is going to give itself. And you'll see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=532" target="_blank">00:08:52.840</a></span> | <span class="t">that in your request logs. It's just a string because any client can set whatever they like for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=539" target="_blank">00:08:59.320</a></span> | <span class="t">this. But it's surprising how many will actually just tell you who they are. And you can use open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=545" target="_blank">00:09:05.000</a></span> | <span class="t">source libraries to detect this and create rules around it. At Artjet, we've got an open source project with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=552" target="_blank">00:09:12.200</a></span> | <span class="t">several thousand different user agents that you can download and use to build your own rules to identify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=558" target="_blank">00:09:18.040</a></span> | <span class="t">who you want to access your site. But it's just a string in a HTTP header and you can set it to whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=564" target="_blank">00:09:24.280</a></span> | <span class="t">you want. And so the bad bots will just change this. They'll pretend to be Google or they'll pretend to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=569" target="_blank">00:09:29.880</a></span> | <span class="t">Chrome. And so it's not always a good signal about who's actually visiting your site. And so the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=577" target="_blank">00:09:37.000</a></span> | <span class="t">thing you can do is to verify that. If a request is made to your site and it claims to be Apple's crawler,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=585" target="_blank">00:09:45.080</a></span> | <span class="t">Bing, Google, OpenAI, all of these services support verification. So you can look at the source IP address</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=594" target="_blank">00:09:54.600</a></span> | <span class="t">and you can query those services using a reverse DNS lookup to check whether it is actually who it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=599" target="_blank">00:09:59.880</a></span> | <span class="t">claims to be. So if you see a request coming from Google, you can ask Google, is this actually Google?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=606" target="_blank">00:10:06.040</a></span> | <span class="t">And they'll give you a response back saying whether it is or not. And this makes it quite straightforward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=612" target="_blank">00:10:12.040</a></span> | <span class="t">to use the combination of the user agent string plus IP verification to check whether it is the good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=618" target="_blank">00:10:18.680</a></span> | <span class="t">bots are visiting your site and to set up some simple rules to allow those crawlers that you actually want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=623" target="_blank">00:10:23.560</a></span> | <span class="t">to be on the site. Things start to get a bit more complicated if those signals don't provide you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=631" target="_blank">00:10:31.480</a></span> | <span class="t">with sufficient information. Bot detection is not 100 percent accurate. And so you have to build up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=637" target="_blank">00:10:37.720</a></span> | <span class="t">these layers. And so the next thing you can do is looking at IP addresses. The idea is to build up a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=645" target="_blank">00:10:45.240</a></span> | <span class="t">pattern to understand what is normal from each IP address. And not just a single IP address, but the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=652" target="_blank">00:10:52.520</a></span> | <span class="t">different IP address ranges, how they associate with different networks and different network operators,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=658" target="_blank">00:10:58.120</a></span> | <span class="t">whether the request is coming from a data center or not, and the country level information. And you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=664" target="_blank">00:11:04.440</a></span> | <span class="t">get this from various databases. You have to pay for access to most of them, but there are also some free</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=670" target="_blank">00:11:10.120</a></span> | <span class="t">APIs you can use to query the metadata associated with a particular IP address. Maximine and IP Info are two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=677" target="_blank">00:11:17.800</a></span> | <span class="t">more popular ones. And you want to be looking at things like, well, where's the traffic coming from,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=682" target="_blank">00:11:22.760</a></span> | <span class="t">and what's the association with the network? Is this coming from a VPN or a proxy? Is it a residential or a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=689" target="_blank">00:11:29.480</a></span> | <span class="t">mobile IP address? And last year, 12 percent of all bot traffic that hit the Cloudflare network was from the AWS</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=699" target="_blank">00:11:39.400</a></span> | <span class="t">network. And so you can start to ask yourself, well, are the normal users of our site application going to come from a data center?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=707" target="_blank">00:11:47.880</a></span> | <span class="t">Maybe if you're allowing crawlers on your site, then that's expected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=713" target="_blank">00:11:53.880</a></span> | <span class="t">But if you have a signup form that you're expecting only humans to submit, then it's unlikely that a request that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=720" target="_blank">00:12:00.440</a></span> | <span class="t">coming from a data center IP address is going to be traffic that you want to accept.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=727" target="_blank">00:12:07.000</a></span> | <span class="t">The challenge we're looking at geodata, like blocking a single country, for instance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=731" target="_blank">00:12:11.000</a></span> | <span class="t">is that the geodata is notoriously inaccurate and has become more inaccurate over time as people are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=737" target="_blank">00:12:17.640</a></span> | <span class="t">using satellite and cell phone connectivity, 5G, because the IP address will be geolocated to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=744" target="_blank">00:12:24.920</a></span> | <span class="t">owner of the IP rather than necessarily the user of it. And also, even when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=750" target="_blank">00:12:30.600</a></span> | <span class="t">the database is saying that the IP address is coming from a residential network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=755" target="_blank">00:12:35.560</a></span> | <span class="t">there are proxy services that you can just buy access to which will route your traffic through those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=761" target="_blank">00:12:41.560</a></span> | <span class="t">residential networks to appear like it's coming from a home ISP or a mobile device.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=767" target="_blank">00:12:47.160</a></span> | <span class="t">So you can't always trust these, and you have to build up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=770" target="_blank">00:12:50.840</a></span> | <span class="t">signals and build your own database to understand where this traffic is coming from and what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=775" target="_blank">00:12:55.240</a></span> | <span class="t">the likelihood is that it's an automated client.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=777" target="_blank">00:12:57.320</a></span> | <span class="t">Captures are the standard thing that we've been using now for decades to try and distinguish between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=787" target="_blank">00:13:07.880</a></span> | <span class="t">humans and automated clients, solving puzzles and moving things around on the screen. But it's becoming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=794" target="_blank">00:13:14.280</a></span> | <span class="t">increasingly easy for AI to solve those, putting them into an LM or downloading the audio version,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=800" target="_blank">00:13:20.760</a></span> | <span class="t">and transcribing it, can be done in just a couple of seconds, and it's trivial and cheap to breach these kinds of defenses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=809" target="_blank">00:13:29.160</a></span> | <span class="t">There are newer approaches to this. Proof of work, which has come from the crypto side of things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=818" target="_blank">00:13:38.200</a></span> | <span class="t">means that you require a computer to do a certain number of calculations and provide the answer to a puzzle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=827" target="_blank">00:13:47.080</a></span> | <span class="t">before they can access the resource. And this usually takes a certain amount of time. It costs CPU time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=833" target="_blank">00:13:53.240</a></span> | <span class="t">And on an individual basis, on your laptop or on your phone, it might take a second or two to calculate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=839" target="_blank">00:13:59.160</a></span> | <span class="t">it, and it makes no real difference to an individual. But if you have a crawler that's going to tens of thousands</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=845" target="_blank">00:14:05.160</a></span> | <span class="t">or millions of websites and is having to solve this puzzle every single time, it becomes very expensive to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=851" target="_blank">00:14:11.800</a></span> | <span class="t">And so deploying these proof of work options on your website can be a way to prevent those crawlers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=857" target="_blank">00:14:17.880</a></span> | <span class="t">But then it becomes a question of incentives. So if you're crawling millions of websites, then maybe that is a good defense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=866" target="_blank">00:14:26.520</a></span> | <span class="t">But if we go back to that ticket example, if it costs someone a couple of dollars to solve a capture or to solve a proof of work,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=874" target="_blank">00:14:34.360</a></span> | <span class="t">but they're then going to sell a ticket for $200 or $300, the profit is still there. And so these may not even be a defense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=882" target="_blank">00:14:42.360</a></span> | <span class="t">against certain types of attacks. You can scale the difficulty. So if you bring in all these different signals and see that something is coming from an unverified IP address</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=893" target="_blank">00:14:53.320</a></span> | <span class="t">and has suspicious characteristics, then maybe you could give them a harder puzzle. But then you start to have accessibility problems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=901" target="_blank">00:15:01.960</a></span> | <span class="t">and I'm sure we've all seen those really annoying captures that you can't solve and you have to keep refreshing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=906" target="_blank">00:15:06.920</a></span> | <span class="t">That becomes a problem as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=909" target="_blank">00:15:09.160</a></span> | <span class="t">There are a couple of interesting open source projects that implement these. Anubis is a good one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=917" target="_blank">00:15:17.000</a></span> | <span class="t">GoAway and Nepenthes. These are all proxies that you can install on the Kubernetes cluster or put them in front of your application.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=924" target="_blank">00:15:24.280</a></span> | <span class="t">You can run it yourself and it will implement these proof of work problems and put it in front of the users that it thinks are suspicious.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=930" target="_blank">00:15:30.600</a></span> | <span class="t">And there are also some emerging standards around introducing signatures into requests.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=939" target="_blank">00:15:39.640</a></span> | <span class="t">Because what we're trying to do is to prove that a particular client is who they say it is and is who you want to be on the website.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=947" target="_blank">00:15:47.160</a></span> | <span class="t">Now, Cloudflare has suggested this idea of HTTP message signatures for automated clients where every request will include a cryptographic signature,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=957" target="_blank">00:15:57.240</a></span> | <span class="t">which you can then verify very quickly. And then you can understand which client is coming to your site.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=964" target="_blank">00:16:04.280</a></span> | <span class="t">It's only just been announced a couple of weeks ago, so it's still being developed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=967" target="_blank">00:16:07.960</a></span> | <span class="t">There's some questions around whether it's any better than just verifying the IP address, but it's a way of verifying automated clients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=974" target="_blank">00:16:14.840</a></span> | <span class="t">And then a couple of years ago, Apple announced private access tokens and what they called a privacy pass,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=981" target="_blank">00:16:21.320</a></span> | <span class="t">which allowed website owners to verify that a request was coming from a browser that was owned by an iCloud subscriber.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=991" target="_blank">00:16:31.320</a></span> | <span class="t">This has been implemented across all Apple devices. And if you're using Safari, this is on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=996" target="_blank">00:16:36.120</a></span> | <span class="t">And it will reduce the number of captures that you might see because you can verify that someone's actually a paying subscriber to iCloud.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1002" target="_blank">00:16:42.920</a></span> | <span class="t">But it's had limited adoption elsewhere. Not many sites are using it. And it's only on the Apple ecosystem, even though it's almost an approved standard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1016" target="_blank">00:16:56.520</a></span> | <span class="t">And then we have to implement fingerprints as well. So fingerprinting is looking at the network requests</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1022" target="_blank">00:17:02.360</a></span> | <span class="t">to generate a hash to be able to identify that client because it's quite trivial to change the IP address that your requests are coming from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1031" target="_blank">00:17:11.400</a></span> | <span class="t">And you'll often see crawlers using banks of tens or hundreds of thousands of different IP addresses,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1037" target="_blank">00:17:17.160</a></span> | <span class="t">particularly with IPv6, which means implementing signatures based just on an IP address isn't sufficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1044" target="_blank">00:17:24.760</a></span> | <span class="t">But the client stays the same. The client characteristics stay the same across multiple requests.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1050" target="_blank">00:17:30.760</a></span> | <span class="t">And you can build up a fingerprint of that. This is the open source JA4 hash, which is based on the TLS fingerprint,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1057" target="_blank">00:17:37.880</a></span> | <span class="t">looking at the network level and looking at the configuration of SSL.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1063" target="_blank">00:17:43.160</a></span> | <span class="t">And then there's a proprietary version on HTTP, which is looking at headers and the different headers that are sent with a client</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1070" target="_blank">00:17:50.440</a></span> | <span class="t">and the characteristics of an HTTP request to build up a fingerprint. And then you can use those fingerprints</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1075" target="_blank">00:17:55.560</a></span> | <span class="t">as part of your block rules. So you could look at all the hundreds of thousands of requests coming from a single fingerprint.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1081" target="_blank">00:18:01.640</a></span> | <span class="t">You could just block that fingerprint, regardless of how many IP addresses it's coming across.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1090" target="_blank">00:18:10.040</a></span> | <span class="t">And then rate limiting is used in conjunction with a fingerprint. Once you can fingerprint the client,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1095" target="_blank">00:18:15.320</a></span> | <span class="t">you can apply quotas or a limit to it. And the key is really important there. You can't just rate limit on an IP address</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1101" target="_blank">00:18:21.480</a></span> | <span class="t">because people have different IPs. It changes all the time. And then for malicious crawlers, they can just change them themselves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1108" target="_blank">00:18:28.040</a></span> | <span class="t">And so keying off user session ID is a good way to do it. If the user is logged in and you want to apply your rate limits,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1115" target="_blank">00:18:35.480</a></span> | <span class="t">or if you've got the fingerprint, the J4 hash, you can implement rate limits on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1122" target="_blank">00:18:42.120</a></span> | <span class="t">So these are the eight defenses. Robots.txt is where you start. It's not where you finish though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1131" target="_blank">00:18:51.720</a></span> | <span class="t">because it's not going to prevent all the bots. It's a voluntary standard. It's where you start because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1136" target="_blank">00:18:56.920</a></span> | <span class="t">it helps with the good bots. At the very least, you need to be looking at user agents. There are various</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1142" target="_blank">00:19:02.680</a></span> | <span class="t">open source options for looking at that and setting up rules, and then verifying that the user agent for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1148" target="_blank">00:19:08.600</a></span> | <span class="t">clients that you actually want on your site are the ones that are actually making the requests.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1153" target="_blank">00:19:13.000</a></span> | <span class="t">That gets you most of the way. For most sites, that will deal with everything you need. But for the more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1159" target="_blank">00:19:19.560</a></span> | <span class="t">popular ones or sites with particularly interesting resources or things that people might want to buy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1167" target="_blank">00:19:27.000</a></span> | <span class="t">lots of numbers of, or they're in restricted quantities, you need to go further looking at IP</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1172" target="_blank">00:19:32.040</a></span> | <span class="t">reputation, setting up proof of work, considering these experimental HTTP signatures, and certainly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1179" target="_blank">00:19:39.000</a></span> | <span class="t">the fingerprint side of things is where most people land in combination with the rate limits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1184" target="_blank">00:19:44.760</a></span> | <span class="t">You can implement all these yourselves in code. That's what we do at Artjet. There's a much more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1190" target="_blank">00:19:50.680</a></span> | <span class="t">detailed write-up of this talk on the blog that I just published earlier today. So if you have a look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1195" target="_blank">00:19:55.480</a></span> | <span class="t">at blog.artjet.com, there's a full write-up of this talk with much more detailed examples. I'm happy to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Gi4V8viBGYQ&t=1201" target="_blank">00:20:01.320</a></span> | <span class="t">answer any questions via email, and we also have a booth down in the expo. Thank you very much.</span></div></div></body></html>