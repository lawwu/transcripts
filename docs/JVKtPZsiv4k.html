<html><head><title>Stanford XCS224U: NLU I Fantastic Language Models and How to Build Them, Part 2 I Spring 2023</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford XCS224U: NLU I Fantastic Language Models and How to Build Them, Part 2 I Spring 2023</h2><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k"><img src="https://i.ytimg.com/vi/JVKtPZsiv4k/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./JVKtPZsiv4k.html">Whisper Transcript</a> | <a href="./transcript_JVKtPZsiv4k.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">All right. Welcome everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=7" target="_blank">00:00:07.400</a></span> | <span class="t">Again, we have a very full day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=9" target="_blank">00:00:09.400</a></span> | <span class="t">The plan is to finish up our review of core information retrieval stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=15" target="_blank">00:00:15.280</a></span> | <span class="t">The focus will be on neural information retrieval,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=18" target="_blank">00:00:18.160</a></span> | <span class="t">where a lot of the action is these days.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=20" target="_blank">00:00:20.840</a></span> | <span class="t">I have then a few datasets to show you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=23" target="_blank">00:00:23.240</a></span> | <span class="t">and then I'm going to turn it over to Sid,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=25" target="_blank">00:00:25.240</a></span> | <span class="t">and Sid is going to help us talk again about how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=28" target="_blank">00:00:28.400</a></span> | <span class="t">build fantastic language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=31" target="_blank">00:00:31.200</a></span> | <span class="t">So let's dive in. We'll start by using our big handout here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=36" target="_blank">00:00:36.520</a></span> | <span class="t">information retrieval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=38" target="_blank">00:00:38.400</a></span> | <span class="t">Right. So here we are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=40" target="_blank">00:00:40.040</a></span> | <span class="t">and we are going to skip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=41" target="_blank">00:00:41.520</a></span> | <span class="t">That's right. I had a couple more metrics that I wanted to show you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=44" target="_blank">00:00:44.760</a></span> | <span class="t">So let's start there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=45" target="_blank">00:00:45.680</a></span> | <span class="t">So last time we talked about how assessment in the space of IR should be multidimensional.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=52" target="_blank">00:00:52.800</a></span> | <span class="t">We've been focused on accuracy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=54" target="_blank">00:00:54.920</a></span> | <span class="t">but I will make amends.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=56" target="_blank">00:00:56.080</a></span> | <span class="t">We are going to circle back and talk about these other dimensions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=59" target="_blank">00:00:59.200</a></span> | <span class="t">which I regard as absolutely crucial in this space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=63" target="_blank">00:01:03.040</a></span> | <span class="t">But with that said, we did dive into different metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=66" target="_blank">00:01:06.680</a></span> | <span class="t">We talked about success and reciprocal rank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=70" target="_blank">00:01:10.120</a></span> | <span class="t">Success, you should think of as just saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=72" target="_blank">00:01:12.840</a></span> | <span class="t">for my chosen k,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=74" target="_blank">00:01:14.760</a></span> | <span class="t">is there a star above me?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=76" target="_blank">00:01:16.720</a></span> | <span class="t">That is, is there a relevant document above k?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=80" target="_blank">00:01:20.220</a></span> | <span class="t">So it's a very coarse-grained measure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=82" target="_blank">00:01:22.480</a></span> | <span class="t">So this one here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=83" target="_blank">00:01:23.800</a></span> | <span class="t">if we set success at 2, D1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=86" target="_blank">00:01:26.560</a></span> | <span class="t">has success because there is a star at 2 or above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=90" target="_blank">00:01:30.240</a></span> | <span class="t">D2, that ranking also has a success of 1 because there is a star at 2 or above,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=96" target="_blank">00:01:36.160</a></span> | <span class="t">and poor D3 gets a success of 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=99" target="_blank">00:01:39.760</a></span> | <span class="t">And you can see already that it's coarse-grained because D1 and D2 are differentiated,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=105" target="_blank">00:01:45.320</a></span> | <span class="t">in some intuitive sense,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=106" target="_blank">00:01:46.600</a></span> | <span class="t">but here they both got a success score of 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=110" target="_blank">00:01:50.140</a></span> | <span class="t">Reciprocal rank is a little bit better in the sense that it's more or less just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=115" target="_blank">00:01:55.940</a></span> | <span class="t">registering whether there's a star at or above k,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=118" target="_blank">00:01:58.900</a></span> | <span class="t">except now we are sensitive to the top most ranked one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=123" target="_blank">00:02:03.020</a></span> | <span class="t">So for example, D1 here has an RR at 2 of 1 because there is a star in first place.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=129" target="_blank">00:02:09.820</a></span> | <span class="t">Whereas D2 has 1 over 2 because the first star is in second place.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=136" target="_blank">00:02:16.500</a></span> | <span class="t">And then D3 still gets its poor 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=139" target="_blank">00:02:19.940</a></span> | <span class="t">So pretty coarse-grained but very intuitive and sometimes success and RR are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=145" target="_blank">00:02:25.500</a></span> | <span class="t">good metrics in the sense that you kind of just want to know for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=148" target="_blank">00:02:28.620</a></span> | <span class="t">your chosen k whether you hit the mark,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=151" target="_blank">00:02:31.220</a></span> | <span class="t">whether you got a star.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=152" target="_blank">00:02:32.380</a></span> | <span class="t">And especially if you only have one relevant document per query,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=156" target="_blank">00:02:36.140</a></span> | <span class="t">you might as well use these metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=158" target="_blank">00:02:38.500</a></span> | <span class="t">And then RR will just be a little bit more nuanced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=161" target="_blank">00:02:41.780</a></span> | <span class="t">We also talked about precision and recall,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=164" target="_blank">00:02:44.180</a></span> | <span class="t">the classic accuracy style metrics in this space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=167" target="_blank">00:02:47.960</a></span> | <span class="t">The differentiator here from the previous ones is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=170" target="_blank">00:02:50.960</a></span> | <span class="t">these are going to be sensitive to multiple stars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=173" target="_blank">00:02:53.620</a></span> | <span class="t">So if you have more than one document that's relevant to your query,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=177" target="_blank">00:02:57.900</a></span> | <span class="t">you will be able to detect that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=180" target="_blank">00:03:00.440</a></span> | <span class="t">So we have this notion of a return value that is just the set of documents k or above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=185" target="_blank">00:03:05.700</a></span> | <span class="t">And then the relevant documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=187" target="_blank">00:03:07.500</a></span> | <span class="t">those are the ones with stars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=189" target="_blank">00:03:09.340</a></span> | <span class="t">And precision is saying for my chosen k,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=192" target="_blank">00:03:12.540</a></span> | <span class="t">what percentage of the things at or above k are relevant?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=197" target="_blank">00:03:17.260</a></span> | <span class="t">And that's precision in the sense that if you picked k,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=200" target="_blank">00:03:20.380</a></span> | <span class="t">you're looking at the set of documents and you want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=202" target="_blank">00:03:22.540</a></span> | <span class="t">know how many of them have stars relative to the total.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=205" target="_blank">00:03:25.900</a></span> | <span class="t">Or like the reverse of precision would be like which ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=209" target="_blank">00:03:29.340</a></span> | <span class="t">are kind of imprecise as predictions because there's no star there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=213" target="_blank">00:03:33.060</a></span> | <span class="t">And then recall is kind of the dual of that and it says for my chosen k,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=217" target="_blank">00:03:37.920</a></span> | <span class="t">how many of the stars made it up to k or above?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=221" target="_blank">00:03:41.940</a></span> | <span class="t">And the opposite of that would be like how many stars are lingering down below?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=226" target="_blank">00:03:46.940</a></span> | <span class="t">So you can see here because of the numerator that we're going to differentiate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=230" target="_blank">00:03:50.740</a></span> | <span class="t">systems now based on how many stars are at k or above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=234" target="_blank">00:03:54.820</a></span> | <span class="t">So it's sensitive to multiple stars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=237" target="_blank">00:03:57.460</a></span> | <span class="t">So just to walk through again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=239" target="_blank">00:03:59.440</a></span> | <span class="t">precision at 2 for D1 is 2 out of 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=242" target="_blank">00:04:02.660</a></span> | <span class="t">For D2, it's 1 out of 2 because just half of them have a star.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=248" target="_blank">00:04:08.060</a></span> | <span class="t">And for poor D3, 0 out of 2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=251" target="_blank">00:04:11.820</a></span> | <span class="t">Recall is very similar but now the denominator changes, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=255" target="_blank">00:04:15.140</a></span> | <span class="t">So the recall at 2 for this first one is 2 out of 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=258" target="_blank">00:04:18.420</a></span> | <span class="t">That is of the three-star documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=260" target="_blank">00:04:20.520</a></span> | <span class="t">2 are at k or above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=262" target="_blank">00:04:22.500</a></span> | <span class="t">Here it's 1 out of 3 and here at 0 out of 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=266" target="_blank">00:04:26.500</a></span> | <span class="t">And just to round this out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=268" target="_blank">00:04:28.420</a></span> | <span class="t">poor D3 has not fared well in our ranking so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=272" target="_blank">00:04:32.980</a></span> | <span class="t">But in a surprise twist,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=275" target="_blank">00:04:35.040</a></span> | <span class="t">if I change the value of k to 5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=277" target="_blank">00:04:37.820</a></span> | <span class="t">all of a sudden D3 looks pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=280" target="_blank">00:04:40.860</a></span> | <span class="t">Because now it's got all three of its stars at 5 or above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=285" target="_blank">00:04:45.180</a></span> | <span class="t">Whereas the other two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=286" target="_blank">00:04:46.860</a></span> | <span class="t">even though they've got some high stars up there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=289" target="_blank">00:04:49.560</a></span> | <span class="t">we're not sensitive to that precisely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=292" target="_blank">00:04:52.020</a></span> | <span class="t">And so now D3 has pulled ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=294" target="_blank">00:04:54.820</a></span> | <span class="t">And that is maybe something that you want to watch out for because people kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=298" target="_blank">00:04:58.580</a></span> | <span class="t">innocently choose these k values when they're evaluating systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=301" target="_blank">00:05:01.580</a></span> | <span class="t">And I just showed you that that could really impact the ranking of systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=306" target="_blank">00:05:06.340</a></span> | <span class="t">And in particular, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=309" target="_blank">00:05:09.180</a></span> | <span class="t">you know, it's hard to imagine since there are only six documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=312" target="_blank">00:05:12.060</a></span> | <span class="t">But if it was a lot of work to travel down to our chosen k,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=315" target="_blank">00:05:15.300</a></span> | <span class="t">if k was 1,000,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=317" target="_blank">00:05:17.300</a></span> | <span class="t">this would obscure the fact that we might pick as our winner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=320" target="_blank">00:05:20.960</a></span> | <span class="t">a system that had all the stars more or less at 1,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=324" target="_blank">00:05:24.500</a></span> | <span class="t">And the other systems which have their stars at the top of this ranking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=328" target="_blank">00:05:28.020</a></span> | <span class="t">and therefore they're easy to find,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=329" target="_blank">00:05:29.740</a></span> | <span class="t">those might be diminished with such a high k.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=333" target="_blank">00:05:33.320</a></span> | <span class="t">And so that kind of gets you into the role of thinking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=335" target="_blank">00:05:35.740</a></span> | <span class="t">what are my users trying to do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=337" target="_blank">00:05:37.140</a></span> | <span class="t">What is the cost of them scanning down a list of ranked results and things like that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=341" target="_blank">00:05:41.020</a></span> | <span class="t">And that's where I want you to be when you think about these metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=344" target="_blank">00:05:44.660</a></span> | <span class="t">What are you trying to solve out there in the world?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=347" target="_blank">00:05:47.740</a></span> | <span class="t">What are your users confronting?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=349" target="_blank">00:05:49.200</a></span> | <span class="t">What is the cost of reviewing examples and so forth and so on? Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=354" target="_blank">00:05:54.300</a></span> | <span class="t">Well, the neural IR models that we're going to kind of solve this problem of, right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=359" target="_blank">00:05:59.340</a></span> | <span class="t">because right now everything's based on the presence or not of a word,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=363" target="_blank">00:06:03.500</a></span> | <span class="t">rather than kind of maybe a- either a longer meaning or,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=367" target="_blank">00:06:07.540</a></span> | <span class="t">um, like the quality of the relevance, however we define it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=371" target="_blank">00:06:11.140</a></span> | <span class="t">Like maybe it only says the word once but actually has the best information afterwards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=375" target="_blank">00:06:15.120</a></span> | <span class="t">Will that take care of that or is- is all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=377" target="_blank">00:06:17.420</a></span> | <span class="t">neural also going to be based on presence or not of words?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=380" target="_blank">00:06:20.500</a></span> | <span class="t">That's a great question. Ah, wait, we should be careful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=383" target="_blank">00:06:23.060</a></span> | <span class="t">So yeah, I think for the first part of your question,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=385" target="_blank">00:06:25.740</a></span> | <span class="t">I want to say the neural IR models are overall going to be better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=389" target="_blank">00:06:29.540</a></span> | <span class="t">Because of what you alluded to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=391" target="_blank">00:06:31.380</a></span> | <span class="t">they have a very rich semantic space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=394" target="_blank">00:06:34.140</a></span> | <span class="t">It won't directly impact this because these stars after all aren't about terms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=399" target="_blank">00:06:39.100</a></span> | <span class="t">This is about whether a whole document was relevant to a query.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=401" target="_blank">00:06:41.980</a></span> | <span class="t">You should imagine that the background process is like some team of humans went through and said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=406" target="_blank">00:06:46.900</a></span> | <span class="t">okay, you searched for Bert and now I'm going through documents and saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=411" target="_blank">00:06:51.380</a></span> | <span class="t">yeah, this one is relevant, this one isn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=413" target="_blank">00:06:53.480</a></span> | <span class="t">That's what produced these rankings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=415" target="_blank">00:06:55.900</a></span> | <span class="t">But I think you're right in your core intuition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=418" target="_blank">00:06:58.500</a></span> | <span class="t">Term-based models are going to be kind of brittle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=421" target="_blank">00:07:01.260</a></span> | <span class="t">And if we have hard query document pairs, they might miss them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=426" target="_blank">00:07:06.020</a></span> | <span class="t">Actually, that reminds me like this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=428" target="_blank">00:07:08.020</a></span> | <span class="t">for some reason it didn't display before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=429" target="_blank">00:07:09.700</a></span> | <span class="t">Let's see if it displays now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=430" target="_blank">00:07:10.860</a></span> | <span class="t">I had this nice example that Omar created.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=433" target="_blank">00:07:13.580</a></span> | <span class="t">This is an example of why search is a hard NLU problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=437" target="_blank">00:07:17.880</a></span> | <span class="t">Because this is a query,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=439" target="_blank">00:07:19.540</a></span> | <span class="t">what compounds protect the digestive system against viruses,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=443" target="_blank">00:07:23.020</a></span> | <span class="t">where the response is certainly relevant,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=445" target="_blank">00:07:25.540</a></span> | <span class="t">but there is zero relevant term overlap between query and document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=449" target="_blank">00:07:29.860</a></span> | <span class="t">All of the connections that we want to make are deeply semantic connections.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=454" target="_blank">00:07:34.620</a></span> | <span class="t">And I do think that that is why neural IR models have pulled ahead for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=460" target="_blank">00:07:40.100</a></span> | <span class="t">accuracy style assessments trying to be careful as you'll see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=465" target="_blank">00:07:45.300</a></span> | <span class="t">I have one more metric which is average precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=470" target="_blank">00:07:50.860</a></span> | <span class="t">This will be, I think this is fair to say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=473" target="_blank">00:07:53.300</a></span> | <span class="t">our most nuanced metric.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=475" target="_blank">00:07:55.120</a></span> | <span class="t">Okay. So a little bit hard to think about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=477" target="_blank">00:07:57.260</a></span> | <span class="t">but I think it's intuitive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=478" target="_blank">00:07:58.500</a></span> | <span class="t">Average precision, notice it has no K. And the reason it has no K is that we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=484" target="_blank">00:08:04.540</a></span> | <span class="t">to sum over all the precision values for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=487" target="_blank">00:08:07.200</a></span> | <span class="t">different Ks here where there is a relevant document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=491" target="_blank">00:08:11.140</a></span> | <span class="t">Think back to our rankings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=492" target="_blank">00:08:12.560</a></span> | <span class="t">Wherever there was a star,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=494" target="_blank">00:08:14.200</a></span> | <span class="t">we're going to choose that as a K. And we're going to sum up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=497" target="_blank">00:08:17.780</a></span> | <span class="t">just those precision values and divide it by the number of relevant documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=503" target="_blank">00:08:23.800</a></span> | <span class="t">Here's an example. Same three rankings that we had before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=507" target="_blank">00:08:27.700</a></span> | <span class="t">and what I'll show you are these precision calculations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=510" target="_blank">00:08:30.620</a></span> | <span class="t">So for the first one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=512" target="_blank">00:08:32.040</a></span> | <span class="t">we have stars at position one, two, and six.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=515" target="_blank">00:08:35.380</a></span> | <span class="t">And so we accumulate the precision values for one, two, and six.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=519" target="_blank">00:08:39.540</a></span> | <span class="t">And those are, I hope,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=520" target="_blank">00:08:40.940</a></span> | <span class="t">the ones I've given there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=522" target="_blank">00:08:42.260</a></span> | <span class="t">That sums to 2.5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=524" target="_blank">00:08:44.700</a></span> | <span class="t">and then we divide that by three,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=526" target="_blank">00:08:46.540</a></span> | <span class="t">which is the number of relevant documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=529" target="_blank">00:08:49.660</a></span> | <span class="t">So we've abstracted away the K,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=532" target="_blank">00:08:52.900</a></span> | <span class="t">which is reassuring, and we're also checking at every level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=535" target="_blank">00:08:55.780</a></span> | <span class="t">So it's not going to have that sensitivity I showed you before where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=539" target="_blank">00:08:59.500</a></span> | <span class="t">the choice of K dramatically impacts which rankings we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=542" target="_blank">00:09:02.980</a></span> | <span class="t">favor because now we're kind of looking at all of the ones chosen by the ranking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=547" target="_blank">00:09:07.900</a></span> | <span class="t">So that's D1, and then for D2, same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=551" target="_blank">00:09:11.320</a></span> | <span class="t">But now we're checking at two, five,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=552" target="_blank">00:09:12.980</a></span> | <span class="t">and six because that's where the stars are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=555" target="_blank">00:09:15.100</a></span> | <span class="t">and that sums to 1.4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=557" target="_blank">00:09:17.500</a></span> | <span class="t">And then for D3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=559" target="_blank">00:09:19.500</a></span> | <span class="t">we do the same thing at positions three, four,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=561" target="_blank">00:09:21.780</a></span> | <span class="t">and five, and notice interestingly that D3 has a pulled ahead of D2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=568" target="_blank">00:09:28.340</a></span> | <span class="t">That's less surprising to me in the current context because D2 is kind of good and kind of not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=577" target="_blank">00:09:37.860</a></span> | <span class="t">It has that one star that's near the top,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=580" target="_blank">00:09:40.220</a></span> | <span class="t">but the other two stars are way at the bottom of our ranking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=583" target="_blank">00:09:43.500</a></span> | <span class="t">whereas at least D3 kind of put them all at least not literally at the bottom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=589" target="_blank">00:09:49.460</a></span> | <span class="t">Whereas D1 looks like just a slam dunk winner here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=593" target="_blank">00:09:53.300</a></span> | <span class="t">I mean, it simply has most of the stars right at the top.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=596" target="_blank">00:09:56.940</a></span> | <span class="t">It has that one lonely one at the bottom,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=599" target="_blank">00:09:59.300</a></span> | <span class="t">but you know on balance D1 looks good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=601" target="_blank">00:10:01.540</a></span> | <span class="t">So if I just stepped back from this little example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=604" target="_blank">00:10:04.620</a></span> | <span class="t">I would say that average precision is kind of nice in terms of giving what looks to me like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=609" target="_blank">00:10:09.700</a></span> | <span class="t">a pretty nuanced picture of these three rankings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=613" target="_blank">00:10:13.500</a></span> | <span class="t">I think that's all of the accuracy style metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=619" target="_blank">00:10:19.260</a></span> | <span class="t">Of course, there are others that you'll encounter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=621" target="_blank">00:10:21.100</a></span> | <span class="t">Some are sensitive to the numerical like the float value,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=624" target="_blank">00:10:24.620</a></span> | <span class="t">because sometimes you have not just a one or a zero,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=626" target="_blank">00:10:26.660</a></span> | <span class="t">a star or not, but rather a float value for relevance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=629" target="_blank">00:10:29.860</a></span> | <span class="t">There are lots of versions that of course average these over sets of queries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=634" target="_blank">00:10:34.060</a></span> | <span class="t">That'll be very common to see,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=635" target="_blank">00:10:35.740</a></span> | <span class="t">but underlyingly that's just some kind of arithmetic average of these scores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=640" target="_blank">00:10:40.460</a></span> | <span class="t">So I think this is a good sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=642" target="_blank">00:10:42.000</a></span> | <span class="t">Are there questions I can answer about these metrics?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=646" target="_blank">00:10:46.220</a></span> | <span class="t">Really great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=649" target="_blank">00:10:49.100</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=649" target="_blank">00:10:49.420</a></span> | <span class="t">The float value one for relevance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=652" target="_blank">00:10:52.020</a></span> | <span class="t">how's that at a high level computed?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=654" target="_blank">00:10:54.980</a></span> | <span class="t">What's it called? Like the discounted cumulative gain,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=659" target="_blank">00:10:59.220</a></span> | <span class="t">and it is the sum of all of the scores divided by something or other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=665" target="_blank">00:11:05.900</a></span> | <span class="t">This must be in your history somewhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=668" target="_blank">00:11:08.340</a></span> | <span class="t">It is something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=669" target="_blank">00:11:09.220</a></span> | <span class="t">[LAUGHTER]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=670" target="_blank">00:11:10.220</a></span> | <span class="t">You could also just label,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=672" target="_blank">00:11:12.260</a></span> | <span class="t">you know, have human labels and then you can take the precision,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=677" target="_blank">00:11:17.060</a></span> | <span class="t">or not precision, maybe just position-weighted combination of human labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=681" target="_blank">00:11:21.660</a></span> | <span class="t">[inaudible]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=684" target="_blank">00:11:24.780</a></span> | <span class="t">So you found the discounted cumulative gain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=687" target="_blank">00:11:27.420</a></span> | <span class="t">That's a metric I left out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=689" target="_blank">00:11:29.220</a></span> | <span class="t">And then you're just observing that very often for these datasets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=692" target="_blank">00:11:32.860</a></span> | <span class="t">we'd have humans do a bunch of labeling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=694" target="_blank">00:11:34.820</a></span> | <span class="t">and then average precision is one way of aggregating over the labels we might have collected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=701" target="_blank">00:11:41.180</a></span> | <span class="t">I kind of alluded to this before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=705" target="_blank">00:11:45.860</a></span> | <span class="t">but like here's a partial list of things you could think about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=708" target="_blank">00:11:48.780</a></span> | <span class="t">Which metric? Fundamentally, there is no single answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=712" target="_blank">00:11:52.060</a></span> | <span class="t">Is the cost of sc- scrolling through k passages low?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=716" target="_blank">00:11:56.340</a></span> | <span class="t">Then maybe success at k is fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=718" target="_blank">00:11:58.540</a></span> | <span class="t">Because you don't care whether it was a position nine or position one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=722" target="_blank">00:12:02.060</a></span> | <span class="t">what you really care about is that the user is kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=724" target="_blank">00:12:04.660</a></span> | <span class="t">confronted with the success that they can easily find.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=728" target="_blank">00:12:08.260</a></span> | <span class="t">That's one scenario that you could be in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=730" target="_blank">00:12:10.780</a></span> | <span class="t">Are there multiple relevant documents per query?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=733" target="_blank">00:12:13.980</a></span> | <span class="t">This is straightforward. If so,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=735" target="_blank">00:12:15.540</a></span> | <span class="t">you probably shouldn't use success at k or rrk,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=739" target="_blank">00:12:19.580</a></span> | <span class="t">because they're only sensitive really to one star.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=742" target="_blank">00:12:22.620</a></span> | <span class="t">And if you went to the trouble of getting multiple stars,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=745" target="_blank">00:12:25.660</a></span> | <span class="t">you know, why have your metric be insensitive to that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=748" target="_blank">00:12:28.580</a></span> | <span class="t">So that seems clear. Is it more important to find every relevant document?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=753" target="_blank">00:12:33.500</a></span> | <span class="t">If so, you should favor recall.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=755" target="_blank">00:12:35.100</a></span> | <span class="t">That would be a case where maybe human review is cheap,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=758" target="_blank">00:12:38.460</a></span> | <span class="t">or the cost of missing an example is hugely expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=763" target="_blank">00:12:43.020</a></span> | <span class="t">In that case, you want to favor recall.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=764" target="_blank">00:12:44.980</a></span> | <span class="t">You can't miss anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=766" target="_blank">00:12:46.220</a></span> | <span class="t">Conversely, if you just need to find some relevant things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=770" target="_blank">00:12:50.620</a></span> | <span class="t">maybe in an ocean of examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=772" target="_blank">00:12:52.700</a></span> | <span class="t">because you want to label them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=774" target="_blank">00:12:54.140</a></span> | <span class="t">or because it's just good to know about them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=776" target="_blank">00:12:56.300</a></span> | <span class="t">then you could favor precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=777" target="_blank">00:12:57.820</a></span> | <span class="t">Because then all you really care about is that near the top are some relevant things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=783" target="_blank">00:13:03.740</a></span> | <span class="t">F1 at k is the harmonic mean of precision and recall.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=787" target="_blank">00:13:07.860</a></span> | <span class="t">Same thing as we do in NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=790" target="_blank">00:13:10.340</a></span> | <span class="t">And that can be used where there are multiple relevant documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=793" target="_blank">00:13:13.260</a></span> | <span class="t">but maybe the relative order above k doesn't matter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=796" target="_blank">00:13:16.900</a></span> | <span class="t">That's just one perspective on what I mean when I say we're combining precision and recall.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=802" target="_blank">00:13:22.500</a></span> | <span class="t">And then finally, average precision of the ones I've showed you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=806" target="_blank">00:13:26.140</a></span> | <span class="t">will give you the most fine-grained distinctions of the metrics, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=809" target="_blank">00:13:29.340</a></span> | <span class="t">Because it's sensitive to rank,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=811" target="_blank">00:13:31.260</a></span> | <span class="t">and it's sensitive to precision and recall.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=813" target="_blank">00:13:33.820</a></span> | <span class="t">Precision because it aggregates over those values,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=816" target="_blank">00:13:36.060</a></span> | <span class="t">and recall because that's the denominator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=818" target="_blank">00:13:38.660</a></span> | <span class="t">So that looks like an awfully good way to really get a fine-grained ranking of systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=825" target="_blank">00:13:45.020</a></span> | <span class="t">And then finally, I'm going to talk about this a bit later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=830" target="_blank">00:13:50.220</a></span> | <span class="t">We have to move on beyond accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=832" target="_blank">00:13:52.260</a></span> | <span class="t">This is a paper that I did with a team recently of researchers here and at IBM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=836" target="_blank">00:13:56.780</a></span> | <span class="t">What we're seeing here is a kind of post-hoc leaderboard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=840" target="_blank">00:14:00.460</a></span> | <span class="t">Not an actual leaderboard because part of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=842" target="_blank">00:14:02.860</a></span> | <span class="t">our complaint is that there are no leaderboards that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=845" target="_blank">00:14:05.180</a></span> | <span class="t">really do anything beyond measuring accuracy style things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=848" target="_blank">00:14:08.660</a></span> | <span class="t">But if you did go through the literature as we did here and find a lot of systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=853" target="_blank">00:14:13.900</a></span> | <span class="t">you can see that they vary widely along other dimensions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=857" target="_blank">00:14:17.660</a></span> | <span class="t">Here is the mean reciprocal rank,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=859" target="_blank">00:14:19.740</a></span> | <span class="t">one of our rankings, goes from 19 to 37 or 39 or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=864" target="_blank">00:14:24.740</a></span> | <span class="t">So you say, okay, but then look just to the right of that at the query latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=869" target="_blank">00:14:29.540</a></span> | <span class="t">To get to 37,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=871" target="_blank">00:14:31.660</a></span> | <span class="t">look how much time I have to spend versus down here where 36,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=876" target="_blank">00:14:36.060</a></span> | <span class="t">I spend a fraction of the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=878" target="_blank">00:14:38.100</a></span> | <span class="t">That is absolutely something that will matter to the search experience of users.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=882" target="_blank">00:14:42.820</a></span> | <span class="t">There is almost no way they're waiting around for 691 milliseconds, for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=889" target="_blank">00:14:49.060</a></span> | <span class="t">Or what about the index size?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=890" target="_blank">00:14:50.660</a></span> | <span class="t">Right. If you care about space footprint and you will if you are indexing the web,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=895" target="_blank">00:14:55.220</a></span> | <span class="t">some of these have tiny little indices and then, uh-oh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=898" target="_blank">00:14:58.980</a></span> | <span class="t">that's our model, Colbert V1, 154 gigabytes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=903" target="_blank">00:15:03.180</a></span> | <span class="t">Right. So now if you need to hold it in memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=905" target="_blank">00:15:05.900</a></span> | <span class="t">your world just got a lot more expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=908" target="_blank">00:15:08.980</a></span> | <span class="t">You'll see over here RAM requirements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=911" target="_blank">00:15:11.660</a></span> | <span class="t">So BM25, it has no hardware requirements at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=916" target="_blank">00:15:16.100</a></span> | <span class="t">You can run that on anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=917" target="_blank">00:15:17.880</a></span> | <span class="t">Whereas these models down here that have these really high MRR scores,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=922" target="_blank">00:15:22.220</a></span> | <span class="t">hugely expensive in terms of compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=925" target="_blank">00:15:25.460</a></span> | <span class="t">Classic story of the neural age, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=928" target="_blank">00:15:28.420</a></span> | <span class="t">So you have to pay somewhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=930" target="_blank">00:15:30.700</a></span> | <span class="t">Then of course, I hope you're thinking about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=934" target="_blank">00:15:34.260</a></span> | <span class="t">So then what is the best combination of all these things?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=938" target="_blank">00:15:38.140</a></span> | <span class="t">Well, it depends on how much money you have and how much time you have,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=941" target="_blank">00:15:41.180</a></span> | <span class="t">and how much you care about accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=943" target="_blank">00:15:43.620</a></span> | <span class="t">And so the best pitch I can make to you is that as you evaluate systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=947" target="_blank">00:15:47.880</a></span> | <span class="t">you think about what you care about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=950" target="_blank">00:15:50.140</a></span> | <span class="t">what matters, and conduct- construct your evaluations on that basis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=954" target="_blank">00:15:54.800</a></span> | <span class="t">That's gonna be a big theme of the course later on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=957" target="_blank">00:15:57.560</a></span> | <span class="t">And I'm hoping to time it so that you all,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=960" target="_blank">00:16:00.520</a></span> | <span class="t">for your papers, are thinking about assessment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=963" target="_blank">00:16:03.120</a></span> | <span class="t">And you think, ah, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=964" target="_blank">00:16:04.480</a></span> | <span class="t">I should have a whole section about my philosophy of assessment here and not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=967" target="_blank">00:16:07.720</a></span> | <span class="t">just fall into F1 or fall into success at K or whatever is relevant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=974" target="_blank">00:16:14.460</a></span> | <span class="t">This is kind of interesting too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=979" target="_blank">00:16:19.580</a></span> | <span class="t">This is from the same paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=981" target="_blank">00:16:21.220</a></span> | <span class="t">Here's BM25.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=983" target="_blank">00:16:23.500</a></span> | <span class="t">Costs essentially nothing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=985" target="_blank">00:16:25.460</a></span> | <span class="t">but it has very low performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=987" target="_blank">00:16:27.300</a></span> | <span class="t">If you travel straight up from there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=989" target="_blank">00:16:29.580</a></span> | <span class="t">look at these splayed models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=991" target="_blank">00:16:31.660</a></span> | <span class="t">Also costing essentially nothing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=994" target="_blank">00:16:34.140</a></span> | <span class="t">but vastly better in terms of their performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=996" target="_blank">00:16:36.940</a></span> | <span class="t">That looks like a real discovery to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=999" target="_blank">00:16:39.160</a></span> | <span class="t">You know, this is like the Pareto frontier as they call it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1002" target="_blank">00:16:42.520</a></span> | <span class="t">These systems where you would just wouldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1005" target="_blank">00:16:45.040</a></span> | <span class="t">choose any that are off the frontier no matter what your values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1008" target="_blank">00:16:48.520</a></span> | <span class="t">And obviously, you can see that to favor this model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1011" target="_blank">00:16:51.720</a></span> | <span class="t">there are gonna have to be other dimensions that we care about beyond cost and MRR,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1016" target="_blank">00:16:56.040</a></span> | <span class="t">because otherwise, that's just not a choice you would make.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1019" target="_blank">00:16:59.880</a></span> | <span class="t">But for all I know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1021" target="_blank">00:17:01.920</a></span> | <span class="t">there are hidden dimensions that need to be teased out that would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1024" target="_blank">00:17:04.280</a></span> | <span class="t">show that that ANS model is the best relative to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1030" target="_blank">00:17:10.760</a></span> | <span class="t">Let's dive into some of those models then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1035" target="_blank">00:17:15.280</a></span> | <span class="t">Neural IR. First, we'll start with cross-encoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1040" target="_blank">00:17:20.840</a></span> | <span class="t">This will be very intuitive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1042" target="_blank">00:17:22.760</a></span> | <span class="t">Okay. Here, just imagine I have a huge transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1046" target="_blank">00:17:26.880</a></span> | <span class="t">And for cross-encoders, what I do is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1049" target="_blank">00:17:29.640</a></span> | <span class="t">I just concatenate the query and the document together,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1052" target="_blank">00:17:32.780</a></span> | <span class="t">process them with my transformer model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1055" target="_blank">00:17:35.440</a></span> | <span class="t">And then on the top here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1056" target="_blank">00:17:36.800</a></span> | <span class="t">I put a little scoring function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1058" target="_blank">00:17:38.440</a></span> | <span class="t">And the scoring function will just say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1060" target="_blank">00:17:40.600</a></span> | <span class="t">for this query, how good is this document?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1064" target="_blank">00:17:44.000</a></span> | <span class="t">Enormously powerful to this comment from before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1068" target="_blank">00:17:48.800</a></span> | <span class="t">we are making like maximal use of this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1072" target="_blank">00:17:52.320</a></span> | <span class="t">say, BERT model here to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1074" target="_blank">00:17:54.600</a></span> | <span class="t">every possible interaction between query and document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1077" target="_blank">00:17:57.880</a></span> | <span class="t">So this will be good in terms of accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1080" target="_blank">00:18:00.600</a></span> | <span class="t">But you might worry about some other things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1083" target="_blank">00:18:03.140</a></span> | <span class="t">Here, let me walk through a bit more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1084" target="_blank">00:18:04.620</a></span> | <span class="t">In the background here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1085" target="_blank">00:18:05.740</a></span> | <span class="t">I'm assuming that our dataset looks like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1088" target="_blank">00:18:08.220</a></span> | <span class="t">We have a query, one positive document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1091" target="_blank">00:18:11.660</a></span> | <span class="t">and a set of one or more negative documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1095" target="_blank">00:18:15.500</a></span> | <span class="t">We could have multiple of the negatives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1098" target="_blank">00:18:18.740</a></span> | <span class="t">What I'm depicting on the left here is a model we could summarize like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1104" target="_blank">00:18:24.040</a></span> | <span class="t">This is the encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1105" target="_blank">00:18:25.980</a></span> | <span class="t">We concatenate the query and the document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1108" target="_blank">00:18:28.980</a></span> | <span class="t">and process them, and we retrieve this representation here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1113" target="_blank">00:18:33.340</a></span> | <span class="t">layer n, position 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1116" target="_blank">00:18:36.020</a></span> | <span class="t">We feed that through a dense layer that does our scoring,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1119" target="_blank">00:18:39.700</a></span> | <span class="t">and that is the basis for essentially a classifier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1124" target="_blank">00:18:44.060</a></span> | <span class="t">This is called the negative log likelihood of the positive passage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1127" target="_blank">00:18:47.860</a></span> | <span class="t">And if you squint or you don't squint,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1130" target="_blank">00:18:50.540</a></span> | <span class="t">you just let it go blurry,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1131" target="_blank">00:18:51.940</a></span> | <span class="t">you will see that it is a typical classifier loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1135" target="_blank">00:18:55.420</a></span> | <span class="t">The only possible twist is the denominator is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1138" target="_blank">00:18:58.620</a></span> | <span class="t">the positive passage score and then on the denominator,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1142" target="_blank">00:19:02.020</a></span> | <span class="t">I have the positive passage sum together with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1144" target="_blank">00:19:04.380</a></span> | <span class="t">all the negative passages that I have in my example set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1147" target="_blank">00:19:07.940</a></span> | <span class="t">But fundamentally, it's a classifier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1151" target="_blank">00:19:11.340</a></span> | <span class="t">So that's why this examples look like this because that's what's being used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1156" target="_blank">00:19:16.980</a></span> | <span class="t">here to optimize all these parameters to score documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1162" target="_blank">00:19:22.780</a></span> | <span class="t">Final thing, I hope you're thinking about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1166" target="_blank">00:19:26.740</a></span> | <span class="t">It's going to be incredibly expressive and powerful,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1169" target="_blank">00:19:29.380</a></span> | <span class="t">but it just won't scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1171" target="_blank">00:19:31.740</a></span> | <span class="t">The cost of having the query and document interact at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1174" target="_blank">00:19:34.940</a></span> | <span class="t">query time is that I can't process any of these documents ahead of time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1178" target="_blank">00:19:38.860</a></span> | <span class="t">So just imagine this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1180" target="_blank">00:19:40.140</a></span> | <span class="t">your query comes in on the web,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1181" target="_blank">00:19:41.860</a></span> | <span class="t">like your Google, you're using a cross encoder, the user queries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1185" target="_blank">00:19:45.820</a></span> | <span class="t">You need to process that query together with every single document on the web,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1190" target="_blank">00:19:50.220</a></span> | <span class="t">to score them, and then on that basis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1192" target="_blank">00:19:52.660</a></span> | <span class="t">you will get beautiful scores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1194" target="_blank">00:19:54.660</a></span> | <span class="t">But obviously, each query could take years to serve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1199" target="_blank">00:19:59.380</a></span> | <span class="t">So from this perspective,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1201" target="_blank">00:20:01.700</a></span> | <span class="t">it is just not a practical choice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1203" target="_blank">00:20:03.940</a></span> | <span class="t">Maybe we could use it for re-ranking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1206" target="_blank">00:20:06.620</a></span> | <span class="t">You see this sometimes where a cheap retriever gets a lot of like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1210" target="_blank">00:20:10.220</a></span> | <span class="t">like a 1,000 documents and then this is done to re-rank the last 1,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1213" target="_blank">00:20:13.980</a></span> | <span class="t">But we can't do this at web scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1216" target="_blank">00:20:16.700</a></span> | <span class="t">So a question in the back. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1218" target="_blank">00:20:18.540</a></span> | <span class="t">Um, could you use this with multiple possible,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1221" target="_blank">00:20:21.500</a></span> | <span class="t">uh, positive documents as well?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1223" target="_blank">00:20:23.700</a></span> | <span class="t">Um.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1225" target="_blank">00:20:25.540</a></span> | <span class="t">Like if you were like, like for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1227" target="_blank">00:20:27.820</a></span> | <span class="t">for like the ranking thing right here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1229" target="_blank">00:20:29.340</a></span> | <span class="t">like multiple of those could be like good, but.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1233" target="_blank">00:20:33.700</a></span> | <span class="t">I- let's see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1236" target="_blank">00:20:36.180</a></span> | <span class="t">I don't see why not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1237" target="_blank">00:20:37.100</a></span> | <span class="t">The numerator could be the sum of the positive and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1239" target="_blank">00:20:39.340</a></span> | <span class="t">then the denominator could just include all of those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1241" target="_blank">00:20:41.780</a></span> | <span class="t">So what you would be doing is, well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1246" target="_blank">00:20:46.220</a></span> | <span class="t">I'm just trying to think through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1251" target="_blank">00:20:51.900</a></span> | <span class="t">That, that would be one approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1253" target="_blank">00:20:53.060</a></span> | <span class="t">The other approach would be to just treat them as separate examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1256" target="_blank">00:20:56.700</a></span> | <span class="t">I think under some conditions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1258" target="_blank">00:20:58.620</a></span> | <span class="t">those will be identical,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1259" target="_blank">00:20:59.700</a></span> | <span class="t">but I'd have to think it through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1260" target="_blank">00:21:00.780</a></span> | <span class="t">But I don't see a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1264" target="_blank">00:21:04.140</a></span> | <span class="t">I don't see a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1266" target="_blank">00:21:06.220</a></span> | <span class="t">But it's worth thinking about. I'll get back to you on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1270" target="_blank">00:21:10.140</a></span> | <span class="t">Let's improve on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1273" target="_blank">00:21:13.660</a></span> | <span class="t">DPR, dense passage retriever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1277" target="_blank">00:21:17.020</a></span> | <span class="t">This will also be intuitive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1278" target="_blank">00:21:18.260</a></span> | <span class="t">Here we go. Query and document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1280" target="_blank">00:21:20.020</a></span> | <span class="t">except notice now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1281" target="_blank">00:21:21.580</a></span> | <span class="t">they are processed by separate models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1283" target="_blank">00:21:23.900</a></span> | <span class="t">The query encoder and the document encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1286" target="_blank">00:21:26.340</a></span> | <span class="t">Could be the same parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1287" target="_blank">00:21:27.700</a></span> | <span class="t">but the point is, we process them separately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1290" target="_blank">00:21:30.280</a></span> | <span class="t">And I've made lighter every state except the output tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1294" target="_blank">00:21:34.980</a></span> | <span class="t">but below the two class tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1297" target="_blank">00:21:37.120</a></span> | <span class="t">because those are the only ones that we need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1299" target="_blank">00:21:39.660</a></span> | <span class="t">Okay. These two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1301" target="_blank">00:21:41.700</a></span> | <span class="t">And then we do some kind of scoring on that basis like similarity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1305" target="_blank">00:21:45.740</a></span> | <span class="t">Right. So here are examples are the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1308" target="_blank">00:21:48.660</a></span> | <span class="t">Now, the similarity function as I'm calling it for,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1312" target="_blank">00:21:52.140</a></span> | <span class="t">for a query and a document is we process the query,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1314" target="_blank">00:21:54.980</a></span> | <span class="t">we get this guy, process the document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1317" target="_blank">00:21:57.540</a></span> | <span class="t">and we get this guy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1318" target="_blank">00:21:58.780</a></span> | <span class="t">and then we do scoring on that basis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1320" target="_blank">00:22:00.900</a></span> | <span class="t">There are no additional parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1323" target="_blank">00:22:03.100</a></span> | <span class="t">We just score based on those representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1326" target="_blank">00:22:06.420</a></span> | <span class="t">They're dot product.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1328" target="_blank">00:22:08.260</a></span> | <span class="t">So now, we've got something that is highly scalable because we can process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1333" target="_blank">00:22:13.740</a></span> | <span class="t">every document in our entire web collection into a single vector,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1337" target="_blank">00:22:17.660</a></span> | <span class="t">this one, and it can just sit there on disk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1340" target="_blank">00:22:20.540</a></span> | <span class="t">And then at query time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1342" target="_blank">00:22:22.100</a></span> | <span class="t">process the query, get its vector,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1344" target="_blank">00:22:24.000</a></span> | <span class="t">and do this super fast dot product comparison for scoring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1348" target="_blank">00:22:28.620</a></span> | <span class="t">So now we've got something that is probably even going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1351" target="_blank">00:22:31.380</a></span> | <span class="t">function as a full ranking model, not just a re-ranker.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1355" target="_blank">00:22:35.380</a></span> | <span class="t">But the real game is that we can process all our documents offline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1359" target="_blank">00:22:39.140</a></span> | <span class="t">The cost was that we now have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1361" target="_blank">00:22:41.500</a></span> | <span class="t">almost no interactions between the query and the document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1364" target="_blank">00:22:44.460</a></span> | <span class="t">Like if you think about token identities,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1366" target="_blank">00:22:46.920</a></span> | <span class="t">if you think about the soft matching that happens with TF-IDF,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1370" target="_blank">00:22:50.940</a></span> | <span class="t">none of that is going to be able to happen here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1373" target="_blank">00:22:53.900</a></span> | <span class="t">That was the cost. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1379" target="_blank">00:22:59.900</a></span> | <span class="t">So, uh, I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1381" target="_blank">00:23:01.540</a></span> | <span class="t">essentially what we'll be comparing would be two fixed length vectors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1385" target="_blank">00:23:05.020</a></span> | <span class="t">right? I mean, a vector representing the document and another representing the query.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1388" target="_blank">00:23:08.860</a></span> | <span class="t">So is there, I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1391" target="_blank">00:23:11.260</a></span> | <span class="t">a limit to the length of the document that would be represented in that vector?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1395" target="_blank">00:23:15.580</a></span> | <span class="t">I mean, like, could it represent an arbitrary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1398" target="_blank">00:23:18.260</a></span> | <span class="t">a long document? It would lose context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1402" target="_blank">00:23:22.420</a></span> | <span class="t">These are great questions. Let me repeat them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1404" target="_blank">00:23:24.060</a></span> | <span class="t">For the first question, yes, you are right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1406" target="_blank">00:23:26.700</a></span> | <span class="t">The one constraint we need to impose on the query encoder and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1409" target="_blank">00:23:29.900</a></span> | <span class="t">the document encoder is that they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1411" target="_blank">00:23:31.420</a></span> | <span class="t">the same dimensionality so that we can do the dot product.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1414" target="_blank">00:23:34.160</a></span> | <span class="t">They can otherwise be separate models if we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1417" target="_blank">00:23:37.040</a></span> | <span class="t">And then length of query and length of document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1419" target="_blank">00:23:39.840</a></span> | <span class="t">that's just going to be imposed by whatever we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1422" target="_blank">00:23:42.020</a></span> | <span class="t">choose for the query and the document themselves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1424" target="_blank">00:23:44.240</a></span> | <span class="t">So if you choose BERT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1425" target="_blank">00:23:45.860</a></span> | <span class="t">you're going to be stuck with 512 as the length,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1427" target="_blank">00:23:47.980</a></span> | <span class="t">the longest document that you can process unless we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1430" target="_blank">00:23:50.620</a></span> | <span class="t">do some further manipulation of these things. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1436" target="_blank">00:23:56.700</a></span> | <span class="t">If these models are trained to project into kind of like a shared embedding space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1443" target="_blank">00:24:03.060</a></span> | <span class="t">so like documents that are similar to a query are going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1446" target="_blank">00:24:06.040</a></span> | <span class="t">fall into a similar location in embedding space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1449" target="_blank">00:24:09.700</a></span> | <span class="t">could we have a system where we essentially take,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1452" target="_blank">00:24:12.840</a></span> | <span class="t">like we pre-process all the documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1455" target="_blank">00:24:15.240</a></span> | <span class="t">we take a query at inference time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1457" target="_blank">00:24:17.840</a></span> | <span class="t">project it into embedding space and then do like a new research or something like that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1463" target="_blank">00:24:23.040</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1464" target="_blank">00:24:24.200</a></span> | <span class="t">Well, yes. So some aspects of what you're describing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1467" target="_blank">00:24:27.200</a></span> | <span class="t">I think, are what DPR will be optimized for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1470" target="_blank">00:24:30.000</a></span> | <span class="t">The other parts of what you're saying are going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1472" target="_blank">00:24:32.440</a></span> | <span class="t">optimization tricks that I show you in a second, I believe. Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1477" target="_blank">00:24:37.960</a></span> | <span class="t">You elaborate on what you mean by limited query doc interactions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1481" target="_blank">00:24:41.880</a></span> | <span class="t">Just that all we've got in the end is this vector for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1485" target="_blank">00:24:45.860</a></span> | <span class="t">the whole query and this vector for the whole document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1489" target="_blank">00:24:49.020</a></span> | <span class="t">So token identities to the extent that they're preserved at all,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1492" target="_blank">00:24:52.400</a></span> | <span class="t">they have to have been packed into those vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1495" target="_blank">00:24:55.900</a></span> | <span class="t">Whereas over here, we had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1500" target="_blank">00:25:00.040</a></span> | <span class="t">every token level interaction you can imagine as a result of us using like the transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1506" target="_blank">00:25:06.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1509" target="_blank">00:25:09.160</a></span> | <span class="t">Is there any room for training some more clever synthesis of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1513" target="_blank">00:25:13.120</a></span> | <span class="t">the two representations you get at the end as opposed to just dot producting them?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1516" target="_blank">00:25:16.480</a></span> | <span class="t">Oh, that's, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1517" target="_blank">00:25:17.760</a></span> | <span class="t">I think that's a natural follow-on is that you might think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1520" target="_blank">00:25:20.660</a></span> | <span class="t">I want to have in this layer here some additional parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1524" target="_blank">00:25:24.260</a></span> | <span class="t">and you can kind of see how that might work, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1526" target="_blank">00:25:26.560</a></span> | <span class="t">So instead of just using this vector,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1528" target="_blank">00:25:28.260</a></span> | <span class="t">I would put some parameters on top and then the same optimization can be used.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1533" target="_blank">00:25:33.560</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1534" target="_blank">00:25:34.160</a></span> | <span class="t">If they're going to the same embedding space, attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1539" target="_blank">00:25:39.040</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1540" target="_blank">00:25:40.080</a></span> | <span class="t">Yeah. Yeah. And this could be good in the sense that we,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1544" target="_blank">00:25:44.280</a></span> | <span class="t">we would pay a little bit of a cost by adding more parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1547" target="_blank">00:25:47.440</a></span> | <span class="t">but we might gain something in terms of expressivity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1551" target="_blank">00:25:51.320</a></span> | <span class="t">Nice. Let me show you a happy compromise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1558" target="_blank">00:25:58.420</a></span> | <span class="t">Oh yeah, I just wanted to point this out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1560" target="_blank">00:26:00.900</a></span> | <span class="t">that I've just showed you two loss functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1563" target="_blank">00:26:03.500</a></span> | <span class="t">I showed you the cross encoder and the DPR,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1566" target="_blank">00:26:06.000</a></span> | <span class="t">and you can probably already see that they are identical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1568" target="_blank">00:26:08.800</a></span> | <span class="t">except for this function that you might call comp here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1572" target="_blank">00:26:12.340</a></span> | <span class="t">And that's kind of freeing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1574" target="_blank">00:26:14.100</a></span> | <span class="t">And as you think about these different model architectures,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1576" target="_blank">00:26:16.980</a></span> | <span class="t">probably what you're thinking about is simply changing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1579" target="_blank">00:26:19.860</a></span> | <span class="t">this comp function and then using your available data to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1583" target="_blank">00:26:23.200</a></span> | <span class="t">train the model against this negative log likelihood of the positive passage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1587" target="_blank">00:26:27.720</a></span> | <span class="t">There are other losses out there in the literature,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1591" target="_blank">00:26:31.160</a></span> | <span class="t">but this is the most widely used and it seems to be very effective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1595" target="_blank">00:26:35.760</a></span> | <span class="t">Colbert. This stands for contextualized late interaction with BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1604" target="_blank">00:26:44.120</a></span> | <span class="t">It was invented by Omar and Matei who are here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1606" target="_blank">00:26:46.760</a></span> | <span class="t">Omar is my student, I work closely with Matei.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1609" target="_blank">00:26:49.040</a></span> | <span class="t">Um, and let's see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1611" target="_blank">00:26:51.040</a></span> | <span class="t">So Omar would want you to know that this stands for contextualized late interaction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1616" target="_blank">00:26:56.120</a></span> | <span class="t">and he pronounces it Colbert because Stephen Colbert has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1619" target="_blank">00:26:59.520</a></span> | <span class="t">a show full of contextualized late night interactions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1624" target="_blank">00:27:04.120</a></span> | <span class="t">But you can also pronounce it Colbert.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1627" target="_blank">00:27:07.340</a></span> | <span class="t">It's your choice because the BERT there is the BERT model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1631" target="_blank">00:27:11.680</a></span> | <span class="t">And we are, yes, still hoping that Stephen Colbert will take notice of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1636" target="_blank">00:27:16.040</a></span> | <span class="t">[inaudible]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1645" target="_blank">00:27:25.200</a></span> | <span class="t">I haven't been so bold,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1646" target="_blank">00:27:26.440</a></span> | <span class="t">but I welcome you all to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1648" target="_blank">00:27:28.760</a></span> | <span class="t">That's great. Add him on Twitter, yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1651" target="_blank">00:27:31.640</a></span> | <span class="t">Here's how this will work. I've drawn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1653" target="_blank">00:27:33.920</a></span> | <span class="t">the query encoder on the side for reasons that you'll see,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1656" target="_blank">00:27:36.320</a></span> | <span class="t">but it's the same kind of thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1657" target="_blank">00:27:37.520</a></span> | <span class="t">So imagine BERT processes my query and I've grayed out everything,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1661" target="_blank">00:27:41.000</a></span> | <span class="t">but the final representations because crucially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1663" target="_blank">00:27:43.280</a></span> | <span class="t">those are the only ones that we actually need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1665" target="_blank">00:27:45.480</a></span> | <span class="t">Same thing with the document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1667" target="_blank">00:27:47.400</a></span> | <span class="t">and it could be the same encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1669" target="_blank">00:27:49.300</a></span> | <span class="t">Now what I'm going to do with Colbert is form a grid of scores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1674" target="_blank">00:27:54.040</a></span> | <span class="t">And this is going to essentially give the similarity value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1677" target="_blank">00:27:57.640</a></span> | <span class="t">between every query token and every document token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1682" target="_blank">00:28:02.560</a></span> | <span class="t">And then I will choose the values along the rows,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1687" target="_blank">00:28:07.400</a></span> | <span class="t">that is for each query,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1688" target="_blank">00:28:08.480</a></span> | <span class="t">the document token that maximizes that similarity comparison.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1692" target="_blank">00:28:12.880</a></span> | <span class="t">And the scoring function is essentially the sum of those three max values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1698" target="_blank">00:28:18.800</a></span> | <span class="t">That is why you see maxim all over the place for Colbert.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1703" target="_blank">00:28:23.760</a></span> | <span class="t">Examples are as before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1706" target="_blank">00:28:26.320</a></span> | <span class="t">losses as before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1708" target="_blank">00:28:28.240</a></span> | <span class="t">and I wrote down here what we would think of as the comp function,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1711" target="_blank">00:28:31.200</a></span> | <span class="t">and I wrote it as maxim.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1712" target="_blank">00:28:32.760</a></span> | <span class="t">For a query in a document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1714" target="_blank">00:28:34.200</a></span> | <span class="t">you sum over all the query tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1716" target="_blank">00:28:36.640</a></span> | <span class="t">and you get the max matching document token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1720" target="_blank">00:28:40.760</a></span> | <span class="t">So you can see why it's contextualized late interaction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1724" target="_blank">00:28:44.120</a></span> | <span class="t">because I'm using the output states.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1726" target="_blank">00:28:46.520</a></span> | <span class="t">But unlike DPR, I'm allowing them all to interact with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1730" target="_blank">00:28:50.360</a></span> | <span class="t">each other via these very fast maxim calculations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1734" target="_blank">00:28:54.120</a></span> | <span class="t">I have token level interactions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1736" target="_blank">00:28:56.760</a></span> | <span class="t">It's right, so highly scalable and highly expressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1740" target="_blank">00:29:00.440</a></span> | <span class="t">The only cost is that the interactions happen only in this very thin final layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1746" target="_blank">00:29:06.320</a></span> | <span class="t">But this is really pleasing for IR,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1750" target="_blank">00:29:10.120</a></span> | <span class="t">that Colbert because of this brings us back to common intuitions in IR.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1754" target="_blank">00:29:14.960</a></span> | <span class="t">We do genuinely achieve with these maxim scores intuitive soft alignments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1760" target="_blank">00:29:20.120</a></span> | <span class="t">Here I have the query, when did the Transformers cartoon series come out?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1764" target="_blank">00:29:24.000</a></span> | <span class="t">And the response document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1765" target="_blank">00:29:25.680</a></span> | <span class="t">the animated Transformers was released in August 1986.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1769" target="_blank">00:29:29.480</a></span> | <span class="t">And these are proportional to actual maxim values query relative to document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1775" target="_blank">00:29:35.400</a></span> | <span class="t">The thickness of that line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1777" target="_blank">00:29:37.160</a></span> | <span class="t">And you can see that it is doing something very intuitive,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1780" target="_blank">00:29:40.080</a></span> | <span class="t">and also something very semantic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1782" target="_blank">00:29:42.440</a></span> | <span class="t">Because unlike term-based models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1784" target="_blank">00:29:44.240</a></span> | <span class="t">I don't have to do anything special to capture the fact that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1787" target="_blank">00:29:47.600</a></span> | <span class="t">come in the context of come out is a lot like released.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1792" target="_blank">00:29:52.400</a></span> | <span class="t">And similarly with when and that date.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1795" target="_blank">00:29:55.000</a></span> | <span class="t">Here I'm showing the two topmost maxim values,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1798" target="_blank">00:29:58.060</a></span> | <span class="t">and they're also very intuitive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1800" target="_blank">00:30:00.040</a></span> | <span class="t">And this is wonderful because IR has been so successful for so long,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1804" target="_blank">00:30:04.200</a></span> | <span class="t">doing term matching, and it is nice to see that intuition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1807" target="_blank">00:30:07.920</a></span> | <span class="t">carried forward into this more semantic space in my view.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1812" target="_blank">00:30:12.520</a></span> | <span class="t">So I can go up. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1814" target="_blank">00:30:14.880</a></span> | <span class="t">Is that matrix of like query to document mapping,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1819" target="_blank">00:30:19.760</a></span> | <span class="t">is that why the in-memory index is very purple there?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1823" target="_blank">00:30:23.360</a></span> | <span class="t">Yes. So your question is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1825" target="_blank">00:30:25.520</a></span> | <span class="t">why is the index for Colbert so big?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1827" target="_blank">00:30:27.840</a></span> | <span class="t">It is because we have to store every token level representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1832" target="_blank">00:30:32.080</a></span> | <span class="t">Yes. I'm gonna, I'm gonna show you that we can do better,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1834" target="_blank">00:30:34.360</a></span> | <span class="t">but naively storing these for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1836" target="_blank">00:30:36.960</a></span> | <span class="t">our entire document store is gonna be a lot of vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1840" target="_blank">00:30:40.600</a></span> | <span class="t">One per token, not one per type, one per token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1846" target="_blank">00:30:46.040</a></span> | <span class="t">Yeah. I have to pay somewhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1850" target="_blank">00:30:50.520</a></span> | <span class="t">I guess that's the insight. Yeah. Question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1853" target="_blank">00:30:53.240</a></span> | <span class="t">Maybe there's some intuition that can make this a little clearer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1857" target="_blank">00:30:57.280</a></span> | <span class="t">If the document has multiple variants of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1860" target="_blank">00:31:00.320</a></span> | <span class="t">of transformers or, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1862" target="_blank">00:31:02.200</a></span> | <span class="t">Decepticon, Optimus Prime or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1864" target="_blank">00:31:04.360</a></span> | <span class="t">they, they're all related to the original token transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1867" target="_blank">00:31:07.840</a></span> | <span class="t">Would you be able to kind of draw that link to all those other tokens as well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1872" target="_blank">00:31:12.040</a></span> | <span class="t">or would you have to pick,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1874" target="_blank">00:31:14.200</a></span> | <span class="t">I guess, one relationship?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1877" target="_blank">00:31:17.080</a></span> | <span class="t">Transformers is represented once.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1879" target="_blank">00:31:19.520</a></span> | <span class="t">I think that's a great question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1881" target="_blank">00:31:21.960</a></span> | <span class="t">So transformers, that's why I picked it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1883" target="_blank">00:31:23.960</a></span> | <span class="t">It's amusingly ambiguous between our model and the animated cartoon series.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1889" target="_blank">00:31:29.840</a></span> | <span class="t">Um, of my youth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1892" target="_blank">00:31:32.240</a></span> | <span class="t">So, but I think the point is that because it's BERT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1896" target="_blank">00:31:36.760</a></span> | <span class="t">transformers in this context will have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1899" target="_blank">00:31:39.320</a></span> | <span class="t">a very different representation from the one if we were talking about NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1903" target="_blank">00:31:43.200</a></span> | <span class="t">And that's why it's so good that we are using BERT because then we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1906" target="_blank">00:31:46.280</a></span> | <span class="t">get Maxims that are appropriately semantic. That is the hope.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1910" target="_blank">00:31:50.600</a></span> | <span class="t">Yeah. Whereas term-based models really gonna struggle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1913" target="_blank">00:31:53.560</a></span> | <span class="t">The best they're gonna be able to do is have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1915" target="_blank">00:31:55.840</a></span> | <span class="t">engrams that kind of capture the fact that this transformers is the cartoon series one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1921" target="_blank">00:32:01.840</a></span> | <span class="t">So another, actually, that's another argument in favor of being in a more semantic space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1928" target="_blank">00:32:08.760</a></span> | <span class="t">I want to just quickly talk with you about how we have worked to optimize Colbert,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1935" target="_blank">00:32:15.880</a></span> | <span class="t">because I think that this suggests things that you would want to do if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1938" target="_blank">00:32:18.600</a></span> | <span class="t">developed your own neural retrieval models because the hard truth here is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1943" target="_blank">00:32:23.080</a></span> | <span class="t">BM25 is blazingly fast and scalable and these neural models are not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1949" target="_blank">00:32:29.800</a></span> | <span class="t">You have to work much harder to get them to that point of being as performant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1953" target="_blank">00:32:33.240</a></span> | <span class="t">in terms of other dimensions beyond accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1956" target="_blank">00:32:36.660</a></span> | <span class="t">We could use Colbert as a re-ranker as I alluded to before, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1960" target="_blank">00:32:40.960</a></span> | <span class="t">So here I have all these token level representations which I do have to store,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1966" target="_blank">00:32:46.040</a></span> | <span class="t">and they're each connected to a document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1968" target="_blank">00:32:48.880</a></span> | <span class="t">Now, on- if used naively,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1971" target="_blank">00:32:51.400</a></span> | <span class="t">this will be not scalable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1973" target="_blank">00:32:53.080</a></span> | <span class="t">but I could do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1974" target="_blank">00:32:54.120</a></span> | <span class="t">Given some query, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1975" target="_blank">00:32:55.920</a></span> | <span class="t">that's represented as a sequence of tokens, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1979" target="_blank">00:32:59.080</a></span> | <span class="t">I could get the top k documents for it using like BM25 and then re-rank that top k.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1985" target="_blank">00:33:05.440</a></span> | <span class="t">[NOISE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1986" target="_blank">00:33:06.760</a></span> | <span class="t">And so if k is small,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1988" target="_blank">00:33:08.560</a></span> | <span class="t">I pay the full price of the Colbert model but only for k documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1992" target="_blank">00:33:12.840</a></span> | <span class="t">And you're hoping that BM25 did a good job of getting you to that initial point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=1998" target="_blank">00:33:18.240</a></span> | <span class="t">It's a very common application and it can be really meaningful to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2001" target="_blank">00:33:21.960</a></span> | <span class="t">re-rank that final set of k documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2005" target="_blank">00:33:25.280</a></span> | <span class="t">But we could do a little better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2006" target="_blank">00:33:26.960</a></span> | <span class="t">If we wanted to use Colbert end-to-end,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2008" target="_blank">00:33:28.760</a></span> | <span class="t">here's how we could work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2009" target="_blank">00:33:29.960</a></span> | <span class="t">We again store all those token level vectors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2013" target="_blank">00:33:33.020</a></span> | <span class="t">but now we're gonna kind of turn things around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2015" target="_blank">00:33:35.160</a></span> | <span class="t">We just need to keep track of those vectors and their associated documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2019" target="_blank">00:33:39.820</a></span> | <span class="t">For a query that we have encoded as a set of vectors using Colbert,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2024" target="_blank">00:33:44.840</a></span> | <span class="t">we take each query vector wi,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2027" target="_blank">00:33:47.940</a></span> | <span class="t">and we retrieve the p most token vectors from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2030" target="_blank">00:33:50.960</a></span> | <span class="t">this huge list that are similar to our target.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2034" target="_blank">00:33:54.360</a></span> | <span class="t">And that doesn't require the full Colbert model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2036" target="_blank">00:33:56.840</a></span> | <span class="t">That could just be a similarity calculation and you can do those really fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2041" target="_blank">00:34:01.400</a></span> | <span class="t">People have really optimized that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2043" target="_blank">00:34:03.200</a></span> | <span class="t">And then you get all the documents associated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2046" target="_blank">00:34:06.120</a></span> | <span class="t">with this small set of vectors that you found and you score them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2049" target="_blank">00:34:09.640</a></span> | <span class="t">So again, the name of the game is to use Colbert only very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2053" target="_blank">00:34:13.680</a></span> | <span class="t">sparingly in a final stage because it is so expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2058" target="_blank">00:34:18.780</a></span> | <span class="t">And then a third step here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2061" target="_blank">00:34:21.240</a></span> | <span class="t">just quickly, we can do even better and this is quite striking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2064" target="_blank">00:34:24.860</a></span> | <span class="t">What we can do is cluster our token level representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2068" target="_blank">00:34:28.940</a></span> | <span class="t">into their centroids using k-means clustering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2071" target="_blank">00:34:31.980</a></span> | <span class="t">That's what I've got in red here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2074" target="_blank">00:34:34.260</a></span> | <span class="t">And then use them as the basis for search.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2076" target="_blank">00:34:36.860</a></span> | <span class="t">So again, we encode our query into a series of vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2080" target="_blank">00:34:40.300</a></span> | <span class="t">And then for this target vector wi,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2083" target="_blank">00:34:43.060</a></span> | <span class="t">we first get the centroids that are closest to that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2086" target="_blank">00:34:46.340</a></span> | <span class="t">And this is important because in practice,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2088" target="_blank">00:34:48.620</a></span> | <span class="t">we can collect only like four centroids per token vector and do really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2094" target="_blank">00:34:54.740</a></span> | <span class="t">That's a tiny number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2096" target="_blank">00:34:56.420</a></span> | <span class="t">Then we get the t most similar token vectors to that centroid.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2101" target="_blank">00:35:01.580</a></span> | <span class="t">And then we finally do scoring on the associated documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2105" target="_blank">00:35:05.980</a></span> | <span class="t">And so by leaps and bounds here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2108" target="_blank">00:35:08.980</a></span> | <span class="t">we have reduced the amount of compute we need to do with this huge index</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2113" target="_blank">00:35:13.300</a></span> | <span class="t">by using the centroids and then using Colbert again very sparingly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2118" target="_blank">00:35:18.660</a></span> | <span class="t">Final thing and then I'll take some questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2122" target="_blank">00:35:22.020</a></span> | <span class="t">The team has worked very hard to reduce the latency of Colbert.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2125" target="_blank">00:35:25.940</a></span> | <span class="t">This is a latency analysis here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2127" target="_blank">00:35:27.900</a></span> | <span class="t">And the thing I want to point out to you is that the Colbert model steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2130" target="_blank">00:35:30.780</a></span> | <span class="t">actually for this second version,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2132" target="_blank">00:35:32.640</a></span> | <span class="t">the one I just described to you with the centroids,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2134" target="_blank">00:35:34.900</a></span> | <span class="t">that was actually a relatively small part of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2137" target="_blank">00:35:37.260</a></span> | <span class="t">the overall cost because it was being used so sparingly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2140" target="_blank">00:35:40.380</a></span> | <span class="t">The big costs were being in the- dealing with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2144" target="_blank">00:35:44.460</a></span> | <span class="t">the huge index and also doing work to quantize the vectors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2149" target="_blank">00:35:49.940</a></span> | <span class="t">so that they were easier to store on disk by making them smaller.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2153" target="_blank">00:35:53.520</a></span> | <span class="t">And so after a bunch of work with this framework called Plaid,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2157" target="_blank">00:35:57.580</a></span> | <span class="t">they were able to get rid of almost all of that index lookup and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2161" target="_blank">00:36:01.380</a></span> | <span class="t">de-quantization or decompression steps for the vectors that were costing so much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2165" target="_blank">00:36:05.900</a></span> | <span class="t">And they brought the latency down to like 58 milliseconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2170" target="_blank">00:36:10.620</a></span> | <span class="t">Which- so it went from something that is impossible to imagine deploying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2174" target="_blank">00:36:14.980</a></span> | <span class="t">industrially to something that is close to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2177" target="_blank">00:36:17.820</a></span> | <span class="t">what you might entertain as a possibility for deployment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2181" target="_blank">00:36:21.100</a></span> | <span class="t">And I- you know, the details are in the Plaid paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2183" target="_blank">00:36:23.900</a></span> | <span class="t">We can talk about them offline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2185" target="_blank">00:36:25.500</a></span> | <span class="t">I just wanted to call out that I think this is an incredible achievement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2189" target="_blank">00:36:29.100</a></span> | <span class="t">It is so clever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2190" target="_blank">00:36:30.980</a></span> | <span class="t">the set of things that they did to achieve this enormous improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2195" target="_blank">00:36:35.300</a></span> | <span class="t">So shout out to them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2196" target="_blank">00:36:36.580</a></span> | <span class="t">And it does mean that if you had heard a rumor that Colbert was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2200" target="_blank">00:36:40.580</a></span> | <span class="t">impractical to use because the index was too large and the latency was too long,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2204" target="_blank">00:36:44.620</a></span> | <span class="t">I think it's not true anymore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2206" target="_blank">00:36:46.500</a></span> | <span class="t">The indices are small because of quantization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2209" target="_blank">00:36:49.180</a></span> | <span class="t">and this is that picture of latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2211" target="_blank">00:36:51.300</a></span> | <span class="t">So give it a shot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2214" target="_blank">00:36:54.100</a></span> | <span class="t">I have one more model, but let me take questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2217" target="_blank">00:36:57.020</a></span> | <span class="t">Yeah. Did you have a question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2218" target="_blank">00:36:58.380</a></span> | <span class="t">Oh, sorry. I just had a question about the latency and also the predictor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2221" target="_blank">00:37:01.700</a></span> | <span class="t">Okay. Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2222" target="_blank">00:37:02.740</a></span> | <span class="t">Yeah, I'm happy to talk more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2223" target="_blank">00:37:03.860</a></span> | <span class="t">The Plaid paper is full of tricks and things like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2227" target="_blank">00:37:07.020</a></span> | <span class="t">I don't want to take up too much time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2228" target="_blank">00:37:08.580</a></span> | <span class="t">I definitely want to give Sid plenty of time to talk about models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2230" target="_blank">00:37:10.900</a></span> | <span class="t">So let me just show you one more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2232" target="_blank">00:37:12.340</a></span> | <span class="t">This is SPLADE. This is also ingenious.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2234" target="_blank">00:37:14.540</a></span> | <span class="t">It'll get you thinking in a new way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2236" target="_blank">00:37:16.420</a></span> | <span class="t">Okay. So for SPLADE,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2238" target="_blank">00:37:18.740</a></span> | <span class="t">I wrote sequence at the bottom because we're going to do this for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2241" target="_blank">00:37:21.780</a></span> | <span class="t">both queries and documents, this process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2244" target="_blank">00:37:24.780</a></span> | <span class="t">And crucially, here I have the vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2248" target="_blank">00:37:28.620</a></span> | <span class="t">I've only represented seven tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2250" target="_blank">00:37:30.560</a></span> | <span class="t">but if it was BERT, it would be like 30,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2252" target="_blank">00:37:32.980</a></span> | <span class="t">Okay. So we again process the text into the output states,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2258" target="_blank">00:37:38.540</a></span> | <span class="t">T1 through T3 there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2260" target="_blank">00:37:40.980</a></span> | <span class="t">And then we form all these scores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2264" target="_blank">00:37:44.020</a></span> | <span class="t">And the scores are determined by this thing here, that's SI sub J.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2268" target="_blank">00:37:48.420</a></span> | <span class="t">So we're going to apply a linear layer to the encoding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2271" target="_blank">00:37:51.900</a></span> | <span class="t">those output states, and we're going to combine it with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2275" target="_blank">00:37:55.500</a></span> | <span class="t">the embedding for these vocabulary items with a bias.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2279" target="_blank">00:37:59.300</a></span> | <span class="t">So if you strip away the details,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2281" target="_blank">00:38:01.060</a></span> | <span class="t">you can see that this is like a dot product of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2283" target="_blank">00:38:03.540</a></span> | <span class="t">these states with all of these values here in our vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2288" target="_blank">00:38:08.660</a></span> | <span class="t">And then SPLADE is the sum of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2292" target="_blank">00:38:12.060</a></span> | <span class="t">And so you can think of that as summing across all the document tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2295" target="_blank">00:38:15.260</a></span> | <span class="t">And so what we've got in that orange column there is a probably very sparse vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2302" target="_blank">00:38:22.140</a></span> | <span class="t">that represents this text down here with respect to our vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2309" target="_blank">00:38:29.260</a></span> | <span class="t">So this is a lot like term-based, uh, work of old, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2318" target="_blank">00:38:38.500</a></span> | <span class="t">This is a lot like a TF-IDF representation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2321" target="_blank">00:38:41.320</a></span> | <span class="t">except it was done in the neural space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2323" target="_blank">00:38:43.420</a></span> | <span class="t">So we should get the advantages of being with a semantic model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2328" target="_blank">00:38:48.180</a></span> | <span class="t">And then the similarity value is just the SPLADE representation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2332" target="_blank">00:38:52.580</a></span> | <span class="t">that is this representation here for the query dot product with the document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2337" target="_blank">00:38:57.820</a></span> | <span class="t">And the loss is the one that we've been using all along.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2342" target="_blank">00:39:02.100</a></span> | <span class="t">So just to be clear, so you do the SPLADE process both with the query and with the document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2351" target="_blank">00:39:11.140</a></span> | <span class="t">And then, okay, cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2352" target="_blank">00:39:12.940</a></span> | <span class="t">Yeah, that's it. There's a bunch of- it looks similar in my document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2355" target="_blank">00:39:15.980</a></span> | <span class="t">This is great. Let me review what you just said.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2357" target="_blank">00:39:17.660</a></span> | <span class="t">There's a bunch of new things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2358" target="_blank">00:39:18.860</a></span> | <span class="t">Sequence, not query or document because we do this for both kinds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2362" target="_blank">00:39:22.900</a></span> | <span class="t">And of course, we can do all the documents ahead of time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2366" target="_blank">00:39:26.180</a></span> | <span class="t">The big twist is that we're scoring these sequences with respect to the vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2371" target="_blank">00:39:31.140</a></span> | <span class="t">And we are essentially getting in semantic space because this is an embedding space here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2376" target="_blank">00:39:36.020</a></span> | <span class="t">and this is a contextual embedding space here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2378" target="_blank">00:39:38.500</a></span> | <span class="t">scores for each query term with respect to the whole vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2384" target="_blank">00:39:44.180</a></span> | <span class="t">That gives us this big,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2385" target="_blank">00:39:45.940</a></span> | <span class="t">presumably pretty sparse vector,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2387" target="_blank">00:39:47.980</a></span> | <span class="t">and their optimization further encourages sparsity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2391" target="_blank">00:39:51.300</a></span> | <span class="t">And then the similarity value is the dot product of those for queries and for documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2396" target="_blank">00:39:56.580</a></span> | <span class="t">So it has some hallmarks of late interaction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2399" target="_blank">00:39:59.860</a></span> | <span class="t">except it is interacting the text representations with the vocabulary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2405" target="_blank">00:40:05.220</a></span> | <span class="t">kind of like what you get with TF-IDF.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2408" target="_blank">00:40:08.300</a></span> | <span class="t">And this model is outstanding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2412" target="_blank">00:40:12.020</a></span> | <span class="t">You saw it in some of my doc- of my slides before, very impressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2416" target="_blank">00:40:16.860</a></span> | <span class="t">And it's also a new way of thinking, which I really like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2421" target="_blank">00:40:21.820</a></span> | <span class="t">Here's a bunch of more recent developments,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2424" target="_blank">00:40:24.780</a></span> | <span class="t">and one theme of them, I won't go through them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2426" target="_blank">00:40:26.620</a></span> | <span class="t">is just that people are working hard finally on making these models more efficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2431" target="_blank">00:40:31.780</a></span> | <span class="t">So a big theme of this is not just obsession with accuracy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2435" target="_blank">00:40:35.420</a></span> | <span class="t">but also obsession with especially latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2439" target="_blank">00:40:39.620</a></span> | <span class="t">And then finally, for that paper that I mentioned before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2443" target="_blank">00:40:43.300</a></span> | <span class="t">we did a bunch of systematic investigations of different approaches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2448" target="_blank">00:40:48.140</a></span> | <span class="t">You can see BM25, DPR, Colbert,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2450" target="_blank">00:40:50.780</a></span> | <span class="t">and some splayed models here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2452" target="_blank">00:40:52.540</a></span> | <span class="t">And these are all kind of variants of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2454" target="_blank">00:40:54.580</a></span> | <span class="t">these models where people have worked hard to optimize them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2457" target="_blank">00:40:57.580</a></span> | <span class="t">There's lots of tables like this in the paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2460" target="_blank">00:41:00.060</a></span> | <span class="t">Let me just draw out a few comparisons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2462" target="_blank">00:41:02.080</a></span> | <span class="t">BM25 is the only solution that could run on this tiny hardware here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2467" target="_blank">00:41:07.720</a></span> | <span class="t">We couldn't even run the other systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2469" target="_blank">00:41:09.900</a></span> | <span class="t">That's why it's alone in its own little block there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2472" target="_blank">00:41:12.580</a></span> | <span class="t">And it costs nothing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2475" target="_blank">00:41:15.260</a></span> | <span class="t">Right. But it's not that successful either.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2478" target="_blank">00:41:18.300</a></span> | <span class="t">Success at 10 is low relative to the rest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2481" target="_blank">00:41:21.060</a></span> | <span class="t">When we move here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2482" target="_blank">00:41:22.700</a></span> | <span class="t">this is sort of interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2484" target="_blank">00:41:24.260</a></span> | <span class="t">These two Colbert models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2486" target="_blank">00:41:26.500</a></span> | <span class="t">uh, achieve very similar performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2489" target="_blank">00:41:29.260</a></span> | <span class="t">If you look all the way to the right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2490" target="_blank">00:41:30.900</a></span> | <span class="t">except one of them is double the latency of the other one for this hardware.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2496" target="_blank">00:41:36.900</a></span> | <span class="t">And so you might wonder, do I really need this extra point of performance?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2502" target="_blank">00:41:42.300</a></span> | <span class="t">If I'm gonna have to wait that long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2504" target="_blank">00:41:44.620</a></span> | <span class="t">And then if you look to splayed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2506" target="_blank">00:41:46.540</a></span> | <span class="t">so splayed is below Colbert v2 small,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2510" target="_blank">00:41:50.180</a></span> | <span class="t">but its latency is a quarter or something of the Colbert v2 small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2517" target="_blank">00:41:57.780</a></span> | <span class="t">So maybe you care more about that and not so much about the success.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2521" target="_blank">00:42:01.380</a></span> | <span class="t">And then if you compare these two splayed, right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2523" target="_blank">00:42:03.780</a></span> | <span class="t">they have the same performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2525" target="_blank">00:42:05.540</a></span> | <span class="t">But if you just jack up the hardware a little bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2529" target="_blank">00:42:09.580</a></span> | <span class="t">then you get much lower latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2533" target="_blank">00:42:13.140</a></span> | <span class="t">But look how much the price went up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2536" target="_blank">00:42:16.660</a></span> | <span class="t">It went up for all of them with this heavy duty hardware.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2540" target="_blank">00:42:20.420</a></span> | <span class="t">Uh, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2542" target="_blank">00:42:22.500</a></span> | <span class="t">So this is the space that you're actually operating in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2545" target="_blank">00:42:25.020</a></span> | <span class="t">I'll- we'll talk later about how we might more systematically integrate all these scores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2549" target="_blank">00:42:29.940</a></span> | <span class="t">I think this is enough now to get you thinking about all of these dimensions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2553" target="_blank">00:42:33.860</a></span> | <span class="t">And-</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2554" target="_blank">00:42:34.180</a></span> | <span class="t">[inaudible]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2555" target="_blank">00:42:35.980</a></span> | <span class="t">They are the Plaid Colbert.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2557" target="_blank">00:42:37.140</a></span> | <span class="t">Yeah. Pretty expensive there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2558" target="_blank">00:42:38.900</a></span> | <span class="t">Luckily, in the paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2560" target="_blank">00:42:40.020</a></span> | <span class="t">we show that you never need a GPU for Colbert, I believe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2562" target="_blank">00:42:42.900</a></span> | <span class="t">You just- so you can always use cheaper hardware.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2565" target="_blank">00:42:45.860</a></span> | <span class="t">Yeah. But those costs do look scary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2569" target="_blank">00:42:49.300</a></span> | <span class="t">[LAUGHTER]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2572" target="_blank">00:42:52.180</a></span> | <span class="t">The final section of this is just some datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2574" target="_blank">00:42:54.220</a></span> | <span class="t">I think I don't need to go through it because you have it as a resource.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2576" target="_blank">00:42:56.660</a></span> | <span class="t">If you want to get started in neural information retrieval,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2579" target="_blank">00:42:59.500</a></span> | <span class="t">you've got T-REC, MS Marko,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2582" target="_blank">00:43:02.140</a></span> | <span class="t">and then there are a bunch of new benchmarks that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2584" target="_blank">00:43:04.420</a></span> | <span class="t">designed to assess systems out of the box, that is zero-shot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2587" target="_blank">00:43:07.540</a></span> | <span class="t">Beer is great. Latte is great for long-tailed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2591" target="_blank">00:43:11.260</a></span> | <span class="t">topic stratified evaluation, and then this XOR tie-dye is cool because this is multilingual.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2597" target="_blank">00:43:17.140</a></span> | <span class="t">And I know you have expressed interest in multilingual stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2600" target="_blank">00:43:20.060</a></span> | <span class="t">This could be a great playground for doing that with kind of QA and retrieval,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2604" target="_blank">00:43:24.260</a></span> | <span class="t">like open QA as we've been doing it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2606" target="_blank">00:43:26.860</a></span> | <span class="t">Bunch of other topics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2609" target="_blank">00:43:29.140</a></span> | <span class="t">I think the bottom line here is just,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2612" target="_blank">00:43:32.820</a></span> | <span class="t">again, this is like a refrain in this class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2615" target="_blank">00:43:35.620</a></span> | <span class="t">NLU and IR are back together again after being apart for so long,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2620" target="_blank">00:43:40.340</a></span> | <span class="t">and this is having profound implications for research and technology development.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2624" target="_blank">00:43:44.860</a></span> | <span class="t">So this is absolutely a very exciting moment to participate in this research because there is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2630" target="_blank">00:43:50.420</a></span> | <span class="t">so much innovation yet to happen and it is having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2634" target="_blank">00:43:54.060</a></span> | <span class="t">such an impact on research and also out in the wider world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2639" target="_blank">00:43:59.100</a></span> | <span class="t">Excellent. All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2641" target="_blank">00:44:01.540</a></span> | <span class="t">Sid, want to take over?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2643" target="_blank">00:44:03.260</a></span> | <span class="t">So it's cool. It's like retrieval isn't just hitting NLU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2646" target="_blank">00:44:06.380</a></span> | <span class="t">it's hitting everywhere, like vision and robotics as of like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2650" target="_blank">00:44:10.260</a></span> | <span class="t">this week we're starting to use retrieval methods to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2653" target="_blank">00:44:13.660</a></span> | <span class="t">What's the best way to figure out how to do a new task?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2656" target="_blank">00:44:16.820</a></span> | <span class="t">Maybe retrieve some examples of a robot or a human doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2660" target="_blank">00:44:20.460</a></span> | <span class="t">the same task and then generating your actions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2663" target="_blank">00:44:23.060</a></span> | <span class="t">So cool stuff. Cool. All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2667" target="_blank">00:44:27.860</a></span> | <span class="t">Let's see if this works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2670" target="_blank">00:44:30.580</a></span> | <span class="t">Yeah. All right. So I'm going to kind of pick up or try to pick up where I left off</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2679" target="_blank">00:44:39.060</a></span> | <span class="t">last week and kind of give you this evolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2681" target="_blank">00:44:41.820</a></span> | <span class="t">this history lesson on how we got to the transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2685" target="_blank">00:44:45.420</a></span> | <span class="t">and then go from there into tips and tricks for training big models generally,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2690" target="_blank">00:44:50.620</a></span> | <span class="t">and then end with like a small little teaser on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2693" target="_blank">00:44:53.020</a></span> | <span class="t">fine tuning and parameter efficient tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2696" target="_blank">00:44:56.060</a></span> | <span class="t">So you can use that in your projects down the road.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2698" target="_blank">00:44:58.780</a></span> | <span class="t">Cool. So just to kind of blaze past things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2701" target="_blank">00:45:01.780</a></span> | <span class="t">I kind of started by talking through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2704" target="_blank">00:45:04.980</a></span> | <span class="t">where things were pre-2017 when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2707" target="_blank">00:45:07.740</a></span> | <span class="t">the transformer paper came out on both the RNN and the CNN side,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2711" target="_blank">00:45:11.340</a></span> | <span class="t">and tied a lot of the innovation around the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2715" target="_blank">00:45:15.380</a></span> | <span class="t">to how modern convolutional neural nets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2720" target="_blank">00:45:20.500</a></span> | <span class="t">specifically residual nets were working,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2722" target="_blank">00:45:22.300</a></span> | <span class="t">and the connections there were closer than the connections to RNNs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2726" target="_blank">00:45:26.300</a></span> | <span class="t">Kind of walk through how we got to the self-attention block with this fancy code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2731" target="_blank">00:45:31.860</a></span> | <span class="t">which is basically just saying like you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2733" target="_blank">00:45:33.580</a></span> | <span class="t">splitting your heads and you can kind of think of your heads in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2736" target="_blank">00:45:36.300</a></span> | <span class="t">a self-attention block as the different kind of kernels or filters in a CNN layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2741" target="_blank">00:45:41.460</a></span> | <span class="t">Then kind of closing with like this full self-attention block,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2745" target="_blank">00:45:45.860</a></span> | <span class="t">where we're actually doing the RNN style attention,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2748" target="_blank">00:45:48.500</a></span> | <span class="t">and then this question of this non-linearity that we're adding at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2752" target="_blank">00:45:52.500</a></span> | <span class="t">Because without this non-linearity and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2754" target="_blank">00:45:54.780</a></span> | <span class="t">this sort of MLP that we're adding to the end of each transformer block,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2758" target="_blank">00:45:58.180</a></span> | <span class="t">we're really just doing weighted averages of linear transforms of values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2762" target="_blank">00:46:02.820</a></span> | <span class="t">Okay. So, if we kind of take this as ground truth,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2769" target="_blank">00:46:09.060</a></span> | <span class="t">starting point for what a transformer block looks like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2772" target="_blank">00:46:12.140</a></span> | <span class="t">very much inspired by the ideas of CNNs and RNNs with attention at the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2777" target="_blank">00:46:17.580</a></span> | <span class="t">We have this residual connection here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2780" target="_blank">00:46:20.740</a></span> | <span class="t">which is kind of just adding X over and over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2783" target="_blank">00:46:23.380</a></span> | <span class="t">again as we stack more and more layers together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2785" target="_blank">00:46:25.860</a></span> | <span class="t">There's a problem. Can anyone spot the problem in this implementation by itself?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2791" target="_blank">00:46:31.420</a></span> | <span class="t">So, the problem is that activations blow up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2794" target="_blank">00:46:34.700</a></span> | <span class="t">We keep adding the same input over and over again as we go deeper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2798" target="_blank">00:46:38.980</a></span> | <span class="t">Eventually, specifically in the RNN attention layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2803" target="_blank">00:46:43.700</a></span> | <span class="t">when we take this dot product between the queries and the keys,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2806" target="_blank">00:46:46.460</a></span> | <span class="t">we're going to get overflow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2808" target="_blank">00:46:48.260</a></span> | <span class="t">So, we need to do something about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2811" target="_blank">00:46:51.020</a></span> | <span class="t">All right. So, while the first part of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2813" target="_blank">00:46:53.340</a></span> | <span class="t">kind of building the transformer layer is very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2814" target="_blank">00:46:54.940</a></span> | <span class="t">very much inspired by history,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2816" target="_blank">00:46:56.680</a></span> | <span class="t">the second part is just trying to make sure it doesn't fail,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2819" target="_blank">00:46:59.620</a></span> | <span class="t">and doesn't blow up, and doesn't crash when we try training it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2822" target="_blank">00:47:02.300</a></span> | <span class="t">So, what's one thing that we can do to kind of avoid</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2825" target="_blank">00:47:05.140</a></span> | <span class="t">this sort of blow up of our activations?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2829" target="_blank">00:47:09.540</a></span> | <span class="t">So, layer normalization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2831" target="_blank">00:47:11.260</a></span> | <span class="t">So, layer normalization, maybe batch norm and layer norm were covered earlier on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2836" target="_blank">00:47:16.180</a></span> | <span class="t">is a very, very simple idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2837" target="_blank">00:47:17.900</a></span> | <span class="t">Along each feature dimension,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2839" target="_blank">00:47:19.540</a></span> | <span class="t">we're just going to normalize so that each feature has mean zero,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2843" target="_blank">00:47:23.340</a></span> | <span class="t">standard deviation one, which means that every time we add a residual connection,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2848" target="_blank">00:47:28.300</a></span> | <span class="t">we're going to normalize so that everything comes back to a decent space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2851" target="_blank">00:47:31.300</a></span> | <span class="t">We're still able to learn the kind of same level of expressivity we care about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2855" target="_blank">00:47:35.140</a></span> | <span class="t">We're just not necessarily going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2857" target="_blank">00:47:37.900</a></span> | <span class="t">keep blowing up or growing the magnitude of our activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2861" target="_blank">00:47:41.660</a></span> | <span class="t">What that looks like is two calls to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2865" target="_blank">00:47:45.860</a></span> | <span class="t">NN dot layer norm with the dimensionality of our transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2869" target="_blank">00:47:49.660</a></span> | <span class="t">and then adding that into a res block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2871" target="_blank">00:47:51.940</a></span> | <span class="t">We're just going to normalize each X before we pass it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2874" target="_blank">00:47:54.300</a></span> | <span class="t">into the attention and the MLP layers respectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2877" target="_blank">00:47:57.420</a></span> | <span class="t">Now, there's a problem with this that isn't obvious,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2880" target="_blank">00:48:00.860</a></span> | <span class="t">and actually wasn't obvious to the people building transformers at the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2883" target="_blank">00:48:03.580</a></span> | <span class="t">It wasn't really explained kind of till three years later,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2886" target="_blank">00:48:06.900</a></span> | <span class="t">which is that you have optimization issues when you do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2892" target="_blank">00:48:12.340</a></span> | <span class="t">Specifically, if you just try to optimize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2894" target="_blank">00:48:14.300</a></span> | <span class="t">the naive transformer with this layer norm in place,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2897" target="_blank">00:48:17.420</a></span> | <span class="t">with kind of conventional ML wisdom,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2899" target="_blank">00:48:19.500</a></span> | <span class="t">which is like learning rate decay or a constant learning rate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2903" target="_blank">00:48:23.900</a></span> | <span class="t">bad things happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2905" target="_blank">00:48:25.740</a></span> | <span class="t">Specifically, I'm going to use the hugging face emojis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2907" target="_blank">00:48:27.980</a></span> | <span class="t">my stand in for a transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2910" target="_blank">00:48:30.180</a></span> | <span class="t">Stuff happens. The optimization crashes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2913" target="_blank">00:48:33.500</a></span> | <span class="t">It's either exploding gradients,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2915" target="_blank">00:48:35.300</a></span> | <span class="t">it's either vanishing gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2916" target="_blank">00:48:36.340</a></span> | <span class="t">If you ask someone in 2018 or 2019 or 2020,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2918" target="_blank">00:48:38.540</a></span> | <span class="t">they would tell you one or the other is happening,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2920" target="_blank">00:48:40.740</a></span> | <span class="t">but there are definitely no gradients that are like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2922" target="_blank">00:48:42.380</a></span> | <span class="t">stable throughout the training process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2924" target="_blank">00:48:44.660</a></span> | <span class="t">So, you introduce this kind of weird thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2927" target="_blank">00:48:47.580</a></span> | <span class="t">It kind of comes out of almost nowhere,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2929" target="_blank">00:48:49.540</a></span> | <span class="t">which is like this transform,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2930" target="_blank">00:48:50.980</a></span> | <span class="t">this like warm-up schedule that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2934" target="_blank">00:48:54.100</a></span> | <span class="t">see a lot of the time in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2937" target="_blank">00:48:57.020</a></span> | <span class="t">like any code for training or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2938" target="_blank">00:48:58.500</a></span> | <span class="t">even fine-tuning transformers these days.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2940" target="_blank">00:49:00.540</a></span> | <span class="t">Now, this is actually just like fun because I have the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2944" target="_blank">00:49:04.060</a></span> | <span class="t">I'm going to like go through it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2945" target="_blank">00:49:05.660</a></span> | <span class="t">Who came up with this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2947" target="_blank">00:49:07.980</a></span> | <span class="t">>> I'm thinking, like I think I remember in the [inaudible] paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2961" target="_blank">00:49:21.100</a></span> | <span class="t">they had like a weird learning rate, but I don't remember.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2963" target="_blank">00:49:23.380</a></span> | <span class="t">>> So, it is in the original transformer papers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2966" target="_blank">00:49:26.300</a></span> | <span class="t">like the main thing that they get to get this stable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2968" target="_blank">00:49:28.980</a></span> | <span class="t">So, it's one of the authors that came up with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2970" target="_blank">00:49:30.940</a></span> | <span class="t">But if you actually run a Git blame</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2973" target="_blank">00:49:33.580</a></span> | <span class="t">on the first ever transformer code base from Google,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2975" target="_blank">00:49:35.780</a></span> | <span class="t">the Tensor2Tensor code base,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2977" target="_blank">00:49:37.220</a></span> | <span class="t">like in the very first commit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2979" target="_blank">00:49:39.100</a></span> | <span class="t">in like the R parse like flags for the different optimizers you use,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2984" target="_blank">00:49:44.340</a></span> | <span class="t">there's one option just called Gnome, after Gnome Shazier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2987" target="_blank">00:49:47.540</a></span> | <span class="t">And in the annotated transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2989" target="_blank">00:49:49.460</a></span> | <span class="t">like the very first like block host,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2990" target="_blank">00:49:50.820</a></span> | <span class="t">that's what the optimizer is called.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2992" target="_blank">00:49:52.020</a></span> | <span class="t">It's called Gnome Opt in Sasha Rush's code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2994" target="_blank">00:49:54.700</a></span> | <span class="t">And it's called the Gnome Optimizer for a really long time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2997" target="_blank">00:49:57.620</a></span> | <span class="t">until they just decided to call it just like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=2999" target="_blank">00:49:59.580</a></span> | <span class="t">you know, linear warmup, cosine decay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3002" target="_blank">00:50:02.460</a></span> | <span class="t">And so, Gnome Shazier kind of came up with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3005" target="_blank">00:50:05.420</a></span> | <span class="t">And if you were to kind of go back and think about like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3008" target="_blank">00:50:08.340</a></span> | <span class="t">the sorts of problems and the papers he was working on at the time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3011" target="_blank">00:50:11.820</a></span> | <span class="t">he was actually doing a lot of stuff with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3013" target="_blank">00:50:13.820</a></span> | <span class="t">the different types of like gradient descent optimizers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3019" target="_blank">00:50:19.660</a></span> | <span class="t">like RMSProp, Adafactor came out like a year after the transformer paper came out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3025" target="_blank">00:50:25.060</a></span> | <span class="t">And he was really like interested in like looking at this problem of like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3028" target="_blank">00:50:28.060</a></span> | <span class="t">"Huh, okay, weights seem to be where like if you just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3030" target="_blank">00:50:30.900</a></span> | <span class="t">really inspect the gradients early on with like this layer norm thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3034" target="_blank">00:50:34.340</a></span> | <span class="t">variance seems to be high and you kind of want to burn that in."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3037" target="_blank">00:50:37.580</a></span> | <span class="t">And he's seeing this for LSTM,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3038" target="_blank">00:50:38.900</a></span> | <span class="t">so he's kind of doing this already for his LSTM work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3042" target="_blank">00:50:42.460</a></span> | <span class="t">And then he just like, "Let's try this."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3046" target="_blank">00:50:46.020</a></span> | <span class="t">It worked and no one really questioned it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3048" target="_blank">00:50:48.620</a></span> | <span class="t">It breaks conventional machine learning wisdom,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3050" target="_blank">00:50:50.940</a></span> | <span class="t">like why am I warming up my learning rate before I'm bringing it down, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3053" target="_blank">00:50:53.820</a></span> | <span class="t">Like if I'm optimizing some surface,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3055" target="_blank">00:50:55.420</a></span> | <span class="t">I kind of like want to start kind of high,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3057" target="_blank">00:50:57.660</a></span> | <span class="t">move in, and then like maybe anneal it as I get closer to my minimum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3061" target="_blank">00:51:01.860</a></span> | <span class="t">But no one is able to explain why,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3064" target="_blank">00:51:04.900</a></span> | <span class="t">till three years later, a paper comes out that kind of like steps through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3069" target="_blank">00:51:09.580</a></span> | <span class="t">the specifics of training a transformer model on some data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3073" target="_blank">00:51:13.340</a></span> | <span class="t">like synthetic data with the atom optimizer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3076" target="_blank">00:51:16.260</a></span> | <span class="t">and actually tie it to the layer normalization layers that we just added.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3080" target="_blank">00:51:20.060</a></span> | <span class="t">We fixed one problem, we added another.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3081" target="_blank">00:51:21.860</a></span> | <span class="t">Right. So up top, we have kind of good gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3085" target="_blank">00:51:25.180</a></span> | <span class="t">Right. So on the left here is the gradient magnitude and here's the update magnitude.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3089" target="_blank">00:51:29.020</a></span> | <span class="t">So the gradients that are computed and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3090" target="_blank">00:51:30.820</a></span> | <span class="t">the updates that are actually applied to the weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3092" target="_blank">00:51:32.700</a></span> | <span class="t">With warm up in blue,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3094" target="_blank">00:51:34.220</a></span> | <span class="t">in red, we have the same thing but without warm up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3097" target="_blank">00:51:37.420</a></span> | <span class="t">And what ends up happening is that gradients go to zero somehow as you train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3101" target="_blank">00:51:41.820</a></span> | <span class="t">It's actually a weird graph because like as you're coming forward in time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3105" target="_blank">00:51:45.020</a></span> | <span class="t">it's like as you're training more and more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3107" target="_blank">00:51:47.180</a></span> | <span class="t">So this is kind of like starting out and then like this is kind of, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3111" target="_blank">00:51:51.620</a></span> | <span class="t">And this is kind of like towards the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3114" target="_blank">00:51:54.420</a></span> | <span class="t">you know, wherever training becomes unstable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3117" target="_blank">00:51:57.380</a></span> | <span class="t">And then your updates also become super high variance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3120" target="_blank">00:52:00.860</a></span> | <span class="t">So they do some math and they kind of bound the update as a kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3127" target="_blank">00:52:07.020</a></span> | <span class="t">like proportional to the dimensionality of the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3131" target="_blank">00:52:11.540</a></span> | <span class="t">or the square root of the dimensionality of your transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3133" target="_blank">00:52:13.780</a></span> | <span class="t">over the input norm that's coming in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3136" target="_blank">00:52:16.100</a></span> | <span class="t">So if your input norm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3137" target="_blank">00:52:17.460</a></span> | <span class="t">like if the size of your activation is like sufficiently large,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3141" target="_blank">00:52:21.940</a></span> | <span class="t">your layer norm gradient is going to be completely, completely screwed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3148" target="_blank">00:52:28.820</a></span> | <span class="t">So what they end up doing is like, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3151" target="_blank">00:52:31.780</a></span> | <span class="t">so warm up is necessary because it helps you get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3155" target="_blank">00:52:35.780</a></span> | <span class="t">the atom optimizer to kind of like move slowly enough at the beginning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3160" target="_blank">00:52:40.900</a></span> | <span class="t">So that we're kind of like saturating the gradients, we're like, okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3164" target="_blank">00:52:44.940</a></span> | <span class="t">And then when we kind of go full throttle,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3166" target="_blank">00:52:46.700</a></span> | <span class="t">like things are generally stable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3168" target="_blank">00:52:48.780</a></span> | <span class="t">The activations norms aren't changing all too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3173" target="_blank">00:52:53.740</a></span> | <span class="t">They're changing in a predictable way and we can kind of start to handle that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3176" target="_blank">00:52:56.540</a></span> | <span class="t">and then conventional ML kicks in. But it's weird.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3180" target="_blank">00:53:00.340</a></span> | <span class="t">And it's also weird that it took three years later,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3182" target="_blank">00:53:02.340</a></span> | <span class="t">and some people still don't buy this explanation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3184" target="_blank">00:53:04.340</a></span> | <span class="t">but it's the best explanation I've got to why we need that warm up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3187" target="_blank">00:53:07.220</a></span> | <span class="t">So general wisdom,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3189" target="_blank">00:53:09.700</a></span> | <span class="t">you're fine tuning or pre-training a transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3191" target="_blank">00:53:11.980</a></span> | <span class="t">warm up for at least five percent of your full training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3194" target="_blank">00:53:14.660</a></span> | <span class="t">and then start decaying. It just helps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3197" target="_blank">00:53:17.580</a></span> | <span class="t">>> Can I ask this? I don't know this paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3200" target="_blank">00:53:20.660</a></span> | <span class="t">So is there some data dependency or some assumption about what the data will be like?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3206" target="_blank">00:53:26.220</a></span> | <span class="t">Because it seems like you said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3207" target="_blank">00:53:27.700</a></span> | <span class="t">hey look, after a while we can relax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3209" target="_blank">00:53:29.780</a></span> | <span class="t">These updates are small or reasonable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3213" target="_blank">00:53:33.140</a></span> | <span class="t">but the world could do a lot to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3215" target="_blank">00:53:35.100</a></span> | <span class="t">And if you shifted genres or data types,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3218" target="_blank">00:53:38.100</a></span> | <span class="t">it would go back into being very unstable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3220" target="_blank">00:53:40.700</a></span> | <span class="t">>> Yeah. So I think in this paper they're looking at what I'll call nice datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3225" target="_blank">00:53:45.300</a></span> | <span class="t">They're looking at the Wikitext 2s of the world that are somewhat predictable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3228" target="_blank">00:53:48.700</a></span> | <span class="t">It's all Wikipedia homogenized language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3231" target="_blank">00:53:51.100</a></span> | <span class="t">But even when you're training the modern,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3233" target="_blank">00:53:53.060</a></span> | <span class="t">like the really big transformer these days,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3234" target="_blank">00:53:54.980</a></span> | <span class="t">even after all of these tricks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3236" target="_blank">00:53:56.620</a></span> | <span class="t">you're still going to have bad batches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3239" target="_blank">00:53:59.060</a></span> | <span class="t">Just really, really unpredictable things that are low likelihood under your model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3243" target="_blank">00:54:03.660</a></span> | <span class="t">that are going to cause big updates in the middle of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3245" target="_blank">00:54:05.100</a></span> | <span class="t">training that are going to completely crash your run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3247" target="_blank">00:54:07.380</a></span> | <span class="t">So this happened tons of times while we were training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3249" target="_blank">00:54:09.020</a></span> | <span class="t">like the 355 million parameter models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3251" target="_blank">00:54:11.300</a></span> | <span class="t">This happened every time you're training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3253" target="_blank">00:54:13.900</a></span> | <span class="t">any big model in like the one million plus parameter range.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3256" target="_blank">00:54:16.940</a></span> | <span class="t">So the Luther AI folks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3258" target="_blank">00:54:18.500</a></span> | <span class="t">like this happens all of the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3260" target="_blank">00:54:20.180</a></span> | <span class="t">The T5 models have this thing in like one of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3264" target="_blank">00:54:24.020</a></span> | <span class="t">the notes in like the GitHub repository for like training a T5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3267" target="_blank">00:54:27.660</a></span> | <span class="t">which is like, if training fails,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3269" target="_blank">00:54:29.940</a></span> | <span class="t">rewind to the latest checkpoint,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3271" target="_blank">00:54:31.500</a></span> | <span class="t">re-randomize your data order and then try again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3273" target="_blank">00:54:33.820</a></span> | <span class="t">and it won't crash.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3275" target="_blank">00:54:35.140</a></span> | <span class="t">That's kind of how modern ML or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3278" target="_blank">00:54:38.420</a></span> | <span class="t">most modern language models are trained right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3282" target="_blank">00:54:42.060</a></span> | <span class="t">We don't know how to avoid it yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3283" target="_blank">00:54:43.740</a></span> | <span class="t">We think it's tied to the data, we can't isolate it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3285" target="_blank">00:54:45.940</a></span> | <span class="t">So why not just re-roll and try again?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3289" target="_blank">00:54:49.340</a></span> | <span class="t">Eventually, you'll just keep making progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3291" target="_blank">00:54:51.740</a></span> | <span class="t">Cool. So question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3295" target="_blank">00:54:55.980</a></span> | <span class="t">>> Back to the graphs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3297" target="_blank">00:54:57.220</a></span> | <span class="t">what do the different colors represent in-</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3300" target="_blank">00:55:00.740</a></span> | <span class="t">>> Yeah. So the question was,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3302" target="_blank">00:55:02.220</a></span> | <span class="t">what the different colors represent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3303" target="_blank">00:55:03.660</a></span> | <span class="t">So up top is blue with the traditional transformer learning rate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3308" target="_blank">00:55:08.060</a></span> | <span class="t">so warm up and then go down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3310" target="_blank">00:55:10.780</a></span> | <span class="t">Red is the no warm up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3314" target="_blank">00:55:14.420</a></span> | <span class="t">let's just start the learning rate high and then taper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3316" target="_blank">00:55:16.820</a></span> | <span class="t">So red is bad, blue is good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3320" target="_blank">00:55:20.060</a></span> | <span class="t">>> [inaudible]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3326" target="_blank">00:55:26.660</a></span> | <span class="t">>> Yeah. So the way you can interpret this graph,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3329" target="_blank">00:55:29.020</a></span> | <span class="t">and the paper's linked in at the bottom of the slide,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3331" target="_blank">00:55:31.980</a></span> | <span class="t">but you can think of the furthest back magnitude is like this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3336" target="_blank">00:55:36.820</a></span> | <span class="t">basically plotting the mean standard deviation of the updates across layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3341" target="_blank">00:55:41.540</a></span> | <span class="t">The furthest back is like batch zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3344" target="_blank">00:55:44.700</a></span> | <span class="t">As you get further in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3347" target="_blank">00:55:47.300</a></span> | <span class="t">you get to batch 100 or batch 400 or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3351" target="_blank">00:55:51.260</a></span> | <span class="t">Yeah. Question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3354" target="_blank">00:55:54.580</a></span> | <span class="t">>> I wonder to what extent the warm up and the rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3360" target="_blank">00:56:00.060</a></span> | <span class="t">>> I think I'm relating to the choice of optimizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3365" target="_blank">00:56:05.540</a></span> | <span class="t">Because I've run into some problems where I found that using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3371" target="_blank">00:56:11.060</a></span> | <span class="t">AtomX of the infinity norm will work because I've got this level of dropout or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3375" target="_blank">00:56:15.740</a></span> | <span class="t">Is there any guidance of all these big hyperparameters that go into this tune,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3381" target="_blank">00:56:21.580</a></span> | <span class="t">where if I pull one lever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3383" target="_blank">00:56:23.580</a></span> | <span class="t">I should be pushing one down or choose this optimizer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3386" target="_blank">00:56:26.380</a></span> | <span class="t">I should do another because it feels like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3388" target="_blank">00:56:28.260</a></span> | <span class="t">I mean, taking three years,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3391" target="_blank">00:56:31.580</a></span> | <span class="t">it feels a little bit like the Wild West, which is what it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3394" target="_blank">00:56:34.820</a></span> | <span class="t">>> Yeah. So if I were to paraphrase your question,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3398" target="_blank">00:56:38.540</a></span> | <span class="t">it's like, if you decide to change anything about the current recipe,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3402" target="_blank">00:56:42.380</a></span> | <span class="t">like change your optimizer, change dropout, change your learning rate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3405" target="_blank">00:56:45.220</a></span> | <span class="t">are there rules of thumb for what else you need to change to get things to work?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3410" target="_blank">00:56:50.060</a></span> | <span class="t">No. It is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3414" target="_blank">00:56:54.820</a></span> | <span class="t">So part of why I led with how we got to here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3420" target="_blank">00:57:00.500</a></span> | <span class="t">starting from the historical context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3422" target="_blank">00:57:02.500</a></span> | <span class="t">was to unpack a lot of this folk knowledge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3425" target="_blank">00:57:05.620</a></span> | <span class="t">Because it's still at the point where optimizing these models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3428" target="_blank">00:57:08.980</a></span> | <span class="t">especially as we go bigger,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3430" target="_blank">00:57:10.660</a></span> | <span class="t">is still concentrated in the minds and experience of a very small number of people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3436" target="_blank">00:57:16.820</a></span> | <span class="t">Because who's trained a seven billion parameter language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3439" target="_blank">00:57:19.460</a></span> | <span class="t">or who's trained a 100 billion parameter language model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3441" target="_blank">00:57:21.900</a></span> | <span class="t">Where does that skill set come from?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3443" target="_blank">00:57:23.340</a></span> | <span class="t">When you're talking about a training run that cost millions of dollars to develop,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3448" target="_blank">00:57:28.180</a></span> | <span class="t">plus however much the compute costs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3451" target="_blank">00:57:31.340</a></span> | <span class="t">how many things are you really going to be trying at the end?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3454" target="_blank">00:57:34.300</a></span> | <span class="t">What things can you extrapolate from?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3456" target="_blank">00:57:36.740</a></span> | <span class="t">So folks at OpenAI have definitely done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3458" target="_blank">00:57:38.740</a></span> | <span class="t">like scaling laws research where they're trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3460" target="_blank">00:57:40.500</a></span> | <span class="t">these different things in some bounded search space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3463" target="_blank">00:57:43.420</a></span> | <span class="t">But if you were to invent like a brand new optimizer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3466" target="_blank">00:57:46.100</a></span> | <span class="t">it kind of looks at like maybe second,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3467" target="_blank">00:57:47.780</a></span> | <span class="t">third, fourth order moments of your gradients,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3471" target="_blank">00:57:51.300</a></span> | <span class="t">maybe do something fancy relative to how things are changing over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3475" target="_blank">00:57:55.860</a></span> | <span class="t">And you were to just try and apply it to the biggest language model you could train,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3480" target="_blank">00:58:00.740</a></span> | <span class="t">I have no idea what I would tell you in terms of like what things you should change,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3485" target="_blank">00:58:05.100</a></span> | <span class="t">beyond like some obvious things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3486" target="_blank">00:58:06.220</a></span> | <span class="t">like maybe don't set the learning rate to be ridiculously high.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3489" target="_blank">00:58:09.140</a></span> | <span class="t">Starting now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3490" target="_blank">00:58:10.340</a></span> | <span class="t">>> If you have a batch of data that's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3496" target="_blank">00:58:16.380</a></span> | <span class="t">let's just say during training you come across a bad batch of data that happens to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3500" target="_blank">00:58:20.300</a></span> | <span class="t">cause like the destabilization with the gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3503" target="_blank">00:58:23.700</a></span> | <span class="t">And then you rewind back to your checkpoint and you take that same exact batch of data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3508" target="_blank">00:58:28.020</a></span> | <span class="t">but instead of running it through training when gradients are enabled,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3512" target="_blank">00:58:32.580</a></span> | <span class="t">if you just run it through inference,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3514" target="_blank">00:58:34.460</a></span> | <span class="t">will that bad batch of data have caused like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3517" target="_blank">00:58:37.500</a></span> | <span class="t">anomalous behavior from the model during inference,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3521" target="_blank">00:58:41.060</a></span> | <span class="t">or is it strictly just a back propagation issue?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3523" target="_blank">00:58:43.580</a></span> | <span class="t">>> So when we debug or when we debug this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3527" target="_blank">00:58:47.140</a></span> | <span class="t">so we a couple of years ago trained like some,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3530" target="_blank">00:58:50.980</a></span> | <span class="t">by today's standards, really,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3532" target="_blank">00:58:52.500</a></span> | <span class="t">really small language models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3533" target="_blank">00:58:53.660</a></span> | <span class="t">but like 124 million to 355 million scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3536" target="_blank">00:58:56.940</a></span> | <span class="t">We were noticing this problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3539" target="_blank">00:58:59.140</a></span> | <span class="t">The way we debugged it was like looking at the gradients,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3542" target="_blank">00:59:02.140</a></span> | <span class="t">which didn't tell us much, but then we just looked at activation norms per layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3546" target="_blank">00:59:06.140</a></span> | <span class="t">and that's how we actually debug this, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3548" target="_blank">00:59:08.780</a></span> | <span class="t">So looking at the forward pass,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3550" target="_blank">00:59:10.300</a></span> | <span class="t">looking at the magnitudes of each layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3552" target="_blank">00:59:12.420</a></span> | <span class="t">like where we thought we could possibly be overflowing or underflowing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3556" target="_blank">00:59:16.380</a></span> | <span class="t">that's exactly how we debugged it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3558" target="_blank">00:59:18.980</a></span> | <span class="t">But we didn't debug it at the batch level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3561" target="_blank">00:59:21.100</a></span> | <span class="t">We debugged it as a function of time, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3563" target="_blank">00:59:23.540</a></span> | <span class="t">Because a single batch isn't going to perturb everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3566" target="_blank">00:59:26.260</a></span> | <span class="t">A series of batches,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3568" target="_blank">00:59:28.060</a></span> | <span class="t">like maybe two, three, who knows how many,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3569" target="_blank">00:59:29.980</a></span> | <span class="t">eventually you're going to fall under some trajectory where things get bad,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3573" target="_blank">00:59:33.300</a></span> | <span class="t">your activations blow up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3574" target="_blank">00:59:34.900</a></span> | <span class="t">So we would be able to deterministically be running to that checkpoint,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3578" target="_blank">00:59:38.060</a></span> | <span class="t">then deterministically step through training and log every activation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3582" target="_blank">00:59:42.540</a></span> | <span class="t">which is expensive, but that's how we were able to get to the bottom of the problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3586" target="_blank">00:59:46.060</a></span> | <span class="t">But I don't think we have tools for actually figuring out which batch of data was,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3591" target="_blank">00:59:51.100</a></span> | <span class="t">or which sequence of batches of data were the actual triggers for that behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3595" target="_blank">00:59:55.860</a></span> | <span class="t">>> I guess I was just curious specifically about if the same data that causes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3600" target="_blank">01:00:00.020</a></span> | <span class="t">destabilization in training can cause anomalous behavior,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3605" target="_blank">01:00:05.060</a></span> | <span class="t">or just like a normal form of pass?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3607" target="_blank">01:00:07.300</a></span> | <span class="t">>> It probably would.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3609" target="_blank">01:00:09.380</a></span> | <span class="t">There's some more recent work about how to quantize these models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3612" target="_blank">01:00:12.860</a></span> | <span class="t">like how to get a transformer that's trained with like 16-bit precision to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3617" target="_blank">01:00:17.060</a></span> | <span class="t">like train or to run with like eight bit precision by like intelligently like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3621" target="_blank">01:00:21.740</a></span> | <span class="t">bucketing floats from Tim Detmers who's a PhD student up at UW.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3627" target="_blank">01:00:27.140</a></span> | <span class="t">He has this theory on something called outlier features that show up in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3630" target="_blank">01:00:30.860</a></span> | <span class="t">these really big models that kind of try and get at this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3633" target="_blank">01:00:33.420</a></span> | <span class="t">but more of an art than a science right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3636" target="_blank">01:00:36.980</a></span> | <span class="t">Yeah. Okay. So are we done now that we fix this like layer norm stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3644" target="_blank">01:00:44.260</a></span> | <span class="t">the learning rate stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3645" target="_blank">01:00:45.660</a></span> | <span class="t">all of the stuff to get the transformer to work?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3647" target="_blank">01:00:47.660</a></span> | <span class="t">Kind of. Right. So like over the last few years,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3650" target="_blank">01:00:50.040</a></span> | <span class="t">like training has been stable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3651" target="_blank">01:00:51.420</a></span> | <span class="t">people want to like milk the most of the transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3654" target="_blank">01:00:54.500</a></span> | <span class="t">you know, especially as they scale up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3657" target="_blank">01:00:57.540</a></span> | <span class="t">So they do a couple of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3659" target="_blank">01:00:59.900</a></span> | <span class="t">So one, when you're training and potentially and you're projecting to queries and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3664" target="_blank">01:01:04.460</a></span> | <span class="t">keys at sufficient scale,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3667" target="_blank">01:01:07.220</a></span> | <span class="t">the bias term in each like linear layers like WX plus B,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3670" target="_blank">01:01:10.580</a></span> | <span class="t">you can get rid of the Bs because like it's not really doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3672" target="_blank">01:01:12.540</a></span> | <span class="t">anything and it saves a little bit of compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3674" target="_blank">01:01:14.460</a></span> | <span class="t">So let's get rid of them. Like that's like the first thing to throw out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3677" target="_blank">01:01:17.700</a></span> | <span class="t">There are different activations that have been invented and different types</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3681" target="_blank">01:01:21.020</a></span> | <span class="t">of like cool ways to just better fit your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3685" target="_blank">01:01:25.820</a></span> | <span class="t">So there's this like swish glue,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3687" target="_blank">01:01:27.220</a></span> | <span class="t">so a gated linear unit actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3689" target="_blank">01:01:29.820</a></span> | <span class="t">defines like a separate weight matrix as part of the activation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3693" target="_blank">01:01:33.940</a></span> | <span class="t">And then a swish is like a sigmoid activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3699" target="_blank">01:01:39.740</a></span> | <span class="t">that applies to one part of the weight and not the other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3701" target="_blank">01:01:41.500</a></span> | <span class="t">I've code for all of this. It works better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3704" target="_blank">01:01:44.460</a></span> | <span class="t">This is actually the activation of choice now in most transformer implementations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3709" target="_blank">01:01:49.420</a></span> | <span class="t">So Lama was trained with this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3711" target="_blank">01:01:51.020</a></span> | <span class="t">Palm was trained with this, works really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3715" target="_blank">01:01:55.060</a></span> | <span class="t">One thing that folks noticed is that moving the layer norm to happen,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3720" target="_blank">01:02:00.860</a></span> | <span class="t">you know, before you actually feed it through the attention or the MLP layers instead of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3727" target="_blank">01:02:07.340</a></span> | <span class="t">after is a more stabilizing force is actually kind of important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3731" target="_blank">01:02:11.780</a></span> | <span class="t">Also a layer norm has trainable weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3734" target="_blank">01:02:14.660</a></span> | <span class="t">So some papers decide to be like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3736" target="_blank">01:02:16.580</a></span> | <span class="t">you don't actually need these trainable parameters for mean and variance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3740" target="_blank">01:02:20.980</a></span> | <span class="t">You can actually just like divide by the mean square</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3743" target="_blank">01:02:23.500</a></span> | <span class="t">or the RMS of like your tire activation feature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3747" target="_blank">01:02:27.100</a></span> | <span class="t">All things to just get rid of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3748" target="_blank">01:02:28.940</a></span> | <span class="t">irrelevant flops because we're training massive models and we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3751" target="_blank">01:02:31.700</a></span> | <span class="t">trying to do the bigger model on the compute that we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3755" target="_blank">01:02:35.900</a></span> | <span class="t">Oh, yeah, here's the code for like a swish glue activation and an RMS norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3760" target="_blank">01:02:40.860</a></span> | <span class="t">So swish glue is like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3762" target="_blank">01:02:42.220</a></span> | <span class="t">so the Silly is like basically a sigmoid,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3764" target="_blank">01:02:44.380</a></span> | <span class="t">a projection layer is basically saying like let's take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3766" target="_blank">01:02:46.580</a></span> | <span class="t">this input feature projected into like two separate chunks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3770" target="_blank">01:02:50.260</a></span> | <span class="t">One chunk becomes like a gating value kind of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3773" target="_blank">01:02:53.260</a></span> | <span class="t">in a gated recurrent unit in like the RNN literature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3777" target="_blank">01:02:57.300</a></span> | <span class="t">One becomes the actual value,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3779" target="_blank">01:02:59.540</a></span> | <span class="t">you apply the sigmoid to the gate and then multiply it element-wise with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3783" target="_blank">01:03:03.100</a></span> | <span class="t">the value and you get your new thing, works really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3786" target="_blank">01:03:06.620</a></span> | <span class="t">An RMS norm is like literally just dividing by the norm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3790" target="_blank">01:03:10.180</a></span> | <span class="t">of the vector instead of like trying to learn anything fancy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3793" target="_blank">01:03:13.940</a></span> | <span class="t">Cool. This is what the modern transform looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3797" target="_blank">01:03:17.820</a></span> | <span class="t">So that's it for the evolution of the transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3801" target="_blank">01:03:21.940</a></span> | <span class="t">As far as I know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3803" target="_blank">01:03:23.420</a></span> | <span class="t">nothing in the last two weeks have like changed drastically from this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3806" target="_blank">01:03:26.860</a></span> | <span class="t">In the last two weeks. To what extent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3809" target="_blank">01:03:29.900</a></span> | <span class="t">let's say we are doing a fine-tune instead of like the full train,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3814" target="_blank">01:03:34.500</a></span> | <span class="t">or we're doing like lower on top of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3816" target="_blank">01:03:36.660</a></span> | <span class="t">How would we still want to follow these kinds of guidelines or these specific to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3821" target="_blank">01:03:41.220</a></span> | <span class="t">just doing all of the data doing a full pre-train?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3825" target="_blank">01:03:45.140</a></span> | <span class="t">Yeah. So question is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3826" target="_blank">01:03:46.860</a></span> | <span class="t">what of this do we really need if we're fine-tuning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3830" target="_blank">01:03:50.420</a></span> | <span class="t">or if we're kind of doing like parameter efficient fine-tuning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3832" target="_blank">01:03:52.460</a></span> | <span class="t">like is this only necessary for pre-training?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3834" target="_blank">01:03:54.380</a></span> | <span class="t">So I've started using the Swish Glue instead of like any other activation like everywhere,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3840" target="_blank">01:04:00.540</a></span> | <span class="t">even for like a two-layer MLP,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3842" target="_blank">01:04:02.340</a></span> | <span class="t">tends to work better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3844" target="_blank">01:04:04.540</a></span> | <span class="t">So take that with a grain of salt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3847" target="_blank">01:04:07.340</a></span> | <span class="t">Everything else you can probably not care about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3850" target="_blank">01:04:10.540</a></span> | <span class="t">The RMS norm, the pre-norm is probably just like a general rule of thumb if you're adding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3856" target="_blank">01:04:16.180</a></span> | <span class="t">any transformer layers just because it is like demonstrably more stable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3859" target="_blank">01:04:19.980</a></span> | <span class="t">but other than that, no.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3862" target="_blank">01:04:22.900</a></span> | <span class="t">Other questions here before we move to how to train on lots and lots of compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3870" target="_blank">01:04:30.300</a></span> | <span class="t">Cool. So let's talk about training at scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3875" target="_blank">01:04:35.500</a></span> | <span class="t">So I'll start with a story, my story.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3880" target="_blank">01:04:40.940</a></span> | <span class="t">Okay. So I am not old,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3884" target="_blank">01:04:44.740</a></span> | <span class="t">but I have seen a few things as far as language models have gone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3890" target="_blank">01:04:50.340</a></span> | <span class="t">So like 2018 is when I think did my first deep learning tutorial.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3895" target="_blank">01:04:55.940</a></span> | <span class="t">I trained a MNIST like the typical like two-layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3899" target="_blank">01:04:59.740</a></span> | <span class="t">four-layer MLP for classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3903" target="_blank">01:05:03.060</a></span> | <span class="t">There's actually a line there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3904" target="_blank">01:05:04.940</a></span> | <span class="t">It's the 100,000 parameter line. That's 2018.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3909" target="_blank">01:05:09.660</a></span> | <span class="t">As I kind of start my PhD in 2019,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3912" target="_blank">01:05:12.700</a></span> | <span class="t">I'm doing more NLP stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3914" target="_blank">01:05:14.220</a></span> | <span class="t">I'm looking at like word vectors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3915" target="_blank">01:05:15.700</a></span> | <span class="t">RNNs, some more sophisticated things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3918" target="_blank">01:05:18.500</a></span> | <span class="t">I'm getting up to a million parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3921" target="_blank">01:05:21.460</a></span> | <span class="t">2020, I kind of branch out from like the small NLP stuff I'm doing to like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3926" target="_blank">01:05:26.100</a></span> | <span class="t">more intensive NLP so looking at tasks like summarization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3930" target="_blank">01:05:30.420</a></span> | <span class="t">training models with like 10 million parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3933" target="_blank">01:05:33.580</a></span> | <span class="t">Then by 2021, like the biggest models I was training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3939" target="_blank">01:05:39.580</a></span> | <span class="t">was like when I switched into multimodality robotics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3941" target="_blank">01:05:41.660</a></span> | <span class="t">looking at visual question answering, 18 million parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3945" target="_blank">01:05:45.460</a></span> | <span class="t">At the time, the standard pipeline for me,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3947" target="_blank">01:05:47.660</a></span> | <span class="t">and I think this was the standard pipeline for a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3949" target="_blank">01:05:49.340</a></span> | <span class="t">grad students that I talked to then,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3952" target="_blank">01:05:52.020</a></span> | <span class="t">is like I'd be able to train most of my things on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3955" target="_blank">01:05:55.140</a></span> | <span class="t">one GPU or even my laptop CPU for like a maximum of a few hours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3961" target="_blank">01:06:01.220</a></span> | <span class="t">I got it is what a training run would take,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3963" target="_blank">01:06:03.620</a></span> | <span class="t">at least for like most of the things I was doing on a day-to-day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3967" target="_blank">01:06:07.020</a></span> | <span class="t">But in 2021, Percy's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3972" target="_blank">01:06:12.620</a></span> | <span class="t">"Hey, this GPT-3 thing seems cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3975" target="_blank">01:06:15.260</a></span> | <span class="t">Let's at least figure out if we can get an academic lab to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3978" target="_blank">01:06:18.140</a></span> | <span class="t">like try and train a GPT-2 like the earlier generation."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3981" target="_blank">01:06:21.420</a></span> | <span class="t">So clocking in at like 124 million parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3984" target="_blank">01:06:24.700</a></span> | <span class="t">which is notably an order of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3986" target="_blank">01:06:26.700</a></span> | <span class="t">magnitude bigger than anything I trained at the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3988" target="_blank">01:06:28.860</a></span> | <span class="t">So why I decided to do this is still beyond me,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3991" target="_blank">01:06:31.260</a></span> | <span class="t">but I learned a lot of useful things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3993" target="_blank">01:06:33.300</a></span> | <span class="t">One of the useful things that I learned is that training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=3997" target="_blank">01:06:37.860</a></span> | <span class="t">a 124 million parameter model on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4000" target="_blank">01:06:40.940</a></span> | <span class="t">a decent GPU that we had access to at the time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4004" target="_blank">01:06:44.300</a></span> | <span class="t">with a batch size greater than four would go out of memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4007" target="_blank">01:06:47.420</a></span> | <span class="t">which is bad because a batch size of four is small,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4010" target="_blank">01:06:50.340</a></span> | <span class="t">and we wanted to ideally train with like a batch size of 512.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4013" target="_blank">01:06:53.660</a></span> | <span class="t">So there was a simple trick,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4016" target="_blank">01:06:56.460</a></span> | <span class="t">and it's called gradient accumulation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4017" target="_blank">01:06:57.980</a></span> | <span class="t">which is like I'm going to run batch sizes of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4020" target="_blank">01:07:00.140</a></span> | <span class="t">four however many times it takes to get into 512,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4024" target="_blank">01:07:04.060</a></span> | <span class="t">and then do an update after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4025" target="_blank">01:07:05.740</a></span> | <span class="t">processing all of those batches sequentially.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4027" target="_blank">01:07:07.860</a></span> | <span class="t">So I'm just going to keep accumulating the gradients,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4030" target="_blank">01:07:10.140</a></span> | <span class="t">and PyTorch makes that really easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4031" target="_blank">01:07:11.580</a></span> | <span class="t">It's just a for loop and an if statement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4034" target="_blank">01:07:14.060</a></span> | <span class="t">But if you do the math,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4036" target="_blank">01:07:16.860</a></span> | <span class="t">it's like 100 days to train on that single GPU for 400,000 steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4040" target="_blank">01:07:20.900</a></span> | <span class="t">So how do we go from this clock of 100 days to something reasonable?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4046" target="_blank">01:07:26.340</a></span> | <span class="t">That's what we're going to talk about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4047" target="_blank">01:07:27.940</a></span> | <span class="t">So with the scaling toolbox,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4052" target="_blank">01:07:32.180</a></span> | <span class="t">at least as far as we were concerned,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4057" target="_blank">01:07:37.300</a></span> | <span class="t">ended up looking like three different parts across</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4062" target="_blank">01:07:42.780</a></span> | <span class="t">16 GPUs because Percy and Chris Ray,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4065" target="_blank">01:07:45.460</a></span> | <span class="t">and I think Chris and Dan and Chris Manning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4068" target="_blank">01:07:48.900</a></span> | <span class="t">and the NLP group decided to invest upfront in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4071" target="_blank">01:07:51.220</a></span> | <span class="t">like really powerful GPU machines,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4073" target="_blank">01:07:53.660</a></span> | <span class="t">so we could actually train on like 16 GPUs at once.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4077" target="_blank">01:07:57.100</a></span> | <span class="t">For reference, 16 GPUs on AWS,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4082" target="_blank">01:08:02.260</a></span> | <span class="t">just rent on an hourly basis is 56 bucks an hour now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4086" target="_blank">01:08:06.580</a></span> | <span class="t">Fifty six bucks an hour if you want to just like sit on them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4091" target="_blank">01:08:11.460</a></span> | <span class="t">But if you're willing to like let anyone who has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4095" target="_blank">01:08:15.180</a></span> | <span class="t">the money and like wants to sit on them like preempt you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4098" target="_blank">01:08:18.140</a></span> | <span class="t">you can get them for 16 bucks an hour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4099" target="_blank">01:08:19.980</a></span> | <span class="t">So like across four days like that's not the worst.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4103" target="_blank">01:08:23.180</a></span> | <span class="t">It's like not great, but totally doable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4107" target="_blank">01:08:27.340</a></span> | <span class="t">So the scaling toolbox we ended up looking at was data parallelism.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4112" target="_blank">01:08:32.420</a></span> | <span class="t">You can think about this as like literally just divide and conquer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4115" target="_blank">01:08:35.220</a></span> | <span class="t">How do I just parallelize work across all of these GPUs instead of one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4120" target="_blank">01:08:40.860</a></span> | <span class="t">Mixed precision training, and we're going to talk a little bit about what that means.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4126" target="_blank">01:08:46.820</a></span> | <span class="t">Then this interesting idea called zero redundancy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4129" target="_blank">01:08:49.620</a></span> | <span class="t">which is about minimizing the memory footprint of training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4132" target="_blank">01:08:52.820</a></span> | <span class="t">Then later on as you want to scale up to hundreds of billions of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4138" target="_blank">01:08:58.140</a></span> | <span class="t">parameters on 256, 512, 1024, 2048 GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4145" target="_blank">01:09:05.340</a></span> | <span class="t">We'll talk like there are things that come in handy like model parallelism.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4149" target="_blank">01:09:09.700</a></span> | <span class="t">There are things to consider like hardware and software limitations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4154" target="_blank">01:09:14.700</a></span> | <span class="t">But some of you might be here looking at me which is like, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4158" target="_blank">01:09:18.740</a></span> | <span class="t">do I need any of this stuff if I'm not training really big models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4161" target="_blank">01:09:21.060</a></span> | <span class="t">Like if I'm just fine tuning stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4163" target="_blank">01:09:23.620</a></span> | <span class="t">A lot of these tips and tricks like you may not have access to 100 GPUs or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4171" target="_blank">01:09:31.020</a></span> | <span class="t">even eight, but you might have access to two or four, comes in handy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4175" target="_blank">01:09:35.460</a></span> | <span class="t">A lot of the ideas here are still ideas that I'm using when I'm training stuff on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4180" target="_blank">01:09:40.100</a></span> | <span class="t">my laptop or when I'm trying to run inference with the latest big model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4183" target="_blank">01:09:43.020</a></span> | <span class="t">that is publicly released, so it's useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4185" target="_blank">01:09:45.140</a></span> | <span class="t">But please ask questions if things become too hazy or too not useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4192" target="_blank">01:09:52.180</a></span> | <span class="t">>> [INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4193" target="_blank">01:09:53.700</a></span> | <span class="t">>> Mm-hm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4195" target="_blank">01:09:55.060</a></span> | <span class="t">>> For people relying on Colab,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4198" target="_blank">01:09:58.180</a></span> | <span class="t">data parallelism might actually not help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4201" target="_blank">01:10:01.780</a></span> | <span class="t">>> So Colab, yeah, Colab, you're still limited to a single GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4204" target="_blank">01:10:04.980</a></span> | <span class="t">>> And I'm guessing zero redundancy might help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4208" target="_blank">01:10:08.940</a></span> | <span class="t">>> So mixed precision would help, kind of, definitely for running inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4215" target="_blank">01:10:15.660</a></span> | <span class="t">And zero redundancy would also help running inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4218" target="_blank">01:10:18.140</a></span> | <span class="t">>> What's the zero redundancy?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4220" target="_blank">01:10:20.380</a></span> | <span class="t">>> So zero redundancy has an add-on that they wrote up in a paper later called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4224" target="_blank">01:10:24.940</a></span> | <span class="t">zero infinity, which is like, what if I didn't put all my weights on the GPU at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4228" target="_blank">01:10:28.500</a></span> | <span class="t">once, what if I put some of them in CPU RAM or even in NVMe SSD storage?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4235" target="_blank">01:10:35.100</a></span> | <span class="t">So actually turning your laptop into a more powerful workhorse than a Colab GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4239" target="_blank">01:10:39.460</a></span> | <span class="t">Cool, so this is a toy example kind of going through data parallelism.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4247" target="_blank">01:10:47.340</a></span> | <span class="t">We're running low on time-ish, so this is MNIST with an MLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4254" target="_blank">01:10:54.700</a></span> | <span class="t">We're trying to do classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4256" target="_blank">01:10:56.340</a></span> | <span class="t">It's kind of the typical PyTorch workflow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4259" target="_blank">01:10:59.180</a></span> | <span class="t">I'm going to define an N dot module.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4261" target="_blank">01:11:01.580</a></span> | <span class="t">I'm going to define a batch size, a data loader that's going to load from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4264" target="_blank">01:11:04.420</a></span> | <span class="t">the TorchVision data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4266" target="_blank">01:11:06.020</a></span> | <span class="t">And then I'm just going to run lots and lots of gradient steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4270" target="_blank">01:11:10.420</a></span> | <span class="t">The idea here is, how do we parallelize this across multiple workers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4277" target="_blank">01:11:17.620</a></span> | <span class="t">multiple GPUs?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4279" target="_blank">01:11:19.140</a></span> | <span class="t">Well, that batch size you see there is totally divisible, especially given that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4284" target="_blank">01:11:24.420</a></span> | <span class="t">what we're doing at the end when we kind of compute the loss is just take an average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4288" target="_blank">01:11:28.220</a></span> | <span class="t">An average of averages is still the average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4291" target="_blank">01:11:31.860</a></span> | <span class="t">That's the idea we're going to work with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4293" target="_blank">01:11:33.420</a></span> | <span class="t">The mean of means is still the global mean.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4296" target="_blank">01:11:36.460</a></span> | <span class="t">So just like in CPU land where you can kind of think about SIMD instructions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4301" target="_blank">01:11:41.020</a></span> | <span class="t">like single instruction, multiple data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4302" target="_blank">01:11:42.860</a></span> | <span class="t">Right, so this is kind of how most graphics and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4305" target="_blank">01:11:45.500</a></span> | <span class="t">media operations work on your laptops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4308" target="_blank">01:11:48.260</a></span> | <span class="t">We're going to now think about the SPMD paradigm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4311" target="_blank">01:11:51.220</a></span> | <span class="t">I'm going to write one program, and it's just going to automatically scale to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4314" target="_blank">01:11:54.980</a></span> | <span class="t">being split across our running machines,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4316" target="_blank">01:11:56.900</a></span> | <span class="t">because we're going to split the data across multiple machines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4319" target="_blank">01:11:59.460</a></span> | <span class="t">It seems hard, but as of PyTorch 1.4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4323" target="_blank">01:12:03.140</a></span> | <span class="t">a lot of the hard parts are taken care of for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4326" target="_blank">01:12:06.220</a></span> | <span class="t">These are the only lines you need to change in the implementation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4329" target="_blank">01:12:09.060</a></span> | <span class="t">Two of them are import statements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4331" target="_blank">01:12:11.220</a></span> | <span class="t">So the first thing we're going to do is we're going to just create something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4334" target="_blank">01:12:14.780</a></span> | <span class="t">called a distributed sampler, which is going to automatically partition our data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4337" target="_blank">01:12:17.980</a></span> | <span class="t">across the number of workers we define up front.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4340" target="_blank">01:12:20.580</a></span> | <span class="t">Right, we're defining a world size of eight, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4343" target="_blank">01:12:23.820</a></span> | <span class="t">that means we're training on eight GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4345" target="_blank">01:12:25.500</a></span> | <span class="t">So this is going to partition our data into eight different subsets that each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4348" target="_blank">01:12:28.380</a></span> | <span class="t">worker gets to go through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4349" target="_blank">01:12:29.540</a></span> | <span class="t">We're going to wrap our nn.module with this nice little wrapper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4354" target="_blank">01:12:34.860</a></span> | <span class="t">this distributed data parallel wrapper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4356" target="_blank">01:12:36.980</a></span> | <span class="t">which is going to sync the gradients for us behind the scenes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4360" target="_blank">01:12:40.340</a></span> | <span class="t">And then we're going to run this with a special command called Cortron,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4365" target="_blank">01:12:45.940</a></span> | <span class="t">which is just going to inject a bunch of environment variables so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4368" target="_blank">01:12:48.660</a></span> | <span class="t">that we can get some statistics about our local rank,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4373" target="_blank">01:12:53.020</a></span> | <span class="t">who's the guy who should be printing stuff to the screen,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4375" target="_blank">01:12:55.300</a></span> | <span class="t">who's the guy who should be logging stuff, where each worker lives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4380" target="_blank">01:13:00.060</a></span> | <span class="t">And that's about it, and you can do all of this, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4385" target="_blank">01:13:05.260</a></span> | <span class="t">you just parallelize naively across 16 GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4387" target="_blank">01:13:07.860</a></span> | <span class="t">You get not quite a 16x speedup, because there is some overhead from communication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4393" target="_blank">01:13:13.460</a></span> | <span class="t">It's like seven days, that's cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4396" target="_blank">01:13:16.140</a></span> | <span class="t">It was not good enough, because we were trying to train lots of models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4399" target="_blank">01:13:19.620</a></span> | <span class="t">reproducibly, five seeds for like ten different model types, so like 50 models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4406" target="_blank">01:13:26.060</a></span> | <span class="t">So we needed to go a little faster than this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4408" target="_blank">01:13:28.540</a></span> | <span class="t">So let's talk about memory footprints.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4410" target="_blank">01:13:30.900</a></span> | <span class="t">When I am training any model with an atom optimizer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4415" target="_blank">01:13:35.540</a></span> | <span class="t">how much memory does just storing that model and the optimizer weights take up?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4423" target="_blank">01:13:43.980</a></span> | <span class="t">So in 32-bit precision, our model's going to have parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4430" target="_blank">01:13:50.260</a></span> | <span class="t">where each parameter is stored with 32 bits, that's a float.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4434" target="_blank">01:13:54.100</a></span> | <span class="t">Gradients, 32 bits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4436" target="_blank">01:13:56.380</a></span> | <span class="t">Now your optimizer is also going to do this weird thing where it's going to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4438" target="_blank">01:13:58.380</a></span> | <span class="t">a copy, its own separate copy of the parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4440" target="_blank">01:14:00.540</a></span> | <span class="t">like kind of duplicating a little bit of work there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4442" target="_blank">01:14:02.940</a></span> | <span class="t">That's also 32 bits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4444" target="_blank">01:14:04.660</a></span> | <span class="t">And then atom tracks momentum and variance, like the first and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4448" target="_blank">01:14:08.540</a></span> | <span class="t">second order of the gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4450" target="_blank">01:14:10.940</a></span> | <span class="t">So that's another 64 bytes, or bits, right there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4454" target="_blank">01:14:14.580</a></span> | <span class="t">So the lower bound on static memory, just like storing this stuff on a GPU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4459" target="_blank">01:14:19.300</a></span> | <span class="t">is 20 bytes times the number of parameters that you have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4461" target="_blank">01:14:21.620</a></span> | <span class="t">This doesn't include activations at all for these larger transform models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4466" target="_blank">01:14:26.980</a></span> | <span class="t">If I want to keep around every buffer, like every intermediate matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4471" target="_blank">01:14:31.380</a></span> | <span class="t">as I pass it through the network, that takes up way more space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4474" target="_blank">01:14:34.420</a></span> | <span class="t">But this at least gives us something that we can reason about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4478" target="_blank">01:14:38.700</a></span> | <span class="t">The training implications of this is that if I want to fit a model with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4482" target="_blank">01:14:42.260</a></span> | <span class="t">a billion parameters, that's going to take about 18 gigs resting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4486" target="_blank">01:14:46.140</a></span> | <span class="t">31 gigs of GPU RAM with a batch size of one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4489" target="_blank">01:14:49.900</a></span> | <span class="t">Which is problematic, because most GPUs then cap out at 24 gigs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4496" target="_blank">01:14:56.100</a></span> | <span class="t">The really expensive ones now have like 40 or 80, but this is still bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4499" target="_blank">01:14:59.740</a></span> | <span class="t">175 billion parameters would take three terabytes of RAM,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4504" target="_blank">01:15:04.980</a></span> | <span class="t">not storage, just RAM, without activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4508" target="_blank">01:15:08.180</a></span> | <span class="t">With activations, it's probably looking like ten terabytes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4510" target="_blank">01:15:10.860</a></span> | <span class="t">Good luck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4511" target="_blank">01:15:11.380</a></span> | <span class="t">>> [INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4513" target="_blank">01:15:13.740</a></span> | <span class="t">>> The numbers in bold are batch size one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4515" target="_blank">01:15:15.540</a></span> | <span class="t">Numbers not in bold are just putting it on the thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4519" target="_blank">01:15:19.180</a></span> | <span class="t">And things you should know about floats,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4525" target="_blank">01:15:25.300</a></span> | <span class="t">it was a standard defined in this IEEE document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4529" target="_blank">01:15:29.020</a></span> | <span class="t">You have a one bit sign, eight bit exponent, 23 bit scientific notation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4534" target="_blank">01:15:34.620</a></span> | <span class="t">like all the stuff that happens after the exponent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4537" target="_blank">01:15:37.460</a></span> | <span class="t">Wide range, up to 1E38.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4539" target="_blank">01:15:39.900</a></span> | <span class="t">And the question is, do you need that range?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4541" target="_blank">01:15:41.940</a></span> | <span class="t">Answer is, kind of, but not really.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4545" target="_blank">01:15:45.060</a></span> | <span class="t">So the mixed precision memory footprint.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4547" target="_blank">01:15:47.220</a></span> | <span class="t">If I'm training a model in mixed precision, what that means is that I'm just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4550" target="_blank">01:15:50.700</a></span> | <span class="t">going to run everything in a forward pass and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4553" target="_blank">01:15:53.900</a></span> | <span class="t">part of the backwards pass in 16 bit precision instead of 32 bit precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4559" target="_blank">01:15:59.940</a></span> | <span class="t">Notably, what that means is now I'm storing my parameters in 16 bits,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4563" target="_blank">01:16:03.380</a></span> | <span class="t">my gradient in 16 bits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4565" target="_blank">01:16:05.660</a></span> | <span class="t">All of those intermediate activations that take up lots and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4568" target="_blank">01:16:08.820</a></span> | <span class="t">lots and lots of memory, especially as you go bigger, are halved, which is great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4572" target="_blank">01:16:12.540</a></span> | <span class="t">But the weird part about mixed precision is not everything is mixed precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4577" target="_blank">01:16:17.900</a></span> | <span class="t">So your optimizer to stably update your model still needs the 32 bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4581" target="_blank">01:16:21.700</a></span> | <span class="t">parameter copies, your 32 bit momentum, 32 bit variance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4585" target="_blank">01:16:25.660</a></span> | <span class="t">But you've dropped four bytes, and those four bytes are kind of useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4591" target="_blank">01:16:31.260</a></span> | <span class="t">Yet training with mixed precision, at least a couple years ago, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4594" target="_blank">01:16:34.940</a></span> | <span class="t">it's still mostly true now, is still way faster than training with full precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4600" target="_blank">01:16:40.660</a></span> | <span class="t">And the reason for that is most NVIDIA GPUs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4605" target="_blank">01:16:45.580</a></span> | <span class="t">starting with the Volta cards, started shipping with these things called tensor cores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4611" target="_blank">01:16:51.860</a></span> | <span class="t">Tensor cores are basically the individual logical units on a GPU that are responsible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4616" target="_blank">01:16:56.940</a></span> | <span class="t">for matrix multiplies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4618" target="_blank">01:16:58.660</a></span> | <span class="t">Your GPU is really good at accelerating neural network training because it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4621" target="_blank">01:17:01.860</a></span> | <span class="t">really good at doing matrix multiplies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4624" target="_blank">01:17:04.020</a></span> | <span class="t">These things are optimized for 4x4 to 16x16 size shards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4631" target="_blank">01:17:11.660</a></span> | <span class="t">If you're training in 16 bit precision,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4633" target="_blank">01:17:13.460</a></span> | <span class="t">you can actually end up using way more tensor cores than if you were using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4637" target="_blank">01:17:17.580</a></span> | <span class="t">32 bit precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4638" target="_blank">01:17:18.460</a></span> | <span class="t">And so you're able to get a ton of speed ups just because you're able to tap</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4643" target="_blank">01:17:23.420</a></span> | <span class="t">into the underlying hardware of your system more frequently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4646" target="_blank">01:17:26.460</a></span> | <span class="t">As of the Ampere style cards, like the A100s or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4651" target="_blank">01:17:31.380</a></span> | <span class="t">the more recent 3090s, 3090TIs, 4090s.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4656" target="_blank">01:17:36.140</a></span> | <span class="t">Those start shipping with these cores that are able to do float 32 precision, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4661" target="_blank">01:17:41.420</a></span> | <span class="t">are still even faster for 16 bit precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4663" target="_blank">01:17:43.940</a></span> | <span class="t">So when you can, train with 16 bit precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4666" target="_blank">01:17:46.740</a></span> | <span class="t">All right, this shaves a day off of our small scale training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4674" target="_blank">01:17:54.020</a></span> | <span class="t">This shaves off way more, especially as you go bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4678" target="_blank">01:17:58.700</a></span> | <span class="t">And now the final bit is how do we eliminate the redundancies?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4682" target="_blank">01:18:02.460</a></span> | <span class="t">Right, so in standard data parallelism.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4684" target="_blank">01:18:04.380</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4686" target="_blank">01:18:06.020</a></span> | <span class="t">>> I have a question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4687" target="_blank">01:18:07.020</a></span> | <span class="t">So why do you need the 32 bit precision for the optimizer, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4690" target="_blank">01:18:10.220</a></span> | <span class="t">what is it for the model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4691" target="_blank">01:18:11.140</a></span> | <span class="t">>> So when you are estimating the gradients, precision matters more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4696" target="_blank">01:18:16.500</a></span> | <span class="t">You want that full range.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4698" target="_blank">01:18:18.300</a></span> | <span class="t">Specifically, you want those 23 bits that kind of correspond to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4703" target="_blank">01:18:23.700</a></span> | <span class="t">everything that has data to be meaningful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4707" target="_blank">01:18:27.460</a></span> | <span class="t">Because while the full range of float 32 is really, really big,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4712" target="_blank">01:18:32.380</a></span> | <span class="t">it actually can't be super precise in the 0, 1 range, for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4718" target="_blank">01:18:38.660</a></span> | <span class="t">So you kind of want as much there as possible to kind of ensure precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4724" target="_blank">01:18:44.140</a></span> | <span class="t">Okay, so zero redundancy, standard data parallelism.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4728" target="_blank">01:18:48.940</a></span> | <span class="t">You're basically storing everything on each GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4731" target="_blank">01:18:51.780</a></span> | <span class="t">Key idea is I don't need to store everything on every GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4736" target="_blank">01:18:56.380</a></span> | <span class="t">I just need to store some things on every GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4739" target="_blank">01:18:59.100</a></span> | <span class="t">So the model gets to stay on each GPU cuz the model has to do all the work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4743" target="_blank">01:19:03.140</a></span> | <span class="t">But the gradients, I can just split across the number of devices that I have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4746" target="_blank">01:19:06.140</a></span> | <span class="t">So half my gradients, if I have two GPUs, go on one device,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4749" target="_blank">01:19:09.580</a></span> | <span class="t">half of them go on the other device.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4751" target="_blank">01:19:11.700</a></span> | <span class="t">Same with the optimizer states.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4752" target="_blank">01:19:12.900</a></span> | <span class="t">Half of them go on one device, half of them go on the other device.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4755" target="_blank">01:19:15.340</a></span> | <span class="t">With this model of zero redundancy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4757" target="_blank">01:19:17.460</a></span> | <span class="t">you're actually not adding any extra communication cost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4760" target="_blank">01:19:20.540</a></span> | <span class="t">You just get free memory because you're just intelligently partitioning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4764" target="_blank">01:19:24.620</a></span> | <span class="t">things across devices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4766" target="_blank">01:19:26.780</a></span> | <span class="t">Notice that this scales, you use less and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4771" target="_blank">01:19:31.620</a></span> | <span class="t">less memory as you add more and more machines, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4774" target="_blank">01:19:34.780</a></span> | <span class="t">So this is kind of like the biggest trick to start training 1 billion to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4777" target="_blank">01:19:37.940</a></span> | <span class="t">10 billion parameter plus models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4780" target="_blank">01:19:40.780</a></span> | <span class="t">And now when you add this, you're at three days.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4783" target="_blank">01:19:43.260</a></span> | <span class="t">>> So would you have to tell it what,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4788" target="_blank">01:19:48.660</a></span> | <span class="t">cuz this would require things being slightly out of sync to optimize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4793" target="_blank">01:19:53.100</a></span> | <span class="t">Would you have to- >> So this actually doesn't require</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4795" target="_blank">01:19:55.060</a></span> | <span class="t">anything out of sync, because in a backwards pass with distributed data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4798" target="_blank">01:19:58.700</a></span> | <span class="t">parallel, the individual updates already have to be synced across processes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4805" target="_blank">01:20:05.700</a></span> | <span class="t">If you take the loss across average and across all processes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4808" target="_blank">01:20:08.860</a></span> | <span class="t">that means that the gradients you apply have to be transferred as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4812" target="_blank">01:20:12.420</a></span> | <span class="t">So this just basically does that work for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4815" target="_blank">01:20:15.860</a></span> | <span class="t">We're gonna wrap up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4820" target="_blank">01:20:20.100</a></span> | <span class="t">You hit a communication wall, matrix multiplies,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4822" target="_blank">01:20:22.300</a></span> | <span class="t">stop fitting on a device, so you start charting them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4824" target="_blank">01:20:24.860</a></span> | <span class="t">And then you have to start scheduling things wisely, and yeah, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4827" target="_blank">01:20:27.980</a></span> | <span class="t">Fine tuning inference, there is a great library that you should use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4832" target="_blank">01:20:32.140</a></span> | <span class="t">called Peft from Hugging Face, it's great, and that's it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=JVKtPZsiv4k&t=4834" target="_blank">01:20:34.780</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>