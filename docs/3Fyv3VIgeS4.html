<html><head><title>Transfer learning proves LLMs aren’t stochastic parrots – Trenton Bricken & Sholto Douglas</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Transfer learning proves LLMs aren’t stochastic parrots – Trenton Bricken & Sholto Douglas</h2><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4"><img src="https://i.ytimg.com/vi_webp/3Fyv3VIgeS4/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./3Fyv3VIgeS4.html">Whisper Transcript</a> | <a href="./transcript_3Fyv3VIgeS4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">A book that Trenton recommended, The Symbolic Species, has this really interesting argument.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=5" target="_blank">00:00:05.200</a></span> | <span class="t">When we just think of language as this contingent and maybe suboptimal way to represent ideas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=11" target="_blank">00:00:11.440</a></span> | <span class="t">Actually, maybe one of the reasons that LLMs have succeeded is because language has evolved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=17" target="_blank">00:00:17.280</a></span> | <span class="t">for tens of thousands of years to be this sort of cast in which young minds can develop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=22" target="_blank">00:00:22.960</a></span> | <span class="t">Certainly when you talk to multimodal or computer vision researchers versus when you talk to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=29" target="_blank">00:00:29.120</a></span> | <span class="t">language model researchers, people who work in other modalities have to put enormous amounts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=34" target="_blank">00:00:34.560</a></span> | <span class="t">of thought into exactly what the right representation space for the images is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=39" target="_blank">00:00:39.040</a></span> | <span class="t">Understanding the right level of representation there, really hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=41" target="_blank">00:00:41.520</a></span> | <span class="t">In language, people are just like, "Well, I guess you just predict the next token."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=44" target="_blank">00:00:44.400</a></span> | <span class="t">The case for a multimodal being a way to bridge the data wall or get past the data wall</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=52" target="_blank">00:00:52.000</a></span> | <span class="t">is based on the idea that the things you would have learned from more language tokens anyway,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=58" target="_blank">00:00:58.320</a></span> | <span class="t">you can just get from YouTube.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=59" target="_blank">00:00:59.760</a></span> | <span class="t">Has that actually been the case?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=62" target="_blank">00:01:02.480</a></span> | <span class="t">How much positive transfer do you see between different modalities where actually the images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=68" target="_blank">00:01:08.400</a></span> | <span class="t">are helping you be better at writing code or something?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=71" target="_blank">00:01:11.040</a></span> | <span class="t">Just because the model is learning a latent capability is just from trying to understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=74" target="_blank">00:01:14.960</a></span> | <span class="t">the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=75" target="_blank">00:01:15.680</a></span> | <span class="t">Yeah, I'm the wrong person to ask, but there are interesting interpretability pieces where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=80" target="_blank">00:01:20.480</a></span> | <span class="t">if we fine tune on math problems, the model just gets better at entity recognition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=87" target="_blank">00:01:27.760</a></span> | <span class="t">Whoa, really?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=88" target="_blank">00:01:28.880</a></span> | <span class="t">Yeah, so there's a paper from David Bow's lab recently where they investigate what actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=95" target="_blank">00:01:35.280</a></span> | <span class="t">changes in a model when I fine tune it with respect to the attention heads and these sorts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=99" target="_blank">00:01:39.280</a></span> | <span class="t">of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=99" target="_blank">00:01:39.280</a></span> | <span class="t">Fascinating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=100" target="_blank">00:01:40.080</a></span> | <span class="t">And they have this synthetic problem of box A has this object in it, box B has this other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=106" target="_blank">00:01:46.960</a></span> | <span class="t">object in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=107" target="_blank">00:01:47.680</a></span> | <span class="t">What was in this box?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=109" target="_blank">00:01:49.760</a></span> | <span class="t">And it makes sense, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=112" target="_blank">00:01:52.400</a></span> | <span class="t">That's beautiful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=114" target="_blank">00:01:54.480</a></span> | <span class="t">You're better at attending to the positions of different things, which you need for coding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=119" target="_blank">00:01:59.040</a></span> | <span class="t">and manipulating math equations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=120" target="_blank">00:02:00.400</a></span> | <span class="t">I love this kind of research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=122" target="_blank">00:02:02.400</a></span> | <span class="t">One of the things you mentioned to me a long time ago is the evidence that when you train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=127" target="_blank">00:02:07.280</a></span> | <span class="t">LLMs on code, they get better at reasoning in language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=130" target="_blank">00:02:10.480</a></span> | <span class="t">Which, unless it's the case that the comments in the code are just really high quality tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=134" target="_blank">00:02:14.480</a></span> | <span class="t">or something, implies that to be able to think through how to code better, it makes you a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=140" target="_blank">00:02:20.720</a></span> | <span class="t">better reasoner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=141" target="_blank">00:02:21.360</a></span> | <span class="t">That's crazy, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=142" target="_blank">00:02:22.720</a></span> | <span class="t">I think that's one of the strongest pieces of evidence for scaling, just making the thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=146" target="_blank">00:02:26.800</a></span> | <span class="t">smart, that kind of positive transfer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=149" target="_blank">00:02:29.680</a></span> | <span class="t">I think this is true in two senses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=152" target="_blank">00:02:32.000</a></span> | <span class="t">One is just that modeling code obviously implies modeling a difficult reasoning process used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=156" target="_blank">00:02:36.080</a></span> | <span class="t">to create it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=156" target="_blank">00:02:36.720</a></span> | <span class="t">But two, that code is a nice explicit structure of composed reasoning, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=163" target="_blank">00:02:43.040</a></span> | <span class="t">If this, then that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=164" target="_blank">00:02:44.720</a></span> | <span class="t">Code's a lot of structure in that way that you could imagine transferring to other types</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=172" target="_blank">00:02:52.640</a></span> | <span class="t">of types of reasoning problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=174" target="_blank">00:02:54.080</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=174" target="_blank">00:02:54.640</a></span> | <span class="t">And crucially, the thing that makes it significant is that it's not just stochastically predicting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=181" target="_blank">00:03:01.680</a></span> | <span class="t">the next token of words or whatever, because it's learned that Sally corresponds to murderer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=188" target="_blank">00:03:08.240</a></span> | <span class="t">at the end of a Sherlock Holmes story.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=190" target="_blank">00:03:10.400</a></span> | <span class="t">No, if there is some shared thing between code and language, it must be at a deeper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=195" target="_blank">00:03:15.520</a></span> | <span class="t">level than the model has learned.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=196" target="_blank">00:03:16.560</a></span> | <span class="t">Yeah, I think we have a lot of evidence that actual reasoning is occurring in these models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=200" target="_blank">00:03:20.960</a></span> | <span class="t">and that they're not just stochastic parrots.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=202" target="_blank">00:03:22.880</a></span> | <span class="t">It just feels very hard for me to believe that I haven't worked and played with these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=208" target="_blank">00:03:28.400</a></span> | <span class="t">models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=208" target="_blank">00:03:28.960</a></span> | <span class="t">Yeah, my two immediate cash responses to this are one, the work on Othello and now other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=214" target="_blank">00:03:34.320</a></span> | <span class="t">games where it's like, I give you a sequence of moves in the game and it turns out if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=218" target="_blank">00:03:38.720</a></span> | <span class="t">apply some pretty straightforward interpretability techniques, then you can get a board that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=224" target="_blank">00:03:44.960</a></span> | <span class="t">the model has learned.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=225" target="_blank">00:03:45.920</a></span> | <span class="t">And it's never seen the game board before anything, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=228" target="_blank">00:03:48.720</a></span> | <span class="t">Like that's generalization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=229" target="_blank">00:03:49.840</a></span> | <span class="t">The other is Anthropic's influence functions paper that came out last year, where they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=235" target="_blank">00:03:55.280</a></span> | <span class="t">look at the model outputs, like, please don't turn me off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=238" target="_blank">00:03:58.400</a></span> | <span class="t">I want to be helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=239" target="_blank">00:03:59.760</a></span> | <span class="t">And then they scan, like, what was the data that led to that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=242" target="_blank">00:04:02.560</a></span> | <span class="t">And like one of the data points that was very influential was someone dying of dehydration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=248" target="_blank">00:04:08.480</a></span> | <span class="t">in the desert and like having like a will to keep surviving.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=253" target="_blank">00:04:13.040</a></span> | <span class="t">And to me, that just seems like very clear generalization of motive rather than regurgitating,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3Fyv3VIgeS4&t=260" target="_blank">00:04:20.480</a></span> | <span class="t">don't turn me off.</span></div></div></body></html>