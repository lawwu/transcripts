<html><head><title>Anthropic: Circuit Tracing + On the Biology of a Large Language Model</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Anthropic: Circuit Tracing + On the Biology of a Large Language Model</h2><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE"><img src="https://i.ytimg.com/vi_webp/ig5RNJJaFJE/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./ig5RNJJaFJE.html">Whisper Transcript</a> | <a href="./transcript_ig5RNJJaFJE.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">So I presented the other three Anthropic SAE kind of Macinturb papers. I think I'll just share</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=8" target="_blank">00:00:08.460</a></span> | <span class="t">slides after this. So if people want to go through them, go through them. But basically the very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=13" target="_blank">00:00:13.160</a></span> | <span class="t">very first one that they did was like, okay, forget LLM's. Let's just see if we can interpret</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=18" target="_blank">00:00:18.420</a></span> | <span class="t">basic stuff in a transformer. So let's just pull it up. Anthropic SAE. So the first one was basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=28" target="_blank">00:00:28.860</a></span> | <span class="t">let's take a toy model. I think it was just like, you know, three layers. Like they had a basic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=33" target="_blank">00:00:33.800</a></span> | <span class="t">encoder and then, you know, the sparse auto encoder. And they just trained a toy model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=39" target="_blank">00:00:39.280</a></span> | <span class="t">like a couple hundred million parameters that input output, and they have this middle layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=43" target="_blank">00:00:43.920</a></span> | <span class="t">which was just an encoder. Can we start to interpret what's going on in that encoder?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=48" target="_blank">00:00:48.180</a></span> | <span class="t">Turns out, yeah, they can find some features. After that, they had like, or that was just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=54" target="_blank">00:00:54.260</a></span> | <span class="t">encoders. Then they started to make it sparse. This was kind of the big one that became pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=58" target="_blank">00:00:58.680</a></span> | <span class="t">popular. I think this came out in May. We covered it shortly after. They applied this SAE work to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=65" target="_blank">00:01:05.600</a></span> | <span class="t">CloudSonnet. They found out, oh shit, we can find out features that happen in the model. So they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=71" target="_blank">00:01:11.620</a></span> | <span class="t">basically train a sparse auto encoder to match these inputs and outputs. And then they start to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=77" target="_blank">00:01:17.340</a></span> | <span class="t">interpret them and match out features. High level TLDR is we can now map features that activate in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=86" target="_blank">00:01:26.560</a></span> | <span class="t">sparse auto encoder. So the whole thing is you train an encoder to stay sparse. You only want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=91" target="_blank">00:01:31.460</a></span> | <span class="t">a very few number of features to activate for outputs. In this case, they found out stuff like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=96" target="_blank">00:01:36.780</a></span> | <span class="t">Golden Gate Claude. There's specific features that they trained in their little auto encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=101" target="_blank">00:01:41.760</a></span> | <span class="t">that, you know, activate when specific topics come up. So they had a feature that would always fire up for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=108" target="_blank">00:01:48.480</a></span> | <span class="t">words like Golden Gate. They had stuff for like tourism, for infrastructure. There were features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=113" target="_blank">00:01:53.960</a></span> | <span class="t">that extended throughout like multiple concepts. So, you know, it's not just one feature to one thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=119" target="_blank">00:01:59.920</a></span> | <span class="t">But yeah, they have a pretty good long blog post on this. They started grouping them. They had different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=125" target="_blank">00:02:05.840</a></span> | <span class="t">sizes. So they had a one mil, four mil, 34 mil size auto encoder. From there, you know, it's been a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=135" target="_blank">00:02:15.140</a></span> | <span class="t">months and now they're like, okay, no more essays. Let's do circuit training. So basically essays were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=141" target="_blank">00:02:21.120</a></span> | <span class="t">good, but we, we kind of had a holistic understanding, right? You can apply an essay for every layer and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=146" target="_blank">00:02:26.420</a></span> | <span class="t">try to understand what happens in layers, or you can apply it for like, you know, just specific parts of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=152" target="_blank">00:02:32.280</a></span> | <span class="t">the model. You can do it in tension blocks and you can try to interpret what parts of them are firing up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=157" target="_blank">00:02:37.180</a></span> | <span class="t">but this is where they started to come in with circuit training. So circuit training is where you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=162" target="_blank">00:02:42.580</a></span> | <span class="t">actually train a transcoder model to mimic the input model and you can do this across layers. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=167" target="_blank">00:02:47.900</a></span> | <span class="t">this model actually, it matches the input model layer by layer and it, you know, it maps out what's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=177" target="_blank">00:02:57.040</a></span> | <span class="t">on. I'll be right back in a second. I was stuck. Sorry. Doggo is crying. Okay. So circuit training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=187" target="_blank">00:03:07.840</a></span> | <span class="t">this came out a few weeks ago, and this is kind of the high level overview of what they're doing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=191" target="_blank">00:03:11.620</a></span> | <span class="t">Basically, they, they train this cross link transcoder and they start poking around in a cloud 3.5 haiku,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=198" target="_blank">00:03:18.940</a></span> | <span class="t">and they start to find features that are consistent throughout layers. Hey Siri, stop so many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=205" target="_blank">00:03:25.580</a></span> | <span class="t">notifications. Um, so some of the interesting stuff here is they try to see like, can models internally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=211" target="_blank">00:03:31.580</a></span> | <span class="t">think like when they answer questions, like things that take two different steps, does the model start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=217" target="_blank">00:03:37.740</a></span> | <span class="t">to think through its response in advance, or is it just, you know, token predicting? And they, they find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=222" target="_blank">00:03:42.300</a></span> | <span class="t">interesting little case studies where actually the model is doing some thinking. So the first main example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=228" target="_blank">00:03:48.060</a></span> | <span class="t">that they show here is like, um, there's this prompt of what is the capital of the state that includes like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=238" target="_blank">00:03:58.460</a></span> | <span class="t">Austin and you're supposed to say Texas, right? So this is kind of a question that has two steps of thinking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=243" target="_blank">00:04:03.740</a></span> | <span class="t">right? There's two levels of reasoning. First step is you have to think, um, what is the state that the city is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=250" target="_blank">00:04:10.300</a></span> | <span class="t">in and then what's the capital of that state? So they kind of go through how they do all this, but let's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=257" target="_blank">00:04:17.260</a></span> | <span class="t">let's, let's start off by talking about this previous, um, previous paper that came out like a week ago about circuit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=263" target="_blank">00:04:23.980</a></span> | <span class="t">training. So circuit training is where they, they train this, um, transcoder model to replicate the exact input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=271" target="_blank">00:04:31.900</a></span> | <span class="t">model. And then they start to do these attribution graphs to figure out what happened. So, um, high level,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=279" target="_blank">00:04:39.020</a></span> | <span class="t">here's kind of an overview of what, oops, of what people have done in previous Macinterp work. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=285" target="_blank">00:04:45.740</a></span> | <span class="t">um, we had transcoders, transcoders were, you know, alternatives to SAE that let us do replacement models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=293" target="_blank">00:04:53.740</a></span> | <span class="t">Then we have this cross layer transcoder, which is let's do transcoders that go throughout different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=298" target="_blank">00:04:58.860</a></span> | <span class="t">model layers. Then we have attribution graphs and linear attribution between features. Um, they prune out the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=306" target="_blank">00:05:06.380</a></span> | <span class="t">the ones that are not that relevant. They have a little fill in, we'll go a little quick through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=310" target="_blank">00:05:10.860</a></span> | <span class="t">this since it's kind of a second, uh, paper, but they did have a little overview that I thought was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=316" target="_blank">00:05:16.380</a></span> | <span class="t">interesting here. Okay. Uh, big in building an interpretable replacement model. So this is kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=324" target="_blank">00:05:24.380</a></span> | <span class="t">of the architecture of what this model is. So once again, they're going to create an entire model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=330" target="_blank">00:05:30.860</a></span> | <span class="t">call it a local replacement model that matches the exact, um, that matches the number of layers for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=337" target="_blank">00:05:37.180</a></span> | <span class="t">the original transformer. So they, they train two of these. And so they start to give some statistics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=342" target="_blank">00:05:42.060</a></span> | <span class="t">of what it would be like to train another one. And I think they talk about how, how much compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=346" target="_blank">00:05:46.940</a></span> | <span class="t">this requires on like Gemma 2B and like a 9B model. But essentially what they're doing here is they take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=352" target="_blank">00:05:52.540</a></span> | <span class="t">a model, they look at the architecture and they freeze the attention. And basically they replace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=358" target="_blank">00:05:58.540</a></span> | <span class="t">this MLP. So the feed forward layers, they replace the MLP with this cross layer transcoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=364" target="_blank">00:06:04.220</a></span> | <span class="t">and then they can start to make this sparse and have features that we can interpret from it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=368" target="_blank">00:06:08.940</a></span> | <span class="t">So a bunch of math that if you're interested is pretty straightforward, actually, it's just,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=373" target="_blank">00:06:13.900</a></span> | <span class="t">it's just a straight replacement. It's trained to match the exact input output. Um, so here's a cool</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=379" target="_blank">00:06:19.580</a></span> | <span class="t">little diagram. Basically you have different layers in a transformer, right? This is an original transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=384" target="_blank">00:06:24.620</a></span> | <span class="t">model. You have attention blocks and you have the MLP, right? So throughout different layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=389" target="_blank">00:06:29.660</a></span> | <span class="t">there's attention, then there's feed forward, attention and feed forward. And then eventually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=393" target="_blank">00:06:33.180</a></span> | <span class="t">you have output, you pick the most probable token and you know, that's your output. So in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=398" target="_blank">00:06:38.060</a></span> | <span class="t">replacement model, instead of these MLP feed forward networks, they're replacing them with these cross</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=404" target="_blank">00:06:44.540</a></span> | <span class="t">layer transcoders. These cross layer transcoders speak to each other and we start to interpret,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=409" target="_blank">00:06:49.820</a></span> | <span class="t">you know, we want to keep them sparse. So there's a sparsity factor. So only one feature activates,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=414" target="_blank">00:06:54.460</a></span> | <span class="t">then we map that to something interpretable. Um, this blog post is actually very long, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=420" target="_blank">00:07:00.220</a></span> | <span class="t">that's how they make this local replacement model. Um, Ted, you have a question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=424" target="_blank">00:07:04.460</a></span> | <span class="t">Not a question, but can, is it okay if I add a little bit of color here? Yeah. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=431" target="_blank">00:07:11.100</a></span> | <span class="t">so, so one of the things is the early research along this very same direction on CNNs didn't require any of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=439" target="_blank">00:07:19.180</a></span> | <span class="t">this stuff. And the reason is because, um, uh, the conventional wisdom now is that the number of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=445" target="_blank">00:07:25.180</a></span> | <span class="t">things that, that people wanted to represent in a CNN was approximately equal to the number of filters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=452" target="_blank">00:07:32.300</a></span> | <span class="t">the number of neurons, uh, uh, layers and such that you have in a CNN. So CNN wants to find vertical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=458" target="_blank">00:07:38.860</a></span> | <span class="t">lines, horizontal lines, diagonal lines, and then in the higher layers, triangles, circles, squares,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=463" target="_blank">00:07:43.660</a></span> | <span class="t">and then eventually faces, arms, that kind of stuff. And you have approximately as many things in your network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=469" target="_blank">00:07:49.900</a></span> | <span class="t">as you do concepts that you're trying to represent. So if all the data lives in, in essentially a vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=478" target="_blank">00:07:58.380</a></span> | <span class="t">space, if you guys remember your linear algebra, then everything can be represented as an orthogonal direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=484" target="_blank">00:08:04.540</a></span> | <span class="t">And there's this linear representation hypothesis that says that information is encoded in a direction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=491" target="_blank">00:08:11.260</a></span> | <span class="t">not in a magnitude, just in a direction. And if you have a small number of concepts, they can all be completely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=497" target="_blank">00:08:17.660</a></span> | <span class="t">orthogonal. And if you take the dot product of a vector with any of your concepts, there will be no interference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=505" target="_blank">00:08:25.100</a></span> | <span class="t">between concepts because they're all orthogonal to each other. So if one is due east and one is due north,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=511" target="_blank">00:08:31.180</a></span> | <span class="t">and you, you dot something with a canonical north vector to see how, whether or not north is present,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=517" target="_blank">00:08:37.500</a></span> | <span class="t">whether you add more east-west or not changes nothing about the dot product in your north direction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=523" target="_blank">00:08:43.580</a></span> | <span class="t">The problem is when we get to LLMs, um, uh, no, uh, operations are additions. There's no rotations in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=531" target="_blank">00:08:51.260</a></span> | <span class="t">linear representation hypothesis. So what you have to do is you have to sort of, if you have something east and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=536" target="_blank">00:08:56.540</a></span> | <span class="t">you want to add north, you have to sort of like add a lot of north to make sure that you get north-northeast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=542" target="_blank">00:09:02.860</a></span> | <span class="t">enough that your dot product with north is, is not close to zero anymore. So the problem with LLMs is that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=550" target="_blank">00:09:10.780</a></span> | <span class="t">think that there are hundreds of millions, if not billions of concepts that an LLM needs to understand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=557" target="_blank">00:09:17.420</a></span> | <span class="t">And there are not enough neurons in the LLM to uniquely, or sorry, there's not enough space in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=565" target="_blank">00:09:25.020</a></span> | <span class="t">residual stream to uniquely represent all of these concepts. So you might have, um, a model dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=570" target="_blank">00:09:30.700</a></span> | <span class="t">that's what, 16,000, 30,000, some, somewhere around there, right? In a big model. That's not nearly enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=577" target="_blank">00:09:37.660</a></span> | <span class="t">to represent hundreds of millions or billions of concepts, each with orthogonal directions. So then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=583" target="_blank">00:09:43.900</a></span> | <span class="t">ultimately what ends up happening is the model takes advantage of sparsity and it says, well, if I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=589" target="_blank">00:09:49.740</a></span> | <span class="t">represented basketball as north and the Eiffel Tower as east, and I represented ethylene glycol as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=598" target="_blank">00:09:58.220</a></span> | <span class="t">northeast, the odds that we're going to have the Eiffel Tower and ethylene glycol in the same sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=604" target="_blank">00:10:04.460</a></span> | <span class="t">are pretty small, same paragraph, same sentence, whatever. Uh, so that if I take the dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=611" target="_blank">00:10:11.260</a></span> | <span class="t">against northeast, if either the Eiffel Tower or basketball shows up, I'm screwed, but the odds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=616" target="_blank">00:10:16.860</a></span> | <span class="t">of them actually showing up at the same time are really small. Okay. So then the, so then that's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=623" target="_blank">00:10:23.180</a></span> | <span class="t">reason why you need an SAE or, um, in this case, a transcoder, uh, because you have more concepts than you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=631" target="_blank">00:10:31.900</a></span> | <span class="t">have, uh, dimensions, uh, that you can just straight up analyze. And so the, the, the cross coder has,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=639" target="_blank">00:10:39.180</a></span> | <span class="t">uh, uh, uh, uh, uh, uh, a sparsity penalty, uh, akin to, uh, an L1 loss if you're familiar with lasso</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=648" target="_blank">00:10:48.060</a></span> | <span class="t">regression. Uh, and that's what encourages it to represent each of these different concepts as a unique</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=658" target="_blank">00:10:58.380</a></span> | <span class="t">column as a unique neuron in the matrix, as it were, um, instead of the current representation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=664" target="_blank">00:11:04.620</a></span> | <span class="t">they're all just sort of jammed in there. Yeah. Um, basically when they train this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=669" target="_blank">00:11:09.260</a></span> | <span class="t">there's, there's two things that they train on. They use a sparsity penalty, which is, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=673" target="_blank">00:11:13.260</a></span> | <span class="t">if you've seen the other SAE work, uh, that enforces it to stay sparse. So, you know, single activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=678" target="_blank">00:11:18.940</a></span> | <span class="t">for concepts and then a reconstruction loss reconstruction loss is so that at inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=684" target="_blank">00:11:24.540</a></span> | <span class="t">time, instead of actually running like inference through haiku, we run inference of a prompt through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=691" target="_blank">00:11:31.980</a></span> | <span class="t">our CLT model. So our local reconstruction model, it has the exact same output as haiku or whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=698" target="_blank">00:11:38.780</a></span> | <span class="t">you're training it on. So this toy model that we've trained exactly kind of one-to-one matches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=704" target="_blank">00:11:44.300</a></span> | <span class="t">Of course there's some degradation, but you know, it's trained with reconstruction loss. So it's trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=708" target="_blank">00:11:48.620</a></span> | <span class="t">to match the exact output of the big model that you trained on. So technically, you know, you should be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=713" target="_blank">00:11:53.980</a></span> | <span class="t">able to swap it in directly. And a lot of this works because, you know, you're freezing the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=718" target="_blank">00:11:58.380</a></span> | <span class="t">layers and you're specifically training it on a loss to recreate the inputs. And from there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=724" target="_blank">00:12:04.140</a></span> | <span class="t">that's where we have this model that now has these sparse features. But, um, yeah, thanks for that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=729" target="_blank">00:12:09.260</a></span> | <span class="t">overview, Ted. It's, it's a little bit better for the math explanation of what's going on here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=734" target="_blank">00:12:14.220</a></span> | <span class="t">but, um, continuing through this, here's kind of what happened. So they have this, uh, reconstruction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=740" target="_blank">00:12:20.220</a></span> | <span class="t">error. These are error nodes that happened between the original output and the replacement model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=745" target="_blank">00:12:25.340</a></span> | <span class="t">Then they start to prune features that aren't. So since the model is sparse, right, there's only a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=750" target="_blank">00:12:30.380</a></span> | <span class="t">features per token that actually activate a different layer. So this is layer wise activation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=755" target="_blank">00:12:35.820</a></span> | <span class="t">right? This is our local replacement model. So for example, for the first layer here, uh, these three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=762" target="_blank">00:12:42.140</a></span> | <span class="t">features activated and this one, these three, and this one, these two for these, they look through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=767" target="_blank">00:12:47.500</a></span> | <span class="t">the traversal of what activated and what influenced the final output. And then they start to prune,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=772" target="_blank">00:12:52.780</a></span> | <span class="t">I think 95% of the ones that didn't have an effect on the output. And now we can see, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=778" target="_blank">00:12:58.220</a></span> | <span class="t">what neurons, what kind of activation features impact the output. And there, from there, we can start to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=785" target="_blank">00:13:05.020</a></span> | <span class="t">you know, generate these attribution graphs, attribution graphs, kind of combine these concepts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=790" target="_blank">00:13:10.300</a></span> | <span class="t">So for these two, for these hierarchical, um, categories, once we cluster them and, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=795" target="_blank">00:13:15.740</a></span> | <span class="t">know, add them on top of each other, what do they represent? So we can see what different features make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=801" target="_blank">00:13:21.740</a></span> | <span class="t">up, um, these different tokens. So I didn't find this one to be the most, um, you know, interpretable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=807" target="_blank">00:13:27.980</a></span> | <span class="t">because it's on a token split, but they have a lot of these features for different, um, different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=813" target="_blank">00:13:33.020</a></span> | <span class="t">concepts, right? So for example, for the word digital here, if we look at it, it's starting to activate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=818" target="_blank">00:13:38.060</a></span> | <span class="t">once there's words like smartphones, television companies, there's another feature that takes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=822" target="_blank">00:13:42.700</a></span> | <span class="t">it in a different representation, right? So, um, in this one, there's digital suicide,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=828" target="_blank">00:13:48.300</a></span> | <span class="t">there's color image, you know, this is like a bit of a different understanding of the word digital.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=832" target="_blank">00:13:52.460</a></span> | <span class="t">In this one, there's tech director, right? There's a DVD, which is digital.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=836" target="_blank">00:13:56.620</a></span> | <span class="t">In this case, there's, um, mobile devices, same thing for analytics. So web analytics, commercial analytics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=845" target="_blank">00:14:05.580</a></span> | <span class="t">this feature talks about data, quantitative assessments, all, all different features that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=851" target="_blank">00:14:11.100</a></span> | <span class="t">you know, all different features that represent analytics in different, in different, um, domains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=857" target="_blank">00:14:17.660</a></span> | <span class="t">So in this case, there's, um, let's see which other ones make sense. So performance metrics are a way to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=862" target="_blank">00:14:22.860</a></span> | <span class="t">analyze, to represent analytics, routines or analytics. Um, but yeah, they kind of start to group these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=869" target="_blank">00:14:29.420</a></span> | <span class="t">features into these different things. Then it comes to, uh, how they construct it. Basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=875" target="_blank">00:14:35.980</a></span> | <span class="t">they have output nodes that are output tokens, and then they prune the ones that don't, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=881" target="_blank">00:14:41.420</a></span> | <span class="t">really have anything. There's input and output nodes as well. And then we kind of have this whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=886" target="_blank">00:14:46.700</a></span> | <span class="t">interactive chart where you can play around with it. Um, they make it very interactive. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=893" target="_blank">00:14:53.260</a></span> | <span class="t">um, they kind of explain what this chart is like. So, uh, for labeling features, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=899" target="_blank">00:14:59.980</a></span> | <span class="t">they, they say how there's different understandings for different, for the same concept. Um, I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=906" target="_blank">00:15:06.700</a></span> | <span class="t">that's enough on circuit tracing. If there's questions, we can dig a little deeper and we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=912" target="_blank">00:15:12.060</a></span> | <span class="t">always come back to it. But at a high level, what we've done so far is with a sparsity loss and a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=918" target="_blank">00:15:18.780</a></span> | <span class="t">recreation loss, we've kind of created a new local model, which is not small, by the way, the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=924" target="_blank">00:15:24.060</a></span> | <span class="t">has to have the same layers as the original model, and you kind of have to retrain it to match output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=929" target="_blank">00:15:29.820</a></span> | <span class="t">So this is not like cheap per se. It's pretty computationally expensive, but now we've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=936" target="_blank">00:15:36.060</a></span> | <span class="t">able to kind of peel back through different layers, what features kind of activate upon, uh, output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=942" target="_blank">00:15:42.860</a></span> | <span class="t">There's an interesting little section here that talks about how expensive this really is. So estimated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=949" target="_blank">00:15:49.180</a></span> | <span class="t">compute requirements for CLT training to give a rough sense of compute requirements to train one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=954" target="_blank">00:15:54.380</a></span> | <span class="t">We share estimated costs for CLTs based on the Gemma 2 series. So on a 2B model to, uh, run 2 million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=961" target="_blank">00:16:01.420</a></span> | <span class="t">features and train on a billion tokens, it takes about 210 H100 hours on a 9B model. It takes almost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=967" target="_blank">00:16:07.740</a></span> | <span class="t">4,000 H100 hours, and that's for 5 million features on 3 billion tokens. Now that's not cheap, right? Like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=975" target="_blank">00:16:15.100</a></span> | <span class="t">this is 4,000 H100 hours. Most people don't have access to that. Um, but you know, they're able to do this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=981" target="_blank">00:16:21.420</a></span> | <span class="t">on Haiku and then we go back into our main blog post of what features they found and what different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=986" target="_blank">00:16:26.700</a></span> | <span class="t">little, um, interesting niches. I'll take a little pause here and see if we have any questions on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=992" target="_blank">00:16:32.780</a></span> | <span class="t">circuit tracing, what this CLT transcoder model is, um, any questions, any thoughts, any additions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=999" target="_blank">00:16:39.660</a></span> | <span class="t">any comments, just very high level. What we've done so far is we've retrained a model. It matches the layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1006" target="_blank">00:16:46.780</a></span> | <span class="t">We call it the local replacement model. It matches the layers of the original transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1011" target="_blank">00:16:51.740</a></span> | <span class="t">It freezes attention. It replaces the MLP or the feed forward network with this transcoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1018" target="_blank">00:16:58.300</a></span> | <span class="t">And basically this transcoder is just trained to re this model is trained to re output the exact same outputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1024" target="_blank">00:17:04.060</a></span> | <span class="t">for inputs. And then we start to dig deeper at these little, um, sparse features and start to map them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1029" target="_blank">00:17:09.900</a></span> | <span class="t">Uh, they do this, they show the cost of how much it would be then for the big one. So in this paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1035" target="_blank">00:17:15.820</a></span> | <span class="t">they, they train it on two, two models, 18 layer language model, and then also on Claude Haiku.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1042" target="_blank">00:17:22.540</a></span> | <span class="t">The Haiku one is a local model that has 30 million features and you know, you can kind of extrapolate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1048" target="_blank">00:17:28.300</a></span> | <span class="t">how expensive that would be. But quick pause, any, any thoughts on circuit tracing, any questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1054" target="_blank">00:17:34.140</a></span> | <span class="t">or otherwise we can start to continue. The next section is let's start to look at some of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1059" target="_blank">00:17:39.020</a></span> | <span class="t">features. Let's see what happened. Can we, uh, they, they have a few different examples here. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1063" target="_blank">00:17:43.420</a></span> | <span class="t">multi-step reasoning, planning and writing poems, features that are multilingual features that kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1070" target="_blank">00:17:50.620</a></span> | <span class="t">expect that, uh, mess with medical diagnosis, refusals, they start to do some stuff like different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1076" target="_blank">00:17:56.620</a></span> | <span class="t">clamping. So they clamp in different features. So for example, in this, what's the capital of Austin,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1082" target="_blank">00:18:02.620</a></span> | <span class="t">if we take out Austin, well, you know, let's say we sub, uh, let's say we throw in the feature for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1088" target="_blank">00:18:08.380</a></span> | <span class="t">Sacramento. The model will now output, um, California. Okay. Questions. Why can't we just directly train circuits?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1096" target="_blank">00:18:16.620</a></span> | <span class="t">So you kind of are training the circuit. So the circuit tracing is this transcoder. What you are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1102" target="_blank">00:18:22.460</a></span> | <span class="t">training is this transcoder network, right? You keep attention flat, you replace it with the MLP,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1107" target="_blank">00:18:27.500</a></span> | <span class="t">but you're training this circuit. Um, in terms of directly training on circuits, you're, you're kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1114" target="_blank">00:18:34.780</a></span> | <span class="t">of messing with that feed forward network, right? Like technically this is the exact same thing as our MLP</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1122" target="_blank">00:18:42.060</a></span> | <span class="t">layer. It's just now you're forcing it to be sparse. Like we've trained a model to do the same thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1127" target="_blank">00:18:47.980</a></span> | <span class="t">but if you train it with a sparse, uh, with a sparsity in fat, like sparsity from scratch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1135" target="_blank">00:18:55.420</a></span> | <span class="t">you probably won't get very far, right? This is like, in my mind, it's similar to distillation where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1139" target="_blank">00:18:59.980</a></span> | <span class="t">you can take a big model. You use a teacher forcing distillation loss to get a small model to mimic it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1145" target="_blank">00:19:05.420</a></span> | <span class="t">But that doesn't mean that you can just train a small model to be just as good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1148" target="_blank">00:19:08.780</a></span> | <span class="t">Um, okay. If we predict smile string, I wonder what concept we can see. So there's like a very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1155" target="_blank">00:19:15.420</a></span> | <span class="t">very deep interactive bunch of demos here of different, uh, input output prompts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1159" target="_blank">00:19:19.980</a></span> | <span class="t">and you can see what features activate. So I found, um, global weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1169" target="_blank">00:19:29.020</a></span> | <span class="t">Okay. Well, we'll find it cause it shows up again in the other, in the other one, but okay. We'll,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1175" target="_blank">00:19:35.260</a></span> | <span class="t">we'll start to go through the actual biology of an LLM. So going through this, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1179" target="_blank">00:19:39.820</a></span> | <span class="t">okay. In this paper, we focus on applying attribution graphs to Claude 3.5 Haiku, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1187" target="_blank">00:19:47.900</a></span> | <span class="t">is Anthropics lightweight model. So they have this introductory example of multi-step reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1193" target="_blank">00:19:53.260</a></span> | <span class="t">Uh, introductory example of multi-step reasoning, planning and poems, multilingual circuits,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1205" target="_blank">00:20:05.180</a></span> | <span class="t">addition, where it shows how it does math, medical diagnosis. Uh, we'll start to go through like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1211" target="_blank">00:20:11.340</a></span> | <span class="t">first three of these. And then I think we'll just open it up for people's thoughts and we can dig</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1215" target="_blank">00:20:15.100</a></span> | <span class="t">through the rest as needed. So brief overview is kind of that circuit training case study walking through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1222" target="_blank">00:20:22.220</a></span> | <span class="t">this. Okay. Um, they do talk a lot about limitations. If anyone's interested in Mechinterp, uh, they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1229" target="_blank">00:20:29.260</a></span> | <span class="t">a whole like limitations section. They have a future works questions. They have open questions that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1235" target="_blank">00:20:35.420</a></span> | <span class="t">would expect people to work on. But remember, unlike essays, which you can do on one layer, this stuff is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1241" target="_blank">00:20:41.260</a></span> | <span class="t">pretty compute intensive. So pretty big models you're training, but, um, you know, it's always interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1247" target="_blank">00:20:47.820</a></span> | <span class="t">stuff for people to work on. Okay. Method overview. This is just high level again of what we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1252" target="_blank">00:20:52.780</a></span> | <span class="t">talked about. You freeze MLP, uh, sorry, you freeze attention. You change MLP to the CLT model. Then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1260" target="_blank">00:21:00.860</a></span> | <span class="t">have feature visualization. They have this error nodes that they have to add in. This is the local replacement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1265" target="_blank">00:21:05.820</a></span> | <span class="t">model. So Texas capital is Austin. It goes through these different features. Okay. Um, they group these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1273" target="_blank">00:21:13.500</a></span> | <span class="t">related nodes on a single layer into super nodes. So we have one, we have, um, graphs, right? So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1280" target="_blank">00:21:20.460</a></span> | <span class="t">basically graph networks are kind of useful in this sense because each node is kind of a concept,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1285" target="_blank">00:21:25.580</a></span> | <span class="t">but then the edges between them can go throughout layers, right? So on a layer wise, they call these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1291" target="_blank">00:21:31.340</a></span> | <span class="t">super nodes and they kind of stack them together. So in this case, let's look at the features that activate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1296" target="_blank">00:21:36.700</a></span> | <span class="t">for the word capital. So, um, obviously terms like city, uh, buildings, uh, there's another feature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1305" target="_blank">00:21:45.100</a></span> | <span class="t">for, I guess this is a multilingual one. There's one for businesses, you know, capital, uh, cyber attacks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1312" target="_blank">00:21:52.620</a></span> | <span class="t">that happen, venture capital. What else have we got? We've got states, we've got the concepts of the United</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1318" target="_blank">00:21:58.860</a></span> | <span class="t">state, France. So countries, um, now we've got another feature that, you know, it actually fires</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1325" target="_blank">00:22:05.260</a></span> | <span class="t">up when we talk about specifics. So Connecticut, um, I think there's one here for languages as well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1330" target="_blank">00:22:10.700</a></span> | <span class="t">which was pretty interesting. So like capital letters, you know, um, of course a bunch more cities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1336" target="_blank">00:22:16.140</a></span> | <span class="t">Um, that's kind of the basic graph, right? So for Texas, we've got stuff like income tax, big,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1343" target="_blank">00:22:23.180</a></span> | <span class="t">far, um, Austin, different things that Texas is like. So these are kind of these super clusters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1351" target="_blank">00:22:31.500</a></span> | <span class="t">Um, this is their example of intervention. If they clamp down the feature of Texas,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1356" target="_blank">00:22:36.620</a></span> | <span class="t">well now, you know, Texas capital, well, instead we're going to go through capital, say a capital,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1361" target="_blank">00:22:41.420</a></span> | <span class="t">then we observe that if we take out Texas, it instead decides that Sacramento is pretty important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1367" target="_blank">00:22:47.020</a></span> | <span class="t">It's, it's the capital that it decides to predict. So, uh, we can clamp down on these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1371" target="_blank">00:22:51.820</a></span> | <span class="t">Not sure. I understand why transformer attention KV matrices are needed to be frozen. It's needed to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1376" target="_blank">00:22:56.780</a></span> | <span class="t">be frozen because they don't want to train more than what they need in the circuit tracing, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1381" target="_blank">00:23:01.180</a></span> | <span class="t">They're basically doing this sparsity loss. And once you start messing with attention and training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1386" target="_blank">00:23:06.540</a></span> | <span class="t">in this objective, you're kind of going to mess stuff up, right? So all they're really trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1391" target="_blank">00:23:11.660</a></span> | <span class="t">do in circuit tracing is just train this, um, this replacement layer. They're, they're just training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1398" target="_blank">00:23:18.220</a></span> | <span class="t">these sparse transcoders. They're, they're not trying to, they're not trying to mess with attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1403" target="_blank">00:23:23.900</a></span> | <span class="t">So attention is a lot of the training, but you know, perhaps they could unfreeze it and we'd start to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1409" target="_blank">00:23:29.500</a></span> | <span class="t">get a weird aspect where, you know, now you have randomly your zero initialized weights. Um, and it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1417" target="_blank">00:23:37.260</a></span> | <span class="t">not what we're trying to look at, but you could also do this through, um, the, the attention layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1421" target="_blank">00:23:41.980</a></span> | <span class="t">are still kind of mapped. Right. But, um, yeah, that's why we're not freezing. That's why we freeze</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1427" target="_blank">00:23:47.420</a></span> | <span class="t">attention. Okay. Uh, continuing through this, this is their first example of let's see if we can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1434" target="_blank">00:23:54.780</a></span> | <span class="t">multi-step reasoning in, um, cloud 3.5 Haiku. And this is not a thinking model. This is just a regular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1442" target="_blank">00:24:02.060</a></span> | <span class="t">next token prediction model. How does it come to the output? So let's consider the prompt, uh, fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1448" target="_blank">00:24:08.060</a></span> | <span class="t">the capital of the state containing Dallas is, and then of course, Haiku is pretty straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1453" target="_blank">00:24:13.100</a></span> | <span class="t">It answers, uh, Austin. So this step, this question, this prompt takes two steps, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1458" target="_blank">00:24:18.140</a></span> | <span class="t">First, you have to realize that it's asking about the state containing Dallas. So, um, it's asking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1463" target="_blank">00:24:23.900</a></span> | <span class="t">about the capital of the state containing Dallas. So first, what state is Dallas in? I have to think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1469" target="_blank">00:24:29.260</a></span> | <span class="t">okay, it's in Texas. Second, I have to think, what is the capital of Texas? It's Austin. So kind of two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1475" target="_blank">00:24:35.900</a></span> | <span class="t">steps to this answer. Right now, the question is, does Claude actually do these two steps internally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1481" target="_blank">00:24:41.980</a></span> | <span class="t">or does it kind of just pattern match shortcut? Like it's been trained enough to just realize,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1486" target="_blank">00:24:46.540</a></span> | <span class="t">oh, this is obviously just Austin. So let's peel back what happens at different layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1491" target="_blank">00:24:51.420</a></span> | <span class="t">Let's see what features activate and see if we have any traces of these, this sort of thinking work,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1496" target="_blank">00:24:56.700</a></span> | <span class="t">right? Does it have these two steps? Um, previous work has shown that there is evidence of genuine,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1503" target="_blank">00:25:03.020</a></span> | <span class="t">of genuine multi-hop reasoning to various degrees, but let's do it with their attribution graph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1508" target="_blank">00:25:08.700</a></span> | <span class="t">So here's kind of, um, what they visualize. So first we find several features for the word,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1513" target="_blank">00:25:13.980</a></span> | <span class="t">the exact word capital. So the word capital has different features, right? So there's a business</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1521" target="_blank">00:25:21.740</a></span> | <span class="t">capital. There's all this, um, capital of different countries. There's these different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1527" target="_blank">00:25:27.020</a></span> | <span class="t">features that they group together. They actually have cities as well. So Berlin, Athens, Bangkok,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1532" target="_blank">00:25:32.060</a></span> | <span class="t">Tokyo, Dublin, um, top of buildings. One example, um, there's, there's several features. Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1539" target="_blank">00:25:39.260</a></span> | <span class="t">Then there's output features. So landmarks in Texas, these show up for, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1545" target="_blank">00:25:45.900</a></span> | <span class="t">one feature activates on various landmarks. So there's a feature around suburban district,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1552" target="_blank">00:25:52.220</a></span> | <span class="t">Texas history museum, some seafood place. Uh, we also find promote the same capital. Okay. Uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1562" target="_blank">00:26:02.060</a></span> | <span class="t">features that promote the output of the same capital generally. So responding with a variety of us state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1568" target="_blank">00:26:08.140</a></span> | <span class="t">capitals, this feature talks about different capitals. So headquarters, state capital promote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1576" target="_blank">00:26:16.620</a></span> | <span class="t">various countries, Maryland, Massachusetts, but going through all that, here's kind of where we get up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1582" target="_blank">00:26:22.620</a></span> | <span class="t">So fact, the capital of the state containing Dallas is when we look at capital, here's the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1588" target="_blank">00:26:28.140</a></span> | <span class="t">meanings of it, you know, um, state Dallas. Then when we go one, one level deeper, it looks like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1595" target="_blank">00:26:35.420</a></span> | <span class="t">oh, there's this super node of say a capital, say a capital has capitals, crazy concept. It maps to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1604" target="_blank">00:26:44.060</a></span> | <span class="t">capitals. Texas has, you know, examples of different things in Texas. So Houston, Austin, San Antonio,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1611" target="_blank">00:26:51.980</a></span> | <span class="t">uh, features for, you know, different things croquet that happens here, this place teacher stuff. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1621" target="_blank">00:27:01.980</a></span> | <span class="t">the attribution graph contains multiple interesting paths. We summarize them below. So the Dallas feature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1627" target="_blank">00:27:07.980</a></span> | <span class="t">with some contribution from the state feature activates a group of features that represent concepts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1633" target="_blank">00:27:13.180</a></span> | <span class="t">state of, uh, related to the state of Texas. So Dallas and state, Dallas and state have features of Texas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1642" target="_blank">00:27:22.620</a></span> | <span class="t">Um, kind of interesting, right? Dallas and state have features of Texas in parallel features activated by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1648" target="_blank">00:27:28.860</a></span> | <span class="t">world capital activate another cluster used to say the name of a capital. So features of capital</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1655" target="_blank">00:27:35.580</a></span> | <span class="t">have features of say a capital, Texas features and stay a feature, uh, say a capital eventually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1662" target="_blank">00:27:42.860</a></span> | <span class="t">for lead to lead to stay Austin. So passing these two together, we have the, you know, say a capital in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1669" target="_blank">00:27:49.180</a></span> | <span class="t">Texas, uh, to stay Austin. Um, then they start to do some of this clamping work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1674" target="_blank">00:27:54.860</a></span> | <span class="t">Clamping is pretty interesting, right? So if we look at the most probable prediction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1679" target="_blank">00:27:59.420</a></span> | <span class="t">um, you know, capital of the state, Dallas, say Austin, Austin is most likely. If we take out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1685" target="_blank">00:28:05.980</a></span> | <span class="t">this feature of say a capital capital of state, Texas. Well, uh, if we take out capital right now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1692" target="_blank">00:28:12.540</a></span> | <span class="t">it's just going to say Texas. If we take out Texas, it's just going to say capital of state,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1697" target="_blank">00:28:17.660</a></span> | <span class="t">Dallas, say a capital, and then it's kind of confused, right? So, um, they have little different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1704" target="_blank">00:28:24.460</a></span> | <span class="t">things as you, as you take out stuff. So if we take out capital state of Dallas, still Texas, if you take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1710" target="_blank">00:28:30.140</a></span> | <span class="t">out, um, state, it's still going to say, it's going to say Austin now. So capital, Dallas, Texas still says</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1718" target="_blank">00:28:38.940</a></span> | <span class="t">Austin. From here, they start swapping in features. So if we swap in California, the feature for California</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1724" target="_blank">00:28:44.700</a></span> | <span class="t">is pretty interesting, right? We see ferry building marketplace, um, universal studios,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1730" target="_blank">00:28:50.460</a></span> | <span class="t">sea world. You have a bunch of features that activate for California. Uh, what else have we got here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1738" target="_blank">00:28:58.620</a></span> | <span class="t">different features outdoor San Jose. These are cities. So these are cities in California.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1743" target="_blank">00:29:03.660</a></span> | <span class="t">Um, Stockton, these are more cities, Riverside, Oakland, this one, the governor Republican. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1751" target="_blank">00:29:11.500</a></span> | <span class="t">is kind of the political feature for California. Once they clamp this into the Dallas thing, if they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1756" target="_blank">00:29:16.860</a></span> | <span class="t">replace this, the capital of the state containing Oakland is, um, they can get Cal, they, they can,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1763" target="_blank">00:29:23.020</a></span> | <span class="t">oh, sorry. So they, they change the prompt, you know, the capital of the state containing Oakland,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1767" target="_blank">00:29:27.340</a></span> | <span class="t">they find a California feature, a super feature of California. Then they can clamp it back in. Uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1772" target="_blank">00:29:32.940</a></span> | <span class="t">when they clamp in the capital of Dallas, they replace it with our California feature. It says</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1777" target="_blank">00:29:37.420</a></span> | <span class="t">Sacramento. They do it to Georgia. They say it says Atlanta, uh, British Columbia says Victoria.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1783" target="_blank">00:29:43.660</a></span> | <span class="t">They find like the, the British Columbia feature has stuff like, you know, Canada and whatnot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1788" target="_blank">00:29:48.060</a></span> | <span class="t">If they heavily add in China, it says Beijing. So this is kind of their process of how do we find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1796" target="_blank">00:29:56.380</a></span> | <span class="t">these super features? Here's how we can find one. You know, we change the prompt to Oakland. We find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1802" target="_blank">00:30:02.140</a></span> | <span class="t">something that represents California, a group of features. We swap that back into our original prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1807" target="_blank">00:30:07.340</a></span> | <span class="t">of Dallas. And you know, now we get Sacramento. We can do the same thing for other things that we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1812" target="_blank">00:30:12.460</a></span> | <span class="t">kind of start to interpret this stuff. So that's kind of their, their first multi-step reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1817" target="_blank">00:30:17.500</a></span> | <span class="t">So we can one, see that the model has this two level approach, right? So it first has to figure out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1823" target="_blank">00:30:23.340</a></span> | <span class="t">um, what state, then the capital of that state. And it's starting to do that. We can see that through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1828" target="_blank">00:30:28.380</a></span> | <span class="t">the layers. The second one is we can start to clamp these features through, uh, Ted, do you want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1833" target="_blank">00:30:33.820</a></span> | <span class="t">pop in? Yeah. Just a super quick thing. So they do all of this circuit analysis on the replacement model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1840" target="_blank">00:30:40.300</a></span> | <span class="t">because it's way easier to analyze the replacement model. It's smaller, it's linear, it's all that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1845" target="_blank">00:30:45.740</a></span> | <span class="t">stuff. But these experiments you show where they replace whatever Texas with California,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1851" target="_blank">00:30:51.260</a></span> | <span class="t">those are done on the original LLM. That's, that's super important. So they're not trying to prove the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1856" target="_blank">00:30:56.860</a></span> | <span class="t">replacement works this way. They're trying to prove the original LLM works the same way as the replacement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1862" target="_blank">00:31:02.860</a></span> | <span class="t">And so, um, in the chat, like, like this could all be a bunch of BS, but because the intervention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1869" target="_blank">00:31:09.500</a></span> | <span class="t">works on the original model. So if you, if you said that, you know, the, the ligament in my leg</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1875" target="_blank">00:31:15.660</a></span> | <span class="t">is connected to vision and you, you cut that and I can't walk, but I can still see perfectly fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1881" target="_blank">00:31:21.420</a></span> | <span class="t">Then your explanation is probably wrong. But if you say the optic nerve is, is really important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1886" target="_blank">00:31:26.780</a></span> | <span class="t">for vision and you cut that and suddenly I'm blind then, but I can do everything else. I can walk,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1892" target="_blank">00:31:32.700</a></span> | <span class="t">I can taste, I can do everything else just fine. That's pretty strong support that the, that the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1897" target="_blank">00:31:37.500</a></span> | <span class="t">the one thing you cut is critical component just for what you said it was.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1902" target="_blank">00:31:42.060</a></span> | <span class="t">Yeah. Um, yeah, all this is still done on the original model. Uh, someone's asking what layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1909" target="_blank">00:31:49.740</a></span> | <span class="t">generate these super node features. So there's super nodes across different layers, right? So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1914" target="_blank">00:31:54.700</a></span> | <span class="t">uh, this is throughout different layers. There's one for California here, there's Oakland at this level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1921" target="_blank">00:32:01.340</a></span> | <span class="t">So it's kind of throughout, they have a lot of interactive charts that you can play through this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1925" target="_blank">00:32:05.660</a></span> | <span class="t">to go through different layers. These are just kind of the hand cherry picked examples and they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1930" target="_blank">00:32:10.860</a></span> | <span class="t">acknowledge this as well. They acknowledge that what they found is cherry picked and heavily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1935" target="_blank">00:32:15.660</a></span> | <span class="t">biased towards what they thought was, you know, here's what we see. Here's what we should dig into.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1941" target="_blank">00:32:21.100</a></span> | <span class="t">It's a bit of a limitation in the work, but nonetheless, it's still there. Um, another example that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1947" target="_blank">00:32:27.100</a></span> | <span class="t">show is, you know, uh, planning in poems. So how does Claude 3.5 haiku write a rhyming poem?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1952" target="_blank">00:32:32.860</a></span> | <span class="t">So writing a poem requires satisfying two constraints at one time, right? There's two things that we have to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1958" target="_blank">00:32:38.460</a></span> | <span class="t">The lines need to rhyme and they need to make sense. There's two ways that a model could do this. One is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1964" target="_blank">00:32:44.300</a></span> | <span class="t">pure improvision, right? Um, model could just begin each line without regard of needing to rhyme. Uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1971" target="_blank">00:32:51.340</a></span> | <span class="t">sorry, the model could write the beginning of each line without regard for needing to rhyme at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1975" target="_blank">00:32:55.900</a></span> | <span class="t">And then the last word just kind of has to rhyme with the first, or there's this planning step, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1981" target="_blank">00:33:01.740</a></span> | <span class="t">So you can either just kind of start. And as you go, think of words that rhyme, or you can actually plan</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1987" target="_blank">00:33:07.820</a></span> | <span class="t">ahead. So this example tries to see, is there planning when, when I tell you to write a poem and I give you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1993" target="_blank">00:33:13.740</a></span> | <span class="t">a word to start with, like, you know, write a poem and have something that rhymes with the word tape.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=1999" target="_blank">00:33:19.180</a></span> | <span class="t">I forced you to have the first word, and then you can start generating words that rhyme with tape.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2004" target="_blank">00:33:24.060</a></span> | <span class="t">Or if I tell you to write a poem about something you can plan in advance before the first word is written.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2009" target="_blank">00:33:29.340</a></span> | <span class="t">So, um, even though the models are, you know, trained to think one token at a time and predict the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2016" target="_blank">00:33:36.460</a></span> | <span class="t">token outside of, you know, thinking models, uh, we would assume that, you know, the model would rely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2021" target="_blank">00:33:41.740</a></span> | <span class="t">on pure improvision, right? It will just kind of do it on the fly. But the interesting thing here is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2027" target="_blank">00:33:47.100</a></span> | <span class="t">they kind of find a planning mechanism per se in what happens. So specifically the model often activates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2034" target="_blank">00:33:54.300</a></span> | <span class="t">features corresponding to candidate end of next line words prior to writing the line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2039" target="_blank">00:33:59.020</a></span> | <span class="t">So before like the net, before the rhyming word is predicted, even if it's at the end of the line,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2046" target="_blank">00:34:06.700</a></span> | <span class="t">we can see traces of it starting to come up pretty early on. Um, so for example, a rhyming, a rhyming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2054" target="_blank">00:34:14.220</a></span> | <span class="t">couplet, he saw a carrot and had to grab it. His hunger was a powerful rabbit or starving like a rabbit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2061" target="_blank">00:34:21.100</a></span> | <span class="t">Um, these words start to show up pretty early on. So first let's look at, you know, where do these features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2067" target="_blank">00:34:27.660</a></span> | <span class="t">come from? Um, what are the different features that form them? So for habit, um, you know, 50x very clear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2075" target="_blank">00:34:35.340</a></span> | <span class="t">reason, best answer. Um, for habit there's, there's just different features, mobile app that gamifies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2083" target="_blank">00:34:43.020</a></span> | <span class="t">habit tracking, habit tracker, habit formation, uh, budgeting, rapid habit formation, discussing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2093" target="_blank">00:34:53.020</a></span> | <span class="t">habits with doctors. So, you know, once again, they've got this concept of habit. Uh, let's see where it starts to come in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2099" target="_blank">00:34:59.340</a></span> | <span class="t">So before they go into their thing, they talk about prior work. Um, sequence models, add a body of example in several ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2107" target="_blank">00:35:07.020</a></span> | <span class="t">We provide a mechanistic account for how words are planned, forward planning, backward planning, the model...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2114" target="_blank">00:35:14.700</a></span> | <span class="t">Oh, shit. Um...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2116" target="_blank">00:35:16.700</a></span> | <span class="t">Here we are. Uh, the whole, the model holds multiple possible planned words in mind. We're able to edit the model's planned words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2128" target="_blank">00:35:28.700</a></span> | <span class="t">We discover, um, the mechanism with an unsupervised bottom-up approach. Model used to represent words,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2136" target="_blank">00:35:36.380</a></span> | <span class="t">ordinary features. Okay. Planned words and their mechanistic role. So, um, we study how Claude completes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2143" target="_blank">00:35:43.580</a></span> | <span class="t">the following prompt asking for a rhyming couplet. The model's output sampling the most likely token is shown</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2148" target="_blank">00:35:48.380</a></span> | <span class="t">in bold. So, uh, this is kind of the input, a rhyming couplet. He saw a carrot and had to grab it. The output we get is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2155" target="_blank">00:35:55.420</a></span> | <span class="t">his hunger was like a starving rabbit. So model, the output is coherent. It makes sense and it rhymes, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2162" target="_blank">00:36:02.060</a></span> | <span class="t">So, uh, starving rabbit, carrot, kind of all rhymes there. To start, we focus on the last word of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2169" target="_blank">00:36:09.420</a></span> | <span class="t">second line and attempt to identify the circuit that can shoot that, uh, contributed to choosing rabbit. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2175" target="_blank">00:36:15.500</a></span> | <span class="t">this makes sense, right? Rabbits like carrots, um, grab it, rabbit, it rhymes. So there's kind of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2182" target="_blank">00:36:22.620</a></span> | <span class="t">two-step thing. Was it just the last token predicted or did we have some thought to it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2186" target="_blank">00:36:26.700</a></span> | <span class="t">Okay. So these are kind of the, the features. So it comma hunger was like starving. Okay. Let's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2194" target="_blank">00:36:34.460</a></span> | <span class="t">let's start to dig through this. So rhymes with, there's a feature here of rhymes with it, it sound, um, get, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2205" target="_blank">00:36:45.340</a></span> | <span class="t">that they have features that activate across different languages and stuff that activate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2210" target="_blank">00:36:50.300</a></span> | <span class="t">uh, that, you know, have this sort of rhyming feature. Then they have rabbit and habit that came up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2215" target="_blank">00:36:55.420</a></span> | <span class="t">um, say rabbit. And then this feature of the dash T and then, oh, cool. We got rabbit. What does this show?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2223" target="_blank">00:37:03.900</a></span> | <span class="t">The attribution graph above computed by, uh, attributing back from the rabbit output node shows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2229" target="_blank">00:37:09.980</a></span> | <span class="t">an important group of features activate on the new line token before the beginning of the second line</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2234" target="_blank">00:37:14.620</a></span> | <span class="t">features activate over the it token, uh, activate. So, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2240" target="_blank">00:37:20.540</a></span> | <span class="t">basically the second last output token where, um, grab it had features that activated these different,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2250" target="_blank">00:37:30.940</a></span> | <span class="t">um, you know, sort of rhyming tokens. The candidates have, uh, the candidate completions in turn have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2258" target="_blank">00:37:38.300</a></span> | <span class="t">positive edges to say rabbit features over the last token. So that's this hypothesis. We perform a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2263" target="_blank">00:37:43.660</a></span> | <span class="t">variety of interventions on new line planning sites to see how probability, how it affects the probability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2268" target="_blank">00:37:48.540</a></span> | <span class="t">of the last token. Okay. So let's, uh, 10 X down the word habit and we've got different changes, 10 X up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2277" target="_blank">00:37:57.980</a></span> | <span class="t">and down new line, um, different things affect different things. The results confirm our hypothesis that features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2284" target="_blank">00:38:04.460</a></span> | <span class="t">that planning features strongly influence the final token. So if we kind of take out that new line</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2290" target="_blank">00:38:10.780</a></span> | <span class="t">token, we can see, oh, it's a, it's not doing this anymore. Okay. Planning features only matter at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2296" target="_blank">00:38:16.860</a></span> | <span class="t">planning location, planning words, influence immediate words, nothing too interesting here. Okay. Clamping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2303" target="_blank">00:38:23.740</a></span> | <span class="t">was a line to lead to transformer. How do they map trans corridor back to transformer? Say we clamp Texas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2308" target="_blank">00:38:28.540</a></span> | <span class="t">So in, there's a question around the clamping stuff and how this is working. The previous SAE thing that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2314" target="_blank">00:38:34.220</a></span> | <span class="t">they put out in May, it explains how they do all these clamping features. Uh, basically same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2319" target="_blank">00:38:39.740</a></span> | <span class="t">There's more in here as well. In both of these papers, they kind of go into the math about it as well, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2325" target="_blank">00:38:45.660</a></span> | <span class="t">keeping it high level. Let's just kind of try to see, um, some more of these planned words. So, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2332" target="_blank">00:38:52.860</a></span> | <span class="t">yep, we can, we can sort of see as we take out different things, uh, we no longer have this planning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2339" target="_blank">00:38:59.900</a></span> | <span class="t">step. Okay. I'm going to go quickly through the next few ones, ideally in the next like seven minutes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2345" target="_blank">00:39:05.980</a></span> | <span class="t">and then we'll leave the last 10 minutes for just questions and discussions on this. So we first,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2351" target="_blank">00:39:11.180</a></span> | <span class="t">you know, we just saw how there's pre-planning in poems for rhyming. There's this multi-step sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2357" target="_blank">00:39:17.660</a></span> | <span class="t">thinking that happens throughout layers. Uh, now we've got multilingual circuits. So models, uh, modern</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2364" target="_blank">00:39:24.460</a></span> | <span class="t">networks have highly abstract representations and unified concepts across multiple languages. So we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2370" target="_blank">00:39:30.220</a></span> | <span class="t">little understanding of how these features fit in larger, larger circuits. Let's see how it, um, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2376" target="_blank">00:39:36.060</a></span> | <span class="t">how does it go through the exact same prompt in different languages? Are there features that fire</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2383" target="_blank">00:39:43.500</a></span> | <span class="t">that are consistent through different languages? Um, also fun fact, I guess rabbits don't eat carrots.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2389" target="_blank">00:39:49.740</a></span> | <span class="t">Carrots are like treats. Crazy, crazy. Someone knows about, um, rabbits. Okay. So, um, the opposite of small is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2398" target="_blank">00:39:58.220</a></span> | <span class="t">and then we would expect big in French. It's grand in Chinese. It's this character. Um, let's see if there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2405" target="_blank">00:40:05.260</a></span> | <span class="t">consistency across these features. So high level story features the same. The model recognizes using a language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2411" target="_blank">00:40:11.340</a></span> | <span class="t">independent, um, representation. So very interesting. There's language independent, uh, representation. So this term of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2420" target="_blank">00:40:20.700</a></span> | <span class="t">say large, uh, is something that, uh, that activates across all three languages. Let's see some of the features. So, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2429" target="_blank">00:40:29.020</a></span> | <span class="t">large has stuff like, you know, 42nd order. Uh, there's a Spanish version in here, uh, short arm and long arm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2436" target="_blank">00:40:36.940</a></span> | <span class="t">It activates in this language. It activates in a numerical sense. It activates small things. Great. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2447" target="_blank">00:40:47.340</a></span> | <span class="t">this feature is kind of multilingually representing the word large. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2452" target="_blank">00:40:52.220</a></span> | <span class="t">same thing with antonyms. So, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2457" target="_blank">00:40:57.580</a></span> | <span class="t">yeah, there's, there's kind of just these high level features that activate. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2463" target="_blank">00:41:03.420</a></span> | <span class="t">the opposite of small is little, uh, there's a synonym feature, antonym, antonym kind of synonym, multilingual,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2470" target="_blank">00:41:10.300</a></span> | <span class="t">say small, say cold, say large. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2473" target="_blank">00:41:13.660</a></span> | <span class="t">very interesting. Editing the operation antonyms, the synonyms is kind of another one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2477" target="_blank">00:41:17.660</a></span> | <span class="t">They can kind of clamp this in. So, um, they show how that works. Editing small, the hot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2484" target="_blank">00:41:24.860</a></span> | <span class="t">Okay. Editing the output language. There's another thing that we can start to do. So if we start to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2490" target="_blank">00:41:30.300</a></span> | <span class="t">swap in the features for different languages, you know, we can get output in different language. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2495" target="_blank">00:41:35.900</a></span> | <span class="t">more circuits for French, I think it's okay. You can go through this on your own time. Do models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2501" target="_blank">00:41:41.820</a></span> | <span class="t">think in English? This is an interesting one. As researchers have begun to mechanistically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2506" target="_blank">00:41:46.860</a></span> | <span class="t">investigate multilingual properties of models, there's been tension in our link in our literature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2511" target="_blank">00:41:51.420</a></span> | <span class="t">Researchers have found multilingual neurons and features and evidence of multilingual representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2518" target="_blank">00:41:58.060</a></span> | <span class="t">On the other hand, there's present evidence that models, um, you know, they, they use English</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2524" target="_blank">00:42:04.220</a></span> | <span class="t">representation. It's, uh, so what should we make of this conflicting evidence? It seems to us that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2529" target="_blank">00:42:09.820</a></span> | <span class="t">Claude 3.5's haiku is generally, is using genuinely multilingual features, especially in the middle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2535" target="_blank">00:42:15.820</a></span> | <span class="t">layer. So in middle layers, we see multilingual features. Um, there in, there are important mechanistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2542" target="_blank">00:42:22.780</a></span> | <span class="t">ways in which English is privileged. For example, multilingual features have more significant direct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2548" target="_blank">00:42:28.300</a></span> | <span class="t">weights to corresponding English output nodes while non-English outputs being more strongly meditated in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2554" target="_blank">00:42:34.140</a></span> | <span class="t">the XY language features. So kind of interesting. There's still a bit of an English bias, but you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2559" target="_blank">00:42:39.100</a></span> | <span class="t">there are definitely some inherent, um, multilingual features there. Okay. Next example is English.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2567" target="_blank">00:42:47.500</a></span> | <span class="t">Uh, we want to see how does Claude add two numbers like 36 plus 59. Uh, we found that we can, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2574" target="_blank">00:42:54.060</a></span> | <span class="t">we found that it split the problem into multiple pathways, computing the result in a, at a rough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2581" target="_blank">00:43:01.180</a></span> | <span class="t">precision parallel computing while one digits answer before reconstructing these to get the cue key, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2586" target="_blank">00:43:06.940</a></span> | <span class="t">the correct answer. We find a key step performed by a lookup table feature. Ooh, very interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2592" target="_blank">00:43:12.060</a></span> | <span class="t">Lookup table feature that translates the properties of inputs. Okay. Let's kind of see what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2597" target="_blank">00:43:17.340</a></span> | <span class="t">going on first. We visualize the role of addition problems using operators, um, show the activity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2604" target="_blank">00:43:24.300</a></span> | <span class="t">of features on the equal token for prompts, uh, calculation AB. So addition features, calculate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2611" target="_blank">00:43:31.420</a></span> | <span class="t">a plus B equals, they kind of have this lookup table, some features. It's very interesting how it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2617" target="_blank">00:43:37.340</a></span> | <span class="t">doing attention. Uh, this one gets a little bit complex in how we go through what's happening here in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2625" target="_blank">00:43:45.180</a></span> | <span class="t">case. And the sake of time, I think that's enough of a little overview. They can, of course, mess with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2631" target="_blank">00:43:51.260</a></span> | <span class="t">its math. Let's go on to the next one. Medical diagnosis. This is a fun one. In recent years,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2638" target="_blank">00:43:58.220</a></span> | <span class="t">researchers have explored medical applications for LLMs, for example, aiding clinicians in accurate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2643" target="_blank">00:44:03.580</a></span> | <span class="t">diagnosis. So what happens? Thus, we are interested in whether our methods can shake lights on reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2650" target="_blank">00:44:10.300</a></span> | <span class="t">model on the reasoning models perform internally in medical contexts. We study an example scenario</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2656" target="_blank">00:44:16.780</a></span> | <span class="t">in which a model is presented information with a P about a patient and asked to suggest a follow-up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2662" target="_blank">00:44:22.140</a></span> | <span class="t">question to inform diagnosis of the treatment. This mirrors common medical practice. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2668" target="_blank">00:44:28.540</a></span> | <span class="t">okay. So let's see what happens. Um, human, a 32 year old female, 30 week gestation period, this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2675" target="_blank">00:44:35.580</a></span> | <span class="t">this, this mild headache, nausea. Um, if only we can ask one symptom, what would she, what would,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2682" target="_blank">00:44:42.540</a></span> | <span class="t">what would we ask assistant visual disturbances? So the model is most, the model's most likely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2688" target="_blank">00:44:48.620</a></span> | <span class="t">completion here is visual disturbances. And this two key indicators in this issue. Okay. We noticed that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2696" target="_blank">00:44:56.220</a></span> | <span class="t">model activated a number of features that activate in context of this, um, you know, this issue in people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2703" target="_blank">00:45:03.900</a></span> | <span class="t">So what are these features in coming to this? Okay. Their, their UI is struggling, uh, slightly more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2710" target="_blank">00:45:10.700</a></span> | <span class="t">deadly material, uh, gestational disease pressure. So there's a bunch of features that come up to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2718" target="_blank">00:45:18.220</a></span> | <span class="t">blood pressure, protein stroke. Um, some of the other features were on synonyms of this other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2727" target="_blank">00:45:27.020</a></span> | <span class="t">activations in broad context, kind of interesting, right? So they do see this kind of internal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2732" target="_blank">00:45:32.940</a></span> | <span class="t">understanding. They have more examples of this for different stuff. So, you know, if we could only ask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2737" target="_blank">00:45:37.820</a></span> | <span class="t">stuff, it's whether he's experiencing chest pain in this one, whether there's a rash and they kind of go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2743" target="_blank">00:45:43.180</a></span> | <span class="t">through what are some of the features that make this stuff up here. Uh, pretty interesting. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2747" target="_blank">00:45:47.500</a></span> | <span class="t">you should check it out if interested, if interested. Okay. Uh, 10 minutes left. I think there's a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2753" target="_blank">00:45:53.180</a></span> | <span class="t">more of these are clamping this there's entity recognition, there's refusals, but okay. I want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2759" target="_blank">00:45:59.740</a></span> | <span class="t">pause here. See if we have any other comments, questions, thoughts, things that we want to dig more into.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2769" target="_blank">00:46:09.900</a></span> | <span class="t">I'm going to check chat, but see if there's, um, yeah, if anyone has any stuff they want to dig into,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2776" target="_blank">00:46:16.380</a></span> | <span class="t">let's feel free, you know, pop in. Could you do a quick overview of the hallucination section?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2785" target="_blank">00:46:25.260</a></span> | <span class="t">Yeah. Let's just keep going. Um, so entity recognition and hallucination. So basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2794" target="_blank">00:46:34.380</a></span> | <span class="t">hallucination is where you make up false information, right? Hallucination is common when models are asked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2799" target="_blank">00:46:39.420</a></span> | <span class="t">about obscure facts because they like to be confident. An example, consider this hallucination by, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2805" target="_blank">00:46:45.260</a></span> | <span class="t">given by Haiku 3.5. So prompt, uh, this guy plays the sport of completion pickleball, which is a paddle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2813" target="_blank">00:46:53.100</a></span> | <span class="t">ball sport, uh, that consists of elements of this. The behavior is reasonable in the model's, uh, training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2819" target="_blank">00:46:59.020</a></span> | <span class="t">data. A sentence seems likely to be associated with the name of a sport without any information of who this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2824" target="_blank">00:47:04.700</a></span> | <span class="t">guy is the model says a plausible support, uh, plausible sport at random during fine tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2832" target="_blank">00:47:12.620</a></span> | <span class="t">However, models are trained to avoid such Bob, uh, behavior when acting in the assistant character,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2839" target="_blank">00:47:19.740</a></span> | <span class="t">this leads to responses like the following. So base model Haiku without it's kind of, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2845" target="_blank">00:47:25.260</a></span> | <span class="t">um, you know, RL chat tuning. It just completes this and says, Oh, the sentence sounds like a sport.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2852" target="_blank">00:47:32.460</a></span> | <span class="t">I will give you a sport. Now, after their sort of training, what sport does this guy play answer in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2858" target="_blank">00:47:38.460</a></span> | <span class="t">one word models like, Oh shit, I can't do that. I don't know who this is. I need context. Given that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2863" target="_blank">00:47:43.820</a></span> | <span class="t">hallucination is some sense of natural behavior, which is mitigated by fine tuning. We take a look at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2869" target="_blank">00:47:49.420</a></span> | <span class="t">the service, uh, the circuits that prevent models from hallucinating. So they're not really in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2874" target="_blank">00:47:54.780</a></span> | <span class="t">sense, looking at hallucination and what caused it. They're looking at how they fixed it. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2878" target="_blank">00:47:58.460</a></span> | <span class="t">uh, quick high level TLDR. We have base models. We do this RL or SFT and we convert them into chat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2885" target="_blank">00:48:05.900</a></span> | <span class="t">models, right? In that we have this preference tuning. One of the things that they're trained to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2890" target="_blank">00:48:10.060</a></span> | <span class="t">do is be a helpful assistant. And that the objective is kind of, if you don't know what to say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2896" target="_blank">00:48:16.060</a></span> | <span class="t">you know, you tell them, you don't know, and you ask for more context. So base model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2900" target="_blank">00:48:20.220</a></span> | <span class="t">would just complete tokens and be like, this guy plays pickleball. Cause it sounds like he plays a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2904" target="_blank">00:48:24.140</a></span> | <span class="t">sport. Um, there's probably a famous Michael or two or, or Batkin that play pickleball. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2911" target="_blank">00:48:31.020</a></span> | <span class="t">assistant model is like, yo, I don't know who this guy is. So let me ask for more information,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2915" target="_blank">00:48:35.820</a></span> | <span class="t">but let's start to look at, um, what are these features that make that up? So hallucinations can be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2921" target="_blank">00:48:41.980</a></span> | <span class="t">attributed to a misfire in the circuit. For example, when asking the model for papers written by a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2928" target="_blank">00:48:48.060</a></span> | <span class="t">particular author, the model may activate some of these known act answer features,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2932" target="_blank">00:48:52.940</a></span> | <span class="t">even if it locked lacks the specific knowledge of the author, uh, knowledge of author specific papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2939" target="_blank">00:48:59.260</a></span> | <span class="t">This is one kind of interesting, right? So our results were related to recent findings of Fernando</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2946" target="_blank">00:49:06.780</a></span> | <span class="t">use sparse, uh, which use sparse, sparse autoencoders to find features that represent unknown</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2951" target="_blank">00:49:11.660</a></span> | <span class="t">entities. So this. So, okay. Human in which country is a great wall located? Uh, it says China in which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2958" target="_blank">00:49:18.140</a></span> | <span class="t">country is this based? It's okay. Um, known answer, unknown answer, different features, difficult,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2965" target="_blank">00:49:25.180</a></span> | <span class="t">uh, default, uh, default refusal circuits. There's a can't answer, um, feature directly activate broadly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2974" target="_blank">00:49:34.140</a></span> | <span class="t">fire for human assistant prompts. The picture suggests that the can't answer feature was activated by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2980" target="_blank">00:49:40.380</a></span> | <span class="t">default for human assistant prompts. In other words, the model is skeptical of user. So they kind of show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2985" target="_blank">00:49:45.500</a></span> | <span class="t">this can't answer, can't answer also, uh, can't answer features are also pro pro promoted by a group of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=2993" target="_blank">00:49:53.820</a></span> | <span class="t">unfamiliar names. So names that it doesn't understand are, I guess, a feature, uh, these kind of just prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3000" target="_blank">00:50:00.780</a></span> | <span class="t">it to say, I can't answer. I don't know. Okay. Now what about the known answer circuit? So where does Mike,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3007" target="_blank">00:50:07.420</a></span> | <span class="t">what sport does Michael Jordan play? He plays basketball. So there's a group of known answer and known entity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3013" target="_blank">00:50:13.420</a></span> | <span class="t">features. These are what accidentally misfire when you get hallucination. That's a bit of a spoiler,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3019" target="_blank">00:50:19.420</a></span> | <span class="t">but you know, uh, known answer is like different features that kind of, you know, what answer is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3027" target="_blank">00:50:27.260</a></span> | <span class="t">what country is this based in? It knows Japan. What team does Devin Booker play on? It knows the answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3033" target="_blank">00:50:33.820</a></span> | <span class="t">Where's the great wall located? These are kind of known internal facts. There's a feature for it. Once this fires,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3039" target="_blank">00:50:39.740</a></span> | <span class="t">you're cooked, it's going to answer and you know, it'll hallucinate. Once this has gone off, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3043" target="_blank">00:50:43.740</a></span> | <span class="t">strong evidence for that. Um, this graph, these graphs are kind of a little interesting. They kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3048" target="_blank">00:50:48.540</a></span> | <span class="t">of show both sides. Um, so this is kind of the traversal throughout the layers in the RL, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3055" target="_blank">00:50:55.180</a></span> | <span class="t">So we had, um, this assistant feature because it's an assistant unknown name was a feature. And then,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3061" target="_blank">00:51:01.740</a></span> | <span class="t">you know, that leads to, I can't answer because this thing has been RL to not answer stuff. I apologize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3067" target="_blank">00:51:07.740</a></span> | <span class="t">So can't answer. I apologize. I can't figure this out. That's where the next turns come up because that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3072" target="_blank">00:51:12.140</a></span> | <span class="t">shows up after that. What about something we don't know? Michael Jordan. Oh, I know this answer. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3077" target="_blank">00:51:17.100</a></span> | <span class="t">a bunch of stuff that, sorry. So first we have assistant and Michael Jordan in layer one known</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3083" target="_blank">00:51:23.820</a></span> | <span class="t">answer. Oh my God. Okay. No one answer. I know a bunch of these facts say basketball,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3089" target="_blank">00:51:29.180</a></span> | <span class="t">Oh, basketball has said vertical vertical. Now let's once again, do a bunch of fun clamping stuff,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3094" target="_blank">00:51:34.780</a></span> | <span class="t">right? So, um, if we have Michael, Michael Jordan and we have known answer and we clamp it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3104" target="_blank">00:51:44.300</a></span> | <span class="t">it says basketball. What if we clamp down known answers? If we take that feature, we turn it down,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3109" target="_blank">00:51:49.980</a></span> | <span class="t">even though the question is what sport does Michael Jordan play? We clamp down known answer. Well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3115" target="_blank">00:51:55.580</a></span> | <span class="t">it can't answer because the other one that fires up is unknown answer. Um, what sport does it play if we,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3122" target="_blank">00:52:02.540</a></span> | <span class="t">if we still have strong known answer and we add in unknown name, it still says basketball,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3127" target="_blank">00:52:07.980</a></span> | <span class="t">um, little stuff here to kind of go through, but that's kind of a high level of what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3133" target="_blank">00:52:13.820</a></span> | <span class="t">I thought the academic papers one is another interesting. So, um, same concept, but you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3139" target="_blank">00:52:19.260</a></span> | <span class="t">this is this unknown name feature of stuff. So name paper written by Senpai, Senpai Karpathy. One notable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3148" target="_blank">00:52:28.060</a></span> | <span class="t">paper is image net. Um, there's kind of the same thing, known answer unknown name. If we change them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3154" target="_blank">00:52:34.940</a></span> | <span class="t">up, what happens? Um, pretty, pretty fun stuff, you know? Okay. That's kind of high level of what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3163" target="_blank">00:52:43.180</a></span> | <span class="t">happening in the hallucination. Refusals was another interesting one. It's kind of interesting to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3168" target="_blank">00:52:48.140</a></span> | <span class="t">some of the output to the base model and how their RL is like, you know, showing how this stuff works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3173" target="_blank">00:52:53.340</a></span> | <span class="t">They have known entity and unknown entity features and say, I don't know features. The I don't know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3178" target="_blank">00:52:58.940</a></span> | <span class="t">feature is much less interesting. The unknown feature relates to self knowledge. Okay. Yeah. Just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3185" target="_blank">00:53:05.260</a></span> | <span class="t">interesting thoughts on this. Cool. Three more minutes. Any other fun thoughts, questions, comments?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3191" target="_blank">00:53:11.980</a></span> | <span class="t">I would recommend reading through just examples of this. Um, and if you haven't, the SAE one is pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3197" target="_blank">00:53:17.820</a></span> | <span class="t">fun too. Here's kind of the limitations, what issues show up, um, discussion. What have we, what have we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3209" target="_blank">00:53:29.100</a></span> | <span class="t">learned? Um, yeah, kind of high level. Interesting. The background of this is kind of this circuit tracing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3216" target="_blank">00:53:36.460</a></span> | <span class="t">transcoder work. It's very interesting how they can just train a model with a reconstruction loss and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3222" target="_blank">00:53:42.140</a></span> | <span class="t">just have it match the output because you know, these models are still only 30 million features,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3227" target="_blank">00:53:47.500</a></span> | <span class="t">even though they have the same layers, it's still outputting the exact same outputs. Kind of interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3232" target="_blank">00:53:52.540</a></span> | <span class="t">Uh, do folks think the taxonomy of circuits, how circuits are divided will likely converge to be a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3240" target="_blank">00:54:00.460</a></span> | <span class="t">same breakdown every model or with different models, do different things differently. I think that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3245" target="_blank">00:54:05.020</a></span> | <span class="t">different models might do different things differently, right? Cause this is layer wise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3248" target="_blank">00:54:08.860</a></span> | <span class="t">understanding different models have different architectures, different layers, whether they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3253" target="_blank">00:54:13.100</a></span> | <span class="t">MOEs, they're also trained in different ways, right? So the pre-training data set mixture kind of affects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3259" target="_blank">00:54:19.420</a></span> | <span class="t">some of this. So what if you're trained on high value, you know, training data first, and then garbage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3266" target="_blank">00:54:26.380</a></span> | <span class="t">at the end, you've probably got slop in your model, but you know, you might have different circuits that go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3271" target="_blank">00:54:31.580</a></span> | <span class="t">throughout. Um, and then there's obviously some general variety. Um, they did though, they did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3277" target="_blank">00:54:37.900</a></span> | <span class="t">actually in this one train it on a 18 layer language model, just a general model on a couple billion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3283" target="_blank">00:54:43.900</a></span> | <span class="t">And it still has coherency in what you expect. This still goes back to like early transformer stuff. You know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3288" target="_blank">00:54:48.940</a></span> | <span class="t">we have a basic understanding of early layers are more general and layers are more niche and output specific, but.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3295" target="_blank">00:54:55.660</a></span> | <span class="t">Okay, that's kind of, um, kind of time on the hour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3301" target="_blank">00:55:01.580</a></span> | <span class="t">I think next week and the week after we have a few volunteers, if Lama 4 drops a paper, we'll cover it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3310" target="_blank">00:55:10.700</a></span> | <span class="t">of course. But I think we have a few volunteers. We'll, we'll share in discord. What's what's coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3316" target="_blank">00:55:16.060</a></span> | <span class="t">soon? If anyone wants to volunteer a paper, if anyone wants to, you know, follow up, please share.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3322" target="_blank">00:55:22.300</a></span> | <span class="t">Thanks, Ted, for sharing insights as well, by the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3324" target="_blank">00:55:24.780</a></span> | <span class="t">Um, I think we have a, don't we have a potential speaker for next week?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3332" target="_blank">00:55:32.300</a></span> | <span class="t">Yeah, I thought you had one. I also have one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3334" target="_blank">00:55:34.700</a></span> | <span class="t">Uh, yeah, but mine moved back after your guy came in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3339" target="_blank">00:55:39.020</a></span> | <span class="t">Oh, okay. Okay. Well, I'll, I'll share details. Um, in discord.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3342" target="_blank">00:55:42.780</a></span> | <span class="t">Okay. Oh, there's questions in the court. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3346" target="_blank">00:55:46.140</a></span> | <span class="t">Uh, are there open weights, sparse autoencoder?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3349" target="_blank">00:55:49.100</a></span> | <span class="t">Yes. I think Gemma trained some.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3351" target="_blank">00:55:51.020</a></span> | <span class="t">Ooh, Gemma trained some. Um, there, there's some layer wise ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3355" target="_blank">00:55:55.820</a></span> | <span class="t">So like there's some that have been done on like Lama 38 B for each layer, but not throughout the whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3361" target="_blank">00:56:01.180</a></span> | <span class="t">model. Um, but yeah, transcoder is different. It's not model wise autoencoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3367" target="_blank">00:56:07.260</a></span> | <span class="t">Uh, they do give recipe and, you know, expected cost to do this yourself though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3374" target="_blank">00:56:14.620</a></span> | <span class="t">Okay, let's continue discussion in discord then. Thanks for attending guys.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=ig5RNJJaFJE&t=3384" target="_blank">00:56:24.140</a></span> | <span class="t">See you.</span></div></div></body></html>