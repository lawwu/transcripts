<html><head><title>o1 - What is Going On? Why o1 is a 3rd Paradigm of Model + 10 Things You Might Not Know</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>o1 - What is Going On? Why o1 is a 3rd Paradigm of Model + 10 Things You Might Not Know</h2><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4"><img src="https://i.ytimg.com/vi_webp/KKF7kL0pGc4/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=64">1:4</a> How o1 Works (The 3rd Paradigm)<br><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=190">3:10</a> We Donâ€™t Need Human Examples (OpenAI)<br><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=234">3:54</a> How o1 Works (Temp 1 Graded)<br><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=388">6:28</a> Is This Reasoning?<br><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=528">8:48</a> Personal Announcement<br><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=687">11:27</a> Hidden, serial Thoughts?<br><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=791">13:11</a> Memorized Reasoning?<br><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=940">15:40</a> 10 Facts<br><br><div style="text-align: left;"><a href="./KKF7kL0pGc4.html">Whisper Transcript</a> | <a href="./transcript_KKF7kL0pGc4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">The world has had just a few days to process the impact of O1 Preview from OpenAI and I have used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=8" target="_blank">00:00:08.480</a></span> | <span class="t">that time to read, or in a couple of cases re-read, seven papers that I think help explain what O1 is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=15" target="_blank">00:00:15.600</a></span> | <span class="t">and what's coming next. I'll also draw on talks released earlier today to back up the claim that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=22" target="_blank">00:00:22.640</a></span> | <span class="t">I made a few days ago that O1 Preview represents a step change in how models are trained and what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=29" target="_blank">00:00:29.200</a></span> | <span class="t">they can do. Of course, I'll also remind you of what they can't yet do, even if they thought about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=34" target="_blank">00:00:34.560</a></span> | <span class="t">it for the length of this entire video. Here at least is what one top OpenAI researcher thinks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=41" target="_blank">00:00:41.360</a></span> | <span class="t">"I didn't expect," he said, "there to be much time where there's two totally different, roughly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=48" target="_blank">00:00:48.240</a></span> | <span class="t">intelligence-matched, winning on different dimensions, species. But that seems pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=53" target="_blank">00:00:53.440</a></span> | <span class="t">clearly where we're at." To be honest, I just wanted to use this tweet to set the stage for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=59" target="_blank">00:00:59.680</a></span> | <span class="t">the special moment we're in in AI. Here is what I think OpenAI did at a very high level with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=68" target="_blank">00:01:08.000</a></span> | <span class="t">O1 series of models. As the video progresses, I'll get even more granular with my reasoning and quote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=74" target="_blank">00:01:14.800</a></span> | <span class="t">paragraphs from three-year-old papers to back it up. But for those who want a big picture overview,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=81" target="_blank">00:01:21.200</a></span> | <span class="t">here's what I think they've done. The foundational, original objective of language models is to model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=88" target="_blank">00:01:28.960</a></span> | <span class="t">language. It's to predict the next word. You can think of that, if you like, as paradigm one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=94" target="_blank">00:01:34.640</a></span> | <span class="t">Interesting, but not overly useful. Ask a question and the language model might predict another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=101" target="_blank">00:01:41.440</a></span> | <span class="t">question to follow it. So to simplify again, we brought in another objective, paradigm two. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=107" target="_blank">00:01:47.360</a></span> | <span class="t">wanted models to be honest, harmless, and helpful. We, or more like a proxy for us, would give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=114" target="_blank">00:01:54.400</a></span> | <span class="t">rewards to the models when it produced outputs that met those objectives. We started to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=119" target="_blank">00:01:59.920</a></span> | <span class="t">answers that weren't just likely from a probability perspective, but also, sometimes, harmless,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=126" target="_blank">00:02:06.240</a></span> | <span class="t">honest, and helpful. Enter, chat your BT, and I hear that's doing well. O1, for me at least,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=132" target="_blank">00:02:12.000</a></span> | <span class="t">represents paradigm three. We want to reward answers that are objectively correct. Not saying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=138" target="_blank">00:02:18.720</a></span> | <span class="t">that we've forgotten the original objectives, but we've layered another one on top of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=143" target="_blank">00:02:23.280</a></span> | <span class="t">But how did they actually do that? Well, again, I'm going to give you the one-minute summary and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=147" target="_blank">00:02:27.600</a></span> | <span class="t">then go into more detail later in the video. Most of us might be aware that you can get models to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=153" target="_blank">00:02:33.360</a></span> | <span class="t">output what's called a chain of thought. By asking models, for example, to think step-by-step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=158" target="_blank">00:02:38.640</a></span> | <span class="t">you can get much longer outputs that have reasoning steps within them. But that secret's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=163" target="_blank">00:02:43.760</a></span> | <span class="t">already a few years old, so that's not what is special about O1. So people thought of a brilliant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=169" target="_blank">00:02:49.360</a></span> | <span class="t">idea that just didn't quite work. How about we feed the model thousands of examples of human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=176" target="_blank">00:02:56.000</a></span> | <span class="t">step-by-step reasoning? Well, yes, that does work, but it's not really optimal. It doesn't scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=182" target="_blank">00:03:02.240</a></span> | <span class="t">super well. OpenAI realized you could go one step better, so I'm going to hand the mic to them for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=188" target="_blank">00:03:08.320</a></span> | <span class="t">30 seconds. Wait, so it's better to train on model-generated chains of thought? But how come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=216" target="_blank">00:03:36.720</a></span> | <span class="t">they're so often wrong? And what does he mean by reinforcement learning in this context? Well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=221" target="_blank">00:03:41.680</a></span> | <span class="t">how about this? And here, clearly, I'm going to get slightly metaphorical. How about we go up to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=225" target="_blank">00:03:45.840</a></span> | <span class="t">the model and whisper in its ear, "Get really creative. Don't worry as much about predicting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=230" target="_blank">00:03:50.800</a></span> | <span class="t">the next word super accurately. I just want really diverse outputs from you." The model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=235" target="_blank">00:03:55.600</a></span> | <span class="t">of course, at what's called a temperature of one, is more than happy to get creative and generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=240" target="_blank">00:04:00.720</a></span> | <span class="t">loads of diverse chains of thought. Meanwhile, other researchers must be looking on at these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=245" target="_blank">00:04:05.600</a></span> | <span class="t">guys thinking, "What are they doing? These are going to be so unreliable." But then what if we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=249" target="_blank">00:04:09.840</a></span> | <span class="t">had a way, preferably automatically, of grading those outputs? Then even many of you might agree,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=255" target="_blank">00:04:15.600</a></span> | <span class="t">"Well, some of those outputs are going to be good." Especially with more and more time spent thinking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=261" target="_blank">00:04:21.440</a></span> | <span class="t">longer and longer chains of thought. Doesn't matter how low a proportion of the outputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=265" target="_blank">00:04:25.920</a></span> | <span class="t">are correct, as long as we get at least one or a few. Then out of those thousands of outputs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=270" target="_blank">00:04:30.800</a></span> | <span class="t">we can take those that work, those that produce the correct answer in mathematics, science,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=275" target="_blank">00:04:35.920</a></span> | <span class="t">coding. We take that answer and we fine-tune the model on those correct answers with correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=282" target="_blank">00:04:42.320</a></span> | <span class="t">reasoning steps. That's how this becomes reinforcement learning. Only the best outputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=287" target="_blank">00:04:47.040</a></span> | <span class="t">are making it through to the next round and being used to further train the model. And because you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=292" target="_blank">00:04:52.880</a></span> | <span class="t">only fine-tuning or further training on those correct outputs with correct reasoning steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=299" target="_blank">00:04:59.280</a></span> | <span class="t">this process is highly data efficient. Unlike training on the web, where it might include one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=305" target="_blank">00:05:05.520</a></span> | <span class="t">of your random Reddit comments, which were awful by the way, or a tweet you did a few years ago,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=310" target="_blank">00:05:10.720</a></span> | <span class="t">this is golden data. So notice then how it's a marriage of train time compute,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=317" target="_blank">00:05:17.040</a></span> | <span class="t">the fine-tuning or training of a model, and what's called test time compute, that thinking time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=322" target="_blank">00:05:22.560</a></span> | <span class="t">Test time, if you weren't clear, is when the model is actually outputting something,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=326" target="_blank">00:05:26.400</a></span> | <span class="t">not when it's being trained. We already knew that giving the models the time to produce what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=330" target="_blank">00:05:30.960</a></span> | <span class="t">called serial calculations, one after another, after another, before producing their final output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=336" target="_blank">00:05:36.560</a></span> | <span class="t">would boost results. That kind of makes sense, right? Especially in technical domains. And that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=340" target="_blank">00:05:40.560</a></span> | <span class="t">what we've seen. But then marry that with train time compute, training on those correct generations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=347" target="_blank">00:05:47.280</a></span> | <span class="t">and then you get these two scaling graphs. For this difficult mathematics competition,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=352" target="_blank">00:05:52.640</a></span> | <span class="t">more time to think equals better results. But then train or fine-tune the model or generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=359" target="_blank">00:05:59.840</a></span> | <span class="t">on correct outputs and reasoning steps, and that also produces a noticeable increase. And as you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=366" target="_blank">00:06:06.960</a></span> | <span class="t">may have noticed, neither of those graphs look like they are particularly leveling off anytime</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=372" target="_blank">00:06:12.800</a></span> | <span class="t">soon. Before I get into those seven juicy papers that I mentioned at the start, I do want to touch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=378" target="_blank">00:06:18.640</a></span> | <span class="t">on a bigger question that many of you might have, which is, is this reasoning? Does it count as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=384" target="_blank">00:06:24.240</a></span> | <span class="t">human-like intelligence? Well, it's definitely not human-like, but it might not ultimately matter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=390" target="_blank">00:06:30.800</a></span> | <span class="t">The analogy I came up with was this. Think of a librarian. You're going up to this librarian</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=397" target="_blank">00:06:37.120</a></span> | <span class="t">because you have a question you want answered. The library books here are the model's training data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=402" target="_blank">00:06:42.800</a></span> | <span class="t">and the original Chachapiti was a very friendly librarian, but it would often bring you the wrong</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=407" target="_blank">00:06:47.840</a></span> | <span class="t">book. Or maybe it would bring you the right book that could answer your question, but point to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=412" target="_blank">00:06:52.960</a></span> | <span class="t">wrong paragraph within that book. It was clear that Chachapiti was decent as a librarian, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=419" target="_blank">00:06:59.040</a></span> | <span class="t">had no idea what it was handing to you. It was pretty easy if you wanted to, to demonstrate that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=424" target="_blank">00:07:04.000</a></span> | <span class="t">it wasn't actually intelligent. The O1 series of models are much better librarians. They've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=429" target="_blank">00:07:09.200</a></span> | <span class="t">taking notes on what books successfully answered the questions that guests had and which ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=434" target="_blank">00:07:14.080</a></span> | <span class="t">didn't, down to the level not just of the book, but the chapter, the paragraph, and the line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=438" target="_blank">00:07:18.880</a></span> | <span class="t">We are still left though, of course, with the fundamental question, but the librarian doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=443" target="_blank">00:07:23.440</a></span> | <span class="t">actually understand what it's presenting. This though, is when things get philosophically murky.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=448" target="_blank">00:07:28.880</a></span> | <span class="t">Does it ultimately matter in the end? We don't even understand how the human brain works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=453" target="_blank">00:07:33.680</a></span> | <span class="t">Frankly, I'm going to leave this one to you guys, and you can let me know what you think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=457" target="_blank">00:07:37.520</a></span> | <span class="t">in the comments. But one thing is clear from this metaphor, which is, if you ask a question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=463" target="_blank">00:07:43.440</a></span> | <span class="t">about something that's not in the model's training data, that's not in the library,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=467" target="_blank">00:07:47.280</a></span> | <span class="t">then doesn't matter what you think, the librarian will screw up. By the way, the librarian is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=472" target="_blank">00:07:52.640</a></span> | <span class="t">exceptionally unlikely to say, "I don't know," and instead will bring you an irrelevant book.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=477" target="_blank">00:07:57.120</a></span> | <span class="t">That weakness, of course, is still incredibly prevalent in O1 Preview.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=481" target="_blank">00:08:01.520</a></span> | <span class="t">And there is another hurdle that would follow if you agree with this analysis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=485" target="_blank">00:08:05.760</a></span> | <span class="t">not just a lack of training data. What about domains that have plenty of training data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=490" target="_blank">00:08:10.320</a></span> | <span class="t">but no clearly correct or incorrect answers? Then you would have no way of sifting through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=496" target="_blank">00:08:16.240</a></span> | <span class="t">all of those chains of thought and fine-tuning on the correct ones. Compared to the original</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=501" target="_blank">00:08:21.280</a></span> | <span class="t">GPT-4-O in domains with correct and incorrect answers, largely, you can see the performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=506" target="_blank">00:08:26.880</a></span> | <span class="t">boost. In areas with harder to distinguish correct or incorrect answers, much less of a boost. In</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=512" target="_blank">00:08:32.480</a></span> | <span class="t">fact, a regress in personal writing. So that's the big picture, but now time for the juicy details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=519" target="_blank">00:08:39.120</a></span> | <span class="t">and hidden hints we've seen over the last few days. But before that, I hope you'll forgive me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=523" target="_blank">00:08:43.920</a></span> | <span class="t">for just two minutes about me and the channel. And when I say that I'm grateful for comments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=530" target="_blank">00:08:50.480</a></span> | <span class="t">and for watching to the end, I really do mean it. It's an honor to take a small parcel of your time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=536" target="_blank">00:08:56.880</a></span> | <span class="t">and I don't expect any support beyond that. When I launched AI Insiders late last year on Patreon,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=542" target="_blank">00:09:02.240</a></span> | <span class="t">it was my attempt, though, at keeping the channel financially viable, as I had permanently given up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=548" target="_blank">00:09:08.000</a></span> | <span class="t">running my previous business around mid last year. I picked a price, frankly, that I thought it was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=553" target="_blank">00:09:13.120</a></span> | <span class="t">worth, which was $29. And I was honestly moved that people signed up and stayed steady for almost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=560" target="_blank">00:09:20.480</a></span> | <span class="t">a year. These guys are truly my Spartans, and many of you will be watching. But yes, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=566" target="_blank">00:09:26.000</a></span> | <span class="t">I read the emails of people saying it was just a bit too much money for them and they couldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=571" target="_blank">00:09:31.280</a></span> | <span class="t">quite afford it. So nine months on, I have decided to take what you could call a gamble with my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=578" target="_blank">00:09:38.080</a></span> | <span class="t">entire career and reduce the price significantly from $29 a month to $9 a month all in, or actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=587" target="_blank">00:09:47.440</a></span> | <span class="t">with an annual sub discount, $7.56 a month. Now, just quickly to encourage my dedicated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=593" target="_blank">00:09:53.840</a></span> | <span class="t">supporters to stay on that higher tier, I will be keeping the unfiltered personal podcast exclusive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=599" target="_blank">00:09:59.360</a></span> | <span class="t">to that original $29 tier. And to anyone who stays at that tier, I will personally message you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=604" target="_blank">00:10:04.880</a></span> | <span class="t">with thanks. Also, I do that for every new person joining that tier. But to everyone else for whom</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=610" target="_blank">00:10:10.560</a></span> | <span class="t">$9 a month is viable, let me finish these two quick minutes with a tour. What you get access</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=616" target="_blank">00:10:16.320</a></span> | <span class="t">to is exclusive AI explained videos. I think there's around 30 of them now, like this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=621" target="_blank">00:10:21.440</a></span> | <span class="t">from last night on that humanities last exam or benchmark that people were talking about yesterday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=626" target="_blank">00:10:26.800</a></span> | <span class="t">Exact same quality that you would expect. And you get explainers like this one on the origins of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=631" target="_blank">00:10:31.520</a></span> | <span class="t">term AGI. Obviously people comment as they do on YouTube and on and on. You can also download each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=637" target="_blank">00:10:37.360</a></span> | <span class="t">video so you can watch it offline if you want to. For those $9 or $7, you also get access to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=644" target="_blank">00:10:44.720</a></span> | <span class="t">Discord, which has evolved a lot since it started. Now has live meetups, a new book club, and of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=650" target="_blank">00:10:50.640</a></span> | <span class="t">course, general discussion. If you go to the introductions page, you can see the caliber of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=656" target="_blank">00:10:56.000</a></span> | <span class="t">the kind of people who join on Discord. Some people, of course, won't care about any of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=661" target="_blank">00:11:01.040</a></span> | <span class="t">and will just want to support hype-free AI journalism in a landscape I wrote that increasingly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=667" target="_blank">00:11:07.360</a></span> | <span class="t">needs it. Totally understand, by the way, if $9 is too much, I am just super grateful for you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=672" target="_blank">00:11:12.720</a></span> | <span class="t">watching. Back to O1 though, and one thing you might have noticed is we can't actually see those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=678" target="_blank">00:11:18.480</a></span> | <span class="t">chains of thought. If you've used O1 for sure, you do see a summary and of course the output,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=683" target="_blank">00:11:23.440</a></span> | <span class="t">but not the true chains of thought that led it to the output. OpenAI admits that part of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=688" target="_blank">00:11:28.800</a></span> | <span class="t">reason for that is their own competitive advantage and if you have followed the analysis so far,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=694" target="_blank">00:11:34.480</a></span> | <span class="t">that would kind of make sense. Rival labs, especially those that don't care much about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=698" target="_blank">00:11:38.240</a></span> | <span class="t">terms and conditions, could train on successful chains of thought that were outputted by the O1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=703" target="_blank">00:11:43.840</a></span> | <span class="t">series. After all, that is the key ingredient to its success, so it makes sense. But even if we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=708" target="_blank">00:11:48.960</a></span> | <span class="t">can't see those chains of thought, they have clearly unlocked much better serial calculations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=714" target="_blank">00:11:54.720</a></span> | <span class="t">Imagine you had to square a number multiple times in a row. It's really hard to do that in parallel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=720" target="_blank">00:12:00.000</a></span> | <span class="t">isn't it? You kind of need to know the result of the first calculation before you can do the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=724" target="_blank">00:12:04.720</a></span> | <span class="t">one. Well, with a really long scratchpad to work things out on, or a chain of thought that's hidden,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=730" target="_blank">00:12:10.960</a></span> | <span class="t">models get much better at that. That ability to break down long or confusing questions into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=736" target="_blank">00:12:16.880</a></span> | <span class="t">series of small computational steps is why I think that O1 preview gets questions like these correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=743" target="_blank">00:12:23.280</a></span> | <span class="t">most of the time, as people have been pointing out to me. Now, I'm very much aware of that fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=747" target="_blank">00:12:27.600</a></span> | <span class="t">because I analyzed every single answer that O1 preview gave, as I said in my last video when I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=752" target="_blank">00:12:32.880</a></span> | <span class="t">benchmarked it initially on SimpleBench. But that whole thing of just sneaking in a fact amongst</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=758" target="_blank">00:12:38.480</a></span> | <span class="t">many others, as you might see in this question when she eats three other cookies, that's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=762" target="_blank">00:12:42.880</a></span> | <span class="t">one small component of SimpleBench. There still remains many, many question categories where it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=767" target="_blank">00:12:47.920</a></span> | <span class="t">flops badly. Again, because the data is not in its training data. The librarian can't retrieve a book</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=773" target="_blank">00:12:53.680</a></span> | <span class="t">that's not there. The makers of ArcAGI, amongst the most popular AI benchmarks, say this. "In</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=779" target="_blank">00:12:59.360</a></span> | <span class="t">summary, O1 represents a paradigm shift from 'memorize the answers' to 'memorize the reasoning'.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=786" target="_blank">00:13:06.640</a></span> | <span class="t">Remember, it was trained on those reasoning steps that did end up leading to a correct answer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=792" target="_blank">00:13:12.640</a></span> | <span class="t">so it's starting to get better at recognizing which kinds of reasoning lead to correct answers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=799" target="_blank">00:13:19.200</a></span> | <span class="t">in which domain. Less, do I have that exact fact, exact answer in my training data? And more, do I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=806" target="_blank">00:13:26.080</a></span> | <span class="t">have the kind of reasoning steps that I think might be appropriate for solving this problem?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=810" target="_blank">00:13:30.960</a></span> | <span class="t">But still, as I think I've made clear in this video, if those reasoning steps or facts are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=816" target="_blank">00:13:36.080</a></span> | <span class="t">not in the training data, they're not in distribution, it still will fail. O1 is still not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=822" target="_blank">00:13:42.720</a></span> | <span class="t">a departure from the broader paradigm of fitting a curve to a distribution in order to boost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=828" target="_blank">00:13:48.400</a></span> | <span class="t">performance by making everything in distribution, training on everything, expanding the library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=833" target="_blank">00:13:53.760</a></span> | <span class="t">They say we still need new ideas for artificial general intelligence. Another way of putting this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=840" target="_blank">00:14:00.000</a></span> | <span class="t">is that there doesn't exist a foundation model for the physical world. We don't have those banks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=845" target="_blank">00:14:05.680</a></span> | <span class="t">and banks of "correct answers" for real-world tasks. And that's partly why models flop on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=852" target="_blank">00:14:12.240</a></span> | <span class="t">SimpleBench. So you should start to notice a pattern in those questions that O1 Preview</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=858" target="_blank">00:14:18.000</a></span> | <span class="t">is now getting right where GPT-4.0 couldn't. One of the stars of O1, Noam Brown of OpenAI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=864" target="_blank">00:14:24.720</a></span> | <span class="t">gave this example. It came from the famous Professor Rao that I interviewed on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=869" target="_blank">00:14:29.520</a></span> | <span class="t">channel and actually for Insiders. It's about stacking blocks and it's quite confusing at first,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=874" target="_blank">00:14:34.240</a></span> | <span class="t">but O1 Preview gets it nicely. This by the way was originally given as an example of the kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=879" target="_blank">00:14:39.280</a></span> | <span class="t">of problems that LLMs simply can't get right. But I wouldn't say that stacking blocks is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=884" target="_blank">00:14:44.160</a></span> | <span class="t">data sparse kind of domain. It's just that previous models got overwhelmed with the amount</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=888" target="_blank">00:14:48.800</a></span> | <span class="t">of things going on. It just required too many serial calculations and computations and they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=893" target="_blank">00:14:53.680</a></span> | <span class="t">couldn't do it. And if you want more evidence that training data for better or ill dictates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=900" target="_blank">00:15:00.320</a></span> | <span class="t">performance, here's an example with O1 Preview. The surgeon who is the boy's father says,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=908" target="_blank">00:15:08.480</a></span> | <span class="t">"I can't operate on this boy. He's my son." Who is the surgeon to the boy? Remember? He's been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=914" target="_blank">00:15:14.480</a></span> | <span class="t">described as the boy's father. But the surgeon is the boy's other father. The boy has two fathers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=920" target="_blank">00:15:20.160</a></span> | <span class="t">As always then, it's worth remembering that exam-style knowledge benchmarks in particular,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=926" target="_blank">00:15:26.320</a></span> | <span class="t">rather than true reasoning benchmarks, does not equal real-world capabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=931" target="_blank">00:15:31.040</a></span> | <span class="t">I now want to count down 10 more interesting facts and bits of background about O1 before I end on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=937" target="_blank">00:15:37.840</a></span> | <span class="t">where we all go from here. What comes next? First, as you may have gathered, the training of O1 was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=943" target="_blank">00:15:43.600</a></span> | <span class="t">fundamentally different from GPT-40. That extra layer of reinforcement learning means that no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=949" target="_blank">00:15:49.760</a></span> | <span class="t">amount of prompt engineering on the base GPT-40, no amount of asking for thinking step-by-step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=955" target="_blank">00:15:55.600</a></span> | <span class="t">will be able to match its performance. Next is that O1 Preview and O1 might be piecing together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=962" target="_blank">00:16:02.720</a></span> | <span class="t">reasoning steps that we haven't pieced together before. They're still "our" reasoning steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=969" target="_blank">00:16:09.200</a></span> | <span class="t">but the model is optimised to piece together those steps that achieve the desired result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=975" target="_blank">00:16:15.200</a></span> | <span class="t">As one of the key authors of O1, who I talked about a lot last year, Lucas Kaiser said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=980" target="_blank">00:16:20.880</a></span> | <span class="t">"When you know the right chain of thought, you can compute anything." And as Andrej Karpathy said</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=986" target="_blank">00:16:26.560</a></span> | <span class="t">two days ago, "Those thoughts don't even need to be legible to us." They might piece together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=991" target="_blank">00:16:31.360</a></span> | <span class="t">reasoning steps that are translated from other languages, or are in their own made-up language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=997" target="_blank">00:16:37.120</a></span> | <span class="t">Remember that the objective is now clearly to get the right answer, so the models will optimise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1002" target="_blank">00:16:42.880</a></span> | <span class="t">however they can to do so. And my next point is, as Noam Brown points out, this is exactly what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1008" target="_blank">00:16:48.800</a></span> | <span class="t">happened with chess. Indeed, the way he says it is, "This is starting to sound a lot like," referring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1014" target="_blank">00:16:54.160</a></span> | <span class="t">to O1 Mini's performance in the Codeforces contest, "It's starting to sound a lot like the trajectory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1019" target="_blank">00:16:59.680</a></span> | <span class="t">of chess." Which was what? Well, I'm obviously oversimplifying here, but Stockfish, the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1024" target="_blank">00:17:04.960</a></span> | <span class="t">chess model, was trained originally with human heuristics, hand-crafted functions to evaluate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1031" target="_blank">00:17:11.600</a></span> | <span class="t">board positions. Obviously it used search to assess way more positions than a human could,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1036" target="_blank">00:17:16.880</a></span> | <span class="t">but it still had those hand-crafted functions. Well, until July 2023. Stockfish removed the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1043" target="_blank">00:17:23.920</a></span> | <span class="t">hand-crafted evaluation and transitioned to a fully neural network-based approach. Or to put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1049" target="_blank">00:17:29.600</a></span> | <span class="t">it another way, by crafting its own reasoning steps and being optimised to put them together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1054" target="_blank">00:17:34.720</a></span> | <span class="t">in the most effective fashion, we may end up with reasoning that we ourselves couldn't have come up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1059" target="_blank">00:17:39.440</a></span> | <span class="t">with. As long as there is something out there that can grade correct versus incorrect, the performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1064" target="_blank">00:17:44.880</a></span> | <span class="t">will keep improving. For the next series of interesting points, I'm going to draw on a video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1069" target="_blank">00:17:49.840</a></span> | <span class="t">I made nine months ago. Obviously, I am ridiculously biased, but I think it was absolutely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1077" target="_blank">00:17:57.280</a></span> | <span class="t">bang on in terms of its predictions about Q*. Honestly, if you've got time, I recommend watching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1082" target="_blank">00:18:02.240</a></span> | <span class="t">this entire video, but I'm going to pick out a handful of moments where I really called it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1087" target="_blank">00:18:07.280</a></span> | <span class="t">but that's not the important bit. It's where it helps explain that these researchers saw what is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1092" target="_blank">00:18:12.880</a></span> | <span class="t">coming nine months, 12 months ago. The clues were out there. We just had to put them together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1097" target="_blank">00:18:17.680</a></span> | <span class="t">So my fourth interesting point comes from minute 17 of the video, where this approach of emitting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1103" target="_blank">00:18:23.680</a></span> | <span class="t">chains of thought can be extended into different modalities. "Multimodal, where the chain of thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1109" target="_blank">00:18:29.680</a></span> | <span class="t">is basically a simulation of the world. So it will be multimodality and this ability to generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1116" target="_blank">00:18:36.000</a></span> | <span class="t">sequences of things before you give an answer that will resemble much more what we call reasoning."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1123" target="_blank">00:18:43.600</a></span> | <span class="t">That was a short snippet, but I think contains a crucial detail. Just like the O1 family of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1128" target="_blank">00:18:48.640</a></span> | <span class="t">models is scoring dramatically better in physics tests, Sora, the video generation model from OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1135" target="_blank">00:18:55.040</a></span> | <span class="t">could get way better at modeling physics in pixels. It could attempt to predict the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1141" target="_blank">00:19:01.040</a></span> | <span class="t">pixel with chains of thought and be fine-tuned on those predictions that actually worked,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1146" target="_blank">00:19:06.320</a></span> | <span class="t">potentially without even needing a data labeling revolution. A video generation model could learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1151" target="_blank">00:19:11.360</a></span> | <span class="t">which sources, which videos from YouTube, for example, depict reality with the most accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1156" target="_blank">00:19:16.640</a></span> | <span class="t">As one former Googler and OpenAI member, Jeffrey Irving said, "You could have a scenario of let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1162" target="_blank">00:19:22.240</a></span> | <span class="t">think pixel by pixel." This step change, in other words, doesn't have to be limited to text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1167" target="_blank">00:19:27.760</a></span> | <span class="t">Now for my next point, I have no idea why I delayed it this long into the video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1172" target="_blank">00:19:32.240</a></span> | <span class="t">but look at this prediction that I made back in November. I picked out a key paragraph in a paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1177" target="_blank">00:19:37.520</a></span> | <span class="t">called "Let's verify step-by-step" which indicated what OpenAI were working on. "Let's verify step-by-step"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1184" target="_blank">00:19:44.480</a></span> | <span class="t">could be like choosing an action. After all, in the original paper, using test-time compute in this way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1190" target="_blank">00:19:50.000</a></span> | <span class="t">was described as a kind of search. And in "Let's verify", they hinted at a step forward involving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1195" target="_blank">00:19:55.920</a></span> | <span class="t">reinforcement learning. They said, "We do not attempt to improve the generator, the model coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1200" target="_blank">00:20:00.800</a></span> | <span class="t">up with solutions, with reinforcement learning. We do not discuss any supervision the generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1206" target="_blank">00:20:06.000</a></span> | <span class="t">would receive from the reward model, if trained with RL." And here's the key sentence, "Although</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1211" target="_blank">00:20:11.280</a></span> | <span class="t">fine-tuning the generator with reinforcement learning is a natural next step, it is intentionally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1217" target="_blank">00:20:17.200</a></span> | <span class="t">not the focus of this work." Is that the follow-up work that they did? I mean, if that prediction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1222" target="_blank">00:20:22.400</a></span> | <span class="t">isn't worthy of a like on YouTube, or preferably joining AI Insiders, then I don't know what is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1228" target="_blank">00:20:28.000</a></span> | <span class="t">I then went into detail on the 2022 paper that showed how that would be done. In a nutshell,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1233" target="_blank">00:20:33.520</a></span> | <span class="t">it involves fine-tuning a model on the outputs it generated that happen to work. Keep going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1239" target="_blank">00:20:39.280</a></span> | <span class="t">until you generate rationales that get the correct answer, and then fine-tune on all of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1244" target="_blank">00:20:44.640</a></span> | <span class="t">rationales. And they say that, "We show that STAR significantly improves performance on multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1249" target="_blank">00:20:49.760</a></span> | <span class="t">datasets compared to a model fine-tuned to directly predict final answers." Does that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1254" target="_blank">00:20:54.560</a></span> | <span class="t">remind you of Let's Verify? "And performs comparably to fine-tuning a 30x larger state-of-the-art</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1260" target="_blank">00:21:00.960</a></span> | <span class="t">language model." Next, I want to show you all a warning straight from Ilya Sutskever, one of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1267" target="_blank">00:21:07.040</a></span> | <span class="t">key authors of this approach. Presumably, he's putting it to work in the safe superintelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1272" target="_blank">00:21:12.080</a></span> | <span class="t">company. But he had a warning, "Reinforcement learning is creative." Reinforcement learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1277" target="_blank">00:21:17.360</a></span> | <span class="t">has a much more significant challenge. It is creative. Reinforcement learning is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1286" target="_blank">00:21:26.400</a></span> | <span class="t">creative. Every single stunning example of creativity in AI comes from a reinforcement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1294" target="_blank">00:21:34.480</a></span> | <span class="t">learning system. For example, AlphaZero has invented a whole new way of playing a game that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1301" target="_blank">00:21:41.760</a></span> | <span class="t">humans have perfected for thousands of years. It is reinforcement learning that can come up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1305" target="_blank">00:21:45.680</a></span> | <span class="t">creative solutions to problems, solutions which we might not be able to understand at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1311" target="_blank">00:21:51.600</a></span> | <span class="t">And so what happens if you do reinforcement learning on long or even medium time horizon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1317" target="_blank">00:21:57.680</a></span> | <span class="t">when your AI is interacting with the real world, trying to achieve some kind of a beneficial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1324" target="_blank">00:22:04.320</a></span> | <span class="t">outcome, let's say, as judged by us, but while being very, very, very creative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1328" target="_blank">00:22:08.720</a></span> | <span class="t">This does not mean that this problem is unsolvable, but it means that it is a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1334" target="_blank">00:22:14.000</a></span> | <span class="t">And it means that some of the more naive approaches will suffer from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1337" target="_blank">00:22:17.440</a></span> | <span class="t">some unexpected creativity that will make the antics of Sydney seem very modest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1342" target="_blank">00:22:22.720</a></span> | <span class="t">Next, I feel I foreshadowed Q*, Strawberry or O1's weakness with spatial reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1348" target="_blank">00:22:28.800</a></span> | <span class="t">I think the development is likely a big step forward for narrow domains like mathematics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1354" target="_blank">00:22:34.240</a></span> | <span class="t">but is in no way yet a solution for AGI. The world is still a bit too complex for this to work yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1361" target="_blank">00:22:41.520</a></span> | <span class="t">That desperate need to model the world's complexity and achieve true spatial intelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1366" target="_blank">00:22:46.560</a></span> | <span class="t">is why Fei-Fei Li's startup is already worth $1 billion after just four months.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1372" target="_blank">00:22:52.240</a></span> | <span class="t">Now, as I've hinted already in this video, I think OpenAI graded the individual reasoning steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1377" target="_blank">00:22:57.920</a></span> | <span class="t">of the generators outputs, not just whether the overall answer was correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1382" target="_blank">00:23:02.080</a></span> | <span class="t">But for more background on that, it would be easier for me to just play</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1386" target="_blank">00:23:06.000</a></span> | <span class="t">a couple of minutes from that November 2023 video, in which, by the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1390" target="_blank">00:23:10.400</a></span> | <span class="t">I cite a June 2023 video from this channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1394" target="_blank">00:23:14.080</a></span> | <span class="t">So that's test time compute, but what about let's verify step by step?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1397" target="_blank">00:23:17.760</a></span> | <span class="t">Well, going back to that original 2021 verifier paper, they said this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1401" target="_blank">00:23:21.760</a></span> | <span class="t">The problem they noticed with their approach back in 2021 was that their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1405" target="_blank">00:23:25.440</a></span> | <span class="t">models were rewarding correct solutions, but sometimes there would be false positives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1410" target="_blank">00:23:30.320</a></span> | <span class="t">Getting to the correct final answer using flawed reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1413" target="_blank">00:23:33.840</a></span> | <span class="t">They knew this was a problem, and so they worked on it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1416" target="_blank">00:23:36.400</a></span> | <span class="t">And then in May of this year, they came out with let's verify step by step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1421" target="_blank">00:23:41.360</a></span> | <span class="t">In this paper, by getting a verifier or reward model to focus on the process,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1426" target="_blank">00:23:46.560</a></span> | <span class="t">the P, instead of the outcome, the O, results were far more dramatic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1431" target="_blank">00:23:51.600</a></span> | <span class="t">Next, notice how the graph is continuing to rise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1435" target="_blank">00:23:55.040</a></span> | <span class="t">If they just had more, let's say, test time compute, this could continue rising higher.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1440" target="_blank">00:24:00.960</a></span> | <span class="t">And I actually speculated on that back on June the 1st.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1444" target="_blank">00:24:04.480</a></span> | <span class="t">That difference of about 10% is more than half of the difference between GPT-3 and GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1450" target="_blank">00:24:10.800</a></span> | <span class="t">And also, is it me, or is that line continuing to grow?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1454" target="_blank">00:24:14.320</a></span> | <span class="t">Suggesting that when more compute is available, the difference could be even more stark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1458" target="_blank">00:24:18.960</a></span> | <span class="t">Imagine a future where GPT-4 or 5 can sample, say, a trillion 10 to the 12 solutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1465" target="_blank">00:24:25.360</a></span> | <span class="t">So you're beginning to see my hypothesis emerging.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1467" target="_blank">00:24:27.840</a></span> | <span class="t">A new and improved let's verify step by step, called Q*,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1471" target="_blank">00:24:31.600</a></span> | <span class="t">drawing upon enhanced inference time compute to push the graph toward 100%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1476" target="_blank">00:24:36.880</a></span> | <span class="t">If you want more details on that process reward model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1480" target="_blank">00:24:40.160</a></span> | <span class="t">check out the video I did back then called Double the Performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1483" target="_blank">00:24:43.760</a></span> | <span class="t">But the very short version is that they trained a reward model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1487" target="_blank">00:24:47.200</a></span> | <span class="t">to notice the individual steps in a reasoning sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1491" target="_blank">00:24:51.360</a></span> | <span class="t">That reward model then got very good at spotting erroneous steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1495" target="_blank">00:24:55.760</a></span> | <span class="t">Furthermore, when that model concluded that there were no erroneous steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1499" target="_blank">00:24:59.360</a></span> | <span class="t">as we've seen from the graphs, that was highly indicative of a correct solution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1504" target="_blank">00:25:04.080</a></span> | <span class="t">Notice also that sometimes it could pick out such a correct solution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1508" target="_blank">00:25:08.240</a></span> | <span class="t">when the original generator, GPT-4, only outputted that correct solution one time in a thousand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1514" target="_blank">00:25:14.480</a></span> | <span class="t">Furthermore, the method somewhat generalized out of distribution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1518" target="_blank">00:25:18.400</a></span> | <span class="t">going beyond mathematics to boost performance in chemistry, physics, and other subjects.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1524" target="_blank">00:25:24.000</a></span> | <span class="t">And Noam Brown, I think, gave a clear hint that verifiers were used in the training of O1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1530" target="_blank">00:25:30.480</a></span> | <span class="t">Again, my theory is the only answers for which every reasoning step was correct,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1535" target="_blank">00:25:35.120</a></span> | <span class="t">and the final answer were used to train or fine tune the O1 family.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1540" target="_blank">00:25:40.400</a></span> | <span class="t">But just look at this point he leaves hanging in the air</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1543" target="_blank">00:25:43.760</a></span> | <span class="t">after showing the famous let's verify graph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1546" target="_blank">00:25:46.400</a></span> | <span class="t">If you do this process reward models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1547" target="_blank">00:25:47.760</a></span> | <span class="t">where you're verifying every single step with a really good reward model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1550" target="_blank">00:25:50.640</a></span> | <span class="t">you're getting an even bigger boost and you're getting up to 78.2%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1553" target="_blank">00:25:53.440</a></span> | <span class="t">And you can see it still looks like that number,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1555" target="_blank">00:25:55.520</a></span> | <span class="t">that line would go up more if you generated more samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1558" target="_blank">00:25:58.160</a></span> | <span class="t">That's as big a hint as you're going to get that let's verify was key for O1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1564" target="_blank">00:26:04.320</a></span> | <span class="t">And very quickly before I leave let's verify,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1566" target="_blank">00:26:06.880</a></span> | <span class="t">don't forget that that paper cited work from Google.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1570" target="_blank">00:26:10.240</a></span> | <span class="t">Some of the other key authors behind and around let's verify have also gone to Anthropic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1575" target="_blank">00:26:15.440</a></span> | <span class="t">So it's not like OpenAI will be the only ones working on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1579" target="_blank">00:26:19.040</a></span> | <span class="t">Yes, they're well ahead, but I could well see one of those other two labs catching up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1583" target="_blank">00:26:23.200</a></span> | <span class="t">And do you remember early in this video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1584" target="_blank">00:26:24.800</a></span> | <span class="t">I talked about how higher temperature was optimal for generating those creative chains of thought?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1590" target="_blank">00:26:30.000</a></span> | <span class="t">Well, that was suggested as early as 2021 at OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1594" target="_blank">00:26:34.640</a></span> | <span class="t">From the paper I cited in that November 2023 video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1598" target="_blank">00:26:38.320</a></span> | <span class="t">I talked about this paragraph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1600" target="_blank">00:26:40.480</a></span> | <span class="t">Verification consists of sampling multiple high temperature solutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1604" target="_blank">00:26:44.960</a></span> | <span class="t">And then it goes on about verification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1606" target="_blank">00:26:46.720</a></span> | <span class="t">You might be wondering where I'm going with this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1609" target="_blank">00:26:49.120</a></span> | <span class="t">but that is why I think the API of the O1 family keep the temperature at one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1615" target="_blank">00:26:55.520</a></span> | <span class="t">I think the model itself was used to generate those chains of thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1620" target="_blank">00:27:00.320</a></span> | <span class="t">And then that same model was then fine-tuned on those correct solutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1624" target="_blank">00:27:04.400</a></span> | <span class="t">In other words, because the model was trained that way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1626" target="_blank">00:27:06.480</a></span> | <span class="t">it's optimal to keep the temperature at one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1628" target="_blank">00:27:08.640</a></span> | <span class="t">OpenAI don't actually allow you to change it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1630" target="_blank">00:27:10.720</a></span> | <span class="t">Let me know in the comments if you think I've figured out something there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1633" target="_blank">00:27:13.520</a></span> | <span class="t">Anyway, those were the facts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1635" target="_blank">00:27:15.440</a></span> | <span class="t">And the White House is certainly taking all of this quite seriously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1638" target="_blank">00:27:18.960</a></span> | <span class="t">They were shown Strawberry and O1 earlier this year,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1642" target="_blank">00:27:22.640</a></span> | <span class="t">and they now describe how AI data center development and promoting it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1646" target="_blank">00:27:26.960</a></span> | <span class="t">and funding it reflects the importance of these projects to American national security</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1652" target="_blank">00:27:32.640</a></span> | <span class="t">and economic interests.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1654" target="_blank">00:27:34.080</a></span> | <span class="t">The government at the very least is a believer, but are we?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1657" target="_blank">00:27:37.760</a></span> | <span class="t">Well, I have been very impressed by O1 Preview.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1661" target="_blank">00:27:41.040</a></span> | <span class="t">Let me know if you have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1662" target="_blank">00:27:42.560</a></span> | <span class="t">Thank you so much for watching.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1664" target="_blank">00:27:44.240</a></span> | <span class="t">I would love to see you over on AI Insiders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=KKF7kL0pGc4&t=1667" target="_blank">00:27:47.600</a></span> | <span class="t">But either way, please do have a wonderful day.</span></div></div></body></html>