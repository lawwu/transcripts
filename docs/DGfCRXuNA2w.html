<html><head><title>Stanford CS224N NLP with Deep Learning | 2023 | Lecture 9 - Pretraining</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford CS224N NLP with Deep Learning | 2023 | Lecture 9 - Pretraining</h2><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w"><img src="https://i.ytimg.com/vi/DGfCRXuNA2w/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./DGfCRXuNA2w.html">Whisper Transcript</a> | <a href="./transcript_DGfCRXuNA2w.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">[AUDIO OUT]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=5" target="_blank">00:00:05.480</a></span> | <span class="t">Hello.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=6" target="_blank">00:00:06.240</a></span> | <span class="t">Welcome to CS224N.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=9" target="_blank">00:00:09.520</a></span> | <span class="t">Today we'll be talking about pre-training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=12" target="_blank">00:00:12.440</a></span> | <span class="t">which is another exciting topic on the road to modern natural language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=18" target="_blank">00:00:18.120</a></span> | <span class="t">processing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=20" target="_blank">00:00:20.160</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=21" target="_blank">00:00:21.760</a></span> | <span class="t">How is everyone doing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=23" target="_blank">00:00:23.520</a></span> | <span class="t">Thumbs up, some side, thumbs down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=27" target="_blank">00:00:27.280</a></span> | <span class="t">Wow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=28" target="_blank">00:00:28.240</a></span> | <span class="t">No response bias there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=29" target="_blank">00:00:29.880</a></span> | <span class="t">All thumbs up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=31" target="_blank">00:00:31.200</a></span> | <span class="t">Oh, side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=31" target="_blank">00:00:31.760</a></span> | <span class="t">Nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=32" target="_blank">00:00:32.000</a></span> | <span class="t">I like that honesty.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=32" target="_blank">00:00:32.840</a></span> | <span class="t">That's good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=33" target="_blank">00:00:33.360</a></span> | <span class="t">Well, OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=35" target="_blank">00:00:35.800</a></span> | <span class="t">So we're now-- what is this, week five?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=39" target="_blank">00:00:39.360</a></span> | <span class="t">Yes, it's week five.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=40" target="_blank">00:00:40.640</a></span> | <span class="t">And we have a couple--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=42" target="_blank">00:00:42.880</a></span> | <span class="t">so this lecture, the Transformers lecture, and then to a lesser extent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=47" target="_blank">00:00:47.800</a></span> | <span class="t">Thursday's lecture on natural language generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=51" target="_blank">00:00:51.680</a></span> | <span class="t">will be sort of the sum of lectures for the assignments you have to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=56" target="_blank">00:00:56.280</a></span> | <span class="t">So assignment five is coming out on Thursday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=61" target="_blank">00:01:01.480</a></span> | <span class="t">And the topics covered in this lecture, and self-attention transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=66" target="_blank">00:01:06.640</a></span> | <span class="t">and again, a little bit of natural language generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=69" target="_blank">00:01:09.000</a></span> | <span class="t">will be tested in assignment five.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=70" target="_blank">00:01:10.440</a></span> | <span class="t">And then the rest of the course will go through some really fascinating topics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=74" target="_blank">00:01:14.600</a></span> | <span class="t">in sort of modern natural language processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=77" target="_blank">00:01:17.640</a></span> | <span class="t">that should be useful for your final projects, and future jobs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=80" target="_blank">00:01:20.920</a></span> | <span class="t">and interviews, and intellectual curiosity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=85" target="_blank">00:01:25.240</a></span> | <span class="t">But I think that today's lecture is significantly less technical in detail</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=91" target="_blank">00:01:31.800</a></span> | <span class="t">than last Thursday's on self-attention and transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=95" target="_blank">00:01:35.600</a></span> | <span class="t">but should give you an idea of the sort of world of pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=101" target="_blank">00:01:41.160</a></span> | <span class="t">and sort of how it helps define natural language processing today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=106" target="_blank">00:01:46.600</a></span> | <span class="t">So a reminder about assignment five, your project proposals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=109" target="_blank">00:01:49.240</a></span> | <span class="t">also are due on Tuesday, next Tuesday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=113" target="_blank">00:01:53.760</a></span> | <span class="t">Please do get those in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=115" target="_blank">00:01:55.160</a></span> | <span class="t">Try to get them in on time so that we can give you prompt feedback</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=118" target="_blank">00:01:58.860</a></span> | <span class="t">about your project proposals.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=121" target="_blank">00:02:01.360</a></span> | <span class="t">And yeah, so let's jump into it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=123" target="_blank">00:02:03.440</a></span> | <span class="t">OK, so what we're going to start with today</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=129" target="_blank">00:02:09.240</a></span> | <span class="t">is a bit of a technical detail on word structure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=136" target="_blank">00:02:16.160</a></span> | <span class="t">and sort of how we model the input sequence of words that we get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=139" target="_blank">00:02:19.800</a></span> | <span class="t">So when we were teaching Word2Vec and sort of all the methods</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=146" target="_blank">00:02:26.360</a></span> | <span class="t">that we've talked about so far, we assumed a finite vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=149" target="_blank">00:02:29.840</a></span> | <span class="t">So you had a vocabulary v that you define via whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=152" target="_blank">00:02:32.560</a></span> | <span class="t">You've looked at some data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=153" target="_blank">00:02:33.680</a></span> | <span class="t">You've decided what the words are in that data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=156" target="_blank">00:02:36.640</a></span> | <span class="t">And so you have some words like hat and learn.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=162" target="_blank">00:02:42.720</a></span> | <span class="t">And you have this embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=164" target="_blank">00:02:44.680</a></span> | <span class="t">It's in red because you've learned it properly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=166" target="_blank">00:02:46.920</a></span> | <span class="t">Actually, let's replace hat and learn with pizza and tasty.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=169" target="_blank">00:02:49.360</a></span> | <span class="t">Those are better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=171" target="_blank">00:02:51.760</a></span> | <span class="t">And so that's all well and good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=173" target="_blank">00:02:53.760</a></span> | <span class="t">You see these words in your model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=176" target="_blank">00:02:56.440</a></span> | <span class="t">And you have an embedding that's been learned on your data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=180" target="_blank">00:03:00.800</a></span> | <span class="t">to sort of know what to do when you see those words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=184" target="_blank">00:03:04.120</a></span> | <span class="t">But when you see some sort of variations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=186" target="_blank">00:03:06.020</a></span> | <span class="t">maybe you see like tasty and maybe a typo like learn,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=191" target="_blank">00:03:11.640</a></span> | <span class="t">or maybe novel items where it's like a word that you as a human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=195" target="_blank">00:03:15.760</a></span> | <span class="t">can understand as sort of this combination.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=198" target="_blank">00:03:18.160</a></span> | <span class="t">This is called derivational morphology of this word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=202" target="_blank">00:03:22.240</a></span> | <span class="t">transformer that you know and if I, which means take this noun</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=206" target="_blank">00:03:26.800</a></span> | <span class="t">and give me back a verb.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=209" target="_blank">00:03:29.240</a></span> | <span class="t">That means to make more like that noun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=211" target="_blank">00:03:31.160</a></span> | <span class="t">To transformerify NLP might mean to make NLP more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=216" target="_blank">00:03:36.200</a></span> | <span class="t">like using transformers and such.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=219" target="_blank">00:03:39.000</a></span> | <span class="t">And for each of these, this maybe didn't show up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=221" target="_blank">00:03:41.200</a></span> | <span class="t">in your training corpus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=222" target="_blank">00:03:42.400</a></span> | <span class="t">And language is always doing this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=225" target="_blank">00:03:45.760</a></span> | <span class="t">People are always coming up with new words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=227" target="_blank">00:03:47.640</a></span> | <span class="t">And there's new domains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=228" target="_blank">00:03:48.960</a></span> | <span class="t">And young people are always making new words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=232" target="_blank">00:03:52.360</a></span> | <span class="t">It's great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=232" target="_blank">00:03:52.840</a></span> | <span class="t">And so it's a problem for your model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=234" target="_blank">00:03:54.640</a></span> | <span class="t">though, because you've defined this finite vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=237" target="_blank">00:03:57.440</a></span> | <span class="t">And there's sort of no mapping in that vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=240" target="_blank">00:04:00.880</a></span> | <span class="t">for each of these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=242" target="_blank">00:04:02.400</a></span> | <span class="t">Even though their meanings should be relatively well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=245" target="_blank">00:04:05.280</a></span> | <span class="t">defined based on the data you've seen so far,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=248" target="_blank">00:04:08.120</a></span> | <span class="t">it's just that the sort of string of characters that define them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=251" target="_blank">00:04:11.560</a></span> | <span class="t">aren't quite what you've seen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=253" target="_blank">00:04:13.760</a></span> | <span class="t">And so what do you do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=254" target="_blank">00:04:14.640</a></span> | <span class="t">Well, maybe you map them to this sort of universal unknown token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=258" target="_blank">00:04:18.440</a></span> | <span class="t">This is UNK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=260" target="_blank">00:04:20.000</a></span> | <span class="t">So it's like, oh, I see something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=261" target="_blank">00:04:21.000</a></span> | <span class="t">I don't know what.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=261" target="_blank">00:04:21.960</a></span> | <span class="t">I've never seen it before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=263" target="_blank">00:04:23.240</a></span> | <span class="t">I'm going to say it's always represented by the same token UNK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=266" target="_blank">00:04:26.840</a></span> | <span class="t">And so that's been done in the past.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=269" target="_blank">00:04:29.120</a></span> | <span class="t">And that's sort of bad, right, because it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=270" target="_blank">00:04:30.960</a></span> | <span class="t">totally losing tons of information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=274" target="_blank">00:04:34.760</a></span> | <span class="t">But you need to map it to something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=278" target="_blank">00:04:38.640</a></span> | <span class="t">And so this is like a clear problem, especially--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=282" target="_blank">00:04:42.480</a></span> | <span class="t">I mean, in English, it's a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=284" target="_blank">00:04:44.120</a></span> | <span class="t">In many of the roles languages, it's a substantially larger problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=289" target="_blank">00:04:49.000</a></span> | <span class="t">So English has relatively simple word structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=293" target="_blank">00:04:53.360</a></span> | <span class="t">There's a couple of conjugations for each verb, like eat, eats, eaten, ate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=300" target="_blank">00:05:00.360</a></span> | <span class="t">But in a language with much more complex morphology or word structure,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=306" target="_blank">00:05:06.960</a></span> | <span class="t">you'll have a considerably more complex sort of set of things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=311" target="_blank">00:05:11.040</a></span> | <span class="t">that you could see in the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=312" target="_blank">00:05:12.360</a></span> | <span class="t">So here is a conjugation table for a Swahili verb.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=317" target="_blank">00:05:17.560</a></span> | <span class="t">And it has over 300 conjugations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=320" target="_blank">00:05:20.840</a></span> | <span class="t">And if I define the vocabulary to be every unique string of characters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=324" target="_blank">00:05:24.800</a></span> | <span class="t">maps to its own word, then every one of the 300 conjugations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=328" target="_blank">00:05:28.400</a></span> | <span class="t">would get an independent vector under my model, which makes no sense,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=333" target="_blank">00:05:33.280</a></span> | <span class="t">because the 300 conjugations obviously have a lot in common</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=337" target="_blank">00:05:37.200</a></span> | <span class="t">and differ by sort of meaningful extent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=339" target="_blank">00:05:39.680</a></span> | <span class="t">So you don't want to do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=341" target="_blank">00:05:41.240</a></span> | <span class="t">You'd have to have a huge vocabulary if I wanted all conjugations to show up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=346" target="_blank">00:05:46.400</a></span> | <span class="t">And that's a mistake for efficiency reasons and for learning reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=351" target="_blank">00:05:51.200</a></span> | <span class="t">Any questions so far?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=352" target="_blank">00:05:52.080</a></span> | <span class="t">Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=356" target="_blank">00:05:56.000</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=357" target="_blank">00:05:57.160</a></span> | <span class="t">And so what we end up doing is we'll look at subword structure,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=365" target="_blank">00:06:05.440</a></span> | <span class="t">subword modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=366" target="_blank">00:06:06.640</a></span> | <span class="t">So what we're going to do is we're going to say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=368" target="_blank">00:06:08.680</a></span> | <span class="t">if I can try to define what the set of all words is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=372" target="_blank">00:06:12.640</a></span> | <span class="t">I'm going to define my vocabulary to include parts of words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=377" target="_blank">00:06:17.640</a></span> | <span class="t">So I'm going to split words into sequences of known subwords.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=390" target="_blank">00:06:30.280</a></span> | <span class="t">And so there's a simple sort of algorithm for this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=393" target="_blank">00:06:33.200</a></span> | <span class="t">where you start with all characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=395" target="_blank">00:06:35.480</a></span> | <span class="t">So if I only had a vocabulary of all characters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=398" target="_blank">00:06:38.240</a></span> | <span class="t">and maybe like an end of word symbol for a finite data set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=404" target="_blank">00:06:44.320</a></span> | <span class="t">then no matter what word I saw in the future,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=406" target="_blank">00:06:46.480</a></span> | <span class="t">as long as I had seen all possible characters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=408" target="_blank">00:06:48.560</a></span> | <span class="t">I could take the word and say, I don't know what this word is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=411" target="_blank">00:06:51.100</a></span> | <span class="t">I'm going to split it into all of its individual characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=413" target="_blank">00:06:53.960</a></span> | <span class="t">So you won't have this unk problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=415" target="_blank">00:06:55.440</a></span> | <span class="t">You can sort of represent any word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=417" target="_blank">00:06:57.360</a></span> | <span class="t">And then you're going to find common adjacent characters and say, OK,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=421" target="_blank">00:07:01.240</a></span> | <span class="t">A and B co-occur next to each other quite a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=423" target="_blank">00:07:03.920</a></span> | <span class="t">So I'm going to add a new word to my vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=427" target="_blank">00:07:07.120</a></span> | <span class="t">Now it's all characters plus this new word A, B, which is a subword.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=433" target="_blank">00:07:13.440</a></span> | <span class="t">And likewise, so now I'm going to replace the character pair</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=436" target="_blank">00:07:16.040</a></span> | <span class="t">with the new subword and repeat until you add a lot, a lot, a lot of vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=440" target="_blank">00:07:20.720</a></span> | <span class="t">items through this process of what things tend to co-occur next to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=444" target="_blank">00:07:24.520</a></span> | <span class="t">And so what you'll end up with is a vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=448" target="_blank">00:07:28.480</a></span> | <span class="t">of very commonly co-occurring sort of substrings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=451" target="_blank">00:07:31.600</a></span> | <span class="t">by which you can build up words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=453" target="_blank">00:07:33.540</a></span> | <span class="t">And this was originally developed for machine translation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=456" target="_blank">00:07:36.000</a></span> | <span class="t">but then it's been used considerably in pretty much all modern language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=461" target="_blank">00:07:41.200</a></span> | <span class="t">So now we have a hat and learn, hat and learn.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=464" target="_blank">00:07:44.120</a></span> | <span class="t">So in our subword vocabulary, hat and learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=466" target="_blank">00:07:46.840</a></span> | <span class="t">showed up enough that they're their own individual words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=469" target="_blank">00:07:49.920</a></span> | <span class="t">So that's sort of good, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=471" target="_blank">00:07:51.800</a></span> | <span class="t">So simple common words show up as a word in your vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=476" target="_blank">00:07:56.560</a></span> | <span class="t">just like you'd like them to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=477" target="_blank">00:07:57.760</a></span> | <span class="t">But now tasty maybe gets split into T-A-A.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=481" target="_blank">00:08:01.200</a></span> | <span class="t">And then maybe in some cases, this hash hash</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=484" target="_blank">00:08:04.040</a></span> | <span class="t">means like don't add a space next, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=487" target="_blank">00:08:07.160</a></span> | <span class="t">So T-A-A and then A-A-A and then S-T-Y, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=492" target="_blank">00:08:12.160</a></span> | <span class="t">So I've actually taken one sort of thing that seems like a word,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=495" target="_blank">00:08:15.200</a></span> | <span class="t">and in my vocabulary, it's now split into three subword tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=500" target="_blank">00:08:20.120</a></span> | <span class="t">So when I pass this to my transformer or to my recurrent neural network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=504" target="_blank">00:08:24.960</a></span> | <span class="t">the recurrent neural network would take T-A-A as just a single element,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=509" target="_blank">00:08:29.960</a></span> | <span class="t">do the RNN update, and then take A-A-A, do the RNN update, and then S-T-Y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=515" target="_blank">00:08:35.200</a></span> | <span class="t">So it could learn to process constructions like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=519" target="_blank">00:08:39.720</a></span> | <span class="t">And maybe I can even add more A-A-As in the middle,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=521" target="_blank">00:08:41.920</a></span> | <span class="t">and have it do something similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=524" target="_blank">00:08:44.080</a></span> | <span class="t">Instead of just seeing the entire word tasty and not knowing what it means.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=531" target="_blank">00:08:51.960</a></span> | <span class="t">Is that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=533" target="_blank">00:08:53.240</a></span> | <span class="t">That's feedback, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=538" target="_blank">00:08:58.920</a></span> | <span class="t">How loud is that feedback?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=541" target="_blank">00:09:01.320</a></span> | <span class="t">We good?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=542" target="_blank">00:09:02.920</a></span> | <span class="t">OK, I think we're fixed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=544" target="_blank">00:09:04.200</a></span> | <span class="t">Great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=546" target="_blank">00:09:06.480</a></span> | <span class="t">And so same with transformerify.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=548" target="_blank">00:09:08.040</a></span> | <span class="t">Maybe transformer is its own word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=550" target="_blank">00:09:10.080</a></span> | <span class="t">And then if I--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=551" target="_blank">00:09:11.240</a></span> | <span class="t">and so you can see that you have sort of three learned embeddings instead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=554" target="_blank">00:09:14.760</a></span> | <span class="t">of one sort of useless unkembedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=557" target="_blank">00:09:17.760</a></span> | <span class="t">This is just wildly useful and is used pretty much everywhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=561" target="_blank">00:09:21.280</a></span> | <span class="t">Variants of this algorithm are used pretty much everywhere in modern NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=566" target="_blank">00:09:26.480</a></span> | <span class="t">Questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=567" target="_blank">00:09:27.040</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=568" target="_blank">00:09:28.640</a></span> | <span class="t">If we have three embeddings for tasty, do we just add them together?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=572" target="_blank">00:09:32.840</a></span> | <span class="t">So the question is, if we have three embeddings for tasty,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=575" target="_blank">00:09:35.220</a></span> | <span class="t">do we just add them together?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=578" target="_blank">00:09:38.080</a></span> | <span class="t">If we want to represent--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=579" target="_blank">00:09:39.920</a></span> | <span class="t">so when we're actually processing the sequence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=582" target="_blank">00:09:42.520</a></span> | <span class="t">I'd see something like I learned about the T-A-A, A-A-A, S-T-Y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=590" target="_blank">00:09:50.160</a></span> | <span class="t">So it'd actually be totally separate tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=592" target="_blank">00:09:52.480</a></span> | <span class="t">But if I wanted to then say, what's my representation of this thing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=597" target="_blank">00:09:57.520</a></span> | <span class="t">Depends on what you want to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=598" target="_blank">00:09:58.800</a></span> | <span class="t">Sometimes you average the contextual representations of the three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=602" target="_blank">00:10:02.960</a></span> | <span class="t">or look at the last one maybe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=606" target="_blank">00:10:06.400</a></span> | <span class="t">At that point, it's unclear what to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=608" target="_blank">00:10:08.000</a></span> | <span class="t">But everything sort of works OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=610" target="_blank">00:10:10.920</a></span> | <span class="t">How do you know where to split?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=612" target="_blank">00:10:12.800</a></span> | <span class="t">How do you what?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=613" target="_blank">00:10:13.520</a></span> | <span class="t">How do you know where to split?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=615" target="_blank">00:10:15.200</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=615" target="_blank">00:10:15.720</a></span> | <span class="t">So you know where to split based on the algorithm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=618" target="_blank">00:10:18.720</a></span> | <span class="t">that I specified earlier for learning the vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=623" target="_blank">00:10:23.280</a></span> | <span class="t">So you learn this vocabulary by just combining</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=625" target="_blank">00:10:25.800</a></span> | <span class="t">commonly co-occurring adjacent strings of letters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=629" target="_blank">00:10:29.080</a></span> | <span class="t">So like A, B co-occurred a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=630" target="_blank">00:10:30.920</a></span> | <span class="t">So now I've got a new word that's A, B.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=634" target="_blank">00:10:34.000</a></span> | <span class="t">And then when I'm actually walking through and tokenizing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=636" target="_blank">00:10:36.520</a></span> | <span class="t">I try to split as little as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=638" target="_blank">00:10:38.560</a></span> | <span class="t">So I split words into the maximal sort of subword</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=641" target="_blank">00:10:41.600</a></span> | <span class="t">that takes up the most characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=643" target="_blank">00:10:43.060</a></span> | <span class="t">There are algorithms for this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=645" target="_blank">00:10:45.120</a></span> | <span class="t">Yeah, so I'm like, OK, if I want to split this up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=649" target="_blank">00:10:49.040</a></span> | <span class="t">there's many ways I could split it up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=650" target="_blank">00:10:50.580</a></span> | <span class="t">And you try to find some approximate what the best way to split it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=654" target="_blank">00:10:54.080</a></span> | <span class="t">into the fewest words is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=655" target="_blank">00:10:55.120</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=656" target="_blank">00:10:56.120</a></span> | <span class="t">Does it seem to make sense to use punctuation in the character set?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=660" target="_blank">00:11:00.520</a></span> | <span class="t">So the question is, do people use punctuation in the character set?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=664" target="_blank">00:11:04.600</a></span> | <span class="t">Do people do it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=665" target="_blank">00:11:05.240</a></span> | <span class="t">Yes, absolutely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=666" target="_blank">00:11:06.360</a></span> | <span class="t">So sort of from this point on, just assume</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=672" target="_blank">00:11:12.760</a></span> | <span class="t">that what text is given to these models is as unprocessed as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=677" target="_blank">00:11:17.680</a></span> | <span class="t">You try to make it sort of clean looking text, where you've removed HTML tags,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=682" target="_blank">00:11:22.680</a></span> | <span class="t">maybe if it's from the internet or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=686" target="_blank">00:11:26.240</a></span> | <span class="t">But then beyond that, you process it as little as possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=689" target="_blank">00:11:29.120</a></span> | <span class="t">so that it reflects as well as possible what people might actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=692" target="_blank">00:11:32.600</a></span> | <span class="t">be using this for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=695" target="_blank">00:11:35.080</a></span> | <span class="t">So maybe earlier in the course, when we were looking at Word2Vec,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=698" target="_blank">00:11:38.320</a></span> | <span class="t">maybe we had what might have thought about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=700" target="_blank">00:11:40.280</a></span> | <span class="t">oh, we don't want Word2Vec vectors of punctuation or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=705" target="_blank">00:11:45.520</a></span> | <span class="t">Now everything is just as close as possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=708" target="_blank">00:11:48.240</a></span> | <span class="t">to what the text you'd get with people trying to use your system would be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=712" target="_blank">00:11:52.120</a></span> | <span class="t">So yes, in practice, punctuation and dot, dot, dot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=715" target="_blank">00:11:55.600</a></span> | <span class="t">might be its own word, and maybe a sequence of hyphens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=720" target="_blank">00:12:00.320</a></span> | <span class="t">because people make big bars across tables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=723" target="_blank">00:12:03.200</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=723" target="_blank">00:12:03.700</a></span> | <span class="t">How does it impact one wordage now?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=731" target="_blank">00:12:11.800</a></span> | <span class="t">Could be multiple embeddings versus a single embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=736" target="_blank">00:12:16.680</a></span> | <span class="t">Does the system treat those any differently?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=741" target="_blank">00:12:21.760</a></span> | <span class="t">The question is, does the system treat any differently words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=744" target="_blank">00:12:24.280</a></span> | <span class="t">that are really themselves a whole word versus words that are pieces?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=748" target="_blank">00:12:28.440</a></span> | <span class="t">No, the system has no idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=749" target="_blank">00:12:29.680</a></span> | <span class="t">They're all just indices into your embedding vocabulary matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=756" target="_blank">00:12:36.320</a></span> | <span class="t">So they're all treated equally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=757" target="_blank">00:12:37.960</a></span> | <span class="t">What about really long words that are relatively common?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=764" target="_blank">00:12:44.640</a></span> | <span class="t">Because if you're building up from single character all the way up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=767" target="_blank">00:12:47.880</a></span> | <span class="t">what happens then?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=769" target="_blank">00:12:49.440</a></span> | <span class="t">The question is, what happens to very long words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=771" target="_blank">00:12:51.920</a></span> | <span class="t">if you're building up from character pairs and portions of characters?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=777" target="_blank">00:12:57.400</a></span> | <span class="t">In practice, the statistics speak really well for themselves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=781" target="_blank">00:13:01.080</a></span> | <span class="t">So if a long word is very common, it will end up in the vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=784" target="_blank">00:13:04.720</a></span> | <span class="t">And if it's not very common, it won't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=787" target="_blank">00:13:07.920</a></span> | <span class="t">There are algorithms that aren't this that do slightly better in various ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=793" target="_blank">00:13:13.000</a></span> | <span class="t">But the intuition that you figure out what the common co-occurring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=797" target="_blank">00:13:17.520</a></span> | <span class="t">substrings are, independent of length almost,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=800" target="_blank">00:13:20.480</a></span> | <span class="t">is the right intuition to have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=802" target="_blank">00:13:22.040</a></span> | <span class="t">And so you can actually just look at the learned vocabularies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=805" target="_blank">00:13:25.080</a></span> | <span class="t">of a lot of these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=806" target="_blank">00:13:26.600</a></span> | <span class="t">And you see some long words just because they showed up a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=812" target="_blank">00:13:32.240</a></span> | <span class="t">I'm curious, how does it weigh the frequency?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=821" target="_blank">00:13:41.280</a></span> | <span class="t">So let's say there's if-y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=823" target="_blank">00:13:43.680</a></span> | <span class="t">In your next slide, it was like if-i at the very last one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=828" target="_blank">00:13:48.080</a></span> | <span class="t">So if could be really common.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=830" target="_blank">00:13:50.120</a></span> | <span class="t">So how does it weigh the frequency of a subword versus the length of it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=834" target="_blank">00:13:54.320</a></span> | <span class="t">It tries to spread it up into the smallest number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=836" target="_blank">00:13:56.920</a></span> | <span class="t">But what if it split it up into three, but one of them was super common?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=840" target="_blank">00:14:00.960</a></span> | <span class="t">Yeah, so the question is, if transformer is a subword in my vocabulary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=845" target="_blank">00:14:05.920</a></span> | <span class="t">and if is a subword, and y is a subword, and if-i as a three-letter tuple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=852" target="_blank">00:14:12.840</a></span> | <span class="t">is also a subword, how does it choose to take the--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=855" target="_blank">00:14:15.800</a></span> | <span class="t">if-i, maybe it's not very common, as opposed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=859" target="_blank">00:14:19.920</a></span> | <span class="t">to splitting it into more subwords.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=863" target="_blank">00:14:23.000</a></span> | <span class="t">It's just a choice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=863" target="_blank">00:14:23.840</a></span> | <span class="t">We choose to try to take the smallest number of subwords,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=866" target="_blank">00:14:26.480</a></span> | <span class="t">because that tends to be more of the bottleneck, as opposed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=869" target="_blank">00:14:29.720</a></span> | <span class="t">to having a bunch of very common, very short subwords.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=874" target="_blank">00:14:34.800</a></span> | <span class="t">Sequence length is a big problem in transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=876" target="_blank">00:14:36.960</a></span> | <span class="t">And this seems to be what works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=879" target="_blank">00:14:39.360</a></span> | <span class="t">Although trying to split things into multiple options of a sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=882" target="_blank">00:14:42.560</a></span> | <span class="t">and running the transformer on all of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=884" target="_blank">00:14:44.600</a></span> | <span class="t">is the thing that people have done to see which one will work better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=887" target="_blank">00:14:47.760</a></span> | <span class="t">But yeah, having fewer bigger subwords tends to be the best sort of idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=891" target="_blank">00:14:51.640</a></span> | <span class="t">I'm going to start moving on, though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=893" target="_blank">00:14:53.320</a></span> | <span class="t">Feel free to ask me more questions about this afterward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=896" target="_blank">00:14:56.720</a></span> | <span class="t">OK, so let's talk about pre-training from the context of the course so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=903" target="_blank">00:15:03.120</a></span> | <span class="t">So at the very beginning of the course, we gave you this quote, which was,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=907" target="_blank">00:15:07.480</a></span> | <span class="t">"You shall know a word by the company it keeps."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=909" target="_blank">00:15:09.640</a></span> | <span class="t">This was the sort of thesis of the distributional hypothesis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=913" target="_blank">00:15:13.640</a></span> | <span class="t">that the meaning of the word is defined by, or at least reflected by,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=917" target="_blank">00:15:17.960</a></span> | <span class="t">what words it tends to co-occur around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=919" target="_blank">00:15:19.800</a></span> | <span class="t">And we implemented this via Word2Vec.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=923" target="_blank">00:15:23.960</a></span> | <span class="t">The same person who made that quote had a separate quote, actually earlier,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=929" target="_blank">00:15:29.720</a></span> | <span class="t">that continues this notion of meaning as defined by context, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=934" target="_blank">00:15:34.800</a></span> | <span class="t">has something along the lines of, well, since the word shows up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=938" target="_blank">00:15:38.920</a></span> | <span class="t">in context when we actually use it, when we speak to each other,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=942" target="_blank">00:15:42.560</a></span> | <span class="t">the meaning of the word should be defined in the context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=945" target="_blank">00:15:45.760</a></span> | <span class="t">that it actually shows up in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=947" target="_blank">00:15:47.480</a></span> | <span class="t">And so the complete meaning of a word is always contextual,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=951" target="_blank">00:15:51.360</a></span> | <span class="t">and no study of meaning apart from a complete context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=954" target="_blank">00:15:54.280</a></span> | <span class="t">can be taken seriously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=955" target="_blank">00:15:55.920</a></span> | <span class="t">So the big difference here is, at Word2Vec training time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=961" target="_blank">00:16:01.240</a></span> | <span class="t">if I have the word record, R-E-C-O-R-D, when I'm training Word2Vec,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=967" target="_blank">00:16:07.920</a></span> | <span class="t">I get one vector or two, but one vector meaning record, the string.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=976" target="_blank">00:16:16.160</a></span> | <span class="t">And it has to learn by what context it shows up in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=979" target="_blank">00:16:19.960</a></span> | <span class="t">that sometimes it can mean I record, i.e. the verb, or record, i.e.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=986" target="_blank">00:16:26.720</a></span> | <span class="t">the noun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=988" target="_blank">00:16:28.040</a></span> | <span class="t">But I only have one vector to represent it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=990" target="_blank">00:16:30.480</a></span> | <span class="t">And so when I use the Word2Vec embedding of record,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=993" target="_blank">00:16:33.320</a></span> | <span class="t">it sort of has this mixture meaning of both of its sort of senses, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=998" target="_blank">00:16:38.960</a></span> | <span class="t">It doesn't get to specialize and say, oh, this part means record,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1003" target="_blank">00:16:43.040</a></span> | <span class="t">and this part means record.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1005" target="_blank">00:16:45.040</a></span> | <span class="t">And so Word2Vec is going to just sort of fail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1008" target="_blank">00:16:48.320</a></span> | <span class="t">And so I can build better representations of language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1011" target="_blank">00:16:51.360</a></span> | <span class="t">through these contextual representations that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1013" target="_blank">00:16:53.640</a></span> | <span class="t">are going to take things like recurrent neural networks or transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1016" target="_blank">00:16:56.640</a></span> | <span class="t">that we used before to build up sort of contextual meaning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1019" target="_blank">00:16:59.640</a></span> | <span class="t">[AUDIO OUT]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1023" target="_blank">00:17:03.320</a></span> | <span class="t">So what we had before were pre-trained word embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1027" target="_blank">00:17:07.600</a></span> | <span class="t">And then we had sort of a big box on top of it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1030" target="_blank">00:17:10.960</a></span> | <span class="t">like a transformer or an LSTM, that was not pre-trained, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1035" target="_blank">00:17:15.160</a></span> | <span class="t">So you learn via context your word embeddings here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1039" target="_blank">00:17:19.320</a></span> | <span class="t">And then you have a task, like sentiment analysis or machine translation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1043" target="_blank">00:17:23.400</a></span> | <span class="t">or parsing or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1045" target="_blank">00:17:25.760</a></span> | <span class="t">And you initialize all the parameters of this randomly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1049" target="_blank">00:17:29.180</a></span> | <span class="t">And then you train to predict your label.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1053" target="_blank">00:17:33.120</a></span> | <span class="t">And the big difference in today's work is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1057" target="_blank">00:17:37.040</a></span> | <span class="t">that we're going to try to pre-train all the parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1059" target="_blank">00:17:39.600</a></span> | <span class="t">So I have my big transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1061" target="_blank">00:17:41.180</a></span> | <span class="t">And instead of just pre-training my word embeddings with Word2Vec,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1065" target="_blank">00:17:45.500</a></span> | <span class="t">I'm going to train all of the parameters of the network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1070" target="_blank">00:17:50.800</a></span> | <span class="t">trying to teach it much more about language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1074" target="_blank">00:17:54.560</a></span> | <span class="t">that I could use in my downstream tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1077" target="_blank">00:17:57.600</a></span> | <span class="t">So now the labeled data that I have for, say, machine translation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1083" target="_blank">00:18:03.600</a></span> | <span class="t">might need to be smaller.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1085" target="_blank">00:18:05.720</a></span> | <span class="t">I might not need as much of it, because I've already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1088" target="_blank">00:18:08.520</a></span> | <span class="t">trained much more of the network than I otherwise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1090" target="_blank">00:18:10.760</a></span> | <span class="t">would have if I had just gotten Word2Vec embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1093" target="_blank">00:18:13.480</a></span> | <span class="t">So here, I've pre-trained this entire structure--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1100" target="_blank">00:18:20.360</a></span> | <span class="t">the word embeddings, the transformer on top.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1103" target="_blank">00:18:23.640</a></span> | <span class="t">Everything's been trained via methods that we'll talk about today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1107" target="_blank">00:18:27.040</a></span> | <span class="t">And so what does this give you?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1108" target="_blank">00:18:28.680</a></span> | <span class="t">I mean, it gives you very strong representations of language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1111" target="_blank">00:18:31.520</a></span> | <span class="t">So the meaning of record and record will be different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1116" target="_blank">00:18:36.120</a></span> | <span class="t">in the sort of contextual representations that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1118" target="_blank">00:18:38.920</a></span> | <span class="t">know where in the sequence it is and what words are co-occurring with it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1122" target="_blank">00:18:42.920</a></span> | <span class="t">in this specific input than Word2Vec, which only has one representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1126" target="_blank">00:18:46.800</a></span> | <span class="t">for record independent of where it shows up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1130" target="_blank">00:18:50.080</a></span> | <span class="t">It'll also be used as strong parameter initializations for NLP models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1135" target="_blank">00:18:55.040</a></span> | <span class="t">So in all of your homework so far, you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1136" target="_blank">00:18:56.920</a></span> | <span class="t">worked with building out a natural language processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1140" target="_blank">00:19:00.440</a></span> | <span class="t">system sort of from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1142" target="_blank">00:19:02.040</a></span> | <span class="t">How do I initialize this weight matrix?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1143" target="_blank">00:19:03.680</a></span> | <span class="t">And we always say, oh, small, normally distributed noise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1148" target="_blank">00:19:08.080</a></span> | <span class="t">like little values close to 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1152" target="_blank">00:19:12.280</a></span> | <span class="t">And here, we're going to say, well, just like we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1154" target="_blank">00:19:14.800</a></span> | <span class="t">were going to use the Word2Vec embeddings and those sort of encoded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1158" target="_blank">00:19:18.440</a></span> | <span class="t">structure, I'm going to start maybe my machine translation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1161" target="_blank">00:19:21.400</a></span> | <span class="t">system from a parameter initialization that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1163" target="_blank">00:19:23.760</a></span> | <span class="t">given to me via pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1167" target="_blank">00:19:27.380</a></span> | <span class="t">And then also, it's going to give us probability distributions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1169" target="_blank">00:19:29.880</a></span> | <span class="t">over language that we can use to generate and otherwise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1173" target="_blank">00:19:33.440</a></span> | <span class="t">And we'll talk about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1175" target="_blank">00:19:35.800</a></span> | <span class="t">So whole models are going to be pre-trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1178" target="_blank">00:19:38.240</a></span> | <span class="t">So all of pre-training is effectively going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1182" target="_blank">00:19:42.020</a></span> | <span class="t">to be centered around this idea of reconstructing the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1185" target="_blank">00:19:45.600</a></span> | <span class="t">So you have an input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1187" target="_blank">00:19:47.040</a></span> | <span class="t">It's a sequence of text that some human has generated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1189" target="_blank">00:19:49.840</a></span> | <span class="t">And the sort of hypothesis is that by masking out part of it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1195" target="_blank">00:19:55.960</a></span> | <span class="t">and tasking a neural network with reconstructing the original input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1200" target="_blank">00:20:00.720</a></span> | <span class="t">that neural network has to learn a lot about language, about the world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1205" target="_blank">00:20:05.320</a></span> | <span class="t">in order to do a good job of reconstructing the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1207" target="_blank">00:20:07.960</a></span> | <span class="t">So this is now a supervised learning problem,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1210" target="_blank">00:20:10.880</a></span> | <span class="t">just like machine translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1213" target="_blank">00:20:13.520</a></span> | <span class="t">Taking this sentence that just existed, Stanford University</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1216" target="_blank">00:20:16.120</a></span> | <span class="t">is located in, say, Palo Alto, California, or Stanford, California,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1220" target="_blank">00:20:20.560</a></span> | <span class="t">I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1223" target="_blank">00:20:23.240</a></span> | <span class="t">And I have, by removing this part of the sentence, made a label for myself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1229" target="_blank">00:20:29.560</a></span> | <span class="t">The input is this sort of broken masked sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1233" target="_blank">00:20:33.680</a></span> | <span class="t">And the label is Stanford or Palo Alto.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1236" target="_blank">00:20:36.420</a></span> | <span class="t">So if I give this example to a network and ask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1241" target="_blank">00:20:41.940</a></span> | <span class="t">it to predict the center thing, as it's doing its gradient step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1245" target="_blank">00:20:45.360</a></span> | <span class="t">on this input, it's going to encode information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1247" target="_blank">00:20:47.760</a></span> | <span class="t">about the co-occurrence between this context, Stanford University is located</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1251" target="_blank">00:20:51.600</a></span> | <span class="t">in, and Palo Alto.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1253" target="_blank">00:20:53.680</a></span> | <span class="t">So by tasking it with this, it might learn, say, where Stanford is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1258" target="_blank">00:20:58.320</a></span> | <span class="t">What else might it learn?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1259" target="_blank">00:20:59.320</a></span> | <span class="t">Well, it can learn things about maybe syntax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1261" target="_blank">00:21:01.560</a></span> | <span class="t">So I put blank fork down on the table.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1265" target="_blank">00:21:05.480</a></span> | <span class="t">Here, there's only a certain set of words that could go here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1268" target="_blank">00:21:08.200</a></span> | <span class="t">I put the fork down on the table.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1269" target="_blank">00:21:09.960</a></span> | <span class="t">I put a fork down on the table.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1271" target="_blank">00:21:11.960</a></span> | <span class="t">These are syntactic constraints.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1274" target="_blank">00:21:14.240</a></span> | <span class="t">So the context shows me what kinds of words can appear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1278" target="_blank">00:21:18.520</a></span> | <span class="t">in what kinds of contexts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1279" target="_blank">00:21:19.720</a></span> | <span class="t">The woman walked across the street checking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1284" target="_blank">00:21:24.320</a></span> | <span class="t">for traffic over blank shoulder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1287" target="_blank">00:21:27.000</a></span> | <span class="t">Any ideas on what could go here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1289" target="_blank">00:21:29.520</a></span> | <span class="t">Her, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1290" target="_blank">00:21:30.080</a></span> | <span class="t">So this sort of co-reference between this entity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1295" target="_blank">00:21:35.320</a></span> | <span class="t">who is being discussed in the world, this woman, and her shoulder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1299" target="_blank">00:21:39.040</a></span> | <span class="t">Now, when I discuss--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1300" target="_blank">00:21:40.840</a></span> | <span class="t">this is sort of a linguistic concept.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1302" target="_blank">00:21:42.380</a></span> | <span class="t">Her here is a co-referent to woman.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1304" target="_blank">00:21:44.840</a></span> | <span class="t">It's referring to the same entity in the discourse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1307" target="_blank">00:21:47.240</a></span> | <span class="t">And so the network might be able to learn things about what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1311" target="_blank">00:21:51.400</a></span> | <span class="t">entities are doing what where.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1312" target="_blank">00:21:52.800</a></span> | <span class="t">It can learn things about semantics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1318" target="_blank">00:21:58.480</a></span> | <span class="t">So if I went to the ocean to see the fish, turtles, seals, and blank,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1322" target="_blank">00:22:02.800</a></span> | <span class="t">then the word that's in the blank should be a member of the class</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1326" target="_blank">00:22:06.520</a></span> | <span class="t">that I'm thinking of as a person writing this sentence of stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1329" target="_blank">00:22:09.840</a></span> | <span class="t">that I see when I go to the ocean and see these other things as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1333" target="_blank">00:22:13.860</a></span> | <span class="t">So in order to do this prediction task, maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1335" target="_blank">00:22:15.840</a></span> | <span class="t">I learn about the semantics of aquatic creatures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1342" target="_blank">00:22:22.840</a></span> | <span class="t">OK, so what else could I learn?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1344" target="_blank">00:22:24.580</a></span> | <span class="t">I've got overall, the value I got from the two hours watching it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1347" target="_blank">00:22:27.460</a></span> | <span class="t">was the sum total of the popcorn and drink.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1349" target="_blank">00:22:29.760</a></span> | <span class="t">The movie was blank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1351" target="_blank">00:22:31.920</a></span> | <span class="t">What kind of task could I be learning from doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1353" target="_blank">00:22:33.980</a></span> | <span class="t">this sort of prediction problem?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1357" target="_blank">00:22:37.680</a></span> | <span class="t">Sentiment, exactly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1358" target="_blank">00:22:38.820</a></span> | <span class="t">So this is just a naturalistic sort of text that I naturally wrote myself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1365" target="_blank">00:22:45.800</a></span> | <span class="t">But by saying, oh, the movie was bad, I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1368" target="_blank">00:22:48.920</a></span> | <span class="t">learning about sort of the latent sentiment of the person who</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1373" target="_blank">00:22:53.200</a></span> | <span class="t">wrote this, what they were feeling about the movie at the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1377" target="_blank">00:22:57.080</a></span> | <span class="t">So maybe if I see a new review later on, I can just paste in the review,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1381" target="_blank">00:23:01.240</a></span> | <span class="t">say the movie was blank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1384" target="_blank">00:23:04.400</a></span> | <span class="t">And if the model generates bad or good, that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1387" target="_blank">00:23:07.200</a></span> | <span class="t">could be implicitly solving the task of sentiment analysis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1390" target="_blank">00:23:10.640</a></span> | <span class="t">So here's another one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1394" target="_blank">00:23:14.720</a></span> | <span class="t">Iroh went to the kitchen to make some tea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1396" target="_blank">00:23:16.760</a></span> | <span class="t">Standing next to Iroh, Zuko pondered his destiny.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1399" target="_blank">00:23:19.760</a></span> | <span class="t">Zuko left the blank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1403" target="_blank">00:23:23.160</a></span> | <span class="t">OK, so in this scenario, we've got a world implicitly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1407" target="_blank">00:23:27.120</a></span> | <span class="t">that's been designed by the person who is creating this text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1411" target="_blank">00:23:31.160</a></span> | <span class="t">I've got physical locations in the discourse, like the kitchen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1415" target="_blank">00:23:35.280</a></span> | <span class="t">And I've got Zuko.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1417" target="_blank">00:23:37.160</a></span> | <span class="t">Iroh's in the kitchen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1418" target="_blank">00:23:38.480</a></span> | <span class="t">Zuko's next to Iroh.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1420" target="_blank">00:23:40.680</a></span> | <span class="t">So Zuko must be in the kitchen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1424" target="_blank">00:23:44.080</a></span> | <span class="t">So what could Zuko leave but the kitchen?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1427" target="_blank">00:23:47.120</a></span> | <span class="t">And so in terms of latent notions of embodiment and physical location,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1431" target="_blank">00:23:51.640</a></span> | <span class="t">the way that people talk about people being next to something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1434" target="_blank">00:23:54.760</a></span> | <span class="t">and then leaving something could tell you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1437" target="_blank">00:23:57.800</a></span> | <span class="t">stuff about sort of, yeah, a little bit about how the world works even.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1444" target="_blank">00:24:04.920</a></span> | <span class="t">So here's a sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1446" target="_blank">00:24:06.360</a></span> | <span class="t">I was thinking about the sequence that goes 1, 1, 2, 3, 5, 8, 13, 21, blank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1452" target="_blank">00:24:12.640</a></span> | <span class="t">And this is a pretty tough one, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1458" target="_blank">00:24:18.000</a></span> | <span class="t">This is the Fibonacci sequence, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1459" target="_blank">00:24:19.640</a></span> | <span class="t">If you had to model by looking at a bunch of numbers from the Fibonacci</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1463" target="_blank">00:24:23.120</a></span> | <span class="t">sequence, learn to, in general, predict the next one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1467" target="_blank">00:24:27.160</a></span> | <span class="t">it's a question you should be thinking about throughout the lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1471" target="_blank">00:24:31.920</a></span> | <span class="t">OK, any questions on these sort of examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1474" target="_blank">00:24:34.240</a></span> | <span class="t">of what you might learn from predicting the context?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1476" target="_blank">00:24:36.360</a></span> | <span class="t">OK, OK, cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1484" target="_blank">00:24:44.240</a></span> | <span class="t">So a very simple way to think about pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1487" target="_blank">00:24:47.800</a></span> | <span class="t">is pre-training is language modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1489" target="_blank">00:24:49.340</a></span> | <span class="t">So we saw language modeling earlier in the course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1491" target="_blank">00:24:51.640</a></span> | <span class="t">And now we're just going to say, instead of using my language model just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1495" target="_blank">00:24:55.140</a></span> | <span class="t">to provide probabilities over the next word,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1497" target="_blank">00:24:57.560</a></span> | <span class="t">I am going to train it on that task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1499" target="_blank">00:24:59.600</a></span> | <span class="t">I'm going to actually model the distribution p theta of the word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1506" target="_blank">00:25:06.440</a></span> | <span class="t">t given all the words previous.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1510" target="_blank">00:25:10.080</a></span> | <span class="t">And there's a ton of data for this, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1512" target="_blank">00:25:12.240</a></span> | <span class="t">There's just an amazing amount of data for this in a lot of languages,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1515" target="_blank">00:25:15.720</a></span> | <span class="t">especially English.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1516" target="_blank">00:25:16.800</a></span> | <span class="t">There's very little data for this in actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1518" target="_blank">00:25:18.680</a></span> | <span class="t">most of the world's languages, which is a separate problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1521" target="_blank">00:25:21.920</a></span> | <span class="t">But you can pre-train just through language modeling, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1524" target="_blank">00:25:24.340</a></span> | <span class="t">So I'm going to sort of do the teacher forcing thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1527" target="_blank">00:25:27.160</a></span> | <span class="t">So I have IRO.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1528" target="_blank">00:25:28.080</a></span> | <span class="t">I predict goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1528" target="_blank">00:25:28.880</a></span> | <span class="t">I have goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1529" target="_blank">00:25:29.400</a></span> | <span class="t">I predict to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1530" target="_blank">00:25:30.600</a></span> | <span class="t">And I'm going to train my sort of LSTM or my transformer to do this task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1535" target="_blank">00:25:35.760</a></span> | <span class="t">And then I'm just going to keep all the weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1538" target="_blank">00:25:38.400</a></span> | <span class="t">OK, I'm going to save all the network parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1541" target="_blank">00:25:41.000</a></span> | <span class="t">And then once I have these parameters, instead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1546" target="_blank">00:25:46.340</a></span> | <span class="t">of generating from my language model, I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1548" target="_blank">00:25:48.040</a></span> | <span class="t">just going to use them as an initialization for my parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1552" target="_blank">00:25:52.280</a></span> | <span class="t">So I have this pre-training fine-tuning paradigm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1555" target="_blank">00:25:55.280</a></span> | <span class="t">Two steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1556" target="_blank">00:25:56.640</a></span> | <span class="t">Most of you, I think, in your--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1558" target="_blank">00:25:58.320</a></span> | <span class="t">well, maybe not this year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1559" target="_blank">00:25:59.680</a></span> | <span class="t">Let's say a large portion of you this year in your final projects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1562" target="_blank">00:26:02.440</a></span> | <span class="t">will be doing the pre-training fine-tuning sort of paradigm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1565" target="_blank">00:26:05.160</a></span> | <span class="t">where someone has done the pre-training for you, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1567" target="_blank">00:26:07.460</a></span> | <span class="t">So you have a ton of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1569" target="_blank">00:26:09.100</a></span> | <span class="t">You learn very general things about the distribution of words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1573" target="_blank">00:26:13.080</a></span> | <span class="t">and sort of the latent things that that tells you about the world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1575" target="_blank">00:26:15.940</a></span> | <span class="t">and about language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1577" target="_blank">00:26:17.400</a></span> | <span class="t">And then in step two, you've got some task, maybe sentiment analysis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1582" target="_blank">00:26:22.040</a></span> | <span class="t">And you have maybe not very many labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1584" target="_blank">00:26:24.560</a></span> | <span class="t">You have a little bit of labeled data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1586" target="_blank">00:26:26.720</a></span> | <span class="t">And you adapt the pre-trained model to the task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1589" target="_blank">00:26:29.840</a></span> | <span class="t">that you care about by further doing gradient steps on this task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1594" target="_blank">00:26:34.040</a></span> | <span class="t">So you give it the movie was.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1595" target="_blank">00:26:35.680</a></span> | <span class="t">You predict happy or sad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1597" target="_blank">00:26:37.960</a></span> | <span class="t">And then you sort of continue to update the parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1602" target="_blank">00:26:42.080</a></span> | <span class="t">based on the initialization from the pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1606" target="_blank">00:26:46.240</a></span> | <span class="t">And this just works exceptionally well--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1608" target="_blank">00:26:48.440</a></span> | <span class="t">I mean, unbelievably well-- compared to training from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1611" target="_blank">00:26:51.800</a></span> | <span class="t">Intuitively, because you've taken a lot of the burden of learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1614" target="_blank">00:26:54.760</a></span> | <span class="t">about language, learning about the world, off of the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1618" target="_blank">00:26:58.280</a></span> | <span class="t">that you've labeled for sentiment analysis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1620" target="_blank">00:27:00.400</a></span> | <span class="t">And you're sort of giving that task of learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1622" target="_blank">00:27:02.560</a></span> | <span class="t">all this sort of very general stuff to the much more general task of language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1626" target="_blank">00:27:06.400</a></span> | <span class="t">modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1626" target="_blank">00:27:06.960</a></span> | <span class="t">Yes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1627" target="_blank">00:27:07.460</a></span> | <span class="t">You said we didn't have much data in other languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1630" target="_blank">00:27:10.880</a></span> | <span class="t">What do you mean by data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1631" target="_blank">00:27:11.920</a></span> | <span class="t">Is it just text in that language?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1633" target="_blank">00:27:13.960</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1634" target="_blank">00:27:14.460</a></span> | <span class="t">Or is it labeled in some way?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1636" target="_blank">00:27:16.600</a></span> | <span class="t">The question is, you said we have a lot of data in English,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1639" target="_blank">00:27:19.720</a></span> | <span class="t">but not in other languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1642" target="_blank">00:27:22.320</a></span> | <span class="t">What do you mean by data that we don't have a lot of in other languages?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1645" target="_blank">00:27:25.280</a></span> | <span class="t">Is it just text?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1645" target="_blank">00:27:25.980</a></span> | <span class="t">It's literally just text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1648" target="_blank">00:27:28.320</a></span> | <span class="t">No annotations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1649" target="_blank">00:27:29.960</a></span> | <span class="t">Because you don't need annotations to do language model pre-training, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1653" target="_blank">00:27:33.240</a></span> | <span class="t">The existence of that sequence of words that someone has written</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1657" target="_blank">00:27:37.280</a></span> | <span class="t">provides you with all these pairs of input and output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1661" target="_blank">00:27:41.040</a></span> | <span class="t">Input IRO, output goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1662" target="_blank">00:27:42.680</a></span> | <span class="t">Input IRO goes, output too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1664" target="_blank">00:27:44.800</a></span> | <span class="t">Those are all labels sort of that you've constructed from the input just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1668" target="_blank">00:27:48.840</a></span> | <span class="t">existing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1669" target="_blank">00:27:49.520</a></span> | <span class="t">But in most languages, even on the entire internet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1672" target="_blank">00:27:52.840</a></span> | <span class="t">I mean, there's about 7,000-ish languages on Earth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1675" target="_blank">00:27:55.960</a></span> | <span class="t">And most of them don't have the sort of billions of words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1681" target="_blank">00:28:01.200</a></span> | <span class="t">you might want to train these systems on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1684" target="_blank">00:28:04.760</a></span> | <span class="t">Yeah?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1686" target="_blank">00:28:06.680</a></span> | <span class="t">If you're pre-training the entire thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1688" target="_blank">00:28:08.320</a></span> | <span class="t">are you still learning one vector representation per word?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1691" target="_blank">00:28:11.480</a></span> | <span class="t">The question is, if you're pre-training the entire thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1693" target="_blank">00:28:13.800</a></span> | <span class="t">do you still learn one vector representation per word?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1696" target="_blank">00:28:16.120</a></span> | <span class="t">You learn one vector representation that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1697" target="_blank">00:28:17.940</a></span> | <span class="t">is the non-contextual input vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1701" target="_blank">00:28:21.280</a></span> | <span class="t">So you have your vocabulary matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1703" target="_blank">00:28:23.000</a></span> | <span class="t">You've got your embedding matrix that is vocabulary size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1706" target="_blank">00:28:26.240</a></span> | <span class="t">by model dimensionality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1708" target="_blank">00:28:28.920</a></span> | <span class="t">And so yeah, IRO has one vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1710" target="_blank">00:28:30.720</a></span> | <span class="t">GOES has one vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1712" target="_blank">00:28:32.680</a></span> | <span class="t">But then the transformer that you're learning on top of it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1715" target="_blank">00:28:35.520</a></span> | <span class="t">takes in the sequence so far and sort of gives a vector to each of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1719" target="_blank">00:28:39.440</a></span> | <span class="t">that's dependent on the context in that case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1721" target="_blank">00:28:41.760</a></span> | <span class="t">But still, at the input, you only have one embedding per word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1726" target="_blank">00:28:46.000</a></span> | <span class="t">Yeah?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1726" target="_blank">00:28:46.500</a></span> | <span class="t">So what sort of metrics would you use to evaluate a pre-trained model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1731" target="_blank">00:28:51.740</a></span> | <span class="t">It's supposed to be general.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1733" target="_blank">00:28:53.900</a></span> | <span class="t">But there's application-specific metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1735" target="_blank">00:28:55.660</a></span> | <span class="t">So which one do you use?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1736" target="_blank">00:28:56.860</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1737" target="_blank">00:28:57.340</a></span> | <span class="t">So the question is, what metric do you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1738" target="_blank">00:28:58.700</a></span> | <span class="t">use to evaluate pre-trained models since it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1740" target="_blank">00:29:00.620</a></span> | <span class="t">supposed to be so general?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1742" target="_blank">00:29:02.740</a></span> | <span class="t">But there are lots of very specific evaluations you could use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1747" target="_blank">00:29:07.300</a></span> | <span class="t">We'll get into a lot of that in the rest of the lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1749" target="_blank">00:29:09.940</a></span> | <span class="t">While you're training it, you can use simple metrics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1752" target="_blank">00:29:12.220</a></span> | <span class="t">that sort of correlate with what you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1753" target="_blank">00:29:13.900</a></span> | <span class="t">but aren't actually what you want, just like the probability quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1758" target="_blank">00:29:18.340</a></span> | <span class="t">So you can evaluate the perplexity of your language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1761" target="_blank">00:29:21.180</a></span> | <span class="t">just like you would have when you cared about language modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1763" target="_blank">00:29:23.760</a></span> | <span class="t">And it turns out to be the case that better perplexity correlates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1767" target="_blank">00:29:27.460</a></span> | <span class="t">with all the stuff that's much harder to evaluate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1770" target="_blank">00:29:30.080</a></span> | <span class="t">like lots and lots of different tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1772" target="_blank">00:29:32.420</a></span> | <span class="t">But also, the natural language processing community</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1774" target="_blank">00:29:34.460</a></span> | <span class="t">has built very large sort of benchmark suites of varying tasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1779" target="_blank">00:29:39.520</a></span> | <span class="t">to try to get at sort of a notion of generality,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1781" target="_blank">00:29:41.780</a></span> | <span class="t">although that's very, very difficult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1783" target="_blank">00:29:43.460</a></span> | <span class="t">It's sort of ill-defined, even.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1785" target="_blank">00:29:45.540</a></span> | <span class="t">And so when you develop new pre-training methods, what you often do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1788" target="_blank">00:29:48.820</a></span> | <span class="t">is you try to pick a whole bunch of evaluations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1791" target="_blank">00:29:51.260</a></span> | <span class="t">and show that you do better on all of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1793" target="_blank">00:29:53.700</a></span> | <span class="t">And that's your argument for generality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1795" target="_blank">00:29:55.660</a></span> | <span class="t">So why should this sort of pre-training, fine-tuning, two-part paradigm help?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1806" target="_blank">00:30:06.740</a></span> | <span class="t">This is still an open area of research, but the intuitions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1810" target="_blank">00:30:10.380</a></span> | <span class="t">are all you're going to take from this course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1812" target="_blank">00:30:12.500</a></span> | <span class="t">So pre-training provides some sort of starting parameters, L theta.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1817" target="_blank">00:30:17.500</a></span> | <span class="t">So this is like all the parameters in your network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1820" target="_blank">00:30:20.140</a></span> | <span class="t">from trying to do this minimum over all possible settings of your parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1824" target="_blank">00:30:24.300</a></span> | <span class="t">of the pre-training loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1826" target="_blank">00:30:26.900</a></span> | <span class="t">And then the fine-tuning process takes your data for fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1831" target="_blank">00:30:31.220</a></span> | <span class="t">You've got some labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1832" target="_blank">00:30:32.580</a></span> | <span class="t">And it tries to approximate the minimum through gradient descent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1836" target="_blank">00:30:36.380</a></span> | <span class="t">of the loss of the fine-tuning task of theta.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1839" target="_blank">00:30:39.140</a></span> | <span class="t">But you start at theta hat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1841" target="_blank">00:30:41.340</a></span> | <span class="t">So you start gradient descent at theta hat,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1843" target="_blank">00:30:43.820</a></span> | <span class="t">which your pre-training process gave you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1846" target="_blank">00:30:46.420</a></span> | <span class="t">And then if you could actually solve this min and wanted to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1851" target="_blank">00:30:51.900</a></span> | <span class="t">it sort of feels like the starting point shouldn't matter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1855" target="_blank">00:30:55.700</a></span> | <span class="t">But it really, really, really does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1858" target="_blank">00:30:58.140</a></span> | <span class="t">It really does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1860" target="_blank">00:31:00.940</a></span> | <span class="t">So we'll talk a bit more about this later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1863" target="_blank">00:31:03.900</a></span> | <span class="t">But the process of gradient descent, maybe it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1867" target="_blank">00:31:07.660</a></span> | <span class="t">sticks relatively close to the theta hat during fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1871" target="_blank">00:31:11.700</a></span> | <span class="t">So you start at theta hat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1874" target="_blank">00:31:14.620</a></span> | <span class="t">And then you sort of walk downhill with gradient descent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1877" target="_blank">00:31:17.500</a></span> | <span class="t">until you hit sort of a valley.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1879" target="_blank">00:31:19.380</a></span> | <span class="t">And that valley ends up being really good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1881" target="_blank">00:31:21.620</a></span> | <span class="t">because it's close to the pre-training parameters, which were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1884" target="_blank">00:31:24.260</a></span> | <span class="t">really good for a lot of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1886" target="_blank">00:31:26.060</a></span> | <span class="t">This is a cool place where sort of practice and theory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1889" target="_blank">00:31:29.300</a></span> | <span class="t">are sort of like meeting, where optimization people want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1891" target="_blank">00:31:31.940</a></span> | <span class="t">to understand why this is so useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1894" target="_blank">00:31:34.700</a></span> | <span class="t">NLP people sort of just want to build better systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1899" target="_blank">00:31:39.060</a></span> | <span class="t">So yeah, maybe the stuff around theta hat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1903" target="_blank">00:31:43.140</a></span> | <span class="t">tends to generalize well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1904" target="_blank">00:31:44.460</a></span> | <span class="t">If you want to work on this kind of thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1906" target="_blank">00:31:46.220</a></span> | <span class="t">you should talk about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1907" target="_blank">00:31:47.220</a></span> | <span class="t">Yeah?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1908" target="_blank">00:31:48.220</a></span> | <span class="t">So if stochastic gradient descent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1910" target="_blank">00:31:50.220</a></span> | <span class="t">sticks relatively close, but what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1911" target="_blank">00:31:51.980</a></span> | <span class="t">if we were to use a different optimizer?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1913" target="_blank">00:31:53.740</a></span> | <span class="t">How would that change our results?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1916" target="_blank">00:31:56.180</a></span> | <span class="t">The question is, if stochastic gradient descent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1919" target="_blank">00:31:59.180</a></span> | <span class="t">sticks relatively close, what if we use a different optimizer?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1921" target="_blank">00:32:01.780</a></span> | <span class="t">I mean, if we use sort of any common variant of gradient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1925" target="_blank">00:32:05.020</a></span> | <span class="t">descent, like any first order method,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1927" target="_blank">00:32:07.100</a></span> | <span class="t">like Adam, which we use in this course, or AdaGrad,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1930" target="_blank">00:32:10.420</a></span> | <span class="t">or they all have this very, very similar properties.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1934" target="_blank">00:32:14.860</a></span> | <span class="t">Other types of optimization we just tend to not use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1937" target="_blank">00:32:17.660</a></span> | <span class="t">So who knows?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1939" target="_blank">00:32:19.460</a></span> | <span class="t">Yeah?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1939" target="_blank">00:32:19.960</a></span> | <span class="t">Yeah, I'm still a little unclear on why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1941" target="_blank">00:32:21.700</a></span> | <span class="t">the pre-training plus fine tuning works better than just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1945" target="_blank">00:32:25.060</a></span> | <span class="t">fine tuning, but making the model more powerful,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1947" target="_blank">00:32:27.180</a></span> | <span class="t">like adding more layers, more data, et cetera.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1949" target="_blank">00:32:29.580</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1950" target="_blank">00:32:30.300</a></span> | <span class="t">The question is, why does the pre-trained fine tune paradigm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1953" target="_blank">00:32:33.540</a></span> | <span class="t">work better than just making the model more powerful,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1956" target="_blank">00:32:36.580</a></span> | <span class="t">adding more layers, adding more data to just the fine tuning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1959" target="_blank">00:32:39.180</a></span> | <span class="t">The simple answer is that you have orders of magnitude</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1965" target="_blank">00:32:45.860</a></span> | <span class="t">more data that's unlabeled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1968" target="_blank">00:32:48.500</a></span> | <span class="t">That's just text that you found.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1971" target="_blank">00:32:51.860</a></span> | <span class="t">Then you do carefully labeled data and the tasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1974" target="_blank">00:32:54.460</a></span> | <span class="t">that you care about, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1975" target="_blank">00:32:55.540</a></span> | <span class="t">Because that's expensive to get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1977" target="_blank">00:32:57.140</a></span> | <span class="t">It has to be examples of your movie reviews</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1979" target="_blank">00:32:59.660</a></span> | <span class="t">or whatever that you've had someone label carefully.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1983" target="_blank">00:33:03.220</a></span> | <span class="t">So you have something like on the internet at least 5</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1989" target="_blank">00:33:09.460</a></span> | <span class="t">trillion, maybe 10 trillion words of this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1993" target="_blank">00:33:13.020</a></span> | <span class="t">and you have maybe a million words of your labeled data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1996" target="_blank">00:33:16.620</a></span> | <span class="t">or whatever over here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=1997" target="_blank">00:33:17.860</a></span> | <span class="t">So it's just the scale is way off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2001" target="_blank">00:33:21.460</a></span> | <span class="t">But there's also an intuition that learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2004" target="_blank">00:33:24.260</a></span> | <span class="t">to do a very, very simple thing like sentiment analysis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2008" target="_blank">00:33:28.180</a></span> | <span class="t">is not going to get you a very generally able agent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2014" target="_blank">00:33:34.940</a></span> | <span class="t">in a wide range of settings compared to language modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2018" target="_blank">00:33:38.940</a></span> | <span class="t">So it's hard to get--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2020" target="_blank">00:33:40.900</a></span> | <span class="t">how do I put it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2022" target="_blank">00:33:42.180</a></span> | <span class="t">Even if you have a lot of labeled data of movie reviews</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2025" target="_blank">00:33:45.020</a></span> | <span class="t">of the kind that people are writing today, maybe tomorrow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2029" target="_blank">00:33:49.260</a></span> | <span class="t">they start writing slightly different kinds of movie</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2031" target="_blank">00:33:51.380</a></span> | <span class="t">reviews, and your system doesn't perform as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2033" target="_blank">00:33:53.660</a></span> | <span class="t">Whereas if you pre-trained on a really diverse set of text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2036" target="_blank">00:33:56.700</a></span> | <span class="t">from a wide range of sources and people,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2038" target="_blank">00:33:58.900</a></span> | <span class="t">it might be more adaptable to seeing stuff that doesn't quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2043" target="_blank">00:34:03.260</a></span> | <span class="t">look like the training data you showed it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2045" target="_blank">00:34:05.060</a></span> | <span class="t">even if you showed it a ton of training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2047" target="_blank">00:34:07.580</a></span> | <span class="t">So one of the big takeaways of pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2050" target="_blank">00:34:10.420</a></span> | <span class="t">is that you get this huge amount of variety of text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2054" target="_blank">00:34:14.980</a></span> | <span class="t">on the internet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2055" target="_blank">00:34:15.660</a></span> | <span class="t">And you have to be very careful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2057" target="_blank">00:34:17.100</a></span> | <span class="t">I mean, yeah, you should be very careful about what kind of text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2060" target="_blank">00:34:20.220</a></span> | <span class="t">you're showing it and what kind of text you're not,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2062" target="_blank">00:34:22.460</a></span> | <span class="t">because the internet is full of awful text as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2067" target="_blank">00:34:27.780</a></span> | <span class="t">But some of that generality just comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2069" target="_blank">00:34:29.660</a></span> | <span class="t">from how hard this problem is and how much data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2071" target="_blank">00:34:31.940</a></span> | <span class="t">you can show it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2073" target="_blank">00:34:33.940</a></span> | <span class="t">[INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2074" target="_blank">00:34:34.420</a></span> | <span class="t">--pre-trained model was trained on so much data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2077" target="_blank">00:34:37.780</a></span> | <span class="t">How do you then train it so that it considers the stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2082" target="_blank">00:34:42.140</a></span> | <span class="t">that you're fine-tuning it with as more important, more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2084" target="_blank">00:34:44.660</a></span> | <span class="t">salient to the task it's trying to do,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2086" target="_blank">00:34:46.660</a></span> | <span class="t">rather than just one in a billion articles of data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2090" target="_blank">00:34:50.580</a></span> | <span class="t">Yeah, it's a good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2091" target="_blank">00:34:51.900</a></span> | <span class="t">So the question is, given that the amount of data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2094" target="_blank">00:34:54.380</a></span> | <span class="t">on the pre-training side is orders of magnitude</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2096" target="_blank">00:34:56.340</a></span> | <span class="t">more than the amount of data on the fine-tuning side,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2098" target="_blank">00:34:58.540</a></span> | <span class="t">how do you get across to the model that, OK, actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2101" target="_blank">00:35:01.220</a></span> | <span class="t">the fine-tuning task is what I care about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2103" target="_blank">00:35:03.140</a></span> | <span class="t">So focus on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2104" target="_blank">00:35:04.940</a></span> | <span class="t">It's about the fact that I did this first,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2107" target="_blank">00:35:07.220</a></span> | <span class="t">the pre-training first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2108" target="_blank">00:35:08.540</a></span> | <span class="t">And then I do the fine-tuning second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2111" target="_blank">00:35:11.900</a></span> | <span class="t">So I've gotten my parameter initialization from this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2114" target="_blank">00:35:14.780</a></span> | <span class="t">I've set it somewhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2116" target="_blank">00:35:16.100</a></span> | <span class="t">And then I fine-tune.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2117" target="_blank">00:35:17.620</a></span> | <span class="t">I move to where the parameters are doing well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2120" target="_blank">00:35:20.100</a></span> | <span class="t">for this task afterward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2122" target="_blank">00:35:22.220</a></span> | <span class="t">And so, well, it might just forget a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2125" target="_blank">00:35:25.060</a></span> | <span class="t">about how to do this, because now I'm just asking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2127" target="_blank">00:35:27.540</a></span> | <span class="t">it to do this at this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2130" target="_blank">00:35:30.820</a></span> | <span class="t">I should move on, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2132" target="_blank">00:35:32.940</a></span> | <span class="t">But we're going to keep talking about this in much more detail</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2136" target="_blank">00:35:36.060</a></span> | <span class="t">with more concrete elements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2138" target="_blank">00:35:38.180</a></span> | <span class="t">So OK, so let's talk about model pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2144" target="_blank">00:35:44.980</a></span> | <span class="t">Oh, wait.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2147" target="_blank">00:35:47.140</a></span> | <span class="t">That did not advance the slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2149" target="_blank">00:35:49.100</a></span> | <span class="t">Nice, OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2155" target="_blank">00:35:55.140</a></span> | <span class="t">Let's talk about model pre-training three ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2158" target="_blank">00:35:58.020</a></span> | <span class="t">In our Transformers lecture Tuesday,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2161" target="_blank">00:36:01.660</a></span> | <span class="t">we talked about encoders, encoder decoders, and decoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2164" target="_blank">00:36:04.980</a></span> | <span class="t">And we'll do decoders last, because actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2168" target="_blank">00:36:08.580</a></span> | <span class="t">many of the largest models that are being used today</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2172" target="_blank">00:36:12.140</a></span> | <span class="t">are all decoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2174" target="_blank">00:36:14.180</a></span> | <span class="t">And so we'll have a bit more to say about them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2177" target="_blank">00:36:17.260</a></span> | <span class="t">So let's recall these three.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2179" target="_blank">00:36:19.340</a></span> | <span class="t">So encoders get bidirectional context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2181" target="_blank">00:36:21.540</a></span> | <span class="t">You have a single sequence, and you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2183" target="_blank">00:36:23.700</a></span> | <span class="t">able to see the whole thing, kind of like an encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2185" target="_blank">00:36:25.940</a></span> | <span class="t">in machine translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2188" target="_blank">00:36:28.100</a></span> | <span class="t">Encoder decoders have one portion of the network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2192" target="_blank">00:36:32.340</a></span> | <span class="t">that gets bidirectional context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2194" target="_blank">00:36:34.140</a></span> | <span class="t">So that's like the source sentence of my machine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2196" target="_blank">00:36:36.620</a></span> | <span class="t">translation system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2197" target="_blank">00:36:37.900</a></span> | <span class="t">And then they're sort of paired with a decoder that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2200" target="_blank">00:36:40.540</a></span> | <span class="t">gets unidirectional context, so that I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2202" target="_blank">00:36:42.420</a></span> | <span class="t">have this sort of informational masking where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2205" target="_blank">00:36:45.420</a></span> | <span class="t">I can't see the future, so that I can do things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2207" target="_blank">00:36:47.460</a></span> | <span class="t">like language modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2208" target="_blank">00:36:48.500</a></span> | <span class="t">I can generate the next token of my translation, whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2211" target="_blank">00:36:51.260</a></span> | <span class="t">So you could think of it as I've got my source sentence here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2214" target="_blank">00:36:54.820</a></span> | <span class="t">and my partial translation here, and I'm sort of decoding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2217" target="_blank">00:36:57.260</a></span> | <span class="t">out the translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2219" target="_blank">00:36:59.180</a></span> | <span class="t">And then decoders only are things like language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2222" target="_blank">00:37:02.060</a></span> | <span class="t">We've seen a lot of this so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2223" target="_blank">00:37:03.540</a></span> | <span class="t">And there's pre-training for all three sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2225" target="_blank">00:37:05.580</a></span> | <span class="t">of large classes of models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2229" target="_blank">00:37:09.100</a></span> | <span class="t">And how you pre-train them and then how you use them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2231" target="_blank">00:37:11.380</a></span> | <span class="t">depends on the properties and the proactivities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2234" target="_blank">00:37:14.260</a></span> | <span class="t">of the specific architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2235" target="_blank">00:37:15.740</a></span> | <span class="t">So let's look at encoders first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2238" target="_blank">00:37:18.740</a></span> | <span class="t">So we've looked at language modeling quite a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2241" target="_blank">00:37:21.460</a></span> | <span class="t">But we can't do language modeling with an encoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2244" target="_blank">00:37:24.100</a></span> | <span class="t">because they get bidirectional context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2246" target="_blank">00:37:26.620</a></span> | <span class="t">So if I'm down here at i, and I want to present--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2251" target="_blank">00:37:31.100</a></span> | <span class="t">I want to predict the next word, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2253" target="_blank">00:37:33.460</a></span> | <span class="t">a trivial task at this level here to predict the next word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2258" target="_blank">00:37:38.020</a></span> | <span class="t">Because in the middle, I was able to look at the next word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2261" target="_blank">00:37:41.900</a></span> | <span class="t">And so I should just know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2263" target="_blank">00:37:43.060</a></span> | <span class="t">There's nothing hard about learning to predict the next word here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2265" target="_blank">00:37:45.560</a></span> | <span class="t">because I could just look at it, see what it is, and then copy it over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2269" target="_blank">00:37:49.380</a></span> | <span class="t">So when I'm training an encoder in something for pre-training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2274" target="_blank">00:37:54.720</a></span> | <span class="t">I have to be a little bit more clever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2277" target="_blank">00:37:57.380</a></span> | <span class="t">In practice, what I do is something like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2279" target="_blank">00:37:59.900</a></span> | <span class="t">I take the input, and I modify it somewhat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2282" target="_blank">00:38:02.100</a></span> | <span class="t">I mask out words, sort of like I did in the examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2284" target="_blank">00:38:04.620</a></span> | <span class="t">I gave at the beginning of class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2286" target="_blank">00:38:06.020</a></span> | <span class="t">So I blank to the blank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2289" target="_blank">00:38:09.260</a></span> | <span class="t">And then I have the network predict with its whole--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2292" target="_blank">00:38:12.980</a></span> | <span class="t">I have it build contextual representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2295" target="_blank">00:38:15.340</a></span> | <span class="t">So now this vector representation of the blank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2298" target="_blank">00:38:18.060</a></span> | <span class="t">sees the entire context around it here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2302" target="_blank">00:38:22.340</a></span> | <span class="t">And then I predict the word "went," and then here, the word "store."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2309" target="_blank">00:38:29.340</a></span> | <span class="t">Any questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2314" target="_blank">00:38:34.460</a></span> | <span class="t">And you can see how this is doing something quite a bit like language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2317" target="_blank">00:38:37.940</a></span> | <span class="t">modeling, but with bidirectional context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2321" target="_blank">00:38:41.180</a></span> | <span class="t">I've removed the network's information about the words that go in the blanks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2325" target="_blank">00:38:45.340</a></span> | <span class="t">and I'm training it to reconstruct that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2327" target="_blank">00:38:47.740</a></span> | <span class="t">So I only have loss terms, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2329" target="_blank">00:38:49.620</a></span> | <span class="t">I only ask it to actually do the prediction, compute the loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2332" target="_blank">00:38:52.780</a></span> | <span class="t">backpropagate the gradients for the words that I've masked out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2336" target="_blank">00:38:56.580</a></span> | <span class="t">And you can think of this as instead of learning probability of x,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2340" target="_blank">00:39:00.580</a></span> | <span class="t">where x is like a sentence or a document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2343" target="_blank">00:39:03.140</a></span> | <span class="t">this is learning the probability of x, the real document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2346" target="_blank">00:39:06.300</a></span> | <span class="t">given x tilde, which is this sort of corrupted document,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2351" target="_blank">00:39:11.420</a></span> | <span class="t">with some of the information missing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2354" target="_blank">00:39:14.940</a></span> | <span class="t">And so we get the sequence of vectors here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2357" target="_blank">00:39:17.780</a></span> | <span class="t">one per word, which is the output of my encoder in blue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2361" target="_blank">00:39:21.380</a></span> | <span class="t">And then I'd say that for the words that I want to predict, yi, I draw them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2365" target="_blank">00:39:25.700</a></span> | <span class="t">This is the sim means the probability is proportional to my embedding matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2372" target="_blank">00:39:32.940</a></span> | <span class="t">times my representation of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2376" target="_blank">00:39:36.500</a></span> | <span class="t">So it's just a linear transformation of that last thing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2378" target="_blank">00:39:38.980</a></span> | <span class="t">So this a plus b is this red portion here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2381" target="_blank">00:39:41.860</a></span> | <span class="t">And I do the prediction, and I train the entire network to do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2384" target="_blank">00:39:44.820</a></span> | <span class="t">Yes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2387" target="_blank">00:39:47.020</a></span> | <span class="t">So the words that we mask out, do we just select them randomly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2391" target="_blank">00:39:51.900</a></span> | <span class="t">or is there some scheme to it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2394" target="_blank">00:39:54.260</a></span> | <span class="t">The question is, do we just choose words randomly to mask out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2397" target="_blank">00:39:57.100</a></span> | <span class="t">or is there a scheme?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2398" target="_blank">00:39:58.380</a></span> | <span class="t">Mostly randomly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2399" target="_blank">00:39:59.380</a></span> | <span class="t">We'll talk about a slightly smarter scheme in a couple of slides,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2402" target="_blank">00:40:02.140</a></span> | <span class="t">but yeah, just mostly randomly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2405" target="_blank">00:40:05.500</a></span> | <span class="t">Yeah?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2407" target="_blank">00:40:07.020</a></span> | <span class="t">What was that last part on the bottom, x, the masked version of--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2411" target="_blank">00:40:11.460</a></span> | <span class="t">like, if it's the first or the very last sentence?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2416" target="_blank">00:40:16.580</a></span> | <span class="t">Yeah, so I'm saying that I'm defining x tilde to be this input part, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2423" target="_blank">00:40:23.100</a></span> | <span class="t">I've got the masked version of the sentence with these words missing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2426" target="_blank">00:40:26.820</a></span> | <span class="t">And then I'm defining a probability distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2429" target="_blank">00:40:29.060</a></span> | <span class="t">that's the probability of a sequence conditioned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2432" target="_blank">00:40:32.340</a></span> | <span class="t">on the input being the corrupted sequence, the masked sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2435" target="_blank">00:40:35.940</a></span> | <span class="t">So this brings us to a very, very popular NLP model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2447" target="_blank">00:40:47.300</a></span> | <span class="t">that you need to know about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2448" target="_blank">00:40:48.460</a></span> | <span class="t">It's called BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2449" target="_blank">00:40:49.940</a></span> | <span class="t">And it was the first one to popularize this masked language modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2453" target="_blank">00:40:53.500</a></span> | <span class="t">objective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2455" target="_blank">00:40:55.300</a></span> | <span class="t">And they released the weights of this pre-trained transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2458" target="_blank">00:40:58.420</a></span> | <span class="t">that they pre-trained via something that looks a lot like masked language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2461" target="_blank">00:41:01.380</a></span> | <span class="t">modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2461" target="_blank">00:41:01.900</a></span> | <span class="t">And so these you can download.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2463" target="_blank">00:41:03.780</a></span> | <span class="t">You can use them via code that's released by the company HuggingFace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2467" target="_blank">00:41:07.660</a></span> | <span class="t">that we have continued to bring up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2470" target="_blank">00:41:10.300</a></span> | <span class="t">Many of you will use a model like BERT in your final project</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2473" target="_blank">00:41:13.700</a></span> | <span class="t">because it's such a useful builder of representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2476" target="_blank">00:41:16.500</a></span> | <span class="t">of language and context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2478" target="_blank">00:41:18.340</a></span> | <span class="t">So let's talk a little bit about the details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2480" target="_blank">00:41:20.140</a></span> | <span class="t">of masked language modeling in BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2483" target="_blank">00:41:23.260</a></span> | <span class="t">First, we take 15% of the subword tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2487" target="_blank">00:41:27.020</a></span> | <span class="t">So remember, all of our inputs now are subword tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2490" target="_blank">00:41:30.460</a></span> | <span class="t">I've made them all look like words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2492" target="_blank">00:41:32.500</a></span> | <span class="t">But just like we saw at the very beginning of class,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2494" target="_blank">00:41:34.620</a></span> | <span class="t">each of these tokens could just be some portion, some subword.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2498" target="_blank">00:41:38.940</a></span> | <span class="t">And I'm going to do a couple of things with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2500" target="_blank">00:41:40.900</a></span> | <span class="t">Sometimes I am going to just mask out the word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2505" target="_blank">00:41:45.860</a></span> | <span class="t">and then predict the true word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2508" target="_blank">00:41:48.220</a></span> | <span class="t">Sometimes I'm going to replace the word with some random sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2513" target="_blank">00:41:53.260</a></span> | <span class="t">of another word from my vocabulary and predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2516" target="_blank">00:41:56.700</a></span> | <span class="t">the real word that was supposed to go there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2518" target="_blank">00:41:58.780</a></span> | <span class="t">And sometimes I'm going to not change the word at all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2522" target="_blank">00:42:02.780</a></span> | <span class="t">and still predict it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2524" target="_blank">00:42:04.300</a></span> | <span class="t">The intuition of this is the following.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2527" target="_blank">00:42:07.340</a></span> | <span class="t">If I just had to build good representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2531" target="_blank">00:42:11.820</a></span> | <span class="t">in the middle of this network for words that are masked out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2535" target="_blank">00:42:15.940</a></span> | <span class="t">then when I actually use the model at test time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2539" target="_blank">00:42:19.220</a></span> | <span class="t">on some real review to do sentiment analysis on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2542" target="_blank">00:42:22.820</a></span> | <span class="t">well, there are never going to be any tokens like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2545" target="_blank">00:42:25.340</a></span> | <span class="t">So maybe the model won't do a very good job</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2547" target="_blank">00:42:27.300</a></span> | <span class="t">because it's like, oh, I have no job to do here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2549" target="_blank">00:42:29.780</a></span> | <span class="t">because I only need to deal with the mask tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2553" target="_blank">00:42:33.540</a></span> | <span class="t">By giving it sequences of words where sometimes it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2556" target="_blank">00:42:36.660</a></span> | <span class="t">the real word that needs to be predicted,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2558" target="_blank">00:42:38.420</a></span> | <span class="t">sometimes you have to detect if the word is wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2561" target="_blank">00:42:41.300</a></span> | <span class="t">The idea is that now when I give it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2563" target="_blank">00:42:43.100</a></span> | <span class="t">a sentence that doesn't have any masks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2566" target="_blank">00:42:46.660</a></span> | <span class="t">it actually does a good job of representing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2568" target="_blank">00:42:48.660</a></span> | <span class="t">all the words in context because it has this chance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2571" target="_blank">00:42:51.660</a></span> | <span class="t">that it could be asked to predict anything at any time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2574" target="_blank">00:42:54.120</a></span> | <span class="t">OK, so the folks at Google who were defining this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2583" target="_blank">00:43:03.980</a></span> | <span class="t">had a separate additional task that is sort of interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2589" target="_blank">00:43:09.100</a></span> | <span class="t">to think about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2590" target="_blank">00:43:10.780</a></span> | <span class="t">So this was their BERT model from their paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2593" target="_blank">00:43:13.340</a></span> | <span class="t">They had their position embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2594" target="_blank">00:43:14.760</a></span> | <span class="t">just like we saw from our transformers lecture,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2598" target="_blank">00:43:18.180</a></span> | <span class="t">token embeddings just like we saw from the transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2600" target="_blank">00:43:20.500</a></span> | <span class="t">lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2601" target="_blank">00:43:21.620</a></span> | <span class="t">But then also they had this thing called a segment embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2603" target="_blank">00:43:23.980</a></span> | <span class="t">where they had two possible segments, segment A</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2606" target="_blank">00:43:26.380</a></span> | <span class="t">and segment B. And they had this additional task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2611" target="_blank">00:43:31.820</a></span> | <span class="t">where they would get a big chunk of text for segment A</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2614" target="_blank">00:43:34.780</a></span> | <span class="t">and a big chunk of text for segment B.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2617" target="_blank">00:43:37.220</a></span> | <span class="t">And then they would ask the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2618" target="_blank">00:43:38.780</a></span> | <span class="t">is segment B a real continuation of segment A?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2623" target="_blank">00:43:43.140</a></span> | <span class="t">Was it the text that actually came next?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2625" target="_blank">00:43:45.780</a></span> | <span class="t">Or did I just pick this big segment randomly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2628" target="_blank">00:43:48.100</a></span> | <span class="t">from somewhere else?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2629" target="_blank">00:43:49.660</a></span> | <span class="t">And the idea was that this should teach the network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2632" target="_blank">00:43:52.180</a></span> | <span class="t">some notion of long distance coherence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2635" target="_blank">00:43:55.460</a></span> | <span class="t">about the connection between a bunch of text over here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2638" target="_blank">00:43:58.420</a></span> | <span class="t">and a bunch of text over there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2640" target="_blank">00:44:00.180</a></span> | <span class="t">Turns out it's not really necessary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2641" target="_blank">00:44:01.740</a></span> | <span class="t">but it's an interesting idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2644" target="_blank">00:44:04.940</a></span> | <span class="t">And similar things have continued</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2646" target="_blank">00:44:06.880</a></span> | <span class="t">to have some sort of influence since then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2649" target="_blank">00:44:09.980</a></span> | <span class="t">But again, you should get this intuition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2652" target="_blank">00:44:12.060</a></span> | <span class="t">that we're trying to come up with hard problems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2654" target="_blank">00:44:14.100</a></span> | <span class="t">for the network to solve such that by solving them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2656" target="_blank">00:44:16.780</a></span> | <span class="t">it has to learn a lot about language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2659" target="_blank">00:44:19.460</a></span> | <span class="t">And we're defining those problems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2661" target="_blank">00:44:21.580</a></span> | <span class="t">by making simple transformations or removing information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2665" target="_blank">00:44:25.060</a></span> | <span class="t">from text that just happened to occur.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2666" target="_blank">00:44:26.860</a></span> | <span class="t">Questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2672" target="_blank">00:44:32.580</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2673" target="_blank">00:44:33.080</a></span> | <span class="t">The plus signs, do we concatenate the vectors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2675" target="_blank">00:44:35.500</a></span> | <span class="t">or do we do an element-wise addition?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2678" target="_blank">00:44:38.420</a></span> | <span class="t">The question is, for these plus signs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2680" target="_blank">00:44:40.020</a></span> | <span class="t">do we concatenate the vectors or do element-wise addition?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2683" target="_blank">00:44:43.140</a></span> | <span class="t">We do element-wise addition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2685" target="_blank">00:44:45.940</a></span> | <span class="t">You could have concatenated them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2688" target="_blank">00:44:48.180</a></span> | <span class="t">However, one of the big conventions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2690" target="_blank">00:44:50.660</a></span> | <span class="t">of all of these networks is that you always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2692" target="_blank">00:44:52.420</a></span> | <span class="t">have exactly the same number of dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2694" target="_blank">00:44:54.980</a></span> | <span class="t">everywhere at every layer of the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2696" target="_blank">00:44:56.660</a></span> | <span class="t">It just makes everything very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2698" target="_blank">00:44:58.420</a></span> | <span class="t">So just saying everything's the same dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2700" target="_blank">00:45:00.300</a></span> | <span class="t">and then doing addition just ends up being simpler.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2703" target="_blank">00:45:03.980</a></span> | <span class="t">So why was the next sentence prediction not necessary?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2709" target="_blank">00:45:09.220</a></span> | <span class="t">What's the main question for that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2711" target="_blank">00:45:11.060</a></span> | <span class="t">Yeah, why was the next sentence prediction not necessary?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2714" target="_blank">00:45:14.420</a></span> | <span class="t">One thing that it does that's a negative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2716" target="_blank">00:45:16.460</a></span> | <span class="t">is that now the effective context length for a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2724" target="_blank">00:45:24.300</a></span> | <span class="t">of your examples is halved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2726" target="_blank">00:45:26.580</a></span> | <span class="t">So one of the things that's useful about pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2728" target="_blank">00:45:28.820</a></span> | <span class="t">seemingly is that you get to build representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2730" target="_blank">00:45:30.980</a></span> | <span class="t">of very long sequences of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2733" target="_blank">00:45:33.220</a></span> | <span class="t">This is very short, but in practice,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2735" target="_blank">00:45:35.460</a></span> | <span class="t">segment A was going to be something like 250 words,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2739" target="_blank">00:45:39.540</a></span> | <span class="t">and segment B was going to be 250 words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2742" target="_blank">00:45:42.060</a></span> | <span class="t">And in the paper that let us know that this wasn't necessary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2745" target="_blank">00:45:45.460</a></span> | <span class="t">they always had a long segment of 500 words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2748" target="_blank">00:45:48.940</a></span> | <span class="t">And it seemed to be useful to always have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2750" target="_blank">00:45:50.740</a></span> | <span class="t">this very long context because longer contexts help give you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2755" target="_blank">00:45:55.380</a></span> | <span class="t">more information about the role that each word is playing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2758" target="_blank">00:45:58.060</a></span> | <span class="t">in that specific context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2759" target="_blank">00:45:59.820</a></span> | <span class="t">If I see one word, it's hard to know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2762" target="_blank">00:46:02.100</a></span> | <span class="t">If I just see record, it's hard to know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2763" target="_blank">00:46:03.980</a></span> | <span class="t">what it's supposed to mean.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2765" target="_blank">00:46:05.220</a></span> | <span class="t">But if I see 1,000 words around it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2766" target="_blank">00:46:06.900</a></span> | <span class="t">it's much clearer what its role is in that context is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2769" target="_blank">00:46:09.540</a></span> | <span class="t">So yeah, it cuts the effective context size is one answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2773" target="_blank">00:46:13.100</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2773" target="_blank">00:46:13.600</a></span> | <span class="t">Another thing is that this is actually much more difficult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2779" target="_blank">00:46:19.860</a></span> | <span class="t">This is a much more recent paper that I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2781" target="_blank">00:46:21.980</a></span> | <span class="t">don't have in the slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2783" target="_blank">00:46:23.260</a></span> | <span class="t">But it's been shown since then that these models are really,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2785" target="_blank">00:46:25.760</a></span> | <span class="t">really bad at the next sentence prediction task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2788" target="_blank">00:46:28.860</a></span> | <span class="t">So it could be that maybe it just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2791" target="_blank">00:46:31.140</a></span> | <span class="t">was too hard at the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2794" target="_blank">00:46:34.860</a></span> | <span class="t">And so it just wasn't useful because the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2797" target="_blank">00:46:37.060</a></span> | <span class="t">was failing to do it at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2799" target="_blank">00:46:39.740</a></span> | <span class="t">So I can give the link for that paper later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2803" target="_blank">00:46:43.100</a></span> | <span class="t">Can you explain again why we need to do a next sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2805" target="_blank">00:46:45.940</a></span> | <span class="t">prediction?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2806" target="_blank">00:46:46.500</a></span> | <span class="t">What about just masking and predicting the next?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2809" target="_blank">00:46:49.020</a></span> | <span class="t">I missed that jump.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2810" target="_blank">00:46:50.140</a></span> | <span class="t">So it's the next sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2812" target="_blank">00:46:52.020</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2812" target="_blank">00:46:52.540</a></span> | <span class="t">So the question is, why do we need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2813" target="_blank">00:46:53.620</a></span> | <span class="t">to do next sentence prediction?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2814" target="_blank">00:46:54.700</a></span> | <span class="t">Why not just do the masking we saw before?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2817" target="_blank">00:46:57.020</a></span> | <span class="t">That's the thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2817" target="_blank">00:46:57.380</a></span> | <span class="t">You seem to not need to do next sentence prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2819" target="_blank">00:46:59.660</a></span> | <span class="t">But as history of the research, it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2823" target="_blank">00:47:03.020</a></span> | <span class="t">was thought that this was useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2825" target="_blank">00:47:05.380</a></span> | <span class="t">And the idea was that it required</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2827" target="_blank">00:47:07.420</a></span> | <span class="t">you to develop this pairwise, do these two segments of text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2832" target="_blank">00:47:12.060</a></span> | <span class="t">interact?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2832" target="_blank">00:47:12.560</a></span> | <span class="t">How do they interact?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2833" target="_blank">00:47:13.500</a></span> | <span class="t">Are they related?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2834" target="_blank">00:47:14.260</a></span> | <span class="t">The sort of longer distance notion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2836" target="_blank">00:47:16.300</a></span> | <span class="t">And many NLP tasks are defined on pairs of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2839" target="_blank">00:47:19.860</a></span> | <span class="t">And they thought that might be useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2842" target="_blank">00:47:22.180</a></span> | <span class="t">And so they published it with this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2844" target="_blank">00:47:24.020</a></span> | <span class="t">And then someone else came through,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2845" target="_blank">00:47:25.500</a></span> | <span class="t">published a new model that didn't do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2847" target="_blank">00:47:27.260</a></span> | <span class="t">And it sort of did better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2849" target="_blank">00:47:29.500</a></span> | <span class="t">So this is just-- yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2851" target="_blank">00:47:31.820</a></span> | <span class="t">So yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2853" target="_blank">00:47:33.060</a></span> | <span class="t">There are intuitions as to why it could work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2854" target="_blank">00:47:34.860</a></span> | <span class="t">It just didn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2856" target="_blank">00:47:36.260</a></span> | <span class="t">So BERT wasn't doing masking or was doing--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2858" target="_blank">00:47:38.700</a></span> | <span class="t">It was doing both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2859" target="_blank">00:47:39.420</a></span> | <span class="t">It was doing both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2860" target="_blank">00:47:40.260</a></span> | <span class="t">It was doing both this next sentence--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2862" target="_blank">00:47:42.100</a></span> | <span class="t">so BERT was doing both this next sentence prediction training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2866" target="_blank">00:47:46.540</a></span> | <span class="t">as well as this masking training all at the same time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2872" target="_blank">00:47:52.220</a></span> | <span class="t">And so you had to have a separate predictor head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2875" target="_blank">00:47:55.380</a></span> | <span class="t">on top of BERT, a separate predictor sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2877" target="_blank">00:47:57.340</a></span> | <span class="t">of classification thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2879" target="_blank">00:47:59.580</a></span> | <span class="t">And so one detail there is that there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2882" target="_blank">00:48:02.300</a></span> | <span class="t">this special word at the beginning of BERT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2884" target="_blank">00:48:04.460</a></span> | <span class="t">in every sequence that's CLS.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2887" target="_blank">00:48:07.140</a></span> | <span class="t">And you can define a predictor on top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2890" target="_blank">00:48:10.140</a></span> | <span class="t">of that sort of fake word embedding that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2892" target="_blank">00:48:12.420</a></span> | <span class="t">was going to say, is the next sentence real or fake or not?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2896" target="_blank">00:48:16.140</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2897" target="_blank">00:48:17.740</a></span> | <span class="t">OK, I'm going to move on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2900" target="_blank">00:48:20.620</a></span> | <span class="t">And so this gets at sort of the question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2902" target="_blank">00:48:22.500</a></span> | <span class="t">that we had earlier about how do you evaluate these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2905" target="_blank">00:48:25.540</a></span> | <span class="t">There's a lot of different NLP tasks out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2907" target="_blank">00:48:27.780</a></span> | <span class="t">Gosh.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2908" target="_blank">00:48:28.380</a></span> | <span class="t">And when people were defining these papers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2912" target="_blank">00:48:32.140</a></span> | <span class="t">they would look at a ton of different evaluations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2914" target="_blank">00:48:34.580</a></span> | <span class="t">that had been sort of compiled as a set of things that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2916" target="_blank">00:48:36.880</a></span> | <span class="t">are a little hard for today's systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2918" target="_blank">00:48:38.860</a></span> | <span class="t">So are you detecting paraphrases between questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2921" target="_blank">00:48:41.900</a></span> | <span class="t">Are two Quora questions actually the same question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2924" target="_blank">00:48:44.260</a></span> | <span class="t">That turns out to be hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2927" target="_blank">00:48:47.500</a></span> | <span class="t">Can you do sentiment analysis on this hard data set?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2931" target="_blank">00:48:51.540</a></span> | <span class="t">Can you tell if sentences are linguistically acceptable?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2934" target="_blank">00:48:54.460</a></span> | <span class="t">Are they grammatical or not?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2936" target="_blank">00:48:56.620</a></span> | <span class="t">Are two sequences similar semantically?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2939" target="_blank">00:48:59.020</a></span> | <span class="t">Do they mean sort of vaguely the similar thing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2941" target="_blank">00:49:01.900</a></span> | <span class="t">And we'll talk a bit about natural language inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2944" target="_blank">00:49:04.100</a></span> | <span class="t">later, but that's the task of defining sort of if I say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2948" target="_blank">00:49:08.240</a></span> | <span class="t">you know, I saw the dog, that does not necessarily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2951" target="_blank">00:49:11.400</a></span> | <span class="t">mean I saw the little dog.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2954" target="_blank">00:49:14.440</a></span> | <span class="t">But saying I saw the little dog does mean I saw the dog.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2958" target="_blank">00:49:18.000</a></span> | <span class="t">So that's sort of this natural language inference task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2960" target="_blank">00:49:20.560</a></span> | <span class="t">And the difference between sort of pre-pre-training days,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2966" target="_blank">00:49:26.920</a></span> | <span class="t">where you had this sort of this row here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2969" target="_blank">00:49:29.320</a></span> | <span class="t">before you had substantial amounts of pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2973" target="_blank">00:49:33.600</a></span> | <span class="t">and BERT was just like the field was taken aback in a way that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2977" target="_blank">00:49:37.540</a></span> | <span class="t">hard to describe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2979" target="_blank">00:49:39.420</a></span> | <span class="t">You know, very carefully crafted architectures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2981" target="_blank">00:49:41.960</a></span> | <span class="t">for each individual task, where everyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2984" target="_blank">00:49:44.040</a></span> | <span class="t">was designing their own neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2985" target="_blank">00:49:45.660</a></span> | <span class="t">and doing things that they thought were sort of clever as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2988" target="_blank">00:49:48.000</a></span> | <span class="t">to how to define all the connections and the weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2990" target="_blank">00:49:50.300</a></span> | <span class="t">and whatever to do their tasks independently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2992" target="_blank">00:49:52.400</a></span> | <span class="t">So everyone was doing a different thing for each one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2994" target="_blank">00:49:54.600</a></span> | <span class="t">of these tasks, roughly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2997" target="_blank">00:49:57.360</a></span> | <span class="t">All of that was blown out of the water</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=2999" target="_blank">00:49:59.360</a></span> | <span class="t">by just build a big transformer and just teach it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3002" target="_blank">00:50:02.120</a></span> | <span class="t">to predict the missing words a whole bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3004" target="_blank">00:50:04.160</a></span> | <span class="t">and then fine tune it on each of these tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3007" target="_blank">00:50:07.000</a></span> | <span class="t">So this was just a sea change in the field.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3009" target="_blank">00:50:09.680</a></span> | <span class="t">People were, I mean, amazed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3011" target="_blank">00:50:11.920</a></span> | <span class="t">It's a little bit less flashy than chat GPT, I'll admit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3014" target="_blank">00:50:14.760</a></span> | <span class="t">But it's really part of the story that gets us to it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3017" target="_blank">00:50:17.160</a></span> | <span class="t">you know?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3018" target="_blank">00:50:18.920</a></span> | <span class="t">OK, questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3020" target="_blank">00:50:20.800</a></span> | <span class="t">So like to get stuff out of the--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3028" target="_blank">00:50:28.200</a></span> | <span class="t">during the encoder pre-training stage,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3031" target="_blank">00:50:31.680</a></span> | <span class="t">encoder usually outputs some sort of hidden values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3036" target="_blank">00:50:36.680</a></span> | <span class="t">How do we correlate those to words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3039" target="_blank">00:50:39.200</a></span> | <span class="t">that we are trying to test against?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3041" target="_blank">00:50:41.720</a></span> | <span class="t">So the question is, the encoder output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3044" target="_blank">00:50:44.760</a></span> | <span class="t">is a bunch of hidden values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3048" target="_blank">00:50:48.320</a></span> | <span class="t">How do we actually correlate those values to stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3051" target="_blank">00:50:51.320</a></span> | <span class="t">that we want to predict?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3052" target="_blank">00:50:52.640</a></span> | <span class="t">I'm going to go on to the next slide here to bring up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3054" target="_blank">00:50:54.980</a></span> | <span class="t">this example here, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3056" target="_blank">00:50:56.120</a></span> | <span class="t">So the encoder gives us, for each input word token,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3060" target="_blank">00:51:00.200</a></span> | <span class="t">a vector of that token that represents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3062" target="_blank">00:51:02.640</a></span> | <span class="t">the token in context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3064" target="_blank">00:51:04.360</a></span> | <span class="t">And the question is, how do we get these representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3067" target="_blank">00:51:07.520</a></span> | <span class="t">and turn them into sort of answers for the tasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3071" target="_blank">00:51:11.560</a></span> | <span class="t">that we care about?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3073" target="_blank">00:51:13.080</a></span> | <span class="t">And the answer comes back to something like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3090" target="_blank">00:51:30.080</a></span> | <span class="t">Something like this, maybe?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3092" target="_blank">00:51:32.480</a></span> | <span class="t">Sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3099" target="_blank">00:51:39.360</a></span> | <span class="t">So when we were doing the pre-training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3101" target="_blank">00:51:41.040</a></span> | <span class="t">we had the transformer that was giving us our representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3103" target="_blank">00:51:43.840</a></span> | <span class="t">And we had this little last layer here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3106" target="_blank">00:51:46.040</a></span> | <span class="t">this little sort of affine transformation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3109" target="_blank">00:51:49.840</a></span> | <span class="t">that moved us from the encoder's hidden state size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3112" target="_blank">00:51:52.480</a></span> | <span class="t">to the vocabulary to do our prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3115" target="_blank">00:51:55.000</a></span> | <span class="t">And we just removed this last prediction layer here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3118" target="_blank">00:51:58.280</a></span> | <span class="t">And let's say we want to do something that is classifying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3123" target="_blank">00:52:03.320</a></span> | <span class="t">the sentiment of the sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3124" target="_blank">00:52:04.600</a></span> | <span class="t">We just pick arbitrarily maybe the last word in the sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3128" target="_blank">00:52:08.320</a></span> | <span class="t">And we stick a linear classifier on top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3131" target="_blank">00:52:11.480</a></span> | <span class="t">and map it to positive or negative,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3133" target="_blank">00:52:13.320</a></span> | <span class="t">and then fine tune the whole thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3136" target="_blank">00:52:16.040</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3137" target="_blank">00:52:17.160</a></span> | <span class="t">So yeah, the BERT model had two different models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3141" target="_blank">00:52:21.160</a></span> | <span class="t">One was 110 million parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3142" target="_blank">00:52:22.920</a></span> | <span class="t">One was 340 million.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3144" target="_blank">00:52:24.840</a></span> | <span class="t">Keep that sort of in the back of your head sort of percolating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3147" target="_blank">00:52:27.480</a></span> | <span class="t">as we talk about models with many, many more parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3150" target="_blank">00:52:30.160</a></span> | <span class="t">later on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3151" target="_blank">00:52:31.160</a></span> | <span class="t">It was trained on 800 million words plus--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3158" target="_blank">00:52:38.320</a></span> | <span class="t">that is definitely wrong--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3160" target="_blank">00:52:40.000</a></span> | <span class="t">maybe 25 million words, but on the order of less than a billion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3164" target="_blank">00:52:44.520</a></span> | <span class="t">words of text, quite a bit still.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3168" target="_blank">00:52:48.220</a></span> | <span class="t">And it was trained on what was considered at the time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3170" target="_blank">00:52:50.640</a></span> | <span class="t">to be a whole lot of compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3173" target="_blank">00:52:53.120</a></span> | <span class="t">Just it was Google doing this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3174" target="_blank">00:52:54.840</a></span> | <span class="t">And they released it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3175" target="_blank">00:52:55.720</a></span> | <span class="t">And we were like, oh, who has that kind of compute?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3177" target="_blank">00:52:57.400</a></span> | <span class="t">But Google-- although nowadays, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3179" target="_blank">00:52:59.280</a></span> | <span class="t">not considered to be very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3181" target="_blank">00:53:01.600</a></span> | <span class="t">But fine tuning is practical and common on a single GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3184" target="_blank">00:53:04.720</a></span> | <span class="t">So you could take the BERT model that they've spent a lot of time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3187" target="_blank">00:53:07.560</a></span> | <span class="t">training and fine tune it yourself on your task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3190" target="_blank">00:53:10.640</a></span> | <span class="t">on even sort of a very small GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3194" target="_blank">00:53:14.120</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3197" target="_blank">00:53:17.820</a></span> | <span class="t">So one question is like, well, this seems really great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3204" target="_blank">00:53:24.520</a></span> | <span class="t">Why don't we just use this for everything?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3207" target="_blank">00:53:27.080</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3211" target="_blank">00:53:31.400</a></span> | <span class="t">And the answer is, well, what is the sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3213" target="_blank">00:53:33.960</a></span> | <span class="t">of pre-training objective?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3215" target="_blank">00:53:35.040</a></span> | <span class="t">What's the structure of the pre-trained model good for?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3218" target="_blank">00:53:38.520</a></span> | <span class="t">BERT is really good for sort of filling in the blanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3221" target="_blank">00:53:41.920</a></span> | <span class="t">But it's much less naturally used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3224" target="_blank">00:53:44.320</a></span> | <span class="t">for actually generating text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3226" target="_blank">00:53:46.800</a></span> | <span class="t">So I wouldn't want to use BERT to generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3228" target="_blank">00:53:48.960</a></span> | <span class="t">a summary of something because it's not really built for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3233" target="_blank">00:53:53.080</a></span> | <span class="t">It doesn't have a natural notion of predicting the next word given</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3236" target="_blank">00:53:56.520</a></span> | <span class="t">all the words that came before it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3238" target="_blank">00:53:58.280</a></span> | <span class="t">So maybe I want to use BERT if I want a good representation of, say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3241" target="_blank">00:54:01.840</a></span> | <span class="t">a document to classify it, give it a set of topic labels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3245" target="_blank">00:54:05.440</a></span> | <span class="t">or say it's toxic or non-toxic or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3247" target="_blank">00:54:07.960</a></span> | <span class="t">But I wouldn't want to use it to generate a whole sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3252" target="_blank">00:54:12.960</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3253" target="_blank">00:54:13.460</a></span> | <span class="t">Some extensions of BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3255" target="_blank">00:54:15.040</a></span> | <span class="t">So we had a question earlier of whether you just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3257" target="_blank">00:54:17.400</a></span> | <span class="t">mask things out randomly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3258" target="_blank">00:54:18.920</a></span> | <span class="t">One thing that seems to work better is you mask out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3263" target="_blank">00:54:23.480</a></span> | <span class="t">sort of whole contiguous spans because sort of the difficulty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3270" target="_blank">00:54:30.480</a></span> | <span class="t">of this problem is much easier than it would otherwise be because sort of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3275" target="_blank">00:54:35.720</a></span> | <span class="t">is part of irresistibly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3277" target="_blank">00:54:37.120</a></span> | <span class="t">And you can tell very easily based on the sort of subwords that came before it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3281" target="_blank">00:54:41.160</a></span> | <span class="t">Whereas if I have a much longer sequence, it's a trade-off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3285" target="_blank">00:54:45.500</a></span> | <span class="t">But this might be a harder problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3287" target="_blank">00:54:47.840</a></span> | <span class="t">And it ends up being better to do this sort of span-based masking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3291" target="_blank">00:54:51.600</a></span> | <span class="t">than random masking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3292" target="_blank">00:54:52.600</a></span> | <span class="t">And that might be because subwords make very simple prediction problems when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3296" target="_blank">00:54:56.680</a></span> | <span class="t">you mask out just one subword of a word versus all the subwords of a word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3302" target="_blank">00:55:02.160</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3302" target="_blank">00:55:02.660</a></span> | <span class="t">So this ends up doing much better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3305" target="_blank">00:55:05.360</a></span> | <span class="t">There's also a paper called the Roberta paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3307" target="_blank">00:55:07.360</a></span> | <span class="t">which showed that the next sentence prediction wasn't necessary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3312" target="_blank">00:55:12.180</a></span> | <span class="t">They also showed that they really should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3313" target="_blank">00:55:13.880</a></span> | <span class="t">have trained it on a lot more text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3316" target="_blank">00:55:16.840</a></span> | <span class="t">So Roberta is a drop-in replacement for BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3319" target="_blank">00:55:19.560</a></span> | <span class="t">So if you're thinking of using BERT, just use Roberta.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3321" target="_blank">00:55:21.760</a></span> | <span class="t">It's better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3322" target="_blank">00:55:22.640</a></span> | <span class="t">And it gave us this intuition that we really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3324" target="_blank">00:55:24.280</a></span> | <span class="t">don't know a whole lot about the best practices for training these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3327" target="_blank">00:55:27.400</a></span> | <span class="t">You sort of train it for as long as you're willing to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3329" target="_blank">00:55:29.800</a></span> | <span class="t">And things do good stuff and whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3333" target="_blank">00:55:33.600</a></span> | <span class="t">So this is very-- but it's very difficult to do sort of iteration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3337" target="_blank">00:55:37.920</a></span> | <span class="t">on these models because they're big.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3339" target="_blank">00:55:39.420</a></span> | <span class="t">It's expensive to train them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3342" target="_blank">00:55:42.520</a></span> | <span class="t">Another thing that you should know for your final projects in the world ahead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3345" target="_blank">00:55:45.960</a></span> | <span class="t">is this notion of fine-tuning all parameters of the network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3349" target="_blank">00:55:49.200</a></span> | <span class="t">versus just a couple of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3351" target="_blank">00:55:51.200</a></span> | <span class="t">So what we've talked about so far is you pre-train all the parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3354" target="_blank">00:55:54.840</a></span> | <span class="t">and then you fine-tune all of them as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3356" target="_blank">00:55:56.640</a></span> | <span class="t">So all the parameter values change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3359" target="_blank">00:55:59.480</a></span> | <span class="t">Alternative, which you call parameter efficient or lightweight fine-tuning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3364" target="_blank">00:56:04.000</a></span> | <span class="t">you sort of choose little bits of parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3366" target="_blank">00:56:06.520</a></span> | <span class="t">or you choose the very smart way of keeping most of the parameters fixed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3369" target="_blank">00:56:09.640</a></span> | <span class="t">and only fine-tuning others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3371" target="_blank">00:56:11.480</a></span> | <span class="t">And the intuition is that these pre-trained parameters were really good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3376" target="_blank">00:56:16.600</a></span> | <span class="t">And you want to make the minimal change from the pre-trained model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3380" target="_blank">00:56:20.080</a></span> | <span class="t">to the model that does what you want so that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3382" target="_blank">00:56:22.120</a></span> | <span class="t">keep some of the generality, some of the goodness of the pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3386" target="_blank">00:56:26.280</a></span> | <span class="t">So one way that this is done is called prefix tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3389" target="_blank">00:56:29.280</a></span> | <span class="t">Prompt tuning is very similar, where you actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3391" target="_blank">00:56:31.560</a></span> | <span class="t">freeze all the parameters of the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3393" target="_blank">00:56:33.280</a></span> | <span class="t">So I've pre-trained my network here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3396" target="_blank">00:56:36.920</a></span> | <span class="t">And I never change any of the parameter values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3399" target="_blank">00:56:39.720</a></span> | <span class="t">Instead, I make a bunch of fake sort of pseudo word vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3404" target="_blank">00:56:44.360</a></span> | <span class="t">that I prepend to the very beginning of the sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3407" target="_blank">00:56:47.360</a></span> | <span class="t">And I train just them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3409" target="_blank">00:56:49.280</a></span> | <span class="t">Sort of unintuitive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3410" target="_blank">00:56:50.800</a></span> | <span class="t">It's like these would have been like inputs to the network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3413" target="_blank">00:56:53.480</a></span> | <span class="t">but I'm specifying them as parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3415" target="_blank">00:56:55.340</a></span> | <span class="t">And I'm training everything to do my sentiment analysis task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3418" target="_blank">00:56:58.640</a></span> | <span class="t">just by changing the values of these sort of fake words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3423" target="_blank">00:57:03.120</a></span> | <span class="t">And this is nice because I get to keep all the good pre-trained parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3428" target="_blank">00:57:08.960</a></span> | <span class="t">and then just specify the sort of diff that ends up generalizing better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3435" target="_blank">00:57:15.000</a></span> | <span class="t">This is a very open field of research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3437" target="_blank">00:57:17.520</a></span> | <span class="t">But this is also cheaper because I don't have to compute the gradients,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3441" target="_blank">00:57:21.480</a></span> | <span class="t">or I don't have to store the gradients and all the optimizer state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3445" target="_blank">00:57:25.240</a></span> | <span class="t">With respect to all these parameters, I'm only training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3448" target="_blank">00:57:28.160</a></span> | <span class="t">a very small number of parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3450" target="_blank">00:57:30.840</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3451" target="_blank">00:57:31.340</a></span> | <span class="t">[INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3453" target="_blank">00:57:33.340</a></span> | <span class="t">It's like fake parameters at the end, as if like here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3458" target="_blank">00:57:38.180</a></span> | <span class="t">It doesn't make any difference if you put these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3460" target="_blank">00:57:40.180</a></span> | <span class="t">at the end or the beginning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3461" target="_blank">00:57:41.380</a></span> | <span class="t">In a decoder, you have to put them at the beginning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3463" target="_blank">00:57:43.540</a></span> | <span class="t">because otherwise you don't see them before you process the whole sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3468" target="_blank">00:57:48.780</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3469" target="_blank">00:57:49.280</a></span> | <span class="t">Can we just attach a few layers and only train the new layers?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3473" target="_blank">00:57:53.500</a></span> | <span class="t">The question is, can we just attach a new layers at the top of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3476" target="_blank">00:57:56.660</a></span> | <span class="t">and only train those?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3477" target="_blank">00:57:57.660</a></span> | <span class="t">Absolutely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3478" target="_blank">00:57:58.820</a></span> | <span class="t">This works a bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3480" target="_blank">00:58:00.540</a></span> | <span class="t">Another thing that works well-- sorry, we're running out of time--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3484" target="_blank">00:58:04.340</a></span> | <span class="t">is taking each weight matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3486" target="_blank">00:58:06.780</a></span> | <span class="t">So I have a bunch of weight matrices in my transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3489" target="_blank">00:58:09.700</a></span> | <span class="t">And I freeze the weight matrix and learn a very low rank little diff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3495" target="_blank">00:58:15.420</a></span> | <span class="t">And I set the weight matrix's value to be sort of the original value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3499" target="_blank">00:58:19.660</a></span> | <span class="t">plus my sort of very low rank diff from the original one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3504" target="_blank">00:58:24.900</a></span> | <span class="t">And this ends up being a very similarly useful technique.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3509" target="_blank">00:58:29.620</a></span> | <span class="t">And the overall idea here is that, again, I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3511" target="_blank">00:58:31.700</a></span> | <span class="t">learning way fewer parameters than I did via pre-training and freezing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3516" target="_blank">00:58:36.180</a></span> | <span class="t">most of the pre-training parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3519" target="_blank">00:58:39.300</a></span> | <span class="t">OK, encoder-decoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3521" target="_blank">00:58:41.140</a></span> | <span class="t">So for encoder-decoders, we could do something like language modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3525" target="_blank">00:58:45.300</a></span> | <span class="t">I've got my input sequence here, encoder, output sequence here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3529" target="_blank">00:58:49.700</a></span> | <span class="t">And I could say this part is my prefix for sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3532" target="_blank">00:58:52.980</a></span> | <span class="t">of having bidirectional context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3535" target="_blank">00:58:55.100</a></span> | <span class="t">And I could then predict all the words that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3538" target="_blank">00:58:58.220</a></span> | <span class="t">are sort of in the latter half of the sequence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3540" target="_blank">00:59:00.780</a></span> | <span class="t">just like a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3541" target="_blank">00:59:01.900</a></span> | <span class="t">And that would work fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3544" target="_blank">00:59:04.460</a></span> | <span class="t">And so this is something that you could do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3547" target="_blank">00:59:07.140</a></span> | <span class="t">You sort of take a long text, split it into two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3549" target="_blank">00:59:09.700</a></span> | <span class="t">give half of it to the encoder, and then generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3552" target="_blank">00:59:12.080</a></span> | <span class="t">the second half with the decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3553" target="_blank">00:59:13.420</a></span> | <span class="t">But in practice, what works much better is this notion of span corruption.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3560" target="_blank">00:59:20.300</a></span> | <span class="t">Span corruption is going to show up in your assignment 5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3563" target="_blank">00:59:23.260</a></span> | <span class="t">And the idea here is a lot like BERT, but in a sort of generative sense,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3570" target="_blank">00:59:30.580</a></span> | <span class="t">where I'm going to mask out a bunch of words in the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3573" target="_blank">00:59:33.500</a></span> | <span class="t">Thank you, mask token 1, me to your party, mask token 2, week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3580" target="_blank">00:59:40.860</a></span> | <span class="t">And then at the output, I generate the mask token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3584" target="_blank">00:59:44.660</a></span> | <span class="t">and then what was supposed to be there, but the mask token replaced it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3588" target="_blank">00:59:48.580</a></span> | <span class="t">So thank you, then predict for inviting at the output,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3592" target="_blank">00:59:52.500</a></span> | <span class="t">me to your party, last week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3594" target="_blank">00:59:54.860</a></span> | <span class="t">And what this does is that it allows you to have bidirectional context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3600" target="_blank">01:00:00.900</a></span> | <span class="t">I get to see the whole sequence, except I can generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3605" target="_blank">01:00:05.220</a></span> | <span class="t">the parts that were missing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3607" target="_blank">01:00:07.100</a></span> | <span class="t">So this feels a little bit like you mask out parts of the input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3610" target="_blank">01:00:10.020</a></span> | <span class="t">but you actually generate the output as a sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3612" target="_blank">01:00:12.960</a></span> | <span class="t">like you would in language modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3614" target="_blank">01:00:14.860</a></span> | <span class="t">So this might be good for something like machine translation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3617" target="_blank">01:00:17.420</a></span> | <span class="t">where I have an input that I want bidirectional context in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3620" target="_blank">01:00:20.340</a></span> | <span class="t">but then I want to generate an output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3622" target="_blank">01:00:22.300</a></span> | <span class="t">And I want to pre-train the whole thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3624" target="_blank">01:00:24.380</a></span> | <span class="t">So this was shown to work better than language modeling at the scales</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3627" target="_blank">01:00:27.780</a></span> | <span class="t">that these folks at Google were able to test back in 2018.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3631" target="_blank">01:00:31.580</a></span> | <span class="t">This is still quite popular.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3632" target="_blank">01:00:32.860</a></span> | <span class="t">Yeah, there's a lot of numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3637" target="_blank">01:00:37.940</a></span> | <span class="t">It works better than the other stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3640" target="_blank">01:00:40.100</a></span> | <span class="t">I'm not going to worry about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3643" target="_blank">01:00:43.780</a></span> | <span class="t">There's a fascinating property of these models also.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3646" target="_blank">01:00:46.540</a></span> | <span class="t">So T5 was the model that was originally introduced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3651" target="_blank">01:00:51.060</a></span> | <span class="t">with salient span masking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3652" target="_blank">01:00:52.820</a></span> | <span class="t">And you can think of at pre-training time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3655" target="_blank">01:00:55.820</a></span> | <span class="t">you saw a bunch of things like Franklin D. Roosevelt was born in blank,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3660" target="_blank">01:01:00.540</a></span> | <span class="t">and you generated out the blank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3662" target="_blank">01:01:02.580</a></span> | <span class="t">And there's this task called open domain question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3667" target="_blank">01:01:07.620</a></span> | <span class="t">answering, which has a bunch of trivia questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3670" target="_blank">01:01:10.220</a></span> | <span class="t">like when was Franklin D. Roosevelt born?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3672" target="_blank">01:01:12.820</a></span> | <span class="t">And then you're supposed to generate out the answer as a string, just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3676" target="_blank">01:01:16.860</a></span> | <span class="t">from your parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3677" target="_blank">01:01:17.940</a></span> | <span class="t">So you did a bunch of pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3679" target="_blank">01:01:19.400</a></span> | <span class="t">You saw a bunch of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3680" target="_blank">01:01:20.580</a></span> | <span class="t">And then you're supposed to generate these answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3682" target="_blank">01:01:22.900</a></span> | <span class="t">And what's fascinating is that this salient span masking method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3689" target="_blank">01:01:29.900</a></span> | <span class="t">allowed you to pre-train and then fine tune</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3692" target="_blank">01:01:32.380</a></span> | <span class="t">on some examples of trivia questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3696" target="_blank">01:01:36.820</a></span> | <span class="t">And then when you tested on new trivia questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3700" target="_blank">01:01:40.260</a></span> | <span class="t">the model would implicitly extract from its pre-training data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3704" target="_blank">01:01:44.540</a></span> | <span class="t">somehow the answer to that new question that it never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3707" target="_blank">01:01:47.780</a></span> | <span class="t">saw explicitly at fine tuning time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3709" target="_blank">01:01:49.700</a></span> | <span class="t">So it learned this sort of implicit retrieval-- sometimes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3713" target="_blank">01:01:53.060</a></span> | <span class="t">sometimes, less than 50% of the time or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3715" target="_blank">01:01:55.740</a></span> | <span class="t">but much more than random chance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3720" target="_blank">01:02:00.020</a></span> | <span class="t">And that's fascinating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3721" target="_blank">01:02:01.580</a></span> | <span class="t">So you've learned to access this latent knowledge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3725" target="_blank">01:02:05.180</a></span> | <span class="t">that you stored up by pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3727" target="_blank">01:02:07.380</a></span> | <span class="t">And so you just pass it the text, when was Roosevelt born,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3730" target="_blank">01:02:10.820</a></span> | <span class="t">and it would pass out an answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3733" target="_blank">01:02:13.020</a></span> | <span class="t">And one thing to know is that the answers always look very fluent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3735" target="_blank">01:02:15.860</a></span> | <span class="t">They always look very reasonable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3737" target="_blank">01:02:17.820</a></span> | <span class="t">But they're frequently wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3739" target="_blank">01:02:19.980</a></span> | <span class="t">And that's still true of things like ChatsGPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3741" target="_blank">01:02:21.860</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3745" target="_blank">01:02:25.980</a></span> | <span class="t">OK, so that's encoder-decoder models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3750" target="_blank">01:02:30.300</a></span> | <span class="t">Next up, we've got decoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3751" target="_blank">01:02:31.740</a></span> | <span class="t">And we'll spend a long time on decoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3754" target="_blank">01:02:34.100</a></span> | <span class="t">So this is just our normal language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3755" target="_blank">01:02:35.980</a></span> | <span class="t">So I get a sequence of hidden states from my decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3758" target="_blank">01:02:38.940</a></span> | <span class="t">The model-- the words can only look at themselves, not the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3763" target="_blank">01:02:43.220</a></span> | <span class="t">And then I predict the next word in the sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3766" target="_blank">01:02:46.780</a></span> | <span class="t">And then here again, I can--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3768" target="_blank">01:02:48.700</a></span> | <span class="t">to do sentiment analysis, maybe take the last state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3770" target="_blank">01:02:50.900</a></span> | <span class="t">for the last word, and then predict happy or sad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3773" target="_blank">01:02:53.540</a></span> | <span class="t">based on that last embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3776" target="_blank">01:02:56.340</a></span> | <span class="t">Back-propagate the gradients of the whole network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3778" target="_blank">01:02:58.420</a></span> | <span class="t">train the whole thing, or do some kind of lightweight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3781" target="_blank">01:03:01.700</a></span> | <span class="t">or parameter-efficient fine-tuning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3783" target="_blank">01:03:03.420</a></span> | <span class="t">like we mentioned earlier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3785" target="_blank">01:03:05.100</a></span> | <span class="t">So this is our pre-training a decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3787" target="_blank">01:03:07.940</a></span> | <span class="t">And I can just pre-train it on language modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3793" target="_blank">01:03:13.460</a></span> | <span class="t">So again, you might want to do this if you are wanting to generate texts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3799" target="_blank">01:03:19.820</a></span> | <span class="t">generate things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3802" target="_blank">01:03:22.220</a></span> | <span class="t">You sort of can use this like you use an encoder-decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3805" target="_blank">01:03:25.700</a></span> | <span class="t">But in practice, as we'll see, a lot of the sort of biggest,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3809" target="_blank">01:03:29.580</a></span> | <span class="t">most powerful pre-trained models tend to be decoder-only.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3813" target="_blank">01:03:33.740</a></span> | <span class="t">It's not really clear exactly why, except they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3816" target="_blank">01:03:36.780</a></span> | <span class="t">seem a little bit simpler than encoder-decoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3821" target="_blank">01:03:41.140</a></span> | <span class="t">And you get to share all the parameters in one big network for the decoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3825" target="_blank">01:03:45.060</a></span> | <span class="t">whereas in an encoder-decoder, you have to split them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3827" target="_blank">01:03:47.820</a></span> | <span class="t">sort of some into the encoder, some into the decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3830" target="_blank">01:03:50.620</a></span> | <span class="t">So for the rest of this lecture, we'll talk only about decoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3835" target="_blank">01:03:55.500</a></span> | <span class="t">In modern things, the biggest networks do tend to be decoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3840" target="_blank">01:04:00.780</a></span> | <span class="t">So we're coming all the way back again to 2018.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3843" target="_blank">01:04:03.740</a></span> | <span class="t">And the GPT model from OpenAI was a big success.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3849" target="_blank">01:04:09.420</a></span> | <span class="t">It had 117 million parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3853" target="_blank">01:04:13.060</a></span> | <span class="t">It had 768 dimensional hidden states.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3856" target="_blank">01:04:16.660</a></span> | <span class="t">And it had this vocabulary that was 40,000-ish words that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3863" target="_blank">01:04:23.180</a></span> | <span class="t">was defined via a method like what we showed at the beginning of class,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3866" target="_blank">01:04:26.780</a></span> | <span class="t">trained on BooksCorpus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3868" target="_blank">01:04:28.620</a></span> | <span class="t">And actually, GPT never actually showed up in the original paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3872" target="_blank">01:04:32.860</a></span> | <span class="t">It's unclear what exactly it's supposed to refer to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3879" target="_blank">01:04:39.180</a></span> | <span class="t">But this model was a precursor to all the things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3883" target="_blank">01:04:43.580</a></span> | <span class="t">that you're hearing about nowadays.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3886" target="_blank">01:04:46.100</a></span> | <span class="t">If you move forward--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3888" target="_blank">01:04:48.700</a></span> | <span class="t">oh, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3889" target="_blank">01:04:49.200</a></span> | <span class="t">So if you-- hmm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3895" target="_blank">01:04:55.820</a></span> | <span class="t">So if we wanted to do something like natural language inference, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3899" target="_blank">01:04:59.900</a></span> | <span class="t">says, take these pairs of sentences-- the man is in the doorway,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3903" target="_blank">01:05:03.780</a></span> | <span class="t">the person is near the door--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3905" target="_blank">01:05:05.460</a></span> | <span class="t">and say that these mean that one entails the other,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3909" target="_blank">01:05:09.100</a></span> | <span class="t">the premise entails the hypothesis, that I can believe the hypothesis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3912" target="_blank">01:05:12.900</a></span> | <span class="t">if I believe the premise, I'd just concatenate them together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3916" target="_blank">01:05:16.780</a></span> | <span class="t">So give it maybe a start token, pass in one sentence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3921" target="_blank">01:05:21.180</a></span> | <span class="t">pass in some delimiter token, pass in the other,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3923" target="_blank">01:05:23.920</a></span> | <span class="t">and then predict yes, no, entailment, not entailment, fine tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3930" target="_blank">01:05:30.220</a></span> | <span class="t">GPT on this, it worked really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3933" target="_blank">01:05:33.340</a></span> | <span class="t">And then BERT came after GPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3935" target="_blank">01:05:35.620</a></span> | <span class="t">BERT did a bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3936" target="_blank">01:05:36.740</a></span> | <span class="t">It had bidirectional context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3939" target="_blank">01:05:39.740</a></span> | <span class="t">But it did an excellent job.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3944" target="_blank">01:05:44.180</a></span> | <span class="t">And then came GPT-2, where they focused more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3947" target="_blank">01:05:47.220</a></span> | <span class="t">on the generative abilities of the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3949" target="_blank">01:05:49.660</a></span> | <span class="t">So we looked at now a much larger network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3954" target="_blank">01:05:54.640</a></span> | <span class="t">We've gone from 117 million to 1.5 billion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3957" target="_blank">01:05:57.840</a></span> | <span class="t">And given some sort of prompt, it could generate, at the time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3961" target="_blank">01:06:01.800</a></span> | <span class="t">a quite surprisingly coherent continuation to the prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3964" target="_blank">01:06:04.680</a></span> | <span class="t">So it's telling this sort of story about scientists and unicorns here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3971" target="_blank">01:06:11.480</a></span> | <span class="t">And this size of model is still sort of small enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3975" target="_blank">01:06:15.280</a></span> | <span class="t">that you can use on a small GPU and fine tune and whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3979" target="_blank">01:06:19.620</a></span> | <span class="t">And its capabilities of generating long, coherent text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3983" target="_blank">01:06:23.060</a></span> | <span class="t">was just sort of exceptional at the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3988" target="_blank">01:06:28.140</a></span> | <span class="t">It was also trained on more data, although I don't--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3992" target="_blank">01:06:32.020</a></span> | <span class="t">something like 9 billion words of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=3995" target="_blank">01:06:35.580</a></span> | <span class="t">And then, so after GPT-2, we come to GPT-3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4000" target="_blank">01:06:40.340</a></span> | <span class="t">sort of walking through these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4002" target="_blank">01:06:42.280</a></span> | <span class="t">And then we come with a different way of interacting with the models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4005" target="_blank">01:06:45.620</a></span> | <span class="t">So we've interacted with pre-trained models in two ways so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4009" target="_blank">01:06:49.060</a></span> | <span class="t">We've sort of sampled from the distribution that they define.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4013" target="_blank">01:06:53.180</a></span> | <span class="t">We generated text via a machine translation system or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4017" target="_blank">01:06:57.380</a></span> | <span class="t">Or we fine-tuned them on a task that we care about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4019" target="_blank">01:06:59.620</a></span> | <span class="t">And then we take their predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4023" target="_blank">01:07:03.620</a></span> | <span class="t">But GPT-3 seems to have an interesting new ability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4030" target="_blank">01:07:10.180</a></span> | <span class="t">It's much larger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4031" target="_blank">01:07:11.580</a></span> | <span class="t">And it can do some tasks without any sort of fine-tuning whatsoever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4037" target="_blank">01:07:17.820</a></span> | <span class="t">GPT-3 is much larger than GPT-2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4040" target="_blank">01:07:20.060</a></span> | <span class="t">So we went from GPT, 100-ish million parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4043" target="_blank">01:07:23.500</a></span> | <span class="t">GPT-2, 1.5 billion, GPT-3, 175 billion, much larger,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4048" target="_blank">01:07:28.820</a></span> | <span class="t">trained on 300 billion words of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4052" target="_blank">01:07:32.100</a></span> | <span class="t">And this sort of notion of in-context learning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4054" target="_blank">01:07:34.500</a></span> | <span class="t">that it could define or figure out patterns in the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4057" target="_blank">01:07:37.740</a></span> | <span class="t">or in the example that it's currently seeing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4060" target="_blank">01:07:40.140</a></span> | <span class="t">and continue the pattern, is called in-context learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4064" target="_blank">01:07:44.700</a></span> | <span class="t">So you've got the word "thanks."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4066" target="_blank">01:07:46.440</a></span> | <span class="t">And I pass in this little arrow and say, OK, thanks goes to merci.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4070" target="_blank">01:07:50.180</a></span> | <span class="t">And then hello goes to bonjour.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4071" target="_blank">01:07:51.580</a></span> | <span class="t">And then I give it all of these examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4073" target="_blank">01:07:53.700</a></span> | <span class="t">and ask it what otter should go to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4077" target="_blank">01:07:57.300</a></span> | <span class="t">And it's learned to sort of continue the pattern</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4081" target="_blank">01:08:01.020</a></span> | <span class="t">and say that this is the translation of otter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4084" target="_blank">01:08:04.660</a></span> | <span class="t">So now, remember, this is a single sort of input that I've given to my model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4089" target="_blank">01:08:09.860</a></span> | <span class="t">And I haven't said, oh, do translation or fine-tune it on translation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4093" target="_blank">01:08:13.460</a></span> | <span class="t">or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4094" target="_blank">01:08:14.380</a></span> | <span class="t">I've just passed in the input, given it some examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4096" target="_blank">01:08:16.980</a></span> | <span class="t">And then it is able to, to some extent, do this seemingly complex task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4102" target="_blank">01:08:22.260</a></span> | <span class="t">That's in-context learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4105" target="_blank">01:08:25.620</a></span> | <span class="t">And here are more examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4107" target="_blank">01:08:27.140</a></span> | <span class="t">Maybe you give it examples of addition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4109" target="_blank">01:08:29.820</a></span> | <span class="t">And then it can do some simple addition afterward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4113" target="_blank">01:08:33.900</a></span> | <span class="t">You give it-- in this case, this is sort of rewriting typos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4116" target="_blank">01:08:36.900</a></span> | <span class="t">It can figure out how to rewrite typos in context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4119" target="_blank">01:08:39.460</a></span> | <span class="t">learning for machine translation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4121" target="_blank">01:08:41.820</a></span> | <span class="t">And this was the start of this idea that there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4123" target="_blank">01:08:43.860</a></span> | <span class="t">were these emergent properties that showed up in much larger models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4127" target="_blank">01:08:47.940</a></span> | <span class="t">And it wasn't clear, when looking at the smaller models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4131" target="_blank">01:08:51.020</a></span> | <span class="t">that you'd get this sort of new, this qualitatively new behavior out of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4137" target="_blank">01:08:57.780</a></span> | <span class="t">Like, it's not obvious from just the language modeling signal, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4141" target="_blank">01:09:01.140</a></span> | <span class="t">GPT-3 is just trained on that decoder only, just predict the next word,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4146" target="_blank">01:09:06.420</a></span> | <span class="t">that it would, as a result of that training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4149" target="_blank">01:09:09.740</a></span> | <span class="t">learn to perform seemingly quite complex things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4152" target="_blank">01:09:12.620</a></span> | <span class="t">as a function of its context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4153" target="_blank">01:09:13.700</a></span> | <span class="t">Yeah, OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4157" target="_blank">01:09:17.900</a></span> | <span class="t">One or two questions about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4159" target="_blank">01:09:19.540</a></span> | <span class="t">This should be quite surprising, I think, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4169" target="_blank">01:09:29.060</a></span> | <span class="t">So far, we've talked about good representations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4171" target="_blank">01:09:31.900</a></span> | <span class="t">contextual representations, meanings of words in context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4175" target="_blank">01:09:35.060</a></span> | <span class="t">This is some very, very high-level pattern matching, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4177" target="_blank">01:09:37.500</a></span> | <span class="t">It's coming up with patterns in just the input data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4180" target="_blank">01:09:40.660</a></span> | <span class="t">And that one sequence of text that you've passed it so far,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4183" target="_blank">01:09:43.660</a></span> | <span class="t">and it's able to sort of identify how to complete the pattern.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4188" target="_blank">01:09:48.180</a></span> | <span class="t">And you think, what kinds of things can this solve?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4190" target="_blank">01:09:50.780</a></span> | <span class="t">What are its capabilities?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4192" target="_blank">01:09:52.380</a></span> | <span class="t">What are its limitations?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4194" target="_blank">01:09:54.220</a></span> | <span class="t">This ends up being an open area of research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4196" target="_blank">01:09:56.100</a></span> | <span class="t">Sort of, what are the kinds of problems that you maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4198" target="_blank">01:09:58.700</a></span> | <span class="t">saw in the training data a lot?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4200" target="_blank">01:10:00.020</a></span> | <span class="t">Maybe GPT-3 saw a ton of pairs of words, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4203" target="_blank">01:10:03.780</a></span> | <span class="t">It saw a bunch of dictionaries, bilingual dictionaries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4206" target="_blank">01:10:06.860</a></span> | <span class="t">in its training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4207" target="_blank">01:10:07.740</a></span> | <span class="t">So it learned to do something like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4209" target="_blank">01:10:09.660</a></span> | <span class="t">Or is it doing something much more general,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4211" target="_blank">01:10:11.420</a></span> | <span class="t">where it's really learning the task in context?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4214" target="_blank">01:10:14.660</a></span> | <span class="t">The actual story, we're not totally sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4217" target="_blank">01:10:17.460</a></span> | <span class="t">Something in the middle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4218" target="_blank">01:10:18.740</a></span> | <span class="t">It seems like it has to be tied to your training data in ways</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4222" target="_blank">01:10:22.540</a></span> | <span class="t">that we don't quite understand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4224" target="_blank">01:10:24.140</a></span> | <span class="t">But there's also a non-trivial ability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4226" target="_blank">01:10:26.180</a></span> | <span class="t">to learn new sort of, at least, types of patterns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4230" target="_blank">01:10:30.140</a></span> | <span class="t">just from the context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4231" target="_blank">01:10:31.580</a></span> | <span class="t">So this is a very interesting thing to work on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4234" target="_blank">01:10:34.740</a></span> | <span class="t">Now, we've talked a lot about the size of these models so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4237" target="_blank">01:10:37.660</a></span> | <span class="t">And as models have gotten larger,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4239" target="_blank">01:10:39.700</a></span> | <span class="t">they've always gotten better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4240" target="_blank">01:10:40.900</a></span> | <span class="t">We train them on more data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4243" target="_blank">01:10:43.220</a></span> | <span class="t">So GPT-3 was trained on 300 billion words of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4246" target="_blank">01:10:46.940</a></span> | <span class="t">And it was 175 billion parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4250" target="_blank">01:10:50.900</a></span> | <span class="t">And at that scale, it costs a lot of money</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4255" target="_blank">01:10:55.100</a></span> | <span class="t">to build these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4256" target="_blank">01:10:56.140</a></span> | <span class="t">And it's very unclear whether you're getting the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4258" target="_blank">01:10:58.260</a></span> | <span class="t">use out of your money.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4259" target="_blank">01:10:59.220</a></span> | <span class="t">It's bigger, really, what you should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4260" target="_blank">01:11:00.640</a></span> | <span class="t">have been doing in terms of the number of parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4263" target="_blank">01:11:03.740</a></span> | <span class="t">So the cost of training one of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4266" target="_blank">01:11:06.180</a></span> | <span class="t">is roughly you take the number of parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4268" target="_blank">01:11:08.140</a></span> | <span class="t">you multiply it by the number of tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4269" target="_blank">01:11:09.740</a></span> | <span class="t">that you're going to train it on, the number of words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4272" target="_blank">01:11:12.780</a></span> | <span class="t">And some folks at DeepMind--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4274" target="_blank">01:11:14.820</a></span> | <span class="t">oh, I forgot the citation on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4276" target="_blank">01:11:16.240</a></span> | <span class="t">Some folks at DeepMind realized through some experimentation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4280" target="_blank">01:11:20.980</a></span> | <span class="t">that actually GPT-3 was just comically oversized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4285" target="_blank">01:11:25.300</a></span> | <span class="t">So Chinchilla, the model they trained,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4287" target="_blank">01:11:27.660</a></span> | <span class="t">is less than half the size and works better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4290" target="_blank">01:11:30.720</a></span> | <span class="t">But they just trained it on way more data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4294" target="_blank">01:11:34.640</a></span> | <span class="t">And this is an interesting trade-off about how do you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4298" target="_blank">01:11:38.020</a></span> | <span class="t">best spend your compute?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4299" target="_blank">01:11:39.120</a></span> | <span class="t">I mean, you can't do this more than a handful of times,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4301" target="_blank">01:11:41.420</a></span> | <span class="t">even if you're Google.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4304" target="_blank">01:11:44.100</a></span> | <span class="t">So open questions there as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4308" target="_blank">01:11:48.280</a></span> | <span class="t">Another way of interacting with these networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4311" target="_blank">01:11:51.320</a></span> | <span class="t">that has come out recently is called chain of thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4316" target="_blank">01:11:56.120</a></span> | <span class="t">So the prefix, we saw in the in-context learning slide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4320" target="_blank">01:12:00.200</a></span> | <span class="t">that the prefix can help specify what task you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4322" target="_blank">01:12:02.600</a></span> | <span class="t">trying to solve right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4324" target="_blank">01:12:04.360</a></span> | <span class="t">And it can do even more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4326" target="_blank">01:12:06.000</a></span> | <span class="t">So here's standard prompting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4327" target="_blank">01:12:07.680</a></span> | <span class="t">We have a prefix of examples of questions and answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4331" target="_blank">01:12:11.440</a></span> | <span class="t">So you have a question and then an example answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4334" target="_blank">01:12:14.800</a></span> | <span class="t">So that's your prompt that's specifying the task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4337" target="_blank">01:12:17.360</a></span> | <span class="t">And then you have a new question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4338" target="_blank">01:12:18.800</a></span> | <span class="t">And you're having the model generate an answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4340" target="_blank">01:12:20.760</a></span> | <span class="t">And it generates it wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4343" target="_blank">01:12:23.160</a></span> | <span class="t">And chain of thought prompting says, well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4346" target="_blank">01:12:26.560</a></span> | <span class="t">how about in the example, in the demonstration we give,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4349" target="_blank">01:12:29.280</a></span> | <span class="t">we give the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4350" target="_blank">01:12:30.600</a></span> | <span class="t">And then we give this sort of decomposition of steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4354" target="_blank">01:12:34.080</a></span> | <span class="t">towards how to get an answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4356" target="_blank">01:12:36.180</a></span> | <span class="t">So I'm actually writing this out as part of the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4358" target="_blank">01:12:38.380</a></span> | <span class="t">I'm giving annotations as a human to say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4361" target="_blank">01:12:41.480</a></span> | <span class="t">oh, to solve this sort of word problem,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4364" target="_blank">01:12:44.360</a></span> | <span class="t">here's how you could think it through-ish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4367" target="_blank">01:12:47.280</a></span> | <span class="t">And then I give it a new question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4369" target="_blank">01:12:49.480</a></span> | <span class="t">And the model says, oh, I know what I'm supposed to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4371" target="_blank">01:12:51.760</a></span> | <span class="t">I'm supposed to first generate a sequence of steps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4375" target="_blank">01:12:55.920</a></span> | <span class="t">of intermediate steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4377" target="_blank">01:12:57.640</a></span> | <span class="t">And then next, say the answer is--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4380" target="_blank">01:13:00.160</a></span> | <span class="t">and then say what the answer is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4381" target="_blank">01:13:01.840</a></span> | <span class="t">And it turns out-- and this should, again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4384" target="_blank">01:13:04.040</a></span> | <span class="t">be very surprising--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4386" target="_blank">01:13:06.440</a></span> | <span class="t">that the model can tend to generate plausible sequences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4389" target="_blank">01:13:09.960</a></span> | <span class="t">of steps and then much more frequently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4392" target="_blank">01:13:12.440</a></span> | <span class="t">generates the correct answer after doing so,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4394" target="_blank">01:13:14.880</a></span> | <span class="t">relative to trying to generate the answer by itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4398" target="_blank">01:13:18.160</a></span> | <span class="t">So you can think of this as a scratch pad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4400" target="_blank">01:13:20.600</a></span> | <span class="t">You can think of this as increasing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4403" target="_blank">01:13:23.080</a></span> | <span class="t">the amount of computation that you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4404" target="_blank">01:13:24.660</a></span> | <span class="t">putting into trying to solve the problem,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4407" target="_blank">01:13:27.000</a></span> | <span class="t">sort of writing out your thoughts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4408" target="_blank">01:13:28.420</a></span> | <span class="t">Right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4408" target="_blank">01:13:28.920</a></span> | <span class="t">As I generate each word of this continuation here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4413" target="_blank">01:13:33.040</a></span> | <span class="t">I'm able to condition on all the past words so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4416" target="_blank">01:13:36.200</a></span> | <span class="t">And so maybe it just allows the network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4420" target="_blank">01:13:40.280</a></span> | <span class="t">to sort of decompose the problem into smaller, simpler</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4423" target="_blank">01:13:43.160</a></span> | <span class="t">problems, which it's more able to solve each.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4427" target="_blank">01:13:47.800</a></span> | <span class="t">No one's really sure why this works exactly either.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4431" target="_blank">01:13:51.240</a></span> | <span class="t">At this point, with networks that are this large,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4434" target="_blank">01:13:54.120</a></span> | <span class="t">their emergent properties are both very powerful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4437" target="_blank">01:13:57.720</a></span> | <span class="t">and exceptionally hard to understand,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4439" target="_blank">01:13:59.600</a></span> | <span class="t">and very hard, you should think, to trust.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4443" target="_blank">01:14:03.440</a></span> | <span class="t">Because it's unclear what its capabilities are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4445" target="_blank">01:14:05.560</a></span> | <span class="t">and what its limitations are, where it will fail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4449" target="_blank">01:14:09.200</a></span> | <span class="t">So what do we think pre-training is teaching?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4451" target="_blank">01:14:11.720</a></span> | <span class="t">Gosh, a wide range of things, even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4454" target="_blank">01:14:14.520</a></span> | <span class="t">beyond what I've written in this slide, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4457" target="_blank">01:14:17.360</a></span> | <span class="t">I mostly wrote two years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4459" target="_blank">01:14:19.600</a></span> | <span class="t">So it can teach you trivia, and syntax, and coreference,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4462" target="_blank">01:14:22.480</a></span> | <span class="t">and maybe some lexical semantics, and sentiment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4464" target="_blank">01:14:24.920</a></span> | <span class="t">and some reasoning, like way more reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4467" target="_blank">01:14:27.360</a></span> | <span class="t">than we would have thought even three years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4470" target="_blank">01:14:30.280</a></span> | <span class="t">And yet, they also learn and exacerbate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4473" target="_blank">01:14:33.400</a></span> | <span class="t">racism and sexism, all manner of biases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4477" target="_blank">01:14:37.480</a></span> | <span class="t">There'll be more on this later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4478" target="_blank">01:14:38.920</a></span> | <span class="t">But the generality of this is really,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4482" target="_blank">01:14:42.800</a></span> | <span class="t">I think, what's taken many people aback.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4485" target="_blank">01:14:45.040</a></span> | <span class="t">And so increasingly, these objects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4487" target="_blank">01:14:47.440</a></span> | <span class="t">are not just studied for the sake of using them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4491" target="_blank">01:14:51.040</a></span> | <span class="t">but studied for the sake of understanding anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4493" target="_blank">01:14:53.760</a></span> | <span class="t">about how they work and how they fail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4495" target="_blank">01:14:55.440</a></span> | <span class="t">Yeah, any questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4499" target="_blank">01:14:59.440</a></span> | <span class="t">Has anyone tried benchmarking GPT for programming tasks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4511" target="_blank">01:15:11.240</a></span> | <span class="t">like how accurately it does, et cetera?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4513" target="_blank">01:15:13.920</a></span> | <span class="t">The question is, has anyone tried benchmarking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4516" target="_blank">01:15:16.320</a></span> | <span class="t">GPT for programming tasks?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4518" target="_blank">01:15:18.920</a></span> | <span class="t">Anyone seen how well it does?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4521" target="_blank">01:15:21.600</a></span> | <span class="t">Yes, so there's definitely examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4523" target="_blank">01:15:23.120</a></span> | <span class="t">of people using GPT-3 for simple programming things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4528" target="_blank">01:15:28.400</a></span> | <span class="t">And then the modern, state-of-the-art,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4530" target="_blank">01:15:30.920</a></span> | <span class="t">competitive programming bots are all based on ideas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4534" target="_blank">01:15:34.760</a></span> | <span class="t">from language modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4536" target="_blank">01:15:36.600</a></span> | <span class="t">And I think they're all also based on pre-trained language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4540" target="_blank">01:15:40.160</a></span> | <span class="t">models themselves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4541" target="_blank">01:15:41.160</a></span> | <span class="t">If you just take all of these ideas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4543" target="_blank">01:15:43.360</a></span> | <span class="t">and apply it to GitHub, then you get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4546" target="_blank">01:15:46.960</a></span> | <span class="t">some very interesting emergent behaviors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4548" target="_blank">01:15:48.720</a></span> | <span class="t">relating to code fallout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4550" target="_blank">01:15:50.920</a></span> | <span class="t">And so yeah, I think all of the best systems use this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4555" target="_blank">01:15:55.280</a></span> | <span class="t">more or less.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4556" target="_blank">01:15:56.160</a></span> | <span class="t">So lots of benchmarking there, for sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4558" target="_blank">01:15:58.840</a></span> | <span class="t">Is that the basis for what GitHub Copilot's trying to do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4562" target="_blank">01:16:02.680</a></span> | <span class="t">The question is, is this the basis?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4564" target="_blank">01:16:04.120</a></span> | <span class="t">Is what we just mentioned the basis for the GitHub Copilot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4567" target="_blank">01:16:07.080</a></span> | <span class="t">system?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4567" target="_blank">01:16:07.580</a></span> | <span class="t">Yes, absolutely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4570" target="_blank">01:16:10.320</a></span> | <span class="t">We don't know exactly what it is in terms of details,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4573" target="_blank">01:16:13.680</a></span> | <span class="t">but it's all these ideas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4576" target="_blank">01:16:16.080</a></span> | <span class="t">What if you have a situation where you have still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4578" target="_blank">01:16:18.640</a></span> | <span class="t">a large amount of data for general data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4581" target="_blank">01:16:21.000</a></span> | <span class="t">and then you have also a large amount of data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4583" target="_blank">01:16:23.280</a></span> | <span class="t">for your fine-tuning task?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4584" target="_blank">01:16:24.880</a></span> | <span class="t">At what point is it better to train a new model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4587" target="_blank">01:16:27.760</a></span> | <span class="t">for that fine-tuning versus get data from both?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4590" target="_blank">01:16:30.760</a></span> | <span class="t">Yeah, the question is, what if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4592" target="_blank">01:16:32.160</a></span> | <span class="t">have a large amount of data for pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4593" target="_blank">01:16:33.760</a></span> | <span class="t">and a large amount of data for fine-tuning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4595" target="_blank">01:16:35.560</a></span> | <span class="t">When is it better to do a separate training on just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4599" target="_blank">01:16:39.280</a></span> | <span class="t">the fine-tuning data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4601" target="_blank">01:16:41.880</a></span> | <span class="t">Almost never.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4603" target="_blank">01:16:43.240</a></span> | <span class="t">If you have a bunch of data for the task that you care about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4608" target="_blank">01:16:48.400</a></span> | <span class="t">what's frequently done instead is three-part training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4611" target="_blank">01:16:51.840</a></span> | <span class="t">where you pre-train on a very broad corpus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4614" target="_blank">01:16:54.720</a></span> | <span class="t">Then you continue to pre-train using something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4617" target="_blank">01:16:57.320</a></span> | <span class="t">like language modeling on an unlabeled version of the label</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4622" target="_blank">01:17:02.200</a></span> | <span class="t">data that you have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4623" target="_blank">01:17:03.280</a></span> | <span class="t">You just strip the labels off and just treat it all as text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4625" target="_blank">01:17:05.660</a></span> | <span class="t">and do language modeling on that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4627" target="_blank">01:17:07.560</a></span> | <span class="t">adapt the parameters a little bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4629" target="_blank">01:17:09.320</a></span> | <span class="t">and then do the final stage of fine-tuning with the labels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4632" target="_blank">01:17:12.360</a></span> | <span class="t">that you want, and that works even better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4634" target="_blank">01:17:14.240</a></span> | <span class="t">There's an interesting paper called Don't Stop Pre-Training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4639" target="_blank">01:17:19.280</a></span> | <span class="t">Nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4640" target="_blank">01:17:20.280</a></span> | <span class="t">Final question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4641" target="_blank">01:17:21.840</a></span> | <span class="t">We asked a lot of questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4643" target="_blank">01:17:23.920</a></span> | <span class="t">Anyone?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4644" target="_blank">01:17:24.420</a></span> | <span class="t">New?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4644" target="_blank">01:17:24.920</a></span> | <span class="t">New?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4645" target="_blank">01:17:25.420</a></span> | <span class="t">Someone new with a question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4646" target="_blank">01:17:26.720</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4647" target="_blank">01:17:27.220</a></span> | <span class="t">Yeah, I was wondering, do you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4652" target="_blank">01:17:32.800</a></span> | <span class="t">if there's a lot of instances where a pre-trained model can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4656" target="_blank">01:17:36.840</a></span> | <span class="t">do some task that's not seen before even without fine-tuning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4661" target="_blank">01:17:41.160</a></span> | <span class="t">Yeah, so are there any instances of where a pre-trained model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4663" target="_blank">01:17:43.700</a></span> | <span class="t">can do a task that it hasn't seen before without fine-tuning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4667" target="_blank">01:17:47.240</a></span> | <span class="t">The question is, what does hasn't seen before mean?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4670" target="_blank">01:17:50.960</a></span> | <span class="t">These models, especially GPT-3 and similar very large models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4675" target="_blank">01:17:55.280</a></span> | <span class="t">during pre-training, did it ever see something exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4678" target="_blank">01:17:58.320</a></span> | <span class="t">like this sort of word problem arithmetic?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4681" target="_blank">01:18:01.600</a></span> | <span class="t">Maybe, maybe not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4683" target="_blank">01:18:03.080</a></span> | <span class="t">It's actually sort of unclear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4685" target="_blank">01:18:05.080</a></span> | <span class="t">It's clearly able to recombine bits and pieces of tasks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4688" target="_blank">01:18:08.920</a></span> | <span class="t">that it saw implicitly during pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4691" target="_blank">01:18:11.360</a></span> | <span class="t">We saw the same thing with trivia.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4693" target="_blank">01:18:13.040</a></span> | <span class="t">Language modeling looks a lot like trivia sometimes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4695" target="_blank">01:18:15.520</a></span> | <span class="t">where you just read the first paragraph of a Wikipedia page,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4699" target="_blank">01:18:19.080</a></span> | <span class="t">and it's kind of like answering a bunch of little trivia</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4701" target="_blank">01:18:21.360</a></span> | <span class="t">questions about where someone was born and when.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4704" target="_blank">01:18:24.400</a></span> | <span class="t">But it's never seen something quite like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4706" target="_blank">01:18:26.480</a></span> | <span class="t">And it's actually still kind of astounding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4708" target="_blank">01:18:28.280</a></span> | <span class="t">how much it's able to do things that don't seem like they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4710" target="_blank">01:18:30.640</a></span> | <span class="t">should have shown up all that directly in the pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4713" target="_blank">01:18:33.040</a></span> | <span class="t">data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4713" target="_blank">01:18:33.920</a></span> | <span class="t">Quantifying that extent is an open research problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4717" target="_blank">01:18:37.480</a></span> | <span class="t">OK, that's it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4718" target="_blank">01:18:38.080</a></span> | <span class="t">Let's call it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4720" target="_blank">01:18:40.360</a></span> | <span class="t">Exactly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DGfCRXuNA2w&t=4721" target="_blank">01:18:41.920</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>