<html><head><title>Why GPT-4 is much smarter than it was a year ago – OpenAI cofounder John Schulman</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>Why GPT-4 is much smarter than it was a year ago – OpenAI cofounder John Schulman</h2><a href="https://www.youtube.com/watch?v=JclnqKZBTUU" target="_blank"><img src="https://i.ytimg.com/vi_webp/JclnqKZBTUU/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=JclnqKZBTUU&t=0 target="_blank"">0:0</a> Posttraining vs pretraining<br><a href="https://www.youtube.com/watch?v=JclnqKZBTUU&t=51 target="_blank"">0:51</a> ELO score<br><a href="https://www.youtube.com/watch?v=JclnqKZBTUU&t=100 target="_blank"">1:40</a> Posttraining<br><a href="https://www.youtube.com/watch?v=JclnqKZBTUU&t=219 target="_blank"">3:39</a> Intuitions<br><h3>Transcript</h3><div class='max-width'><p>would the fraction of compute that is spent on training that is free training versus post training change significantly in favor of post training in the future? Yeah, there are some arguments for that. I mean, right now it's a pretty lopsided ratio, but you could argue that the output generated by the model is like high quality compared to or higher quality than what most of what's on the web.</p><p>So it sort of makes more sense for the model to think by itself instead of just like training to imitate what's on the web. So I think there's a first principles argument for that. And I would say we found a lot of gains through post training. So I'm not sure.</p><p>So I would expect us to keep like pushing this methodology and probably increasing the amount of compute we put into it. The current GPT-4 has a ELO score that is like 100 points higher than the original one that was released. And is that all because of what you're talking about with these improvements that are brought on by post training?</p><p>Yeah, I would say that we've, I would say that most of that is post training. Interesting. So there are a lot of different separate axes for improvement. Like you can, yeah, so we think about like data quality, data quantity, just doing more iterations of the whole process of deploying and collecting new data and like changing what you're, what kind of annotations you're collecting.</p><p>So there's a lot of, a lot of things that stack up, but together they give you a pretty good like effective compute increase. How much of a moat is better post training? Currently companies that distinguish themselves by, well, how big is our model and so forth. Will it be a big moat who has figured out all the finickiness that you were talking about earlier with regards to all this data?</p><p>I think there's something of a moat because it's just a very complex operation. And there's, so it takes, you have to have a lot of skilled people doing it. And so there's a lot of tacit knowledge and there's a lot of organizational knowledge that's required. So, so I think, yeah, I think post-training like to create a model that actually like has all the need, the functionality people care about is pretty complicated.</p><p>It requires a pretty complicated effort. So, and this requires a lot of, this is basically an accumulation of a lot of R&D. So I would say, I would say that makes it somewhat of a moat that it's not trivial to spin this up immediately. It does seem like, like the same companies that are putting together the most serious pre-training efforts are also putting together the serious post-training efforts.</p><p>So it seems like it is somewhat, somewhat possible to copy or to, to spin up more of these efforts. There's also like one force that sort of makes it less of a moat is that you can like distill the models or you can take someone else's model and clone the outputs, or you can use someone else's model as a judge to like do comparisons.</p><p>So I think like the more big league people probably aren't doing that because it goes against terms of service policies, but, and it would also be a sort of hit to their pride, but I would expect some of the smaller players are doing that to get off the ground.</p><p>What makes for somebody who's really good at doing this sort of RR research? I hear it's super finicky, but like what, what is the sort of intuitions that you have that enable you to find these ways to mess with the data and set up these environments? I'd say I just have a decent amount of experience at this point from like the different parts of the stack from like RL algorithms, obviously, since I've worked on those since grad school, to like the data collection, like the annotation process, to like language, playing with language models.</p><p>So I mean, I'd say I just dabbled with these things and I'd say the people who do well at this kind of research have some view of the whole stack and have a lot of curiosity about the different parts of it. And also sort of think about, well, you want to be both empirical and like use experiment, let experiments update your views, but you also want to think from first principles somewhat like what like assuming that like learning works, like what would be the ideal type of data to collect and that sort of thing.</p><p>Thank you.</p></div></div></body></html>