<html><head><title>How to Train Your Agent: Building Reliable Agents with RL — Kyle Corbitt, OpenPipe</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>How to Train Your Agent: Building Reliable Agents with RL — Kyle Corbitt, OpenPipe</h2><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4"><img src="https://i.ytimg.com/vi_webp/gEDl9C8s_-4/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=0">0:0</a> Introduction to building reliable agents with RL.<br><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=49">0:49</a> Case Study: ART-E, an AI email assistant.<br><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=139">2:19</a> The importance of starting with prompted models before moving to RL.<br><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=197">3:17</a> Performance improvements of RL over prompted models.<br><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=318">5:18</a> Cost and latency benefits of the RL approach.<br><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=482">8:2</a> The two hardest problems in modern RL: realistic environments and reward functions.<br><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=793">13:13</a> Optimizing agent behavior with "extra rewards."<br><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=925">15:25</a> The problem of "reward hacking" and how to address it.<br><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1117">18:37</a> The solution to reward hacking<br><br><div style="text-align: left;"><a href="./gEDl9C8s_-4.html">Whisper Transcript</a> | <a href="./transcript_gEDl9C8s_-4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hey everyone, glad you're all here. This is the Reasoning and Reinforcement Learning Track</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=19" target="_blank">00:00:19.920</a></span> | <span class="t">on the afternoon of the last day of the AI Engineer World's Fair. Glad you're all here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=24" target="_blank">00:00:24.480</a></span> | <span class="t">glad you're sharing it with us. Today what I'm going to talk about is a very specific case study</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=29" target="_blank">00:00:29.880</a></span> | <span class="t">that we did. This case study I'm going to talk about lessons learned very concretely,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=33" target="_blank">00:00:33.960</a></span> | <span class="t">what did and didn't work, how we were able to build an agent that worked well with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=36" target="_blank">00:00:36.900</a></span> | <span class="t">Reinforcement Learning, all of this, everything that I'm talking about in this presentation. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=41" target="_blank">00:00:41.160</a></span> | <span class="t">is an open source code base that we built. We wanted to share these learnings and I'll share</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=46" target="_blank">00:00:46.680</a></span> | <span class="t">that link with you at the end as well for those of you who want to replicate what we did. So what is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=52" target="_blank">00:00:52.080</a></span> | <span class="t">the project we're going to be talking about? It's a project called ARTE. It is a natural language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=56" target="_blank">00:00:56.880</a></span> | <span class="t">assistant that helps you answer questions from your email inbox. So I'll give you an example of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=62" target="_blank">00:01:02.640</a></span> | <span class="t">what we're talking about here. Let's say you want to ask, you know, in this case our example question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=68" target="_blank">00:01:08.080</a></span> | <span class="t">is when is Sherry's move to Portland targeted for? So you would ask this question to the assistant,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=72" target="_blank">00:01:12.000</a></span> | <span class="t">it then goes and it searches your inbox. It's got several tools, so it has like a search tool,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=75" target="_blank">00:01:15.520</a></span> | <span class="t">it has a read email tool, and then it can actually answer the final question. You can kind of see if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=79" target="_blank">00:01:19.920</a></span> | <span class="t">if you look here what's going on behind the scenes. This is important so you get a sense of kind of how this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=84" target="_blank">00:01:24.240</a></span> | <span class="t">agent works and as we're talking through how we built it, how we made it work, hopefully that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=88" target="_blank">00:01:28.160</a></span> | <span class="t">that helps make the conversation very grounded in a specific task. So anyway, you see the agent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=92" target="_blank">00:01:32.960</a></span> | <span class="t">it's it's you know searching for certain keywords, it gets those messages back, it's in reading one of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=97" target="_blank">00:01:37.920</a></span> | <span class="t">them and answering the question. That's that's what it does. Okay, so question, you know, once we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=105" target="_blank">00:01:45.040</a></span> | <span class="t">decided this is kind of the task we're trying to solve, why would you reuse reinforcement learning for this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=110" target="_blank">00:01:50.000</a></span> | <span class="t">specifically? And the answer is like to start with you shouldn't. In fact, to start off with we did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=115" target="_blank">00:01:55.920</a></span> | <span class="t">not. So the first version of this agent, once we decided we wanted to build this, we didn't use any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=120" target="_blank">00:02:00.960</a></span> | <span class="t">reinforcement learning at all, we purely built this on prompted models. And this is the first lesson</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=125" target="_blank">00:02:05.280</a></span> | <span class="t">from this talk that I want to share is I would generally always recommend starting with getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=130" target="_blank">00:02:10.480</a></span> | <span class="t">the best performance you can with a prompted model before going to any training, including reinforcement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=134" target="_blank">00:02:14.960</a></span> | <span class="t">learning. There's a few different reasons to do that three in specifically. The first one is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=140" target="_blank">00:02:20.480</a></span> | <span class="t">like working out the bugs in your environment, right? You know, maybe your tools aren't implemented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=144" target="_blank">00:02:24.400</a></span> | <span class="t">properly, maybe they don't have access to the data you think they do. We find this happens a lot,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=149" target="_blank">00:02:29.440</a></span> | <span class="t">and it's a lot less frustrating to debug that, you know, separately from debugging your your training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=154" target="_blank">00:02:34.400</a></span> | <span class="t">loop. So you want to make sure that like you can get at least some kind of performance before you start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=158" target="_blank">00:02:38.080</a></span> | <span class="t">training. And then second of all, you may find as you're trying to improve the performance on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=163" target="_blank">00:02:43.120</a></span> | <span class="t">using these prompted models that you can get it working really well. And that's great. So that means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=167" target="_blank">00:02:47.760</a></span> | <span class="t">you don't need to train anything. And that saves you a lot of time. There's a third reason as well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=172" target="_blank">00:02:52.640</a></span> | <span class="t">that I'll share, which is basically once you've gone to that effort, you've done your best to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=177" target="_blank">00:02:57.840</a></span> | <span class="t">the best quality prompted baselines you possibly can. Then if you find that those baselines are not able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=184" target="_blank">00:03:04.240</a></span> | <span class="t">to get you where you need to go, and you're able to surpass them with reinforcement learning, it feels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=187" target="_blank">00:03:07.840</a></span> | <span class="t">great. You get to gloat and be like, yes, I was able to beat the the frontier models on my task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=191" target="_blank">00:03:11.440</a></span> | <span class="t">I highly recommend it. It feels good. You can post on X about it. There's nice graphs and stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=197" target="_blank">00:03:17.760</a></span> | <span class="t">So this is what it looks like when everything goes right. So this is an example of a training run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=204" target="_blank">00:03:24.320</a></span> | <span class="t">for this RTE model that I'm going to be talking about. You can see that there's these lines for each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=209" target="_blank">00:03:29.440</a></span> | <span class="t">of the prompted model baselines that we've got. So we've got 03, 04 mini, and then Gemini and 4.1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=215" target="_blank">00:03:35.360</a></span> | <span class="t">And you can see those ones, you know, they have certain level performance. And then you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=220" target="_blank">00:03:40.080</a></span> | <span class="t">this this sort of moving line that's going on. This is the model that we trained. And you can see it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=225" target="_blank">00:03:45.520</a></span> | <span class="t">actually starts out significantly worse than these other models from from the start. That's because we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=229" target="_blank">00:03:49.520</a></span> | <span class="t">started from a Quen 2.5, the 14 billion parameter one. It's a relatively small model, relatively weak</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=235" target="_blank">00:03:55.360</a></span> | <span class="t">model. And so it was doing much worse than these initially. But you can see as training progresses,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=239" target="_blank">00:03:59.840</a></span> | <span class="t">you know, initially at the beginning, it's sort of maybe it's learning the right way to do tool calls.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=245" target="_blank">00:04:05.360</a></span> | <span class="t">There's a very sharp bump as it figures out the basic stuff, and then a more gradual climb until</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=249" target="_blank">00:04:09.600</a></span> | <span class="t">eventually it's able to significantly outperform any of the prompted models on this task. And this is sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=255" target="_blank">00:04:15.040</a></span> | <span class="t">of what you're, you know, in the ideal case, when everything works, this is what you're looking for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=258" target="_blank">00:04:18.560</a></span> | <span class="t">This is what you're hoping to achieve. This is another view actually of that same data we were just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=264" target="_blank">00:04:24.640</a></span> | <span class="t">looking at. I like, I wanted to highlight it in this way, because it's important to realize. So on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=270" target="_blank">00:04:30.320</a></span> | <span class="t">last graph, it looked like the lines sort of asymptote out pretty close together. That's because they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=274" target="_blank">00:04:34.400</a></span> | <span class="t">getting near 100%. But the last, you can see, for example, with our best prompted model here, 03,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=280" target="_blank">00:04:40.560</a></span> | <span class="t">it's 90% accuracy. And with our RL model, we're able to get up to 96%. And so one way to think about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=287" target="_blank">00:04:47.520</a></span> | <span class="t">that is like 60% of the errors that 03 was making are actually solved with our model, which is quite a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=295" target="_blank">00:04:55.120</a></span> | <span class="t">large, you know, we find that that's actually can be very, very important for the user experience of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=299" target="_blank">00:04:59.840</a></span> | <span class="t">someone using one of these. If you're getting, you know, just half as many errors, that can make the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=304" target="_blank">00:05:04.320</a></span> | <span class="t">product much stronger. So this is where we got to an accuracy. There's a couple other metrics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=310" target="_blank">00:05:10.480</a></span> | <span class="t">that we find are often very, very important. And you know, the tradeoff between these does is very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=316" target="_blank">00:05:16.800</a></span> | <span class="t">task dependent, but they matter in many cases. Cost, obviously, is a big one. So for this email,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=323" target="_blank">00:05:23.680</a></span> | <span class="t">agentic harness that we had, we benchmarked the cost on 03, 04 mini, and our model. So if you wanted to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=329" target="_blank">00:05:29.760</a></span> | <span class="t">do like 1000 searches using 03, that's going to cost $55, which is a lot, I think for most use cases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=336" target="_blank">00:05:36.720</a></span> | <span class="t">that probably would be cost prohibitive, just from a unit economics point of view. On</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=340" target="_blank">00:05:40.400</a></span> | <span class="t">04 mini, we're down to $8, but that's still quite expensive. And then we drop another order of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=344" target="_blank">00:05:44.560</a></span> | <span class="t">magnitude by moving to this smaller Quen 2.5 14b. Again, this is just driven by it being a much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=349" target="_blank">00:05:49.840</a></span> | <span class="t">smaller model. So it's much cheaper to run. But we're still able to get very good performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=353" target="_blank">00:05:53.840</a></span> | <span class="t">because we've specialized it on our task. Beyond cost and the accuracy, the third metric that often</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=360" target="_blank">00:06:00.480</a></span> | <span class="t">comes up is latency, particularly if you're doing, I mean, certainly anything with voice. But if there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=365" target="_blank">00:06:05.520</a></span> | <span class="t">any real-time human interaction with the task, latency is going to matter a lot. And we were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=371" target="_blank">00:06:11.040</a></span> | <span class="t">able to find on this task, we were able to get significantly better latency. There's a number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=375" target="_blank">00:06:15.120</a></span> | <span class="t">of different ways, which I'll go into in more detail later, that we were able to achieve this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=378" target="_blank">00:06:18.320</a></span> | <span class="t">One was just, again, moving to a smaller model helps. There's just less loading from memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=383" target="_blank">00:06:23.440</a></span> | <span class="t">less matrix multiplies. It's just you're able to get tokens out faster. We were also able to train this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=388" target="_blank">00:06:28.080</a></span> | <span class="t">model to have fewer turns going back and forth with the database, with the actual email, the list of emails. We were able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=395" target="_blank">00:06:35.440</a></span> | <span class="t">train it to be more efficient with its queries. And I'll go into that in a moment. And so that leads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=400" target="_blank">00:06:40.160</a></span> | <span class="t">to lower latency. There's actually a third thing, which we didn't apply here, but can help a lot with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=404" target="_blank">00:06:44.160</a></span> | <span class="t">these smaller things, which is called speculative decoding. That's something you can do on large or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=407" target="_blank">00:06:47.760</a></span> | <span class="t">small models. It generally works better on smaller task-specific models because you get higher acceptance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=412" target="_blank">00:06:52.800</a></span> | <span class="t">rates on your speculator. But basically, there's lots of reasons why smaller models work better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=416" target="_blank">00:06:56.720</a></span> | <span class="t">Okay, so then the next question, for those of you who haven't done this yet, is like, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=422" target="_blank">00:07:02.640</a></span> | <span class="t">what is the effort required to do this to actually achieve these results?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=427" target="_blank">00:07:07.360</a></span> | <span class="t">If you'd asked me this question a year ago, I would say, "Hey, you should really only be doing this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=431" target="_blank">00:07:11.360</a></span> | <span class="t">if you're this big company and willing to put months of work into a project."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=435" target="_blank">00:07:15.360</a></span> | <span class="t">I think that's changing. I honestly do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=437" target="_blank">00:07:17.360</a></span> | <span class="t">In this case, so this training run, it cost us about $80 in GPU time. It did take about a week of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=444" target="_blank">00:07:24.080</a></span> | <span class="t">engineering time to build this. And caveat that was with an engineer who is familiar with this domain and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=448" target="_blank">00:07:28.560</a></span> | <span class="t">had quite a lot of experience with machine learning and RL. But I actually expect, as we figure out the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=454" target="_blank">00:07:34.640</a></span> | <span class="t">right patterns here, collectively as an industry, this will keep dropping. And I expect that the sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=460" target="_blank">00:07:40.080</a></span> | <span class="t">payback period to get a return on investment from these specialized bottles is actually going to continue</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=464" target="_blank">00:07:44.800</a></span> | <span class="t">falling as well. And part of the reason I wanted to give this talk is to sort of distribute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=471" target="_blank">00:07:51.200</a></span> | <span class="t">the knowledge we learned and hopefully move faster towards that world where this is just sort of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=475" target="_blank">00:07:55.840</a></span> | <span class="t">a thing everyone knows how to do and it's very easy and very fast. So that's what we'll be talking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=480" target="_blank">00:08:00.560</a></span> | <span class="t">about for the rest of the time is some more of the lessons we learned. Okay, so when you are using RL</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=488" target="_blank">00:08:08.880</a></span> | <span class="t">to train an agent or really using RL for anything else, I find that consistently with different problems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=494" target="_blank">00:08:14.320</a></span> | <span class="t">we look at, there are sort of two hard problems that come up every single time, all right? And the two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=499" target="_blank">00:08:19.200</a></span> | <span class="t">hard problems are, first of all, figuring out a realistic environment, right? So if you're training an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=503" target="_blank">00:08:23.840</a></span> | <span class="t">agent, you need to be training it with realistic data, with realistic inputs and outputs, tools available,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=509" target="_blank">00:08:29.520</a></span> | <span class="t">everything like that to how it's going to be used in production. Because if you don't, then it's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=514" target="_blank">00:08:34.160</a></span> | <span class="t">to be optimizing for the wrong thing and you won't get the results you want when you deploy it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=517" target="_blank">00:08:37.280</a></span> | <span class="t">And then the second thing, which sometimes is hard, sometimes isn't, this one is a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=522" target="_blank">00:08:42.080</a></span> | <span class="t">task dependent, is getting the right reward function. So reward function, that just means you have to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=526" target="_blank">00:08:46.880</a></span> | <span class="t">able to know when your agent's gone through and say in this case, give it an answer to my email,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=530" target="_blank">00:08:50.960</a></span> | <span class="t">you have to have some way of knowing did it do a good job or a bad job, all right? That's the reward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=534" target="_blank">00:08:54.880</a></span> | <span class="t">function, it decides, it's how you decide if it's good or it's bad. Some, depending on the domain,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=540" target="_blank">00:09:00.560</a></span> | <span class="t">sometimes that's really easy. We have, I don't know if Nathan's here, he's going to be talking next,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=544" target="_blank">00:09:04.000</a></span> | <span class="t">but you know, he and his team put together this thing called RLVR, which in some verifiable domains,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=548" target="_blank">00:09:08.400</a></span> | <span class="t">it's actually very easy to do a reward. Oftentimes, not all domains are like that. Oftentimes, it is kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=554" target="_blank">00:09:14.720</a></span> | <span class="t">of hard. And so it's somewhat task dependent. I'm going to go through how we solve these problems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=559" target="_blank">00:09:19.360</a></span> | <span class="t">specifically with RE. Okay, first one, realistic environment. So for our RE task, what is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=565" target="_blank">00:09:25.280</a></span> | <span class="t">environment we need? What's the environment this agent's going to be operating in? Well, it needs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=568" target="_blank">00:09:28.960</a></span> | <span class="t">these tools available, it needs to be able to go and query an email inbox, it needs to be able to like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=572" target="_blank">00:09:32.320</a></span> | <span class="t">get emails back, and that look realistic. These emails, you know, the inbox should be large,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=577" target="_blank">00:09:37.760</a></span> | <span class="t">because that's what most email inboxes are like. The emails in it should be diverse, and they have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=582" target="_blank">00:09:42.080</a></span> | <span class="t">look kind of like real emails. So this could be kind of hard, because you can't just go ask like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=587" target="_blank">00:09:47.280</a></span> | <span class="t">a 1000 people to, you know, give you their personal emails to train on. Luckily, in this case, we were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=593" target="_blank">00:09:53.120</a></span> | <span class="t">able to solve this with the help of a company that has contributed a lot to just the open data ecosystem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=598" target="_blank">00:09:58.080</a></span> | <span class="t">Generally, it's like a quite an iconic company, perhaps I would call it a historic company. I'm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=603" target="_blank">00:10:03.520</a></span> | <span class="t">of course, talking about Enron. I'm hearing some laughter. So anyway, Enron was a there were a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=611" target="_blank">00:10:11.520</a></span> | <span class="t">financialized energy company in the 90s and 2000s, committed massive fraud, ended up getting shut down by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=616" target="_blank">00:10:16.720</a></span> | <span class="t">Department of Justice. As part of this, you know, process, the court cases they were going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=622" target="_blank">00:10:22.560</a></span> | <span class="t">through, a dump of like 500,000 of their emails was released to the public as part of the discovery</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=626" target="_blank">00:10:26.880</a></span> | <span class="t">process. So that's, that's, that's great for things like this. And that's what we used as our environment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=631" target="_blank">00:10:31.840</a></span> | <span class="t">for the email inboxes. All right, so now we've got realistic email inboxes with tens of thousands of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=637" target="_blank">00:10:37.440</a></span> | <span class="t">emails that are real emails back and forth. Now we have to design our reward function. So as our agent is going,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=642" target="_blank">00:10:42.800</a></span> | <span class="t">and as our agent is, you know, we're asking it questions, and then it's giving us answers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=647" target="_blank">00:10:47.760</a></span> | <span class="t">we have to know is the answer correct or not, so we can reward it when it gets the answer right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=651" target="_blank">00:10:51.440</a></span> | <span class="t">and it can learn to do that better. There's different ways, and this part is very task dependent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=656" target="_blank">00:10:56.960</a></span> | <span class="t">The way that we went about it in this case, was we basically turned it into a more of a verifiable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=664" target="_blank">00:11:04.320</a></span> | <span class="t">problem. And the way we did that was, we actually took our email inbox, we sort of inverted the problem,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=668" target="_blank">00:11:08.640</a></span> | <span class="t">we, we grabbed batches of 20 emails at a time, from the inbox, and gave them to Gemini 2.5 Pro,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=675" target="_blank">00:11:15.680</a></span> | <span class="t">and said, hey, given this set of emails, give us a few questions that a user might realistically ask,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=680" target="_blank">00:11:20.880</a></span> | <span class="t">that the answers are found in this email, right? And so Gemini generated the questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=685" target="_blank">00:11:25.280</a></span> | <span class="t">it generated the answers, and then of course, the source emails that came from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=688" target="_blank">00:11:28.480</a></span> | <span class="t">And there were some extra steps on top of that, a lot of the questions it came up with looked a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=692" target="_blank">00:11:32.720</a></span> | <span class="t">bit unrealistic, we had a separate filtering step, where we're like, okay, let's find the subset of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=696" target="_blank">00:11:36.560</a></span> | <span class="t">that actually look like questions that, you know, I would maybe ask. And we ended up with a list of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=701" target="_blank">00:11:41.120</a></span> | <span class="t">a few thousand questions, along with their verified answers. And so at this point, it becomes much more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=707" target="_blank">00:11:47.520</a></span> | <span class="t">of a sort of verified thing, the reward function becomes much easier, because we know what the correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=712" target="_blank">00:11:52.000</a></span> | <span class="t">answer should be. And so the way we can tell if our agent did a good job, is we give our agent the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=716" target="_blank">00:11:56.720</a></span> | <span class="t">question, we let it go and search the email inbox, and try and find the right emails and everything,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=720" target="_blank">00:12:00.000</a></span> | <span class="t">and eventually comes back with an answer. And then we can just use an LLM as judge, a very simple one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=724" target="_blank">00:12:04.560</a></span> | <span class="t">and say like, hey, you know, here's the question, here's the golden answer that we believe is right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=729" target="_blank">00:12:09.200</a></span> | <span class="t">here's the answer we got from our model, is it right or not. We did have to do a little bit of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=734" target="_blank">00:12:14.320</a></span> | <span class="t">iteration there, making sure that the judge was well calibrated on what counts as correct or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=740" target="_blank">00:12:20.000</a></span> | <span class="t">But by and large, this worked pretty well, and was able to make this more of a verified task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=746" target="_blank">00:12:26.080</a></span> | <span class="t">So that's how we solved the reward function problem was by having that, you know, turning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=750" target="_blank">00:12:30.080</a></span> | <span class="t">this into something where we had more of a golden data set. Okay, so once you've solved that problem,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=755" target="_blank">00:12:35.200</a></span> | <span class="t">those problems, once you have your environment, once you have your reward function defined,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=760" target="_blank">00:12:40.160</a></span> | <span class="t">then basically, you just kind of have to run a loop over and over and over again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=763" target="_blank">00:12:43.840</a></span> | <span class="t">where you have your agent go through and it tries to solve the problem, and then you figure out if it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=769" target="_blank">00:12:49.120</a></span> | <span class="t">good or it's bad, and then you just, you know, reward if it's good, and punish if it's bad, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=775" target="_blank">00:12:55.120</a></span> | <span class="t">that's it. And you do this over and over and over again, and then hopefully, if you've got everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=780" target="_blank">00:13:00.800</a></span> | <span class="t">set up right, it learns what good looks like, it learns what bad looks like, and it starts doing it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=786" target="_blank">00:13:06.480</a></span> | <span class="t">right. And then again, this is this is the curve we saw earlier, where you can see it, it starts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=791" target="_blank">00:13:11.520</a></span> | <span class="t">getting better over time. Okay, a few other like interesting learnings from this project. One thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=798" target="_blank">00:13:18.800</a></span> | <span class="t">is, we found that there's actually, you can throw a lot of stuff into your reward function, beyond just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=804" target="_blank">00:13:24.960</a></span> | <span class="t">the primary thing you're trying to solve for. And so we actually ended up, there were like sort of eight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=809" target="_blank">00:13:29.600</a></span> | <span class="t">different little things that we gave extra credit for. I'm going to share two of them here. So the first one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=814" target="_blank">00:13:34.960</a></span> | <span class="t">here is, is we're trying to have it optimized for the number of turns, how many times back and forth,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=820" target="_blank">00:13:40.480</a></span> | <span class="t">how many times it had to query the email inbox, before it came up with the right answer, right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=824" target="_blank">00:13:44.720</a></span> | <span class="t">So because the most important thing, of course, is getting the answer right. But between two answers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=828" target="_blank">00:13:48.880</a></span> | <span class="t">that both get it right, we would rather it took fewer turns back and forth, because that's fewer tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=833" target="_blank">00:13:53.200</a></span> | <span class="t">that's lower latency, lower costs, it's just like a more efficient agent. So you can see here on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=839" target="_blank">00:13:59.280</a></span> | <span class="t">first graph that early on, while it was getting its feet wet and figuring out what worked, it ended up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=844" target="_blank">00:14:04.480</a></span> | <span class="t">spiking up to over six turns on average. So it would go back and forth a bunch of times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=848" target="_blank">00:14:08.480</a></span> | <span class="t">with the email inbox and try and find the right thing. But then once it was able to like, figure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=853" target="_blank">00:14:13.120</a></span> | <span class="t">out how to use the tools efficiently, figure out like, you know, the right way to construct keywords</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=857" target="_blank">00:14:17.280</a></span> | <span class="t">and find the right email, it was able to get very efficient and actually fast, better than any of our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=861" target="_blank">00:14:21.680</a></span> | <span class="t">prompted models on this metric of using fewer turns. And again, this was just because we gave it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=866" target="_blank">00:14:26.000</a></span> | <span class="t">a little bit of extra, it was it was a very small amount relative to the reward for getting it right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=870" target="_blank">00:14:30.720</a></span> | <span class="t">but a little bit of extra credit on using for fewer turns, and it was able to use that to optimize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=876" target="_blank">00:14:36.880</a></span> | <span class="t">against that. Another extra reward function we gave it is to try and discourage it from hallucinating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=882" target="_blank">00:14:42.960</a></span> | <span class="t">answers. So obviously, the best thing is to get the right answer. If you can't find the right answer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=888" target="_blank">00:14:48.400</a></span> | <span class="t">it's much better to say, hey, I don't know than to make up an answer in a situation like this. So we basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=894" target="_blank">00:14:54.160</a></span> | <span class="t">penalized it if if the reward model said, hey, you got the answer wrong, and but it had tried to give an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=900" target="_blank">00:15:00.320</a></span> | <span class="t">answer, give an answer, that was like a much lower reward than if it just said, hey, I don't know, I can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=905" target="_blank">00:15:05.120</a></span> | <span class="t">solve this problem. And as you can see, that worked quite well, compared to any of the prompted models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=908" target="_blank">00:15:08.880</a></span> | <span class="t">including O3, we ended up with a significantly lower hallucination rate, because that was part of our reward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=914" target="_blank">00:15:14.400</a></span> | <span class="t">function. Again, these are these are things that are just sort of like extra credit. But we found that like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=919" target="_blank">00:15:19.040</a></span> | <span class="t">you can throw in a bunch of these, and it cannot jointly optimize all of them at the same time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=923" target="_blank">00:15:23.200</a></span> | <span class="t">which is super powerful. Okay, I want to talk a little bit about reward hacking. It's something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=929" target="_blank">00:15:29.280</a></span> | <span class="t">that comes up a lot when you're trying to do this. And it's kind of a fun thing to talk about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=932" target="_blank">00:15:32.320</a></span> | <span class="t">This is an iconic video some of you might have seen. This was released by OpenAI almost a decade ago at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=937" target="_blank">00:15:37.920</a></span> | <span class="t">this point of they were they were trying to, they had this environment where you were trying to get this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=943" target="_blank">00:15:43.280</a></span> | <span class="t">boat to complete a race. And instead of learning to complete compute, complete the race, it learned that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=947" target="_blank">00:15:47.920</a></span> | <span class="t">oh, if I just go in this like little circle, that's not even part of the race track, I can like just get a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=951" target="_blank">00:15:51.360</a></span> | <span class="t">bunch of points. And so I just started doing that over and over and over again, instead of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=955" target="_blank">00:15:55.520</a></span> | <span class="t">actually following. This is something that comes up a lot if you're doing reinforcement learning. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=960" target="_blank">00:16:00.400</a></span> | <span class="t">it's basically just the difference between the difference between what you actually want the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=966" target="_blank">00:16:06.720</a></span> | <span class="t">model to do and what you can measure, like what you're actually rewarding it for. And and if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=971" target="_blank">00:16:11.440</a></span> | <span class="t">almost always if you let one of these run long enough, it will figure out some way to exploit your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=975" target="_blank">00:16:15.920</a></span> | <span class="t">measure. And it will figure out some way to to get a really high reward without actually solving the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=981" target="_blank">00:16:21.280</a></span> | <span class="t">problem. And you need to just watch for that. So I'm going to give a couple examples here. This is a this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=985" target="_blank">00:16:25.840</a></span> | <span class="t">is a graph from another project, actually, not this one. So an engineer on our team was was working on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=992" target="_blank">00:16:32.080</a></span> | <span class="t">game called NYT Connections. Some of you might know, you get 16 words, and you have to put them in like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=996" target="_blank">00:16:36.720</a></span> | <span class="t">four groups of four. It's quite a challenging game, especially for these language models, because it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1001" target="_blank">00:16:41.040</a></span> | <span class="t">requires a lot of world knowledge and like, you know, lateral thinking anyway. So they were trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1006" target="_blank">00:16:46.080</a></span> | <span class="t">train this model to do it. And it wasn't figuring out wasn't figured out what it wasn't figuring out. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1010" target="_blank">00:16:50.320</a></span> | <span class="t">then boom, you can see here around step 40, it just like takes off. And it's like, okay, we figured out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1014" target="_blank">00:16:54.000</a></span> | <span class="t">how to how to solve this. And this engineer, I'm gonna I'm gonna call out where's where's on our team?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1018" target="_blank">00:16:58.960</a></span> | <span class="t">He's here at the conference. Yeah, he's great. You should talk to him after. But he was like, hey, we solved it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1023" target="_blank">00:17:03.280</a></span> | <span class="t">like we got NYT Connections and like, and it's like, okay, the graph looks good. Let's look at what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1027" target="_blank">00:17:07.280</a></span> | <span class="t">it's actually doing. What it was actually doing is it figured out there was a bug in how we wrote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1032" target="_blank">00:17:12.320</a></span> | <span class="t">the verification. And if it just put every single word in every single category, it was able to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1036" target="_blank">00:17:16.720</a></span> | <span class="t">a perfect score. Because we weren't verifying that they were in fact, only four words in each category.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1042" target="_blank">00:17:22.400</a></span> | <span class="t">So this is another example. This is a fun one. So I was I was training a model to produce really good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1048" target="_blank">00:17:28.800</a></span> | <span class="t">titles for hacker news, titles that would get a thing upvoted. So I had this reward model I'd trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1053" target="_blank">00:17:33.840</a></span> | <span class="t">on like existing hacker news articles and how many upvotes they got. And I was I was trying to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1058" target="_blank">00:17:38.400</a></span> | <span class="t">this model to produce new titles. And it was working really well for a while, you can see and sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1063" target="_blank">00:17:43.120</a></span> | <span class="t">subjectively as well, I looked at a bunch of these these titles generated and for these first like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1067" target="_blank">00:17:47.280</a></span> | <span class="t">1000 steps or so, it was actually learning things that I was like, okay, as someone who spends way too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1072" target="_blank">00:17:52.080</a></span> | <span class="t">much time on hacker news, yeah, that that does look like a good title, you're doing a good job. And then you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1076" target="_blank">00:17:56.240</a></span> | <span class="t">around step 1200 here, it just like jumps a bunch, right? It's like, okay, it clearly figured something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1081" target="_blank">00:18:01.920</a></span> | <span class="t">out. I don't know what it figured out. But we should look at that. And so what it turns out what the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1088" target="_blank">00:18:08.720</a></span> | <span class="t">model had figured out was that it could just completely ignore the content of the post and generate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1094" target="_blank">00:18:14.240</a></span> | <span class="t">same title for every single one of them. And that would like maximize its score. So it generated this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1098" target="_blank">00:18:18.640</a></span> | <span class="t">title Google lays off 80% of workforce, literally every single article this was this was what it labeled it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1104" target="_blank">00:18:24.000</a></span> | <span class="t">as and when the remote was like, yes, that is going to get up on hacker news for sure,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1107" target="_blank">00:18:27.520</a></span> | <span class="t">which which it probably would to be fair.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1109" target="_blank">00:18:29.680</a></span> | <span class="t">So anyway, the way the way we solve this, what we found is that it's really important to watch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1116" target="_blank">00:18:36.640</a></span> | <span class="t">out for this. Solving it typically involves modifying in some way your reward function to penalize things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1123" target="_blank">00:18:43.600</a></span> | <span class="t">like that. So in the second example I talked about, it was actually quite an easy fix once we identified it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1128" target="_blank">00:18:48.480</a></span> | <span class="t">which was just add an extra LMS judge that looked at the title, looked at the content and said, hey,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1132" target="_blank">00:18:52.960</a></span> | <span class="t">is there anything in the title that's not supported by the content? And we added that on and it actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1137" target="_blank">00:18:57.120</a></span> | <span class="t">worked great. The important thing here is you want to be looking at your your rollouts, not just blindly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1142" target="_blank">00:19:02.000</a></span> | <span class="t">trusting the reward function, figuring out what's actually happening. Anyway, so that's it. I'm almost out of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1148" target="_blank">00:19:08.880</a></span> | <span class="t">time. So I'm going to stop a couple of QR codes for you. Everything in this presentation and there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1154" target="_blank">00:19:14.480</a></span> | <span class="t">a much longer write up I have of this whole project. It includes the code, it includes the artifacts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1159" target="_blank">00:19:19.040</a></span> | <span class="t">data sets along the way. You can you can check that out there. One more thing is we have a discord that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1165" target="_blank">00:19:25.920</a></span> | <span class="t">open. We have an open source project for training reinforcement learning models. We have a discord you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1170" target="_blank">00:19:30.880</a></span> | <span class="t">can go to if you're interested in this kind of thing. We were all in there. We answer questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1175" target="_blank">00:19:35.440</a></span> | <span class="t">There's lots of people from the community trying to do these things. So if if you're interested in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1179" target="_blank">00:19:39.440</a></span> | <span class="t">building things with this, feel free to join it. And yeah, happy happy to chat there. And yes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=gEDl9C8s_-4&t=1184" target="_blank">00:19:44.080</a></span> | <span class="t">thank you everyone. Appreciate your time.</span></div></div></body></html>