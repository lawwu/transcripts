<html><head><title>Detecting Driver Frustration from Audio and Video (IJCAI 2016)</title></head><body>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    <a href="index.html">back to index</a><h2>Detecting Driver Frustration from Audio and Video (IJCAI 2016)</h2><a href="https://www.youtube.com/watch?v=wiYMwmPPGto"><img src="https://i.ytimg.com/vi_webp/wiYMwmPPGto/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./wiYMwmPPGto.html">Whisper Transcript</a> | <a href="./transcript_wiYMwmPPGto.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=0">00:00:00.000</a></span> | <span class="t">This video accompanies our paper presented at IJCAI, the International Joint Conference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=5">00:00:05.720</a></span> | <span class="t">on Artificial Intelligence, where we propose a system for detecting driver frustration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=12">00:00:12.120</a></span> | <span class="t">from the fusion of two data streams, first the audio of the driver's voice and second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=18">00:00:18.000</a></span> | <span class="t">the video of the driver's face.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=22">00:00:22.160</a></span> | <span class="t">Let's ask an illustrative question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=25">00:00:25.000</a></span> | <span class="t">These are video snapshots of two drivers using the in-car voice-based navigation system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=31">00:00:31.840</a></span> | <span class="t">Which one of them looks more frustrated with the interaction?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=36">00:00:36.760</a></span> | <span class="t">To help answer that question, let's take a look at an example interaction involving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=41">00:00:41.200</a></span> | <span class="t">the driver on the right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=43">00:00:43.900</a></span> | <span class="t">Our proposed approach uses the audio of the driver's voice when the "human" is speaking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=50">00:00:50.120</a></span> | <span class="t">and the video of the driver's face when he is listening to the machine speak.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=57">00:00:57.640</a></span> | <span class="t">What you are seeing and hearing is the driver attempting to instruct the car's voice-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=61">00:01:01.760</a></span> | <span class="t">navigation system to navigate to 177 Massachusetts Ave, Cambridge, Massachusetts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=69">00:01:09.800</a></span> | <span class="t">177 Massachusetts Ave, Cambridge, Massachusetts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=84">00:01:24.840</a></span> | <span class="t">Man of the above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=91">00:01:31.840</a></span> | <span class="t">177 Massachusetts Ave, Cambridge, Massachusetts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=115">00:01:55.840</a></span> | <span class="t">Man of the above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=122">00:02:02.840</a></span> | <span class="t">Man of the above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=128">00:02:08.840</a></span> | <span class="t">Cambridge, Massachusetts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=140">00:02:20.840</a></span> | <span class="t">So there is your answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=142">00:02:22.680</a></span> | <span class="t">On a scale of 1 to 10, with 1 being completely satisfied and 10 being completely frustrated,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=148">00:02:28.680</a></span> | <span class="t">the smiling driver reported his frustration level with this interaction to be a 9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=155">00:02:35.540</a></span> | <span class="t">We use self-reported level of frustration as the ground truth for the binary classification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=160">00:02:40.300</a></span> | <span class="t">of satisfied versus frustrated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=165">00:02:45.320</a></span> | <span class="t">When the driver is speaking, we extract the Geneva Minimalistic Acoustic Parameter Set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=170">00:02:50.600</a></span> | <span class="t">(GMAPS) features from their voice which measures basic physiological changes in voice production.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=178">00:02:58.520</a></span> | <span class="t">When the driver is listening, we extract 14 facial actions using the AFDEX system from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=183">00:03:03.920</a></span> | <span class="t">the video of the driver's face.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=186">00:03:06.840</a></span> | <span class="t">The classified decisions are fused together to produce an accuracy of 88.5% on an on-road</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=193">00:03:13.380</a></span> | <span class="t">data set of 20 subjects.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=198">00:03:18.080</a></span> | <span class="t">There are two takeaways from this work that may go beyond just detecting driver frustration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=203">00:03:23.320</a></span> | <span class="t">First, self-reported emotion state may be very different than one assigned by a group</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=209">00:03:29.480</a></span> | <span class="t">of external annotators, so we have to be careful when using such annotations as the ground</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=215">00:03:35.160</a></span> | <span class="t">truth for other effective computing experiments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=219">00:03:39.680</a></span> | <span class="t">Second, detection of emotion may require considering not just facial actions or voice acoustics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=226">00:03:46.720</a></span> | <span class="t">but also context of the interaction, and the target of the effective communication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=234">00:03:54.040</a></span> | <span class="t">For more information or to contact the authors, please visit the following website.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=238">00:03:58.680</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=239">00:03:59.720</a></span> | <span class="t">[END]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=240">00:04:00.220</a></span> | <span class="t">1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wiYMwmPPGto&t=241">00:04:01.220</a></span> | <span class="t">Page 2 of 9</span></div></div></body></html>