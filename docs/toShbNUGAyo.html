<html><head><title>Gemini Full Breakdown + AlphaCode 2 Bombshell</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Gemini Full Breakdown + AlphaCode 2 Bombshell</h2><a href="https://www.youtube.com/watch?v=toShbNUGAyo"><img src="https://i.ytimg.com/vi/toShbNUGAyo/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./toShbNUGAyo.html">Whisper Transcript</a> | <a href="./transcript_toShbNUGAyo.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">In the three to four hours since Google Gemini has been announced, I've read the full 60 page</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=5" target="_blank">00:00:05.120</a></span> | <span class="t">technical report, the attached AlphaCode 2 fascinating technical report and all the media</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=11" target="_blank">00:00:11.920</a></span> | <span class="t">interviews, clips and press releases that Google have put out. I've got 45 notes so I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=18" target="_blank">00:00:18.480</a></span> | <span class="t">skip the long intro and get straight to it. Here is the paper Gemini, a family of highly capable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=24" target="_blank">00:00:24.320</a></span> | <span class="t">multimodal models. And let's get one thing out of the way straight away. Is this AGI? No. Is it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=30" target="_blank">00:00:30.720</a></span> | <span class="t">better than GPT-4? Yes, in many modalities, but in text it's probably a draw. Are many people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=37" target="_blank">00:00:37.600</a></span> | <span class="t">going to overlook the bombshell AlphaCode 2 paper? Probably. Anyway, it's three models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=42" target="_blank">00:00:42.800</a></span> | <span class="t">Ultra, Pro and Nano. Nano being for your phone, Pro being the rough equivalent of GPT-3.5 or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=49" target="_blank">00:00:49.680</a></span> | <span class="t">slightly better and Ultra being released early next year as the GPT-4 competitor. Now, the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=56" target="_blank">00:00:56.000</a></span> | <span class="t">paragraph of both that technical report and this accompanying web page tout its abilities in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=61" target="_blank">00:01:01.600</a></span> | <span class="t">MMLU. And I must say in the web page, they were gunning for maximum hype because they had this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=67" target="_blank">00:01:07.120</a></span> | <span class="t">human expert level here and they had Gemini being the first model to beat it. The first problem that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=72" target="_blank">00:01:12.800</a></span> | <span class="t">you might have noticed is that GPT-4 score was done five shots. Basically, it was given five</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=78" target="_blank">00:01:18.480</a></span> | <span class="t">examples to learn from before answering each question. Whereas Gemini Ultra, the biggest model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=83" target="_blank">00:01:23.760</a></span> | <span class="t">was done chain of thought with 32 samples. This is not the video to go into chain of thought or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=89" target="_blank">00:01:29.760</a></span> | <span class="t">self-consistency, but it's a different way of measuring. It's not an apples to apples comparison</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=94" target="_blank">00:01:34.080</a></span> | <span class="t">and in the appendix of the technical report, we'll see a genuine comparison. Also, I've had many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=99" target="_blank">00:01:39.680</a></span> | <span class="t">conversations with the creators of the MMLU as I was doing my smart GPT video and that figure of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=106" target="_blank">00:01:46.000</a></span> | <span class="t">89.8% is very approximate. The 10-second summary of the MMLU is that it's a multiple choice test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=113" target="_blank">00:01:53.680</a></span> | <span class="t">across 57 different subjects, from chemistry to business to mathematics to morality. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=119" target="_blank">00:01:59.200</a></span> | <span class="t">unfortunately, Demis Hassabis engaged in some of that hype with this remark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=124" target="_blank">00:02:04.240</a></span> | <span class="t">What's amazing about Gemini is that it's so good at so many things. As we started getting to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=129" target="_blank">00:02:09.040</a></span> | <span class="t">end of the training, we started seeing that Gemini was better than any other model out there on these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=134" target="_blank">00:02:14.640</a></span> | <span class="t">very, very important benchmarks. For example, each of the 50 different subject areas that we tested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=139" target="_blank">00:02:19.680</a></span> | <span class="t">on, it's as good as the best expert humans in those areas. So no, Gemini Ultra and GPT-4 can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=147" target="_blank">00:02:27.040</a></span> | <span class="t">beat most human experts. And while they describe the MMLU as one of the most popular methods to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=152" target="_blank">00:02:32.880</a></span> | <span class="t">test the knowledge and problem solving abilities of AI models, they don't actually try to back up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=157" target="_blank">00:02:37.760</a></span> | <span class="t">its credibility. If you watch my second smart GPT video, I showed how with some basic prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=163" target="_blank">00:02:43.040</a></span> | <span class="t">scaffolding, you can reach 89% with GPT-4. And frankly, if we had a slightly larger budget than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=169" target="_blank">00:02:49.440</a></span> | <span class="t">the couple thousand dollars in API calls that we used, we could have reached 90% with GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=174" target="_blank">00:02:54.800</a></span> | <span class="t">Furthermore, it's somewhat ridiculous to showcase these results to one decimal place when the test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=179" target="_blank">00:02:59.840</a></span> | <span class="t">itself has maybe 2 to 3% of its questions being in error. If you want more details, check out that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=185" target="_blank">00:03:05.520</a></span> | <span class="t">video, but it's quite egregious. I actually spoke with Anthropic, another leading AGI lab about this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=191" target="_blank">00:03:11.360</a></span> | <span class="t">and they did a blog post on the errors in this test. So the fact that months after that, Google</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=196" target="_blank">00:03:16.800</a></span> | <span class="t">is still touting results on this test is a little surprising to me. That's not to say that Gemini</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=201" target="_blank">00:03:21.920</a></span> | <span class="t">Ultra isn't the best new model. I think it is. It's just weird that they picked this particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=206" target="_blank">00:03:26.720</a></span> | <span class="t">benchmark. And deep in the appendix of the paper, Google sheepishly gives a slightly more reasonable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=211" target="_blank">00:03:31.920</a></span> | <span class="t">comparison between the two models on these text questions. As you can see, depending on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=216" target="_blank">00:03:36.640</a></span> | <span class="t">prompting strategy, you get different results. And please forgive me for one last bit of mockery of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=221" target="_blank">00:03:41.760</a></span> | <span class="t">the two decimal places they give here when 2 to 3% of the test contains errors. Very briefly though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=227" target="_blank">00:03:47.760</a></span> | <span class="t">before we get back to the paper, many of you might be wondering what are these kind of techniques</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=232" target="_blank">00:03:52.080</a></span> | <span class="t">that can boost performance? Well, I was intending to launch this slightly later on, but now is as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=237" target="_blank">00:03:57.760</a></span> | <span class="t">good a time as any. It's my new AI Insiders content on Patreon. And no, I'm not going to do a long ad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=244" target="_blank">00:04:04.320</a></span> | <span class="t">We'll be back to Gemini in 30 seconds. I've been working on this for months, doing interviews with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=249" target="_blank">00:04:09.200</a></span> | <span class="t">Google DeepMind, people like Jim Fan, Microsoft authors, basically creating the best possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=255" target="_blank">00:04:15.120</a></span> | <span class="t">exclusive content that I could come up with. And the reason I mention it now is because in one of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=259" target="_blank">00:04:19.760</a></span> | <span class="t">these exclusive videos, I talk with a top Google author about the future of prompting. It's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=266" target="_blank">00:04:26.160</a></span> | <span class="t">this one, although I'm really proud of that one, reasoning as the holy grail of LLMs. Not this one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=271" target="_blank">00:04:31.440</a></span> | <span class="t">I think it was this one. I spoke to Xingchen Wan about this evolution of prompting. There is much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=276" target="_blank">00:04:36.800</a></span> | <span class="t">more content coming and I'm even going to have a feature where you can vote on what kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=280" target="_blank">00:04:40.880</a></span> | <span class="t">questions I ask the next round of experts. Some of whom will feature later in this video on Google</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=286" target="_blank">00:04:46.800</a></span> | <span class="t">Gemini. But why do I say in other modalities it beats GPT-4? Well, look at this. In 9 of 9</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=293" target="_blank">00:04:53.600</a></span> | <span class="t">image understanding benchmarks, it beats GPT-4 Vision and all other models. 6 of 6 video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=299" target="_blank">00:04:59.280</a></span> | <span class="t">understanding benchmarks and 5 of 5 speech recognition and speech translation benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=305" target="_blank">00:05:05.280</a></span> | <span class="t">That's not bad. They are trained to support a 32,000 token context window, which compares to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=311" target="_blank">00:05:11.440</a></span> | <span class="t">128,000 for GPT-4 Turbo. With Anthropic, you can get up to 200,000 tokens, but the performance isn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=319" target="_blank">00:05:19.040</a></span> | <span class="t">quite as good. Interestingly, they did tell us the parameter count of the nano models at 1.8</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=325" target="_blank">00:05:25.040</a></span> | <span class="t">billion parameters and 3.25 billion parameters. They even give us the detail that they are 4-bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=330" target="_blank">00:05:30.880</a></span> | <span class="t">quantized or distilled down smaller versions of the larger Gemini models. What about other key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=336" target="_blank">00:05:36.640</a></span> | <span class="t">details like the dataset they used? Well, as you might have guessed, they say, "We plan to update</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=342" target="_blank">00:05:42.160</a></span> | <span class="t">this report with more details ahead of the general availability of the Gemini Ultra model." And later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=348" target="_blank">00:05:48.000</a></span> | <span class="t">on, they go into fantastic detail, but not really, saying, "Our pre-trained dataset uses data from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=354" target="_blank">00:05:54.560</a></span> | <span class="t">web documents, books and code, and includes image, audio and video data." Great. Instead of detail on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=361" target="_blank">00:06:01.680</a></span> | <span class="t">the dataset, we do get this incredible nugget. Some of the delay to Gemini was due to external</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=368" target="_blank">00:06:08.720</a></span> | <span class="t">factors such as cosmic rays. Now, obviously I'm being facetious, but that is an interesting detail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=374" target="_blank">00:06:14.480</a></span> | <span class="t">Now, one key detail that I mentioned back in the Palm 2 video was this case of positive transfer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=380" target="_blank">00:06:20.320</a></span> | <span class="t">Essentially, by training the model on image, audio, as well as text and video, they got positive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=386" target="_blank">00:06:26.320</a></span> | <span class="t">transfer. In other words, the model got better at text by being trained on images. As Google keeps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=392" target="_blank">00:06:32.000</a></span> | <span class="t">saying, it was trained from the ground up to be multimodal, and that's why it gets such good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=397" target="_blank">00:06:37.120</a></span> | <span class="t">results in other modalities, which I'll get to. In fact, here they are pretty much state of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=401" target="_blank">00:06:41.600</a></span> | <span class="t">art across natural image understanding, document understanding, infographic understanding. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=407" target="_blank">00:06:47.600</a></span> | <span class="t">even better in video captioning, video question answering, speech translation. But these are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=413" target="_blank">00:06:53.840</a></span> | <span class="t">solid results. This is nothing to do with prompting. It genuinely is a better model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=418" target="_blank">00:06:58.960</a></span> | <span class="t">in these modalities. Remember though, that we're not getting the ultra until early next year,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=424" target="_blank">00:07:04.080</a></span> | <span class="t">and at the moment, pro and nano can only respond with text and code. They can't yet do what you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=430" target="_blank">00:07:10.480</a></span> | <span class="t">seeing in all of these demos, which I'll get to in a second, which is generate images. Speaking of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=435" target="_blank">00:07:15.280</a></span> | <span class="t">the release though, people in the UK and EU like me aren't even getting Google Gemini on launch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=441" target="_blank">00:07:21.520</a></span> | <span class="t">Apparently it's about regulations, so time will tell. This is the kind of interactive UI that I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=447" target="_blank">00:07:27.040</a></span> | <span class="t">mean, and it does look good. Clicking on the interface regenerates the data to be rendered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=452" target="_blank">00:07:32.320</a></span> | <span class="t">by the coded route. Oh, I know she likes cupcakes. I can now click on anything in the interface and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=458" target="_blank">00:07:38.400</a></span> | <span class="t">ask it for more information. I could say step by step instructions on how to bake this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=464" target="_blank">00:07:44.800</a></span> | <span class="t">and it starts to generate a new UI. This time it designs a UI best suited for giving me step by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=471" target="_blank">00:07:51.120</a></span> | <span class="t">step instructions. But now time for some of the highlights, and I'm going to start with the one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=476" target="_blank">00:07:56.400</a></span> | <span class="t">that I was most impressed by. Because of Gemini's ability to understand nuanced information and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=482" target="_blank">00:08:02.640</a></span> | <span class="t">answer questions relating to complicated topics, it can give you a customized explanation of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=487" target="_blank">00:08:07.600</a></span> | <span class="t">subject you're trying to learn. And lastly, if you want to learn more, you can just ask.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=497" target="_blank">00:08:17.440</a></span> | <span class="t">Gemini will provide personalized practice problems based on mistakes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=501" target="_blank">00:08:21.440</a></span> | <span class="t">Here I have a similar problem where I have to figure out the cat's speed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=506" target="_blank">00:08:26.640</a></span> | <span class="t">The height of the ground is double. Oh yeah, I knew that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=512" target="_blank">00:08:32.000</a></span> | <span class="t">Now I'm not naive enough to think that Google Gemini won't sometimes hallucinate answers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=516" target="_blank">00:08:36.800</a></span> | <span class="t">but this format of providing follow-up questions, understanding messy handwriting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=521" target="_blank">00:08:41.760</a></span> | <span class="t">and tying it all together is pretty impressive. The paper makes a great point that because it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=526" target="_blank">00:08:46.160</a></span> | <span class="t">was trained from the ground up to be multimodal, it doesn't take audio and then put it into text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=531" target="_blank">00:08:51.200</a></span> | <span class="t">where you lose some nuance like tone. For languages like Mandarin, which I've studied in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=536" target="_blank">00:08:56.000</a></span> | <span class="t">China, that's super important as this demo demonstrates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=539" target="_blank">00:08:59.680</a></span> | <span class="t">How to pronounce the words lunar January in Chinese?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=543" target="_blank">00:09:03.200</a></span> | <span class="t">Option A, zhēng yuè. Option B, zhèng yuè. Which one is correct? Which tone is the correct tone for the first character?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=552" target="_blank">00:09:12.560</a></span> | <span class="t">Option A, the first character is pronounced with the first tone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=556" target="_blank">00:09:16.400</a></span> | <span class="t">Gemini was able to differentiate the two ways of pronouncing the word to make sure it was correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=561" target="_blank">00:09:21.840</a></span> | <span class="t">And speaking of video understanding, these two demos weren't bad either.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=567" target="_blank">00:09:27.840</a></span> | <span class="t">You are trying to get me to find the paper ball under the cup. I accept the challenge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=572" target="_blank">00:09:32.080</a></span> | <span class="t">The cup to the left.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=576" target="_blank">00:09:36.240</a></span> | <span class="t">Nice. What movie are they acting out here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=581" target="_blank">00:09:41.760</a></span> | <span class="t">I think they are acting out the famous bullet time scene from The Matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=585" target="_blank">00:09:45.120</a></span> | <span class="t">Ooh, nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=585" target="_blank">00:09:45.840</a></span> | <span class="t">What do you think might happen next?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=590" target="_blank">00:09:50.400</a></span> | <span class="t">The cat is going to jump to the wall and stick the landing. It's going to be a perfect 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=597" target="_blank">00:09:57.440</a></span> | <span class="t">Oh, and it's a miss. It looks like it was just a little too far away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=601" target="_blank">00:10:01.280</a></span> | <span class="t">But don't worry, the cat is a natural athlete and it will be back up there in no time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=605" target="_blank">00:10:05.440</a></span> | <span class="t">Going back to languages for a second, we see from this machine translation benchmark,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=610" target="_blank">00:10:10.240</a></span> | <span class="t">which couldn't have been in the training data by the way, that Gemini Ultra beats Palm 2 large.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=615" target="_blank">00:10:15.840</a></span> | <span class="t">But why is beating Palm 2 large so significant?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=619" target="_blank">00:10:19.040</a></span> | <span class="t">Well, I covered this at the time, but in certain settings, we observe that Palm 2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=623" target="_blank">00:10:23.600</a></span> | <span class="t">improves quality both over Palm and Google Translate. And Gemini Ultra is an improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=629" target="_blank">00:10:29.120</a></span> | <span class="t">on Palm 2 large. So expect the multilingual performance to be next level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=634" target="_blank">00:10:34.160</a></span> | <span class="t">Now, what about coding? Well, here's where it's a draw in some ways</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=638" target="_blank">00:10:38.640</a></span> | <span class="t">and a massive win for Gemini Ultra in other ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=642" target="_blank">00:10:42.400</a></span> | <span class="t">Natural 2 code was a held out data set with no leakage on the web.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=647" target="_blank">00:10:47.520</a></span> | <span class="t">So a really good benchmark to use and Gemini Ultra beats GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=652" target="_blank">00:10:52.480</a></span> | <span class="t">Gemini Pro by the way, beats GPT-3.5. But yes, the results are fairly close,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=658" target="_blank">00:10:58.240</a></span> | <span class="t">a 1% point difference. The craziness though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=661" target="_blank">00:11:01.360</a></span> | <span class="t">comes from the AlphaCode 2 technical report. This was also released three to four hours ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=666" target="_blank">00:11:06.080</a></span> | <span class="t">Now, AlphaCode 2 is based on Gemini, Gemini Pro actually, not Gemini Ultra,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=670" target="_blank">00:11:10.640</a></span> | <span class="t">and it achieves truly outstanding things. That's not to say it will be available to you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=675" target="_blank">00:11:15.200</a></span> | <span class="t">anytime soon. It's very compute intensive, but it does show what is coming to the automation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=680" target="_blank">00:11:20.000</a></span> | <span class="t">of coding. I'll try to get to as many details as I can. Yes, I have read this report in full too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=685" target="_blank">00:11:25.600</a></span> | <span class="t">AlphaCode 2 based on Gemini Pro was evaluated on the Codeforces platform.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=690" target="_blank">00:11:30.400</a></span> | <span class="t">GPT-4 could solve a zero out of 10 of the easiest problems when they were recent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=696" target="_blank">00:11:36.080</a></span> | <span class="t">not within its data set. As this author points out, that strongly points towards</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=699" target="_blank">00:11:39.680</a></span> | <span class="t">contamination because it could solve 10 out of 10 of the pre-2021 problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=704" target="_blank">00:11:44.560</a></span> | <span class="t">Anyway, it's a really challenging problem set. AlphaCode 2 solves 43% of those problems within</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=711" target="_blank">00:11:51.200</a></span> | <span class="t">10 attempts, beating 85% of competition participants. Now, AlphaCode 2 isn't just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=717" target="_blank">00:11:57.120</a></span> | <span class="t">one model, it's an entire system. They basically get a family of Gemini models by tweaking different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=722" target="_blank">00:12:02.880</a></span> | <span class="t">hyperparameters. Think of it as different flavors of Gemini, which generate code samples for each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=727" target="_blank">00:12:07.760</a></span> | <span class="t">problem. It was important to have those different flavors because they wanted code diversity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=731" target="_blank">00:12:11.840</a></span> | <span class="t">Then they sampled hundreds and up to a million code samples to search over the space of possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=738" target="_blank">00:12:18.080</a></span> | <span class="t">programs. This is maybe what Demis Hassabis mentioned when he talked about AlphaGo + GPT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=743" target="_blank">00:12:23.520</a></span> | <span class="t">in a video I did a while back. At this point, you can see why it's not yet for consumer release</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=748" target="_blank">00:12:28.640</a></span> | <span class="t">because that is incredibly compute intensive. Anyway, they then filtered out the results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=753" target="_blank">00:12:33.440</a></span> | <span class="t">to remove code that didn't compile or didn't pass the unit tests. They also had a mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=758" target="_blank">00:12:38.720</a></span> | <span class="t">to filter out code that was too similar. But then here's the interesting bit. They used Gemini</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=763" target="_blank">00:12:43.440</a></span> | <span class="t">as a scoring model to surface the best candidate. Are you getting vibes of Let's Verify step by step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=770" target="_blank">00:12:50.160</a></span> | <span class="t">from my Q* video? If not, I'm not hinting strongly enough. Here's some more evidence. They used a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=775" target="_blank">00:12:55.280</a></span> | <span class="t">fine-tuned Gemini Pro model to attribute an estimated correctness score between 0 and 1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=780" target="_blank">00:13:00.880</a></span> | <span class="t">to code samples. Remember from Let's Verify that evaluation is easier than generation? I'll have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=786" target="_blank">00:13:06.320</a></span> | <span class="t">to cover this in more detail in another video because there's other juicy nuggets to get into.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=791" target="_blank">00:13:11.440</a></span> | <span class="t">The ranking of AlphaGo 2 on the test was between expert and master. In its best two performances,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=798" target="_blank">00:13:18.320</a></span> | <span class="t">AlphaGo 2 outperformed more than 99.5% of competition participants. Here's where it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=804" target="_blank">00:13:24.320</a></span> | <span class="t">gets more interesting. To solve these level of problems before writing the code implementation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=808" target="_blank">00:13:28.720</a></span> | <span class="t">one needs to understand, analyze and reason about the problem. This explains why generally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=813" target="_blank">00:13:33.600</a></span> | <span class="t">available AI systems, I think they mean GPT-4, perform poorly on this benchmark. AlphaGo 2's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=819" target="_blank">00:13:39.360</a></span> | <span class="t">success on this competitive programming contest represents an impressive step change. This is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=825" target="_blank">00:13:45.280</a></span> | <span class="t">something I actually discussed with Jim Fan, a senior AI researcher at NVIDIA for AI Insiders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=831" target="_blank">00:13:51.440</a></span> | <span class="t">He quoted mathematics being the first to fall. I think that's one of the reasons why coding and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=837" target="_blank">00:13:57.200</a></span> | <span class="t">math look set to be the first to fall. I'm not talking imminently, but if you can generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=841" target="_blank">00:14:01.520</a></span> | <span class="t">enough samples and then test them, it becomes more a matter of compute rather than reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=847" target="_blank">00:14:07.200</a></span> | <span class="t">Brute force over beauty. You can see here how even with the number of samples approaching a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=852" target="_blank">00:14:12.880</a></span> | <span class="t">million, the results keep getting better. They also note that the sample efficiency of AlphaGo 2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=858" target="_blank">00:14:18.720</a></span> | <span class="t">because of the underlying model is a lot better than AlphaGo 1. I'm sure you all want to try it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=864" target="_blank">00:14:24.240</a></span> | <span class="t">and they say we are working towards bringing AlphaGo 2's unique capabilities to our foundation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=870" target="_blank">00:14:30.000</a></span> | <span class="t">Gemini models. But why can't we have it here? Well, they reiterate that just above. Our system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=875" target="_blank">00:14:35.440</a></span> | <span class="t">requires a lot of trial and error and remains too costly to operate at scale. And many of you may</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=881" target="_blank">00:14:41.440</a></span> | <span class="t">have picked up on another key detail. I said they used Gemini Pro. Maybe this was for budgeting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=887" target="_blank">00:14:47.680</a></span> | <span class="t">reasons, but they say we suspect using Gemini Ultra as the foundation model instead with its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=893" target="_blank">00:14:53.680</a></span> | <span class="t">improved coding and reasoning capabilities would lead to further improvements in the overall Alpha</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=899" target="_blank">00:14:59.120</a></span> | <span class="t">Code 2 approach. They do try to give a sliver of reassurance to human coders a bit later on though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=904" target="_blank">00:15:04.960</a></span> | <span class="t">They note that when using Alpha Code 2 with human coders who can specify additional filtering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=910" target="_blank">00:15:10.160</a></span> | <span class="t">properties, we score above the 90th percentile. That's a five percentile increase. And they say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=915" target="_blank">00:15:15.840</a></span> | <span class="t">optimistically, we hope this kind of interactive coding will be the future of programming where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=920" target="_blank">00:15:20.960</a></span> | <span class="t">programmers make use of the highly capable AI models as collaborative tools. As always, let me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=925" target="_blank">00:15:25.920</a></span> | <span class="t">know what you think in the comments. Some more notes on the release of Gemini before we get to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=931" target="_blank">00:15:31.680</a></span> | <span class="t">the media round that Hasabis did. First, Gemini Nano is coming to the Pixel 8 Pro. That's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=937" target="_blank">00:15:37.840</a></span> | <span class="t">to power features like Summarize and Smart Reply. Honestly, I wouldn't yet trust a 3.5 billion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=943" target="_blank">00:15:43.360</a></span> | <span class="t">parameter model to reply to anything, but that's just me. They say you can expect in the coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=948" target="_blank">00:15:48.480</a></span> | <span class="t">months that Gemini will be available in services such as Search, Ads, Chrome, and Duo AI. In a week</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=954" target="_blank">00:15:54.560</a></span> | <span class="t">though, starting December 13th, devs and enterprise customers can access Gemini Pro via the Gemini API</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=961" target="_blank">00:16:01.520</a></span> | <span class="t">in Google AI Studio. Starting today, Bard will use a fine-tuned version of Gemini Pro in those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=967" target="_blank">00:16:07.200</a></span> | <span class="t">170 countries excluding the UK and EU. And even though I'm hearing reports of people being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=972" target="_blank">00:16:12.800</a></span> | <span class="t">disappointed with Gemini Pro, remember that's not the biggest model. That's Gemini Ultra. Gemini Pro</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=978" target="_blank">00:16:18.000</a></span> | <span class="t">is more like the original Chachi BT. In my last video, I already covered what the delay was behind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=983" target="_blank">00:16:23.760</a></span> | <span class="t">Gemini Ultra. They're basically doing more reinforcement learning from human feedback,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=988" target="_blank">00:16:28.160</a></span> | <span class="t">especially for low resource languages where it was apparently really easy to jailbreak.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=993" target="_blank">00:16:33.600</a></span> | <span class="t">They also kind of teased out this Bard Advanced, which I suspect will be a subscription model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=998" target="_blank">00:16:38.880</a></span> | <span class="t">and they call it a new cutting-edge AI experience that gives you access to our best models and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1003" target="_blank">00:16:43.040</a></span> | <span class="t">capabilities starting with Ultra. Be very interesting to see whether they pitch that higher,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1007" target="_blank">00:16:47.600</a></span> | <span class="t">lower, or the same as Chachi BT Pro. I'll be honest, I'll be buying it regardless,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1012" target="_blank">00:16:52.320</a></span> | <span class="t">assuming it's available in the UK. In terms of API pricing, we don't yet know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1017" target="_blank">00:16:57.680</a></span> | <span class="t">but this New York Times article did point out that during that crisis at OpenAI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1022" target="_blank">00:17:02.720</a></span> | <span class="t">Google offered the same price to customers at OpenAI as their current OpenAI rate and also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1029" target="_blank">00:17:09.040</a></span> | <span class="t">offered cloud credits and discounts thrown in. We'll have to see if that still applies to Gemini</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1033" target="_blank">00:17:13.920</a></span> | <span class="t">Pro and Gemini Ultra. What about the future of Gemini though? Gemini 2.0? Well, Demis Hassabis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1039" target="_blank">00:17:19.440</a></span> | <span class="t">the CEO of Google DeepMind, gave us this clue. He said that Google DeepMind is already looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1043" target="_blank">00:17:23.680</a></span> | <span class="t">into how Gemini might be combined with robotics to physically interact with the world. To become</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1049" target="_blank">00:17:29.440</a></span> | <span class="t">truly multimodal, you'll want to include touch and tactile feedback. And I can't resist pointing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1054" target="_blank">00:17:34.800</a></span> | <span class="t">out at this point that I spoke to Panag Sanketi for AI Insiders. He is the tech lead manager for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1060" target="_blank">00:17:40.560</a></span> | <span class="t">RT2 and I also spoke about this topic with many other lead authors at NVIDIA and elsewhere,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1066" target="_blank">00:17:46.800</a></span> | <span class="t">and I hope that video will be out on AI Insiders before the end of this month. In this Wired</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1071" target="_blank">00:17:51.600</a></span> | <span class="t">interview, Demis Hassabis also strongly hinted that this work was related to what Q* might be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1077" target="_blank">00:17:57.520</a></span> | <span class="t">about. Further evidence that this is the direction that all the major AGI labs are heading toward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1082" target="_blank">00:18:02.960</a></span> | <span class="t">When asked about that, he said, "We have some of the world's best reinforcement learning experts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1086" target="_blank">00:18:06.960</a></span> | <span class="t">who invented some of this stuff." And went on, "We've got some interesting innovations we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1091" target="_blank">00:18:11.360</a></span> | <span class="t">working on to bring to future versions of Gemini." And again, like me, he is a somewhat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1096" target="_blank">00:18:16.320</a></span> | <span class="t">understated Londoner, so that could be pretty significant. In The Verge, he doubled down on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1101" target="_blank">00:18:21.360</a></span> | <span class="t">that, talking about Gemini Ultra, saying, "It's going to get even more general than images,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1105" target="_blank">00:18:25.840</a></span> | <span class="t">video, and audio. There's still things like action and touch, more like robotics." Over time, he says,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1111" target="_blank">00:18:31.120</a></span> | <span class="t">"Gemini will get more senses, become more aware." And he ended his media round with this, "As we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1117" target="_blank">00:18:37.120</a></span> | <span class="t">approach AGI, things are going to be different," Hassabis says. "We're going to gain insanity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1121" target="_blank">00:18:41.520</a></span> | <span class="t">points," is what Sam Altman said. "It's kind of an active technology, so I think we have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1126" target="_blank">00:18:46.160</a></span> | <span class="t">approach that cautiously. Cautiously, but optimistically." And on that note, I want to end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1131" target="_blank">00:18:51.360</a></span> | <span class="t">the video. And yes, I'm super excited about the rolling launch of AI Insiders, which you can sign</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1137" target="_blank">00:18:57.280</a></span> | <span class="t">up to now. But I also want to reassure my longstanding audience, for many of whom $29 or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1143" target="_blank">00:19:03.040</a></span> | <span class="t">even $25 is way too expensive for them. I totally respect that, and for most of my life, it would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1149" target="_blank">00:19:09.440</a></span> | <span class="t">have been too expensive for me too. So don't worry, as this video shows, I will still be posting as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1154" target="_blank">00:19:14.320</a></span> | <span class="t">frequently on the main AI Explained channel. And for those who can join, at least for the next few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1159" target="_blank">00:19:19.200</a></span> | <span class="t">weeks, I'm going to be writing a personal message of thanks for joining AI Insiders. Of course, I am</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1165" target="_blank">00:19:25.120</a></span> | <span class="t">also massively grateful for all of those supporting me at the legendary level. You guys will still get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1171" target="_blank">00:19:31.200</a></span> | <span class="t">my personal updates and blog style posts. So that's Google Gemini. Definitely not the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=toShbNUGAyo&t=1176" target="_blank">00:19:36.400</a></span> | <span class="t">video from me on any of those models. Thank you so much for watching this video and have a wonderful day.</span></div></div></body></html>