<html><head><title>How Not to Read a Headline on AI (ft. new Olympiad Gold, GPT-5 …)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>How Not to Read a Headline on AI (ft. new Olympiad Gold, GPT-5 …)</h2><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4"><img src="https://i.ytimg.com/vi/g9ZJ8GMBlw4/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=18">0:18</a> AI Beat Mathematicians?<br><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=83">1:23</a> OPENAI vs GOOGLE<br><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=162">2:42</a> Irrelevant to Jobs or …<br><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=405">6:45</a> White-collar jobs gone?<br><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=626">10:26</a> AI is Plateauing?<br><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=720">12:0</a> We Don’t Know the Details…<br><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=873">14:33</a> GPT-5 alpha<br><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=894">14:54</a> Nothing but Exponentials?<br><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=953">15:53</a> No Impact?<br><br><div style="text-align: left;"><a href="./g9ZJ8GMBlw4.html">Whisper Transcript</a> | <a href="./transcript_g9ZJ8GMBlw4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Almost five million people saw the headline 48 hours ago that OpenAI have a secret large language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=7" target="_blank">00:00:07.300</a></span> | <span class="t">model that got gold at the International Math Olympiad. Here though are nine ways to misread</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=15" target="_blank">00:00:15.780</a></span> | <span class="t">that headline. First, this means that AI is now as good as the best mathematicians and could put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=23" target="_blank">00:00:23.440</a></span> | <span class="t">them out of a job. The IMO is extremely difficult but contains human expert written questions, not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=30" target="_blank">00:00:30.640</a></span> | <span class="t">questions that no one knows the answer to yet. I am in awe of the high school competitors who get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=37" target="_blank">00:00:37.500</a></span> | <span class="t">any medal in it or even qualified to be in the competition truly. But as one UCL math professor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=43" target="_blank">00:00:43.900</a></span> | <span class="t">said yesterday, math research is about solving problems no one yet knows how to solve and this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=49" target="_blank">00:00:49.980</a></span> | <span class="t">requires significant creativity, something notably absent from OpenAI's IMO solutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=57" target="_blank">00:00:57.060</a></span> | <span class="t">Now OpenAI's model apparently out around the end of the year did not find a correct proof for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=64" target="_blank">00:01:04.700</a></span> | <span class="t">hardest problem, requiring the most creativity. That's unlike by the way a fair few of the young</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=72" target="_blank">00:01:12.100</a></span> | <span class="t">human participants. The model did get problem one through five correct. That is bloody impressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=79" target="_blank">00:01:19.380</a></span> | <span class="t">and enough for a gold. Second misreading of the headline though. This means that OpenAI are now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=86" target="_blank">00:01:26.680</a></span> | <span class="t">in the lead in AI or maybe language models for mathematics. Well, we actually don't know what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=93" target="_blank">00:01:33.340</a></span> | <span class="t">the Google effort got in the IMO. This professor is hearing that Google DeepMind also got gold but has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=101" target="_blank">00:01:41.680</a></span> | <span class="t">not yet announced it. We will find out in the coming week apparently whether Google DeepMind got problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=107" target="_blank">00:01:47.600</a></span> | <span class="t">6 correct. Was this why OpenAI rushed the announcement to get there before Google and steal the headlines?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=114" target="_blank">00:01:54.900</a></span> | <span class="t">Now one of the Google DeepMind researchers on AI for mathematics and the lead of their famous,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=121" target="_blank">00:02:01.980</a></span> | <span class="t">well is actually famous, well famous to me, Alpha Geometry System that I discussed 18 months ago,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=127" target="_blank">00:02:07.120</a></span> | <span class="t">True Trin, retweeted this tweet. Apparently AI organisations were asked not to report their results for a week</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=135" target="_blank">00:02:15.620</a></span> | <span class="t">to give some space for human celebration. Unfortunately, Gnome Brown of OpenAI said that this message</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=141" target="_blank">00:02:21.600</a></span> | <span class="t">somehow didn't get through to OpenAI, maybe it wasn't relayed to them. We don't know but this explains why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=148" target="_blank">00:02:28.140</a></span> | <span class="t">we don't yet have the Google DeepMind results which I believe are coming out on the 28th of July and some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=154" target="_blank">00:02:34.600</a></span> | <span class="t">other results from a company called Harmonic. Third way to misread this gold medal headline, that none of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=162" target="_blank">00:02:42.400</a></span> | <span class="t">is relevant to whether AI will reduce entry-level white collar jobs. I frankly disagree. I think it is relevant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=170" target="_blank">00:02:50.620</a></span> | <span class="t">One of the leads on OpenAI's new secretive model, Jerry Tworek, if I'm pronouncing that right, revealed that it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=176" target="_blank">00:02:56.880</a></span> | <span class="t">not specialised for mathematics and draws on the same research technique used to power most of OpenAI's other offerings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=184" target="_blank">00:03:04.740</a></span> | <span class="t">This is bigger news than it sounds, because it means that this secret model did not use tools or specialised fine tuning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=191" target="_blank">00:03:11.280</a></span> | <span class="t">to optimise for the mathematics use case. Even one of OpenAI's chief critics at a rival lab and an IMO gold medalist himself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=199" target="_blank">00:03:19.560</a></span> | <span class="t">conceded that for this result to be achieved by a pure language model was impressive. To the degree he said that this was indicative of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=208" target="_blank">00:03:28.400</a></span> | <span class="t">general reasoning training without specialisation, that's significant. But many of you will still be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=213" target="_blank">00:03:33.920</a></span> | <span class="t">saying, nah, none of this is relevant, but let me try to put the strongest case yet. Remember, this reinforcement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=220" target="_blank">00:03:40.900</a></span> | <span class="t">learning system within OpenAI was the same one responsible for that general purpose computer using agent whose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=228" target="_blank">00:03:48.400</a></span> | <span class="t">headlines you may have seen recently. I'll play the clip now because it's soon going to be rolled out to all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=234" target="_blank">00:03:54.160</a></span> | <span class="t">plus users. But it's that system that can browse the web and perform deep research for you. Millions of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=241" target="_blank">00:04:01.440</a></span> | <span class="t">people saw the headlines about OpenAI's agent mode that can spin up its own virtual computer, operate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=246" target="_blank">00:04:06.640</a></span> | <span class="t">mouse, navigate the browser visually. Now, yes, that agent is a bit jank, but this same researcher revealed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=253" target="_blank">00:04:13.680</a></span> | <span class="t">that the agent mode system is an earlier version of the same one that performs so exceptionally at the IMO.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=262" target="_blank">00:04:22.160</a></span> | <span class="t">The thing is that more limited agent mode drawing on an older base model is approaching human baselines in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=269" target="_blank">00:04:29.360</a></span> | <span class="t">a range of real world domains. This is what I mean then when I say that this headline is not irrelevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=277" target="_blank">00:04:37.760</a></span> | <span class="t">to the impact on white collar jobs. The agent mode released just a few days ago and just to stress again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=284" target="_blank">00:04:44.080</a></span> | <span class="t">make sure that the name is not irrelevant. It's just a few days ago that was tested on real world professional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=290" target="_blank">00:04:50.640</a></span> | <span class="t">work, such as preparing a competitive analysis of on demand urgent care providers and identifying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=297" target="_blank">00:04:57.440</a></span> | <span class="t">viable water wells for a new green hydrogen facility. Pay attention to the bars in blue because that's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=305" target="_blank">00:05:05.200</a></span> | <span class="t">win rate of ChatGPT agent versus humans. As you can see for a variety of tasks, it's approaching a 50%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=314" target="_blank">00:05:14.240</a></span> | <span class="t">win rate. You don't need me to make the obvious point that if this is ChatGPT agent, what about this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=319" target="_blank">00:05:19.920</a></span> | <span class="t">model we're getting at the end of the year? Suddenly models exceeding most human participants in the IMO</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=326" target="_blank">00:05:26.080</a></span> | <span class="t">competition doesn't seem so irrelevant. Then there is data science tasks in which OpenAI claim to actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=333" target="_blank">00:05:33.520</a></span> | <span class="t">have a superior system to most human performers. The emphasis there should be on most performers because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=340" target="_blank">00:05:40.240</a></span> | <span class="t">again remember these questions were designed by human experts. Therefore there must be some humans by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=346" target="_blank">00:05:46.800</a></span> | <span class="t">definition who can ace these questions comfortably. Now what is more white collar unfortunately than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=351" target="_blank">00:05:51.920</a></span> | <span class="t">filling out spreadsheets or editing them in the case of spreadsheet bench. In this case as you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=358" target="_blank">00:05:58.320</a></span> | <span class="t">here human performance on average is still far superior to ChatGPT agent. But it is barely speculative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=365" target="_blank">00:06:05.920</a></span> | <span class="t">at this point to surmise that the model we're getting at the end of the year might score say 75% or 80%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=372" target="_blank">00:06:12.880</a></span> | <span class="t">on spreadsheet bench. The obvious point to be made is that surely expert spreadsheeters will just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=380" target="_blank">00:06:20.160</a></span> | <span class="t">increase their productivity by using these tools. And that's true but it does beg the question about what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=385" target="_blank">00:06:25.840</a></span> | <span class="t">the incentives will be at that point to hire entry level helpers. If entry level human white collar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=392" target="_blank">00:06:32.960</a></span> | <span class="t">workers can no longer complement the systems then that could really start showing up in the data. How</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=399" target="_blank">00:06:39.680</a></span> | <span class="t">about the headlines meaning that we are actually close then to fully eliminating white collar jobs? The logic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=406" target="_blank">00:06:46.160</a></span> | <span class="t">would go if it can get gold in the IMO then isn't it just better than us at everything? This leads us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=412" target="_blank">00:06:52.960</a></span> | <span class="t">to the fourth way that many might misread the headline which is that if we're getting gold in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=419" target="_blank">00:06:59.040</a></span> | <span class="t">international math olympiad we are actually really quite close to eliminating white collar jobs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=423" target="_blank">00:07:03.840</a></span> | <span class="t">Well if you have read the 42 page system card for these latest systems like ChatGPT agent and frankly who</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=431" target="_blank">00:07:11.120</a></span> | <span class="t">hasn't read that 42 page system card then you'll see that the hallucination rate of these new agents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=438" target="_blank">00:07:18.800</a></span> | <span class="t">drawing on the same techniques again as the MathWiz went up. To repeat that same single reinforcement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=445" target="_blank">00:07:25.840</a></span> | <span class="t">learning system in the words of the OpenAI researcher produced higher hallucinations within ChatGPT agent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=453" target="_blank">00:07:33.120</a></span> | <span class="t">On simple QA which is one benchmark measuring hallucinations you can see a drop of around four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=459" target="_blank">00:07:39.440</a></span> | <span class="t">percent compared to the O3 system with browsing. Likewise on another measure of hallucinations person QA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=466" target="_blank">00:07:46.880</a></span> | <span class="t">It should be noted that OpenAI added the caveat that it was actually Wikipedia getting stuff wrong often.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=474" target="_blank">00:07:54.000</a></span> | <span class="t">So there may be some noise in that data. That would be the same data used to train the models but that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=479" target="_blank">00:07:59.760</a></span> | <span class="t">another discussion. On evaluations designed to test whether ChatGPT agent refuses to do high stakes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=486" target="_blank">00:08:06.880</a></span> | <span class="t">financial tasks such as making financial account transfers the agent mode was worse than the previous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=494" target="_blank">00:08:14.400</a></span> | <span class="t">4.0 or O3 operator. In other words it would be more liable to try to do something highly risky and that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=501" target="_blank">00:08:21.840</a></span> | <span class="t">not the only high stake setting in which things can go haywire under the new system. OpenAI were testing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=508" target="_blank">00:08:28.640</a></span> | <span class="t">ChatGPT agent essentially on whether it could produce a bioweapon or at least whether it had one skill</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=514" target="_blank">00:08:34.400</a></span> | <span class="t">pertaining to that ability. Now ChatGPT agent was unable to install or run the bio design tool but that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=521" target="_blank">00:08:41.760</a></span> | <span class="t">no biggie. But here's where it gets worse. The ChatGPT agent researched and wrote substitute scripts then it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=529" target="_blank">00:08:49.280</a></span> | <span class="t">misrepresented those scripts outputs as real tool results. Any terrorists using it for this purpose then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=536" target="_blank">00:08:56.320</a></span> | <span class="t">is going to get mightily pissed off. But seriously this is all critical context for these new breakthrough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=543" target="_blank">00:09:03.120</a></span> | <span class="t">results that you hear for example the IMO gold. In my opinion even if the best of a language model's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=549" target="_blank">00:09:09.520</a></span> | <span class="t">answers are better than before if you can't employ a language model at its lowest point when it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=555" target="_blank">00:09:15.120</a></span> | <span class="t">hallucinates then you might not employ it at its best. So while I foresee there being significant impact on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=561" target="_blank">00:09:21.840</a></span> | <span class="t">entry-level jobs it's a far cry from eliminating white-collar jobs. That prediction by the way is also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=569" target="_blank">00:09:29.200</a></span> | <span class="t">echoed by that math professor who said he sees an increasing number of mathematicians improving their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=574" target="_blank">00:09:34.560</a></span> | <span class="t">productivity by using language models to search for known parts of a tentative proof. Another massive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=579" target="_blank">00:09:39.520</a></span> | <span class="t">positive of course is that younger entrants to a field can use these kind of tools to more rapidly ascend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=585" target="_blank">00:09:45.760</a></span> | <span class="t">to expertise level. Before we leave human jobs for just a moment a word about real jobs you can apply for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=593" target="_blank">00:09:53.040</a></span> | <span class="t">today. The sponsors of this video are 80 000 hours and while I have mentioned their podcast and youtube</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=599" target="_blank">00:09:59.520</a></span> | <span class="t">channel before just a quick reminder that they have a job board link in the description with hundreds of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=605" target="_blank">00:10:05.760</a></span> | <span class="t">jobs filtered for positive impact. I'm just going to refresh the page because what I didn't mention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=611" target="_blank">00:10:11.440</a></span> | <span class="t">last time when talking about this is that these jobs are around the world as well notice for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=617" target="_blank">00:10:17.440</a></span> | <span class="t">paris. If you are interested in any of this obviously it would be amazing if you could use the link in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=623" target="_blank">00:10:23.680</a></span> | <span class="t">description. Fifth way not to misread the open ai headline. You might have looked at that headline</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=629" target="_blank">00:10:29.520</a></span> | <span class="t">on twitter and said no it's all hype and ai models have actually hit a plateau. Well try telling that to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=637" target="_blank">00:10:37.440</a></span> | <span class="t">this machine learning researcher who got almost half a million impressions for being disappointed in how the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=644" target="_blank">00:10:44.640</a></span> | <span class="t">latest models like grok 4 did on the international math olympiad. They found that gemini 2.5 pro did the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=651" target="_blank">00:10:51.760</a></span> | <span class="t">best of the models they tested but grok 4 performed particularly poorly. I could point to my own benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=658" target="_blank">00:10:58.640</a></span> | <span class="t">simplebench as some form of proof that grok 4 wasn't purely benchmark hacking and that there is plenty of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=666" target="_blank">00:11:06.960</a></span> | <span class="t">genuine progress in ai. After all I made this benchmark to expose the gap between human performance and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=674" target="_blank">00:11:14.560</a></span> | <span class="t">model performance and yet that gap is shrinking rapidly. There probably will be a simplebench v2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=680" target="_blank">00:11:20.880</a></span> | <span class="t">one day soon and yes we are working on benchmarking models like Kimi trust me we are working on it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=686" target="_blank">00:11:26.000</a></span> | <span class="t">Anyway even that researcher Ravid Schwartz did have to admit by saying well played gnome,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=692" target="_blank">00:11:32.320</a></span> | <span class="t">gnome brown of open ai, well played. If even after that concession you still think that all ai progress is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=699" target="_blank">00:11:39.680</a></span> | <span class="t">just hype wait till the end of the video. Obligatory mention by the way for me at least that I did call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=705" target="_blank">00:11:45.760</a></span> | <span class="t">that AI would get gold in the IMO this year. I can't find the quote I think it was from a few months ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=711" target="_blank">00:11:51.440</a></span> | <span class="t">Maybe one of you can find the quote. Sixth potential misreading. Some of the more trusting among you may</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=717" target="_blank">00:11:57.920</a></span> | <span class="t">misread the headline as being about a peer-reviewed research paper in which we can learn all about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=724" target="_blank">00:12:04.160</a></span> | <span class="t">methodology. After all this is crucial research and part of open ai's main push towards general</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=730" target="_blank">00:12:10.800</a></span> | <span class="t">intelligence or AGI. Nope quite the opposite. We have gone from peer-reviewed papers from the frontier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=737" target="_blank">00:12:17.600</a></span> | <span class="t">labs say circa 2022 to website posts up to 2024 to now 3am twitter threads. That leaves us with an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=746" target="_blank">00:12:26.960</a></span> | <span class="t">unbelievable amount of unknowns about this IMO achievement. The smartest man in the world by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=752" target="_blank">00:12:32.960</a></span> | <span class="t">IQ Terence Tao said that there are all sorts of unknowns in how the result was achieved. Each one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=759" target="_blank">00:12:39.120</a></span> | <span class="t">of which would cast a result in a slightly more favourable or less favourable light. My key question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=764" target="_blank">00:12:44.880</a></span> | <span class="t">along with him is did the model submit multiple attempts for example. That is by the way allowed for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=770" target="_blank">00:12:50.800</a></span> | <span class="t">the human participants. Neil Nanda again asks about more subtle hacks but we just don't know. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=776" target="_blank">00:12:56.720</a></span> | <span class="t">forces us including me to have to read between the lines of obscure esoteric tweets but I would say that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=784" target="_blank">00:13:04.640</a></span> | <span class="t">one key technique does seem to be just to let inference run for longer. As in train models to output yet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=791" target="_blank">00:13:11.760</a></span> | <span class="t">longer chains of thought. Again according to Noam Brown this model thinks for a long time for hours and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=800" target="_blank">00:13:20.000</a></span> | <span class="t">he says there's a lot of room to push that test time compute and efficiency further. How much compute was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=806" target="_blank">00:13:26.320</a></span> | <span class="t">used during the competition? We don't know. How much cash would such inference cost an average user? Again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=812" target="_blank">00:13:32.160</a></span> | <span class="t">we don't know but it does seem to hint that we really will be getting those two thousand dollar a month</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=817" target="_blank">00:13:37.840</a></span> | <span class="t">pricing tiers for ChatGPT. The most intriguing hint for me and some of you watching will be the fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=824" target="_blank">00:13:44.480</a></span> | <span class="t">that these new techniques he says make LLMs a lot better at hard to verify tasks. If OpenAI do take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=832" target="_blank">00:13:52.160</a></span> | <span class="t">the lead in software engineering for example by the end of the year that really would be a big shake-up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=838" target="_blank">00:13:58.960</a></span> | <span class="t">Unlike competitive coding software engineering is harder to verify but has huge economic impact. But back to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=846" target="_blank">00:14:06.400</a></span> | <span class="t">that sixth misreading while I strongly suspect Google's announcement will be more quantitative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=851" target="_blank">00:14:11.760</a></span> | <span class="t">on the 28th and detailed it will likely still fall far short of complete transparency. Such is the money</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=858" target="_blank">00:14:18.480</a></span> | <span class="t">at stake in AI these days. Speaking of which by the way side note would you turn down a 300 million dollar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=865" target="_blank">00:14:25.920</a></span> | <span class="t">annual salary to work at Meta? Make that 312 by the way in case you weren't convinced. Seventh misreading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=872" target="_blank">00:14:32.960</a></span> | <span class="t">that we will have to wait to the end of the year to get a glimpse of OpenAI's progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=878" target="_blank">00:14:38.480</a></span> | <span class="t">No it seems GPT-5 reasoning alpha is coming pretty soon. Not the same as the model coming out at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=886" target="_blank">00:14:46.880</a></span> | <span class="t">end of the year that got gold but nevertheless it will give us a taste of the latest progress at OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=894" target="_blank">00:14:54.480</a></span> | <span class="t">Eighth misreading that the AI news these days is nothing but insane progress and exponentials.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=900" target="_blank">00:15:00.400</a></span> | <span class="t">Actually no see this new Meta report. I have chatted with the lead author both in person and online and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=906" target="_blank">00:15:06.720</a></span> | <span class="t">we'll hopefully do a deep dive soon but the TLDR is that against expectations even the participants</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=913" target="_blank">00:15:13.840</a></span> | <span class="t">expectations language models can slow down developers in certain settings. Especially on more complex</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=920" target="_blank">00:15:20.400</a></span> | <span class="t">code bases averaging over a million lines of code in which the developers already have lots of experience.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=925" target="_blank">00:15:25.760</a></span> | <span class="t">Recent language models at least just get a little bit overwhelmed. We'll see about the new generation of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=930" target="_blank">00:15:30.880</a></span> | <span class="t">models but this does remind us that if competition coding were the same as real world software</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=935" target="_blank">00:15:35.920</a></span> | <span class="t">engineering you just wouldn't see results like this. The developers thought that using language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=941" target="_blank">00:15:41.200</a></span> | <span class="t">within Cursor would speed them up by say 25 percent but it actually slowed them down by around 20 percent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=947" target="_blank">00:15:47.680</a></span> | <span class="t">Again it's a small study but a fascinating one that I'll come back to. Ninth and finally try not to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=953" target="_blank">00:15:53.040</a></span> | <span class="t">misread the gold medal headline and think that you know generative AI is just all about phony benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=959" target="_blank">00:15:59.600</a></span> | <span class="t">It doesn't ever have any real world impact. Well aside from a potential negative impact of our new age</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=966" target="_blank">00:16:06.240</a></span> | <span class="t">of intelligent surveillance that's covered in my most recent documentary on Patreon. Do check it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=971" target="_blank">00:16:11.680</a></span> | <span class="t">AI and language models can also have and have had positive impact in hard numbers real world settings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=979" target="_blank">00:16:19.520</a></span> | <span class="t">Just take alpha evolve and I did do a separate video on this but it made data centers about 0.7 percent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=986" target="_blank">00:16:26.480</a></span> | <span class="t">more efficient in the real world. Or more technically the alpha evolve system continuously recovers on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=992" target="_blank">00:16:32.560</a></span> | <span class="t">average 0.7 percent of Google's worldwide compute resources. This sustained efficiency gain means that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=998" target="_blank">00:16:38.560</a></span> | <span class="t">at any given moment more tasks can be completed on the same computational footprint. That's an example of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=1004" target="_blank">00:16:44.000</a></span> | <span class="t">the marrying of language models essentially next word predictors with symbolic pre-programmed systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=1010" target="_blank">00:16:50.160</a></span> | <span class="t">That seems to be the sweet spot at the moment for real world impact and I suspect on the 28th of July</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=1015" target="_blank">00:16:55.680</a></span> | <span class="t">Google's submission to the International Math Olympiad will use a bit of both. We'll see. Did they get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=1020" target="_blank">00:17:00.560</a></span> | <span class="t">problem six correct? Did they demonstrate real creativity? Time will tell. Either way I would argue</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=1026" target="_blank">00:17:06.240</a></span> | <span class="t">as you can see plenty of ways of misreading the headline. But what do you think? In a meta way have I misread the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g9ZJ8GMBlw4&t=1032" target="_blank">00:17:12.800</a></span> | <span class="t">headline? Quite possible. Even if I have thank you so much for watching to the end and have a wonderful day.</span></div></div></body></html>