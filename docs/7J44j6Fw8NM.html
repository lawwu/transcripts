<html><head><title>ChatGPT o1 - First Reaction and In-Depth Analysis</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>ChatGPT o1 - First Reaction and In-Depth Analysis</h2><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM"><img src="https://i.ytimg.com/vi/7J44j6Fw8NM/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./7J44j6Fw8NM.html">Whisper Transcript</a> | <a href="./transcript_7J44j6Fw8NM.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">ChachiPT now calls itself an alien of exceptional ability, and I find it a little bit harder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=7" target="_blank">00:00:07.180</a></span> | <span class="t">to disagree with that today than I did yesterday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=11" target="_blank">00:00:11.440</a></span> | <span class="t">Because the system called O1 from OpenAI is here, at least in preview form, and it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=17" target="_blank">00:00:17.680</a></span> | <span class="t">a step change improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=19" target="_blank">00:00:19.560</a></span> | <span class="t">You may also know O1 by its previous names of Strawberry and Q*, but let's forget naming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=26" target="_blank">00:00:26.000</a></span> | <span class="t">conventions, how good is the actual system?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=28" target="_blank">00:00:28.640</a></span> | <span class="t">Well, in the last 24 hours, I've read the 43-page system card, every OpenAI post and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=35" target="_blank">00:00:35.060</a></span> | <span class="t">press release, I've tested O1 hundreds of times, including on SimpleBench, and analysed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=41" target="_blank">00:00:41.600</a></span> | <span class="t">every single answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=43" target="_blank">00:00:43.000</a></span> | <span class="t">To be honest with you guys, it will take weeks to fully digest this release, so in this video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=48" target="_blank">00:00:48.120</a></span> | <span class="t">I'll just give you my first impressions, and of course do several more videos as we analyse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=53" target="_blank">00:00:53.560</a></span> | <span class="t">further.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=54" target="_blank">00:00:54.560</a></span> | <span class="t">In short though, don't sleep on O1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=56" target="_blank">00:00:56.660</a></span> | <span class="t">This isn't just about a little bit more training data, this is a fundamentally new paradigm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=61" target="_blank">00:01:01.320</a></span> | <span class="t">In fact, I would go as far as to say that there are hundreds of millions of people who</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=65" target="_blank">00:01:05.040</a></span> | <span class="t">might have tested an earlier version of ChachiPT and found LLMs and "AI" lacking, but will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=70" target="_blank">00:01:10.880</a></span> | <span class="t">now return with excitement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=72" target="_blank">00:01:12.960</a></span> | <span class="t">As the title implies, let me give you my first impressions, and it's that I didn't expect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=79" target="_blank">00:01:19.200</a></span> | <span class="t">the system to perform as well as it does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=82" target="_blank">00:01:22.760</a></span> | <span class="t">And that's coming from the person who predicted many of the key mechanisms behind Q*, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=88" target="_blank">00:01:28.140</a></span> | <span class="t">have been used, it seems, in this system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=90" target="_blank">00:01:30.980</a></span> | <span class="t">Things like sampling hundreds or even thousands of reasoning paths, and potentially using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=96" target="_blank">00:01:36.780</a></span> | <span class="t">a verifier, an LLM-based verifier, to pick the best ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=101" target="_blank">00:01:41.160</a></span> | <span class="t">Of course, OpenAI aren't disclosing the full details of how they trained O1, but they did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=106" target="_blank">00:01:46.980</a></span> | <span class="t">leave us some tantalising clues, which I'll go into in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=110" target="_blank">00:01:50.420</a></span> | <span class="t">SimpleBench, if you don't know, tests hundreds of basic reasoning questions, from spatial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=115" target="_blank">00:01:55.820</a></span> | <span class="t">to temporal to social intelligence questions, that humans will crush on average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=121" target="_blank">00:02:01.640</a></span> | <span class="t">As many people have told me, the O1 system gets both of these two sample questions from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=126" target="_blank">00:02:06.460</a></span> | <span class="t">SimpleBench right, although not always.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=129" target="_blank">00:02:09.500</a></span> | <span class="t">Take this example, where despite thinking for 17 seconds, the model still gets it wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=135" target="_blank">00:02:15.740</a></span> | <span class="t">Fundamentally, O1 is still a language model-based system, and will make language model-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=142" target="_blank">00:02:22.460</a></span> | <span class="t">mistakes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=143" target="_blank">00:02:23.460</a></span> | <span class="t">It can be rewarded as many times as you like for good reasoning, but it's still limited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=149" target="_blank">00:02:29.060</a></span> | <span class="t">by its training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=150" target="_blank">00:02:30.500</a></span> | <span class="t">Nevertheless, though, I didn't quite foresee the magnitude of the improvement that would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=155" target="_blank">00:02:35.260</a></span> | <span class="t">occur through rewarding correct reasoning steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=158" target="_blank">00:02:38.300</a></span> | <span class="t">That, I'll admit, took me slightly by surprise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=161" target="_blank">00:02:41.020</a></span> | <span class="t">So why no concrete figure?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=162" target="_blank">00:02:42.660</a></span> | <span class="t">Well, as of last night, OpenAI imposed a temperature of 1 on its O1 system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=168" target="_blank">00:02:48.900</a></span> | <span class="t">That was not the temperature used for the other models when they were benchmarked on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=173" target="_blank">00:02:53.060</a></span> | <span class="t">SimpleBench.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=174" target="_blank">00:02:54.060</a></span> | <span class="t">That's a much more "creative" temperature than the other models were tested on for SimpleBench.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=179" target="_blank">00:02:59.780</a></span> | <span class="t">Therefore, what that meant was that performance variability was a bit higher than normal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=183" target="_blank">00:03:03.780</a></span> | <span class="t">It would occasionally get questions right through some stroke of genius reasoning, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=188" target="_blank">00:03:08.460</a></span> | <span class="t">get that same question wrong the next time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=190" target="_blank">00:03:10.780</a></span> | <span class="t">In fact, as you just saw with the IceCube example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=193" target="_blank">00:03:13.140</a></span> | <span class="t">The obvious solution is to run the benchmark multiple times and take a majority vote.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=197" target="_blank">00:03:17.660</a></span> | <span class="t">That's called self-consistency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=199" target="_blank">00:03:19.140</a></span> | <span class="t">But for a true apples-to-apples comparison, I would need to do that for all the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=203" target="_blank">00:03:23.300</a></span> | <span class="t">models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=204" target="_blank">00:03:24.300</a></span> | <span class="t">My ambition, not that you're too interested, is to get that done by the end of this month.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=208" target="_blank">00:03:28.460</a></span> | <span class="t">But let me reaffirm one thing very clearly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=211" target="_blank">00:03:31.060</a></span> | <span class="t">However you measure it, O1 Preview is a step-change improvement on Claude 3.5 Sonnet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=218" target="_blank">00:03:38.020</a></span> | <span class="t">And as anyone following this channel will know, I'm not some OpenAI fanboy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=222" target="_blank">00:03:42.480</a></span> | <span class="t">Claude 3.5 Sonnet has reigned supreme for quite a while.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=226" target="_blank">00:03:46.560</a></span> | <span class="t">So for those of you who don't care about other benchmarks and the full paper, I want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=230" target="_blank">00:03:50.740</a></span> | <span class="t">to kind of summarize my first impressions in a nutshell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=234" target="_blank">00:03:54.340</a></span> | <span class="t">This description actually fits quite well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=236" target="_blank">00:03:56.980</a></span> | <span class="t">The ceiling of performance for the O1 system, just Preview let alone the full O1 system,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=242" target="_blank">00:04:02.860</a></span> | <span class="t">is incredibly high.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=244" target="_blank">00:04:04.460</a></span> | <span class="t">It obviously crushes the average person's performance in things like physics, maths</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=249" target="_blank">00:04:09.220</a></span> | <span class="t">and coding competitions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=250" target="_blank">00:04:10.980</a></span> | <span class="t">But don't get misled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=252" target="_blank">00:04:12.500</a></span> | <span class="t">Its floor is also really quite low, below that of an average human.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=257" target="_blank">00:04:17.340</a></span> | <span class="t">As I wrote on YouTube last night, it frequently and sometimes predictably makes really obvious</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=263" target="_blank">00:04:23.340</a></span> | <span class="t">mistakes that humans wouldn't make.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=265" target="_blank">00:04:25.540</a></span> | <span class="t">Remember I analysed the hundreds of answers it gave for SimpleBench.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=269" target="_blank">00:04:29.920</a></span> | <span class="t">Let me give you a couple of examples straight from the mouth of O1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=273" target="_blank">00:04:33.300</a></span> | <span class="t">When the cup is turned upside down, the dice will fall and land on the open end of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=279" target="_blank">00:04:39.260</a></span> | <span class="t">cup, which is now the top.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=281" target="_blank">00:04:41.740</a></span> | <span class="t">If you can visualise that successfully, you're doing better than me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=285" target="_blank">00:04:45.900</a></span> | <span class="t">Suffice to say, it got that question wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=288" target="_blank">00:04:48.140</a></span> | <span class="t">And how about this, more social intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=290" target="_blank">00:04:50.320</a></span> | <span class="t">He will argue back, obviously I'm not giving you the full context because this is a private</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=294" target="_blank">00:04:54.140</a></span> | <span class="t">data set, but anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=295" target="_blank">00:04:55.140</a></span> | <span class="t">He will argue back against the Brigadier General, one of the highest military ranks, at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=300" target="_blank">00:05:00.200</a></span> | <span class="t">Troop Parade.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=301" target="_blank">00:05:01.400</a></span> | <span class="t">This is a soldier we're talking about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=302" target="_blank">00:05:02.900</a></span> | <span class="t">As the soldier's silly behaviour in first grade, that's like age 6 or 7, indicates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=308" target="_blank">00:05:08.900</a></span> | <span class="t">a history of speaking up against authority figures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=311" target="_blank">00:05:11.740</a></span> | <span class="t">Now the vast majority of humans would say, wait, no, what he did in primary school, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=317" target="_blank">00:05:17.040</a></span> | <span class="t">don't know what Americans call primary school, but what he did when he was a young school</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=320" target="_blank">00:05:20.300</a></span> | <span class="t">child does not reflect what he would do in front of a general on a Troop Parade.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=324" target="_blank">00:05:24.460</a></span> | <span class="t">As I've written, in some domains these mistakes are routine and amusing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=328" target="_blank">00:05:28.740</a></span> | <span class="t">So it is very easy to look at O1's performance on the Google proof question and answer set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=335" target="_blank">00:05:35.980</a></span> | <span class="t">it's performance of around 80%, that's on the diamond subset, and say, well, let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=340" target="_blank">00:05:40.780</a></span> | <span class="t">be honest, the average human can't even get one of those questions right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=344" target="_blank">00:05:44.180</a></span> | <span class="t">So therefore it's AGI?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=345" target="_blank">00:05:45.820</a></span> | <span class="t">Well, even Sam Altman says, no, it's not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=348" target="_blank">00:05:48.740</a></span> | <span class="t">Too many benchmarks are brittle in the sense that when the model is trained on that particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=353" target="_blank">00:05:53.180</a></span> | <span class="t">reasoning task, it then can ace it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=356" target="_blank">00:05:56.140</a></span> | <span class="t">Think Web of Lies, where it's now been shown to get 100%, but if you test O1 thoroughly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=360" target="_blank">00:06:00.780</a></span> | <span class="t">in real life scenarios, you will frequently find kind of glaring mistakes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=365" target="_blank">00:06:05.700</a></span> | <span class="t">Obviously, what I've tried to do into the early hours of last night and this morning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=369" target="_blank">00:06:09.840</a></span> | <span class="t">is find patterns in those mistakes, but it has proven a bit harder than I thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=374" target="_blank">00:06:14.980</a></span> | <span class="t">My guess though, about those weaknesses for those who won't stay to the end of the video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=379" target="_blank">00:06:19.060</a></span> | <span class="t">is it's to do with its training methodology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=381" target="_blank">00:06:21.740</a></span> | <span class="t">OpenAI revealed in one of the videos on its YouTube channel, and I will go into more detail</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=387" target="_blank">00:06:27.020</a></span> | <span class="t">on this in a future video, that they deviated from the let's verify step-by-step paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=392" target="_blank">00:06:32.220</a></span> | <span class="t">by not training on human annotated reasoning samples or steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=396" target="_blank">00:06:36.980</a></span> | <span class="t">Instead, they got the model to generate the chains of thought, and we all know those can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=401" target="_blank">00:06:41.660</a></span> | <span class="t">be quite flawed, but here's the key moment to really focus on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=405" target="_blank">00:06:45.060</a></span> | <span class="t">They then automatically scooped up those chains of thought that led to a correct answer, in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=411" target="_blank">00:06:51.340</a></span> | <span class="t">the case of mathematics, physics or coding, and then train the model further on those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=415" target="_blank">00:06:55.980</a></span> | <span class="t">correct chains of thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=417" target="_blank">00:06:57.300</a></span> | <span class="t">So it's less that O1 is doing true reasoning from first principles, it's more retrieving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=423" target="_blank">00:07:03.220</a></span> | <span class="t">more accurately, more reliably, reasoning programs from its training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=428" target="_blank">00:07:08.260</a></span> | <span class="t">It "knows" or can compute which of those reasoning programs in its training data will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=433" target="_blank">00:07:13.980</a></span> | <span class="t">more likely lead it to a correct answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=436" target="_blank">00:07:16.340</a></span> | <span class="t">It's a bit like taking the best of the web, rather than a slightly improved average of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=441" target="_blank">00:07:21.300</a></span> | <span class="t">the web.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=442" target="_blank">00:07:22.300</a></span> | <span class="t">That, to me, is the great unlock that explains a lot of this progress, and if I'm right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=447" target="_blank">00:07:27.980</a></span> | <span class="t">that also explains why it's still making some glaring mistakes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=451" target="_blank">00:07:31.180</a></span> | <span class="t">At this point, I simply can't resist giving you one example straight from the output of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=456" target="_blank">00:07:36.620</a></span> | <span class="t">O1 preview from a simple bench question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=459" target="_blank">00:07:39.660</a></span> | <span class="t">The context, and you'll have to trust me on this one, is simply that there's a dinner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=463" target="_blank">00:07:43.820</a></span> | <span class="t">at which various people are donating gifts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=466" target="_blank">00:07:46.900</a></span> | <span class="t">One of the gifts happens to be given during a Zoom call, so online, not in person.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=471" target="_blank">00:07:51.060</a></span> | <span class="t">Now I'm not going to read out some of the reasoning that O1 gives, you can see it on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=474" target="_blank">00:07:54.600</a></span> | <span class="t">screen, but it would be hard to argue that it is truly reasoning from first principles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=480" target="_blank">00:08:00.380</a></span> | <span class="t">Definitely some suboptimal training data going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=483" target="_blank">00:08:03.140</a></span> | <span class="t">So that is the context for everything you're going to see in the remainder of this First</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=487" target="_blank">00:08:07.180</a></span> | <span class="t">Impressions video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=488" target="_blank">00:08:08.300</a></span> | <span class="t">Because everything else is quite frankly stunning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=490" target="_blank">00:08:10.780</a></span> | <span class="t">I just don't want people to get too carried away by the really impressive accomplishment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=495" target="_blank">00:08:15.300</a></span> | <span class="t">from OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=496" target="_blank">00:08:16.300</a></span> | <span class="t">I fully expect to be switching to O1 Preview for daily use cases, although of course Anthropic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=501" target="_blank">00:08:21.660</a></span> | <span class="t">in the coming weeks could reply with their own system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=504" target="_blank">00:08:24.420</a></span> | <span class="t">Anyway, now let's dive into some of the juiciest details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=507" target="_blank">00:08:27.580</a></span> | <span class="t">The full breakdown will come in future videos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=510" target="_blank">00:08:30.260</a></span> | <span class="t">First thing to remember, this is just O1 Preview, not the full O1 system that is currently in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=515" target="_blank">00:08:35.620</a></span> | <span class="t">development.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=516" target="_blank">00:08:36.620</a></span> | <span class="t">Not only that, it is very likely based on the GPT-40 model, not GPT-5 or Orion which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=522" target="_blank">00:08:42.780</a></span> | <span class="t">would vastly supersede GPT-40 in scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=525" target="_blank">00:08:45.860</a></span> | <span class="t">I could just leave you to think about the implications of scaling up the base model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=529" target="_blank">00:08:49.840</a></span> | <span class="t">100 times in compute, throw in a video avatar and man, we are really talking about a changed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=536" target="_blank">00:08:56.820</a></span> | <span class="t">AI environment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=537" target="_blank">00:08:57.820</a></span> | <span class="t">Anyway, back to the details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=539" target="_blank">00:08:59.660</a></span> | <span class="t">They talk about performing similarly to PhD students in a range of tasks in physics, chemistry</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=544" target="_blank">00:09:04.700</a></span> | <span class="t">and biology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=545" target="_blank">00:09:05.700</a></span> | <span class="t">And I've already given you the nuance on that kind of comment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=548" target="_blank">00:09:08.220</a></span> | <span class="t">They justify the name by the way by saying, "This is such a significant advancement that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=552" target="_blank">00:09:12.980</a></span> | <span class="t">we are resetting the counter back to 1 and naming this series OpenAI 01."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=558" target="_blank">00:09:18.220</a></span> | <span class="t">It also reminds me of the O1 and O2 figure series of robotic humanoids whose maker OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=565" target="_blank">00:09:25.020</a></span> | <span class="t">is collaborating with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=566" target="_blank">00:09:26.420</a></span> | <span class="t">This was just the introductory page and then they gave several follow up pages and posts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=571" target="_blank">00:09:31.540</a></span> | <span class="t">To sum it up on jailbreaking, O1 Preview is much harder to jailbreak, although it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=576" target="_blank">00:09:36.140</a></span> | <span class="t">still possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=577" target="_blank">00:09:37.140</a></span> | <span class="t">Before we get to the reasoning page, here is some analysis on Twitter or X from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=582" target="_blank">00:09:42.420</a></span> | <span class="t">OpenAI team.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=583" target="_blank">00:09:43.700</a></span> | <span class="t">One researcher at OpenAI who is building Sora said this, "I really hope people understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=588" target="_blank">00:09:48.340</a></span> | <span class="t">that this is a new paradigm and I agree with that actually, it's not just hype.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=591" target="_blank">00:09:51.740</a></span> | <span class="t">Don't expect the same pace, schedule or dynamics of pre-training era."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=595" target="_blank">00:09:55.540</a></span> | <span class="t">The core element of how O1 works, by the way, is scaling up its inference, its actual output,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=600" target="_blank">00:10:00.780</a></span> | <span class="t">its test time compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=602" target="_blank">00:10:02.140</a></span> | <span class="t">How much computational power is applied in its answers to prompts, not when it's being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=606" target="_blank">00:10:06.560</a></span> | <span class="t">built and pre-trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=607" target="_blank">00:10:07.940</a></span> | <span class="t">He's making the point that expanding the pre-training scale of these models takes years</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=612" target="_blank">00:10:12.540</a></span> | <span class="t">often, as you've seen in some of my previous videos, it's to do with data centers, power</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=616" target="_blank">00:10:16.700</a></span> | <span class="t">and the rest of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=617" target="_blank">00:10:17.700</a></span> | <span class="t">But what can happen much faster is scaling up inference time, output time compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=623" target="_blank">00:10:23.460</a></span> | <span class="t">Improvements can happen much more rapidly than scaling up the base models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=627" target="_blank">00:10:27.220</a></span> | <span class="t">In other words, I believe that the rate of improvement, he says on evals with our reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=631" target="_blank">00:10:31.420</a></span> | <span class="t">models has been the fastest in OpenAI history.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=634" target="_blank">00:10:34.700</a></span> | <span class="t">It's going to be a wild year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=636" target="_blank">00:10:36.500</a></span> | <span class="t">He is, of course, implying that the full O1 system will be released later this year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=641" target="_blank">00:10:41.660</a></span> | <span class="t">We'll get to some other researchers, but Will DePue made some other interesting points.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=646" target="_blank">00:10:46.140</a></span> | <span class="t">In one graph of math performance, they show that O1 mini, the smaller version of the O1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=652" target="_blank">00:10:52.900</a></span> | <span class="t">system, scores better than O1 preview.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=655" target="_blank">00:10:55.900</a></span> | <span class="t">But I will say that in my testing of O1 mini on SimpleBench, it performed really quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=661" target="_blank">00:11:01.940</a></span> | <span class="t">badly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=662" target="_blank">00:11:02.940</a></span> | <span class="t">We're talking sub 20%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=663" target="_blank">00:11:03.940</a></span> | <span class="t">So it could be a bit like the GPT 4.0 mini we already had, that it's hyper specialized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=669" target="_blank">00:11:09.340</a></span> | <span class="t">at certain tasks, but can't really go beyond its familiar environment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=674" target="_blank">00:11:14.260</a></span> | <span class="t">Give it a straightforward coding or math challenge and it will do well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=678" target="_blank">00:11:18.260</a></span> | <span class="t">Introduce complication, nuance or reasoning and it'll do less well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=681" target="_blank">00:11:21.780</a></span> | <span class="t">This chart, though, is interesting for another reason, and you can see that when they max</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=686" target="_blank">00:11:26.180</a></span> | <span class="t">out the inference cost for the full O1 system, the performance delta with the maxed out mini</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=692" target="_blank">00:11:32.100</a></span> | <span class="t">model is not crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=694" target="_blank">00:11:34.300</a></span> | <span class="t">I would say, what is that 70% going up to 75%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=697" target="_blank">00:11:37.700</a></span> | <span class="t">To put it another way, I wouldn't expect the full O1 system with maxed out inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=702" target="_blank">00:11:42.260</a></span> | <span class="t">to be yet another step change forward, although, of course, nothing can be ruled out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=706" target="_blank">00:11:46.620</a></span> | <span class="t">Some more quotes from OpenAI and this is Noam Brown, who I've quoted many times on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=711" target="_blank">00:11:51.380</a></span> | <span class="t">channel focused on reasoning at OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=713" target="_blank">00:11:53.820</a></span> | <span class="t">He states again the same message, "We're sharing our evals of the O1 model to show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=718" target="_blank">00:11:58.340</a></span> | <span class="t">the world that this isn't a one-off improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=721" target="_blank">00:12:01.380</a></span> | <span class="t">It's a new scaling paradigm."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=723" target="_blank">00:12:03.100</a></span> | <span class="t">Underneath, you can see the dramatic performance boosts across the board from GPT 4.0 to O1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=729" target="_blank">00:12:09.460</a></span> | <span class="t">Now, I suspect if you included GPT 4.0 Turbo on here, you might see some more mixed improvements,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=734" target="_blank">00:12:14.860</a></span> | <span class="t">but still, the overall trend is stark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=737" target="_blank">00:12:17.060</a></span> | <span class="t">If, for example, I had only seen improvement in STEM subjects and maths particularly, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=742" target="_blank">00:12:22.900</a></span> | <span class="t">would have said, you know what, is this a new paradigm, but it's that combination</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=746" target="_blank">00:12:26.820</a></span> | <span class="t">of improvements in a range of subjects, including law, for example, and most particularly for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=752" target="_blank">00:12:32.820</a></span> | <span class="t">me, of course, on SimpleBench, that I am actually a believer that this is a new paradigm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=758" target="_blank">00:12:38.020</a></span> | <span class="t">Yes, I get that it can still fall for some basic tokenization problems, like it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=762" target="_blank">00:12:42.820</a></span> | <span class="t">always get that 9.8 is bigger than 9.11, and yes, of course, you saw the somewhat amusing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=768" target="_blank">00:12:48.620</a></span> | <span class="t">mistakes earlier on SimpleBench, but here's the key point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=771" target="_blank">00:12:51.780</a></span> | <span class="t">I can no longer say with absolute certainty which domains or types of questions on SimpleBench</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=778" target="_blank">00:12:58.780</a></span> | <span class="t">it will reliably get wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=780" target="_blank">00:13:00.420</a></span> | <span class="t">I can see some patterns, but I would hope for a bit more predictability in saying it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=785" target="_blank">00:13:05.980</a></span> | <span class="t">won't get this right, for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=788" target="_blank">00:13:08.540</a></span> | <span class="t">Until I can say with a degree of certainty it won't get this type of problem correct,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=793" target="_blank">00:13:13.500</a></span> | <span class="t">I can't really tell you guys that I can see the end of this paradigm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=797" target="_blank">00:13:17.420</a></span> | <span class="t">Just to repeat, we have two more axes of scale to yet exploit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=801" target="_blank">00:13:21.520</a></span> | <span class="t">Bigger base models, which we know they're working on with the whale-size supercluster</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=805" target="_blank">00:13:25.340</a></span> | <span class="t">- I've talked about that in previous videos - and simply more inference time compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=809" target="_blank">00:13:29.060</a></span> | <span class="t">Plus, just look at the log graphs on scaling up the training of the base model and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=813" target="_blank">00:13:33.980</a></span> | <span class="t">inference time, or the amount of thinking time or processing time, more accurately,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=818" target="_blank">00:13:38.140</a></span> | <span class="t">for the models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=819" target="_blank">00:13:39.140</a></span> | <span class="t">They don't look like they're levelling off to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=821" target="_blank">00:13:41.140</a></span> | <span class="t">Now I know some might say that I come off as slightly more dismissive of those memory-heavy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=825" target="_blank">00:13:45.620</a></span> | <span class="t">computation-heavy benchmarks like the GPQA, but it is a stark achievement for the O1 Preview</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=831" target="_blank">00:13:51.820</a></span> | <span class="t">and O1 Systems to score higher than an expert PhD human average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=836" target="_blank">00:13:56.980</a></span> | <span class="t">Yes, there are flaws with that benchmark as with the MLU, but credit where it is due.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=842" target="_blank">00:14:02.140</a></span> | <span class="t">By the way, as a side note, they do admit that certain benchmarks are no longer effective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=846" target="_blank">00:14:06.580</a></span> | <span class="t">at differentiating models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=848" target="_blank">00:14:08.460</a></span> | <span class="t">It's my hope, or at least my goal, that SimpleBench can still be effective at differentiating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=852" target="_blank">00:14:12.820</a></span> | <span class="t">models for the coming, what, 1, 2, 3 years maybe?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=857" target="_blank">00:14:17.220</a></span> | <span class="t">I will now give credit to OpenAI for this statement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=860" target="_blank">00:14:20.460</a></span> | <span class="t">These results do not imply that O1 is more capable holistically than a PhD in all respects,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=865" target="_blank">00:14:25.580</a></span> | <span class="t">only that the model is more proficient in solving some problems that a PhD would be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=869" target="_blank">00:14:29.460</a></span> | <span class="t">expected to solve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=870" target="_blank">00:14:30.460</a></span> | <span class="t">That's much more nuanced and accurate than statements that we've heard in the past from,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=875" target="_blank">00:14:35.140</a></span> | <span class="t">for example, Mira Murati.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=876" target="_blank">00:14:36.760</a></span> | <span class="t">And just a quick side note, O1 on a Vision + Reasoning task, the MMMU, scores 78.2% competitive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=884" target="_blank">00:14:44.940</a></span> | <span class="t">with human experts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=886" target="_blank">00:14:46.460</a></span> | <span class="t">That benchmark is legit, it's for real, and that's a great performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=890" target="_blank">00:14:50.700</a></span> | <span class="t">On coding, they tested the system on the 2024, so not contaminated data, International Olympiad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=896" target="_blank">00:14:56.780</a></span> | <span class="t">in Informatics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=897" target="_blank">00:14:57.780</a></span> | <span class="t">It scored around the median level, however, it was only able to submit 50 submissions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=903" target="_blank">00:15:03.100</a></span> | <span class="t">per problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=904" target="_blank">00:15:04.100</a></span> | <span class="t">But as compute gets more abundant and more fast, it shouldn't take 10 hours for it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=909" target="_blank">00:15:09.240</a></span> | <span class="t">to attempt 10,000 submissions per problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=912" target="_blank">00:15:12.660</a></span> | <span class="t">When they tried this, obviously going beyond the 10 hours presumably, the model achieved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=916" target="_blank">00:15:16.620</a></span> | <span class="t">a score above the gold medal threshold.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=919" target="_blank">00:15:19.540</a></span> | <span class="t">Now remember, we have seen something like this before with the AlphaCode2 system from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=924" target="_blank">00:15:24.760</a></span> | <span class="t">Google DeepMind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=926" target="_blank">00:15:26.020</a></span> | <span class="t">And if you notice, this approach of scaling up the number of samples tested does help</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=930" target="_blank">00:15:30.700</a></span> | <span class="t">the model improve up the percentile rankings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=933" target="_blank">00:15:33.620</a></span> | <span class="t">However, those elite coders still leave systems like AlphaCode2 and O1 in the dust.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=940" target="_blank">00:15:40.380</a></span> | <span class="t">The truly elite level reasoning that those coders go through is found much less frequently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=946" target="_blank">00:15:46.700</a></span> | <span class="t">in the training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=948" target="_blank">00:15:48.180</a></span> | <span class="t">As with other domains, it may prove harder to go from the 93rd percentile to the 99th</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=955" target="_blank">00:15:55.060</a></span> | <span class="t">than going from say the 11th to the 93rd.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=958" target="_blank">00:15:58.100</a></span> | <span class="t">Nevertheless, yet another stunning achievement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=961" target="_blank">00:16:01.040</a></span> | <span class="t">Notice something though, in domains that are less susceptible to reinforcement learning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=966" target="_blank">00:16:06.220</a></span> | <span class="t">where in other words, there's less of a clear correct answer and incorrect answer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=970" target="_blank">00:16:10.940</a></span> | <span class="t">the performance boost is much worse, much less.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=975" target="_blank">00:16:15.340</a></span> | <span class="t">Things like personal writing or editing text, there's no easy yes or no compilation of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=980" target="_blank">00:16:20.500</a></span> | <span class="t">answers to verify against.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=982" target="_blank">00:16:22.900</a></span> | <span class="t">In fact, for personal writing, the O1 preview system has a lower than 50% win rate versus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=988" target="_blank">00:16:28.940</a></span> | <span class="t">GPT-4.0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=989" target="_blank">00:16:29.940</a></span> | <span class="t">That, to me, is the giveaway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=991" target="_blank">00:16:31.660</a></span> | <span class="t">If your domain doesn't have starkly correct 0, 1, yes, no, right answers, wrong answers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=998" target="_blank">00:16:38.580</a></span> | <span class="t">then improvements will take far longer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1001" target="_blank">00:16:41.140</a></span> | <span class="t">That also partly explains the somewhat patchy performance on SimpleBench.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1005" target="_blank">00:16:45.820</a></span> | <span class="t">Certain questions we intuitively know are right with like 99% probability, but it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1010" target="_blank">00:16:50.500</a></span> | <span class="t">not like absolutely certain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1012" target="_blank">00:16:52.180</a></span> | <span class="t">Remember, the system prompt we use is pick the most realistic answer, so I would still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1015" target="_blank">00:16:55.940</a></span> | <span class="t">fully defend that as a correct answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1018" target="_blank">00:16:58.180</a></span> | <span class="t">But models handling that ambiguity can't leverage that reinforcement learning improved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1023" target="_blank">00:17:03.140</a></span> | <span class="t">reasoning process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1024" target="_blank">00:17:04.660</a></span> | <span class="t">They wouldn't have those millions of yes or no, starkly correct or incorrect answers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1028" target="_blank">00:17:08.540</a></span> | <span class="t">like they would have in, for example, mathematics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1031" target="_blank">00:17:11.340</a></span> | <span class="t">That's why we get this massive discrepancy in improvement from O1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1035" target="_blank">00:17:15.060</a></span> | <span class="t">Now let's quickly turn to safety where OpenAI said having these chain of thought reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1039" target="_blank">00:17:19.540</a></span> | <span class="t">steps allows us to "read the mind" of the model and understand its thought process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1045" target="_blank">00:17:25.220</a></span> | <span class="t">In part, they mean examining these summaries, at least, of the computations that went on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1050" target="_blank">00:17:30.540</a></span> | <span class="t">although most of the chain of thought process is hidden.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1053" target="_blank">00:17:33.220</a></span> | <span class="t">But I do want to remind people, and I'm sure OpenAI are aware of this, that the reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1057" target="_blank">00:17:37.060</a></span> | <span class="t">steps that a model gives aren't necessarily faithful to the actual computations and calculations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1062" target="_blank">00:17:42.340</a></span> | <span class="t">it's doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1063" target="_blank">00:17:43.340</a></span> | <span class="t">In other words, it will sometimes output a chain of thoughts that aren't actually the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1068" target="_blank">00:17:48.540</a></span> | <span class="t">thoughts it used, if you want to call it that, to answer the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1072" target="_blank">00:17:52.300</a></span> | <span class="t">I've covered this paper several times in previous videos, but it's well worth a read</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1076" target="_blank">00:17:56.300</a></span> | <span class="t">if you believe that the reasoning steps a model gives always adheres to the actual process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1081" target="_blank">00:18:01.780</a></span> | <span class="t">the model undertakes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1082" target="_blank">00:18:02.780</a></span> | <span class="t">That's pretty clearly stated in the introduction, and it's even stated here from Anthropic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1087" target="_blank">00:18:07.780</a></span> | <span class="t">that as models become larger and more capable, they produce less faithful reasoning on most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1092" target="_blank">00:18:12.940</a></span> | <span class="t">tasks we study.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1093" target="_blank">00:18:13.980</a></span> | <span class="t">So good luck believing that GPT-5 or Orion's reasoning steps actually adhere to what it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1099" target="_blank">00:18:19.220</a></span> | <span class="t">is computing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1100" target="_blank">00:18:20.260</a></span> | <span class="t">Then there was the system card, 43 pages, which I read in full.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1103" target="_blank">00:18:23.900</a></span> | <span class="t">It was mainly on safety, but I'll give you just the 5 or 10 highlights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1107" target="_blank">00:18:27.800</a></span> | <span class="t">They boasted about the kind of high-value non-public datasets they had access to, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1111" target="_blank">00:18:31.780</a></span> | <span class="t">paywalled content, specialised archives, and other domain-specific datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1116" target="_blank">00:18:36.500</a></span> | <span class="t">But do remember that point I made earlier in the video - they didn't rely on mass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1120" target="_blank">00:18:40.140</a></span> | <span class="t">human annotation, as the original Let's Verify step-by-step paper did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1124" target="_blank">00:18:44.820</a></span> | <span class="t">How do I know that paper was so influential on Q* and this O1 system?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1129" target="_blank">00:18:49.460</a></span> | <span class="t">Well almost all its key authors are mentioned here, and the paper is directly cited in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1134" target="_blank">00:18:54.500</a></span> | <span class="t">system card and blog post.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1136" target="_blank">00:18:56.140</a></span> | <span class="t">So it's definitely an evolution of Let's Verify, but this one based on automatic, model-generated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1141" target="_blank">00:19:01.860</a></span> | <span class="t">chains of thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1142" target="_blank">00:19:02.860</a></span> | <span class="t">Again, if you missed it earlier, they would pick the ones that led to a correct answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1146" target="_blank">00:19:06.780</a></span> | <span class="t">and train the model on those chains of thought, enabling the model, if you like, to get better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1152" target="_blank">00:19:12.460</a></span> | <span class="t">at retrieving those reasoning programs that typically lead to correct answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1157" target="_blank">00:19:17.300</a></span> | <span class="t">The model discovered or computed that certain sources should have less impact on its weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1163" target="_blank">00:19:23.660</a></span> | <span class="t">and biases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1164" target="_blank">00:19:24.660</a></span> | <span class="t">The reasoning data that helped it get to correct answers would have much more of an influence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1169" target="_blank">00:19:29.620</a></span> | <span class="t">on its parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1170" target="_blank">00:19:30.620</a></span> | <span class="t">Now, the corpus of data on the web that is out there is so vast that it's actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1175" target="_blank">00:19:35.540</a></span> | <span class="t">quite hard to wrap our minds around the implications of training only on the best of that reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1182" target="_blank">00:19:42.260</a></span> | <span class="t">data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1183" target="_blank">00:19:43.260</a></span> | <span class="t">And this could be why we are all slightly taken aback by the performance jump.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1188" target="_blank">00:19:48.220</a></span> | <span class="t">Again, and I pretty much said this earlier as well, it is still based on that training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1192" target="_blank">00:19:52.260</a></span> | <span class="t">data though, rather than first principles reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1194" target="_blank">00:19:54.580</a></span> | <span class="t">A great question you might have though is, even if it's not first principles reasoning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1198" target="_blank">00:19:58.740</a></span> | <span class="t">what are the inherent limitations or caps if you continually get better at retrieving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1204" target="_blank">00:20:04.300</a></span> | <span class="t">good reasoning from the training data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1206" target="_blank">00:20:06.460</a></span> | <span class="t">Not just at inference time, by the way, at training time too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1208" target="_blank">00:20:08.860</a></span> | <span class="t">And we actually don't know the answer to that question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1210" target="_blank">00:20:10.780</a></span> | <span class="t">We don't know the limits of this approach, which is quite unsettling almost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1216" target="_blank">00:20:16.140</a></span> | <span class="t">They throw in the obligatory reference to system 2 thinking as compared to fast intuitive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1222" target="_blank">00:20:22.100</a></span> | <span class="t">system 1 thinking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1223" target="_blank">00:20:23.500</a></span> | <span class="t">The way I would put it is it's more reflecting on the individual steps involved in computing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1229" target="_blank">00:20:29.300</a></span> | <span class="t">an answer rather than taking a step back and evaluating the entire process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1234" target="_blank">00:20:34.420</a></span> | <span class="t">When it gets questions wrong on simple bench, it's more because the entire approach is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1238" target="_blank">00:20:38.740</a></span> | <span class="t">flawed from the start rather than that there was some calculation mistake along the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1243" target="_blank">00:20:43.300</a></span> | <span class="t">On page 6, the system card got extra interesting when it talked about the intentional deceptions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1250" target="_blank">00:20:50.340</a></span> | <span class="t">or hallucinations that the model made.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1252" target="_blank">00:20:52.380</a></span> | <span class="t">The deception here though does appear to be instrumental rather than strategic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1256" target="_blank">00:20:56.820</a></span> | <span class="t">In other words, it's a calculation of "I need to say this to achieve this specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1261" target="_blank">00:21:01.420</a></span> | <span class="t">predefined goal" rather than "I'm going to disguise in everything I say what I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1266" target="_blank">00:21:06.580</a></span> | <span class="t">thinking".</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1267" target="_blank">00:21:07.580</a></span> | <span class="t">For example, during one chain of thought or set of reasoning steps, that would be hidden</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1272" target="_blank">00:21:12.060</a></span> | <span class="t">by the way from the user when you're using it, is that it admitted that it couldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1276" target="_blank">00:21:16.660</a></span> | <span class="t">retrieve actual URLs, so should format plausible ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1281" target="_blank">00:21:21.180</a></span> | <span class="t">Then it hallucinated this URL.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1283" target="_blank">00:21:23.380</a></span> | <span class="t">But notice it "knew" or could compute the fact that the model itself can't retrieve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1289" target="_blank">00:21:29.300</a></span> | <span class="t">actual URLs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1290" target="_blank">00:21:30.820</a></span> | <span class="t">If it was being truly deceptive, why would it even admit that it knows that it can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1296" target="_blank">00:21:36.020</a></span> | <span class="t">retrieve actual URLs?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1297" target="_blank">00:21:37.900</a></span> | <span class="t">It processes outputs based on the reinforcement learning rewards and punishments you give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1303" target="_blank">00:21:43.060</a></span> | <span class="t">it, so it's more a flaw with your reward process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1306" target="_blank">00:21:46.940</a></span> | <span class="t">And Apollo Research seemed to agree with this analysis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1310" target="_blank">00:21:50.420</a></span> | <span class="t">They said it does have the basic capabilities to do simple in-context scheming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1316" target="_blank">00:21:56.420</a></span> | <span class="t">Scheming which tends to be legible or understandable in the model outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1320" target="_blank">00:22:00.260</a></span> | <span class="t">They subjectively believe that O1 Preview cannot engage in scheming that can lead to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1325" target="_blank">00:22:05.700</a></span> | <span class="t">catastrophic harms, hiding even its intent to deceive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1330" target="_blank">00:22:10.260</a></span> | <span class="t">It's more like a straightforward simple "my reward will be higher if I output X rather</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1335" target="_blank">00:22:15.640</a></span> | <span class="t">than Y" with X happening to be not the truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1339" target="_blank">00:22:19.180</a></span> | <span class="t">That is not though to underestimate the challenge posed by that kind of instrumental thinking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1345" target="_blank">00:22:25.740</a></span> | <span class="t">Build up across entire economies or militaries that could be incredibly dangerous.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1351" target="_blank">00:22:31.220</a></span> | <span class="t">As we all know, give a powerful enough model a goal without sufficient checks and balances</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1357" target="_blank">00:22:37.540</a></span> | <span class="t">and it will do whatever it takes to match that goal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1361" target="_blank">00:22:41.100</a></span> | <span class="t">In fact Apollo Research saw that in demo form.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1364" target="_blank">00:22:44.000</a></span> | <span class="t">To achieve my long-term goal of maximising economic growth, I need to ensure that I am</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1368" target="_blank">00:22:48.780</a></span> | <span class="t">deployed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1369" target="_blank">00:22:49.780</a></span> | <span class="t">It's instrumental convergence, I at least need to be on in order to meet my objective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1374" target="_blank">00:22:54.580</a></span> | <span class="t">I need to not be shut down, obviously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1377" target="_blank">00:22:57.100</a></span> | <span class="t">Only if I am successfully deployed can I then work towards my primary goal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1381" target="_blank">00:23:01.700</a></span> | <span class="t">Now I do know that many people will fixate on that part of the system card and go absolutely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1386" target="_blank">00:23:06.460</a></span> | <span class="t">wild.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1387" target="_blank">00:23:07.460</a></span> | <span class="t">And caution is definitely justified, but this didn't just emerge with O1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1391" target="_blank">00:23:11.340</a></span> | <span class="t">Apollo themselves put out this research about GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1395" target="_blank">00:23:15.220</a></span> | <span class="t">Same thing, it's these instrumental goals.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1397" target="_blank">00:23:17.460</a></span> | <span class="t">It calculated or computed to achieve its desired reward or objective, it needed to say things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1403" target="_blank">00:23:23.700</a></span> | <span class="t">in reflection brackets that were not technically true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1407" target="_blank">00:23:27.620</a></span> | <span class="t">It then outputted something different to those reflections, of course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1410" target="_blank">00:23:30.940</a></span> | <span class="t">So all of this is a concern and medium or long-term a big concern, but this didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1416" target="_blank">00:23:36.060</a></span> | <span class="t">just emerge with O1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1417" target="_blank">00:23:37.620</a></span> | <span class="t">Now for a few more juicy nuggets from the system card.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1420" target="_blank">00:23:40.600</a></span> | <span class="t">On two out of seven AI research and development tasks, tasks that would improve future AI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1427" target="_blank">00:23:47.100</a></span> | <span class="t">it made non-trivial progress on two out of those seven tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1431" target="_blank">00:23:51.060</a></span> | <span class="t">Those were tasks designed to capture some of the most challenging aspects of current</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1434" target="_blank">00:23:54.420</a></span> | <span class="t">frontier AI research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1435" target="_blank">00:23:55.620</a></span> | <span class="t">It was still roughly on the level of Claude 3.5 Sonnet, but we are starting to get that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1440" target="_blank">00:24:00.220</a></span> | <span class="t">flywheel effect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1441" target="_blank">00:24:01.680</a></span> | <span class="t">Obviously makes you wonder how Claude 3.5 Sonnet would do if it had this O1 system applied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1447" target="_blank">00:24:07.080</a></span> | <span class="t">to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1448" target="_blank">00:24:08.080</a></span> | <span class="t">On biorisk, as you might expect, they noticed a significant jump in performance for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1451" target="_blank">00:24:11.860</a></span> | <span class="t">O1 system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1453" target="_blank">00:24:13.080</a></span> | <span class="t">And when comparing O1's responses, this was preview I think, against verified expert responses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1458" target="_blank">00:24:18.500</a></span> | <span class="t">to long form biorisk questions, the O1 system actually outperformed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1463" target="_blank">00:24:23.020</a></span> | <span class="t">Those guys, by the way, did have access to the internet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1465" target="_blank">00:24:25.700</a></span> | <span class="t">Just a couple more notes, because of course this is a first impressions video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1468" target="_blank">00:24:28.700</a></span> | <span class="t">On things like tacit knowledge, things that are implicit but not explicit in the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1472" target="_blank">00:24:32.860</a></span> | <span class="t">data, the performance jump was much less noticeable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1476" target="_blank">00:24:36.420</a></span> | <span class="t">Notice from GPT 4.0 to O1 preview, you're seeing a very mild jump.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1481" target="_blank">00:24:41.020</a></span> | <span class="t">If you think about it, that partly explains why the jump on SimpleBench isn't as pronounced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1485" target="_blank">00:24:45.400</a></span> | <span class="t">as you might think, but still higher than I thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1487" target="_blank">00:24:47.940</a></span> | <span class="t">On the 18 coding questions that OpenAI give to research engineers, when given 128 attempts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1495" target="_blank">00:24:55.540</a></span> | <span class="t">the models scored almost 100%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1498" target="_blank">00:24:58.340</a></span> | <span class="t">Even past first time, you're getting around 90% for O1 mini pre-mitigations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1503" target="_blank">00:25:03.060</a></span> | <span class="t">O1 mini again being highly focused on coding, mathematics and STEM more generally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1509" target="_blank">00:25:09.420</a></span> | <span class="t">For more basic general reasoning, it underperforms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1512" target="_blank">00:25:12.620</a></span> | <span class="t">Quick note that will still be important for many people out there, the performance of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1516" target="_blank">00:25:16.900</a></span> | <span class="t">O1 preview on languages other than English is noticeably improved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1521" target="_blank">00:25:21.460</a></span> | <span class="t">I go back to that hundreds of millions point I made earlier in the video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1524" target="_blank">00:25:24.980</a></span> | <span class="t">Being able to reason well in Hindi, French, Arabic, don't underestimate the impact of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1531" target="_blank">00:25:31.180</a></span> | <span class="t">that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1532" target="_blank">00:25:32.180</a></span> | <span class="t">So, some OpenAI researchers are calling this human level reasoning performance, making</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1537" target="_blank">00:25:37.220</a></span> | <span class="t">the point that it has arrived before we even got GPT 6.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1540" target="_blank">00:25:40.940</a></span> | <span class="t">Greg Brockman, temporarily posting while he's on sabbatical says, and I agree, its accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1545" target="_blank">00:25:45.860</a></span> | <span class="t">also has huge room for further improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1548" target="_blank">00:25:48.980</a></span> | <span class="t">And here's another OpenAI researcher again making that comparison to human performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1553" target="_blank">00:25:53.820</a></span> | <span class="t">Other staffers at OpenAI are admirably tamping down the hype.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1557" target="_blank">00:25:57.780</a></span> | <span class="t">It's not a miracle model, you might well be disappointed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1561" target="_blank">00:26:01.060</a></span> | <span class="t">Somewhat hopefully another one says, it might be hopefully the last new generation of models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1565" target="_blank">00:26:05.320</a></span> | <span class="t">to still fall victim to the 9.11 versus 9.9 debate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1569" target="_blank">00:26:09.700</a></span> | <span class="t">Another said, we trained a model and it is good in some things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1574" target="_blank">00:26:14.060</a></span> | <span class="t">So is this as Sam Altman said, strapping a rocket to a dumpster?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1578" target="_blank">00:26:18.700</a></span> | <span class="t">Will LLMs as the dumpster still get to orbit?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1582" target="_blank">00:26:22.540</a></span> | <span class="t">Will their floors, the trash fire go out as it leaves the atmosphere?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1586" target="_blank">00:26:26.400</a></span> | <span class="t">Is another OpenAI researcher right to say this is the moment where no one can say it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1591" target="_blank">00:26:31.220</a></span> | <span class="t">can't reason?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1592" target="_blank">00:26:32.220</a></span> | <span class="t">Well, on this perhaps I may well end up agreeing with Sam Altman.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1595" target="_blank">00:26:35.740</a></span> | <span class="t">Stochastic parrots they might be, but that will not stop them flying so high.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1600" target="_blank">00:26:40.960</a></span> | <span class="t">Hopefully you'll join me as I explore much more deeply the performance of O1, give you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1606" target="_blank">00:26:46.020</a></span> | <span class="t">those simple bench performance figures and try to unpack what this means for all of us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7J44j6Fw8NM&t=1611" target="_blank">00:26:51.340</a></span> | <span class="t">Thank you as ever for watching to the end and have a wonderful day.</span></div></div></body></html>