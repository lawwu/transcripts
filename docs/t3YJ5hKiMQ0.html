<html><head><title>Building makemore Part 5: Building a WaveNet</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Building makemore Part 5: Building a WaveNet</h2><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0"><img src="https://i.ytimg.com/vi_webp/t3YJ5hKiMQ0/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=0">0:0</a> intro<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=100">1:40</a> starter code walkthrough<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=416">6:56</a> let’s fix the learning rate plot<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=556">9:16</a> pytorchifying our code: layers, containers, torch.nn, fun bugs<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1031">17:11</a> overview: WaveNet<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1173">19:33</a> dataset bump the context size to 8<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1195">19:55</a> re-running baseline code on block_size 8<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1296">21:36</a> implementing WaveNet<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2261">37:41</a> training the WaveNet: first pass<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2330">38:50</a> fixing batchnorm1d bug<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2721">45:21</a> re-training WaveNet with bug fix<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2767">46:7</a> scaling up our WaveNet<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2818">46:58</a> experimental harness<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2864">47:44</a> WaveNet but with “dilated causal convolutions”<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3094">51:34</a> torch.nn<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3148">52:28</a> the development process of building deep neural nets<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3257">54:17</a> going forward<br><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3326">55:26</a> improve on my loss! how far can we improve a WaveNet on this data?<br><br><div style="text-align: left;"><a href="./t3YJ5hKiMQ0.html">Whisper Transcript</a> | <a href="./transcript_t3YJ5hKiMQ0.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hi everyone. Today we are continuing our implementation of MakeMore,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3" target="_blank">00:00:03.760</a></span> | <span class="t">our favorite character-level language model. Now, you'll notice that the background behind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=8" target="_blank">00:00:08.000</a></span> | <span class="t">me is different. That's because I am in Kyoto and it is awesome. So I'm in a hotel room here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=12" target="_blank">00:00:12.560</a></span> | <span class="t">Now, over the last few lectures we've built up to this architecture that is a multi-layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=18" target="_blank">00:00:18.160</a></span> | <span class="t">perceptron character-level language model. So we see that it receives three previous characters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=22" target="_blank">00:00:22.720</a></span> | <span class="t">and tries to predict the fourth character in a sequence using a very simple multi-layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=26" target="_blank">00:00:26.720</a></span> | <span class="t">perceptron using one hidden layer of neurons with tenational neurities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=30" target="_blank">00:00:30.720</a></span> | <span class="t">So what I'd like to do now in this lecture is I'd like to complexify this architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=34" target="_blank">00:00:34.880</a></span> | <span class="t">In particular, we would like to take more characters in a sequence as an input, not just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=39" target="_blank">00:00:39.440</a></span> | <span class="t">three. And in addition to that, we don't just want to feed them all into a single hidden layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=44" target="_blank">00:00:44.720</a></span> | <span class="t">because that squashes too much information too quickly. Instead, we would like to make a deeper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=49" target="_blank">00:00:49.200</a></span> | <span class="t">model that progressively fuses this information to make its guess about the next character in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=54" target="_blank">00:00:54.160</a></span> | <span class="t">a sequence. And so we'll see that as we make this architecture more complex, we're actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=59" target="_blank">00:00:59.680</a></span> | <span class="t">going to arrive at something that looks very much like a WaveNet. So WaveNet is this paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=64" target="_blank">00:01:04.800</a></span> | <span class="t">published by DeKind in 2016, and it is also a language model basically, but it tries to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=72" target="_blank">00:01:12.000</a></span> | <span class="t">audio sequences instead of character-level sequences or word-level sequences. But fundamentally,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=77" target="_blank">00:01:17.600</a></span> | <span class="t">the modeling setup is identical. It is an autoregressive model and it tries to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=83" target="_blank">00:01:23.120</a></span> | <span class="t">the next character in a sequence. And the architecture actually takes this interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=87" target="_blank">00:01:27.520</a></span> | <span class="t">hierarchical sort of approach to predicting the next character in a sequence with this tree-like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=93" target="_blank">00:01:33.440</a></span> | <span class="t">structure. And this is the architecture, and we're going to implement it in the course of this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=98" target="_blank">00:01:38.960</a></span> | <span class="t">So let's get started. So the story code for part five is very similar to where we ended up in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=104" target="_blank">00:01:44.400</a></span> | <span class="t">part three. Recall that part four was the manual backpropagation exercise that is kind of an aside.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=110" target="_blank">00:01:50.160</a></span> | <span class="t">So we are coming back to part three, copy-pasting chunks out of it, and that is our starter code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=114" target="_blank">00:01:54.400</a></span> | <span class="t">for part five. I've changed very few things otherwise. So a lot of this should look familiar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=118" target="_blank">00:01:58.720</a></span> | <span class="t">to you if you've gone through part three. So in particular, very briefly, we are doing imports.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=123" target="_blank">00:02:03.760</a></span> | <span class="t">We are reading our data set of words, and we are processing the data set of words into individual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=130" target="_blank">00:02:10.480</a></span> | <span class="t">examples, and none of this data generation code has changed. And basically, we have lots and lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=135" target="_blank">00:02:15.200</a></span> | <span class="t">of examples. In particular, we have 182,000 examples of three characters trying to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=142" target="_blank">00:02:22.000</a></span> | <span class="t">the fourth one. And we've broken up every one of these words into little problems of given three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=147" target="_blank">00:02:27.520</a></span> | <span class="t">characters, predict the fourth one. So this is our data set, and this is what we're trying to get the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=151" target="_blank">00:02:31.120</a></span> | <span class="t">neural net to do. Now, in part three, we started to develop our code around these layer modules</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=158" target="_blank">00:02:38.480</a></span> | <span class="t">that are, for example, a class linear. And we're doing this because we want to think of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=163" target="_blank">00:02:43.440</a></span> | <span class="t">modules as building blocks and like a Lego building block bricks that we can sort of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=168" target="_blank">00:02:48.960</a></span> | <span class="t">stack up into neural networks. And we can feed data between these layers and stack them up into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=174" target="_blank">00:02:54.240</a></span> | <span class="t">sort of graphs. Now, we also developed these layers to have APIs and signatures very similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=181" target="_blank">00:03:01.280</a></span> | <span class="t">to those that are found in PyTorch. So we have torch.nn, and it's got all these layer building</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=186" target="_blank">00:03:06.160</a></span> | <span class="t">blocks that you would use in practice. And we were developing all of these to mimic the APIs of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=190" target="_blank">00:03:10.720</a></span> | <span class="t">these. So for example, we have linear. So there will also be a torch.nn.linear, and its signature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=197" target="_blank">00:03:17.360</a></span> | <span class="t">will be very similar to our signature, and the functionality will be also quite identical as far</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=201" target="_blank">00:03:21.680</a></span> | <span class="t">as I'm aware. So we have the linear layer with the batch norm 1D layer and the 10H layer that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=207" target="_blank">00:03:27.200</a></span> | <span class="t">developed previously. And linear just does a matrix multiply in the forward pass of this module.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=213" target="_blank">00:03:33.600</a></span> | <span class="t">Batch norm, of course, is this crazy layer that we developed in the previous lecture. And what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=218" target="_blank">00:03:38.880</a></span> | <span class="t">crazy about it is, well, there's many things. Number one, it has these running mean and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=224" target="_blank">00:03:44.080</a></span> | <span class="t">variances that are trained outside of back propagation. They are trained using exponential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=229" target="_blank">00:03:49.840</a></span> | <span class="t">moving average inside this layer, what we call the forward pass. In addition to that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=235" target="_blank">00:03:55.600</a></span> | <span class="t">there's this training flag because the behavior of batch norm is different during train time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=240" target="_blank">00:04:00.400</a></span> | <span class="t">and evaluation time. And so suddenly, we have to be very careful that batch norm is in its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=244" target="_blank">00:04:04.160</a></span> | <span class="t">correct state, that it's in the evaluation state or training state. So that's something to now keep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=248" target="_blank">00:04:08.560</a></span> | <span class="t">track of, something that sometimes introduces bugs because you forget to put it into the right mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=253" target="_blank">00:04:13.840</a></span> | <span class="t">And finally, we saw that batch norm couples the statistics or the activations across the examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=260" target="_blank">00:04:20.240</a></span> | <span class="t">in the batch. So normally, we thought of the batch as just an efficiency thing. But now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=265" target="_blank">00:04:25.360</a></span> | <span class="t">we are coupling the computation across batch elements, and it's done for the purposes of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=270" target="_blank">00:04:30.880</a></span> | <span class="t">controlling the activation statistics as we saw in the previous video. So it's a very weird layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=276" target="_blank">00:04:36.320</a></span> | <span class="t">at least a lot of bugs, partly, for example, because you have to modulate the training and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=281" target="_blank">00:04:41.280</a></span> | <span class="t">eval phase and so on. In addition, for example, you have to wait for the mean and the variance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=288" target="_blank">00:04:48.720</a></span> | <span class="t">to settle and to actually reach a steady state. And so you have to make sure that you... Basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=294" target="_blank">00:04:54.400</a></span> | <span class="t">there's state in this layer, and state is harmful, usually. Now, I brought out the generator object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=302" target="_blank">00:05:02.640</a></span> | <span class="t">Previously, we had a generator equals G and so on inside these layers. I've discarded that in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=307" target="_blank">00:05:07.600</a></span> | <span class="t">favor of just initializing the torch RNG outside here just once globally, just for simplicity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=315" target="_blank">00:05:15.840</a></span> | <span class="t">And then here, we are starting to build out some of the neural network elements. This should look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=320" target="_blank">00:05:20.480</a></span> | <span class="t">very familiar. We have our embedding table C, and then we have a list of layers. And it's a linear,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=327" target="_blank">00:05:27.120</a></span> | <span class="t">feeds to batch or feeds to 10H, and then a linear output layer. And its weights are scaled down,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=333" target="_blank">00:05:33.040</a></span> | <span class="t">so we are not confidently wrong at initialization. We see that this is about 12,000 parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=338" target="_blank">00:05:38.400</a></span> | <span class="t">We're telling PyTorch that the parameters require gradients. The optimization is, as far as I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=344" target="_blank">00:05:44.320</a></span> | <span class="t">aware, identical and should look very, very familiar. Nothing changed here. Lost function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=350" target="_blank">00:05:50.480</a></span> | <span class="t">looks very crazy. We should probably fix this. And that's because 32 batch elements are too few.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=357" target="_blank">00:05:57.120</a></span> | <span class="t">And so you can get very lucky or unlucky in any one of these batches, and it creates a very thick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=362" target="_blank">00:06:02.560</a></span> | <span class="t">loss function. So we're going to fix that soon. Now, once we want to evaluate the trained neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=368" target="_blank">00:06:08.560</a></span> | <span class="t">network, we need to remember, because of the batch norm layers, to set all the layers to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=372" target="_blank">00:06:12.560</a></span> | <span class="t">be training equals false. This only matters for the batch norm layer so far. And then we evaluate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=378" target="_blank">00:06:18.480</a></span> | <span class="t">We see that currently we have a validation loss of 2.10, which is fairly good, but there's still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=385" target="_blank">00:06:25.760</a></span> | <span class="t">a ways to go. But even at 2.10, we see that when we sample from the model, we actually get relatively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=391" target="_blank">00:06:31.520</a></span> | <span class="t">name-like results that do not exist in a training set. So for example, Yvonne, Kilo, Pras, Alaya,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=400" target="_blank">00:06:40.640</a></span> | <span class="t">et cetera. So certainly not unreasonable, I would say, but not amazing. And we can still push this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=408" target="_blank">00:06:48.560</a></span> | <span class="t">validation loss even lower and get much better samples that are even more name-like. So let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=413" target="_blank">00:06:53.760</a></span> | <span class="t">improve this model now. OK, first, let's fix this graph, because it is daggers in my eyes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=419" target="_blank">00:06:59.520</a></span> | <span class="t">and I just can't take it anymore. So loss_i, if you recall, is a Python list of floats. So for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=427" target="_blank">00:07:07.040</a></span> | <span class="t">example, the first 10 elements look like this. Now, what we'd like to do basically is we need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=432" target="_blank">00:07:12.480</a></span> | <span class="t">to average up some of these values to get a more representative value along the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=439" target="_blank">00:07:19.520</a></span> | <span class="t">So one way to do this is the following. In PyTorch, if I create, for example, a tensor of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=445" target="_blank">00:07:25.680</a></span> | <span class="t">the first 10 numbers, then this is currently a one-dimensional array. But recall that I can view</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=450" target="_blank">00:07:30.880</a></span> | <span class="t">this array as two-dimensional. So for example, I can view it as a 2x5 array, and this is a 2D</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=456" target="_blank">00:07:36.560</a></span> | <span class="t">tensor now, 2x5. And you see what PyTorch has done is that the first row of this tensor is the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=462" target="_blank">00:07:42.800</a></span> | <span class="t">five elements, and the second row is the second five elements. I can also view it as a 5x2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=468" target="_blank">00:07:48.560</a></span> | <span class="t">as an example. And then recall that I can also use -1 in place of one of these numbers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=475" target="_blank">00:07:55.360</a></span> | <span class="t">and PyTorch will calculate what that number must be in order to make the number of elements work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=480" target="_blank">00:08:00.400</a></span> | <span class="t">out. So this can be this, or like that. Both will work. Of course, this would not work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=486" target="_blank">00:08:06.800</a></span> | <span class="t">Okay, so this allows it to spread out some of the consecutive values into rows. So that's very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=494" target="_blank">00:08:14.240</a></span> | <span class="t">helpful, because what we can do now is, first of all, we're going to create a Torch.tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=498" target="_blank">00:08:18.800</a></span> | <span class="t">out of the list of floats. And then we're going to view it as whatever it is, but we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=506" target="_blank">00:08:26.560</a></span> | <span class="t">stretch it out into rows of 1,000 consecutive elements. So the shape of this now becomes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=512" target="_blank">00:08:32.480</a></span> | <span class="t">200 by 1,000, and each row is 1,000 consecutive elements in this list. So that's very helpful,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=520" target="_blank">00:08:40.320</a></span> | <span class="t">because now we can do a mean along the rows, and the shape of this will just be 200.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=526" target="_blank">00:08:46.000</a></span> | <span class="t">And so we've taken basically the mean on every row. So plt.plot of that should be something nicer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=532" target="_blank">00:08:52.320</a></span> | <span class="t">Much better. So we see that we've basically made a lot of progress. And then here, this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=538" target="_blank">00:08:58.720</a></span> | <span class="t">learning rate decay. So here we see that the learning rate decay subtracted a ton of energy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=543" target="_blank">00:09:03.680</a></span> | <span class="t">out of the system, and allowed us to settle into the local minimum in this optimization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=549" target="_blank">00:09:09.280</a></span> | <span class="t">So this is a much nicer plot. Let me come up and delete the monster, and we're going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=555" target="_blank">00:09:15.040</a></span> | <span class="t">using this going forward. Now, next up, what I'm bothered by is that you see our forward pass is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=560" target="_blank">00:09:20.640</a></span> | <span class="t">a little bit gnarly, and takes way too many lines of code. So in particular, we see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=565" target="_blank">00:09:25.680</a></span> | <span class="t">we've organized some of the layers inside the layers list, but not all of them for no reason.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=571" target="_blank">00:09:31.120</a></span> | <span class="t">So in particular, we see that we still have the embedding table special case outside of the layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=576" target="_blank">00:09:36.800</a></span> | <span class="t">And in addition to that, the viewing operation here is also outside of our layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=580" target="_blank">00:09:40.880</a></span> | <span class="t">So let's create layers for these, and then we can add those layers to just our list.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=585" target="_blank">00:09:45.360</a></span> | <span class="t">So in particular, the two things that we need is here, we have this embedding table,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=591" target="_blank">00:09:51.200</a></span> | <span class="t">and we are indexing at the integers inside the batch xb, inside the tensor xb.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=597" target="_blank">00:09:57.520</a></span> | <span class="t">So that's an embedding table lookup just done with indexing. And then here we see that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=603" target="_blank">00:10:03.440</a></span> | <span class="t">have this view operation, which if you recall from the previous video, simply rearranges the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=608" target="_blank">00:10:08.320</a></span> | <span class="t">character embeddings and stretches them out into a row. And effectively, what that does is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=615" target="_blank">00:10:15.040</a></span> | <span class="t">concatenation operation, basically, except it's free because viewing is very cheap in PyTorch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=620" target="_blank">00:10:20.480</a></span> | <span class="t">And no memory is being copied. We're just re-representing how we view that tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=625" target="_blank">00:10:25.280</a></span> | <span class="t">So let's create modules for both of these operations, the embedding operation and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=632" target="_blank">00:10:32.000</a></span> | <span class="t">flattening operation. So I actually wrote the code just to save some time. So we have a module</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=639" target="_blank">00:10:39.600</a></span> | <span class="t">embedding and a module flatten, and both of them simply do the indexing operation in a forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=645" target="_blank">00:10:45.200</a></span> | <span class="t">pass and the flattening operation here. And this c now will just become a self.weight inside an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=654" target="_blank">00:10:54.800</a></span> | <span class="t">embedding module. And I'm calling these layers specifically embedding and flatten because it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=659" target="_blank">00:10:59.920</a></span> | <span class="t">turns out that both of them actually exist in PyTorch. So in PyTorch, we have n and dot embedding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=665" target="_blank">00:11:05.520</a></span> | <span class="t">and it also takes the number of embeddings and the dimensionality of the embedding, just like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=669" target="_blank">00:11:09.440</a></span> | <span class="t">we have here. But in addition, PyTorch takes in a lot of other keyword arguments that we are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=674" target="_blank">00:11:14.240</a></span> | <span class="t">using for our purposes yet. And for flatten, that also exists in PyTorch, and it also takes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=681" target="_blank">00:11:21.360</a></span> | <span class="t">additional keyword arguments that we are not using. So we have a very simple flatten.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=686" target="_blank">00:11:26.560</a></span> | <span class="t">But both of them exist in PyTorch, they're just a bit more simpler. And now that we have these,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=691" target="_blank">00:11:31.360</a></span> | <span class="t">we can simply take out some of these special cased things. So instead of c, we're just going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=700" target="_blank">00:11:40.000</a></span> | <span class="t">to have an embedding and a vocab size and n embed. And then after the embedding, we are going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=707" target="_blank">00:11:47.120</a></span> | <span class="t">flatten. So let's construct those modules. And now I can take out this c. And here, I don't have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=714" target="_blank">00:11:54.080</a></span> | <span class="t">special case it anymore, because now c is the embedding's weight, and it's inside layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=720" target="_blank">00:12:00.160</a></span> | <span class="t">So this should just work. And then here, our forward pass simplifies substantially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=727" target="_blank">00:12:07.600</a></span> | <span class="t">because we don't need to do these now outside of these layer, outside and explicitly. They're now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=733" target="_blank">00:12:13.600</a></span> | <span class="t">inside layers, so we can delete those. But now to kick things off, we want this little x, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=740" target="_blank">00:12:20.960</a></span> | <span class="t">in the beginning is just xb, the tensor of integers specifying the identities of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=745" target="_blank">00:12:25.760</a></span> | <span class="t">characters at the input. And so these characters can now directly feed into the first layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=750" target="_blank">00:12:30.720</a></span> | <span class="t">and this should just work. So let me come here and insert a break, because I just want to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=756" target="_blank">00:12:36.000</a></span> | <span class="t">sure that the first iteration of this runs and that there's no mistake. So that ran properly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=760" target="_blank">00:12:40.720</a></span> | <span class="t">And basically, we've substantially simplified the forward pass here. Okay, I'm sorry,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=765" target="_blank">00:12:45.520</a></span> | <span class="t">I changed my microphone. So hopefully, the audio is a little bit better. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=770" target="_blank">00:12:50.320</a></span> | <span class="t">one more thing that I would like to do in order to PyTorchify our code in further</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=773" target="_blank">00:12:53.840</a></span> | <span class="t">is that right now, we are maintaining all of our modules in a naked list of layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=777" target="_blank">00:12:57.520</a></span> | <span class="t">And we can also simplify this, because we can introduce the concept of PyTorch containers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=783" target="_blank">00:13:03.920</a></span> | <span class="t">So in torch.nn, which we are basically rebuilding from scratch here, there's a concept of containers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=788" target="_blank">00:13:08.400</a></span> | <span class="t">And these containers are basically a way of organizing layers into lists or dicts and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=795" target="_blank">00:13:15.520</a></span> | <span class="t">So in particular, there's a sequential, which maintains a list of layers, and is a module</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=801" target="_blank">00:13:21.040</a></span> | <span class="t">class in PyTorch. And it basically just passes a given input through all the layers sequentially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=806" target="_blank">00:13:26.400</a></span> | <span class="t">exactly as we are doing here. So let's write our own sequential. I've written a code here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=811" target="_blank">00:13:31.920</a></span> | <span class="t">And basically, the code for sequential is quite straightforward. We pass in a list of layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=817" target="_blank">00:13:37.520</a></span> | <span class="t">which we keep here. And then given any input in a forward pass, we just call the layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=822" target="_blank">00:13:42.080</a></span> | <span class="t">sequentially and return the result. And in terms of the parameters, it's just all the parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=826" target="_blank">00:13:46.240</a></span> | <span class="t">of the child modules. So we can run this. And we can again simplify this substantially. Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=832" target="_blank">00:13:52.480</a></span> | <span class="t">we don't maintain this naked list of layers. We now have a notion of a model, which is a module.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=837" target="_blank">00:13:57.920</a></span> | <span class="t">And in particular, is a sequential of all these layers. And now, parameters are simply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=846" target="_blank">00:14:06.880</a></span> | <span class="t">just model.parameters. And so that list comprehension now lives here. And then here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=854" target="_blank">00:14:14.320</a></span> | <span class="t">we are doing all the things we used to do. Now here, the code again simplifies substantially.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=860" target="_blank">00:14:20.880</a></span> | <span class="t">Because we don't have to do this forwarding here. Instead, we just call the model on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=865" target="_blank">00:14:25.200</a></span> | <span class="t">input data. And the input data here are the integers inside xb. So we can simply do logits,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=871" target="_blank">00:14:31.040</a></span> | <span class="t">which are the outputs of our model, are simply the model called on xb. And then the cross entropy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=878" target="_blank">00:14:38.080</a></span> | <span class="t">here takes the logits and the targets. So this simplifies substantially. And then this looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=885" target="_blank">00:14:45.280</a></span> | <span class="t">good. So let's just make sure this runs. That looks good. Now here, we actually have some work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=890" target="_blank">00:14:50.960</a></span> | <span class="t">to do still here, but I'm going to come back later. For now, there's no more layers. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=895" target="_blank">00:14:55.040</a></span> | <span class="t">a model that layers, but it's not easy to access attributes of these classes directly. So we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=900" target="_blank">00:15:00.880</a></span> | <span class="t">come back and fix this later. And then here, of course, this simplifies substantially as well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=905" target="_blank">00:15:05.680</a></span> | <span class="t">because logits are the model called on x. And then these logits come here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=911" target="_blank">00:15:11.840</a></span> | <span class="t">So we can evaluate the train and validation loss, which currently is terrible because we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=918" target="_blank">00:15:18.400</a></span> | <span class="t">initialized the neural net. And then we can also sample from the model. And this simplifies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=922" target="_blank">00:15:22.480</a></span> | <span class="t">dramatically as well, because we just want to call the model onto the context and outcome logits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=929" target="_blank">00:15:29.280</a></span> | <span class="t">And then these logits go into Softmax and get the probabilities, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=934" target="_blank">00:15:34.240</a></span> | <span class="t">So we can sample from this model. What did I screw up?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=938" target="_blank">00:15:38.880</a></span> | <span class="t">Okay, so I fixed the issue and we now get the result that we expect,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=945" target="_blank">00:15:45.520</a></span> | <span class="t">which is gibberish because the model is not trained because we reinitialize it from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=950" target="_blank">00:15:50.560</a></span> | <span class="t">The problem was that when I fixed this cell to be modeled out layers instead of just layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=954" target="_blank">00:15:54.960</a></span> | <span class="t">I did not actually run the cell. And so our neural net was in a training mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=959" target="_blank">00:15:59.360</a></span> | <span class="t">And what caused the issue here is the batch norm layer, as batch norm layer often likes to do,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=964" target="_blank">00:16:04.160</a></span> | <span class="t">because batch norm was in the training mode. And here we are passing in an input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=968" target="_blank">00:16:08.880</a></span> | <span class="t">which is a batch of just a single example made up of the context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=972" target="_blank">00:16:12.080</a></span> | <span class="t">And so if you are trying to pass in a single example into a batch norm that is in the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=976" target="_blank">00:16:16.800</a></span> | <span class="t">mode, you're going to end up estimating the variance using the input. And the variance of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=981" target="_blank">00:16:21.280</a></span> | <span class="t">a single number is not a number, because it is a measure of a spread. So for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=986" target="_blank">00:16:26.560</a></span> | <span class="t">the variance of just a single number five, you can see is not a number. And so that's what happened.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=991" target="_blank">00:16:31.760</a></span> | <span class="t">And batch norm basically caused an issue. And then that polluted all of the further processing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=997" target="_blank">00:16:37.040</a></span> | <span class="t">So all that we had to do was make sure that this runs. And we basically made the issue of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1005" target="_blank">00:16:45.120</a></span> | <span class="t">again, we didn't actually see the issue with the loss. We could have evaluated the loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1008" target="_blank">00:16:48.560</a></span> | <span class="t">but we got the wrong result because batch norm was in the training mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1011" target="_blank">00:16:51.360</a></span> | <span class="t">And so we still get a result, it's just the wrong result, because it's using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1016" target="_blank">00:16:56.080</a></span> | <span class="t">sample statistics of the batch. Whereas we want to use the running mean and running variance inside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1021" target="_blank">00:17:01.600</a></span> | <span class="t">the batch norm. And so again, an example of introducing a bug inline, because we did not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1028" target="_blank">00:17:08.800</a></span> | <span class="t">properly maintain the state of what is training or not. Okay, so I re-run everything. And here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1033" target="_blank">00:17:13.600</a></span> | <span class="t">where we are. As a reminder, we have the training loss of 2.05 and validation 2.10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1038" target="_blank">00:17:18.000</a></span> | <span class="t">Now, because these losses are very similar to each other, we have a sense that we are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1042" target="_blank">00:17:22.960</a></span> | <span class="t">overfitting too much on this task. And we can make additional progress in our performance by scaling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1048" target="_blank">00:17:28.160</a></span> | <span class="t">up the size of the neural network and making everything bigger and deeper. Now, currently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1053" target="_blank">00:17:33.200</a></span> | <span class="t">we are using this architecture here, where we are taking in some number of characters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1056" target="_blank">00:17:36.800</a></span> | <span class="t">going into a single hidden layer, and then going to the prediction of the next character.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1061" target="_blank">00:17:41.200</a></span> | <span class="t">The problem here is, we don't have a naive way of making this bigger in a productive way. We could,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1067" target="_blank">00:17:47.360</a></span> | <span class="t">of course, use our layers, sort of building blocks and materials to introduce additional layers here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1073" target="_blank">00:17:53.360</a></span> | <span class="t">and make the network deeper. But it is still the case that we are crushing all of the characters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1077" target="_blank">00:17:57.440</a></span> | <span class="t">into a single layer all the way at the beginning. And even if we make this a bigger layer and add</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1082" target="_blank">00:18:02.960</a></span> | <span class="t">neurons, it's still kind of like silly to squash all that information so fast in a single step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1089" target="_blank">00:18:09.760</a></span> | <span class="t">So we'd like to do instead is we'd like our network to look a lot more like this in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1093" target="_blank">00:18:13.520</a></span> | <span class="t">WaveNet case. So you see in the WaveNet, when we are trying to make the prediction for the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1097" target="_blank">00:18:17.840</a></span> | <span class="t">character in the sequence, it is a function of the previous characters that feed in. But not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1104" target="_blank">00:18:24.400</a></span> | <span class="t">all of these different characters are not just crushed to a single layer, and then you have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1108" target="_blank">00:18:28.640</a></span> | <span class="t">sandwich. They are crushed slowly. So in particular, we take two characters and we fuse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1114" target="_blank">00:18:34.640</a></span> | <span class="t">them into sort of like a bigram representation. And we do that for all these characters consecutively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1120" target="_blank">00:18:40.160</a></span> | <span class="t">And then we take the bigrams and we fuse those into four character level chunks. And then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1127" target="_blank">00:18:47.120</a></span> | <span class="t">fuse that again. And so we do that in this like tree-like hierarchical manner. So we fuse the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1132" target="_blank">00:18:52.720</a></span> | <span class="t">information from the previous context slowly into the network as it gets deeper. And so this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1138" target="_blank">00:18:58.560</a></span> | <span class="t">kind of architecture that we want to implement. Now, in the WaveNet's case, this is a visualization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1143" target="_blank">00:19:03.200</a></span> | <span class="t">of a stack of dilated causal convolution layers. And this makes it sound very scary, but actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1148" target="_blank">00:19:08.480</a></span> | <span class="t">the idea is very simple. And the fact that it's a dilated causal convolution layer is really just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1153" target="_blank">00:19:13.360</a></span> | <span class="t">an implementation detail to make everything fast. We're going to see that later. But for now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1157" target="_blank">00:19:17.680</a></span> | <span class="t">let's just keep the basic idea of it, which is this progressive fusion. So we want to make the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1162" target="_blank">00:19:22.240</a></span> | <span class="t">network deeper. And at each level, we want to fuse only two consecutive elements, two characters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1168" target="_blank">00:19:28.000</a></span> | <span class="t">then two bigrams, then two fourgrams, and so on. So let's implement this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1172" target="_blank">00:19:32.720</a></span> | <span class="t">Okay, so first up, let me scroll to where we built the dataset. And let's change the block size from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1176" target="_blank">00:19:36.720</a></span> | <span class="t">three to eight. So we're going to be taking eight characters of context to predict the ninth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1182" target="_blank">00:19:42.240</a></span> | <span class="t">character. So the dataset now looks like this. We have a lot more context feeding in to predict any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1187" target="_blank">00:19:47.440</a></span> | <span class="t">next character in a sequence. And these eight characters are going to be processed in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1191" target="_blank">00:19:51.440</a></span> | <span class="t">tree-like structure. Now, if we scroll here, everything here should just be able to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1197" target="_blank">00:19:57.440</a></span> | <span class="t">So we should be able to redefine the network. You see that the number of parameters has increased</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1201" target="_blank">00:20:01.440</a></span> | <span class="t">by 10,000. And that's because the block size has grown. So this first linear layer is much,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1206" target="_blank">00:20:06.800</a></span> | <span class="t">much bigger. Our linear layer now takes eight characters into this middle layer. So there's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1212" target="_blank">00:20:12.800</a></span> | <span class="t">lot more parameters there. But this should just run. Let me just break right after the very first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1218" target="_blank">00:20:18.720</a></span> | <span class="t">iteration. So you see that this runs just fine. It's just that this network doesn't make too much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1223" target="_blank">00:20:23.120</a></span> | <span class="t">sense. We're crushing way too much information way too fast. So let's now come in and see how we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1228" target="_blank">00:20:28.640</a></span> | <span class="t">could try to implement the hierarchical scheme. Now, before we dive into the detail of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1233" target="_blank">00:20:33.520</a></span> | <span class="t">reimplementation here, I was just curious to actually run it and see where we are in terms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1238" target="_blank">00:20:38.080</a></span> | <span class="t">of the baseline performance of just lazily scaling up the context length. So I let it run. We get a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1243" target="_blank">00:20:43.600</a></span> | <span class="t">nice loss curve. And then evaluating the loss, we actually see quite a bit of improvement just from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1248" target="_blank">00:20:48.720</a></span> | <span class="t">increasing the context length. So I started a little bit of a performance log here. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1253" target="_blank">00:20:53.200</a></span> | <span class="t">previously where we were is we were getting a performance of 2.10 on the validation loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1258" target="_blank">00:20:58.880</a></span> | <span class="t">And now simply scaling up the context length from three to eight gives us a performance of 2.02.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1264" target="_blank">00:21:04.160</a></span> | <span class="t">So quite a bit of an improvement here. And also, when you sample from the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1268" target="_blank">00:21:08.400</a></span> | <span class="t">you see that the names are definitely improving qualitatively as well. So we could, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1273" target="_blank">00:21:13.840</a></span> | <span class="t">spend a lot of time here tuning things and making it even bigger and scaling up the network further,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1279" target="_blank">00:21:19.840</a></span> | <span class="t">even with a simple set up here. But let's continue. And let's implement the hierarchical model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1286" target="_blank">00:21:26.400</a></span> | <span class="t">and treat this as just a rough baseline performance. But there's a lot of optimization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1291" target="_blank">00:21:31.680</a></span> | <span class="t">left on the table in terms of some of the hyperparameters that you're hopefully getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1295" target="_blank">00:21:35.200</a></span> | <span class="t">a sense of now. OK, so let's scroll up now and come back up. And what I've done here is I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1301" target="_blank">00:21:41.040</a></span> | <span class="t">created a bit of a scratch space for us to just look at the forward pass of the neural net and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1306" target="_blank">00:21:46.560</a></span> | <span class="t">inspect the shape of the tensors along the way as the neural net forwards. So here I'm just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1313" target="_blank">00:21:53.040</a></span> | <span class="t">temporarily for debugging, creating a batch of just, say, four examples, so four random integers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1319" target="_blank">00:21:59.040</a></span> | <span class="t">Then I'm plucking out those rows from our training set. And then I'm passing into the model the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1324" target="_blank">00:22:04.560</a></span> | <span class="t">input xb. Now, the shape of xb here, because we have only four examples, is four by eight. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1330" target="_blank">00:22:10.880</a></span> | <span class="t">this eight is now the current block size. So inspecting xb, we just see that we have four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1337" target="_blank">00:22:17.920</a></span> | <span class="t">examples. Each one of them is a row of xb. And we have eight characters here. And this integer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1345" target="_blank">00:22:25.040</a></span> | <span class="t">tensor just contains the identities of those characters. So the first layer of our neural net</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1350" target="_blank">00:22:30.880</a></span> | <span class="t">is the embedding layer. So passing xb, this integer tensor, through the embedding layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1356" target="_blank">00:22:36.080</a></span> | <span class="t">creates an output that is four by eight by 10. So our embedding table has, for each character,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1363" target="_blank">00:22:43.120</a></span> | <span class="t">a 10-dimensional vector that we are trying to learn. And so what the embedding layer does here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1368" target="_blank">00:22:48.320</a></span> | <span class="t">is it plucks out the embedding vector for each one of these integers and organizes it all in a four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1375" target="_blank">00:22:55.360</a></span> | <span class="t">by eight by 10 tensor now. So all of these integers are translated into 10-dimensional vectors inside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1382" target="_blank">00:23:02.000</a></span> | <span class="t">this three-dimensional tensor now. Now, passing that through the flattened layer, as you recall,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1387" target="_blank">00:23:07.360</a></span> | <span class="t">what this does is it views this tensor as just a four by 80 tensor. And what that effectively does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1394" target="_blank">00:23:14.080</a></span> | <span class="t">is that all these 10-dimensional embeddings for all these eight characters just end up being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1398" target="_blank">00:23:18.640</a></span> | <span class="t">stretched out into a long row. And that looks kind of like a concatenation operation, basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1404" target="_blank">00:23:24.560</a></span> | <span class="t">So by viewing the tensor differently, we now have a four by 80. And inside this 80,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1409" target="_blank">00:23:29.920</a></span> | <span class="t">it's all the 10-dimensional vectors just concatenated next to each other. And the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1416" target="_blank">00:23:36.400</a></span> | <span class="t">linear layer, of course, takes 80 and creates 200 channels just via matrix multiplication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1422" target="_blank">00:23:42.160</a></span> | <span class="t">So, so far, so good. Now I'd like to show you something surprising.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1426" target="_blank">00:23:46.000</a></span> | <span class="t">Let's look at the insides of the linear layer and remind ourselves how it works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1432" target="_blank">00:23:52.480</a></span> | <span class="t">The linear layer here in a forward pass takes the input x, multiplies it with a weight,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1437" target="_blank">00:23:57.440</a></span> | <span class="t">and then optionally adds a bias. And the weight here is two-dimensional, as defined here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1441" target="_blank">00:24:01.680</a></span> | <span class="t">and the bias is one-dimensional here. So effectively, in terms of the shapes involved,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1447" target="_blank">00:24:07.040</a></span> | <span class="t">what's happening inside this linear layer looks like this right now. And I'm using random numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1452" target="_blank">00:24:12.000</a></span> | <span class="t">here, but I'm just illustrating the shapes and what happens. Basically, a four by 80 input comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1458" target="_blank">00:24:18.480</a></span> | <span class="t">into the linear layer, gets multiplied by this 80 by 200 weight matrix inside, and there's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1463" target="_blank">00:24:23.200</a></span> | <span class="t">plus 200 bias. And the shape of the whole thing that comes out of the linear layer is four by 200,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1468" target="_blank">00:24:28.560</a></span> | <span class="t">as we see here. Now, notice here, by the way, that this here will create a four by 200 tensor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1475" target="_blank">00:24:35.840</a></span> | <span class="t">and then plus 200, there's a broadcasting happening here. But four by 200 broadcasts with 200,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1481" target="_blank">00:24:41.600</a></span> | <span class="t">so everything works here. So now the surprising thing that I'd like to show you that you may not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1487" target="_blank">00:24:47.120</a></span> | <span class="t">expect is that this input here that is being multiplied doesn't actually have to be two-</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1492" target="_blank">00:24:52.080</a></span> | <span class="t">dimensional. This matrix multiply operator in PyTorch is quite powerful, and in fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1497" target="_blank">00:24:57.280</a></span> | <span class="t">you can actually pass in higher-dimensional arrays or tensors, and everything works fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1501" target="_blank">00:25:01.680</a></span> | <span class="t">So for example, this could be four by five by 80, and the result in that case will become</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1505" target="_blank">00:25:05.840</a></span> | <span class="t">four by five by 200. You can add as many dimensions as you like on the left here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1510" target="_blank">00:25:10.480</a></span> | <span class="t">And so effectively, what's happening is that the matrix multiplication only works on the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1516" target="_blank">00:25:16.240</a></span> | <span class="t">dimension, and the dimensions before it in the input tensor are left unchanged.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1520" target="_blank">00:25:20.800</a></span> | <span class="t">So basically, these dimensions on the left are all treated as just a batch dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1530" target="_blank">00:25:30.240</a></span> | <span class="t">So we can have multiple batch dimensions, and then in parallel over all those dimensions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1536" target="_blank">00:25:36.320</a></span> | <span class="t">we are doing the matrix multiplication on the last dimension. So this is quite convenient,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1540" target="_blank">00:25:40.800</a></span> | <span class="t">because we can use that in our network now. Because remember that we have these eight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1546" target="_blank">00:25:46.160</a></span> | <span class="t">characters coming in, and we don't want to now flatten all of it out into a large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1552" target="_blank">00:25:52.800</a></span> | <span class="t">eight-dimensional vector, because we don't want to matrix multiply 80 into a weight matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1560" target="_blank">00:26:00.560</a></span> | <span class="t">multiply immediately. Instead, we want to group these like this. So every consecutive two elements,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1569" target="_blank">00:26:09.680</a></span> | <span class="t">one, two, and three, and four, and five, and six, and seven, and eight, all of these should be now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1573" target="_blank">00:26:13.040</a></span> | <span class="t">basically flattened out and multiplied by a weight matrix. But all of these four groups here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1580" target="_blank">00:26:20.320</a></span> | <span class="t">we'd like to process in parallel. So it's kind of like a batch dimension that we can introduce.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1585" target="_blank">00:26:25.120</a></span> | <span class="t">And then we can in parallel basically process all of these bigram groups in the four batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1593" target="_blank">00:26:33.760</a></span> | <span class="t">dimensions of an individual example, and also over the actual batch dimension of the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1598" target="_blank">00:26:38.880</a></span> | <span class="t">you know, four examples in our example here. So let's see how that works. Effectively,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1603" target="_blank">00:26:43.680</a></span> | <span class="t">what we want is right now, we take a 4 by 80, and multiply it by 80 by 200</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1609" target="_blank">00:26:49.360</a></span> | <span class="t">in the linear layer. This is what happens. But instead, what we want is, we don't want 80</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1616" target="_blank">00:26:56.480</a></span> | <span class="t">characters or 80 numbers to come in. We only want two characters to come in on the very first layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1621" target="_blank">00:27:01.920</a></span> | <span class="t">and those two characters should be fused. So in other words, we just want 20 to come in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1628" target="_blank">00:27:08.000</a></span> | <span class="t">right? 20 numbers would come in. And here, we don't want a 4 by 80 to feed into the linear layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1634" target="_blank">00:27:14.320</a></span> | <span class="t">We actually want these groups of two to feed in. So instead of 4 by 80, we want this to be a 4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1640" target="_blank">00:27:20.000</a></span> | <span class="t">by 4 by 20. So these are the four groups of two, and each one of them is 10-dimensional vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1648" target="_blank">00:27:28.720</a></span> | <span class="t">So what we want is now, is we need to change the flattened layer. So it doesn't output a 4 by 80,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1654" target="_blank">00:27:34.400</a></span> | <span class="t">but it outputs a 4 by 4 by 20, where basically, every two consecutive characters are packed in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1664" target="_blank">00:27:44.320</a></span> | <span class="t">on the very last dimension. And then these four is the first batch dimension, and this four is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1670" target="_blank">00:27:50.000</a></span> | <span class="t">second batch dimension, referring to the four groups inside every one of these examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1674" target="_blank">00:27:54.400</a></span> | <span class="t">And then this will just multiply like this. So this is what we want to get to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1679" target="_blank">00:27:59.280</a></span> | <span class="t">So we're going to have to change the linear layer in terms of how many inputs it expects.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1683" target="_blank">00:28:03.280</a></span> | <span class="t">It shouldn't expect 80, it should just expect 20 numbers. And we have to change our flattened layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1688" target="_blank">00:28:08.960</a></span> | <span class="t">so it doesn't just fully flatten out this entire example. It needs to create a 4 by 4 by 20 instead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1695" target="_blank">00:28:15.680</a></span> | <span class="t">of a 4 by 80. So let's see how this could be implemented. Basically, right now, we have an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1700" target="_blank">00:28:20.800</a></span> | <span class="t">input that is a 4 by 8 by 10 that feeds into the flattened layer. And currently, the flattened</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1706" target="_blank">00:28:26.480</a></span> | <span class="t">layer just stretches it out. So if you remember the implementation of flatten, it takes our x,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1712" target="_blank">00:28:32.800</a></span> | <span class="t">and it just views it as whatever the batch dimension is, and then negative 1. So effectively,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1717" target="_blank">00:28:37.840</a></span> | <span class="t">what it does right now is it does E.view of 4, negative 1, and the shape of this, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1723" target="_blank">00:28:43.280</a></span> | <span class="t">is 4 by 80. So that's what currently happens. And we instead want this to be a 4 by 4 by 20,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1730" target="_blank">00:28:50.560</a></span> | <span class="t">where these consecutive 10-dimensional vectors get concatenated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1733" target="_blank">00:28:53.280</a></span> | <span class="t">So you know how in Python, you can take a list of range of 10. So we have numbers from 0 to 9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1742" target="_blank">00:29:02.880</a></span> | <span class="t">And we can index like this to get all the even parts. And we can also index like starting at 1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1749" target="_blank">00:29:09.040</a></span> | <span class="t">and going in steps of 2 to get all the odd parts. So one way to implement this would be as follows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1756" target="_blank">00:29:16.400</a></span> | <span class="t">We can take E, and we can index into it for all the batch elements, and then just even elements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1763" target="_blank">00:29:23.680</a></span> | <span class="t">in this dimension. So at indexes 0, 2, 4, and 8. And then all the parts here from this last dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1773" target="_blank">00:29:33.120</a></span> | <span class="t">And this gives us the even characters. And then here, this gives us all the odd characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1781" target="_blank">00:29:41.440</a></span> | <span class="t">And basically, what we want to do is we want to make sure that these get concatenated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1785" target="_blank">00:29:45.280</a></span> | <span class="t">in PyTorch. And then we want to concatenate these two tensors along the second dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1791" target="_blank">00:29:51.040</a></span> | <span class="t">So this and the shape of it would be 4 by 4 by 20. This is definitely the result we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1798" target="_blank">00:29:58.160</a></span> | <span class="t">We are explicitly grabbing the even parts and the odd parts. And we're arranging those 4 by 4 by 10</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1805" target="_blank">00:30:05.600</a></span> | <span class="t">right next to each other and concatenate. So this works. But it turns out that what also works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1811" target="_blank">00:30:11.440</a></span> | <span class="t">is you can simply use view again and just request the right shape. And it just so happens that in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1817" target="_blank">00:30:17.440</a></span> | <span class="t">this case, those vectors will again end up being arranged exactly the way we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1822" target="_blank">00:30:22.560</a></span> | <span class="t">So in particular, if we take E, and we just view it as a 4 by 4 by 20, which is what we want,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1828" target="_blank">00:30:28.720</a></span> | <span class="t">we can check that this is exactly equal to, let me call this, this is the explicit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1833" target="_blank">00:30:33.760</a></span> | <span class="t">concatenation, I suppose. So explicit dot shape is 4 by 4 by 20. If you just view it as 4 by 4 by 20,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1842" target="_blank">00:30:42.080</a></span> | <span class="t">you can check that when you compare to explicit, you get a bit, this is element-wise operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1848" target="_blank">00:30:48.640</a></span> | <span class="t">So making sure that all of them are true, the values to true. So basically, long story short,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1854" target="_blank">00:30:54.160</a></span> | <span class="t">we don't need to make an explicit call to concatenate, etc. We can simply take this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1859" target="_blank">00:30:59.200</a></span> | <span class="t">input tensor to flatten, and we can just view it in whatever way we want. And in particular,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1866" target="_blank">00:31:06.400</a></span> | <span class="t">we don't want to stretch things out with negative one, we want to actually create a three-dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1870" target="_blank">00:31:10.720</a></span> | <span class="t">array. And depending on how many vectors that are consecutive, we want to fuse, like for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1878" target="_blank">00:31:18.480</a></span> | <span class="t">two, then we can just simply ask for this dimension to be 20. And using negative one here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1885" target="_blank">00:31:25.440</a></span> | <span class="t">and PyTorch will figure out how many groups it needs to pack into this additional batch dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1889" target="_blank">00:31:29.840</a></span> | <span class="t">So let's now go into flatten and implement this. Okay, so I scrolled up here to flatten.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1895" target="_blank">00:31:35.360</a></span> | <span class="t">And what we'd like to do is we'd like to change it now. So let me create a constructor and take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1899" target="_blank">00:31:39.840</a></span> | <span class="t">the number of elements that are consecutive that we would like to concatenate now in the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1904" target="_blank">00:31:44.480</a></span> | <span class="t">dimension of the output. So here, we're just going to remember, cell.n equals n. And then I want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1911" target="_blank">00:31:51.360</a></span> | <span class="t">be careful here, because PyTorch actually has a Torch.flatten, and its keyword arguments are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1916" target="_blank">00:31:56.560</a></span> | <span class="t">different, and they kind of like function differently. So our flatten is going to start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1920" target="_blank">00:32:00.640</a></span> | <span class="t">to depart from PyTorch.flatten. So let me call it flatten consecutive, or something like that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1926" target="_blank">00:32:06.080</a></span> | <span class="t">just to make sure that our APIs are about equal. So this basically flattens only some n</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1933" target="_blank">00:32:13.920</a></span> | <span class="t">consecutive elements and puts them into the last dimension. Now here, the shape of x is b by t by c.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1941" target="_blank">00:32:21.360</a></span> | <span class="t">So let me pop those out into variables and recall that in our example down below, b was 4, t was 8,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1949" target="_blank">00:32:29.440</a></span> | <span class="t">and c was 10. Now, instead of doing x.view of b by negative one, right, this is what we had before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1960" target="_blank">00:32:40.960</a></span> | <span class="t">We want this to be b by negative one by, and basically here, we want c times n. That's how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1969" target="_blank">00:32:49.520</a></span> | <span class="t">many consecutive elements we want. And here, instead of negative one, I don't super love the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1975" target="_blank">00:32:55.920</a></span> | <span class="t">use of negative one, because I like to be very explicit so that you get error messages when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1979" target="_blank">00:32:59.840</a></span> | <span class="t">things don't go according to your expectation. So what do we expect here? We expect this to become</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1984" target="_blank">00:33:04.480</a></span> | <span class="t">t divide n, using integer division here. So that's what I expect to happen. And then one more thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1991" target="_blank">00:33:11.440</a></span> | <span class="t">I want to do here is, remember previously, all the way in the beginning, n was 3, and basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=1998" target="_blank">00:33:18.240</a></span> | <span class="t">we're concatenating all the three characters that existed there. So we basically concatenated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2005" target="_blank">00:33:25.120</a></span> | <span class="t">everything. And so sometimes that can create a spurious dimension of one here. So if it is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2010" target="_blank">00:33:30.880</a></span> | <span class="t">case that x.shape at one is one, then it's kind of like a spurious dimension. So we don't want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2018" target="_blank">00:33:38.240</a></span> | <span class="t">return a three-dimensional tensor with a one here. We just want to return a two-dimensional tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2023" target="_blank">00:33:43.520</a></span> | <span class="t">exactly as we did before. So in this case, basically, we will just say x equals x.squeeze,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2029" target="_blank">00:33:49.600</a></span> | <span class="t">that is a PyTorch function. And squeeze takes a dimension that it identifies as a three-dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2039" target="_blank">00:33:59.280</a></span> | <span class="t">dimension, that it either squeezes out all the dimensions of a tensor that are one, or you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2045" target="_blank">00:34:05.520</a></span> | <span class="t">specify the exact dimension that you want to be squeezed. And again, I like to be as explicit as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2051" target="_blank">00:34:11.520</a></span> | <span class="t">possible always. So I expect to squeeze out the first dimension only of this tensor, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2058" target="_blank">00:34:18.240</a></span> | <span class="t">three-dimensional tensor. And if this dimension here is one, then I just want to return b by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2062" target="_blank">00:34:22.960</a></span> | <span class="t">n. And so self.out will be x, and then we return self.out. So that's the candidate implementation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2071" target="_blank">00:34:31.040</a></span> | <span class="t">And of course, this should be self.in instead of just n. So let's run. And let's come here now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2078" target="_blank">00:34:38.000</a></span> | <span class="t">and take it for a spin. So flatten consecutive. And in the beginning, let's just use eight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2087" target="_blank">00:34:47.680</a></span> | <span class="t">So this should recover the previous behavior. So flatten consecutive of eight, which is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2092" target="_blank">00:34:52.960</a></span> | <span class="t">current block size. We can do this. That should recover the previous behavior. So we should be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2100" target="_blank">00:35:00.400</a></span> | <span class="t">able to run the model. And here we can inspect. I have a little code snippet here where I iterate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2107" target="_blank">00:35:07.680</a></span> | <span class="t">over all the layers. I print the name of this class and the shape. And so we see the shapes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2116" target="_blank">00:35:16.960</a></span> | <span class="t">as we expect them after every single layer in its output. So now let's try to restructure it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2122" target="_blank">00:35:22.720</a></span> | <span class="t">using our flatten consecutive and do it hierarchically. So in particular,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2127" target="_blank">00:35:27.440</a></span> | <span class="t">we want to flatten consecutive not block size, but just two. And then we want to process this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2134" target="_blank">00:35:34.400</a></span> | <span class="t">with linear. Now the number of inputs to this linear will not be n embed times block size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2139" target="_blank">00:35:39.600</a></span> | <span class="t">It will now only be n embed times two, 20. This goes through the first layer. And now we can,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2147" target="_blank">00:35:47.040</a></span> | <span class="t">in principle, just copy paste this. Now the next linear layer should expect n hidden times two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2152" target="_blank">00:35:52.800</a></span> | <span class="t">And the last piece of it should expect n hidden times two again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2159" target="_blank">00:35:59.680</a></span> | <span class="t">So this is sort of like the naive version of it. So running this, we now have a much,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2167" target="_blank">00:36:07.280</a></span> | <span class="t">much bigger model. And we should be able to basically just forward the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2171" target="_blank">00:36:11.760</a></span> | <span class="t">And now we can inspect the numbers in between. So 4 by 8 by 20 was flattened consecutively into 4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2181" target="_blank">00:36:21.040</a></span> | <span class="t">by 4 by 20. This was projected into 4 by 4 by 200. And then Bashorm just worked out of the box. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2190" target="_blank">00:36:30.160</a></span> | <span class="t">we have to verify that Bashorm does the correct thing, even though it takes a three-dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2193" target="_blank">00:36:33.600</a></span> | <span class="t">embed instead of two-dimensional embed. Then we have 10h, which is element-wise. Then we crushed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2199" target="_blank">00:36:39.600</a></span> | <span class="t">it again. So we flattened consecutively and ended up with a 4 by 2 by 400 now. Then linear brought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2206" target="_blank">00:36:46.000</a></span> | <span class="t">it back down to 200, Bashorm 10h. And lastly, we get a 4 by 400. And we see that the flattened</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2212" target="_blank">00:36:52.000</a></span> | <span class="t">consecutive for the last flattened here, it squeezed out that dimension of one. So we only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2217" target="_blank">00:36:57.520</a></span> | <span class="t">ended up with 4 by 400. And then linear Bashorm 10h and the last linear layer to get our logits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2224" target="_blank">00:37:04.880</a></span> | <span class="t">And so the logits end up in the same shape as they were before. But now we actually have a nice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2229" target="_blank">00:37:09.600</a></span> | <span class="t">three-layer neural net. And it basically corresponds to-- whoops, sorry. It basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2234" target="_blank">00:37:14.880</a></span> | <span class="t">corresponds exactly to this network now, except only this piece here, because we only have three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2240" target="_blank">00:37:20.080</a></span> | <span class="t">layers. Whereas here in this example, there's four layers with a total receptive field size of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2247" target="_blank">00:37:27.440</a></span> | <span class="t">16 characters instead of just eight characters. So the block size here is 16. So this piece of it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2253" target="_blank">00:37:33.920</a></span> | <span class="t">is basically implemented here. Now we just have to figure out some good channel numbers to use here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2261" target="_blank">00:37:41.200</a></span> | <span class="t">Now in particular, I changed the number of hidden units to be 68 in this architecture,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2266" target="_blank">00:37:46.240</a></span> | <span class="t">because when I use 68, the number of parameters comes out to be 22,000. So that's exactly the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2271" target="_blank">00:37:51.280</a></span> | <span class="t">same that we had before. And we have the same amount of capacity at this neural net in terms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2275" target="_blank">00:37:55.760</a></span> | <span class="t">of the number of parameters. But the question is whether we are utilizing those parameters in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2279" target="_blank">00:37:59.600</a></span> | <span class="t">more efficient architecture. So what I did then is I got rid of a lot of the debugging cells here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2285" target="_blank">00:38:05.440</a></span> | <span class="t">and I reran the optimization. And scrolling down to the result, we see that we get the identical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2291" target="_blank">00:38:11.360</a></span> | <span class="t">performance roughly. So our validation loss now is 2.029, and previously it was 2.027.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2297" target="_blank">00:38:17.600</a></span> | <span class="t">So controlling for the number of parameters, changing from the flat to hierarchical is not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2301" target="_blank">00:38:21.200</a></span> | <span class="t">giving us anything yet. That said, there are two things to point out. Number one, we didn't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2307" target="_blank">00:38:27.600</a></span> | <span class="t">torture the architecture here very much. This is just my first guess. And there's a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2312" target="_blank">00:38:32.240</a></span> | <span class="t">hyperparameter search that we could do in terms of how we allocate our budget of parameters to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2318" target="_blank">00:38:38.000</a></span> | <span class="t">what layers. Number two, we still may have a bug inside the BashNorm1D layer. So let's take a look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2324" target="_blank">00:38:44.480</a></span> | <span class="t">at that, because it runs, but does it do the right thing? So I pulled up the layer inspector that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2333" target="_blank">00:38:53.840</a></span> | <span class="t">have here and printed out the shapes along the way. And currently it looks like the BashNorm is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2338" target="_blank">00:38:58.240</a></span> | <span class="t">receiving an input that is 32 by 4 by 68. And here on the right, I have the current implementation of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2344" target="_blank">00:39:04.880</a></span> | <span class="t">BashNorm that we have right now. Now, this BashNorm assumed, in the way we wrote it and at the time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2350" target="_blank">00:39:10.400</a></span> | <span class="t">that x is two-dimensional. So it was n by d, where n was the batch size. So that's why we only reduced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2357" target="_blank">00:39:17.920</a></span> | <span class="t">the mean and the variance over the zeroth dimension. But now x will basically become</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2362" target="_blank">00:39:22.000</a></span> | <span class="t">three-dimensional. So what's happening inside the BashNorm layer right now, and how come it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2365" target="_blank">00:39:25.680</a></span> | <span class="t">working at all and not giving any errors? The reason for that is basically because everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2370" target="_blank">00:39:30.000</a></span> | <span class="t">broadcasts properly, but the BashNorm is not doing what we want it to do. So in particular,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2376" target="_blank">00:39:36.400</a></span> | <span class="t">let's basically think through what's happening inside the BashNorm, looking at what's happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2381" target="_blank">00:39:41.760</a></span> | <span class="t">here. I have the code here. So we're receiving an input of 32 by 4 by 68. And then we are doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2390" target="_blank">00:39:50.480</a></span> | <span class="t">here, x dot mean, here I have e instead of x, but we're doing the mean over zero. And that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2397" target="_blank">00:39:57.360</a></span> | <span class="t">actually given us 1 by 4 by 68. So we're doing the mean only over the very first dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2402" target="_blank">00:40:02.480</a></span> | <span class="t">And it's given us a mean and a variance that still maintain this dimension here. So these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2408" target="_blank">00:40:08.240</a></span> | <span class="t">means are only taking over 32 numbers in the first dimension. And then when we perform this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2413" target="_blank">00:40:13.200</a></span> | <span class="t">everything broadcasts correctly still. But basically what ends up happening is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2418" target="_blank">00:40:18.480</a></span> | <span class="t">when we also look at the running mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2422" target="_blank">00:40:22.160</a></span> | <span class="t">the shape of it. So I'm looking at the model dot layers at three, which is the first BashNorm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2429" target="_blank">00:40:29.280</a></span> | <span class="t">layer, and then looking at whatever the running mean became and its shape. The shape of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2434" target="_blank">00:40:34.720</a></span> | <span class="t">running mean now is 1 by 4 by 68. Instead of it being just a size of dimension, because we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2443" target="_blank">00:40:43.520</a></span> | <span class="t">68 channels, we expect to have 68 means and variances that we're maintaining. But actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2448" target="_blank">00:40:48.800</a></span> | <span class="t">we have an array of 4 by 68. And so basically what this is telling us is this BashNorm is currently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2456" target="_blank">00:40:56.320</a></span> | <span class="t">working in parallel over 4 times 68 instead of just 68 channels. So basically, we are maintaining</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2468" target="_blank">00:41:08.400</a></span> | <span class="t">statistics for every one of these four positions individually and independently. And instead,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2474" target="_blank">00:41:14.160</a></span> | <span class="t">what we want to do is we want to treat this 4 as a Bash dimension, just like the 0th dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2479" target="_blank">00:41:19.200</a></span> | <span class="t">So as far as the BashNorm is concerned, we don't want to average over 32 numbers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2486" target="_blank">00:41:26.240</a></span> | <span class="t">we want to now average over 32 times 4 numbers for every single one of these 68 channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2491" target="_blank">00:41:31.760</a></span> | <span class="t">So let me now remove this. It turns out that when you look at the documentation of torch.mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2500" target="_blank">00:41:40.000</a></span> | <span class="t">in one of its signatures, when we specify the dimension,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2513" target="_blank">00:41:53.120</a></span> | <span class="t">we see that the dimension here is not just, it can be int or it can also be a tuple of ints.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2517" target="_blank">00:41:57.520</a></span> | <span class="t">So we can reduce over multiple integers at the same time, over multiple dimensions at the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2523" target="_blank">00:42:03.040</a></span> | <span class="t">time. So instead of just reducing over 0, we can pass in a tuple, 0, 1, and here 0, 1 as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2529" target="_blank">00:42:09.760</a></span> | <span class="t">And then what's going to happen is the output, of course, is going to be the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2533" target="_blank">00:42:13.040</a></span> | <span class="t">But now what's going to happen is because we reduce over 0 and 1, if we look at in mean.shape,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2540" target="_blank">00:42:20.080</a></span> | <span class="t">we see that now we've reduced, we took the mean over both the 0th and the 1st dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2545" target="_blank">00:42:25.760</a></span> | <span class="t">So we're just getting 68 numbers and a bunch of spurious dimensions here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2549" target="_blank">00:42:29.840</a></span> | <span class="t">So now this becomes 1 by 1 by 68, and the running mean and the running variance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2555" target="_blank">00:42:35.920</a></span> | <span class="t">analogously, will become 1 by 1 by 68. So even though there are the spurious dimensions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2560" target="_blank">00:42:40.320</a></span> | <span class="t">the correct thing will happen in that we are only maintaining means and variances for 68 channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2569" target="_blank">00:42:49.520</a></span> | <span class="t">And we're now calculating the mean and variance across 32 times 4 dimensions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2574" target="_blank">00:42:54.080</a></span> | <span class="t">So that's exactly what we want. And let's change the implementation of BatchNorm1D that we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2579" target="_blank">00:42:59.680</a></span> | <span class="t">so that it can take in two-dimensional or three-dimensional inputs and perform accordingly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2585" target="_blank">00:43:05.120</a></span> | <span class="t">So at the end of the day, the fix is relatively straightforward. Basically, the dimension we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2589" target="_blank">00:43:09.040</a></span> | <span class="t">want to reduce over is either 0 or the tuple 0 and 1, depending on the dimensionality of x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2595" target="_blank">00:43:15.280</a></span> | <span class="t">So if x.ndim is 2, so it's a two-dimensional tensor, then the dimension we want to reduce over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2600" target="_blank">00:43:20.480</a></span> | <span class="t">is just the integer 0. If x.ndim is 3, so it's a three-dimensional tensor, then the dims we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2606" target="_blank">00:43:26.960</a></span> | <span class="t">going to assume are 0 and 1 that we want to reduce over. And then here, we just pass in dim.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2612" target="_blank">00:43:32.880</a></span> | <span class="t">And if the dimensionality of x is anything else, we'll now get an error, which is good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2616" target="_blank">00:43:36.640</a></span> | <span class="t">So that should be the fix. Now I want to point out one more thing. We're actually departing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2623" target="_blank">00:43:43.200</a></span> | <span class="t">from the API of PyTorch here a little bit. Because when you come to BatchNorm1D in PyTorch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2627" target="_blank">00:43:47.920</a></span> | <span class="t">you can scroll down and you can see that the input to this layer can either be n by c,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2633" target="_blank">00:43:53.600</a></span> | <span class="t">where n is the batch size and c is the number of features or channels, or it actually does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2637" target="_blank">00:43:57.920</a></span> | <span class="t">accept three-dimensional inputs, but it expects it to be n by c by l, where l is, say, the sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2644" target="_blank">00:44:04.000</a></span> | <span class="t">length or something like that. So this is a problem because you see how c is nested here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2650" target="_blank">00:44:10.160</a></span> | <span class="t">in the middle. And so when it gets three-dimensional inputs, this BatchNorm layer will reduce over 0</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2656" target="_blank">00:44:16.480</a></span> | <span class="t">and 2 instead of 0 and 1. So basically, PyTorch BatchNorm1D layer assumes that c will always be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2664" target="_blank">00:44:24.160</a></span> | <span class="t">the first dimension, whereas we assume here that c is the last dimension and there are some number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2671" target="_blank">00:44:31.120</a></span> | <span class="t">of batch dimensions beforehand. And so it expects n by c or n by c by l. We expect n by c or n by l</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2681" target="_blank">00:44:41.360</a></span> | <span class="t">by c. And so it's a deviation. I think it's okay. I prefer it this way, honestly, so this is the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2689" target="_blank">00:44:49.920</a></span> | <span class="t">that we will keep it for our purposes. So I redefined the layers, reinitialized the neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2694" target="_blank">00:44:54.160</a></span> | <span class="t">nut, and did a single forward pass with a break just for one step. Looking at the shapes along</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2699" target="_blank">00:44:59.520</a></span> | <span class="t">the way, they're of course identical. All the shapes are the same. But the way we see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2703" target="_blank">00:45:03.520</a></span> | <span class="t">things are actually working as we want them to now is that when we look at the BatchNorm layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2707" target="_blank">00:45:07.760</a></span> | <span class="t">the running mean shape is now 1 by 1 by 68. So we're only maintaining 68 means for every one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2713" target="_blank">00:45:13.440</a></span> | <span class="t">of our channels, and we're treating both the 0th and the first dimension as a batch dimension,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2718" target="_blank">00:45:18.640</a></span> | <span class="t">which is exactly what we want. So let me retrain the neural net now. Okay, so I've retrained the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2722" target="_blank">00:45:22.240</a></span> | <span class="t">neural net with the bug fix. We get a nice curve. And when we look at the validation performance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2726" target="_blank">00:45:26.240</a></span> | <span class="t">we do actually see a slight improvement. So it went from 2.029 to 2.022. So basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2731" target="_blank">00:45:31.920</a></span> | <span class="t">the bug inside the BatchNorm was holding us back a little bit, it looks like. And we are getting a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2737" target="_blank">00:45:37.680</a></span> | <span class="t">tiny improvement now, but it's not clear if this is statistically significant. And the reason we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2743" target="_blank">00:45:43.360</a></span> | <span class="t">slightly expect an improvement is because we're not maintaining so many different means and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2747" target="_blank">00:45:47.200</a></span> | <span class="t">variances that are only estimated using 32 numbers, effectively. Now we are estimating them using 32</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2753" target="_blank">00:45:53.440</a></span> | <span class="t">times 4 numbers. So you just have a lot more numbers that go into any one estimate of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2758" target="_blank">00:45:58.000</a></span> | <span class="t">mean and variance. And it allows things to be a bit more stable and less wiggly inside those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2763" target="_blank">00:46:03.360</a></span> | <span class="t">estimates of those statistics. So pretty nice. With this more general architecture in place,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2769" target="_blank">00:46:09.280</a></span> | <span class="t">we are now set up to push the performance further by increasing the size of the network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2773" target="_blank">00:46:13.920</a></span> | <span class="t">So for example, I've bumped up the number of embeddings to 24 instead of 10, and also increased</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2779" target="_blank">00:46:19.280</a></span> | <span class="t">the number of hidden units. But using the exact same architecture, we now have 76,000 parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2784" target="_blank">00:46:24.960</a></span> | <span class="t">And the training takes a lot longer, but we do get a nice curve. And then when you actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2789" target="_blank">00:46:29.600</a></span> | <span class="t">evaluate the performance, we are now getting validation performance of 1.993. So we've crossed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2794" target="_blank">00:46:34.640</a></span> | <span class="t">over the 2.0 sort of territory, and we're at about 1.99. But we are starting to have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2800" target="_blank">00:46:40.400</a></span> | <span class="t">wait quite a bit longer. And we're a little bit in the dark with respect to the correct setting of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2805" target="_blank">00:46:45.920</a></span> | <span class="t">the hyperparameters here and the learning rates and so on, because the experiments are starting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2809" target="_blank">00:46:49.200</a></span> | <span class="t">to take longer to train. And so we are missing sort of like an experimental harness on which we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2814" target="_blank">00:46:54.400</a></span> | <span class="t">could run a number of experiments and really tune this architecture very well. So I'd like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2818" target="_blank">00:46:58.720</a></span> | <span class="t">conclude now with a few notes. We basically improved our performance from a starting of 2.1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2824" target="_blank">00:47:04.160</a></span> | <span class="t">down to 1.9. But I don't want that to be the focus, because honestly, we're kind of in the dark,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2828" target="_blank">00:47:08.800</a></span> | <span class="t">we have no experimental harness, we're just guessing and checking. And this whole thing is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2832" target="_blank">00:47:12.960</a></span> | <span class="t">terrible. We're just looking at the training loss. Normally, you want to look at both the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2836" target="_blank">00:47:16.640</a></span> | <span class="t">training and the validation loss together. The whole thing looks different if you're actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2840" target="_blank">00:47:20.960</a></span> | <span class="t">trying to squeeze out numbers. That said, we did implement this architecture from the WaveNet paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2847" target="_blank">00:47:27.120</a></span> | <span class="t">But we did not implement this specific forward pass of it, where you have a more complicated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2853" target="_blank">00:47:33.760</a></span> | <span class="t">linear layer sort of that is this gated linear layer kind of. And there's residual connections</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2860" target="_blank">00:47:40.000</a></span> | <span class="t">and skip connections and so on. So we did not implement that, we just implemented this structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2864" target="_blank">00:47:44.960</a></span> | <span class="t">I would like to briefly hint or preview how what we've done here relates to convolutional neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2869" target="_blank">00:47:49.600</a></span> | <span class="t">networks as used in the WaveNet paper. And basically, the use of convolutions is strictly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2874" target="_blank">00:47:54.480</a></span> | <span class="t">for efficiency. It doesn't actually change the model we've implemented. So here, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2880" target="_blank">00:48:00.000</a></span> | <span class="t">let me look at a specific name to work with an example. So there's a name in our training set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2885" target="_blank">00:48:05.600</a></span> | <span class="t">and it's D'Andrea. And it has seven letters, so that is eight independent examples in our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2892" target="_blank">00:48:12.000</a></span> | <span class="t">So all these rows here are independent examples of D'Andrea. Now, you can forward, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2897" target="_blank">00:48:17.920</a></span> | <span class="t">any one of these rows independently. So I can take my model and call it on any individual index.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2905" target="_blank">00:48:25.520</a></span> | <span class="t">Notice, by the way, here, I'm being a little bit tricky. The reason for this is that extra at 7.shape</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2911" target="_blank">00:48:31.120</a></span> | <span class="t">is just one dimensional array of eight. So you can't actually call the model on it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2917" target="_blank">00:48:37.840</a></span> | <span class="t">you're going to get an error, because there's no batch dimension. So when you do extra at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2924" target="_blank">00:48:44.000</a></span> | <span class="t">list of seven, then the shape of this becomes one by eight. So I get an extra batch dimension of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2930" target="_blank">00:48:50.800</a></span> | <span class="t">one, and then we can forward the model. So that forwards a single example. And you might imagine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2937" target="_blank">00:48:57.920</a></span> | <span class="t">that you actually may want to forward all of these eight at the same time. So pre-allocating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2944" target="_blank">00:49:04.640</a></span> | <span class="t">some memory and then doing a for loop eight times and forwarding all of those eight here will give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2950" target="_blank">00:49:10.240</a></span> | <span class="t">us all the logits in all these different cases. Now, for us with the model as we've implemented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2955" target="_blank">00:49:15.040</a></span> | <span class="t">it right now, this is eight independent calls to our model. But what convolutions allow you to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2960" target="_blank">00:49:20.400</a></span> | <span class="t">is it allow you to basically slide this model efficiently over the input sequence. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2966" target="_blank">00:49:26.400</a></span> | <span class="t">this for loop can be done not outside in Python, but inside of kernels in CUDA. And so this for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2973" target="_blank">00:49:33.200</a></span> | <span class="t">loop gets hidden into the convolution. So the convolution basically, you can think of it as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2977" target="_blank">00:49:37.840</a></span> | <span class="t">it's a for loop, applying a little linear filter over space of some input sequence. And in our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2984" target="_blank">00:49:44.480</a></span> | <span class="t">case, the space we're interested in is one dimensional, and we're interested in sliding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2987" target="_blank">00:49:47.760</a></span> | <span class="t">these filters over the input data. So this diagram actually is fairly good as well. Basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=2995" target="_blank">00:49:55.760</a></span> | <span class="t">what we've done is here they are highlighting in black one single sort of like tree of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3001" target="_blank">00:50:01.200</a></span> | <span class="t">calculation. So just calculating the single output example here. And so this is basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3008" target="_blank">00:50:08.160</a></span> | <span class="t">what we've implemented here. We've implemented a single, this black structure, we've implemented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3013" target="_blank">00:50:13.680</a></span> | <span class="t">that and calculated a single output, like a single example. But what convolutions allow you to do is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3018" target="_blank">00:50:18.960</a></span> | <span class="t">it allows you to take this black structure and kind of like slide it over the input sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3024" target="_blank">00:50:24.640</a></span> | <span class="t">here and calculate all of these orange outputs at the same time. Or here that corresponds to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3031" target="_blank">00:50:31.520</a></span> | <span class="t">calculating all of these outputs of at all the positions of DeAndre at the same time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3037" target="_blank">00:50:37.440</a></span> | <span class="t">And the reason that this is much more efficient is because number one, as I mentioned, the for loop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3043" target="_blank">00:50:43.920</a></span> | <span class="t">is inside the CUDA kernels in the sliding. So that makes it efficient. But number two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3049" target="_blank">00:50:49.840</a></span> | <span class="t">notice the variable reuse here. For example, if we look at this circle, this node here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3054" target="_blank">00:50:54.400</a></span> | <span class="t">this node here is the right child of this node, but it's also the left child of the node here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3060" target="_blank">00:51:00.240</a></span> | <span class="t">And so basically, this node and its value is used twice. And so right now, in this naive way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3068" target="_blank">00:51:08.000</a></span> | <span class="t">we'd have to recalculate it. But here we are allowed to reuse it. So in the convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3073" target="_blank">00:51:13.360</a></span> | <span class="t">neural network, you think of these linear layers that we have up above as filters. And we take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3079" target="_blank">00:51:19.040</a></span> | <span class="t">these filters, and they're linear filters, and you slide them over input sequence. And we calculate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3084" target="_blank">00:51:24.000</a></span> | <span class="t">the first layer, and then the second layer, and then the third layer, and then the output layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3088" target="_blank">00:51:28.160</a></span> | <span class="t">of the sandwich. And it's all done very efficiently using these convolutions. So we're going to cover</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3093" target="_blank">00:51:33.280</a></span> | <span class="t">that in a future video. The second thing I hope you took away from this video is you've seen me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3097" target="_blank">00:51:37.520</a></span> | <span class="t">basically implement all of these layer Lego building blocks or module building blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3103" target="_blank">00:51:43.680</a></span> | <span class="t">And I'm implementing them over here. And we've implemented a number of layers together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3107" target="_blank">00:51:47.600</a></span> | <span class="t">And we've also implementing these these containers. And we've overall pytorchified our code quite a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3113" target="_blank">00:51:53.680</a></span> | <span class="t">bit more. Now, basically, what we're doing here is we're re-implementing torch.nn, which is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3119" target="_blank">00:51:59.040</a></span> | <span class="t">neural networks library on top of torch.tensor. And it looks very much like this, except it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3125" target="_blank">00:52:05.520</a></span> | <span class="t">much better, because it's in pytorch instead of a janky, lazy, and stupid notebook. So I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3131" target="_blank">00:52:11.520</a></span> | <span class="t">going forward, I will probably have considered us having unlocked torch.nn. We understand roughly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3137" target="_blank">00:52:17.600</a></span> | <span class="t">what's in there, how these modules work, how they're nested, and what they're doing on top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3141" target="_blank">00:52:21.840</a></span> | <span class="t">of torch.tensor. So hopefully, we'll just switch over and continue and start using torch.nn directly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3148" target="_blank">00:52:28.080</a></span> | <span class="t">The next thing I hope you got a bit of a sense of is what the development process of building</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3152" target="_blank">00:52:32.880</a></span> | <span class="t">deep neural networks looks like, which I think was relatively representative to some extent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3157" target="_blank">00:52:37.280</a></span> | <span class="t">So number one, we are spending a lot of time in the documentation page of pytorch. And we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3163" target="_blank">00:52:43.200</a></span> | <span class="t">reading through all the layers, looking at documentations, what are the shapes of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3167" target="_blank">00:52:47.040</a></span> | <span class="t">inputs, what can they be, what does the layer do, and so on. Unfortunately, I have to say the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3172" target="_blank">00:52:52.800</a></span> | <span class="t">pytorch documentation is not very good. They spend a ton of time on hardcore engineering of all kinds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3179" target="_blank">00:52:59.200</a></span> | <span class="t">of distributed primitives, etc. But as far as I can tell, no one is maintaining the documentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3184" target="_blank">00:53:04.240</a></span> | <span class="t">It will lie to you, it will be wrong, it will be incomplete, it will be unclear. So unfortunately,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3191" target="_blank">00:53:11.440</a></span> | <span class="t">it is what it is, and you just kind of do your best with what they've given us. Number two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3199" target="_blank">00:53:19.120</a></span> | <span class="t">the other thing that I hope you got a sense of is there's a ton of trying to make the shapes work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3205" target="_blank">00:53:25.840</a></span> | <span class="t">And there's a lot of gymnastics around these multi-dimensional arrays. And are they two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3209" target="_blank">00:53:29.120</a></span> | <span class="t">dimensional, three dimensional, four dimensional? What layers take what shapes? Is it NCL or NLC?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3215" target="_blank">00:53:35.520</a></span> | <span class="t">And you're permuting and viewing, and it just can get pretty messy. And so that brings me to number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3221" target="_blank">00:53:41.120</a></span> | <span class="t">three. I very often prototype these layers and implementations in Jupyter Notebooks and make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3225" target="_blank">00:53:45.760</a></span> | <span class="t">sure that all the shapes work out. And I'm spending a lot of time basically babysitting the shapes and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3230" target="_blank">00:53:50.880</a></span> | <span class="t">making sure everything is correct. And then once I'm satisfied with the functionality in a Jupyter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3235" target="_blank">00:53:55.120</a></span> | <span class="t">Notebook, I will take that code and copy paste it into my repository of actual code that I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3240" target="_blank">00:54:00.240</a></span> | <span class="t">training with. And so then I'm working with VS code on the side. So I usually have Jupyter Notebook</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3245" target="_blank">00:54:05.440</a></span> | <span class="t">and VS code. I develop a Jupyter Notebook, I paste into VS code, and then I kick off experiments from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3250" target="_blank">00:54:10.560</a></span> | <span class="t">the repo, of course, from the code repository. So that's roughly some notes on the development</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3256" target="_blank">00:54:16.320</a></span> | <span class="t">process of working with neural nets. Lastly, I think this lecture unlocks a lot of potential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3260" target="_blank">00:54:20.800</a></span> | <span class="t">further lectures, because number one, we have to convert our neural network to actually use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3265" target="_blank">00:54:25.040</a></span> | <span class="t">these dilated causal convolutional layers. So implementing the ConvNet. Number two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3270" target="_blank">00:54:30.960</a></span> | <span class="t">I'm potentially starting to get into what this means, where are residual connections and skip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3275" target="_blank">00:54:35.360</a></span> | <span class="t">connections and why are they useful? Number three, as I mentioned, we don't have any experimental</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3281" target="_blank">00:54:41.520</a></span> | <span class="t">harness. So right now I'm just guessing, checking everything. This is not representative of typical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3285" target="_blank">00:54:45.840</a></span> | <span class="t">deep learning workflows. You have to set up your evaluation harness, you can kick off experiments,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3290" target="_blank">00:54:50.800</a></span> | <span class="t">you have lots of arguments that your script can take, you're kicking off a lot of experimentation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3295" target="_blank">00:54:55.360</a></span> | <span class="t">you're looking at a lot of plots of training and validation losses, and you're looking at what is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3299" target="_blank">00:54:59.360</a></span> | <span class="t">working and what is not working. And you're working on this like population level, and you're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3303" target="_blank">00:55:03.360</a></span> | <span class="t">all these hyperparameter searches. And so we've done none of that so far. So how to set that up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3309" target="_blank">00:55:09.520</a></span> | <span class="t">and how to make it good, I think is a whole another topic. And number three, we should probably cover</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3315" target="_blank">00:55:15.280</a></span> | <span class="t">recurring neural networks, RNNs, LSTMs, GRUs, and of course, transformers. So many places to go,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3322" target="_blank">00:55:22.560</a></span> | <span class="t">and we'll cover that in the future. For now, bye. Sorry, I forgot to say that if you are interested,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3329" target="_blank">00:55:29.120</a></span> | <span class="t">I think it is kind of interesting to try to beat this number 1.993. Because I really haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3334" target="_blank">00:55:34.560</a></span> | <span class="t">tried a lot of experimentation here, and there's quite a bit of longing fruit potentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3338" target="_blank">00:55:38.160</a></span> | <span class="t">to still push this further. So I haven't tried any other ways of allocating these channels in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3343" target="_blank">00:55:43.200</a></span> | <span class="t">this neural net. Maybe the number of dimensions for the embedding is all wrong. Maybe it's possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3349" target="_blank">00:55:49.200</a></span> | <span class="t">to actually take the original network, which is one hidden layer, and make it big enough and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3353" target="_blank">00:55:53.360</a></span> | <span class="t">actually beat my fancy hierarchical network. It's not obvious. That would be kind of embarrassing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3358" target="_blank">00:55:58.880</a></span> | <span class="t">If this did not do better, even once you torture it a little bit. Maybe you can read the WaveNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3363" target="_blank">00:56:03.680</a></span> | <span class="t">paper and try to figure out how some of these layers work and implement them yourselves using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3367" target="_blank">00:56:07.280</a></span> | <span class="t">what we have. And of course, you can always tune some of the initialization or some of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3372" target="_blank">00:56:12.480</a></span> | <span class="t">optimization and see if you can improve it that way. So I'd be curious if people can come up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=t3YJ5hKiMQ0&t=3377" target="_blank">00:56:17.120</a></span> | <span class="t">some ways to beat this. And yeah, that's it for now. Bye.</span></div></div></body></html>