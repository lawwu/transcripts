<html><head><title>Udio, the Mysterious GPT Update, and Infinite Attention</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Udio, the Mysterious GPT Update, and Infinite Attention</h2><a href="https://www.youtube.com/watch?v=QASOCG5QLUM"><img src="https://i.ytimg.com/vi/QASOCG5QLUM/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./QASOCG5QLUM.html">Whisper Transcript</a> | <a href="./transcript_QASOCG5QLUM.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">It's been a strange 48 hours in the world of AI with releases like Oudio that have reminded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=6" target="_blank">00:00:06.440</a></span> | <span class="t">millions of people what AI is capable of and models that can pay you infinite attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=13" target="_blank">00:00:13.080</a></span> | <span class="t">But we also got befuddling updates from OpenAI that suggest that not all is smooth sailing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=18" target="_blank">00:00:18.960</a></span> | <span class="t">I'll start, of course, with the new model on Oudio.com and how musicians are reacting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=25" target="_blank">00:00:25.880</a></span> | <span class="t">Then cover the perplexing manner of the release of GPT-4 Turbo with Vision and touch on a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=31" target="_blank">00:00:31.560</a></span> | <span class="t">fascinating new Infinite Context paper from Google.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=35" target="_blank">00:00:35.360</a></span> | <span class="t">But now let's hear three 20-second extracts from Oudio to give you an inkling, if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=41" target="_blank">00:00:41.120</a></span> | <span class="t">haven't heard it already, of what it's capable of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=44" target="_blank">00:00:44.160</a></span> | <span class="t">Here's Dune, the Broadway musical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=66" target="_blank">00:01:06.840</a></span> | <span class="t">And now for some quite frankly amazing AI-generated classical music.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=85" target="_blank">00:01:25.640</a></span> | <span class="t">And next, something I'm going to bleep a little bit, but represents the reaction of Uncharted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=91" target="_blank">00:01:31.320</a></span> | <span class="t">Labs, who are behind Oudio, to their servers going down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=104" target="_blank">00:01:44.300</a></span> | <span class="t">And of course, I have been playing about with Oudio like almost everyone has, and did you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=123" target="_blank">00:02:03.100</a></span> | <span class="t">know it can do stand-up comedy?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=141" target="_blank">00:02:21.820</a></span> | <span class="t">Now I'm not sure if this guy is talking about me, but I thought I'd let you know that this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=145" target="_blank">00:02:25.660</a></span> | <span class="t">kind of thing is possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=147" target="_blank">00:02:27.460</a></span> | <span class="t">And how about a quick, direct comparison between Oudio and Suno V3?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=161" target="_blank">00:02:41.220</a></span> | <span class="t">Now, I prefer Oudio there, but you do sometimes get complete gobbledygook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=190" target="_blank">00:03:10.100</a></span> | <span class="t">Now Will.i.am calls Oudio the best tech on earth, and Uncharted Labs, which is the company</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=202" target="_blank">00:03:22.420</a></span> | <span class="t">behind Oudio, he says is really aiming to be an ally for creatives and artists.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=208" target="_blank">00:03:28.420</a></span> | <span class="t">Now it should of course be noted that Will.i.am is an investor in Oudio, but again they repeat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=213" target="_blank">00:03:33.500</a></span> | <span class="t">that Oudio is about building AI tools to enable the next generation of music creators.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=219" target="_blank">00:03:39.460</a></span> | <span class="t">Now of course everyone has their own opinion, but let's now get a taste of the reaction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=223" target="_blank">00:03:43.060</a></span> | <span class="t">from some musicians.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=224" target="_blank">00:03:44.880</a></span> | <span class="t">One says it's pretty scary thinking what is going to exist a year or two from now, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=229" target="_blank">00:03:49.980</a></span> | <span class="t">what it means for musicians, listeners, and the industry as a whole.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=233" target="_blank">00:03:53.660</a></span> | <span class="t">The top comment says I would buy a band t-shirt, but never buy a shirt for an AI, which makes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=239" target="_blank">00:03:59.300</a></span> | <span class="t">sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=240" target="_blank">00:04:00.300</a></span> | <span class="t">But here are two more common reactions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=242" target="_blank">00:04:02.660</a></span> | <span class="t">I am a music professional, producer/composer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=245" target="_blank">00:04:05.740</a></span> | <span class="t">This is highly advanced, and I thought this stuff was years away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=250" target="_blank">00:04:10.140</a></span> | <span class="t">And one more, I've already gone full circle with it, past the confusion and devastation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=255" target="_blank">00:04:15.180</a></span> | <span class="t">and now I'm just curious what Gregorian chant would sound like with, I can't even pronounce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=259" target="_blank">00:04:19.900</a></span> | <span class="t">that, and blast beats.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=261" target="_blank">00:04:21.660</a></span> | <span class="t">So definitely a mixed reaction from musicians.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=264" target="_blank">00:04:24.860</a></span> | <span class="t">Personally, I don't think it's too much of an exaggeration to call this the Chachapiti</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=269" target="_blank">00:04:29.460</a></span> | <span class="t">moment for music generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=271" target="_blank">00:04:31.660</a></span> | <span class="t">Zuno often has a slight tinniness that gives it away for those not following AI, but with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=277" target="_blank">00:04:37.340</a></span> | <span class="t">Udio, I think you could convince many people that they're listening to human music, just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=282" target="_blank">00:04:42.620</a></span> | <span class="t">like Chachapiti felt like human text if you didn't look too closely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=286" target="_blank">00:04:46.940</a></span> | <span class="t">I could well see before the end of this year, hundreds of millions of people using this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=291" target="_blank">00:04:51.620</a></span> | <span class="t">for entertainment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=292" target="_blank">00:04:52.820</a></span> | <span class="t">Imagine every school child in the world walking out of their lesson in whichever language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=297" target="_blank">00:04:57.860</a></span> | <span class="t">with a catchy tune about what they've learned.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=300" target="_blank">00:05:00.380</a></span> | <span class="t">So yes, I do believe that Udio is the biggest news of this week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=305" target="_blank">00:05:05.100</a></span> | <span class="t">But of course, we had the mysterious release of a new GPT-4 Turbo model from OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=312" target="_blank">00:05:12.020</a></span> | <span class="t">And why do I call it mysterious?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=313" target="_blank">00:05:13.580</a></span> | <span class="t">Well, not because it wasn't named GPT-4.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=317" target="_blank">00:05:17.300</a></span> | <span class="t">They probably thought it wasn't enough of a step forward to give it that name.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=321" target="_blank">00:05:21.520</a></span> | <span class="t">The strangeness was the repeated emphasis on it being better than previous iterations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=327" target="_blank">00:05:27.380</a></span> | <span class="t">but without any detail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=328" target="_blank">00:05:28.640</a></span> | <span class="t">They called it majorly improved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=330" target="_blank">00:05:30.940</a></span> | <span class="t">Where are the benchmarks though?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=332" target="_blank">00:05:32.680</a></span> | <span class="t">And now here's some more mystery.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=334" target="_blank">00:05:34.340</a></span> | <span class="t">All the top players at OpenAI like Greg Brockman and Mira Murati tweeted out the news of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=340" target="_blank">00:05:40.500</a></span> | <span class="t">new model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=341" target="_blank">00:05:41.500</a></span> | <span class="t">But strangely, for the first time, Sam Altman didn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=344" target="_blank">00:05:44.780</a></span> | <span class="t">Now this isn't about reading any tea leaves, it's just a very strange announcement from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=349" target="_blank">00:05:49.380</a></span> | <span class="t">OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=350" target="_blank">00:05:50.380</a></span> | <span class="t">I ran my own maths and logic benchmarks and I couldn't see much of a difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=354" target="_blank">00:05:54.540</a></span> | <span class="t">It failed the same questions that the January version of GPT-4 Turbo failed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=359" target="_blank">00:05:59.260</a></span> | <span class="t">Of course, the functionality improved with function calling within vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=363" target="_blank">00:06:03.100</a></span> | <span class="t">But what intrigued me was the repeated claims that GPT-4 reasoning had been further improved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=369" target="_blank">00:06:09.380</a></span> | <span class="t">Naturally, on this channel, that's what I was most focused about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=372" target="_blank">00:06:12.900</a></span> | <span class="t">The cutting edge of intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=375" target="_blank">00:06:15.180</a></span> | <span class="t">Here though is some of the best benchmarking work that I could find.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=379" target="_blank">00:06:19.100</a></span> | <span class="t">On the noted math benchmark from Dan Hendricks, you could see a bump in its performance on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=384" target="_blank">00:06:24.520</a></span> | <span class="t">the hardest style of questions, from 35% to around 45%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=389" target="_blank">00:06:29.480</a></span> | <span class="t">Even one level down, the performance bumped up from 57% to 66%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=394" target="_blank">00:06:34.380</a></span> | <span class="t">The difference on the easier questions wasn't nearly as pronounced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=397" target="_blank">00:06:37.940</a></span> | <span class="t">It seems pretty clear that the dataset got augmented with some high-level mathematics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=402" target="_blank">00:06:42.860</a></span> | <span class="t">and code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=403" target="_blank">00:06:43.860</a></span> | <span class="t">Otherwise, it wasn't too much changed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=406" target="_blank">00:06:46.460</a></span> | <span class="t">Here's another example, LiveCodeBench.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=408" target="_blank">00:06:48.680</a></span> | <span class="t">You can't complain about contamination because they source their questions from after the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=412" target="_blank">00:06:52.660</a></span> | <span class="t">training day of the models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=414" target="_blank">00:06:54.660</a></span> | <span class="t">And again, as you can see, performance has increased, particularly for harder questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=419" target="_blank">00:06:59.340</a></span> | <span class="t">These are sourced from contests like LeetCode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=422" target="_blank">00:07:02.140</a></span> | <span class="t">And that applies not just to code generation, but self-repair.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=426" target="_blank">00:07:06.300</a></span> | <span class="t">Again though, we're not talking about massive leaps, just small bumps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=430" target="_blank">00:07:10.140</a></span> | <span class="t">Here though is the clearest assessment from Epoch AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=433" target="_blank">00:07:13.780</a></span> | <span class="t">The diamond set of the GPQA are the hardest kind of graduate questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=439" target="_blank">00:07:19.460</a></span> | <span class="t">We're talking Google-proof STEM questions that even PhDs find hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=444" target="_blank">00:07:24.860</a></span> | <span class="t">And yes, there was a bump, maybe by 2% or 3%, but GPT-4 Turbo, April edition, is still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=452" target="_blank">00:07:32.500</a></span> | <span class="t">lower performing than Claude III Opus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=455" target="_blank">00:07:35.420</a></span> | <span class="t">Of course, the deeper question is whether or not this indicates some inherent limitations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=461" target="_blank">00:07:41.020</a></span> | <span class="t">on just simply training on more and more advanced data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=464" target="_blank">00:07:44.740</a></span> | <span class="t">It's a bit like the current paradigm can only go so far, even with better data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=469" target="_blank">00:07:49.740</a></span> | <span class="t">Of course, you can watch any of my other videos to see why I don't think that will be much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=474" target="_blank">00:07:54.420</a></span> | <span class="t">of a bottleneck that much longer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=476" target="_blank">00:07:56.580</a></span> | <span class="t">Now it would be remiss of me not to spend a few seconds touching on two releases from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=481" target="_blank">00:08:01.360</a></span> | <span class="t">the OpenWeights community.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=483" target="_blank">00:08:03.140</a></span> | <span class="t">I'm not going to call it the open source community because they're not releasing their training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=487" target="_blank">00:08:07.340</a></span> | <span class="t">datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=488" target="_blank">00:08:08.340</a></span> | <span class="t">I'm talking about the new Mixed Trial 8x22 billion Mixture of Experts model and Cohere's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=494" target="_blank">00:08:14.340</a></span> | <span class="t">Command R+.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=495" target="_blank">00:08:15.780</a></span> | <span class="t">Now you can judge for yourself, but they land around the level of Claude III Sonnet, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=500" target="_blank">00:08:20.780</a></span> | <span class="t">is the medium-sized model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=502" target="_blank">00:08:22.680</a></span> | <span class="t">Of course, that is a proprietary model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=504" target="_blank">00:08:24.900</a></span> | <span class="t">Some people may have expected the OpenWeights community to have caught up to GPT-4 by now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=510" target="_blank">00:08:30.300</a></span> | <span class="t">but that's not quite the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=512" target="_blank">00:08:32.060</a></span> | <span class="t">Of course, let's wait to see if LLAMA 3 can further bridge that gap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=516" target="_blank">00:08:36.620</a></span> | <span class="t">Now before we get to Google, there was one more announcement of a model I want to touch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=521" target="_blank">00:08:41.380</a></span> | <span class="t">on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=522" target="_blank">00:08:42.380</a></span> | <span class="t">So as I've done once before on this channel, I reached out to the company to ask about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=527" target="_blank">00:08:47.500</a></span> | <span class="t">a sponsorship.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=528" target="_blank">00:08:48.500</a></span> | <span class="t">I've probably turned down thousands of sponsorship offers, but I'm happy to say that this part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=533" target="_blank">00:08:53.140</a></span> | <span class="t">of the video is sponsored by Assembly AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=536" target="_blank">00:08:56.040</a></span> | <span class="t">So what happened?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=537" target="_blank">00:08:57.040</a></span> | <span class="t">They released Universal One.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=538" target="_blank">00:08:58.900</a></span> | <span class="t">And basically the reason I reached out to them is because it's really darn good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=543" target="_blank">00:09:03.520</a></span> | <span class="t">I'm often transcribing videos and rarely do they get characters like GPT correct, let</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=549" target="_blank">00:09:09.320</a></span> | <span class="t">alone names like Satya Nadella.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=552" target="_blank">00:09:12.120</a></span> | <span class="t">Universal One did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=553" target="_blank">00:09:13.580</a></span> | <span class="t">So yes, Universal One is the model I personally use and you can see some comparisons to other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=559" target="_blank">00:09:19.820</a></span> | <span class="t">models in this chart.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=561" target="_blank">00:09:21.260</a></span> | <span class="t">It does seem to hallucinate less than Whisper and takes 38 seconds to process an hour of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=567" target="_blank">00:09:27.940</a></span> | <span class="t">audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=568" target="_blank">00:09:28.940</a></span> | <span class="t">Anyway, Universal One only came out like a week ago and I think it's epic, but let me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=573" target="_blank">00:09:33.780</a></span> | <span class="t">know what you think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=574" target="_blank">00:09:34.940</a></span> | <span class="t">The link, of course, will be in the description.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=577" target="_blank">00:09:37.700</a></span> | <span class="t">But now from yesterday, a quite fascinating paper from Google.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=582" target="_blank">00:09:42.100</a></span> | <span class="t">It's about transformer models that could have infinite context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=586" target="_blank">00:09:46.460</a></span> | <span class="t">Not 1 million or 10 million, but infinite.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=589" target="_blank">00:09:49.420</a></span> | <span class="t">I must say unusually for this channel, I haven't had a chance to finish the paper before talking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=594" target="_blank">00:09:54.460</a></span> | <span class="t">about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=595" target="_blank">00:09:55.460</a></span> | <span class="t">I wanted to include it in this video for a reason.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=597" target="_blank">00:09:57.980</a></span> | <span class="t">Of course, the prospect of feeding in entire libraries is fascinating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=602" target="_blank">00:10:02.680</a></span> | <span class="t">But my theory is that this approach might be behind Gemini 1.5's long context ability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=609" target="_blank">00:10:09.260</a></span> | <span class="t">If you remember, Gemini 1.5, whose API is now widely available, was able to process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=615" target="_blank">00:10:15.340</a></span> | <span class="t">up to at least 10 million tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=618" target="_blank">00:10:18.940</a></span> | <span class="t">Notice the phrase "at least" there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=620" target="_blank">00:10:20.720</a></span> | <span class="t">If you're not familiar with tokens, think 10 million tokens as being around 8 million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=624" target="_blank">00:10:24.860</a></span> | <span class="t">words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=625" target="_blank">00:10:25.860</a></span> | <span class="t">And if that's a daunting number, think 8 entire sets of Harry Potter novels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=630" target="_blank">00:10:30.300</a></span> | <span class="t">Now, on the day that Gemini 1.5 came out, I called it the biggest development of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=635" target="_blank">00:10:35.460</a></span> | <span class="t">day, despite it being the same day that Sora came out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=638" target="_blank">00:10:38.780</a></span> | <span class="t">I would still stick to that to this day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=641" target="_blank">00:10:41.220</a></span> | <span class="t">Gemini 1.5 could find metaphorical needles in videos 3 hours long or audio 22 hours long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=648" target="_blank">00:10:48.620</a></span> | <span class="t">And the performance just kept improving up to and beyond 10 million tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=653" target="_blank">00:10:53.900</a></span> | <span class="t">But back to yesterday's paper, why do I think there's any link?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=657" target="_blank">00:10:57.100</a></span> | <span class="t">Now, one hint is that one of the authors, Manal Faruqi, and sorry if I'm mispronouncing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=661" target="_blank">00:11:01.300</a></span> | <span class="t">your name, was also an author in the original Gemini papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=666" target="_blank">00:11:06.340</a></span> | <span class="t">The other hint comes from the paper itself, where they call their approach a "plug-and-play</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=671" target="_blank">00:11:11.460</a></span> | <span class="t">long-context adaptation capability" with which they can "continually pre-train existing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=678" target="_blank">00:11:18.300</a></span> | <span class="t">LLMs".</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=679" target="_blank">00:11:19.300</a></span> | <span class="t">In other words, it appears like you can take existing LLMs and just pre-train them with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=683" target="_blank">00:11:23.500</a></span> | <span class="t">this approach to make them great at long-context, or indeed infinite-context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=688" target="_blank">00:11:28.860</a></span> | <span class="t">Is that part of what happened to Gemini 1 Pro to turn it into Gemini 1.5 Pro?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=694" target="_blank">00:11:34.300</a></span> | <span class="t">Anyway, it is interesting that Google published this, while still being a bit cagey about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=699" target="_blank">00:11:39.380</a></span> | <span class="t">some crucial details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=700" target="_blank">00:11:40.920</a></span> | <span class="t">They do conclude though that this approach enables LLMs to process infinitely long-context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=707" target="_blank">00:11:47.260</a></span> | <span class="t">even though they've got bounded memory and computation resources.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=711" target="_blank">00:11:51.220</a></span> | <span class="t">Now I am going to consult with some colleagues before I say much more about this paper, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=715" target="_blank">00:11:55.780</a></span> | <span class="t">just think about some of the possibilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=718" target="_blank">00:11:58.620</a></span> | <span class="t">Imagine a model being able to process every film made by a particular director, or every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=724" target="_blank">00:12:04.260</a></span> | <span class="t">work of French literature between a particular period, or every email that you've ever sent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=730" target="_blank">00:12:10.100</a></span> | <span class="t">since birth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=731" target="_blank">00:12:11.100</a></span> | <span class="t">But let's not get too far ahead of ourselves because it's not like Google don't have their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=735" target="_blank">00:12:15.120</a></span> | <span class="t">own issues.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=736" target="_blank">00:12:16.280</a></span> | <span class="t">This week we learned that apparently Demis Hassabis said that he thought it would be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=740" target="_blank">00:12:20.140</a></span> | <span class="t">especially difficult for Google to catch up to its rival OpenAI with generated video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=746" target="_blank">00:12:26.700</a></span> | <span class="t">He also apparently mused about leaving Google and raising billions of dollars to start a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=751" target="_blank">00:12:31.460</a></span> | <span class="t">new research lab.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=753" target="_blank">00:12:33.220</a></span> | <span class="t">If he did leave to start his own lab, that would swiftly become a very competitive lab.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=759" target="_blank">00:12:39.360</a></span> | <span class="t">To bring us back to the start, that's actually how UDIO was born.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=763" target="_blank">00:12:43.240</a></span> | <span class="t">We learned from the information that UDIO is the work of Uncharted Labs, made up primarily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=769" target="_blank">00:12:49.300</a></span> | <span class="t">of former Google DeepMind staff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=771" target="_blank">00:12:51.780</a></span> | <span class="t">Those researchers had created the model Lyria back in the spring of last year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=777" target="_blank">00:12:57.060</a></span> | <span class="t">That could be a very similar model to what we now have in UDIO, but the company didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=782" target="_blank">00:13:02.460</a></span> | <span class="t">unveil it until November of last year and Google still hasn't made it available to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=787" target="_blank">00:13:07.020</a></span> | <span class="t">the public.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=788" target="_blank">00:13:08.020</a></span> | <span class="t">It seems like Demis Hassabis isn't the only one with some frustration at Google.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=792" target="_blank">00:13:12.820</a></span> | <span class="t">But before I end the video, I must give Google great credit for this release within the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=798" target="_blank">00:13:18.100</a></span> | <span class="t">24 hours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=799" target="_blank">00:13:19.260</a></span> | <span class="t">With deep learning, of course, they trained these ultra cute football players.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=803" target="_blank">00:13:23.940</a></span> | <span class="t">And yes, I'm calling it football.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=805" target="_blank">00:13:25.500</a></span> | <span class="t">These two players weren't manually designed to do the moves they're doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=809" target="_blank">00:13:29.580</a></span> | <span class="t">Through deep reinforcement learning, they learnt to anticipate ball movements and block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=815" target="_blank">00:13:35.060</a></span> | <span class="t">opponent shots.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=816" target="_blank">00:13:36.380</a></span> | <span class="t">And these guys were trained in simulation, which I talked about in my recent NVIDIA video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=821" target="_blank">00:13:41.380</a></span> | <span class="t">Compared to a pre-scripted baseline, these agents walked three times faster, turned four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=826" target="_blank">00:13:46.820</a></span> | <span class="t">times faster and kicked the ball 30% faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=830" target="_blank">00:13:50.460</a></span> | <span class="t">Soon therefore, we could have our own mini Erling Haaland.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=833" target="_blank">00:13:53.880</a></span> | <span class="t">So quite the rollercoaster 48 hours in AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=837" target="_blank">00:13:57.800</a></span> | <span class="t">As always, let me know what you think in the comments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=840" target="_blank">00:14:00.720</a></span> | <span class="t">Feel free to hop on board my Patreon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=QASOCG5QLUM&t=843" target="_blank">00:14:03.180</a></span> | <span class="t">But regardless, thank you so much for watching and have a wonderful day.</span></div></div></body></html>