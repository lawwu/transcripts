<html><head><title>Leak: ‘GPT-5 exhibits diminishing returns’, Sam Altman: ‘lol’</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Leak: ‘GPT-5 exhibits diminishing returns’, Sam Altman: ‘lol’</h2><a href="https://www.youtube.com/watch?v=iybgycPk-N4"><img src="https://i.ytimg.com/vi/iybgycPk-N4/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=39">0:39</a> Bear Case, TheInformation Leak<br><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=241">4:1</a> Bull Case, Sam Altman<br><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=380">6:20</a> FrontierMath<br><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=689">11:29</a> o1 Paradigm<br><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=791">13:11</a> Text to Video Greatness and Universal-2<br><br><div style="text-align: left;"><a href="./iybgycPk-N4.html">Whisper Transcript</a> | <a href="./transcript_iybgycPk-N4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">it would be easy to write a title based on yesterday's OpenAI leak that language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=6" target="_blank">00:00:06.960</a></span> | <span class="t">progress is hitting a wall. And it would be just as easy to write an all-caps hype headline</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=13" target="_blank">00:00:13.200</a></span> | <span class="t">if I only listened to the very latest cherry-picked quotes from, say, Sam Altman,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=19" target="_blank">00:00:19.280</a></span> | <span class="t">CEO of OpenAI. But I want to try to convey the nuance behind the headlines and will be diving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=27" target="_blank">00:00:27.040</a></span> | <span class="t">into some brand new papers to do so. The ground truth lies somewhere between both extremes and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=34" target="_blank">00:00:34.320</a></span> | <span class="t">even OpenAI don't know exactly where. Here's how the video would look if I only wanted to focus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=41" target="_blank">00:00:41.600</a></span> | <span class="t">on the bear case for LLMs or AI more generally. An undisclosed source at OpenAI leaked information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=49" target="_blank">00:00:49.440</a></span> | <span class="t">apparently to The Information. The article was published late yesterday and here it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=55" target="_blank">00:00:55.680</a></span> | <span class="t">While the number of people using chatGPT has soared, the rate of improvement, it says,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=61" target="_blank">00:01:01.120</a></span> | <span class="t">for the basic building blocks, the language models underpinning them, appears to be slowing down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=66" target="_blank">00:01:06.240</a></span> | <span class="t">The article isn't talking about a particular product or a way of generating outputs from a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=71" target="_blank">00:01:11.520</a></span> | <span class="t">model. It's talking about the underlying model. The current core model of OpenAI is GPT-4.0,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=78" target="_blank">00:01:18.560</a></span> | <span class="t">and so the next model would naturally be called, say, GPT-5. The suggestion from this article is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=83" target="_blank">00:01:23.920</a></span> | <span class="t">that the more favoured name is Orion, but still we're talking about that core underlying pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=89" target="_blank">00:01:29.280</a></span> | <span class="t">model. At least at an early stage, that new Orion model was looking pretty decent. Remember,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=94" target="_blank">00:01:34.480</a></span> | <span class="t">this comes from a person who heard comments directly from Sam Altman at OpenAI, so presumably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=100" target="_blank">00:01:40.640</a></span> | <span class="t">an OpenAI staff member. And that person said, though OpenAI had only completed 20% of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=106" target="_blank">00:01:46.880</a></span> | <span class="t">training process for this new model Orion, it was already on par with GPT-4 in terms of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=112" target="_blank">00:01:52.720</a></span> | <span class="t">intelligence and abilities to fulfil tasks and answer questions. That sounds decent, right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=117" target="_blank">00:01:57.760</a></span> | <span class="t">but when the training was finished, according to this person, the final increase in quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=123" target="_blank">00:02:03.360</a></span> | <span class="t">was far smaller compared with the jump between GPT-3 and GPT-4. So it's apparently better than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=129" target="_blank">00:02:09.440</a></span> | <span class="t">prior models, its performance exceeds those prior models, but not by as much as previous leaps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=135" target="_blank">00:02:15.200</a></span> | <span class="t">And the article gives a bit more detail here. Some researchers at the company believe Orion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=140" target="_blank">00:02:20.880</a></span> | <span class="t">isn't reliably better than its predecessor in handling certain tasks, like coding. It might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=146" target="_blank">00:02:26.000</a></span> | <span class="t">be better at language tasks, but remember, the trade-off for a bigger model is that it would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=151" target="_blank">00:02:31.360</a></span> | <span class="t">generally be slower and more expensive. And why, according to the article, might progress have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=156" target="_blank">00:02:36.880</a></span> | <span class="t">slowed down? Well, roughly speaking, you can think of GPT-4 as having trained on most of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=163" target="_blank">00:02:43.600</a></span> | <span class="t">accessible web. They kind of ignored copyright to basically train on anything they could grab hold</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=169" target="_blank">00:02:49.200</a></span> | <span class="t">of. At that point, it becomes quite hard to scale up another 10 times, another order of magnitude,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=174" target="_blank">00:02:54.480</a></span> | <span class="t">because where are you going to get that extra data? You can tell though that the article is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=178" target="_blank">00:02:58.560</a></span> | <span class="t">somewhat guessing because they also put forward the hypothesis that it could be that it's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=182" target="_blank">00:03:02.880</a></span> | <span class="t">getting too expensive to train models. They selectively quote Noam Brown, who said that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=188" target="_blank">00:03:08.160</a></span> | <span class="t">it's soon going to cost hundreds of billions of dollars to train the next generation. And at some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=192" target="_blank">00:03:12.720</a></span> | <span class="t">point, the scaling paradigm breaks down. How do I know that's a selective quote? Well, because Noam</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=198" target="_blank">00:03:18.000</a></span> | <span class="t">Brown just today said so, saying he was selectively quoted and that he thinks that there won't be a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=204" target="_blank">00:03:24.720</a></span> | <span class="t">slowdown in AI progress any time soon. The theme though of the article is clear and they quote one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=210" target="_blank">00:03:30.880</a></span> | <span class="t">open AI investor saying this, "We're increasing the number of GPUs used to train AI, but we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=216" target="_blank">00:03:36.880</a></span> | <span class="t">not getting the intelligence improvements out of it at all." And another analyst was quoted at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=222" target="_blank">00:03:42.000</a></span> | <span class="t">end saying, "You could argue that for now we are seeing a plateau in the performance of LLMs."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=228" target="_blank">00:03:48.080</a></span> | <span class="t">As the author of Simplebench, I could bring in tons of examples of the latest models making</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=233" target="_blank">00:03:53.440</a></span> | <span class="t">silly mistakes that a human might not make. Then throw in a few more quotes making Sam Altman or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=239" target="_blank">00:03:59.120</a></span> | <span class="t">OpenAI look bad and call it a day. Alternatively, I could make a video focused only on the most hype</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=245" target="_blank">00:04:05.840</a></span> | <span class="t">worthy of clips. For example, here's four times in the last few days, Sam Altman has given us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=251" target="_blank">00:04:11.920</a></span> | <span class="t">quotes that make it seem like we're on the verge of a giant leap forward. First, he says,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=257" target="_blank">00:04:17.600</a></span> | <span class="t">"We know what to do to reach AGI." Second, and by the way, these are in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=283" target="_blank">00:04:43.920</a></span> | <span class="t">approximately ascending order of optimism, he says scaling is going to continue yes for a long time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=290" target="_blank">00:04:50.800</a></span> | <span class="t">Then he mysteriously alludes to a quote, "Breathtaking research result that he can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=310" target="_blank">00:05:10.400</a></span> | <span class="t">talk about." Fourth, and this has to be the most extreme example, he hinted at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=323" target="_blank">00:05:23.920</a></span> | <span class="t">solving all of physics using AI. To his credit at least, he could see the grandiosity in some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=350" target="_blank">00:05:50.080</a></span> | <span class="t">of his claims. The typed female Twitter account jokingly quoted Sam Altman, "We are a few thousand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=356" target="_blank">00:05:56.000</a></span> | <span class="t">days away from building God. We will build suns on earth, unify physics, and resurrect the worthy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=362" target="_blank">00:06:02.560</a></span> | <span class="t">dead." Interview host, "Sounds like this will be really impactful for startups." Sam Altman,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=367" target="_blank">00:06:07.680</a></span> | <span class="t">"Definitely." So hopefully you can see that just by selecting which news stories to quote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=373" target="_blank">00:06:13.760</a></span> | <span class="t">and which clips to use, you can present entirely different stories. What then is the truth and how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=380" target="_blank">00:06:20.480</a></span> | <span class="t">will we know? Well, a quick hint before I give some evidence to that effect is that even OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=386" target="_blank">00:06:26.640</a></span> | <span class="t">don't know. That's according to a key researcher whom I'll quote in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=390" target="_blank">00:06:30.720</a></span> | <span class="t">This paper, Frontier Math, isn't just interesting because it gives the results of whether current AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=396" target="_blank">00:06:36.240</a></span> | <span class="t">models can compete at the very frontier of mathematics. Answer, no they can't. But it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=401" target="_blank">00:06:41.600</a></span> | <span class="t">also interesting because it shows us what needs to happen before they can. They came up with around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=407" target="_blank">00:06:47.120</a></span> | <span class="t">a hundred questions developed in collaboration with 60 mathematicians from leading institutions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=412" target="_blank">00:06:52.640</a></span> | <span class="t">professors, International Math Olympiad question writers, and field medalists. Think of that like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=418" target="_blank">00:06:58.000</a></span> | <span class="t">the Nobel Prize for mathematics. They go on that these problems typically demand hours or even days</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=425" target="_blank">00:07:05.280</a></span> | <span class="t">for specialist mathematicians to solve. And Terence Tao, widely regarded as one of the smartest human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=431" target="_blank">00:07:11.520</a></span> | <span class="t">beings alive, said these are extremely challenging. Even he couldn't solve most of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=437" target="_blank">00:07:17.360</a></span> | <span class="t">How about the latest language models? Well, they can solve between 1 and 2% of them. That though</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=452" target="_blank">00:07:32.640</a></span> | <span class="t">isn't too disgraceful given that these are unpublished problems, novel ones not found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=459" target="_blank">00:07:39.120</a></span> | <span class="t">in the training data. This benchmark though should serve as somewhat of a canary in the coal mine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=465" target="_blank">00:07:45.120</a></span> | <span class="t">because before any model can quote "solve all of physics" you'd have thought it could get at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=470" target="_blank">00:07:50.640</a></span> | <span class="t">50 to 90% in this benchmark. Why not 100%? Because they estimate an error rate in the benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=477" target="_blank">00:07:57.680</a></span> | <span class="t">itself of around 10%. Quick sidebar is that other benchmarks are known to have an error rate around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=484" target="_blank">00:08:04.480</a></span> | <span class="t">10% for example the MMLU. So depending on your perspective this could either be a sobering wake</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=491" target="_blank">00:08:11.360</a></span> | <span class="t">up call about the remaining deficiencies of models or actually startlingly impressive. Is it the long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=498" target="_blank">00:08:18.000</a></span> | <span class="t">context window of Gemini 1.5 Pro that enables it to get 2%? Or is O1 Preview being underestimated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=504" target="_blank">00:08:24.720</a></span> | <span class="t">when it says it gets 1%? On page 9 of the paper they admit that those results were from a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=510" target="_blank">00:08:30.560</a></span> | <span class="t">evaluation and when they tested models across repeated trials O1 Preview demonstrated the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=516" target="_blank">00:08:36.000</a></span> | <span class="t">strongest performance. Of course you probably don't need reminding that this is just O1 Preview,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=521" target="_blank">00:08:41.040</a></span> | <span class="t">the full O1 comes out maybe in the next two weeks. If I was only trying to present the pessimistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=527" target="_blank">00:08:47.040</a></span> | <span class="t">case however I could focus on this quote. One mathematician interviewed about the difficulty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=532" target="_blank">00:08:52.160</a></span> | <span class="t">of the frontier math problems said this "Benchmark problems aren't quite the same as coming up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=538" target="_blank">00:08:58.000</a></span> | <span class="t">original proofs. So much of mathematics takes years to develop and research and that's really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=542" target="_blank">00:09:02.960</a></span> | <span class="t">hard to encapsulate in a benchmark." On the other hand if you wanted to get hyped you could hear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=547" target="_blank">00:09:07.760</a></span> | <span class="t">this quote from the co-founder of Anthropic "You're saying these things are dumb? People</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=552" target="_blank">00:09:12.720</a></span> | <span class="t">are making the math test equivalent of a basketball eval designed by NBA all-stars because the things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=559" target="_blank">00:09:19.680</a></span> | <span class="t">have gotten so good at basketball that no other tests stand up for more than six months before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=565" target="_blank">00:09:25.200</a></span> | <span class="t">they're obliterated by AI models." Should of course be interesting to see if my own benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=570" target="_blank">00:09:30.320</a></span> | <span class="t">SimpleBench is obliterated in the next six months. We tested the new small Claude 3.5 Haiku from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=576" target="_blank">00:09:36.720</a></span> | <span class="t">Anthropic and it displaced GPT-40 Mini to reach 13th at 15.6% in SimpleBench. SimpleBench is all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=584" target="_blank">00:09:44.800</a></span> | <span class="t">about testing common reasoning and the human baseline is in the mid 80s while frontier models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=590" target="_blank">00:09:50.240</a></span> | <span class="t">get around the low 40s. At this point I would definitely forgive you for being torn between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=594" target="_blank">00:09:54.960</a></span> | <span class="t">optimism and pessimism but where do I come down? Well the key to further progress could come from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=601" target="_blank">00:10:01.120</a></span> | <span class="t">a different axis entirely, data efficiency. After all to solve frontier math problems you either</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=607" target="_blank">00:10:07.440</a></span> | <span class="t">need to be a genius or you need to have access to relevant training data that is almost non-existent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=613" target="_blank">00:10:13.760</a></span> | <span class="t">There are apparently only a dozen papers with the relevant things said Terence Tao. Now of course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=619" target="_blank">00:10:19.840</a></span> | <span class="t">maths isn't everything and many of you will rightly argue that general intelligence, AGI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=625" target="_blank">00:10:25.280</a></span> | <span class="t">might arrive well before a model can crush frontier math. But still the challenges of solving frontier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=631" target="_blank">00:10:31.120</a></span> | <span class="t">math are roughly analogous to solving other domains. So I would ask, will companies like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=637" target="_blank">00:10:37.040</a></span> | <span class="t">OpenAI get access to those few dozen papers that contain the relevant reasoning steps? And even if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=643" target="_blank">00:10:43.280</a></span> | <span class="t">they do, can the models themselves pick out the signal from the noise? Pick out those reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=649" target="_blank">00:10:49.200</a></span> | <span class="t">steps contained within those dozens of papers from the tens of trillions of words that they're also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=655" target="_blank">00:10:55.360</a></span> | <span class="t">trained on? The O1 family of models from OpenAI suggests that is at least possible. If you're new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=662" target="_blank">00:11:02.000</a></span> | <span class="t">to the channel and you have no idea what I'm talking about when I talk about the O1 family</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=666" target="_blank">00:11:06.080</a></span> | <span class="t">of models do check out my video on the topic. The very brief TLDR is that that test time compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=672" target="_blank">00:11:12.240</a></span> | <span class="t">paradigm suggests that models might be able to extract at inference time when they're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=677" target="_blank">00:11:17.760</a></span> | <span class="t">outputs just one output among tens of thousands that contains the necessary reasoning steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=684" target="_blank">00:11:24.080</a></span> | <span class="t">If that's correct expect rapid progress on the frontier math benchmark. Of course those reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=689" target="_blank">00:11:29.680</a></span> | <span class="t">steps do have to be found somewhere in the training data that the weights of a model derive from. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=695" target="_blank">00:11:35.280</a></span> | <span class="t">as long as they are progress can continue and at this point I'll bring us back to the article that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=700" target="_blank">00:11:40.480</a></span> | <span class="t">kicked everything off. Even if OpenAI can only improve the quality of the underlying model the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=705" target="_blank">00:11:45.680</a></span> | <span class="t">GPC5 or Orion at a slower rate it will result in a much better reasoning output. In short because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=712" target="_blank">00:11:52.480</a></span> | <span class="t">if we're asking a model to output 10,000 different answers there's a greater chance that at least one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=718" target="_blank">00:11:58.800</a></span> | <span class="t">of those answers is correct. And again if the quality of the underlying model is even just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=724" target="_blank">00:12:04.800</a></span> | <span class="t">incrementally better it has a significantly better chance of discerning that correct answer from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=731" target="_blank">00:12:11.920</a></span> | <span class="t">noise. Hopefully I've conveyed that the ground truth reality is a lot more nuanced and complex</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=738" target="_blank">00:12:18.560</a></span> | <span class="t">than the positive Panglossian perspective or the everything's hit a wall perspective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=744" target="_blank">00:12:24.720</a></span> | <span class="t">Here at last then is the quote that I've been teasing for quite a while. One of the stars behind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=750" target="_blank">00:12:30.000</a></span> | <span class="t">the training of the O1 family of models said he can see progress continuing at least for one or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=754" target="_blank">00:12:34.640</a></span> | <span class="t">two more years but they simply don't know how long that will last. "I think it's still unclear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=760" target="_blank">00:12:40.800</a></span> | <span class="t">um I think that basically a lot of the assumptions about why we would be hitting a wall needs to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=768" target="_blank">00:12:48.080</a></span> | <span class="t">re-evaluated completely given that this there's this new paradigm and so we're still trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=772" target="_blank">00:12:52.400</a></span> | <span class="t">figure that out. I suspect that a lot of other people are going to be trying to figure that out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=776" target="_blank">00:12:56.000</a></span> | <span class="t">and the answer is like right now we don't know. Looking at the limitations of pre-training and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=781" target="_blank">00:13:01.200</a></span> | <span class="t">saying that's going to be a blocker on continued progress I think that that is no longer a blocker."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=786" target="_blank">00:13:06.000</a></span> | <span class="t">If even OpenAI don't know how much further scaling can go, how can we know? I'm going to end though</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=792" target="_blank">00:13:12.080</a></span> | <span class="t">on a lighter note because not everything in AI is about text-based benchmarks and reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=797" target="_blank">00:13:17.920</a></span> | <span class="t">According to the well-known co-founder and CEO of Runway, OpenAI is planning to finally release</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=804" target="_blank">00:13:24.880</a></span> | <span class="t">Sora in around two weeks. Sora is of course that incredible video generation model first described</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=810" target="_blank">00:13:30.960</a></span> | <span class="t">back in February. So even if you're one of those unlike me who believes that reasoning progress</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=816" target="_blank">00:13:36.480</a></span> | <span class="t">will ground to a hole, that doesn't mean progress in other modalities will too. What would explain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=821" target="_blank">00:13:41.760</a></span> | <span class="t">the discrepancy? Well we just have so much more data from videos say YouTube and from images to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=828" target="_blank">00:13:48.080</a></span> | <span class="t">train models on in those domains than we do for text. Indeed any domain where there's an abundance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=834" target="_blank">00:13:54.000</a></span> | <span class="t">of data expects progress to continue rapidly. Take for example speech-to-text and you guys have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=839" target="_blank">00:13:59.600</a></span> | <span class="t">heard before on the channel talking about channel sponsor AssemblyAI and their Universal One model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=845" target="_blank">00:14:05.840</a></span> | <span class="t">Well even in a surprise to me they have now come out with Universal Two. I'll link the research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=851" target="_blank">00:14:11.920</a></span> | <span class="t">page below because there is an absolute ton I could go through. Probably goes without saying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=856" target="_blank">00:14:16.720</a></span> | <span class="t">that the word error rates are much lower for Universal Two compared to all these other models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=862" target="_blank">00:14:22.640</a></span> | <span class="t">That's why as I've mentioned many times before I actually reached out to AssemblyAI to be a channel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=868" target="_blank">00:14:28.240</a></span> | <span class="t">sponsor. And speaking of audio don't forget to check out my podcasts and exclusive videos</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=873" target="_blank">00:14:33.120</a></span> | <span class="t">on my Patreon which is called AI Insiders. What am I up to now? Almost 40 videos and podcasts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=879" target="_blank">00:14:39.440</a></span> | <span class="t">If you leave this video neither overly hyped nor overly skeptical I've done my job and I get that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=884" target="_blank">00:14:44.800</a></span> | <span class="t">that leaves us in somewhat of a weird place. So here is an AI generated video that captures just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=890" target="_blank">00:14:50.880</a></span> | <span class="t">a bit of that weirdness. "Can a robot write a symphony? Can a robot turn a canvas into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=896" target="_blank">00:14:56.480</a></span> | <span class="t">beautiful masterpiece? Can you?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=902" target="_blank">00:15:02.080</a></span> | <span class="t">[Music]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=914" target="_blank">00:15:14.560</a></span> | <span class="t">[Music]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=926" target="_blank">00:15:26.880</a></span> | <span class="t">Well done to Dari3D who put that video together and a big thank you to all of you for watching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=iybgycPk-N4&t=940" target="_blank">00:15:40.560</a></span> | <span class="t">to the end. Thank you so much and have a wonderful day.</span></div></div></body></html>