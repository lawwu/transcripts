<html><head><title>AI will bring pocket nukes but is still net positive – Tyler Cowen</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>AI will bring pocket nukes but is still net positive – Tyler Cowen</h2><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA"><img src="https://i.ytimg.com/vi_webp/AZAqO3k_KxA/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./AZAqO3k_KxA.html">Whisper Transcript</a> | <a href="./transcript_AZAqO3k_KxA.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">My worry is that energy becomes too cheap and people at very low cost can destroy things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=5" target="_blank">00:00:05.280</a></span> | <span class="t">rather easily. So say if destroying a city with a nuclear weapon cost $50,000,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=11" target="_blank">00:00:11.520</a></span> | <span class="t">what would the world look like? I'm just not sure. It might be more stable than we think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=18" target="_blank">00:00:18.320</a></span> | <span class="t">but I'm greatly worried and I could readily imagine it falling apart. There's uncertainty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=22" target="_blank">00:00:22.720</a></span> | <span class="t">about a lot of things and AI will help us with those other uncertainties. So Annette,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=27" target="_blank">00:00:27.440</a></span> | <span class="t">do you think more intelligence is likely to be good or bad, including against x-risk? And I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=32" target="_blank">00:00:32.080</a></span> | <span class="t">think it's more likely to be good. So if it were the only risk, I'd be more worried about it than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=37" target="_blank">00:00:37.120</a></span> | <span class="t">if there's a whole multitude of risks. But clearly there's a whole multitude of risks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=41" target="_blank">00:00:41.200</a></span> | <span class="t">But since people grew up in pretty stable times, they tend not to see that in emotionally vivid</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=46" target="_blank">00:00:46.160</a></span> | <span class="t">terms. And then this one monster comes along and they're all terrified. In this case, the reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=50" target="_blank">00:00:50.720</a></span> | <span class="t">the nuke got so cheap was because of intelligence. Now that doesn't mean we should stop intelligence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=56" target="_blank">00:00:56.720</a></span> | <span class="t">but if that's the end result of intelligence over hundreds of years, that doesn't seem like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=61" target="_blank">00:01:01.600</a></span> | <span class="t">intelligence is always a net good. Well, we're doing better than the other great apes, I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=67" target="_blank">00:01:07.040</a></span> | <span class="t">say, even though we face these really big risks. And in the meantime, we did incredible things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=71" target="_blank">00:01:11.840</a></span> | <span class="t">So that's a gamble I would take. But I believe we should view it more self-consciously as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=76" target="_blank">00:01:16.560</a></span> | <span class="t">sort of gamble. And it's too late to turn back. The fundamental choice was one of decentralization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=83" target="_blank">00:01:23.040</a></span> | <span class="t">And that may have happened hundreds of millions or billions of years ago. And once you opt for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=87" target="_blank">00:01:27.920</a></span> | <span class="t">decentralization, intelligence is going to have advantages and you're not going to be able to turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=93" target="_blank">00:01:33.440</a></span> | <span class="t">the clock back on it. The risk, not that everyone dies, I think that's quite low, but that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=98" target="_blank">00:01:38.320</a></span> | <span class="t">retreat to some kind of pretty chaotic form of like medieval Balkans existence with a much lower</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=104" target="_blank">00:01:44.720</a></span> | <span class="t">population. That seems to me quite a high risk with or without AI. It's probably the default</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=110" target="_blank">00:01:50.480</a></span> | <span class="t">setting. Given that you think that's the default setting. Why is that not a big part of your when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=116" target="_blank">00:01:56.400</a></span> | <span class="t">you're thinking about how new technologies are coming about? Why not consciously think in terms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=121" target="_blank">00:02:01.440</a></span> | <span class="t">of is this getting us to the outcome where we avoid this sort of pre-industrial state that would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=126" target="_blank">00:02:06.480</a></span> | <span class="t">result from the $50,000 nukes? Well, if you think the risk is cheap energy more than AI per se,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=133" target="_blank">00:02:13.360</a></span> | <span class="t">admittedly, AI could speed the path to cheap energy. It seems very hard to control the strategy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=140" target="_blank">00:02:20.160</a></span> | <span class="t">that's worked best so far is to have relatively benevolent nations become hegemons and establish</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=146" target="_blank">00:02:26.240</a></span> | <span class="t">dominance. So it does influence me. I want the US, UK, some other subset of nations to establish</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=153" target="_blank">00:02:33.840</a></span> | <span class="t">dominance in AI. It may not work forever, but in a decentralized world, it sure beats the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=159" target="_blank">00:02:39.280</a></span> | <span class="t">alternative. So a lot of the AI types, they're too rationalist and they don't start with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=164" target="_blank">00:02:44.080</a></span> | <span class="t">premise that we chose a decentralized world a very, very long time ago, even way before humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=168" target="_blank">00:02:48.960</a></span> | <span class="t">What would have to be different for you to not be a doomer per se, but just one of these people who</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=172" target="_blank">00:02:52.800</a></span> | <span class="t">this is the main thing to be thinking about during this period of history or something like that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=177" target="_blank">00:02:57.200</a></span> | <span class="t">Well, I think it is one of the main things we should be thinking about. But I would say if I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=181" target="_blank">00:03:01.680</a></span> | <span class="t">thought international cooperation were very possible, I would at least possibly have very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=188" target="_blank">00:03:08.160</a></span> | <span class="t">different views than I do now. Or if I thought no other country could make progress on AI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=193" target="_blank">00:03:13.280</a></span> | <span class="t">those seem unlikely to me, but they're not logically impossible. So the fundamental premise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=199" target="_blank">00:03:19.360</a></span> | <span class="t">where I differ from a lot of the doomers is my understanding of a decentralized world and its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=204" target="_blank">00:03:24.800</a></span> | <span class="t">principles being primary. Their understanding is some kind of comparison, like here's the little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=209" target="_blank">00:03:29.440</a></span> | <span class="t">people and here's the big monster and the big monster gets bigger. And even if the big monster</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=214" target="_blank">00:03:34.320</a></span> | <span class="t">does a lot of good things, it's just getting bigger and here are the little people. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=218" target="_blank">00:03:38.320</a></span> | <span class="t">a possible framework. But if you start with decentralization and competition, you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=222" target="_blank">00:03:42.800</a></span> | <span class="t">just think you can wake up in the morning and like legislate safety.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=225" target="_blank">00:03:45.920</a></span> | <span class="t">I think you made an interesting point when you were talking about Keynes in the book where you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=229" target="_blank">00:03:49.440</a></span> | <span class="t">said one of his faults was that he assumed that people like him would always be in charge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=233" target="_blank">00:03:53.680</a></span> | <span class="t">That's right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=234" target="_blank">00:03:54.080</a></span> | <span class="t">And I do see that also in the alignment discourse, like alignment is, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=237" target="_blank">00:03:57.440</a></span> | <span class="t">if it's just handing over to the government and just assuming the government does what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=240" target="_blank">00:04:00.000</a></span> | <span class="t">you'd expect it to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=241" target="_blank">00:04:01.040</a></span> | <span class="t">And I worry about this from my own point of view. So even if you think U.S. is pretty benevolent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=245" target="_blank">00:04:05.120</a></span> | <span class="t">today, which is a highly contested and mixed proposition, and I'm an American citizen,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=250" target="_blank">00:04:10.160</a></span> | <span class="t">pretty patriotic, but I'm fully aware of the long history of my government in killing and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=255" target="_blank">00:04:15.360</a></span> | <span class="t">slaving, doing other terrible things to people. And then you have to rethink that over a long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=261" target="_blank">00:04:21.280</a></span> | <span class="t">period of time, it may be the worst time period that affects the final outcome, even if the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=266" target="_blank">00:04:26.720</a></span> | <span class="t">average is pretty good. And then if power corrupts and if government even indirectly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=272" target="_blank">00:04:32.480</a></span> | <span class="t">controls AI systems, so U.S. government could become worse because it's a leader in AI, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=277" target="_blank">00:04:37.680</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=278" target="_blank">00:04:38.480</a></span> | <span class="t">But again, I've got to still take that over China or Russia or wherever else it might be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=285" target="_blank">00:04:45.120</a></span> | <span class="t">What's your sense of how the government reacts when the labs are doing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=288" target="_blank">00:04:48.720</a></span> | <span class="t">regardless of how they should react, how they will react when the labs are doing, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=292" target="_blank">00:04:52.240</a></span> | <span class="t">I don't know, $10 billion training runs. And if under the premise that, you know, these are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=297" target="_blank">00:04:57.280</a></span> | <span class="t">powerful models, not human level, per se, but just they can do all kinds of crazy stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=301" target="_blank">00:05:01.680</a></span> | <span class="t">How do you think the government's going to, are they going to nationalize the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=304" target="_blank">00:05:04.720</a></span> | <span class="t">labs or how are you staying in Washington? What's your sense?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=307" target="_blank">00:05:07.440</a></span> | <span class="t">My guess is until there's sort of an SBF-like incident, which might even not be significant,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=312" target="_blank">00:05:12.800</a></span> | <span class="t">but a headlines incident, which SBF was, even if it doesn't affect the future evolution of crypto,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=318" target="_blank">00:05:18.320</a></span> | <span class="t">which I guess is my view, it won't. Until there's that, we won't do much of anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=323" target="_blank">00:05:23.280</a></span> | <span class="t">And then we'll have an SBF-like incident and we'll overreact. That seems a very common</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=328" target="_blank">00:05:28.400</a></span> | <span class="t">pattern in American history. And the fact that it's AI, the stakes might be high or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=333" target="_blank">00:05:33.840</a></span> | <span class="t">I doubt if it will change the recurrence of that pattern.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=337" target="_blank">00:05:37.120</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=337" target="_blank">00:05:37.620</a></span> | <span class="t">you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=AZAqO3k_KxA&t=339" target="_blank">00:05:39.680</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>