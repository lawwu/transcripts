<html><head><title>Lesson 8 - Deep Learning for Coders (2020)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 8 - Deep Learning for Coders (2020)</h2><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM"><img src="https://i.ytimg.com/vi_webp/WjnwWeGjZcM/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=15">0:15</a> Natural Language Processing<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=310">5:10</a> Building a Language Model<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=738">12:18</a> Get Files<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=808">13:28</a> Word Tokenizer<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=990">16:30</a> Word Tokenizer Rules<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1058">17:38</a> SubWord Tokenizer<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1141">19:1</a> Setup<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1403">23:23</a> Numericalization<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1543">25:43</a> Batch<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1759">29:19</a> Data Loader<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1818">30:18</a> Independent Variables<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1836">30:36</a> Dependent Variables<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1869">31:9</a> Data Blocks<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1916">31:56</a> Class Methods<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2005">33:25</a> Language Model<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2108">35:8</a> Save Epoch<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2132">35:32</a> Save Encoder<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2275">37:55</a> Text Generation<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2525">42:5</a> Language Models<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2569">42:49</a> Classification<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2590">43:10</a> Batch Size<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2660">44:20</a> Pad Tokens<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2729">45:29</a> Text Classifier<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2911">48:31</a> Data Augmentation<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2934">48:54</a> Predicting the Next Word<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3060">51:0</a> Data Augmentation on Text<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3111">51:51</a> Generation<br><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3491">58:11</a> Creating Datasets<br><br><div style="text-align: left;"><a href="./WjnwWeGjZcM.html">Whisper Transcript</a> | <a href="./transcript_WjnwWeGjZcM.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hi everybody and welcome to Lesson 8, the last lesson of Part 1 of this course. Thanks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6" target="_blank">00:00:06.820</a></span> | <span class="t">so much for sticking with us. Got a very interesting lesson today where we're going to do a dive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=12" target="_blank">00:00:12.540</a></span> | <span class="t">into natural language processing. And remind you, we did see natural language processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=18" target="_blank">00:00:18.000</a></span> | <span class="t">in Lesson 1. This was it here. We looked at a dataset where we could pass in many movie</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=28" target="_blank">00:00:28.160</a></span> | <span class="t">reviews like so and get back probabilities that it's a positive or negative sentiment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=34" target="_blank">00:00:34.740</a></span> | <span class="t">And we trained it with a very standard looking classifier trainer approach. But we haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=41" target="_blank">00:00:41.160</a></span> | <span class="t">really talked about what's going on behind the scenes there, so let's do that. And we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=46" target="_blank">00:00:46.040</a></span> | <span class="t">also learn about how to make it better. So we were getting about 93%. So 93% accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=52" target="_blank">00:00:52.280</a></span> | <span class="t">for sentiment analysis which is actually extremely good and it only took a bit over 10 minutes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=58" target="_blank">00:00:58.560</a></span> | <span class="t">But let's see if we can do better. So we're going to go to notebook number 10. And in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=68" target="_blank">00:01:08.640</a></span> | <span class="t">notebook number 10 we're going to start by talking about what we're going to do to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=76" target="_blank">00:01:16.640</a></span> | <span class="t">an NLP classifier. So a sentiment analysis which is this movie review positive or negative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=82" target="_blank">00:01:22.040</a></span> | <span class="t">sentiment is just a classifier. The dependent variable is binary. And the independent variable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=88" target="_blank">00:01:28.040</a></span> | <span class="t">is the kind of the interesting bit. So we're going to talk about that. But before we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=93" target="_blank">00:01:33.000</a></span> | <span class="t">we're going to talk about what was the pre-trained model that got used here. Because the reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=100" target="_blank">00:01:40.200</a></span> | <span class="t">we got such a good result so quickly is because we're doing fine-tuning of a pre-trained model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=106" target="_blank">00:01:46.540</a></span> | <span class="t">So what is this pre-trained model exactly? Well the pre-trained model is actually a pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=111" target="_blank">00:01:51.440</a></span> | <span class="t">language model. So what is a language model? A language model is a special kind of model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=121" target="_blank">00:02:01.140</a></span> | <span class="t">and it's a model where we try to predict the next word of a sentence. So for example if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=129" target="_blank">00:02:09.680</a></span> | <span class="t">our language model received even if our language model knows the and its job would be to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=138" target="_blank">00:02:18.000</a></span> | <span class="t">basics. Now the language model that we use as our pre-trained model was actually trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=145" target="_blank">00:02:25.760</a></span> | <span class="t">on Wikipedia. So we took all the you know non-trivial sized articles in Wikipedia and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=154" target="_blank">00:02:34.800</a></span> | <span class="t">we built a language model which attempted to predict the next word of every sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=160" target="_blank">00:02:40.080</a></span> | <span class="t">of words in every one of those articles. And it was a neural network of course. And we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=167" target="_blank">00:02:47.280</a></span> | <span class="t">then take those pre-trained weights and those are the pre-trained weights that when we said</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=171" target="_blank">00:02:51.240</a></span> | <span class="t">text classifier learner were automatically loaded in. So conceptually why would it be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=177" target="_blank">00:02:57.680</a></span> | <span class="t">useful to pre-train a language model? How does that help us to do sentiment analysis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=182" target="_blank">00:03:02.960</a></span> | <span class="t">for example? Well just like an ImageNet model has a lot of information about what pictures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=190" target="_blank">00:03:10.360</a></span> | <span class="t">look like and what they're consisting of. A language model tells us a bit a lot about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=196" target="_blank">00:03:16.920</a></span> | <span class="t">what sentences look like and what they know about the world. So a language model for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=204" target="_blank">00:03:24.120</a></span> | <span class="t">if it's going to be able to predict the end of the sentence in 1998 this law was passed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=214" target="_blank">00:03:34.760</a></span> | <span class="t">by president what? So a language model to predict that correctly would have to know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=221" target="_blank">00:03:41.840</a></span> | <span class="t">a whole lot of stuff. It would have to know about well how English language works in general</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=225" target="_blank">00:03:45.760</a></span> | <span class="t">and what kind of sentences go in what places. That after the word president would usually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=231" target="_blank">00:03:51.760</a></span> | <span class="t">be the surname of somebody. It would need to know what country that law was passed in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=237" target="_blank">00:03:57.000</a></span> | <span class="t">and it would need to know what president was president of that country in what I say 1998.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=243" target="_blank">00:04:03.720</a></span> | <span class="t">So it'd have to know a lot about the world. It would have to know a lot about language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=247" target="_blank">00:04:07.880</a></span> | <span class="t">to create a really good language model is really hard. And in fact this is something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=252" target="_blank">00:04:12.720</a></span> | <span class="t">that people spend many many many millions of dollars on creating language models of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=259" target="_blank">00:04:19.440</a></span> | <span class="t">huge datasets. Our particular one doesn't take particularly long to pre-train but there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=265" target="_blank">00:04:25.960</a></span> | <span class="t">no particular reason for you to pre-train one of these language models because you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=269" target="_blank">00:04:29.240</a></span> | <span class="t">download them through fast AI or through other places. So what happened in lesson one is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=279" target="_blank">00:04:39.600</a></span> | <span class="t">we downloaded this pre-trained Wikipedia model and then we fine-tuned it so as per usual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=285" target="_blank">00:04:45.520</a></span> | <span class="t">we threw away the last layer which was specific for predicting the next word of Wikipedia</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=291" target="_blank">00:04:51.840</a></span> | <span class="t">and fine-tuned the model. Initially just the last layer to learn to predict sentiment of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=299" target="_blank">00:04:59.960</a></span> | <span class="t">movie reviews and then as per usual then fine-tuned the rest of the model and that got us 93%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=307" target="_blank">00:05:07.720</a></span> | <span class="t">Now there's a trick we can use though which is we start with this Wikipedia language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=314" target="_blank">00:05:14.000</a></span> | <span class="t">and the particular subset we use is called Wikitext 103. And rather than just jumping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=319" target="_blank">00:05:19.760</a></span> | <span class="t">straight to a classifier which we did in lesson one we can do even better if we first of all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=324" target="_blank">00:05:24.920</a></span> | <span class="t">create an IMDB language model that is to say a language model that learns to predict the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=330" target="_blank">00:05:30.360</a></span> | <span class="t">next word of a movie review. The reason we do that is that this will help it to learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=336" target="_blank">00:05:36.640</a></span> | <span class="t">about IMDB specific kind of words like it'll learn a lot more about the names of actors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=342" target="_blank">00:05:42.760</a></span> | <span class="t">and directors it'll learn about the kinds of words that people use in movie reviews.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=348" target="_blank">00:05:48.760</a></span> | <span class="t">And so if we do that first then we would hope we'll end up with a better classifier. So that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=353" target="_blank">00:05:53.240</a></span> | <span class="t">what we're going to do in the first part of today's lesson. And we're going to kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=359" target="_blank">00:05:59.880</a></span> | <span class="t">do it from scratch and we're going to show you how to do a lot of the things from scratch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=364" target="_blank">00:06:04.540</a></span> | <span class="t">even though later we'll show you how fast AI does it all for you. So how do we build</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=370" target="_blank">00:06:10.240</a></span> | <span class="t">a language model? So as we point out here sentences can be different lengths and documents like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=376" target="_blank">00:06:16.360</a></span> | <span class="t">movie reviews can be very long. So how do we go about this? Well a word is basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=386" target="_blank">00:06:26.440</a></span> | <span class="t">a categorical variable and we already know how to use categorical variables as an independent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=391" target="_blank">00:06:31.680</a></span> | <span class="t">variable in a neural net which was we make a list of all of the possible levels of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=395" target="_blank">00:06:35.880</a></span> | <span class="t">categorical variable which we call the vocab and then we replace each of those categories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=402" target="_blank">00:06:42.640</a></span> | <span class="t">with its index so they all become numbers. We create an initially random embedding matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=409" target="_blank">00:06:49.320</a></span> | <span class="t">for each so each row then is for one element from the vocab and then we make that the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=415" target="_blank">00:06:55.880</a></span> | <span class="t">layer of a neural net. So that's what we've done a few times now and we've even created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=422" target="_blank">00:07:02.540</a></span> | <span class="t">our own embedding layer from scratch remember. So we can do the same thing with text right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=427" target="_blank">00:07:07.540</a></span> | <span class="t">we can make a list of all the possible words in in the whole corpus the whole dataset and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=435" target="_blank">00:07:15.320</a></span> | <span class="t">we can replace each word with the index of the vocab and creating embedding matrix. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=443" target="_blank">00:07:23.080</a></span> | <span class="t">in order to create a list of all levels in this case a list of all possible words let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=448" target="_blank">00:07:28.080</a></span> | <span class="t">first of all concatenate all the documents or the movie reviews together into one big</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=452" target="_blank">00:07:32.480</a></span> | <span class="t">long string and split it into words okay and then our independent variable will basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=459" target="_blank">00:07:39.200</a></span> | <span class="t">be that sequence starting with the first word in the long list and ending with a second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=464" target="_blank">00:07:44.120</a></span> | <span class="t">last and our dependent variable will be the sequence of words starting with a second word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=469" target="_blank">00:07:49.200</a></span> | <span class="t">and ending with a last so they're kind of offset by one so as you move through the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=474" target="_blank">00:07:54.520</a></span> | <span class="t">sequence you're then trying to predict the next word in the next in the in the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=480" target="_blank">00:08:00.320</a></span> | <span class="t">part that's kind of what we're doing right we'll see more detail in a moment. Now when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=486" target="_blank">00:08:06.680</a></span> | <span class="t">we create our vocab by finding all the unique words in this concatenated corpus a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=494" target="_blank">00:08:14.560</a></span> | <span class="t">the words we see will be already in the embedding matrix already in the vocab of the pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=500" target="_blank">00:08:20.920</a></span> | <span class="t">Wikipedia model but there's also going to be some new ones right there might be some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=506" target="_blank">00:08:26.800</a></span> | <span class="t">particular actors that don't appear in Wikipedia or maybe some informal slang words and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=514" target="_blank">00:08:34.920</a></span> | <span class="t">forth so when we build our vocab and then our embedding embedding matrix for the IMDB</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=523" target="_blank">00:08:43.440</a></span> | <span class="t">language model any words that are in the vocab of the pre-trained model we'll just use them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=529" target="_blank">00:08:49.520</a></span> | <span class="t">as is but for new words we'll create a new random vector. So here's the process we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=538" target="_blank">00:08:58.520</a></span> | <span class="t">going to have to go through first we're going to have to take our big concatenated corpus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=543" target="_blank">00:09:03.940</a></span> | <span class="t">and turn it into a list of tokens could be words could be characters could be substrings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=550" target="_blank">00:09:10.800</a></span> | <span class="t">that's called tokenization and then we'll do numericalization which is basically these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=558" target="_blank">00:09:18.700</a></span> | <span class="t">two steps which is replacing each word with its index in a vocab which means we have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=563" target="_blank">00:09:23.600</a></span> | <span class="t">create that vocab so create the vocab and then convert then we're going to need to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=569" target="_blank">00:09:29.200</a></span> | <span class="t">a data loader that has lots of substrings lots of sequences of tokens from IMDB corpus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=577" target="_blank">00:09:37.720</a></span> | <span class="t">as an independent variable and the same thing offset by one as a dependent variable and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=585" target="_blank">00:09:45.520</a></span> | <span class="t">then we're going to have to create a language model. Now a language model is going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=589" target="_blank">00:09:49.560</a></span> | <span class="t">able to handle input lists that can be arbitrarily big or small and we're going to be using something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=596" target="_blank">00:09:56.240</a></span> | <span class="t">called a recurrent neural network to do this which we'll learn about later so basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=600" target="_blank">00:10:00.640</a></span> | <span class="t">so far we've always assumed that everything is a fixed size a fixed input so we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=605" target="_blank">00:10:05.840</a></span> | <span class="t">to have to mix things up a little bit here and deal with architectures that can be different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=610" target="_blank">00:10:10.640</a></span> | <span class="t">sizes for this notebook notebook 10 we're going to kind of treat it as a black box it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=618" target="_blank">00:10:18.360</a></span> | <span class="t">just going to be just a neural net and then later in the lesson we'll look at delving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=623" target="_blank">00:10:23.200</a></span> | <span class="t">inside what's happening in that architecture okay so let's start with the first of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=630" target="_blank">00:10:30.320</a></span> | <span class="t">which is tokenization so converting a text into a list of words or a list of tokens what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=636" target="_blank">00:10:36.480</a></span> | <span class="t">does that mean is a full stop a token what about don't is that single word or is it two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=645" target="_blank">00:10:45.000</a></span> | <span class="t">words don't or is it would I convert it to do not what about long medical words that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=651" target="_blank">00:10:51.040</a></span> | <span class="t">are kind of made up of lots of pieces of medical jargon that are all stuck together what about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=655" target="_blank">00:10:55.880</a></span> | <span class="t">hyphenated words and really interestingly then what about something like Polish where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=661" target="_blank">00:11:01.560</a></span> | <span class="t">you or Turkish where you can create really long words all the time they create really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=666" target="_blank">00:11:06.400</a></span> | <span class="t">long words that are actually lots of separate parts or concatenated together or languages</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=671" target="_blank">00:11:11.360</a></span> | <span class="t">like Japanese and Chinese that don't use spaces at all they don't really have a world of find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=678" target="_blank">00:11:18.560</a></span> | <span class="t">idea of a word well there's no right answer but it's basically three approaches we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=686" target="_blank">00:11:26.480</a></span> | <span class="t">use a word-based approach which is what we use by default at the moment for English although</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=690" target="_blank">00:11:30.640</a></span> | <span class="t">that might change which is we split a sentence on space and then there are some language specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=696" target="_blank">00:11:36.160</a></span> | <span class="t">rules for example turning don't into do and putting punctuation marks as a separate token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=703" target="_blank">00:11:43.240</a></span> | <span class="t">most of the time really interestingly there are tokenizes at a sub word based and this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=709" target="_blank">00:11:49.600</a></span> | <span class="t">is where we split words into smaller parts based on the most commonly occurring substrings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=714" target="_blank">00:11:54.440</a></span> | <span class="t">we'll see that in a moment or the simplest character-based split a sentence into its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=720" target="_blank">00:12:00.640</a></span> | <span class="t">characters we're going to look at word and sub word tokenization in this notebook and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=726" target="_blank">00:12:06.040</a></span> | <span class="t">then if you look at the questionnaire at the end you'll be asked to create your own character</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=730" target="_blank">00:12:10.200</a></span> | <span class="t">based tokenizer so please make sure you do that if you can it'll be a great exercise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=739" target="_blank">00:12:19.280</a></span> | <span class="t">so fastai doesn't invent its own tokenizers we just provide a consistent interface to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=745" target="_blank">00:12:25.960</a></span> | <span class="t">a range of external tokenizers because there's a lot of great tokenizers out there so you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=752" target="_blank">00:12:32.480</a></span> | <span class="t">can switch between different tokenizers pretty easily so let's start let's grab our IMDB data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=758" target="_blank">00:12:38.360</a></span> | <span class="t">set like we did in lesson one and in order to try out a tokenizer let's grab all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=764" target="_blank">00:12:44.320</a></span> | <span class="t">text files so we can instead of calling get image files we'll call get text files and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=771" target="_blank">00:12:51.040</a></span> | <span class="t">you know to have a look at what that's doing don't forget we can even look at the source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=775" target="_blank">00:12:55.640</a></span> | <span class="t">code and you can see actually it's calling a more general thing called get files and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=780" target="_blank">00:13:00.960</a></span> | <span class="t">saying what extensions it wants right so if anything in fastai doesn't work quite the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=784" target="_blank">00:13:04.400</a></span> | <span class="t">way you want and there isn't a option which which works the way you want you can often</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=789" target="_blank">00:13:09.080</a></span> | <span class="t">look always look underneath to see what we're calling and you can call the lower level stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=793" target="_blank">00:13:13.880</a></span> | <span class="t">yourself so files is now a list of files so we can grab the first one we can open it we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=800" target="_blank">00:13:20.280</a></span> | <span class="t">can read it have a look at the start of this review and here it is okay so at the moment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=811" target="_blank">00:13:31.240</a></span> | <span class="t">the default English word tokenizer we use is called spaCy which uses a pretty sophisticated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=817" target="_blank">00:13:37.080</a></span> | <span class="t">set of rules with special rules for particular words and URLs and so forth but we're just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=825" target="_blank">00:13:45.320</a></span> | <span class="t">going to go ahead and say word tokenizer which will automatically use fastai's default word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=829" target="_blank">00:13:49.920</a></span> | <span class="t">tokenizer currently spaCy and so if we pass a list of documents we'll just make it a list</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=838" target="_blank">00:13:58.320</a></span> | <span class="t">of one document here to the tokenizer we just created and just grab the first since we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=844" target="_blank">00:14:04.000</a></span> | <span class="t">created a list that's going to show us as you can see the tokenized version so you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=850" target="_blank">00:14:10.880</a></span> | <span class="t">see here that this movie which I just discovered at the video store has etc it's changed it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=859" target="_blank">00:14:19.440</a></span> | <span class="t">into it's and it's put a comma as a separate punctuation mark and so forth okay so you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=870" target="_blank">00:14:30.400</a></span> | <span class="t">can see how it has tokenized this review.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=878" target="_blank">00:14:38.480</a></span> | <span class="t">Let's look at a more interesting one the US dollar blah blah blah and you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=882" target="_blank">00:14:42.600</a></span> | <span class="t">it actually knows that US is special so it doesn't put the full stop in a set as a separate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=886" target="_blank">00:14:46.840</a></span> | <span class="t">place for US it knows about 1.00 is special so you can see there's a lot of tricky stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=893" target="_blank">00:14:53.120</a></span> | <span class="t">going on with spaCy to try and be as kind of thoughtful about this as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=900" target="_blank">00:15:00.760</a></span> | <span class="t">Fastai then provides this tokenizer wrapper which provides some additional functionality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=908" target="_blank">00:15:08.120</a></span> | <span class="t">to any tokenizer as you can see here which is for example the word it here which previously</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=920" target="_blank">00:15:20.400</a></span> | <span class="t">was capital IT has been turned into lowercase IT and then a special token XX badge has appeared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=927" target="_blank">00:15:27.220</a></span> | <span class="t">at the front everything starting with XX is a special fastai token and this means that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=933" target="_blank">00:15:33.360</a></span> | <span class="t">the next match means that the next word was previously started with a capital letter so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=938" target="_blank">00:15:38.840</a></span> | <span class="t">here's another one this used to be capital T so you make it lowercase and then add XX</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=943" target="_blank">00:15:43.920</a></span> | <span class="t">page XXBOS means this is the start of a document so there's a few special rules going on there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=951" target="_blank">00:15:51.800</a></span> | <span class="t">so why do we do that well if you think about it if we didn't lowercase it for instance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=957" target="_blank">00:15:57.760</a></span> | <span class="t">or this then the capitalized version and the lowercase version are going to be two different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=963" target="_blank">00:16:03.760</a></span> | <span class="t">words in the embedding matrix which probably doesn't make sense you know regardless of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=968" target="_blank">00:16:08.320</a></span> | <span class="t">the capitalization they probably basically mean the same thing having said that sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=975" target="_blank">00:16:15.720</a></span> | <span class="t">the capitalization might matter so we kind of want to say all right use the same embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=980" target="_blank">00:16:20.200</a></span> | <span class="t">every time you see the word this but add some kind of marker that says that this was originally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=984" target="_blank">00:16:24.640</a></span> | <span class="t">capitalized okay so that's why we do it like this so there's quite a few rules you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=993" target="_blank">00:16:33.500</a></span> | <span class="t">see them in text proc rules and you can see the source code here's a summary of what they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=998" target="_blank">00:16:38.520</a></span> | <span class="t">do but let's look at a few examples so if we use that tokenizer we created and pass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1004" target="_blank">00:16:44.760</a></span> | <span class="t">in for example this text you can see the way it's tokenized we get the XX beginning of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1009" target="_blank">00:16:49.820</a></span> | <span class="t">stream or beginning of string beginning of document this HTML entity has become a real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1014" target="_blank">00:16:54.680</a></span> | <span class="t">Unicode we've got the XX Madge we discussed now here www has been replaced by XXRep3w that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1024" target="_blank">00:17:04.680</a></span> | <span class="t">means the letter w is repeated three times so for things where you've got like you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1031" target="_blank">00:17:11.560</a></span> | <span class="t">a hundred exclamation marks in a row all the words so with like 50 Os this is a much better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1037" target="_blank">00:17:17.960</a></span> | <span class="t">representation and then you can see all upper case has been replaced with XX up followed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1046" target="_blank">00:17:26.960</a></span> | <span class="t">by the word so there's some of those rules in action oh you can also see multiple spaces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1053" target="_blank">00:17:33.400</a></span> | <span class="t">have been replaced you know with making just making it standard tokens so that's the word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1060" target="_blank">00:17:40.000</a></span> | <span class="t">tokenizer the really interesting one is the subword tokenizer so how why would you need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1066" target="_blank">00:17:46.820</a></span> | <span class="t">a subword tokenizer well consider for example this sentence here order means they're sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1071" target="_blank">00:17:51.860</a></span> | <span class="t">how'd you rate so this is my name is Jeremy but the interesting thing about it is there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1077" target="_blank">00:17:57.900</a></span> | <span class="t">no spaces here right and that's because there are no spaces in Chinese and there isn't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1086" target="_blank">00:18:06.520</a></span> | <span class="t">a great sense of what a word is in Chinese in this particular sentence it's fairly clear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1090" target="_blank">00:18:10.920</a></span> | <span class="t">what the words are but it's not always obvious sometimes the words are actually split you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1096" target="_blank">00:18:16.720</a></span> | <span class="t">know so some of it's at the start of a sentence and some of it's at the end so you can't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1101" target="_blank">00:18:21.160</a></span> | <span class="t">do word tokenization for something like Chinese so instead we use subword tokenization which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1108" target="_blank">00:18:28.000</a></span> | <span class="t">is where we look at a corpus of documents and we find the most commonly occurring groups</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1113" target="_blank">00:18:33.200</a></span> | <span class="t">of letters and those commonly occurring groups of letters become the vocab so for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1120" target="_blank">00:18:40.600</a></span> | <span class="t">we would probably find order would appear often because that means my and Ming Z and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1127" target="_blank">00:18:47.520</a></span> | <span class="t">then Ming Z for example is name and this is my westernized version of a Chinese name which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1135" target="_blank">00:18:55.960</a></span> | <span class="t">wouldn't be very common at all so they would probably appear separately so let's look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1143" target="_blank">00:19:03.200</a></span> | <span class="t">an example let's grab the first 2000 movie reviews and let's create the default subword</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1153" target="_blank">00:19:13.840</a></span> | <span class="t">tokenizer which currently uses something called sentence piece that might change and now we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1160" target="_blank">00:19:20.080</a></span> | <span class="t">going to use something special something very important which is called setup transforms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1165" target="_blank">00:19:25.960</a></span> | <span class="t">in fastai you can always call this special thing called setup it often doesn't do anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1171" target="_blank">00:19:31.640</a></span> | <span class="t">stupid it's always there but some transforms like a subword tokenizer actually need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1177" target="_blank">00:19:37.960</a></span> | <span class="t">be set up before you can use them in other words you can't tokenize into subwords until</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1183" target="_blank">00:19:43.680</a></span> | <span class="t">you know what the most commonly occurring groups of letters are so passing a list of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1189" target="_blank">00:19:49.840</a></span> | <span class="t">texts in here this list of text to set up will train the subword tokenizer it'll find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1197" target="_blank">00:19:57.840</a></span> | <span class="t">those commonly occurring groups of letters so having done that we can then this is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1204" target="_blank">00:20:04.080</a></span> | <span class="t">for experimenting we're going to pass in some size we'll say what vocab size we want for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1209" target="_blank">00:20:09.640</a></span> | <span class="t">our subword tokenizer we'll set it up with our texts and then we will have a look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1215" target="_blank">00:20:15.640</a></span> | <span class="t">a particular sentence so for example if we create a subword tokenizer with a thousand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1221" target="_blank">00:20:21.600</a></span> | <span class="t">tokens and it returns this this tokenized string now this kind of long underscore thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1232" target="_blank">00:20:32.680</a></span> | <span class="t">is what we replace space with because now we're using subword tokens we kind of want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1236" target="_blank">00:20:36.880</a></span> | <span class="t">to know where the sentence is actually start and stop and you can see here a lot of sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1242" target="_blank">00:20:42.600</a></span> | <span class="t">words are common enough sequences of letters that they get their own vocab item or else</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1249" target="_blank">00:20:49.520</a></span> | <span class="t">discovered it was not wasn't common enough so that became this over it right video appears</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1258" target="_blank">00:20:58.880</a></span> | <span class="t">enough where a store didn't that becomes or so you get the idea right so if we wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1265" target="_blank">00:21:05.660</a></span> | <span class="t">a smaller vocab size that would as you see even this doesn't become its own word movie</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1273" target="_blank">00:21:13.520</a></span> | <span class="t">is so common that it is its own word so it just becomes to for example we have a question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1283" target="_blank">00:21:23.280</a></span> | <span class="t">okay how can we determine if the given pre-trained model in this case wiki text 103 is suitable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1291" target="_blank">00:21:31.700</a></span> | <span class="t">enough for our downstream task if we have limited vocab overlap should we need to add</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1296" target="_blank">00:21:36.920</a></span> | <span class="t">an additional data set to create a language model from scratch if it's in the same language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1305" target="_blank">00:21:45.520</a></span> | <span class="t">so if you're doing English it's always it's almost always sufficient to use Wikipedia</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1312" target="_blank">00:21:52.060</a></span> | <span class="t">we've played around with this a lot and it was one of the key things that Sebastian Ruder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1315" target="_blank">00:21:55.320</a></span> | <span class="t">and I found when we created the ULM fit paper was before that time people really thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1321" target="_blank">00:22:01.160</a></span> | <span class="t">you needed corpus specific pre-trained models but we discovered you don't just like you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1327" target="_blank">00:22:07.440</a></span> | <span class="t">don't that often need corpus specific pre-trained vision models image network surprisingly well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1334" target="_blank">00:22:14.800</a></span> | <span class="t">across a lot of different domains so Wikipedia has a lot of words in it it would be really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1345" target="_blank">00:22:25.360</a></span> | <span class="t">really I haven't come across an English corpus that didn't have a very high level of overlap</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1351" target="_blank">00:22:31.040</a></span> | <span class="t">with Wikipedia on the other hand if you're doing ULM fit with like genomic sequences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1357" target="_blank">00:22:37.920</a></span> | <span class="t">or Greek or whatever then obviously you're going to need a different pre-trained model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1366" target="_blank">00:22:46.000</a></span> | <span class="t">so once we got to a 10,000 word vocab as you can see basically every word at least common</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1371" target="_blank">00:22:51.120</a></span> | <span class="t">word becomes its own vocab item in the subword vocab except say discovered which becomes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1379" target="_blank">00:22:59.000</a></span> | <span class="t">discover it so my guess is that subword approaches are going to become kind of the most common</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1388" target="_blank">00:23:08.200</a></span> | <span class="t">maybe they will be by the time you watch this we've got some fiddling to do to get this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1394" target="_blank">00:23:14.560</a></span> | <span class="t">working super well for fine-tuning but I think I know what we have to do so hopefully we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1401" target="_blank">00:23:21.200</a></span> | <span class="t">get it done pretty soon all right so after we split it into tokens the next thing to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1409" target="_blank">00:23:29.880</a></span> | <span class="t">do is numerical ization so let's go back to our word tokenized text which looks like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1419" target="_blank">00:23:39.400</a></span> | <span class="t">and in order to mean numerical eyes we will first need to call setup so to save a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1429" target="_blank">00:23:49.200</a></span> | <span class="t">of time let's create a subset of our text so just create a couple of hundred of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1433" target="_blank">00:23:53.240</a></span> | <span class="t">co-opuses that's a couple of hundred of the reviews so here's an example of one and we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1438" target="_blank">00:23:58.760</a></span> | <span class="t">create our new miracle eyes object and we will call setup and that's the thing that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1442" target="_blank">00:24:02.860</a></span> | <span class="t">going to create the vocab for us and so after that we can now take a look at the vocab this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1448" target="_blank">00:24:08.160</a></span> | <span class="t">is Cole repra is showing us a representation of a collection it's what the L class uses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1454" target="_blank">00:24:14.960</a></span> | <span class="t">underneath and you can see when we do this that the vocab starts with the special tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1465" target="_blank">00:24:25.000</a></span> | <span class="t">and then we start getting the English tokens in order of frequency so the default is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1473" target="_blank">00:24:33.920</a></span> | <span class="t">vocab size of 60,000 so that'll be the size of your embedding matrix by default and if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1480" target="_blank">00:24:40.560</a></span> | <span class="t">there are more than 60,000 unique words in your vocab in your corpus then any the least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1489" target="_blank">00:24:49.240</a></span> | <span class="t">common ones will be replaced with a special XXunk unknown token so that'll help us avoid</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1495" target="_blank">00:24:55.900</a></span> | <span class="t">having a too big embedding matrix all right so now we can treat the numerical eyes object</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1503" target="_blank">00:25:03.960</a></span> | <span class="t">which we created as if it was a function as we so often do in both fastai and pytorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1509" target="_blank">00:25:09.200</a></span> | <span class="t">and when we do it'll replace each of our words with others so two for example is 0 1 2 beginning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1519" target="_blank">00:25:19.240</a></span> | <span class="t">a string beginning a beginning of stream 8 0 1 2 3 4 5 6 7 8 okay so a capitalized letter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1528" target="_blank">00:25:28.680</a></span> | <span class="t">there they are XXbos XXmaj etc okay and then we can convert them back by indexing into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1537" target="_blank">00:25:37.360</a></span> | <span class="t">the vocab and get back what we started with okay right so now we have done the tokenization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1549" target="_blank">00:25:49.920</a></span> | <span class="t">we've done the numericalization and so the next thing we need to do is to create batches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1556" target="_blank">00:25:56.480</a></span> | <span class="t">so let's say this is the text that we want to create batches from and so if we tokenize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1564" target="_blank">00:26:04.400</a></span> | <span class="t">that text it'll convert it into this and so let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1576" target="_blank">00:26:16.640</a></span> | <span class="t">let's take that and write it out here let's do it here let's take that and write it out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1586" target="_blank">00:26:26.680</a></span> | <span class="t">here so XXbos XXmaj in this chapter XXbos XXmaj in this chapter we will go back over the example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1595" target="_blank">00:26:35.760</a></span> | <span class="t">of classifying and then next row starts here movie reviews we studied in chapter one and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1602" target="_blank">00:26:42.040</a></span> | <span class="t">dig deeper under the surface full stop XXmaj first we will look at the etc okay so we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1608" target="_blank">00:26:48.040</a></span> | <span class="t">taken these 90 tokens and to create a batch size of six we've broken up the text into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1616" target="_blank">00:26:56.600</a></span> | <span class="t">six contiguous parts each of length 15 so 1 2 3 4 5 6 and then we have 15 columns okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1626" target="_blank">00:27:06.640</a></span> | <span class="t">so 6 by 15 now ideally we would just provide that to our model as a batch and if indeed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1637" target="_blank">00:27:17.280</a></span> | <span class="t">that was all the data we had we could just pass it in as a batch but that's not going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1645" target="_blank">00:27:25.840</a></span> | <span class="t">to work for imdb because imdb once we concatenate all the reviews together and then let's say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1652" target="_blank">00:27:32.600</a></span> | <span class="t">we want to use a batch size of 64 then we're going to have 64 rows and you know probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1662" target="_blank">00:27:42.920</a></span> | <span class="t">there's a few million tokens of imdb so a few million divided by 64 across it's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1669" target="_blank">00:27:49.280</a></span> | <span class="t">to be way too big and to fit in our GPU so what we're going to do then is we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1677" target="_blank">00:27:57.320</a></span> | <span class="t">to split up that big wide array and we're going to split it up horizontally so we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1684" target="_blank">00:28:04.880</a></span> | <span class="t">start with XXbos XXmaj in this chapter and then down here we will go back over the example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1692" target="_blank">00:28:12.120</a></span> | <span class="t">of classifying movie reviews we studied in chapter one and dig deeper under the surface</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1698" target="_blank">00:28:18.600</a></span> | <span class="t">etc so this would become our first mini-batch right and so you can see what's happened is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1708" target="_blank">00:28:28.640</a></span> | <span class="t">the kind of second row right actually is continuing what was like way down here and so we basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1719" target="_blank">00:28:39.540</a></span> | <span class="t">treated each row is totally independent so when we predict the second from the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1725" target="_blank">00:28:45.600</a></span> | <span class="t">mini-batch you know the second mini-batch is going to follow from the first and that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1730" target="_blank">00:28:50.080</a></span> | <span class="t">each row to row one in the second mini-batch will join up to row one of the first row two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1736" target="_blank">00:28:56.320</a></span> | <span class="t">of the second mini-batch will join up to row two of the first so please look at this example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1741" target="_blank">00:29:01.800</a></span> | <span class="t">super carefully because we found that this is something that every year a lot of students</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1748" target="_blank">00:29:08.040</a></span> | <span class="t">get confused about because it's just not what they expected to see happen right so go back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1754" target="_blank">00:29:14.400</a></span> | <span class="t">over this and make sure you understand what's happening in this little example so that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1760" target="_blank">00:29:20.160</a></span> | <span class="t">what our mini batches are going to be so the good news is that all these fiddly steps you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1766" target="_blank">00:29:26.760</a></span> | <span class="t">don't have to do yourself you can just use the language model data loader or LM data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1772" target="_blank">00:29:32.320</a></span> | <span class="t">loader so if we take those all the tokens from the first 200 movie reviews and map them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1778" target="_blank">00:29:38.160</a></span> | <span class="t">through our numericalize object right so now we've got numericalized versions of all those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1782" target="_blank">00:29:42.720</a></span> | <span class="t">tokens and then pass them into LM data loader and then grab the first item from the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1789" target="_blank">00:29:49.860</a></span> | <span class="t">loader then we have 64 by 72 why is that well 64 is the default batch size and 72 is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1802" target="_blank">00:30:02.440</a></span> | <span class="t">default sequence length you see here we've got one two three four five here we used a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1808" target="_blank">00:30:08.080</a></span> | <span class="t">sequence length of five right so what we do in practice is we use a default sequence length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1815" target="_blank">00:30:15.080</a></span> | <span class="t">of 72 so if we grab the first of our independent variables and grab the first few tokens and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1824" target="_blank">00:30:24.400</a></span> | <span class="t">look them up in the vocab here it is this movie which I just something at the video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1829" target="_blank">00:30:29.160</a></span> | <span class="t">store so that's interesting so this was not common enough to be in a vocab has apparently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1834" target="_blank">00:30:34.080</a></span> | <span class="t">sit around for a and then if we look at the exact same thing but for the dependent variable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1840" target="_blank">00:30:40.960</a></span> | <span class="t">rather than being XXBOS XXMaj this movie it's XXMaj this movie so you can see it's offset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1847" target="_blank">00:30:47.160</a></span> | <span class="t">by one which means the end rather than being around for a it's for a couple so this is exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1855" target="_blank">00:30:55.280</a></span> | <span class="t">what we want this is offset by one from here so that's looking good so we can now go ahead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1870" target="_blank">00:31:10.160</a></span> | <span class="t">and use these ideas to try and build our even better IMDB sentiment analysis and the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1876" target="_blank">00:31:16.360</a></span> | <span class="t">step will be to as we discussed create the language model but let's just go ahead and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1881" target="_blank">00:31:21.300</a></span> | <span class="t">use the fast AI built-in stuff to do it for us rather than doing all that messing around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1886" target="_blank">00:31:26.520</a></span> | <span class="t">manually so we can just create a data block and our blocks are it's going to be a text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1892" target="_blank">00:31:32.720</a></span> | <span class="t">block from folder and the items are going to be text files from these folders and we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1906" target="_blank">00:31:46.400</a></span> | <span class="t">going to split things randomly and then going to turn that into data loaders with a batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1912" target="_blank">00:31:52.280</a></span> | <span class="t">size of 128 and a sequence length of 80 in this case our blocks we're not just passing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1921" target="_blank">00:32:01.280</a></span> | <span class="t">in a class directly but we're actually passing in here a class method and that's so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1930" target="_blank">00:32:10.600</a></span> | <span class="t">we can allow the tokenization for example to be saved to be cached in some path so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1939" target="_blank">00:32:19.000</a></span> | <span class="t">the next time we run this it won't have to do it all from scratch so that's why we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1944" target="_blank">00:32:24.440</a></span> | <span class="t">a slightly different syntax here so once we've run this we can call show batch and so you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1953" target="_blank">00:32:33.560</a></span> | <span class="t">can see here we've got for example what xxmaj I've read xxmaj death blah blah blah and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1964" target="_blank">00:32:44.000</a></span> | <span class="t">can see so that's the independent variable and so the dependent variable is the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1968" target="_blank">00:32:48.000</a></span> | <span class="t">thing offset by one so we don't have the what anymore but it just goes straight to xxmaj</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1972" target="_blank">00:32:52.880</a></span> | <span class="t">I've read and then at the end this was also this and of course in the dependent variable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1977" target="_blank">00:32:57.680</a></span> | <span class="t">also this is so this is that offset by one just like we were hoping for show batch is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1983" target="_blank">00:33:03.720</a></span> | <span class="t">automatically denumericalizing it for us turning it back into strings but if we look at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1990" target="_blank">00:33:10.400</a></span> | <span class="t">actual or you should look at the actual x and y to confirm that you actually see numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=1996" target="_blank">00:33:16.720</a></span> | <span class="t">there that'll be a good exercise for you is to make sure that you can actually grab a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2000" target="_blank">00:33:20.680</a></span> | <span class="t">mini batch from dlslm so now that we've got the data loaders we can fine-tune our language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2010" target="_blank">00:33:30.400</a></span> | <span class="t">model so fine-tuning the language model means we're going to create a learner which is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2015" target="_blank">00:33:35.060</a></span> | <span class="t">to learn to predict the next word of a movie review so that's our data the data loaders</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2021" target="_blank">00:33:41.700</a></span> | <span class="t">for the language model this is the pre-trained model it's something called awd lstm which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2027" target="_blank">00:33:47.160</a></span> | <span class="t">we'll see how to create from scratch in a moment or something similar to it dropout</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2034" target="_blank">00:33:54.080</a></span> | <span class="t">we'll learn about later that we see how much dropout to use this is how much regularization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2037" target="_blank">00:33:57.680</a></span> | <span class="t">we want and what metrics do we want we've know about accuracy perplexity is not particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2043" target="_blank">00:34:03.760</a></span> | <span class="t">interesting so I won't discuss it but feel free to look it up if you're interested and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2047" target="_blank">00:34:07.640</a></span> | <span class="t">let's train with fp16 to use less memory on the GPU and for any modern GPU it'll also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2055" target="_blank">00:34:15.560</a></span> | <span class="t">run two or three times faster so this gray bit here has been done for us the pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2063" target="_blank">00:34:23.200</a></span> | <span class="t">of the language model for wiki text 103 and now we're up to this bit which is fine-tuning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2068" target="_blank">00:34:28.760</a></span> | <span class="t">the language model for imdb so let's do one epoch and as per usual the using a pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2079" target="_blank">00:34:39.520</a></span> | <span class="t">model automatically calls freeze so we don't have to freeze so this is going to just actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2086" target="_blank">00:34:46.400</a></span> | <span class="t">train only the new embeddings initially and we get an accuracy after a ten minutes or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2093" target="_blank">00:34:53.120</a></span> | <span class="t">so of 30% so that's pretty cool so about a bit under a third of the time our model is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2099" target="_blank">00:34:59.680</a></span> | <span class="t">predicting the next word of a string so I think that's pretty cool now since this takes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2109" target="_blank">00:35:09.720</a></span> | <span class="t">quite a while for each epoch we might as well save it and you can save it under any name</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2117" target="_blank">00:35:17.760</a></span> | <span class="t">you want and that's going to put it into your path into your learner's path into a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2121" target="_blank">00:35:21.720</a></span> | <span class="t">subfolder and it'll give it a .pth extension for PyTorch and then later on you can load</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2128" target="_blank">00:35:28.160</a></span> | <span class="t">that with learn.load after you create the learner and so then we can unfreeze and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2136" target="_blank">00:35:36.280</a></span> | <span class="t">can train a few more epochs and we eventually get up to an accuracy of 34% so that's pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2142" target="_blank">00:35:42.960</a></span> | <span class="t">great so once we've done all that we can save the model but actually all we really need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2151" target="_blank">00:35:51.480</a></span> | <span class="t">to do is to save the encoder what's the encoder the encoder is all of the model except for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2159" target="_blank">00:35:59.280</a></span> | <span class="t">the final layer oh and we're getting a thunderstorm here that could be interesting we've never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2163" target="_blank">00:36:03.880</a></span> | <span class="t">done a lesson with a thunderstorm before but that's the joy of teaching during COVID-19</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2170" target="_blank">00:36:10.920</a></span> | <span class="t">you get all the sound effects so yeah the final layer of our language model is predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2181" target="_blank">00:36:21.040</a></span> | <span class="t">is the bit that actually picks a particular word out which we don't need so when we say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2186" target="_blank">00:36:26.320</a></span> | <span class="t">save encoder it saves everything except for that final layer and that's the pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2191" target="_blank">00:36:31.240</a></span> | <span class="t">model we're going to use that is a pre-trained model of a language model that is fine-tuned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2197" target="_blank">00:36:37.800</a></span> | <span class="t">from Wikipedia fine-tuned using IMDB and doesn't contain the very last layer Rachel any questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2205" target="_blank">00:36:45.880</a></span> | <span class="t">at this point do any language models attempt to provide meaning for instance I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2213" target="_blank">00:36:53.160</a></span> | <span class="t">to the store is the opposite of I'm not going to the store or I barely understand this stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2219" target="_blank">00:36:59.600</a></span> | <span class="t">and that ball came so close to my ear I heard it whistle both contain the idea of something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2224" target="_blank">00:37:04.640</a></span> | <span class="t">almost happening being right on the border is there a way to indicate this kind of subtlety</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2229" target="_blank">00:37:09.280</a></span> | <span class="t">in a language model yeah absolutely our language model will have all of that in it or hopefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2239" target="_blank">00:37:19.360</a></span> | <span class="t">it will hopefully it'll learn about it we don't have to program that the whole point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2242" target="_blank">00:37:22.760</a></span> | <span class="t">of machine learning is it learns it for itself but when it sees a sentence like hey careful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2250" target="_blank">00:37:30.400</a></span> | <span class="t">that ball nearly hit me the expectation of what word is going to be happen next is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2257" target="_blank">00:37:37.080</a></span> | <span class="t">to be different to the sentence hey that ball hit me so so yeah language models generally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2264" target="_blank">00:37:44.860</a></span> | <span class="t">you see in practice tend to get really good at understanding all of these nuances of of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2271" target="_blank">00:37:51.880</a></span> | <span class="t">of English or whatever language it's learning about okay so we have a fine-tuned language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2277" target="_blank">00:37:57.760</a></span> | <span class="t">model so the next thing we're going to do is we're going to try fine-tuning a classifier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2282" target="_blank">00:38:02.760</a></span> | <span class="t">but before we do just for fun let's look at text generation we can create write ourselves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2289" target="_blank">00:38:09.680</a></span> | <span class="t">some words like I liked this movie because and then we can create say two sentences each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2297" target="_blank">00:38:17.080</a></span> | <span class="t">containing say 40 words and so we can just go through those two sentences and call learn.predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2304" target="_blank">00:38:24.440</a></span> | <span class="t">passing in this text and asking to predict this number of words with this amount of kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2311" target="_blank">00:38:31.040</a></span> | <span class="t">of randomization and see what it comes up with I liked this movie because of its story</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2318" target="_blank">00:38:38.520</a></span> | <span class="t">and characters the storyline was very strong very good for a sci-fi the main character</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2322" target="_blank">00:38:42.520</a></span> | <span class="t">alucard was very well developed and brought the whole story but second attempt I like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2328" target="_blank">00:38:48.120</a></span> | <span class="t">this movie because I like the idea of the premise of the movie the very convenient virus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2333" target="_blank">00:38:53.020</a></span> | <span class="t">which well when you have to kill a few people the evil machine has to be used to protect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2337" target="_blank">00:38:57.020</a></span> | <span class="t">blah blah blah so as you can see it's done a good job of inventing language there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2344" target="_blank">00:39:04.440</a></span> | <span class="t">much I shouldn't say more sophisticated there are there are more careful ways to do a generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2351" target="_blank">00:39:11.320</a></span> | <span class="t">from a language model this learn.predict uses the most kind of basic possible one but even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2357" target="_blank">00:39:17.280</a></span> | <span class="t">with a very simple approach you can see we can get from a fine-chin model some pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2362" target="_blank">00:39:22.020</a></span> | <span class="t">authentic looking text and so in practice this is really interesting because we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2369" target="_blank">00:39:29.360</a></span> | <span class="t">now you know by using the prompt you can kind of get it to generate you know appropriate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2377" target="_blank">00:39:37.800</a></span> | <span class="t">context appropriate text particularly if you fine-tune from a particular corpus anyway</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2386" target="_blank">00:39:46.360</a></span> | <span class="t">that was really just a little demonstration of something we accidentally created on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2390" target="_blank">00:39:50.160</a></span> | <span class="t">way of course the whole purpose of this is actually just to be a pre-trained model for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2393" target="_blank">00:39:53.960</a></span> | <span class="t">classification so to do that we're going to need to create another data block and this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2399" target="_blank">00:39:59.880</a></span> | <span class="t">time we've got two blocks not one we've got a text block again just like before but this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2404" target="_blank">00:40:04.460</a></span> | <span class="t">time we're going to ask fastai not to create a vocab from the unique words but using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2411" target="_blank">00:40:11.560</a></span> | <span class="t">vocab that we already have from the language model because otherwise obviously there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2416" target="_blank">00:40:16.200</a></span> | <span class="t">no point reusing a pre-trained model if the vocab is different the numbers would mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2420" target="_blank">00:40:20.920</a></span> | <span class="t">totally different things so that's the independent variable and the dependent variable just like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2426" target="_blank">00:40:26.920</a></span> | <span class="t">we've used before is a category so a category block is for that as we've used many times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2431" target="_blank">00:40:31.700</a></span> | <span class="t">we're going to use parent label to create our dependent variable that's a function get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2437" target="_blank">00:40:37.600</a></span> | <span class="t">items we'll use get text files just like before and we'll split using grandparent splitter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2443" target="_blank">00:40:43.160</a></span> | <span class="t">as we've used before in provision so this has been used for vision this has been used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2448" target="_blank">00:40:48.600</a></span> | <span class="t">for vision and then we'll create our data loaders with a batch size of 128 a sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2453" target="_blank">00:40:53.200</a></span> | <span class="t">length of 72 and now show batch we can see an example of subset of a movie review and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2462" target="_blank">00:41:02.440</a></span> | <span class="t">a category yes question do the tokenizers use any tokenization techniques like stemming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2472" target="_blank">00:41:12.800</a></span> | <span class="t">or lemmatization or is that an outdated approach that would not be a tokenization approach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2481" target="_blank">00:41:21.020</a></span> | <span class="t">so stemming is something that actually removes the stem and we absolutely don't want to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2487" target="_blank">00:41:27.040</a></span> | <span class="t">that that is certainly an outdated approach the in English we have stems for a reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2495" target="_blank">00:41:35.120</a></span> | <span class="t">they tell us something so we we don't like to remove anything that can give us some kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2501" target="_blank">00:41:41.560</a></span> | <span class="t">of information we used to use that for kind of pre deep learning and LP quite a bit because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2508" target="_blank">00:41:48.160</a></span> | <span class="t">that we didn't really have good ways like embedding matrices of handling you know big</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2513" target="_blank">00:41:53.640</a></span> | <span class="t">vocabs that just differed in the you know kind of the end of a word but nowadays we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2521" target="_blank">00:42:01.000</a></span> | <span class="t">definitely don't want to do that oh yeah one other difference here is previously we had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2530" target="_blank">00:42:10.200</a></span> | <span class="t">an is LM equals true when we said text block dot folder from folder to say it was a language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2535" target="_blank">00:42:15.080</a></span> | <span class="t">model we don't have that anymore because it's not a language model okay now one thing with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2544" target="_blank">00:42:24.760</a></span> | <span class="t">a language model that was a bit easier was that we could concatenate all the documents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2548" target="_blank">00:42:28.880</a></span> | <span class="t">together and then we could split them by batch size to create we're not split them by batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2555" target="_blank">00:42:35.960</a></span> | <span class="t">size put them into a number of substrings based on the batch size and that way we could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2561" target="_blank">00:42:41.480</a></span> | <span class="t">ensure that every many batch was the same size it would be batch size by sequence length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2570" target="_blank">00:42:50.200</a></span> | <span class="t">but for classification we can't do that we actually need each dependent variable label</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2577" target="_blank">00:42:57.280</a></span> | <span class="t">to be associated with each complete movie review and we're not showing the whole movie</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2583" target="_blank">00:43:03.480</a></span> | <span class="t">review here we've truncated it just for display purposes but we're going to use the whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2586" target="_blank">00:43:06.760</a></span> | <span class="t">movie review to make our prediction now the problem is that if we're using a batch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2594" target="_blank">00:43:14.440</a></span> | <span class="t">of 128 then and our movie reviews are often like 3,000 words long we could end up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2602" target="_blank">00:43:22.280</a></span> | <span class="t">something that's way too big to fit into the GPU memory so how are we going to deal with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2608" target="_blank">00:43:28.640</a></span> | <span class="t">that well again we're going we can we can split them up so first of all let's grab a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2617" target="_blank">00:43:37.440</a></span> | <span class="t">few of the movie reviews just to a demo here and numericalize them and if we have a look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2622" target="_blank">00:43:42.680</a></span> | <span class="t">at the length so map the length over each you can see that they do vary a lot in length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2630" target="_blank">00:43:50.760</a></span> | <span class="t">now we can we can split them into sequences and indeed we have asked to do that sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2636" target="_blank">00:43:56.080</a></span> | <span class="t">length 72 but when we do so we're you know we don't even have the same number of sub-sequences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2642" target="_blank">00:44:02.640</a></span> | <span class="t">when we split each of these into 72 long sections they're going to be all different lengths</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2651" target="_blank">00:44:11.080</a></span> | <span class="t">so how do we deal with that well just like in vision we can handle different sized sequences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2657" target="_blank">00:44:17.880</a></span> | <span class="t">by adding padding so we're going to add a special XX pad token to every sequence in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2668" target="_blank">00:44:28.680</a></span> | <span class="t">a mini batch so like in this case it looks like 581 is the longest so we would add enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2673" target="_blank">00:44:33.360</a></span> | <span class="t">padding tokens to make this 581 and this 581 and this 581 and so forth and then we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2679" target="_blank">00:44:39.760</a></span> | <span class="t">split them into sequence length into 72 long and it's in the mini batches and we'll be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2686" target="_blank">00:44:46.280</a></span> | <span class="t">right to go now obviously if your lengths are very different like this adding a whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2692" target="_blank">00:44:52.420</a></span> | <span class="t">lot of padding is going to be super wasteful so another thing that fastai does internally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2696" target="_blank">00:44:56.920</a></span> | <span class="t">is it tries to shuffle the documents around so that similar length documents are in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2703" target="_blank">00:45:03.160</a></span> | <span class="t">same mini batch it also randomizes them but it kind of approximately sorts them so it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2709" target="_blank">00:45:09.360</a></span> | <span class="t">wastes a lot less time on padding okay so that is how that is what happens when we we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2719" target="_blank">00:45:19.240</a></span> | <span class="t">don't have to do any of that manually when we call text block from folder without the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2725" target="_blank">00:45:25.760</a></span> | <span class="t">is LM it does that all that for us and then we can now go ahead and create a learner this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2733" target="_blank">00:45:33.920</a></span> | <span class="t">time it's going to be a text classifier learner again we're going to base it off L a WD LSTM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2740" target="_blank">00:45:40.640</a></span> | <span class="t">pass in the data loaders we just created for metric we'll just use accuracy make it FP16</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2746" target="_blank">00:45:46.360</a></span> | <span class="t">again and now we don't want to use a pre-trained Wikipedia model in fact there is no pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2752" target="_blank">00:45:52.480</a></span> | <span class="t">Wikipedia classifier because you know what you classify matters a lot so instead we load</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2760" target="_blank">00:46:00.000</a></span> | <span class="t">the encoder so remember everything except the last layer which we saved just before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2765" target="_blank">00:46:05.640</a></span> | <span class="t">so we're going to load as a pre-trained model a language model for predicting the next word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2771" target="_blank">00:46:11.720</a></span> | <span class="t">of a movie review so let's go ahead and hit one cycle and again by default it will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2783" target="_blank">00:46:23.040</a></span> | <span class="t">frozen so it's only the final layer which is the randomly added classifier layer that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2788" target="_blank">00:46:28.680</a></span> | <span class="t">going to be trained it took 30 seconds and look at this we already have 93% so that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2794" target="_blank">00:46:34.720</a></span> | <span class="t">pretty similar to what we got back in lesson one but rather than taking about 12 minutes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2802" target="_blank">00:46:42.680</a></span> | <span class="t">once all the pre-training's been done it takes about 30 seconds this is quite cool you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2807" target="_blank">00:46:47.120</a></span> | <span class="t">create a language model for your kind of general area of interest and then you can create all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2814" target="_blank">00:46:54.400</a></span> | <span class="t">kinds of different classifiers pretty quickly and so that's just with that's just looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2820" target="_blank">00:47:00.680</a></span> | <span class="t">at the pre fine-tuning the final randomly added layer so now we could just unfreeze</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2829" target="_blank">00:47:09.920</a></span> | <span class="t">and keep learning but something we found is for NLP it's actually better to only unfreeze</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2838" target="_blank">00:47:18.280</a></span> | <span class="t">one layer at a time not to unfreeze the whole model so we've in this case we've automatically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2843" target="_blank">00:47:23.400</a></span> | <span class="t">unfreeze in the last layer and so then to unfreeze the last couple of layer groups we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2848" target="_blank">00:47:28.680</a></span> | <span class="t">can say freeze two minus two and then train a little bit more and look at this we're already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2854" target="_blank">00:47:34.880</a></span> | <span class="t">beating after a bit over a minute easily beating what we got in lesson one and then freeze</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2863" target="_blank">00:47:43.000</a></span> | <span class="t">two minus three to unfreeze another few layers now we're up to 94 and then finally unfreeze</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2868" target="_blank">00:47:48.840</a></span> | <span class="t">the whole model and we're up to about 94.3% accuracy and that was literally the state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2876" target="_blank">00:47:56.640</a></span> | <span class="t">of the art for this very heavily studied data set just three years ago if you also reverse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2884" target="_blank">00:48:04.680</a></span> | <span class="t">all of the reviews to make them go backwards and train a second model on the backwards</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2889" target="_blank">00:48:09.360</a></span> | <span class="t">version and then average the predictions of those two models as an ensemble you get to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2894" target="_blank">00:48:14.320</a></span> | <span class="t">95.1% accuracy and that was the state of the art that we actually got in the ULM fit paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2900" target="_blank">00:48:20.480</a></span> | <span class="t">and it was only beaten for the first time a few months ago using a way way bigger model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2906" target="_blank">00:48:26.120</a></span> | <span class="t">way more data way more compute and way more data augmentation I should mention actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2914" target="_blank">00:48:34.120</a></span> | <span class="t">with the data augmentation one of the cool things they did do was they actually figured</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2917" target="_blank">00:48:37.480</a></span> | <span class="t">out also a way to even beat our 95.1 with less data as well so I should mention that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2922" target="_blank">00:48:42.880</a></span> | <span class="t">actually the data augmentation has become a really since we created the ULM fit paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2927" target="_blank">00:48:47.840</a></span> | <span class="t">has become a really really important approach any questions Rachel can someone explain how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2936" target="_blank">00:48:56.400</a></span> | <span class="t">a model trained to predict the last word in the sentence can generalize to classify sentiment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2941" target="_blank">00:49:01.760</a></span> | <span class="t">they seem like different domains yeah that's a great question they're very different domains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2947" target="_blank">00:49:07.640</a></span> | <span class="t">and it's it's really amazing and basically the trick is that to be able to predict the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2954" target="_blank">00:49:14.440</a></span> | <span class="t">next word of a sentence you just have to know a lot of stuff about not only the language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2959" target="_blank">00:49:19.640</a></span> | <span class="t">but about the world so if you know let's say we wanted to finish the next word of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2967" target="_blank">00:49:27.080</a></span> | <span class="t">sentence by training a model on all the text read backwards and averaging the averaging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2971" target="_blank">00:49:31.160</a></span> | <span class="t">the predictions of these two models we can even get to 95.1% accuracy which was the state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2975" target="_blank">00:49:35.980</a></span> | <span class="t">of the art introduced by the what so to be able to fill in the word ULM fit you would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2982" target="_blank">00:49:42.720</a></span> | <span class="t">have to know a whole lot of stuff about you know the fact that there's a thing called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2987" target="_blank">00:49:47.640</a></span> | <span class="t">fine-tune you know pre-trained language models and which one gets which results and the ULM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2993" target="_blank">00:49:53.480</a></span> | <span class="t">fit got this particular result I mean that would be an amazing language model that could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=2997" target="_blank">00:49:57.600</a></span> | <span class="t">fill that in correctly I'm not sure that any language models can but to give you a sense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3002" target="_blank">00:50:02.360</a></span> | <span class="t">of like what you have to be able to do to be good at language modeling so if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3008" target="_blank">00:50:08.760</a></span> | <span class="t">going to be able to predict the next word of a sentence like wow I really love this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3015" target="_blank">00:50:15.320</a></span> | <span class="t">movie I love every movie containing Meg Watt right maybe it's Ryan you'd have to know about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3023" target="_blank">00:50:23.780</a></span> | <span class="t">like the fact that Meg Ryan is an actress and actresses are in movies and so forth so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3029" target="_blank">00:50:29.120</a></span> | <span class="t">when you know so much about English and about the world to then turn that into something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3035" target="_blank">00:50:35.480</a></span> | <span class="t">which recognizes that I really love this movie is a good thing rather than a bad thing is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3042" target="_blank">00:50:42.400</a></span> | <span class="t">just not a very big step and as we saw you can actually get that far using just pre fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3050" target="_blank">00:50:50.160</a></span> | <span class="t">tuning just the very last layer or two so it is it's amazing and I think that's super</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3058" target="_blank">00:50:58.400</a></span> | <span class="t">super cool all right another question how would you do data augmentation on text well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3072" target="_blank">00:51:12.520</a></span> | <span class="t">you would probably Google for unsupervised data augmentation and read this paper and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3077" target="_blank">00:51:17.000</a></span> | <span class="t">things that have cited it so this is the one that easily beat our IMDB result with only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3084" target="_blank">00:51:24.720</a></span> | <span class="t">20 labeled examples which is amazing right and so they did things like if I remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3093" target="_blank">00:51:33.080</a></span> | <span class="t">correctly translate every sentence into a different language and then translate it back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3099" target="_blank">00:51:39.080</a></span> | <span class="t">again so you kind of get like different rewordings of the sentence that way yeah so kind of tricks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3106" target="_blank">00:51:46.160</a></span> | <span class="t">like that now let's go back to the generation thing so remember we saw that we can generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3125" target="_blank">00:52:05.080</a></span> | <span class="t">context appropriate sentences and it's important to think about what that means in practice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3130" target="_blank">00:52:10.640</a></span> | <span class="t">when you can generate context appropriate sentences have a look for example at even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3135" target="_blank">00:52:15.000</a></span> | <span class="t">before this technology existed in 2017 the FCC asked for comments about a proposal to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3144" target="_blank">00:52:24.120</a></span> | <span class="t">repeal net neutrality and it turned out that less than 800,000 of the 22 million comments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3156" target="_blank">00:52:36.880</a></span> | <span class="t">actually appeared to be unique and this particular person Jeff Cowell discovered that a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3164" target="_blank">00:52:44.000</a></span> | <span class="t">the submissions were slightly different to each other by kind of like picking up different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3172" target="_blank">00:52:52.000</a></span> | <span class="t">you know the green bit would either be citizens or people like me or Americans and the red</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3177" target="_blank">00:52:57.820</a></span> | <span class="t">bit would be as opposed to or rather than and so forth so like and that made a big difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3185" target="_blank">00:53:05.080</a></span> | <span class="t">to I believe to American policy you know here's an example of reddit conversation you're wrong</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3194" target="_blank">00:53:14.880</a></span> | <span class="t">the defense budget is a good example of how badly the US spends money on the military</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3198" target="_blank">00:53:18.400</a></span> | <span class="t">dot dot dot somebody else yeah but that's already happening there's a huge increase</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3202" target="_blank">00:53:22.220</a></span> | <span class="t">in the military budget I didn't mean to sound like stop paying for the military I'm not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3206" target="_blank">00:53:26.520</a></span> | <span class="t">saying that we cannot pay the bills that are all of these are actually created by a language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3211" target="_blank">00:53:31.760</a></span> | <span class="t">model or GPT - and this is a very concerning thing around disinformation is that never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3219" target="_blank">00:53:39.640</a></span> | <span class="t">mind fake news never mind deep fakes think about like what would happen if somebody invested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3225" target="_blank">00:53:45.240</a></span> | <span class="t">a few million dollars in creating a million Twitter bots and Facebook groups bots and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3232" target="_blank">00:53:52.600</a></span> | <span class="t">Weibo bots and made it so that 99% of the content on social networks were deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3243" target="_blank">00:54:03.200</a></span> | <span class="t">bots and furthermore they were trained not just to optimize the next word of a sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3248" target="_blank">00:54:08.040</a></span> | <span class="t">but were trained to optimize the level of disharmony created or the level of agreeableness</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3257" target="_blank">00:54:17.200</a></span> | <span class="t">for some of the half of them and disagreeableness for the other half of them you know you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3261" target="_blank">00:54:21.120</a></span> | <span class="t">create like a whole lot of you know just awful toxic discussion which is actually the goal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3269" target="_blank">00:54:29.620</a></span> | <span class="t">of a lot of propaganda outfits it's not so much to push a particular point of view but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3275" target="_blank">00:54:35.620</a></span> | <span class="t">to make people feel like there's no point engaging because the truth is too hard to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3281" target="_blank">00:54:41.120</a></span> | <span class="t">understand or whatever so I'm Rachel and I are both super worried about what could happen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3291" target="_blank">00:54:51.560</a></span> | <span class="t">to discourse now that we have this incredibly powerful tool and I'm not even sure we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3297" target="_blank">00:54:57.020</a></span> | <span class="t">we don't have a great sense of what to do about it algorithms are unlikely unlikely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3302" target="_blank">00:55:02.800</a></span> | <span class="t">to save us here if you could create a classifier which could do a good job of figuring out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3308" target="_blank">00:55:08.240</a></span> | <span class="t">whether something was generated by a algorithm or not then I could just use your classifier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3314" target="_blank">00:55:14.120</a></span> | <span class="t">as part of my training loop to train an algorithm that can actually learn to trick your classifier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3320" target="_blank">00:55:20.480</a></span> | <span class="t">so this is a real worry and the only solutions I've seen are those which are kind of based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3326" target="_blank">00:55:26.840</a></span> | <span class="t">on cryptographic signatures which is another whole can of worms which has never really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3334" target="_blank">00:55:34.240</a></span> | <span class="t">been properly sorted out at least not in the Western world in a privacy centric way all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3341" target="_blank">00:55:41.280</a></span> | <span class="t">right so yes I'll add and I'll link to this on the forums I gave a keynote at SciPy conference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3349" target="_blank">00:55:49.800</a></span> | <span class="t">last summer which is the scientific Python conference and went into a lot more detail</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3354" target="_blank">00:55:54.280</a></span> | <span class="t">about the the threat that Jeremy is describing about using advanced language models to manipulate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3360" target="_blank">00:56:00.960</a></span> | <span class="t">public opinion and so if you want to kind of learn more about the dangers there and exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3366" target="_blank">00:56:06.280</a></span> | <span class="t">what that threat is you can find that in my SciPy keynote great thanks so much Rachel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3373" target="_blank">00:56:13.400</a></span> | <span class="t">so let's have a five-minute break and see you back here in five minutes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3384" target="_blank">00:56:24.080</a></span> | <span class="t">so we're going to finish with a kind of a segue into what will eventually be part two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3392" target="_blank">00:56:32.720</a></span> | <span class="t">of the course which is to go right underneath the hood and see exactly how a more complex</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3401" target="_blank">00:56:41.120</a></span> | <span class="t">architecture works and specifically we're going to see how a new recurrent neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3406" target="_blank">00:56:46.640</a></span> | <span class="t">works do we have a question first in the previous lesson MNIST example you showed us that under</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3418" target="_blank">00:56:58.080</a></span> | <span class="t">the hood the model was learning parts of the image like curves of a three or angles of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3422" target="_blank">00:57:02.800</a></span> | <span class="t">a seven is there a way to look under the hood of the language models to see if they are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3427" target="_blank">00:57:07.160</a></span> | <span class="t">learning rules of grammar and syntax would it be a good idea to fine-tune models with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3432" target="_blank">00:57:12.600</a></span> | <span class="t">examples of domain specific syntax like technical manuals or does that miss the point of having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3438" target="_blank">00:57:18.920</a></span> | <span class="t">the model learn for themselves yeah there are tools that allow you to kind of see what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3445" target="_blank">00:57:25.840</a></span> | <span class="t">going on inside an NLP model we're not going to look at them in this part of the course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3450" target="_blank">00:57:30.520</a></span> | <span class="t">maybe we will in part two but certainly worth doing some research to see what you can find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3455" target="_blank">00:57:35.000</a></span> | <span class="t">and there's certainly PyTorch libraries you can download and play with yeah I mean I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3464" target="_blank">00:57:44.280</a></span> | <span class="t">it's a perfectly good idea to incorporate some kind of technical manuals and stuff into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3471" target="_blank">00:57:51.600</a></span> | <span class="t">your training corpus there's actually been some recent papers on this general idea of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3477" target="_blank">00:57:57.320</a></span> | <span class="t">trying to kind of create some carefully curated sentences as part of your training corpus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3485" target="_blank">00:58:05.680</a></span> | <span class="t">it's unlikely to hurt and it could well help all right so let's have a look at RNNs now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3495" target="_blank">00:58:15.880</a></span> | <span class="t">when Sylvain and I started creating the RNN stuff for fast AI the first thing I did actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3505" target="_blank">00:58:25.200</a></span> | <span class="t">was to create a new data set and the reason for that is I didn't find any data sets that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3511" target="_blank">00:58:31.920</a></span> | <span class="t">would allow for quick prototyping and really easy debugging so I made one which we call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3519" target="_blank">00:58:39.400</a></span> | <span class="t">human numbers and it contains the first two ten thousand numbers written out in English</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3527" target="_blank">00:58:47.400</a></span> | <span class="t">and I'm surprised at how few people create data sets I create data sets frequently you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3538" target="_blank">00:58:58.360</a></span> | <span class="t">know I specifically look for things that can be kind of small easy to prototype good for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3543" target="_blank">00:59:03.340</a></span> | <span class="t">debugging and quickly trying things out and very very few people do this even though like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3549" target="_blank">00:59:09.240</a></span> | <span class="t">this human numbers data set which has been so useful for us took me I don't know an hour</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3554" target="_blank">00:59:14.160</a></span> | <span class="t">or two to create so this is definitely an underappreciated underutilized technique so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3566" target="_blank">00:59:26.320</a></span> | <span class="t">we can grab the human numbers data set and we can see that there's a training and a validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3571" target="_blank">00:59:31.260</a></span> | <span class="t">text file we can open each of them and for now we're just going to concatenate the two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3575" target="_blank">00:59:35.920</a></span> | <span class="t">together into a file called lines and you can see that the contents are 1 2 3 etc and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3584" target="_blank">00:59:44.920</a></span> | <span class="t">so there's a new line at the end of each we can concatenate those all together and put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3591" target="_blank">00:59:51.760</a></span> | <span class="t">a full stop between them as so okay and then you could tokenize that by splitting on spaces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3600" target="_blank">01:00:00.080</a></span> | <span class="t">and so for example here's tokens 100 to 110 new number 42 new number 43 new number 44 and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3608" target="_blank">01:00:08.480</a></span> | <span class="t">so forth so you can see I'm just using plain Python here there's not even any PyTorch certainly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3612" target="_blank">01:00:12.760</a></span> | <span class="t">not any fast AI to create a vocab we can just create all the unique tokens of which there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3620" target="_blank">01:00:20.040</a></span> | <span class="t">are 30 and then to create a lookup from so that's a lookup from a word to an ID sorry</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3629" target="_blank">01:00:29.320</a></span> | <span class="t">from an ID to a word to go from a word to an ID we can just enumerate that and create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3636" target="_blank">01:00:36.480</a></span> | <span class="t">a dictionary from word to ID so then we can numerical eyes our tokens by calling word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3647" target="_blank">01:00:47.040</a></span> | <span class="t">to index on each one and so here's our tokens and here's the equivalent numericalized version</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3655" target="_blank">01:00:55.480</a></span> | <span class="t">so you can see in fairly small data sets when we don't have to worry about scale and speed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3663" target="_blank">01:01:03.000</a></span> | <span class="t">and the details of tokenization in English you can do the whole thing in just plain Python</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3671" target="_blank">01:01:11.760</a></span> | <span class="t">the only other thing we use did for to save a little bit of time is use L but you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3676" target="_blank">01:01:16.520</a></span> | <span class="t">easily do that with the Python standard library in about the same amount of code so hopefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3684" target="_blank">01:01:24.400</a></span> | <span class="t">that gives you a good sense of really what's going on with tokenization and numericalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3689" target="_blank">01:01:29.200</a></span> | <span class="t">all done by hand so let's create a language model so one way to create a language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3695" target="_blank">01:01:35.520</a></span> | <span class="t">would be to go through all of our tokens and let's create a range from zero to the length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3701" target="_blank">01:01:41.840</a></span> | <span class="t">of our tokens minus four and every three of them and so that's going to allow us to grab</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3707" target="_blank">01:01:47.360</a></span> | <span class="t">three tokens at a time 1.2.3.4.5.6.7.8 and so forth right so here's the first three tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3721" target="_blank">01:02:01.760</a></span> | <span class="t">and then here's the fourth token and here's the second three tokens and here's the seventh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3727" target="_blank">01:02:07.960</a></span> | <span class="t">token and so forth so these are going to be our independent variables and this will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3733" target="_blank">01:02:13.160</a></span> | <span class="t">our dependent variable so here's a super super kind of naive simple language model data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3743" target="_blank">01:02:23.520</a></span> | <span class="t">for the human numbers question so we can do exactly the same thing as before but use the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3750" target="_blank">01:02:30.920</a></span> | <span class="t">numericalized version and create tensors this is exactly the same thing as before but now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3755" target="_blank">01:02:35.600</a></span> | <span class="t">as as through numericalized and as tensors and we can create a data loaders object from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3765" target="_blank">01:02:45.840</a></span> | <span class="t">data sets and remember these are data sets because they have a length and we can index</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3770" target="_blank">01:02:50.000</a></span> | <span class="t">into them right and so we can just grab the first 80% of the tokens as the training set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3775" target="_blank">01:02:55.800</a></span> | <span class="t">the last 20% is the validation set like so batch size 64 and we're ready to go so we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3784" target="_blank">01:03:04.640</a></span> | <span class="t">really used very very little I mean the only pytorch we used was to create these tensors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3791" target="_blank">01:03:11.360</a></span> | <span class="t">and the only fast AI we used was to create the data loaders and it's just grabbing directly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3796" target="_blank">01:03:16.960</a></span> | <span class="t">from the data sets so it's really not doing anything clever at all so let's see if we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3803" target="_blank">01:03:23.160</a></span> | <span class="t">can now create a neural network architecture which takes three numericalized words at a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3809" target="_blank">01:03:29.320</a></span> | <span class="t">time as import and tries to predict the fourth as dependent variable so here is just such</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3819" target="_blank">01:03:39.040</a></span> | <span class="t">a language model it's a three layer neural network so we've got a linear layer here which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3830" target="_blank">01:03:50.520</a></span> | <span class="t">we're going to use once twice three times and after each of them we call value as per usual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3842" target="_blank">01:04:02.480</a></span> | <span class="t">but there's a little bit more going on the first interesting thing is that rather than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3848" target="_blank">01:04:08.760</a></span> | <span class="t">each of these being a different linear layer we've just created one linear layer here which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3858" target="_blank">01:04:18.720</a></span> | <span class="t">we've reused as you can see one two three times so that's the first thing that's a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3867" target="_blank">01:04:27.080</a></span> | <span class="t">tricky and so there's a few things going on it's a bit a little bit different usual but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3872" target="_blank">01:04:32.480</a></span> | <span class="t">the basic idea is here we've got an embedding and nnlinear another nnlinear and in here we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3878" target="_blank">01:04:38.600</a></span> | <span class="t">used the linear layers and relu so it's very nearly a totally standard three layer neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3885" target="_blank">01:04:45.120</a></span> | <span class="t">network I guess for really because there's an output layer yes we have a question sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3891" target="_blank">01:04:51.440</a></span> | <span class="t">is there a way to speed up fine-tuning the NLP model ten plus minutes per epoch slows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3897" target="_blank">01:04:57.200</a></span> | <span class="t">down the iterative process quite a bit any best practices or tips I can't think of any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3904" target="_blank">01:05:04.760</a></span> | <span class="t">obviously other than to say you don't normally need to fine-tune it that often you know the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3913" target="_blank">01:05:13.400</a></span> | <span class="t">work is often more at the classifier stage so yeah I tend to kind of just leave it running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3920" target="_blank">01:05:20.280</a></span> | <span class="t">overnight or while I have lunch or something like that yeah just don't make sure you make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3924" target="_blank">01:05:24.200</a></span> | <span class="t">sure you don't sit there watching it go and do something else this is where it can be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3931" target="_blank">01:05:31.100</a></span> | <span class="t">quite handy to have a second GPU or fire up a second AWS instance or whatever so you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3937" target="_blank">01:05:37.680</a></span> | <span class="t">kind of keep keep moving while something's training in the background all right so what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3946" target="_blank">01:05:46.960</a></span> | <span class="t">going on here in this model to describe it we're actually going to develop a little kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3952" target="_blank">01:05:52.640</a></span> | <span class="t">of pictorial representation and the pictorial representation is going to work like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3957" target="_blank">01:05:57.560</a></span> | <span class="t">let's start with a simple linear model to define this pictorial representation a simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3964" target="_blank">01:06:04.520</a></span> | <span class="t">linear model has an input of size batch size by number of inputs and so we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3970" target="_blank">01:06:10.960</a></span> | <span class="t">use a rectangle to represent an input we're going to use an arrow to represent a layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3983" target="_blank">01:06:23.240</a></span> | <span class="t">computation so in this case there's going to be a matrix product for a simple linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3986" target="_blank">01:06:26.760</a></span> | <span class="t">model there'd be a matrix actually sorry this is a single hidden layer model there'll be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3992" target="_blank">01:06:32.120</a></span> | <span class="t">a matrix product followed by a value so that's what this arrow represents and out of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=3997" target="_blank">01:06:37.560</a></span> | <span class="t">we're going to get some activations and so circles represent computed activations and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4003" target="_blank">01:06:43.320</a></span> | <span class="t">there would be we call this a hidden layer it'll be a size batch size by number of activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4008" target="_blank">01:06:48.080</a></span> | <span class="t">that's its size and then to create a neural net we're going to do a second matrix product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4013" target="_blank">01:06:53.920</a></span> | <span class="t">and this time a softmax so the computation again represented by the arrow and then output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4019" target="_blank">01:06:59.280</a></span> | <span class="t">activations are a triangle so the output would be batch size by num classes so let me show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4025" target="_blank">01:07:05.760</a></span> | <span class="t">you the pictorial version of this so this is going to be a legend triangle is output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4034" target="_blank">01:07:14.560</a></span> | <span class="t">circle hidden rectangle input and here it is we're going to take the first word as an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4043" target="_blank">01:07:23.440</a></span> | <span class="t">input it's going to go through a linear layer and a value and you'll notice here I've deleted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4051" target="_blank">01:07:31.080</a></span> | <span class="t">the details of what the operations are at this point and I've also deleted the sizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4058" target="_blank">01:07:38.520</a></span> | <span class="t">so every arrow is basically just a linear layer followed by a nonlinearity so we take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4064" target="_blank">01:07:44.120</a></span> | <span class="t">the word one input and we put it through the layer the linear layer and the nonlinearity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4073" target="_blank">01:07:53.840</a></span> | <span class="t">to give us some activations so there's our first set of activations and when we put that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4080" target="_blank">01:08:00.680</a></span> | <span class="t">through another linear layer and nonlinearity to get some more activations and at this point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4087" target="_blank">01:08:07.760</a></span> | <span class="t">we get word two and word two is now goes through a linear layer and a nonlinearity and these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4098" target="_blank">01:08:18.900</a></span> | <span class="t">two when two arrows together come to a circle it means that we add or concatenate either</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4104" target="_blank">01:08:24.360</a></span> | <span class="t">is fine the two sets of activations so we'll add the set of activations from this input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4112" target="_blank">01:08:32.400</a></span> | <span class="t">to the set of activations from here to create a new set of activations and then we'll put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4118" target="_blank">01:08:38.720</a></span> | <span class="t">that through another linear layer and a value and again word three is now going to come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4123" target="_blank">01:08:43.100</a></span> | <span class="t">in and go through a linear layer and a value and they'll get added to create another set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4126" target="_blank">01:08:46.680</a></span> | <span class="t">of activations and then they'll find go through a final linear layer and really and softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4134" target="_blank">01:08:54.600</a></span> | <span class="t">to create our output activations so this is our model it's basically a standard one two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4145" target="_blank">01:09:05.000</a></span> | <span class="t">three four layer model but a couple of interesting things are going on the first is that we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4151" target="_blank">01:09:11.640</a></span> | <span class="t">inputs coming in to later layers and get added so that's something we haven't seen before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4157" target="_blank">01:09:17.240</a></span> | <span class="t">and the second is all of the arrows that are the same color use the same weight matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4162" target="_blank">01:09:22.920</a></span> | <span class="t">so every time we get an input we're going to put it through a particular weight matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4168" target="_blank">01:09:28.000</a></span> | <span class="t">and every time we go from one set of activations to the next we'll put it through a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4172" target="_blank">01:09:32.160</a></span> | <span class="t">weight matrix and then to go through the activations to the output we'll use a different weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4176" target="_blank">01:09:36.960</a></span> | <span class="t">matrix so if we now go back to the code to go from input to hidden not surprisingly we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4185" target="_blank">01:09:45.840</a></span> | <span class="t">always use an embedding so in other words an embedding is the green okay and you'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4192" target="_blank">01:09:52.400</a></span> | <span class="t">see we just create one embedding and here is the first so his x which is the three words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4199" target="_blank">01:09:59.080</a></span> | <span class="t">so here's the first word x0 and it goes through that embedding and word 2 goes through the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4204" target="_blank">01:10:04.800</a></span> | <span class="t">same embedding and word 3 index number 2 goes through the same embedding and then each time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4210" target="_blank">01:10:10.440</a></span> | <span class="t">you say we add it to the current set of activations and so having put the got the embedding we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4218" target="_blank">01:10:18.040</a></span> | <span class="t">then put it through this linear layer and again we get the embedding add it to the hit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4224" target="_blank">01:10:24.400</a></span> | <span class="t">to the activations and put it through the linear that linear layer and again the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4228" target="_blank">01:10:28.960</a></span> | <span class="t">thing here put it through the same linear layer so H is the orange so these set of activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4238" target="_blank">01:10:38.880</a></span> | <span class="t">we call the hidden state okay and so the hidden state is why it's called H and so if you follow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4247" target="_blank">01:10:47.520</a></span> | <span class="t">through these steps you'll see how each of them corresponds to a step in this diagram</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4253" target="_blank">01:10:53.480</a></span> | <span class="t">and then finally at the end we go from the hidden state to the output which is this linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4258" target="_blank">01:10:58.560</a></span> | <span class="t">layer hit state to the output okay and then we don't have the actual softmax there because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4268" target="_blank">01:11:08.960</a></span> | <span class="t">as you'll remember we can incorporate that directly into the loss function the cross</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4272" target="_blank">01:11:12.880</a></span> | <span class="t">entropy loss function and using pytorch so one nice thing about this is everything we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4281" target="_blank">01:11:21.400</a></span> | <span class="t">using we have previously created from scratch so there's nothing magic here we've created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4285" target="_blank">01:11:25.800</a></span> | <span class="t">our own embedding layer from scratch we've created our own linear layer from scratch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4289" target="_blank">01:11:29.580</a></span> | <span class="t">we've created our own relu from scratch we've created our own cross entropy loss from scratch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4296" target="_blank">01:11:36.380</a></span> | <span class="t">so you can actually try building this whole thing yourself from scratch so why do we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4305" target="_blank">01:11:45.640</a></span> | <span class="t">in terms of the nomenclature I H so H refers to hidden so this is a layer that goes from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4312" target="_blank">01:11:52.240</a></span> | <span class="t">input to hidden this is one that goes from hidden to hidden this is one that goes from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4316" target="_blank">01:11:56.640</a></span> | <span class="t">hidden to output so if any of this is feeling confusing at any point go back to where we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4323" target="_blank">01:12:03.360</a></span> | <span class="t">actually created each one of these things from scratch and create it from scratch again make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4327" target="_blank">01:12:07.680</a></span> | <span class="t">sure you actually write the code so that nothing here is mysterious so why do we use the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4339" target="_blank">01:12:19.400</a></span> | <span class="t">embedding matrix each time we have a new input word for an input word index 0 1 and 2 well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4346" target="_blank">01:12:26.160</a></span> | <span class="t">because conceptually they all represent English words you know for human numbers so why would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4355" target="_blank">01:12:35.040</a></span> | <span class="t">you expect them to be a different embedding they all should have the same representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4359" target="_blank">01:12:39.320</a></span> | <span class="t">they all have the same meaning same for this hidden to hidden at each time we're basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4364" target="_blank">01:12:44.000</a></span> | <span class="t">describing to how to go from one token to the next of our language model so we'd expect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4369" target="_blank">01:12:49.160</a></span> | <span class="t">it to be the same computation so that's basically what's going on here so having created that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4378" target="_blank">01:12:58.000</a></span> | <span class="t">model we can go ahead and instantiate it so we're going to have to pass in the vocab size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4385" target="_blank">01:13:05.080</a></span> | <span class="t">for the embedding and the number of hidden right so that's number of activations so here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4393" target="_blank">01:13:13.880</a></span> | <span class="t">we create the model and then we create a learner by passing in a model and our data loaders</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4400" target="_blank">01:13:20.440</a></span> | <span class="t">and a loss function and optionally metrics and we can fit now of course this is not pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4409" target="_blank">01:13:29.800</a></span> | <span class="t">right this is not a application specific learner so it wouldn't know what pre-trained model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4414" target="_blank">01:13:34.600</a></span> | <span class="t">to use so this is all random and we're getting somewhere around 45 to 50% or so accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4424" target="_blank">01:13:44.360</a></span> | <span class="t">is that any good well you should always compare to random or not random you should always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4429" target="_blank">01:13:49.520</a></span> | <span class="t">compare to like the simplest model where the simplest model is like some average or something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4435" target="_blank">01:13:55.080</a></span> | <span class="t">so what I did is I grabbed the validation set so all the tokens put it into a Python</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4440" target="_blank">01:14:00.600</a></span> | <span class="t">standard library counter which simply counts how many times each thing appears I found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4445" target="_blank">01:14:05.520</a></span> | <span class="t">that the word thousand is the most common and then I said okay what if we used seven</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4452" target="_blank">01:14:12.520</a></span> | <span class="t">thousand one hundred and four thousand that's here and divide that by the length of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4458" target="_blank">01:14:18.600</a></span> | <span class="t">tokens and we get 15% which in other words means if we always just predicted I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4463" target="_blank">01:14:23.600</a></span> | <span class="t">the next word will be thousand we would get 15% accuracy but in this model we got around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4470" target="_blank">01:14:30.960</a></span> | <span class="t">45 to 50% accuracy so in other words our model is a lot better than the simplest possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4477" target="_blank">01:14:37.800</a></span> | <span class="t">baseline so we've learned something useful that's great so the first thing we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4483" target="_blank">01:14:43.600</a></span> | <span class="t">to do is we're going to refactor this code because you can see we've got X going into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4492" target="_blank">01:14:52.280</a></span> | <span class="t">IH going into HH going into ReLU X going into IH going into HH going to ReLU X going into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4499" target="_blank">01:14:59.040</a></span> | <span class="t">IH going to HH going to ReLU how would you refactor that in Python you would of course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4504" target="_blank">01:15:04.720</a></span> | <span class="t">use a for loop so let's go ahead and write that again so these lines of code are identical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4511" target="_blank">01:15:11.920</a></span> | <span class="t">in fact these lines of code are identical as is this and we're going to instead of doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4517" target="_blank">01:15:17.080</a></span> | <span class="t">all that stuff manually we create a loop that goes through three times and in each time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4521" target="_blank">01:15:21.380</a></span> | <span class="t">it goes IH add to our hidden HH ReLU and then at the end hidden to output so this is exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4531" target="_blank">01:15:31.100</a></span> | <span class="t">the same thing as before but it's just refactored with a for loop and we can train it again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4538" target="_blank">01:15:38.040</a></span> | <span class="t">and again we get the same basically 45 to 50% as you would expect because it's exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4543" target="_blank">01:15:43.320</a></span> | <span class="t">the same it's just been refactored so here's something crazy this is a recurrent neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4554" target="_blank">01:15:54.600</a></span> | <span class="t">network even though it's like exactly the same as it's exactly the same as this right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4567" target="_blank">01:16:07.720</a></span> | <span class="t">it's just been refactored into a loop and so believe it or not that's actually all an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4574" target="_blank">01:16:14.560</a></span> | <span class="t">RNN is an RNN is a simple refactoring of that model with that deep learning linear model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4585" target="_blank">01:16:25.120</a></span> | <span class="t">we saw I shouldn't say linear model deep learning model of simple linear layers with values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4594" target="_blank">01:16:34.480</a></span> | <span class="t">so let's draw our pictorial representation again so remember this was our previous pictorial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4600" target="_blank">01:16:40.480</a></span> | <span class="t">representation we can refactor the picture as well so instead of showing these dots separately</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4606" target="_blank">01:16:46.880</a></span> | <span class="t">we can just take this arrow and represented it represented it as a loop because that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4613" target="_blank">01:16:53.680</a></span> | <span class="t">all that's happening right so the word one goes through an embedding goes into this activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4619" target="_blank">01:16:59.680</a></span> | <span class="t">which then just gets repeated from 2 to the end 2 to n-1 where n at this time is you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4626" target="_blank">01:17:06.080</a></span> | <span class="t">we've got three words basically for each word coming in as well and so we've just refactored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4633" target="_blank">01:17:13.200</a></span> | <span class="t">our diagram and then eventually it goes through our blue to create the output so this diagram</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4640" target="_blank">01:17:20.160</a></span> | <span class="t">is exactly the same as this diagram just replacing the middle with that loop so that's a recurrent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4648" target="_blank">01:17:28.240</a></span> | <span class="t">neural net and so h remember was something that we just kept track of here h h h h h</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4655" target="_blank">01:17:35.360</a></span> | <span class="t">h as we added each layer to it and here we just have it inside the loop we initialize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4664" target="_blank">01:17:44.880</a></span> | <span class="t">it as 0 which is kind of tricky and the reason we can do that is that 0 plus a tensor will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4671" target="_blank">01:17:51.640</a></span> | <span class="t">broadcast this 0 so that's a little neat feature that's why we don't have to make this a particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4677" target="_blank">01:17:57.980</a></span> | <span class="t">size tensor to start with okay so we're going to be seeing the word hidden state a lot and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4688" target="_blank">01:18:08.560</a></span> | <span class="t">so it's important to remember that hidden state simply represents these activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4694" target="_blank">01:18:14.000</a></span> | <span class="t">that are occurring inside our recurrent neural net and a recurrent neural net is just a refactoring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4699" target="_blank">01:18:19.720</a></span> | <span class="t">of a particular kind of fully connected deep model so that's it that's what an RNN is no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4713" target="_blank">01:18:33.160</a></span> | <span class="t">questions at this point Rachel something that's a bit weird about it though is that for every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4725" target="_blank">01:18:45.080</a></span> | <span class="t">batch we're setting our hidden state to 0 even although we're going through the entire</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4730" target="_blank">01:18:50.640</a></span> | <span class="t">set of numbers the human numbers data set in order so you would think that by the time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4736" target="_blank">01:18:56.580</a></span> | <span class="t">you've gone like one two three you shouldn't then forget everything we've learnt when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4740" target="_blank">01:19:00.560</a></span> | <span class="t">go to four five six right it would be great to actually remember where we're up to and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4748" target="_blank">01:19:08.080</a></span> | <span class="t">not reset the hidden state back to zero every time so we can absolutely do that we can maintain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4756" target="_blank">01:19:16.640</a></span> | <span class="t">the state of our RNN and here's how we would do that rather than having something called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4766" target="_blank">01:19:26.120</a></span> | <span class="t">H we'll call it self dot H and we'll set it to zero at the start when we first create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4772" target="_blank">01:19:32.520</a></span> | <span class="t">our model everything else here is the same and everything else here is the same and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4782" target="_blank">01:19:42.200</a></span> | <span class="t">there's just one extra line of code here what's going on here well here's the thing if if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4790" target="_blank">01:19:50.200</a></span> | <span class="t">H is something which persists from batch to batch then effectively this loop is effectively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4800" target="_blank">01:20:00.400</a></span> | <span class="t">kind of becoming infinitely long right our deep learning model therefore is getting effectively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4808" target="_blank">01:20:08.920</a></span> | <span class="t">we're not infinitely deep but as deep as the entire size of our data set because every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4813" target="_blank">01:20:13.560</a></span> | <span class="t">time we're stacking new layers on top of the previous layers the reason this matters is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4820" target="_blank">01:20:20.500</a></span> | <span class="t">that when we then do back propagation when we then calculate the gradients we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4824" target="_blank">01:20:24.840</a></span> | <span class="t">to have to calculate the gradients all the way back through every layer going all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4831" target="_blank">01:20:31.000</a></span> | <span class="t">way so by the time we get to the end of the data set we're going to be effectively back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4835" target="_blank">01:20:35.480</a></span> | <span class="t">propagating not just through this loop but remember self dot H was created also by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4842" target="_blank">01:20:42.400</a></span> | <span class="t">previous quarter forward and the previous quarter forward and the previous quarter forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4845" target="_blank">01:20:45.920</a></span> | <span class="t">so we're going to have this incredibly slow calculation of the gradients all the way back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4853" target="_blank">01:20:53.840</a></span> | <span class="t">to the start it's also going to use up a whole lot of memory because it's going to have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4858" target="_blank">01:20:58.880</a></span> | <span class="t">store all those intermediate gradients in order to calculate them so that's a problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4865" target="_blank">01:21:05.400</a></span> | <span class="t">and so the problem is easily solved by saying detach and what detach does is it basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4871" target="_blank">01:21:11.920</a></span> | <span class="t">says throw away my gradient history forget that I forget that I was calculated from some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4878" target="_blank">01:21:18.240</a></span> | <span class="t">other gradients so the activations are still stored but the gradient history is no longer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4884" target="_blank">01:21:24.040</a></span> | <span class="t">stored and so this kind of cuts off the gradient computation and so this is called truncated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4891" target="_blank">01:21:31.960</a></span> | <span class="t">back propagation so exactly the same lines of code as the other two models H equals zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4900" target="_blank">01:21:40.840</a></span> | <span class="t">has been moved into self dot H equals zero these lines of code are identical and we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4906" target="_blank">01:21:46.800</a></span> | <span class="t">added one more line of code so the only other thing is it from time to time we might have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4912" target="_blank">01:21:52.400</a></span> | <span class="t">to reset self dot H to zero so I've created a method for that and we'll see how that works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4919" target="_blank">01:21:59.200</a></span> | <span class="t">shortly okay so back propagation sorry I was using the wrong jargon back propagation through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4928" target="_blank">01:22:08.360</a></span> | <span class="t">time is what we call it when we calculate the back prop over going back through this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4937" target="_blank">01:22:17.480</a></span> | <span class="t">loop all right now we do need to make sure that the samples are seen in the correct order</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4944" target="_blank">01:22:24.920</a></span> | <span class="t">you know given that we need to make sure that every batch connects up to the previous batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4950" target="_blank">01:22:30.960</a></span> | <span class="t">so go back to notebook 10 to remind yourself of what that needs to look like but basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4955" target="_blank">01:22:35.440</a></span> | <span class="t">the first batch we see that the number the length of our sequences divided by the batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4962" target="_blank">01:22:42.840</a></span> | <span class="t">size is 328 so the first batch will be our index number 0 then M then 2 times M and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4970" target="_blank">01:22:50.440</a></span> | <span class="t">forth the second batch will be 1 M plus 1 2 times M plus 1 and so forth so the details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4976" target="_blank">01:22:56.800</a></span> | <span class="t">don't matter but here's how we create you know do that indexing so now we can go ahead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4983" target="_blank">01:23:03.800</a></span> | <span class="t">and call that group chunks function to calculate to create our training set and our validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=4992" target="_blank">01:23:12.080</a></span> | <span class="t">set and certainly don't shuffle because that would break everything in terms of the ordering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5000" target="_blank">01:23:20.200</a></span> | <span class="t">and then there's one more thing we need to do which is we need to make sure that at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5005" target="_blank">01:23:25.440</a></span> | <span class="t">start of each epoch we call reset because at the start of the epoch we're going back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5013" target="_blank">01:23:33.160</a></span> | <span class="t">to the start of our natural numbers so we need to set self.h back to 0 so something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5021" target="_blank">01:23:41.680</a></span> | <span class="t">that we'll learn about in part 2 is that fastai has something called callbacks and callbacks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5030" target="_blank">01:23:50.720</a></span> | <span class="t">are classes which allow you to basically say during the training loop I want you to call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5036" target="_blank">01:23:56.760</a></span> | <span class="t">some particular code and in particular this is going to call this code and so you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5049" target="_blank">01:24:09.880</a></span> | <span class="t">see callbacks are very small or can be very small they're normally very small when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5053" target="_blank">01:24:13.480</a></span> | <span class="t">start training it'll call reset when we start validation it'll call reset so this is each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5060" target="_blank">01:24:20.120</a></span> | <span class="t">epoch and when we're all finished fitting it will call reset and what does reset do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5065" target="_blank">01:24:25.400</a></span> | <span class="t">it does whatever you tell it to do and we told it to be self.h=0 so if you want to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5072" target="_blank">01:24:32.520</a></span> | <span class="t">a callback you can simply add it to the callbacks list CVs when you create your learner and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5081" target="_blank">01:24:41.960</a></span> | <span class="t">so now when we train that's way better okay so we've now actually kept this is called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5089" target="_blank">01:24:49.800</a></span> | <span class="t">a stateful RNN it's actually keeping the state keeping the hidden state from batch to batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5100" target="_blank">01:25:00.480</a></span> | <span class="t">now we still got a bit of a obvious problem here which is that if you look back to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5107" target="_blank">01:25:07.000</a></span> | <span class="t">data that we created we used these first three tokens to predict the fourth and then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5117" target="_blank">01:25:17.320</a></span> | <span class="t">next three tokens to predict the seventh and then the next three tokens to predict the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5124" target="_blank">01:25:24.640</a></span> | <span class="t">one after and so forth effectively what would rather do you would think is is predict every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5132" target="_blank">01:25:32.480</a></span> | <span class="t">word not just every fourth word it seems like we're throwing away a lot of signal here which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5137" target="_blank">01:25:37.160</a></span> | <span class="t">is pretty wasteful so we want to create more signal and so the way to do that would be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5145" target="_blank">01:25:45.560</a></span> | <span class="t">rather than putting rather than putting this output stage outside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5156" target="_blank">01:25:56.560</a></span> | <span class="t">the loop right so this dotted area is a bit that's looped what if we put the output inside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5164" target="_blank">01:26:04.360</a></span> | <span class="t">the loop so in other words after every hidden state was created we immediately did a prediction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5170" target="_blank">01:26:10.520</a></span> | <span class="t">and so that way we could predict after every time step and our dependent variable could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5175" target="_blank">01:26:15.760</a></span> | <span class="t">be the entire sequence of numbers offset by one so that would give us a lot more signal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5182" target="_blank">01:26:22.360</a></span> | <span class="t">so we have to change our data so the dependent variable has each of the next three words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5187" target="_blank">01:26:27.520</a></span> | <span class="t">after each of the three inputs so instead of being just the numbers from I to I plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5194" target="_blank">01:26:34.440</a></span> | <span class="t">SL as input and then I plus SL plus one as output we're going to have the entire set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5202" target="_blank">01:26:42.120</a></span> | <span class="t">offset by one as our dependent variable so and then we can now do exactly the same as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5208" target="_blank">01:26:48.080</a></span> | <span class="t">we did before to create our data loaders and so you can now see that each sequence is exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5216" target="_blank">01:26:56.080</a></span> | <span class="t">the previous is the independent variable and the dependent variable the same thing but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5220" target="_blank">01:27:00.240</a></span> | <span class="t">offset by one okay and then we need to modify our model very slightly this code is all exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5229" target="_blank">01:27:09.200</a></span> | <span class="t">the same as before but rather than now returning one output will create a list of outputs and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5235" target="_blank">01:27:15.960</a></span> | <span class="t">we'll append to that list after every element of the loop and then at the end we'll stack</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5242" target="_blank">01:27:22.880</a></span> | <span class="t">them all up and then this is the same so it's nearly exactly the same okay just a very minor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5249" target="_blank">01:27:29.080</a></span> | <span class="t">change our loss function needs to we need to create our own loss function which is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5257" target="_blank">01:27:37.680</a></span> | <span class="t">a cross-entropy loss but we need to just flatten it out so the target gets flattened out the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5267" target="_blank">01:27:47.560</a></span> | <span class="t">input gets flattened out and so then we can now pass that as our loss function everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5276" target="_blank">01:27:56.040</a></span> | <span class="t">else here is the same and we can fit and we've gone from I can't remember 58 to 64 so it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5292" target="_blank">01:28:12.020</a></span> | <span class="t">improved a little bit so that's good you know we did find this a little little flaky sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5301" target="_blank">01:28:21.800</a></span> | <span class="t">it would train really well sometimes it wouldn't train great but sometimes we you know we often</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5306" target="_blank">01:28:26.880</a></span> | <span class="t">got this reasonably good answer now one problem here is although effectively we have quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5318" target="_blank">01:28:38.280</a></span> | <span class="t">a deep neural net if you kind of go back to the version so this this version where we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5325" target="_blank">01:28:45.400</a></span> | <span class="t">have the loop in it is kind of the normal way to think about an RNN but perhaps an easier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5330" target="_blank">01:28:50.400</a></span> | <span class="t">way to think about it is what we call the unrolled version and the unrolled version</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5335" target="_blank">01:28:55.960</a></span> | <span class="t">is when you look at it like this now if you unroll this stateful neural net we have you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5343" target="_blank">01:29:03.360</a></span> | <span class="t">know it's it is quite deep but every single one of the hidden to hidden layers uses exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5351" target="_blank">01:29:11.560</a></span> | <span class="t">the same weight matrix so really it's not really that deep at all because it can't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5359" target="_blank">01:29:19.360</a></span> | <span class="t">do very sophisticated computation because it has to use the same weight matrix every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5363" target="_blank">01:29:23.520</a></span> | <span class="t">time so in some ways it's not really any smarter than a plane linear model so it would be nice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5372" target="_blank">01:29:32.860</a></span> | <span class="t">to try to you know create a truly deep model have multiple different layers that it can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5379" target="_blank">01:29:39.760</a></span> | <span class="t">go through so we can actually do that easily enough by creating something called a multi-layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5385" target="_blank">01:29:45.880</a></span> | <span class="t">RNN and all we do is we basically take that diagram we just saw before and we repeat it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5393" target="_blank">01:29:53.640</a></span> | <span class="t">but and this is actually a bit unclear the dotted arrows here are different weight matrices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5402" target="_blank">01:30:02.520</a></span> | <span class="t">to the non-dotted arrows here so we can have a different hidden to hidden weight matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5409" target="_blank">01:30:09.060</a></span> | <span class="t">in the kind of second set of RNN layers and a different weight matrix here for the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5416" target="_blank">01:30:16.860</a></span> | <span class="t">set and so this is called a stacked RNN or a multi-layer RNN and so here's the same thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5426" target="_blank">01:30:26.640</a></span> | <span class="t">in the unrolled version right so this is exactly the same thing but showing you the unrolled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5432" target="_blank">01:30:32.240</a></span> | <span class="t">version. Writing this out by hand maybe that's quite a good exercise or particularly this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5441" target="_blank">01:30:41.120</a></span> | <span class="t">one would be quite a good exercise but it's kind of tedious so we're not going to bother</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5444" target="_blank">01:30:44.800</a></span> | <span class="t">instead we're going to use PyTorch as RNN class and so PyTorch as RNN class is basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5451" target="_blank">01:30:51.040</a></span> | <span class="t">doing exactly what we saw here right and specifically this this part here and this part here right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5464" target="_blank">01:31:04.960</a></span> | <span class="t">but it's nice that it also has an extra number of layers parameter that lets you tell it how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5474" target="_blank">01:31:14.400</a></span> | <span class="t">many to stack on top of each other so it's important when you start using PyTorch as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5479" target="_blank">01:31:19.480</a></span> | <span class="t">RNN to realize there's nothing magic going on right you're just using this refactored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5486" target="_blank">01:31:26.120</a></span> | <span class="t">for loop that we've already seen so we still need the input to hidden embedding this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5492" target="_blank">01:31:32.680</a></span> | <span class="t">now the hidden to hidden with the loop all done for us and then this is the hidden to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5498" target="_blank">01:31:38.160</a></span> | <span class="t">output just as before and then this is our hidden just like before so now we don't need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5505" target="_blank">01:31:45.280</a></span> | <span class="t">the loop we can just call self.rnn and it does the whole loop for us we can do all the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5511" target="_blank">01:31:51.640</a></span> | <span class="t">to hidden at once to save a little bit of time because thanks to the wonder of embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5516" target="_blank">01:31:56.500</a></span> | <span class="t">matrices and as per usual we have to go detach to avoid getting a super deep effective network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5525" target="_blank">01:32:05.160</a></span> | <span class="t">and then pass it through our output linear layer so this is exactly the same as the previous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5531" target="_blank">01:32:11.760</a></span> | <span class="t">model except that we have just refactored it using in RNN and we said we want more than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5539" target="_blank">01:32:19.160</a></span> | <span class="t">one layer so let's request say two layers we still need the model reset it just like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5546" target="_blank">01:32:26.040</a></span> | <span class="t">before because remember nothing's changed and let's go ahead and fit and oh it's terrible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5556" target="_blank">01:32:36.160</a></span> | <span class="t">so why is it terrible well the reason it's terrible is that now we really do have a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5565" target="_blank">01:32:45.000</a></span> | <span class="t">deep model and very deep models are really hard to train because we can get exploding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5575" target="_blank">01:32:55.400</a></span> | <span class="t">or disappearing activations so what that means is we start out with some initial state and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5587" target="_blank">01:33:07.560</a></span> | <span class="t">we're gradually putting it through all of these layers and all of these layers right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5592" target="_blank">01:33:12.280</a></span> | <span class="t">and so each time we're doing a matrix multiplication which remember is just doing a whole bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5596" target="_blank">01:33:16.800</a></span> | <span class="t">of multiplies and adds and then we multiply and add and we multiply and add and we multiply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5601" target="_blank">01:33:21.800</a></span> | <span class="t">and add and we multiply and add and if you do that enough times you can end up with very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5608" target="_blank">01:33:28.120</a></span> | <span class="t">very very big results or so that would be if the kind of things we're multiplying and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5613" target="_blank">01:33:33.000</a></span> | <span class="t">adding by are pretty big or very very very very small results particularly because we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5618" target="_blank">01:33:38.160</a></span> | <span class="t">putting it through the same layer again and again right and why is that a problem well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5626" target="_blank">01:33:46.520</a></span> | <span class="t">if you multiply by 2 a few times you get 1 2 4 8 etc and after 32 steps you're already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5634" target="_blank">01:33:54.840</a></span> | <span class="t">at 4 billion or if you start at 1 and you multiply by half a few times after 32 steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5645" target="_blank">01:34:05.040</a></span> | <span class="t">you're down to this tiny number so a number even slightly or higher or lower than 1 can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5651" target="_blank">01:34:11.040</a></span> | <span class="t">kind of cause an explosion or disappearance of a number and matrix multiplication is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5656" target="_blank">01:34:16.000</a></span> | <span class="t">multiplying numbers and adding them up so exactly the same thing happens to matrix multiplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5660" target="_blank">01:34:20.840</a></span> | <span class="t">you kind of have matrices that grow really big or grow really small and when that does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5669" target="_blank">01:34:29.420</a></span> | <span class="t">that you're also going to have exactly the same things happening to the gradients they'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5673" target="_blank">01:34:33.080</a></span> | <span class="t">get really big really small and one of the problems here is that numbers are not stored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5679" target="_blank">01:34:39.440</a></span> | <span class="t">precisely in a computer they're stored using something called floating point so we stole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5688" target="_blank">01:34:48.720</a></span> | <span class="t">this nice diagram from this article called what you never wanted to know about floating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5694" target="_blank">01:34:54.240</a></span> | <span class="t">point but what we're forced to find out and here we're at this point where we're forced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5697" target="_blank">01:34:57.380</a></span> | <span class="t">to find out and it's basically showing us the granularity with which numbers are stored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5702" target="_blank">01:35:02.720</a></span> | <span class="t">and so the numbers that are further away from zero are stored much less precisely than the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5709" target="_blank">01:35:09.760</a></span> | <span class="t">numbers that are close to zero and so if you think about it that means that the gradients</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5715" target="_blank">01:35:15.960</a></span> | <span class="t">further away from zero could actually for very big numbers could actually become zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5727" target="_blank">01:35:27.160</a></span> | <span class="t">themselves because you could actually end up in kind of with two numbers that are between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5733" target="_blank">01:35:33.280</a></span> | <span class="t">these kind of little gradations here and you actually end up the same thing with the really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5741" target="_blank">01:35:41.120</a></span> | <span class="t">small numbers because they're really small numbers although they're closer together the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5744" target="_blank">01:35:44.840</a></span> | <span class="t">numbers that they represent are also very close together so in both cases they're kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5749" target="_blank">01:35:49.840</a></span> | <span class="t">of the relative accuracy gets worse and worse so you really want to avoid this happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5762" target="_blank">01:36:02.000</a></span> | <span class="t">there's a number of ways to avoid this happening and this is the same for really deep convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5768" target="_blank">01:36:08.760</a></span> | <span class="t">neural nets or really deep kind of tabular standard tabular networks anytime you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5776" target="_blank">01:36:16.040</a></span> | <span class="t">too many layers it can become difficult to train and you generally have to use like either</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5779" target="_blank">01:36:19.680</a></span> | <span class="t">really small learning rates or you have to use special techniques that avoid exploding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5787" target="_blank">01:36:27.400</a></span> | <span class="t">or disappearing activations or gradients. For RNNs one of the most popular approaches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5794" target="_blank">01:36:34.380</a></span> | <span class="t">to this is to use an architecture called an LSTM and I am not going to go into the details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5803" target="_blank">01:36:43.840</a></span> | <span class="t">of an LSTM from scratch today but it's in the it's in the book and in the notebook but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5810" target="_blank">01:36:50.920</a></span> | <span class="t">the key thing to know about an LSTM is let's have a look is that rather than just being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5819" target="_blank">01:36:59.800</a></span> | <span class="t">a matrix multiplication it is this which is that there are a number of linear layers that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5830" target="_blank">01:37:10.120</a></span> | <span class="t">it goes through and those linear layers are combined in particular ways and the way they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5835" target="_blank">01:37:15.160</a></span> | <span class="t">combined which is shown in this kind of diagram here is that it basically is designed such</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5842" target="_blank">01:37:22.340</a></span> | <span class="t">that the that there are like little mini neural networks inside the layer which decide how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5852" target="_blank">01:37:32.360</a></span> | <span class="t">much of the previous state is kept how much is thrown away and how much of the new state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5858" target="_blank">01:37:38.560</a></span> | <span class="t">is added and by letting it have little neural nets to kind of calculate each of these things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5864" target="_blank">01:37:44.600</a></span> | <span class="t">it allows the LSTM layer which again is shown here to decide how much of kind of how much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5874" target="_blank">01:37:54.280</a></span> | <span class="t">of an update to do at each time and then with that capability it basically allows it to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5883" target="_blank">01:38:03.560</a></span> | <span class="t">avoid kind of updating too much or updating too little and by the way this this code you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5894" target="_blank">01:38:14.600</a></span> | <span class="t">can refactor which Sylvain did here into a much smaller amount of code but these two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5900" target="_blank">01:38:20.440</a></span> | <span class="t">things are exactly the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5902" target="_blank">01:38:22.680</a></span> | <span class="t">So as I said I'm not going to worry too much about the details of how this works now the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5907" target="_blank">01:38:27.920</a></span> | <span class="t">important thing just to know is that you can replace the matrix multiplication in an RNN</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5915" target="_blank">01:38:35.320</a></span> | <span class="t">with this sequence of matrix multiplications and sigmoids and times and plus and when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5922" target="_blank">01:38:42.820</a></span> | <span class="t">do so you will very significantly decrease the amount of gradient or activation exploding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5931" target="_blank">01:38:51.680</a></span> | <span class="t">explosions or disappearances. So that's called an LSTM cell and an RNN which uses this instead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5940" target="_blank">01:39:00.560</a></span> | <span class="t">of a matrix multiplication is called an LSTM and so you can replace NN.RNN with NN.LSTM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5951" target="_blank">01:39:11.560</a></span> | <span class="t">Other than that we haven't really changed anything except that LSTMs because they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5959" target="_blank">01:39:19.720</a></span> | <span class="t">more of these layers in them we actually have to make our hidden state have more layers in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5967" target="_blank">01:39:27.040</a></span> | <span class="t">as well but other than that we can just replace RNN with LSTM and we can call it just the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5975" target="_blank">01:39:35.960</a></span> | <span class="t">way as we did before we can detach just like before but that's now a list so we have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5980" target="_blank">01:39:40.640</a></span> | <span class="t">detach all of them and pop it through our output layer which is exactly as before reset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5986" target="_blank">01:39:46.320</a></span> | <span class="t">is just as before except it's got to loop through each one and we can fit it in exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5992" target="_blank">01:39:52.240</a></span> | <span class="t">the same way as before and as you can see we end up with a much better result which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=5999" target="_blank">01:39:59.320</a></span> | <span class="t">is great. We have two questions. Okay perfect. Could we somehow use regularization to try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6005" target="_blank">01:40:05.480</a></span> | <span class="t">to make the RNN parameters close to the identity matrix or would that cause bad results because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6011" target="_blank">01:40:11.200</a></span> | <span class="t">the hidden layers want to deviate from the identity during training? So we're actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6019" target="_blank">01:40:19.320</a></span> | <span class="t">about to look at regularization so we will take a look. The identity matrix for those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6028" target="_blank">01:40:28.320</a></span> | <span class="t">that don't know don't remember is the matrix where if you multiply it by it you get exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6033" target="_blank">01:40:33.480</a></span> | <span class="t">the same thing that you started with so just like if you multiply by one you get back the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6037" target="_blank">01:40:37.720</a></span> | <span class="t">same number you started with. For linear algebra if you multiply by the identity matrix you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6042" target="_blank">01:40:42.600</a></span> | <span class="t">get the same matrix you started with and actually one quite popular approach to initializing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6049" target="_blank">01:40:49.960</a></span> | <span class="t">the hidden to hidden activations is to initialize with a identity matrix which ensures that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6055" target="_blank">01:40:55.960</a></span> | <span class="t">you start with something which doesn't have gradient explosions or activation explosions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6065" target="_blank">01:41:05.560</a></span> | <span class="t">There are yeah we'll have and we're about to have a look at some more regularization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6069" target="_blank">01:41:09.440</a></span> | <span class="t">approaches so let's wait until we do that. All right next question. Is there a way to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6074" target="_blank">01:41:14.600</a></span> | <span class="t">quickly check if the activations are disappearing/exploding? Absolutely just go ahead and calculate them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6084" target="_blank">01:41:24.240</a></span> | <span class="t">and we'll be looking at that in a lot more detail in part two but a really great exercise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6090" target="_blank">01:41:30.240</a></span> | <span class="t">would be to try to figure out how you can actually output the activations of each layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6097" target="_blank">01:41:37.320</a></span> | <span class="t">and it would certainly be very easy to do that in the in the RNNs that we built ourselves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6102" target="_blank">01:41:42.560</a></span> | <span class="t">from scratch because we can actually see the linear layers and so you could just print</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6108" target="_blank">01:41:48.760</a></span> | <span class="t">them out or print out some statistics or store them away or something like that. FAST AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6124" target="_blank">01:42:04.440</a></span> | <span class="t">has a class called Activation Stats which kind of you can check out if you're interested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6135" target="_blank">01:42:15.360</a></span> | <span class="t">if that's a really good way to specifically to do this. Okay so yeah so regularization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6150" target="_blank">01:42:30.280</a></span> | <span class="t">is important we have potentially a lot of parameters and a lot of layers it would be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6155" target="_blank">01:42:35.880</a></span> | <span class="t">really nice if we can do the same kind of thing that we've done with our CNNs and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6163" target="_blank">01:42:43.080</a></span> | <span class="t">forth which is to use more parameters but then use regularization to ensure that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6168" target="_blank">01:42:48.240</a></span> | <span class="t">don't overfit and so we can certainly do that with an LSTM as well and perhaps the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6175" target="_blank">01:42:55.480</a></span> | <span class="t">way to do that is to use something called dropout and dropout is not just used for RNNs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6183" target="_blank">01:43:03.320</a></span> | <span class="t">dropout is used all over the place but it works particularly well in RNNs. This is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6188" target="_blank">01:43:08.200</a></span> | <span class="t">picture from the dropout paper and what happens in dropout is here's a is a kind of a picture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6196" target="_blank">01:43:16.960</a></span> | <span class="t">of a three fully connected layers no sorry I guess it's two one two yeah no three fully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6205" target="_blank">01:43:25.480</a></span> | <span class="t">connected layers and so in these two fully connected layers at the start here what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6212" target="_blank">01:43:32.280</a></span> | <span class="t">could do is we could delete some of the activations at random and so this has happened here but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6219" target="_blank">01:43:39.240</a></span> | <span class="t">X this is what X means it's like deleting those those activations at random and if we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6225" target="_blank">01:43:45.760</a></span> | <span class="t">do so you can see we end up with a lot less computation going on and what dropout does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6231" target="_blank">01:43:51.960</a></span> | <span class="t">is each batch each mini batch it randomly deletes a different set of activations from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6241" target="_blank">01:44:01.780</a></span> | <span class="t">whatever layers you ask for that's what dropout does so basically the idea is that dropout</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6253" target="_blank">01:44:13.240</a></span> | <span class="t">helps to generalize because if a particular activation was kind of effectively learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6262" target="_blank">01:44:22.100</a></span> | <span class="t">some input some some particular piece of input memorizing it then sometimes it gets randomly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6268" target="_blank">01:44:28.560</a></span> | <span class="t">deleted and so then suddenly it's not going to do anything useful at all so by randomly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6276" target="_blank">01:44:36.000</a></span> | <span class="t">deleting activations it ensures that activations can't become over specialized at doing just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6282" target="_blank">01:44:42.320</a></span> | <span class="t">one thing because then if it did then the times they're randomly deleted it's it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6287" target="_blank">01:44:47.880</a></span> | <span class="t">going to work so here is the entire implementation of a dropout layer you pass it some value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6296" target="_blank">01:44:56.280</a></span> | <span class="t">P which is the probability that an activation gets deleted so we'll store that away and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6302" target="_blank">01:45:02.120</a></span> | <span class="t">so then in the forward you're going to get your activations now if you're not training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6306" target="_blank">01:45:06.960</a></span> | <span class="t">so if you're doing validation then we're not going to do dropout right but if we are training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6313" target="_blank">01:45:13.260</a></span> | <span class="t">then we create a mask and so the mask is a Bernoulli random a Bernoulli random variable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6324" target="_blank">01:45:24.680</a></span> | <span class="t">so what is Bernoulli random variable means it means it's a bunch of ones and zeros where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6329" target="_blank">01:45:29.480</a></span> | <span class="t">this is the probability that we get a one which is one minus the probability we get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6336" target="_blank">01:45:36.880</a></span> | <span class="t">a zero and so then we just multiply that by our input so that's going to convert some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6344" target="_blank">01:45:44.360</a></span> | <span class="t">of the inputs into zeros which is basically deleting them so you should check out some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6350" target="_blank">01:45:50.760</a></span> | <span class="t">of the details for example about why we do a divide one minus P which is described here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6355" target="_blank">01:45:55.960</a></span> | <span class="t">and we do point out here that normally and I would normally in the lesson show you an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6361" target="_blank">01:46:01.760</a></span> | <span class="t">example of the of what Bernoulli does but of course nowadays you know we're getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6368" target="_blank">01:46:08.400</a></span> | <span class="t">to the advanced classes you're expected to do it yourself so be sure to create a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6372" target="_blank">01:46:12.760</a></span> | <span class="t">cell here and make sure you actually create a tensor and then run Bernoulli underscore</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6378" target="_blank">01:46:18.120</a></span> | <span class="t">on it and make sure you see exactly what it's doing so that then you can understand this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6383" target="_blank">01:46:23.980</a></span> | <span class="t">class now of course we don't have to use this class we made ourselves we can just use nn.dropout</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6391" target="_blank">01:46:31.800</a></span> | <span class="t">but you can use this class yourself because it does the same thing so again you know we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6396" target="_blank">01:46:36.480</a></span> | <span class="t">trying to make sure that we know how to build stuff from scratch this special self dot training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6404" target="_blank">01:46:44.000</a></span> | <span class="t">is set for every module automatically by fast.ai to based on whether or not you're in the validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6412" target="_blank">01:46:52.660</a></span> | <span class="t">part of your training loop or the training part of your training loop it's also part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6419" target="_blank">01:46:59.520</a></span> | <span class="t">of PyTorch and in PyTorch if you're not using fast.ai you have to call the train method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6424" target="_blank">01:47:04.480</a></span> | <span class="t">on a module to set training to true and the eval method to set it to false for every module</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6429" target="_blank">01:47:09.920</a></span> | <span class="t">inside some other module so that's one great approach to regularization another approach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6438" target="_blank">01:47:18.340</a></span> | <span class="t">which I've only seen used in recurrent neural nets is activation regularization and temporal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6448" target="_blank">01:47:28.080</a></span> | <span class="t">activation regularization which is very very similar to the question that we were just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6452" target="_blank">01:47:32.000</a></span> | <span class="t">asked what happens with activation regularization is it looks a very similar to weight decay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6462" target="_blank">01:47:42.760</a></span> | <span class="t">but rather than adding some multiplier times the sum of squares of the weights we add some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6472" target="_blank">01:47:52.920</a></span> | <span class="t">multiplier by the sum of squares of the activations so in other words we're basically saying we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6480" target="_blank">01:48:00.280</a></span> | <span class="t">not just trying to decrease the weights but decrease the total activations and then similarly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6490" target="_blank">01:48:10.000</a></span> | <span class="t">we can also see what's the difference between the activations from the previous time step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6499" target="_blank">01:48:19.680</a></span> | <span class="t">to this time step so take the difference and then again squared times some value so these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6508" target="_blank">01:48:28.800</a></span> | <span class="t">are two hyper parameters alpha and beta the higher they are the more regularized your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6514" target="_blank">01:48:34.200</a></span> | <span class="t">model and so with TAR it's going to say no layer of the LSTM should too dramatically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6523" target="_blank">01:48:43.080</a></span> | <span class="t">change the activations from one time step to the next and then for alpha it's saying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6530" target="_blank">01:48:50.880</a></span> | <span class="t">no layer of the LSTM should create two large activations and so they wouldn't actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6537" target="_blank">01:48:57.300</a></span> | <span class="t">create these large activations or large changes unless the loss improved by enough to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6543" target="_blank">01:49:03.180</a></span> | <span class="t">it worth it okay so there's then I think just one more thing we need to know about which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6556" target="_blank">01:49:16.320</a></span> | <span class="t">is called weight tying and weight tying is a very minor change and let's have a look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6562" target="_blank">01:49:22.400</a></span> | <span class="t">at it here so this is the embedding we had before this is the LSTM we had before this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6567" target="_blank">01:49:27.520</a></span> | <span class="t">is where we're going to introduce dropout this is the hidden to output linear layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6573" target="_blank">01:49:33.000</a></span> | <span class="t">we had before but we're going to add one more line of code which is the hidden to output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6582" target="_blank">01:49:42.720</a></span> | <span class="t">weights are actually equal to the input to hidden weights now this is not just setting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6590" target="_blank">01:49:50.960</a></span> | <span class="t">them once this is actually setting them so that they're a reference to the exact same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6595" target="_blank">01:49:55.340</a></span> | <span class="t">object in memory the exact same tensor in memory so the weights of the hidden to output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6600" target="_blank">01:50:00.560</a></span> | <span class="t">layer will always be identical to the weights of the input to hidden layer and this is called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6606" target="_blank">01:50:06.920</a></span> | <span class="t">weight tying and the reason we do this is because conceptually in a language model predicting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6614" target="_blank">01:50:14.480</a></span> | <span class="t">the next word is about kind of converting activations into English words or else an embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6621" target="_blank">01:50:21.080</a></span> | <span class="t">is about converting English words to activations and there's a reasonable hypothesis which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6628" target="_blank">01:50:28.180</a></span> | <span class="t">would be that well those are basically exactly the same computation or at least the reverse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6633" target="_blank">01:50:33.000</a></span> | <span class="t">of it so why shouldn't they use the same weights and it turns out lo and behold yes if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6637" target="_blank">01:50:37.920</a></span> | <span class="t">use the same weights then actually it does work a little bit better so then here's our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6644" target="_blank">01:50:44.000</a></span> | <span class="t">forward which is to do the input to hidden do the RNN apply the dropout do the detach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6652" target="_blank">01:50:52.280</a></span> | <span class="t">and then apply the hidden to output which is using exactly the same weights as the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6656" target="_blank">01:50:56.720</a></span> | <span class="t">to hidden and resets the same we haven't created the RNN regularizer from scratch here but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6665" target="_blank">01:51:05.640</a></span> | <span class="t">you can add it as a callback passing in your alpha and your beta if you call text learner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6677" target="_blank">01:51:17.200</a></span> | <span class="t">instead of learner it will add the model resetter and the RNN regularizer for you so that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6684" target="_blank">01:51:24.200</a></span> | <span class="t">what one of the things text learner does so this code is the same as this code and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6690" target="_blank">01:51:30.360</a></span> | <span class="t">we can then train a model again and that's also add weight decay and look at this we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6697" target="_blank">01:51:37.800</a></span> | <span class="t">getting up close to 90% accuracy so we've covered a lot in this lesson but the amazing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6709" target="_blank">01:51:49.640</a></span> | <span class="t">thing is that we've just replicated all of the pieces in an AWD LSTM all of the pieces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6718" target="_blank">01:51:58.220</a></span> | <span class="t">in this state-of-the-art recurrent neural net which we've showed we could use in the previous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6724" target="_blank">01:52:04.940</a></span> | <span class="t">notebook to get what was until very recently state-of-the-art results for text classification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6732" target="_blank">01:52:12.000</a></span> | <span class="t">and far more quickly and with far less compute and memory than more modern than the approaches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6741" target="_blank">01:52:21.360</a></span> | <span class="t">in the last year or so which have beaten that benchmark so this is a really efficient really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6749" target="_blank">01:52:29.940</a></span> | <span class="t">accurate approach and it's still the state-of-the-art in many many academic situations and it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6759" target="_blank">01:52:39.880</a></span> | <span class="t">still very widely used in industry and so it's pretty cool that we've actually seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6763" target="_blank">01:52:43.680</a></span> | <span class="t">how to write it from scratch so the main thing to mention the further research is to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6772" target="_blank">01:52:52.080</a></span> | <span class="t">a look at the source code for AWD LSTM and fast AI and see if you can see how the things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6778" target="_blank">01:52:58.840</a></span> | <span class="t">in AWD LSTM map to the you know what those lines of code how they map to the concepts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6785" target="_blank">01:53:05.520</a></span> | <span class="t">that we've seen in this chapter. Rachel do we have any questions? So here we have come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6794" target="_blank">01:53:14.000</a></span> | <span class="t">to the conclusion of our what was originally going to be seven lessons and turned into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6798" target="_blank">01:53:18.760</a></span> | <span class="t">eight lessons. I hope that you've got a lot out of this, thank you for staying with us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6809" target="_blank">01:53:29.920</a></span> | <span class="t">What a lot of folks people people now do when they finish there at least people have finished</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6815" target="_blank">01:53:35.000</a></span> | <span class="t">previous courses is they go back to lesson one and try and repeat it but doing a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6821" target="_blank">01:53:41.120</a></span> | <span class="t">less looking at the notebooks a lot more doing stuff from scratch yourself and going deeper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6828" target="_blank">01:53:48.000</a></span> | <span class="t">into the assignments so that's one thing you could do next. Another thing you could do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6833" target="_blank">01:53:53.760</a></span> | <span class="t">next would be to pick out a Kaggle competition to enter or pick a book that you want to read</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6841" target="_blank">01:54:01.920</a></span> | <span class="t">about deep learning or a paper and team up with some friends to do like a paper reading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6849" target="_blank">01:54:09.900</a></span> | <span class="t">group or a book reading group you know one of the most important things to keep the learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6854" target="_blank">01:54:14.800</a></span> | <span class="t">going is to get together with other people on the learning journey. Another great way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6860" target="_blank">01:54:20.800</a></span> | <span class="t">to do that of course is through the forums so if you haven't been using the forums much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6864" target="_blank">01:54:24.920</a></span> | <span class="t">so far no problem but now might be a great time to get involved and find some projects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6869" target="_blank">01:54:29.640</a></span> | <span class="t">that are going on that look interesting and it's fine if you you know you don't have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6875" target="_blank">01:54:35.360</a></span> | <span class="t">be an expert right obviously any of those projects the people that are already doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6879" target="_blank">01:54:39.680</a></span> | <span class="t">it are going to know more about it than you do at this point because they're already doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6884" target="_blank">01:54:44.000</a></span> | <span class="t">it but if you drop into a thread and say hey I would love to learn more about this how do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6888" target="_blank">01:54:48.280</a></span> | <span class="t">I get started or have a look at the wiki posts to find out and try things out you can start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6894" target="_blank">01:54:54.800</a></span> | <span class="t">getting involved in other people's projects and help them out. So yeah and of course don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6906" target="_blank">01:55:06.240</a></span> | <span class="t">forget about writing so if you haven't tried writing a blog post yet maybe now is a great</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6910" target="_blank">01:55:10.240</a></span> | <span class="t">time to do that pick something that's interesting to you especially if it's something in your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6915" target="_blank">01:55:15.240</a></span> | <span class="t">area of expertise at work or a hobby or something like that or specific to where you live maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6921" target="_blank">01:55:21.120</a></span> | <span class="t">you could try and build some kind of text classifier or text generator for particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6927" target="_blank">01:55:27.760</a></span> | <span class="t">kinds of text that are that you know about you know that would be that would be a super</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6933" target="_blank">01:55:33.360</a></span> | <span class="t">interesting thing to try out and be sure to share it with the folks on the forum. So there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6939" target="_blank">01:55:39.240</a></span> | <span class="t">a few ideas so don't let this be the end of your learning journey you know keep keep going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6945" target="_blank">01:55:45.840</a></span> | <span class="t">and then come back and try part two if it's not out yet obviously you'll have to wait</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6951" target="_blank">01:55:51.480</a></span> | <span class="t">until it is out if it but if it is out you might want to kind of spend a couple of months</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6956" target="_blank">01:55:56.960</a></span> | <span class="t">you know really experimenting with this before you move on to part two to make sure that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6961" target="_blank">01:56:01.080</a></span> | <span class="t">everything in part one feels pretty pretty solid to you. Well thank you very much everybody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6971" target="_blank">01:56:11.040</a></span> | <span class="t">for your time we've really enjoyed doing this course it's been a tough course for us to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6976" target="_blank">01:56:16.400</a></span> | <span class="t">teach because with all this COVID-19 stuff going on at the same time I'm really glad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6980" target="_blank">01:56:20.840</a></span> | <span class="t">we've got through it I'm particularly particularly grateful to Sylvain who has been extraordinary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6988" target="_blank">01:56:28.280</a></span> | <span class="t">in really making so much of this happen and particularly since I've been so busy with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=6994" target="_blank">01:56:34.080</a></span> | <span class="t">COVID-19 stuff around masks in particular it's really a lot thanks to Sylvain that everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=7001" target="_blank">01:56:41.400</a></span> | <span class="t">has come together and of course to Rachel who's been here with me on on every one of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=7007" target="_blank">01:56:47.280</a></span> | <span class="t">these lessons thank you so much and I'm looking forward to seeing you again in a future course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WjnwWeGjZcM&t=7016" target="_blank">01:56:56.200</a></span> | <span class="t">thanks everybody</span></div></div></body></html>