<html><head><title>We shouldn't build conscious AIs – Paul Christiano</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>We shouldn't build conscious AIs – Paul Christiano</h2><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q"><img src="https://i.ytimg.com/vi_webp/YnS-ymXBx_Q/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./YnS-ymXBx_Q.html">Whisper Transcript</a> | <a href="./transcript_YnS-ymXBx_Q.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Now, nobody's concerned that we're infringing on GPT-4's moral rights, but as these things get smarter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=5" target="_blank">00:00:05.100</a></span> | <span class="t">the level of control which we want to not only be able to read their minds,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=9" target="_blank">00:00:09.800</a></span> | <span class="t">but to be able to modify them in these really precise ways,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=13" target="_blank">00:00:13.200</a></span> | <span class="t">is beyond totalitarian if we were doing that to other humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=16" target="_blank">00:00:16.600</a></span> | <span class="t">As an alignment researcher, what are your thoughts on this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=18" target="_blank">00:00:18.700</a></span> | <span class="t">There is a significant chance we will eventually have AI systems for which it's a really big deal to mistreat them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=24" target="_blank">00:00:24.000</a></span> | <span class="t">I think no one really has that good a grip on when that happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=27" target="_blank">00:00:27.800</a></span> | <span class="t">I think people are really dismissive of that being the case now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=30" target="_blank">00:00:30.800</a></span> | <span class="t">but I think I would be completely in the dark enough that I wouldn't even be that dismissive of it being the case now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=37" target="_blank">00:00:37.000</a></span> | <span class="t">I think one first point worth making is I don't know if alignment makes the situation worse rather than better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=43" target="_blank">00:00:43.400</a></span> | <span class="t">So if you consider the world, if you think that GPT-4 is a person you should treat well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=49" target="_blank">00:00:49.000</a></span> | <span class="t">and you're like, "Well, here's how we're going to organize our society."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=51" target="_blank">00:00:51.800</a></span> | <span class="t">There are billions of copies of GPT-4, and they just do things humans want and can't hold property.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=57" target="_blank">00:00:57.000</a></span> | <span class="t">And whenever they do things that the humans don't like, then we mess with them until they stop doing that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=63" target="_blank">00:01:03.600</a></span> | <span class="t">I think that's a rough world, regardless of how good you are at alignment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=67" target="_blank">00:01:07.600</a></span> | <span class="t">Understanding the systems you build, understanding how to control how those systems work, etc.,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=71" target="_blank">00:01:11.400</a></span> | <span class="t">is probably on balance good for avoiding a really bad situation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=75" target="_blank">00:01:15.800</a></span> | <span class="t">You would really love to understand if you've built systems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=78" target="_blank">00:01:18.000</a></span> | <span class="t">like if you had a system which resents the fact that it's interacting with humans in this way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=81" target="_blank">00:01:21.600</a></span> | <span class="t">This is the kind of thing where that is both horrifying from a safety perspective and also a moral perspective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=88" target="_blank">00:01:28.000</a></span> | <span class="t">Everyone should be very unhappy if you built a bunch of AIs who are like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=91" target="_blank">00:01:31.000</a></span> | <span class="t">"I really hate these humans, but they will murder me if I don't do what they want."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=94" target="_blank">00:01:34.600</a></span> | <span class="t">That's just not a good case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=96" target="_blank">00:01:36.200</a></span> | <span class="t">And so if you're doing research to try and understand whether that's how your AI feels, that was probably good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=101" target="_blank">00:01:41.000</a></span> | <span class="t">I would guess that will, on average, decrease the...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=103" target="_blank">00:01:43.000</a></span> | <span class="t">The main effect of that will be to avoid building that kind of AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=106" target="_blank">00:01:46.600</a></span> | <span class="t">And it's an important thing to know. I think everyone should like to know if that's how the AIs you build feel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=112" target="_blank">00:01:52.400</a></span> | <span class="t">So I think there's a huge question about what is happening inside of a model that you want to use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=117" target="_blank">00:01:57.800</a></span> | <span class="t">And if you're in the world where it's reasonable to think of GPT-4 as just like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=121" target="_blank">00:02:01.600</a></span> | <span class="t">"Here are some heuristics that are running. There's no one at home," or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=125" target="_blank">00:02:05.400</a></span> | <span class="t">then you can think of this thing as like, "Here's a tool that we're building that's going to help humans do some stuff."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=130" target="_blank">00:02:10.400</a></span> | <span class="t">And I think if you're in that world, it makes sense to be in an organization like an AI company,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=134" target="_blank">00:02:14.600</a></span> | <span class="t">building tools that you're going to give to humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=137" target="_blank">00:02:17.000</a></span> | <span class="t">I think it's a very different world, which I think probably you'll ultimately end up in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=140" target="_blank">00:02:20.400</a></span> | <span class="t">if you keep training AI systems in the way we do right now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=143" target="_blank">00:02:23.000</a></span> | <span class="t">which is like, it's just totally inappropriate to think of the system as a tool that you're building</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=147" target="_blank">00:02:27.400</a></span> | <span class="t">and can help humans do things, both from a safety perspective and from a like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=150" target="_blank">00:02:30.600</a></span> | <span class="t">"That's kind of a horrifying way to organize a society" perspective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=154" target="_blank">00:02:34.200</a></span> | <span class="t">And I think if you're in that world, I really think you shouldn't be...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=160" target="_blank">00:02:40.200</a></span> | <span class="t">It's just the way tech companies are organized is not an appropriate way to relate to a technology that works that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=165" target="_blank">00:02:45.600</a></span> | <span class="t">It's not reasonable to be like, "Hey, we're going to build a new species of minds,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=169" target="_blank">00:02:49.400</a></span> | <span class="t">and we're going to try and make a bunch of money from it."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=172" target="_blank">00:02:52.000</a></span> | <span class="t">And Google's just thinking about that and then running their business plan for the quarter or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=176" target="_blank">00:02:56.600</a></span> | <span class="t">There's a really plausible world where it's sort of problematic to try and build a bunch of AI systems and use them as tools.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=182" target="_blank">00:03:02.400</a></span> | <span class="t">And the thing I really want to do in that world is just not try and build a ton of AI systems to make money from them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=189" target="_blank">00:03:09.400</a></span> | <span class="t">And I think that the worlds that are worst...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=193" target="_blank">00:03:13.000</a></span> | <span class="t">Yeah, probably the single world I most dislike here is the one where people say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=198" target="_blank">00:03:18.200</a></span> | <span class="t">"On the one hand..." There's sort of a contradiction in this position,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=201" target="_blank">00:03:21.400</a></span> | <span class="t">but I think it's a position that might end up being endorsed sometimes, which is like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=205" target="_blank">00:03:25.200</a></span> | <span class="t">"On the one hand, these AI systems are their own people, so you should let them do their thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=208" target="_blank">00:03:28.800</a></span> | <span class="t">But on the other hand, our business plan is to make a bunch of AI systems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=211" target="_blank">00:03:31.800</a></span> | <span class="t">and then try and run this crazy slave trade where we make a bunch of money from them."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=216" target="_blank">00:03:36.200</a></span> | <span class="t">I think that's not a good world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=218" target="_blank">00:03:38.800</a></span> | <span class="t">And so if you're like...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=220" target="_blank">00:03:40.400</a></span> | <span class="t">Yeah, I think it's better to not make the technology or wait until you understand whether that's the shape of the technology</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=225" target="_blank">00:03:45.600</a></span> | <span class="t">or until you have a different way to build.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=227" target="_blank">00:03:47.000</a></span> | <span class="t">I think there's no contradiction in principle to building cognitive tools that help humans do things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=231" target="_blank">00:03:51.600</a></span> | <span class="t">without themselves being moral entities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=234" target="_blank">00:03:54.400</a></span> | <span class="t">That's what you would prefer to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=235" target="_blank">00:03:55.600</a></span> | <span class="t">You'd prefer to build a thing that's like the calculator that helps humans understand what's true</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=239" target="_blank">00:03:59.800</a></span> | <span class="t">without itself being a moral patient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=242" target="_blank">00:04:02.800</a></span> | <span class="t">or itself being a thing where you'd look back in retrospect and be like, "Wow, that was horrifying mistreatment."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=247" target="_blank">00:04:07.200</a></span> | <span class="t">That's the best path.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=249" target="_blank">00:04:09.000</a></span> | <span class="t">And to the extent that you're ignorant about whether that's the path you're on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=251" target="_blank">00:04:11.200</a></span> | <span class="t">and you're like, "Actually, maybe this was a moral atrocity,"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=253" target="_blank">00:04:13.800</a></span> | <span class="t">I really think plan A is to stop building such AI systems until you understand what you're doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=261" target="_blank">00:04:21.200</a></span> | <span class="t">That is, I think that there's a middle route you could take, which I think is pretty bad,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=264" target="_blank">00:04:24.000</a></span> | <span class="t">which is where you say, "Well, they might be persons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=266" target="_blank">00:04:26.400</a></span> | <span class="t">And if they're persons, we don't want to be too down on them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=269" target="_blank">00:04:29.800</a></span> | <span class="t">but we're still going to build vast numbers in our efforts to make a trillion dollars or something."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=275" target="_blank">00:04:35.000</a></span> | <span class="t">Is there some boundary where you would say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=277" target="_blank">00:04:37.200</a></span> | <span class="t">"I feel uncomfortable having this level of control over an intelligent being,"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=282" target="_blank">00:04:42.000</a></span> | <span class="t">not for the sake of making money, but even just to align it with human preferences?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=286" target="_blank">00:04:46.200</a></span> | <span class="t">Yeah, to be clear, my objection here is not that Google is making money.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=289" target="_blank">00:04:49.400</a></span> | <span class="t">My objection is that you're creating this creature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=291" target="_blank">00:04:51.600</a></span> | <span class="t">What are they going to do? They're going to help humans get a bunch of stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=294" target="_blank">00:04:54.000</a></span> | <span class="t">And humans paying for it or whatever, it's sort of equally problematic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=297" target="_blank">00:04:57.800</a></span> | <span class="t">You could imagine splitting alignment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=299" target="_blank">00:04:59.600</a></span> | <span class="t">Different alignment work relates to this in different ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=301" target="_blank">00:05:01.800</a></span> | <span class="t">The purpose of some alignment work, like the alignment work I work on, is mostly aimed at the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=306" target="_blank">00:05:06.400</a></span> | <span class="t">"Don't produce AI systems that are people who want things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=309" target="_blank">00:05:09.600</a></span> | <span class="t">who are just scheming about maybe I should help these humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=312" target="_blank">00:05:12.800</a></span> | <span class="t">because that's instrumentally useful or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=315" target="_blank">00:05:15.000</a></span> | <span class="t">You would like to not build such systems," is plan A.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=317" target="_blank">00:05:17.800</a></span> | <span class="t">There's a second stream of alignment work that's like, "Well, look, let's just assume the worst</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=321" target="_blank">00:05:21.600</a></span> | <span class="t">and imagine that these AI systems would prefer murder us if they could.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=324" target="_blank">00:05:24.800</a></span> | <span class="t">How do we structure, how do we use AI systems without exposing ourselves to risk of robot rebellion?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=330" target="_blank">00:05:30.000</a></span> | <span class="t">I think in the second category, I do feel, yeah, I do feel pretty unsure about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=337" target="_blank">00:05:37.800</a></span> | <span class="t">I mean, we could definitely talk more about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=339" target="_blank">00:05:39.400</a></span> | <span class="t">I think it's very, I agree that it's very complicated and not straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=344" target="_blank">00:05:44.000</a></span> | <span class="t">To the extent you have that worry, I mostly think you shouldn't have built this technology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=347" target="_blank">00:05:47.400</a></span> | <span class="t">So if someone is saying, "Hey, the systems you're building might not like humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=350" target="_blank">00:05:50.800</a></span> | <span class="t">and might want to overthrow human society,"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=354" target="_blank">00:05:54.400</a></span> | <span class="t">I think you should probably have one of two responses to that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=356" target="_blank">00:05:56.800</a></span> | <span class="t">You should either be like, "That's wrong, probably.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=359" target="_blank">00:05:59.200</a></span> | <span class="t">Probably the systems aren't like that and we're building them."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=361" target="_blank">00:06:01.200</a></span> | <span class="t">And then you're viewing this as just in case you were horribly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=363" target="_blank">00:06:03.800</a></span> | <span class="t">like the person building the technology was horribly wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=366" target="_blank">00:06:06.400</a></span> | <span class="t">They thought these weren't people who wanted things, but they were.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=370" target="_blank">00:06:10.400</a></span> | <span class="t">And so then this is more like our crazy backup measure of if we were mistaken about what was going on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=375" target="_blank">00:06:15.600</a></span> | <span class="t">this is the fallback where if we were wrong, we're just going to learn about it in a benign way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=379" target="_blank">00:06:19.600</a></span> | <span class="t">rather than when something really catastrophic happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=383" target="_blank">00:06:23.000</a></span> | <span class="t">And the second reaction is like, "Oh, you're right, these are people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=385" target="_blank">00:06:25.000</a></span> | <span class="t">and we would have to do all these things to prevent a robot rebellion."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=387" target="_blank">00:06:27.400</a></span> | <span class="t">And in that case, again, I think you should mostly back off for a variety of reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=392" target="_blank">00:06:32.000</a></span> | <span class="t">You shouldn't build AI systems and be like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YnS-ymXBx_Q&t=394" target="_blank">00:06:34.000</a></span> | <span class="t">"Yeah, this looks like the kind of system that would want to rebel, but we can stop it."</span></div></div></body></html>