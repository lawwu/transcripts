<html><head><title>Scaling LLMs further is an artform - Demis Hassabis (Google DeepMind CEO)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Scaling LLMs further is an artform - Demis Hassabis (Google DeepMind CEO)</h2><a href="https://www.youtube.com/watch?v=666XgM38jJE"><img src="https://i.ytimg.com/vi_webp/666XgM38jJE/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=0">0:0</a> Scaling LLMs<br><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=96">1:36</a> Predicting training loss<br><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=171">2:51</a> Biggest surprise<br><br><div style="text-align: left;"><a href="./666XgM38jJE.html">Whisper Transcript</a> | <a href="./transcript_666XgM38jJE.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Going back to Gemini, I'm curious what the bottlenecks were in the development.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=4" target="_blank">00:00:04.160</a></span> | <span class="t">Like, why not make it immediately one order of magnitude bigger?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=7" target="_blank">00:00:07.120</a></span> | <span class="t">Well, look, first of all, there are practical limits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=9" target="_blank">00:00:09.280</a></span> | <span class="t">How much compute can you actually fit in one data center?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=12" target="_blank">00:00:12.640</a></span> | <span class="t">And actually, you know, you're bumping up against very interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=16" target="_blank">00:00:16.160</a></span> | <span class="t">distributed computing kind of challenges, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=18" target="_blank">00:00:18.560</a></span> | <span class="t">Fortunately, we have some of the best people in the world on those challenges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=21" target="_blank">00:00:21.440</a></span> | <span class="t">And, you know, cross data center training, all these kinds of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=25" target="_blank">00:00:25.040</a></span> | <span class="t">Very interesting challenges, hardware challenges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=26" target="_blank">00:00:26.880</a></span> | <span class="t">And we have our TPUs and so on that we're building and designing all the time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=30" target="_blank">00:00:30.720</a></span> | <span class="t">as well as using GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=32" target="_blank">00:00:32.320</a></span> | <span class="t">And so there's all of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=34" target="_blank">00:00:34.640</a></span> | <span class="t">And then you also have to, the scaling laws, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=37" target="_blank">00:00:37.520</a></span> | <span class="t">they don't just work by magic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=39" target="_blank">00:00:39.040</a></span> | <span class="t">You sort of, you still need to scale up the hyperparameters and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=42" target="_blank">00:00:42.320</a></span> | <span class="t">various innovations are going in all the time with each new scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=45" target="_blank">00:00:45.120</a></span> | <span class="t">It's not just about repeating the same recipe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=47" target="_blank">00:00:47.760</a></span> | <span class="t">At each new scale, you have to adjust the recipe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=50" target="_blank">00:00:50.320</a></span> | <span class="t">And that's a bit of an art form in a way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=52" target="_blank">00:00:52.720</a></span> | <span class="t">And you have to sort of almost get new data points.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=55" target="_blank">00:00:55.120</a></span> | <span class="t">If you try and extend your predictions, extrapolate them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=58" target="_blank">00:00:58.400</a></span> | <span class="t">say several orders of magnitude out, sometimes they don't hold anymore, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=62" target="_blank">00:01:02.240</a></span> | <span class="t">Because new capabilities, they can be step functions in terms of new capabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=67" target="_blank">00:01:07.280</a></span> | <span class="t">And some things hold and other things don't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=71" target="_blank">00:01:11.040</a></span> | <span class="t">So often you do need those intermediate data points actually to correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=75" target="_blank">00:01:15.600</a></span> | <span class="t">some of your hyperparameter optimization and other things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=78" target="_blank">00:01:18.720</a></span> | <span class="t">So the scaling law continues to be true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=82" target="_blank">00:01:22.960</a></span> | <span class="t">So there's sort of various practical limitations onto that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=86" target="_blank">00:01:26.480</a></span> | <span class="t">So, you know, kind of one order of magnitude is about probably the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=90" target="_blank">00:01:30.560</a></span> | <span class="t">maximum that you want to carry on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=93" target="_blank">00:01:33.120</a></span> | <span class="t">You want to sort of do between each era.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=95" target="_blank">00:01:35.600</a></span> | <span class="t">- Oh, that's so fascinating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=97" target="_blank">00:01:37.200</a></span> | <span class="t">You know, in the GPT-4 technical report,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=98" target="_blank">00:01:38.720</a></span> | <span class="t">they say that they were able to predict the training loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=101" target="_blank">00:01:41.120</a></span> | <span class="t">you know, tens of thousands of times less compute than GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=105" target="_blank">00:01:45.680</a></span> | <span class="t">They could see the curve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=106" target="_blank">00:01:46.480</a></span> | <span class="t">But at the point you're making is that the actual capabilities that loss implies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=109" target="_blank">00:01:49.440</a></span> | <span class="t">may not be so clear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=110" target="_blank">00:01:50.800</a></span> | <span class="t">- Yeah, the downstream capabilities sometimes don't follow from the...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=113" target="_blank">00:01:53.440</a></span> | <span class="t">You can often predict the core metrics like training loss or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=117" target="_blank">00:01:57.440</a></span> | <span class="t">But then it doesn't actually translate into MMLU or math</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=121" target="_blank">00:02:01.360</a></span> | <span class="t">or some other actual capability that you care about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=124" target="_blank">00:02:04.880</a></span> | <span class="t">They're not necessarily linear all the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=127" target="_blank">00:02:07.840</a></span> | <span class="t">I think we've got to push scaling as hard as we can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=131" target="_blank">00:02:11.280</a></span> | <span class="t">And that's what we're doing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=132" target="_blank">00:02:12.640</a></span> | <span class="t">And, you know, it's an empirical question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=134" target="_blank">00:02:14.240</a></span> | <span class="t">whether that will hit an asymptote or a brick wall.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=136" target="_blank">00:02:16.960</a></span> | <span class="t">And there are, you know, different people argue about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=139" target="_blank">00:02:19.280</a></span> | <span class="t">But actually, I think we should just test it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=140" target="_blank">00:02:20.880</a></span> | <span class="t">I think no one knows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=141" target="_blank">00:02:21.840</a></span> | <span class="t">But in the meantime, we should also double down on innovation and invention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=148" target="_blank">00:02:28.000</a></span> | <span class="t">And this is something that Google Research and DeepMind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=151" target="_blank">00:02:31.360</a></span> | <span class="t">and Google Brain have, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=153" target="_blank">00:02:33.840</a></span> | <span class="t">we've pioneered many, many things over the last decade.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=156" target="_blank">00:02:36.000</a></span> | <span class="t">That's something that's our bread and butter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=157" target="_blank">00:02:37.840</a></span> | <span class="t">And, you know, you can think of half our effort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=160" target="_blank">00:02:40.480</a></span> | <span class="t">is to do with scaling and half our effort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=162" target="_blank">00:02:42.160</a></span> | <span class="t">is to do with inventing the next architectures,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=164" target="_blank">00:02:44.960</a></span> | <span class="t">the next algorithms that will be needed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=167" target="_blank">00:02:47.280</a></span> | <span class="t">Knowing that you've got this scaled, larger and larger model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=170" target="_blank">00:02:50.160</a></span> | <span class="t">coming along the lines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=171" target="_blank">00:02:51.120</a></span> | <span class="t">- What's been the biggest surprise to you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=173" target="_blank">00:02:53.120</a></span> | <span class="t">if you go back to yourself in 2010,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=175" target="_blank">00:02:55.520</a></span> | <span class="t">when you were starting DeepMind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=176" target="_blank">00:02:56.640</a></span> | <span class="t">in terms of what AI progress has looked like?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=178" target="_blank">00:02:58.640</a></span> | <span class="t">Did you anticipate back then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=180" target="_blank">00:03:00.000</a></span> | <span class="t">that it would in some large sense amount to spend,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=182" target="_blank">00:03:02.720</a></span> | <span class="t">you know, dumping billions of dollars into these models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=184" target="_blank">00:03:04.480</a></span> | <span class="t">Or did you have a different sense of what it would look like?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=185" target="_blank">00:03:05.920</a></span> | <span class="t">- We thought that, and actually, you know, if you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=187" target="_blank">00:03:07.760</a></span> | <span class="t">I know you've interviewed my colleague, Shane,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=189" target="_blank">00:03:09.760</a></span> | <span class="t">and he always thought that in terms of like compute curves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=194" target="_blank">00:03:14.640</a></span> | <span class="t">and then maybe comparing roughly to like the brain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=197" target="_blank">00:03:17.360</a></span> | <span class="t">and how many neurons and synapses there are very loosely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=199" target="_blank">00:03:19.840</a></span> | <span class="t">But we're actually, interestingly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=201" target="_blank">00:03:21.360</a></span> | <span class="t">in that kind of regime now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=202" target="_blank">00:03:22.560</a></span> | <span class="t">roughly in the right order of magnitude of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=204" target="_blank">00:03:24.560</a></span> | <span class="t">you know, number of synapses in the brain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=206" target="_blank">00:03:26.160</a></span> | <span class="t">and the sort of compute that we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=208" target="_blank">00:03:28.720</a></span> | <span class="t">But I think more fundamentally, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=210" target="_blank">00:03:30.960</a></span> | <span class="t">we always thought that we bet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=213" target="_blank">00:03:33.360</a></span> | <span class="t">on generality and learning, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=216" target="_blank">00:03:36.320</a></span> | <span class="t">So those were always at the core</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=218" target="_blank">00:03:38.320</a></span> | <span class="t">of any technique we would use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=219" target="_blank">00:03:39.760</a></span> | <span class="t">That's why we triangulated on reinforcement learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=222" target="_blank">00:03:42.000</a></span> | <span class="t">and search and deep learning, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=224" target="_blank">00:03:44.800</a></span> | <span class="t">As three types of algorithms that would scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=228" target="_blank">00:03:48.800</a></span> | <span class="t">and would be very general</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=231" target="_blank">00:03:51.600</a></span> | <span class="t">and not require a lot of handcrafted human priors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=235" target="_blank">00:03:55.040</a></span> | <span class="t">which we thought was the sort of failure mode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=237" target="_blank">00:03:57.280</a></span> | <span class="t">really of the efforts to build AI in the '90s, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=240" target="_blank">00:04:00.960</a></span> | <span class="t">Places like MIT where there were very, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=243" target="_blank">00:04:03.520</a></span> | <span class="t">logic-based systems, expert systems, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=246" target="_blank">00:04:06.240</a></span> | <span class="t">masses of hand-coded, handcrafted human information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=249" target="_blank">00:04:09.520</a></span> | <span class="t">going into that turned out to be wrong</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=251" target="_blank">00:04:11.040</a></span> | <span class="t">or too rigid.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=252" target="_blank">00:04:12.400</a></span> | <span class="t">So we wanted to move away from that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=253" target="_blank">00:04:13.920</a></span> | <span class="t">I think we spotted that trend early</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=255" target="_blank">00:04:15.840</a></span> | <span class="t">and, you know, and obviously we use games</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=258" target="_blank">00:04:18.800</a></span> | <span class="t">as our proving ground and we did very well with that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=261" target="_blank">00:04:21.120</a></span> | <span class="t">You know, things like AlphaGo, I think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=262" target="_blank">00:04:22.320</a></span> | <span class="t">was a big moment for inspiring many others to think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=264" target="_blank">00:04:24.960</a></span> | <span class="t">"Oh, actually these systems are ready to scale."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=267" target="_blank">00:04:27.680</a></span> | <span class="t">And then of course, with the advent of transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=269" target="_blank">00:04:29.840</a></span> | <span class="t">invented by our colleagues at Google,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=271" target="_blank">00:04:31.280</a></span> | <span class="t">you know, research and brain,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=272" target="_blank">00:04:32.800</a></span> | <span class="t">that was then, you know, the type of deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=276" target="_blank">00:04:36.000</a></span> | <span class="t">that allowed us to ingest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=277" target="_blank">00:04:37.280</a></span> | <span class="t">masses of amounts of information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=279" target="_blank">00:04:39.760</a></span> | <span class="t">And that, of course, has really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=281" target="_blank">00:04:41.520</a></span> | <span class="t">turbocharged where we are today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=282" target="_blank">00:04:42.960</a></span> | <span class="t">So I think that's all part of the same lineage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=284" target="_blank">00:04:44.880</a></span> | <span class="t">You know, we couldn't have predicted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=286" target="_blank">00:04:46.880</a></span> | <span class="t">every twist and turn there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=666XgM38jJE&t=287" target="_blank">00:04:47.920</a></span> | <span class="t">but I think the general direction we were going in</span></div></div></body></html>