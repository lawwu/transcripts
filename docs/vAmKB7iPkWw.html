<html><head><title>Coding a Multimodal (Vision) Language Model from scratch in PyTorch with full explanation</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Coding a Multimodal (Vision) Language Model from scratch in PyTorch with full explanation</h2><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw"><img src="https://i.ytimg.com/vi/vAmKB7iPkWw/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=352">5:52</a> Contrastive Learning and CLIP<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1010">16:50</a> Numerical stability of the Softmax<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1380">23:0</a> SigLip<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1590">26:30</a> Why a Contrastive Vision Encoder?<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1753">29:13</a> Vision Transformer<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2138">35:38</a> Coding SigLip<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3265">54:25</a> Batch Normalization, Layer Normalization<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3928">65:28</a> Coding SigLip (Encoder)<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4572">76:12</a> Coding SigLip (FFN)<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4845">80:45</a> Multi-Head Attention (Coding + Explanation)<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8140">135:40</a> Coding SigLip<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8310">138:30</a> PaliGemma Architecture review<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8479">141:19</a> PaliGemma input processor<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9656">160:56</a> Coding Gemma<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9824">163:44</a> Weight tying<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9980">166:20</a> Coding Gemma<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11334">188:54</a> KV-Cache (Explanation)<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12815">213:35</a> Coding Gemma<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13925">232:5</a> Image features projection<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13997">233:17</a> Coding Gemma<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14565">242:45</a> RMS Normalization<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14990">249:50</a> Gemma Decoder Layer<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15164">252:44</a> Gemma FFN (MLP)<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15362">256:2</a> Multi-Head Attention (Coding)<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15510">258:30</a> Grouped Query Attention<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16715">278:35</a> Multi-Head Attention (Coding)<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17006">283:26</a> KV-Cache (Coding)<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17264">287:44</a> Multi-Head Attention (Coding)<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17760">296:0</a> Rotary Positional Embedding<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19420">323:40</a> Inference code<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19970">332:50</a> Top-P Sampling<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20440">340:40</a> Inference code<br><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20620">343:40</a> Conclusion<br><br><div style="text-align: left;"><a href="./vAmKB7iPkWw.html">Whisper Transcript</a> | <a href="./transcript_vAmKB7iPkWw.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hello guys, welcome back to my channel today. We are going to code a visual language model from scratch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4" target="_blank">00:00:04.720</a></span> | <span class="t">Now, what do I mean by first of all by visual language model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8" target="_blank">00:00:08.000</a></span> | <span class="t">And what do I mean for by coding from scratch?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10" target="_blank">00:00:10.240</a></span> | <span class="t">The visual language model that we will be coding is called the polygamma and it's a language model visual language model that came out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16" target="_blank">00:00:16.640</a></span> | <span class="t">From google around two months ago</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18" target="_blank">00:00:18.960</a></span> | <span class="t">About the weights, but the paper came out around two weeks ago</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=22" target="_blank">00:00:22.960</a></span> | <span class="t">So we will be coding it from scratch meaning that we will be coding from scratch the vision encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=29" target="_blank">00:00:29.360</a></span> | <span class="t">You can see this here. Okay the linear projection, which is just a linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=32" target="_blank">00:00:32.560</a></span> | <span class="t">Layer the language model itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=35" target="_blank">00:00:35.680</a></span> | <span class="t">So which is the transformer language model how to combine the embeddings of the image tokens with the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=42" target="_blank">00:00:42.160</a></span> | <span class="t">And of course how to generate the output using the condition. So what is the language visual language model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=48" target="_blank">00:00:48.160</a></span> | <span class="t">First of all, well visual language model is a language model that can extract information from an image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=52" target="_blank">00:00:52.960</a></span> | <span class="t">So if we have an image like this, for example and a prompt like this, for example, where is the photographer resting?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=59" target="_blank">00:00:59.120</a></span> | <span class="t">The visual language model can understand where this photographer is resting by looking at the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=64" target="_blank">00:01:04.640</a></span> | <span class="t">And generating a response in this case. The response is in a hammock under a tree on a tropical beach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=70" target="_blank">00:01:10.080</a></span> | <span class="t">The topics of today basically are first of all, we will be talking about the vision transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=75" target="_blank">00:01:15.760</a></span> | <span class="t">Which is the vision encoder that we'll be using to extract information from this image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=79" target="_blank">00:01:19.760</a></span> | <span class="t">But this vision transformer has been trained in a particular way called contrastive learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=85" target="_blank">00:01:25.280</a></span> | <span class="t">So we will be talking about a lot about contrastive learning because I want to review not only what is contrastive learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=90" target="_blank">00:01:30.320</a></span> | <span class="t">But also the history of how it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=92" target="_blank">00:01:32.400</a></span> | <span class="t">So the first well-known model is CLIP and then it was transformed into CGLIP by google</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=97" target="_blank">00:01:37.760</a></span> | <span class="t">So we will be seeing these two models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=100" target="_blank">00:01:40.480</a></span> | <span class="t">Then we will be coding the language model itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=103" target="_blank">00:01:43.040</a></span> | <span class="t">So the gamma language model how to combine the embeddings of the vision model and the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=109" target="_blank">00:01:49.600</a></span> | <span class="t">But this one we'll do it in code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=112" target="_blank">00:01:52.640</a></span> | <span class="t">And we will be talking about the KVCache because we want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=115" target="_blank">00:01:55.600</a></span> | <span class="t">Use this language model for inferences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=118" target="_blank">00:01:58.320</a></span> | <span class="t">So we want to do it in an optimized way and the best way of course is to use the KVCache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=123" target="_blank">00:02:03.200</a></span> | <span class="t">So we will be coding it from scratch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=125" target="_blank">00:02:05.200</a></span> | <span class="t">Not only we will be coding it. I will explain step by step how it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=128" target="_blank">00:02:08.800</a></span> | <span class="t">The rotary positional encodings because we need them for the language model and the normalization layers because we have them in the vision model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=135" target="_blank">00:02:15.760</a></span> | <span class="t">And also the language model. We will be seeing what is the batch normalization, the layer normalization and the rms normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=141" target="_blank">00:02:21.520</a></span> | <span class="t">I will be explaining all the math behind them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=143" target="_blank">00:02:23.520</a></span> | <span class="t">In this video i'm also using a slightly different approach at teaching let's say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=148" target="_blank">00:02:28.640</a></span> | <span class="t">Which is by drawing so I will be drawing every single tensor operations that we'll be doing especially in the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=154" target="_blank">00:02:34.800</a></span> | <span class="t">Mechanism because I want people to not only look at the code and hope they get something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=159" target="_blank">00:02:39.520</a></span> | <span class="t">Like an idea of how it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=161" target="_blank">00:02:41.920</a></span> | <span class="t">But actually I want to show each single tensor how it's changing by drawing it from scratch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=168" target="_blank">00:02:48.640</a></span> | <span class="t">I think this helps better visualize what happens in the transformer model, especially during the attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=174" target="_blank">00:02:54.340</a></span> | <span class="t">So we know what each view operation each reshape operation that we are doing to each tensor and also the matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=181" target="_blank">00:03:01.360</a></span> | <span class="t">Multiplications that we are doing so we can visualize what happens to the tensors itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=185" target="_blank">00:03:05.680</a></span> | <span class="t">What are the prerequisites for watching this video?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=189" target="_blank">00:03:09.120</a></span> | <span class="t">Well, you have a basic knowledge about the transformer. You don't have to be a master about it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=194" target="_blank">00:03:14.880</a></span> | <span class="t">It's better if you have watched my previous video on it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=196" target="_blank">00:03:16.960</a></span> | <span class="t">Which will give you the background knowledge to understand this video and you have a basic knowledge of neural networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=202" target="_blank">00:03:22.320</a></span> | <span class="t">So at least you know, what is a loss function, you know, what is a linear layer?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=205" target="_blank">00:03:25.440</a></span> | <span class="t">And at least you know, what is backpropagation you don't need to know how it works or the mathematics behind it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=212" target="_blank">00:03:32.560</a></span> | <span class="t">But at least you know that we train models using backpropagation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=215" target="_blank">00:03:35.460</a></span> | <span class="t">Having said that guys, let's jump to work. So the first part I will be explaining is the visual transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=224" target="_blank">00:03:44.160</a></span> | <span class="t">So this visual encoder we will be seeing what is the contrastive about it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=227" target="_blank">00:03:47.840</a></span> | <span class="t">and we will be coding it and then we will move on to how to combine the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=232" target="_blank">00:03:52.960</a></span> | <span class="t">Embeddings of the image tokens and the text tokens. The only part that we will not be coding is the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=239" target="_blank">00:03:59.700</a></span> | <span class="t">Because I believe it's a separate topic that deserves its own video. So hopefully I will make another video about it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=245" target="_blank">00:04:05.760</a></span> | <span class="t">So let's start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=248" target="_blank">00:04:08.160</a></span> | <span class="t">All right guys before we go deep into each of these topics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=252" target="_blank">00:04:12.080</a></span> | <span class="t">Let me give you a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=254" target="_blank">00:04:14.800</a></span> | <span class="t">Speech actually, so we will be exploring a lot of topics like a lot of topics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=260" target="_blank">00:04:20.800</a></span> | <span class="t">We will be reviewing for example each of the single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=263" target="_blank">00:04:23.600</a></span> | <span class="t">Operations that we do in the attention mechanism and we will be looking at it from the code point of view</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=268" target="_blank">00:04:28.880</a></span> | <span class="t">But also from the concept point of view and from the tensor operations point of view</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=274" target="_blank">00:04:34.640</a></span> | <span class="t">There may be some topics that you are already familiar with and that's perfectly fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=279" target="_blank">00:04:39.120</a></span> | <span class="t">There are some others that you are not familiar with and that's also perfectly fine because I will be explaining each topic multiple times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=285" target="_blank">00:04:45.760</a></span> | <span class="t">So for example, we will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=288" target="_blank">00:04:48.320</a></span> | <span class="t">Implementing the attention mechanism at least twice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=290" target="_blank">00:04:50.960</a></span> | <span class="t">So if you don't understand it the first time along with the code, then you will have another time to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=296" target="_blank">00:04:56.080</a></span> | <span class="t">Understand it and with a different explanation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=299" target="_blank">00:04:59.520</a></span> | <span class="t">And the same more or less goes goes on with all the other topics. For example, we will be first introducing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=304" target="_blank">00:05:04.880</a></span> | <span class="t">Normalization in one part and then I will review again the normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=309" target="_blank">00:05:09.140</a></span> | <span class="t">The positional encoding done in one way and then we will see another type of positional encoding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=313" target="_blank">00:05:13.760</a></span> | <span class="t">So don't worry if you don't understand everything at the beginning because I will be reviewing anyway each topic multiple times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=321" target="_blank">00:05:21.360</a></span> | <span class="t">The important thing is you don't give up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=323" target="_blank">00:05:23.600</a></span> | <span class="t">So if there is some topic that I couldn't explain because of lack of time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=327" target="_blank">00:05:27.200</a></span> | <span class="t">For example, I will not be explaining how convolutions work because there are plenty of videos on how convolutions work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=332" target="_blank">00:05:32.480</a></span> | <span class="t">So if you can pause the video watch five minute video on how a convolution work and then come back to this video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=338" target="_blank">00:05:38.400</a></span> | <span class="t">That's the best approach I recommend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=340" target="_blank">00:05:40.560</a></span> | <span class="t">The second thing is always write down all the code that I am I will be showing you so write it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=346" target="_blank">00:05:46.400</a></span> | <span class="t">Line by line character by character because that's the best way to learn. So now let's get started</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=352" target="_blank">00:05:52.880</a></span> | <span class="t">Let's start with the first part. So the first part we will be talking about is this contrastive vision encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=358" target="_blank">00:05:58.400</a></span> | <span class="t">Which is something that takes any as input an image and converts it into an embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=363" target="_blank">00:06:03.700</a></span> | <span class="t">Actually a series of embedding. We will see one for each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=367" target="_blank">00:06:07.360</a></span> | <span class="t">Block of pixels of this image. So basically our image will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=372" target="_blank">00:06:12.320</a></span> | <span class="t">Split into blocks of pixels like this into a grid and each of this grid will be converted into an embedding you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=382" target="_blank">00:06:22.640</a></span> | <span class="t">This embedding is a vector of a fixed size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=385" target="_blank">00:06:25.840</a></span> | <span class="t">and that will be concatenated with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=389" target="_blank">00:06:29.040</a></span> | <span class="t">Tokens embeddings because as you know, each token is converted into what is known as an embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=395" target="_blank">00:06:35.040</a></span> | <span class="t">Which is a vector of a fixed size. They will be concatenated and sent to the transformer which will basically attend to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=401" target="_blank">00:06:41.520</a></span> | <span class="t">Image tokens as a condition to generate the text. So this is called conditional generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=408" target="_blank">00:06:48.800</a></span> | <span class="t">But okay, we will explore all this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=411" target="_blank">00:06:51.760</a></span> | <span class="t">Let's talk about this vision encoder now the vision encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=415" target="_blank">00:06:55.200</a></span> | <span class="t">First we need to understand what is why it's called a contrastive vision encoder and to understand why it's contrastive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=422" target="_blank">00:07:02.160</a></span> | <span class="t">We need to understand what is contrastive learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=424" target="_blank">00:07:04.240</a></span> | <span class="t">So let's go back to another slide, which is this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=428" target="_blank">00:07:08.720</a></span> | <span class="t">Let's go here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=431" target="_blank">00:07:11.920</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=433" target="_blank">00:07:13.600</a></span> | <span class="t">Imagine for now, we will consider the image encoder as a black box and later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=437" target="_blank">00:07:17.840</a></span> | <span class="t">We will transform this black box into something more concrete</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=440" target="_blank">00:07:20.740</a></span> | <span class="t">now imagine that you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=443" target="_blank">00:07:23.600</a></span> | <span class="t">You go to the internet and when you go on wikipedia</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=446" target="_blank">00:07:26.260</a></span> | <span class="t">You see an image and when you see an image there is always a description of what is inside that image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=451" target="_blank">00:07:31.680</a></span> | <span class="t">If you use a crawler you can crawl all of these images with the corresponding descriptions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=457" target="_blank">00:07:37.460</a></span> | <span class="t">That in this will produce a data set of images along with the descriptions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=462" target="_blank">00:07:42.560</a></span> | <span class="t">Now imagine that for some now for now imagine we have a text encoder that is most usually is a transformer model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=470" target="_blank">00:07:50.400</a></span> | <span class="t">And then we have an image encoder which most of the cases it's a vision transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=475" target="_blank">00:07:55.300</a></span> | <span class="t">And for now, we consider them as black boxes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=478" target="_blank">00:07:58.560</a></span> | <span class="t">So it's something that takes as input an image and produces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=481" target="_blank">00:08:01.940</a></span> | <span class="t">Here an image and produces an embedding representation of this image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=487" target="_blank">00:08:07.040</a></span> | <span class="t">And if you feed a list of images, it produces a list of embeddings one corresponding to each image. What is this embedding?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=493" target="_blank">00:08:13.920</a></span> | <span class="t">It's a vector that captures most of the information of this image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=497" target="_blank">00:08:17.600</a></span> | <span class="t">And we do the same with this text encoder. So the text encoder is a transformer model that produces a series of embeddings. We will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=504" target="_blank">00:08:24.240</a></span> | <span class="t">We'll see later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=507" target="_blank">00:08:27.120</a></span> | <span class="t">But imagine you have this text encoder that given a text produces a single embedding of a single text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=513" target="_blank">00:08:33.040</a></span> | <span class="t">But if you feed it a list of text it will produce a series of embeddings each corresponding to one single text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=519" target="_blank">00:08:39.280</a></span> | <span class="t">now imagine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=522" target="_blank">00:08:42.240</a></span> | <span class="t">The data set that we were talking about before which is the data set of images along with the corresponding descriptions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=528" target="_blank">00:08:48.420</a></span> | <span class="t">So imagine we feed this data set of images along with the corresponding description to the image encoder and respectively to the text encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=537" target="_blank">00:08:57.520</a></span> | <span class="t">It will produce a list of image embeddings and a list of text embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=542" target="_blank">00:09:02.580</a></span> | <span class="t">Now, what do we want these embeddings to be? Of course, we want the embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=548" target="_blank">00:09:08.980</a></span> | <span class="t">Of the first image to be representative of that image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=552" target="_blank">00:09:12.740</a></span> | <span class="t">So we want this embedding to capture most of the information of that image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=556" target="_blank">00:09:16.500</a></span> | <span class="t">and of course, we want the embedding of the text number one to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=560" target="_blank">00:09:20.180</a></span> | <span class="t">A vector that captures most of the information about that text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=566" target="_blank">00:09:26.560</a></span> | <span class="t">Moreover with contrastive learning we don't want only to capture information about the image or the text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=573" target="_blank">00:09:33.200</a></span> | <span class="t">But we also want some properties and the property that we want from these embeddings is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=578" target="_blank">00:09:38.400</a></span> | <span class="t">We want the embedding of each image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=582" target="_blank">00:09:42.000</a></span> | <span class="t">when its dot product with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=585" target="_blank">00:09:45.520</a></span> | <span class="t">Embedding of the corresponding text it should give a high value for this dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=591" target="_blank">00:09:51.840</a></span> | <span class="t">And when you do the dot product of an image with a text that is not the corresponding one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=596" target="_blank">00:09:56.880</a></span> | <span class="t">It should produce a low number for this dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=599" target="_blank">00:09:59.520</a></span> | <span class="t">So basically with contrastive learning what we do we take a list of images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=604" target="_blank">00:10:04.320</a></span> | <span class="t">We take a list of text which is the corresponding text one for each of these images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=608" target="_blank">00:10:08.880</a></span> | <span class="t">So imagine that the image number one correspond to the text number one the image number two correspond to the text number two, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=614" target="_blank">00:10:14.560</a></span> | <span class="t">etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=616" target="_blank">00:10:16.400</a></span> | <span class="t">We encode them into a list of embeddings and then we want to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=620" target="_blank">00:10:20.800</a></span> | <span class="t">This model so this text encoder and this image encoder to produce embeddings in such a way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=626" target="_blank">00:10:26.880</a></span> | <span class="t">That when the dot product of the image with its corresponding text is done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=631" target="_blank">00:10:31.600</a></span> | <span class="t">It should produce a high value and when you do the dot product of an image with a not corresponding text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=636" target="_blank">00:10:36.960</a></span> | <span class="t">For example i2 with text3 it should produce a low value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=640" target="_blank">00:10:40.800</a></span> | <span class="t">now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=642" target="_blank">00:10:42.640</a></span> | <span class="t">What we can do is basically we take this text embeddings, which is a list of embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=647" target="_blank">00:10:47.520</a></span> | <span class="t">We take this image embeddings, which is a list of vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=650" target="_blank">00:10:50.660</a></span> | <span class="t">We do all the possible combinations of dot products</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=653" target="_blank">00:10:53.680</a></span> | <span class="t">So the image number one did with the text number one image number one with the text number two image number one with the text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=658" target="_blank">00:10:58.800</a></span> | <span class="t">Number three, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=660" target="_blank">00:11:00.480</a></span> | <span class="t">Then we do the all the also for the text number one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=663" target="_blank">00:11:03.520</a></span> | <span class="t">So the text number one with the image number one text number one with the image number two text number one with the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=668" target="_blank">00:11:08.320</a></span> | <span class="t">Number three, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=670" target="_blank">00:11:10.240</a></span> | <span class="t">And then we want to find a loss function that forces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=673" target="_blank">00:11:13.520</a></span> | <span class="t">These dot products to be high so that each text with its corresponding image to be high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=678" target="_blank">00:11:18.880</a></span> | <span class="t">While all the other possible combinations to be low in value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=682" target="_blank">00:11:22.560</a></span> | <span class="t">And we do that basically by using what is known as a cross entropy loss. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=689" target="_blank">00:11:29.120</a></span> | <span class="t">To understand why we use cross entropy loss. We need to explore how language models are trained and we will do that very briefly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=696" target="_blank">00:11:36.480</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=698" target="_blank">00:11:38.160</a></span> | <span class="t">To not get us confused. So when we train language model, we do the we do so using what is known as the next token prediction task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=705" target="_blank">00:11:45.680</a></span> | <span class="t">Imagine we want to train a language model on the following sentence. So I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=709" target="_blank">00:11:49.920</a></span> | <span class="t">love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=712" target="_blank">00:11:52.560</a></span> | <span class="t">pepperoni pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=714" target="_blank">00:11:54.560</a></span> | <span class="t">Pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=718" target="_blank">00:11:58.480</a></span> | <span class="t">How do we train such a language model? Well, we give a prompt to this language model for now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=723" target="_blank">00:12:03.200</a></span> | <span class="t">Let's consider it as a black box. So I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=726" target="_blank">00:12:06.240</a></span> | <span class="t">love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=728" target="_blank">00:12:08.240</a></span> | <span class="t">I love pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=730" target="_blank">00:12:10.420</a></span> | <span class="t">We feed it to the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=735" target="_blank">00:12:15.760</a></span> | <span class="t">The language model will produce a series of embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=738" target="_blank">00:12:18.580</a></span> | <span class="t">Which are then converted into logits. So what is the logits? The logits is a distribution. It's a vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=745" target="_blank">00:12:25.440</a></span> | <span class="t">that tells</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=747" target="_blank">00:12:27.200</a></span> | <span class="t">What is the score that the language model has assigned to what the next token should be?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=752" target="_blank">00:12:32.560</a></span> | <span class="t">Among all the tokens in the vocabulary. So for example, imagine this first number here corresponds to the token. Hello</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=759" target="_blank">00:12:39.280</a></span> | <span class="t">the second token here corresponds to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=763" target="_blank">00:12:43.120</a></span> | <span class="t">The second number here corresponds to the token. Let's say pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=766" target="_blank">00:12:46.640</a></span> | <span class="t">The third corresponds to the token car the fourth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=771" target="_blank">00:12:51.120</a></span> | <span class="t">Number to the token dog, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=774" target="_blank">00:12:54.800</a></span> | <span class="t">Which one we want to be the next token? Of course, we know that the next token is a pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=779" target="_blank">00:12:59.680</a></span> | <span class="t">So we want the token number pizza to be high and all the other tokens to be low in value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=784" target="_blank">00:13:04.480</a></span> | <span class="t">So we use the cross entropy loss basically to make sure that the next token is pizza. So how do we do that? Basically we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=793" target="_blank">00:13:13.040</a></span> | <span class="t">Language model will output a list of numbers and we force the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=797" target="_blank">00:13:17.200</a></span> | <span class="t">To produce the following output. So pizza should be one and all the others should be zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=802" target="_blank">00:13:22.000</a></span> | <span class="t">To compare these two things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=805" target="_blank">00:13:25.680</a></span> | <span class="t">This one should be a distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=808" target="_blank">00:13:28.880</a></span> | <span class="t">So basically the cross entropy loss what it does it takes a vector it converts it into a distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=814" target="_blank">00:13:34.900</a></span> | <span class="t">With the softmax function and then we compare it with a label and we force the output to be equal to the label</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=822" target="_blank">00:13:42.400</a></span> | <span class="t">This will change the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=825" target="_blank">00:13:45.200</a></span> | <span class="t">To generate a distribution the next time after the training in such a way that the pizza is given a high number and all the others</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=832" target="_blank">00:13:52.320</a></span> | <span class="t">Are given a low number and this is exactly the same that we do here for contrastive learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=837" target="_blank">00:13:57.360</a></span> | <span class="t">So we can use the cross entropy loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=839" target="_blank">00:13:59.680</a></span> | <span class="t">To force for example in this column here only this number to have a high value and all the others to have a low value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=846" target="_blank">00:14:06.320</a></span> | <span class="t">And for this row here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=848" target="_blank">00:14:08.480</a></span> | <span class="t">Only this number to have a high value and all the other number in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=851" target="_blank">00:14:11.920</a></span> | <span class="t">Row to have a low value and for example for this row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=854" target="_blank">00:14:14.560</a></span> | <span class="t">We want the second item to have a high value and all the others to have a low value, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=859" target="_blank">00:14:19.040</a></span> | <span class="t">And we do that with the cross entropy loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=862" target="_blank">00:14:22.480</a></span> | <span class="t">Now here is the code that the pseudo code that they show in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=867" target="_blank">00:14:27.520</a></span> | <span class="t">Clip paper on how to implement the clip training with contrastive loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=871" target="_blank">00:14:31.840</a></span> | <span class="t">So basically we have a list of images and a list of text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=875" target="_blank">00:14:35.360</a></span> | <span class="t">We encode them and they will become a list of vectors called image vectors and text vectors here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=882" target="_blank">00:14:42.080</a></span> | <span class="t">image embeddings and text embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=884" target="_blank">00:14:44.720</a></span> | <span class="t">We normalize them later. We will see why we normalize stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=889" target="_blank">00:14:49.040</a></span> | <span class="t">But okay, it's make sure that we reduce the internal covariance shift, but for now ignore it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=893" target="_blank">00:14:53.680</a></span> | <span class="t">Anyway, we normalize them later. We will talk about normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=896" target="_blank">00:14:56.900</a></span> | <span class="t">We calculate all the possible dot products between these embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=901" target="_blank">00:15:01.520</a></span> | <span class="t">So the text embeddings and the image embeddings, so we basically generate this grid here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=906" target="_blank">00:15:06.640</a></span> | <span class="t">then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=908" target="_blank">00:15:08.720</a></span> | <span class="t">We generate the labels the labels are what well for the first row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=913" target="_blank">00:15:13.280</a></span> | <span class="t">We want the label the first item to be maximum for the second row the second item for the third row the third item</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=920" target="_blank">00:15:20.320</a></span> | <span class="t">And that's why the labels are arranged this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=922" target="_blank">00:15:22.800</a></span> | <span class="t">This is basically the the function arrange generates a number between zero and in this case n minus one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=929" target="_blank">00:15:29.680</a></span> | <span class="t">So for the row number zero, we want the item number zero to be maximum for the row number one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=935" target="_blank">00:15:35.600</a></span> | <span class="t">We want the item number one, etc, etc until the row number n minus one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=938" target="_blank">00:15:38.880</a></span> | <span class="t">We want the n minus one item to be the maximum one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=942" target="_blank">00:15:42.480</a></span> | <span class="t">Then we calculate the cross entropy loss between what is the output of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=945" target="_blank">00:15:45.920</a></span> | <span class="t">So what are the numbers assigned by the model to each of these dot products and what we want?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=950" target="_blank">00:15:50.560</a></span> | <span class="t">The maximum to be among these numbers. This is the labels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=954" target="_blank">00:15:54.240</a></span> | <span class="t">And we do it by rows and by columns this one you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=960" target="_blank">00:16:00.720</a></span> | <span class="t">then we sum these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=963" target="_blank">00:16:03.200</a></span> | <span class="t">Losses and we compute the average so we compute the average loss between all the rows and all the columns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=970" target="_blank">00:16:10.480</a></span> | <span class="t">And this is how we do contrastive learning. Now, let's explore. What is the problem with CLIP?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=976" target="_blank">00:16:16.320</a></span> | <span class="t">All right. So what is the problem with CLIP?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=980" target="_blank">00:16:20.560</a></span> | <span class="t">Well, the problem with CLIP is very simple is that we are using the cross entropy loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=985" target="_blank">00:16:25.760</a></span> | <span class="t">And the cross entropy loss basically needs to have a compare does the comparison between two distributions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=992" target="_blank">00:16:32.160</a></span> | <span class="t">So in language model we compare the output logits which are transformed into distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=998" target="_blank">00:16:38.080</a></span> | <span class="t">With the label so which item of this distribution we want to be the maximum one and we do the same here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1003" target="_blank">00:16:43.440</a></span> | <span class="t">So we have this column</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1005" target="_blank">00:16:45.600</a></span> | <span class="t">We convert it into a distribution and we do it through a function called the softmax function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1010" target="_blank">00:16:50.960</a></span> | <span class="t">So the softmax function basically it is a function that takes as input a vector and converts it into a distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1017" target="_blank">00:16:57.860</a></span> | <span class="t">What does it mean? It means that when you have a vector like this, for example, it will be a list of numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1024" target="_blank">00:17:04.960</a></span> | <span class="t">To be a distribution each of these numbers needs to be non-negative. So it needs to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1029" target="_blank">00:17:09.760</a></span> | <span class="t">Greater than or equal to zero and plus all of these numbers needs to sum up to one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1035" target="_blank">00:17:15.600</a></span> | <span class="t">That's what a distribution is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1037" target="_blank">00:17:17.760</a></span> | <span class="t">Of course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1038" target="_blank">00:17:18.320</a></span> | <span class="t">The model will predict some numbers and it cannot force all the sum of these numbers to be one and it cannot force the numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1044" target="_blank">00:17:24.640</a></span> | <span class="t">to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1046" target="_blank">00:17:26.320</a></span> | <span class="t">non-negative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1047" target="_blank">00:17:27.440</a></span> | <span class="t">So we apply to the output of the model this function called the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1051" target="_blank">00:17:31.440</a></span> | <span class="t">Which transforms them into a distribution and then we can compare it with the labels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1055" target="_blank">00:17:35.040</a></span> | <span class="t">So our label in the case for example for the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1057" target="_blank">00:17:37.840</a></span> | <span class="t">For the second row will be this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1060" target="_blank">00:17:40.160</a></span> | <span class="t">So we want the first item to be zero the second item to be one and this one to be zero this one to be zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1065" target="_blank">00:17:45.200</a></span> | <span class="t">This one to be zero this one to be zero, but we need to apply the softmax to the output of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1070" target="_blank">00:17:50.240</a></span> | <span class="t">now the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1072" target="_blank">00:17:52.960</a></span> | <span class="t">Function has a problem which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1075" target="_blank">00:17:55.040</a></span> | <span class="t">And we will see now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1077" target="_blank">00:17:57.920</a></span> | <span class="t">this is the expression of the softmax basically to we take the output of the model and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1083" target="_blank">00:18:03.120</a></span> | <span class="t">exponentiate each item in the output vector, which could be a row or a column</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1088" target="_blank">00:18:08.240</a></span> | <span class="t">And after exponentiating we also divide them with the sum of all the other items</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1095" target="_blank">00:18:15.600</a></span> | <span class="t">So the exponential of all the other items</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1097" target="_blank">00:18:17.760</a></span> | <span class="t">So which means that we need to calculate first of all for each row the exponential of the item</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1103" target="_blank">00:18:23.840</a></span> | <span class="t">And then we need to divide by the sum of all the exponentials of all the other items including itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1108" target="_blank">00:18:28.800</a></span> | <span class="t">The the problem is that we are using this exponential. The exponential is basically a function that grows very fast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1116" target="_blank">00:18:36.400</a></span> | <span class="t">So if the argument of the exponential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1118" target="_blank">00:18:38.660</a></span> | <span class="t">Grows the exponential will become huge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1121" target="_blank">00:18:41.680</a></span> | <span class="t">And this is a problem for computers because in computers we store numbers using a fixed representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1128" target="_blank">00:18:48.480</a></span> | <span class="t">Which could be 16 bit or 32 bit which means that we cannot represent up to infinity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1133" target="_blank">00:18:53.520</a></span> | <span class="t">But we can represent each number up to 2 to the power of n minus 1 basically if you don't have negative numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1139" target="_blank">00:18:59.520</a></span> | <span class="t">So if the exponential is too big then our numbers will grow too much and it may not be represented by 32 bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1147" target="_blank">00:19:07.440</a></span> | <span class="t">And that's a problem. So we need to make this softmax function numerically stable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1153" target="_blank">00:19:13.520</a></span> | <span class="t">So whenever you heard the term numerical stability in terms of computer science</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1157" target="_blank">00:19:17.360</a></span> | <span class="t">It means that we want to make sure that the number can be represented within 32 bits or 16 bits or whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1163" target="_blank">00:19:23.040</a></span> | <span class="t">range we are using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1165" target="_blank">00:19:25.440</a></span> | <span class="t">How to make this softmax numerically stable?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1168" target="_blank">00:19:28.640</a></span> | <span class="t">Well, the trick is this. The softmax is uh, each item is exponentiated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1174" target="_blank">00:19:34.740</a></span> | <span class="t">So we do the exponential of each item</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1179" target="_blank">00:19:39.040</a></span> | <span class="t">And then we divide it by this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1181" target="_blank">00:19:41.680</a></span> | <span class="t">This denominator which is known as the normalization constant, which is the sum of all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1187" target="_blank">00:19:47.360</a></span> | <span class="t">Exponentials of all the other items in the vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1190" target="_blank">00:19:50.000</a></span> | <span class="t">Now as you know, this is a fraction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1192" target="_blank">00:19:52.320</a></span> | <span class="t">So in a fraction you can multiply the numerator and the denominator by the same number without changing the fraction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1197" target="_blank">00:19:57.200</a></span> | <span class="t">So we multiply by this constant called c</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1199" target="_blank">00:19:59.840</a></span> | <span class="t">Each number can be written as the exponentials of the logarithm of the number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1206" target="_blank">00:20:06.160</a></span> | <span class="t">And this is because the exponential and the log are inverse functions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1210" target="_blank">00:20:10.400</a></span> | <span class="t">So we can write c as follows. So the exponential of the log of c</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1214" target="_blank">00:20:14.480</a></span> | <span class="t">By using the properties of the exponential which means that the exponential of the product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1221" target="_blank">00:20:21.280</a></span> | <span class="t">The product of two exponential is equal to the exponential of the sum of the arguments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1226" target="_blank">00:20:26.340</a></span> | <span class="t">We can write it like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1228" target="_blank">00:20:28.400</a></span> | <span class="t">And then we can bring this exponential inside the summation because of the distributive property of the product with respect to the sum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1235" target="_blank">00:20:35.680</a></span> | <span class="t">After we bring it inside we can use the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1237" target="_blank">00:20:37.920</a></span> | <span class="t">Rule we applied above which is the exponential of the product is equal to the exponential of the sum of the arguments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1243" target="_blank">00:20:43.620</a></span> | <span class="t">Now what we notice is that if we subtract something from this exponential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1249" target="_blank">00:20:49.300</a></span> | <span class="t">this log of c</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1252" target="_blank">00:20:52.480</a></span> | <span class="t">We can make the argument of the exponential smaller which may make it numerically stable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1258" target="_blank">00:20:58.320</a></span> | <span class="t">So what we choose as this log of c, basically we choose the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1262" target="_blank">00:21:02.700</a></span> | <span class="t">Negative maximum number in the array that we are normalizing using the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1267" target="_blank">00:21:07.440</a></span> | <span class="t">This way basically the argument of the exponential will decrease and it will be less likely that this exponential will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1276" target="_blank">00:21:16.860</a></span> | <span class="t">Go to infinity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1279" target="_blank">00:21:19.980</a></span> | <span class="t">Which makes it numerically stable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1282" target="_blank">00:21:22.460</a></span> | <span class="t">Now this basically means that to calculate the cross entropy loss for each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1289" target="_blank">00:21:29.340</a></span> | <span class="t">columns and each of these rows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1292" target="_blank">00:21:32.940</a></span> | <span class="t">First of all the model needs to output a list of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1296" target="_blank">00:21:36.460</a></span> | <span class="t">Text embeddings and a list of image embeddings as you can see then we do all the possible dot products</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1302" target="_blank">00:21:42.460</a></span> | <span class="t">Then for each column first of all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1305" target="_blank">00:21:45.260</a></span> | <span class="t">We need to find the maximum value in this column so that we can subtract it before calculating the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1311" target="_blank">00:21:51.120</a></span> | <span class="t">Then we need to apply the exponential to each of these items</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1314" target="_blank">00:21:54.780</a></span> | <span class="t">then we sum up all of this exponential to calculate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1319" target="_blank">00:21:59.160</a></span> | <span class="t">Normalization constant then we divide each of these numbers by this normalization constant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1323" target="_blank">00:22:03.800</a></span> | <span class="t">so as you can see to apply the cross entropy loss involves a lot of computations and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1329" target="_blank">00:22:09.960</a></span> | <span class="t">Also, it forces you to always have imagine you want to parallelize this operation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1335" target="_blank">00:22:15.400</a></span> | <span class="t">Imagine that you want to distribute each row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1339" target="_blank">00:22:19.080</a></span> | <span class="t">between different devices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1341" target="_blank">00:22:21.640</a></span> | <span class="t">So this device here needs to have all the row in its memory because it needs to calculate this normalization constant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1347" target="_blank">00:22:27.960</a></span> | <span class="t">So it has needs to have access to all of this row and if you want to do parallelize by column</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1353" target="_blank">00:22:33.800</a></span> | <span class="t">Then you need to have all the column</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1355" target="_blank">00:22:35.800</a></span> | <span class="t">In your memory because you need to calculate the first of all the maximum item then you need to calculate this normalization constant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1361" target="_blank">00:22:41.960</a></span> | <span class="t">Then you need to normalize them so dividing by this normalization constant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1365" target="_blank">00:22:45.240</a></span> | <span class="t">So it is involves a lot of computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1367" target="_blank">00:22:47.400</a></span> | <span class="t">But also it makes it difficult to parallelize because at any moment each device needs to have at least one full row or one full</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1373" target="_blank">00:22:53.960</a></span> | <span class="t">Column, which does not allow us to go to very big batch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1377" target="_blank">00:22:57.880</a></span> | <span class="t">And this is a problem. So if you look at the cglib paper, they say that note that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1384" target="_blank">00:23:04.360</a></span> | <span class="t">Due to the asymmetry of the softmax loss the normalization is also independently performs two times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1390" target="_blank">00:23:10.600</a></span> | <span class="t">So first of all to make the softmax numerically stable, we need to go through each single vector calculate the maximum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1397" target="_blank">00:23:17.020</a></span> | <span class="t">Then we need to calculate the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1399" target="_blank">00:23:19.160</a></span> | <span class="t">but then we also need to calculate the softmax by rows and then by columns why because this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1405" target="_blank">00:23:25.800</a></span> | <span class="t">Matrix here is not symmetric. So as you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1408" target="_blank">00:23:28.920</a></span> | <span class="t">This is image number one with all the text and this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1412" target="_blank">00:23:32.840</a></span> | <span class="t">Text number one with all the images and this item here is not equal to this item here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1417" target="_blank">00:23:37.480</a></span> | <span class="t">Because this is image number one with the text number two, and this is image number two with the text number one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1423" target="_blank">00:23:43.640</a></span> | <span class="t">Because it's not symmetric means that you need to calculate the softmax for each single rows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1428" target="_blank">00:23:48.040</a></span> | <span class="t">And then you need to calculate it for each single column and then you can calculate the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1432" target="_blank">00:23:52.840</a></span> | <span class="t">So the problem with the clip is that it's very computationally expensive to calculate this loss this contrastive loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1440" target="_blank">00:24:00.680</a></span> | <span class="t">that's why in the cglib paper they propose to replace the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1445" target="_blank">00:24:05.080</a></span> | <span class="t">Cross entropy loss with the sigmoid loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1450" target="_blank">00:24:10.440</a></span> | <span class="t">So with the cglib what we do is as follows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1453" target="_blank">00:24:13.160</a></span> | <span class="t">Again, we have an image encoder that converts a list of images into a list of embeddings one for image image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1459" target="_blank">00:24:19.880</a></span> | <span class="t">Then we have list of text which convert each text into a list of embedding one for each text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1465" target="_blank">00:24:25.160</a></span> | <span class="t">Then what we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1469" target="_blank">00:24:29.320</a></span> | <span class="t">We calculate this all the possible dot products</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1471" target="_blank">00:24:31.880</a></span> | <span class="t">So the image number one with the text number one image number two with text number two and also image number one with text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1477" target="_blank">00:24:37.160</a></span> | <span class="t">Number two text number three text four text five blah blah. So all the possible dot products between all these embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1483" target="_blank">00:24:43.100</a></span> | <span class="t">then instead of treating the loss as a distribution over a row or a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1489" target="_blank">00:24:49.560</a></span> | <span class="t">Column or a row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1492" target="_blank">00:24:52.200</a></span> | <span class="t">So we don't say in this row in this column</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1495" target="_blank">00:24:55.160</a></span> | <span class="t">I want this item to be maximum or in this row. I want this item to be maximum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1500" target="_blank">00:25:00.440</a></span> | <span class="t">We use what is known as binary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1506" target="_blank">00:25:06.040</a></span> | <span class="t">We use it as a binary classification task using the sigmoid loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1509" target="_blank">00:25:09.720</a></span> | <span class="t">In which each of these dot products is treated independently from each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1515" target="_blank">00:25:15.400</a></span> | <span class="t">So this is considered a single binary classification task in which we say okay this item here should be one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1521" target="_blank">00:25:21.880</a></span> | <span class="t">This item here should be zero. This item here should be zero. This item here should be zero independently of what are the other items</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1529" target="_blank">00:25:29.400</a></span> | <span class="t">This one here should be zero. This one should be here zero, etc, etc, and we can do that with the sigmoid function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1535" target="_blank">00:25:35.480</a></span> | <span class="t">So as you can see, this is the function the signature expression of the sigmoid function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1538" target="_blank">00:25:38.920</a></span> | <span class="t">It takes as input this value called z which will be the dot product of our vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1545" target="_blank">00:25:45.000</a></span> | <span class="t">And the output of the sigmoid is this stuff here, which is a number between zero and one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1551" target="_blank">00:25:51.160</a></span> | <span class="t">So what we can do is we take each of these dot products. We run it through a sigmoid</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1555" target="_blank">00:25:55.900</a></span> | <span class="t">And then we force the label to be one for corresponding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1561" target="_blank">00:26:01.240</a></span> | <span class="t">Text and images and zero for not corresponding ones. So each of these dot products now becomes a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1567" target="_blank">00:26:07.560</a></span> | <span class="t">independent binary classification task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1570" target="_blank">00:26:10.120</a></span> | <span class="t">basically this allow us to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1573" target="_blank">00:26:13.240</a></span> | <span class="t">Grow the batch size to millions of items and also to parallelize because we can put this block here into one device</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1580" target="_blank">00:26:20.600</a></span> | <span class="t">And it can calculate it independently from this other device because they do not need to calculate any normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1587" target="_blank">00:26:27.400</a></span> | <span class="t">Constant for each item or the maximum item in each row or column because each of them is independent from the others</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1594" target="_blank">00:26:34.360</a></span> | <span class="t">Now you may be wondering why are we even using a contrastive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1600" target="_blank">00:26:40.060</a></span> | <span class="t">vision encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1601" target="_blank">00:26:41.640</a></span> | <span class="t">I mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1601" target="_blank">00:26:41.960</a></span> | <span class="t">Why cannot we just use an ordinary vision encoder that just takes an image and instructs some kind of embeddings that capture the information?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1609" target="_blank">00:26:49.480</a></span> | <span class="t">Of this image why we want it to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1611" target="_blank">00:26:51.480</a></span> | <span class="t">contrastive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1613" target="_blank">00:26:53.160</a></span> | <span class="t">because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1614" target="_blank">00:26:54.280</a></span> | <span class="t">We want these embeddings to not only capture a information about the image, but we want these embeddings to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1621" target="_blank">00:27:01.720</a></span> | <span class="t">Good representation that can be then contrasted or can be used along with text embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1629" target="_blank">00:27:09.100</a></span> | <span class="t">And this is exactly what we do in a vision language model. We extract some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1633" target="_blank">00:27:13.800</a></span> | <span class="t">image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1636" target="_blank">00:27:16.020</a></span> | <span class="t">Embeddings which are vectors representing we will see later a patch of the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1641" target="_blank">00:27:21.480</a></span> | <span class="t">So this you need to think of this image as being divided into a grid and this first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1646" target="_blank">00:27:26.440</a></span> | <span class="t">second third four five six</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1648" target="_blank">00:27:28.920</a></span> | <span class="t">So we produce in this case, for example, nine embeddings which are nine vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1653" target="_blank">00:27:33.800</a></span> | <span class="t">Each of them represents information about a patch of the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1657" target="_blank">00:27:37.080</a></span> | <span class="t">So we want these embeddings to not only be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1662" target="_blank">00:27:42.200</a></span> | <span class="t">Representing the information of these patches, but also to be able to be contrasted with the text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1668" target="_blank">00:27:48.520</a></span> | <span class="t">Which is what we do in a visual language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1670" target="_blank">00:27:50.360</a></span> | <span class="t">So we have some prompt and we kind of contrast it with the image embeddings to produce an output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1677" target="_blank">00:27:57.560</a></span> | <span class="t">It is not really a contrastive learning in this case because we are using it as a condition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1682" target="_blank">00:28:02.600</a></span> | <span class="t">We will see later how these things are merged</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1684" target="_blank">00:28:04.920</a></span> | <span class="t">But we want a visual language a vision encoder that is already trained to be used with the text because it has a better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1691" target="_blank">00:28:11.880</a></span> | <span class="t">Representation for the image for being used along with the text. That's why we use the contrasting vision encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1698" target="_blank">00:28:18.360</a></span> | <span class="t">also, we use them because they are cheaper to train so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1701" target="_blank">00:28:21.880</a></span> | <span class="t">You can basically to train a contrasting vision encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1706" target="_blank">00:28:26.600</a></span> | <span class="t">You just need to crawl billions of images from the internet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1710" target="_blank">00:28:30.360</a></span> | <span class="t">Each of them already has a kind of a description because you can for example in wikipedia</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1715" target="_blank">00:28:35.480</a></span> | <span class="t">You always have the description of each image, but also the internet when you have an image you always have the html alt text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1722" target="_blank">00:28:42.520</a></span> | <span class="t">It's called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1724" target="_blank">00:28:44.040</a></span> | <span class="t">Which is the alternative text that is displayed when the image is not shown</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1727" target="_blank">00:28:47.320</a></span> | <span class="t">So you always have access to some kind of description</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1729" target="_blank">00:28:49.980</a></span> | <span class="t">Now, of course this vision encoder may be noisy because they we crawl stuff from the internet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1735" target="_blank">00:28:55.400</a></span> | <span class="t">Which means that this stuff may not always be correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1738" target="_blank">00:28:58.280</a></span> | <span class="t">So sometimes you see a picture but the description displayed is not correct or maybe the crawler didn't get the correct information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1744" target="_blank">00:29:04.920</a></span> | <span class="t">But because we train it on billions and billions and billions of images eventually it learns a good representation of this image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1753" target="_blank">00:29:13.880</a></span> | <span class="t">So this vision encoder that we will be using is basically a vision transformer. So now let's talk about the vision transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1761" target="_blank">00:29:21.020</a></span> | <span class="t">Let's talk about it here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1764" target="_blank">00:29:24.600</a></span> | <span class="t">So the vision transformer is a transformer basically that was introduced in this paper and image is worth 16 by 16 words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1772" target="_blank">00:29:32.680</a></span> | <span class="t">In which basically they train a transformer as follows. So first of all, what do we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1779" target="_blank">00:29:39.960</a></span> | <span class="t">How does a transformer work?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1783" target="_blank">00:29:43.320</a></span> | <span class="t">we will see later in detail what is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1785" target="_blank">00:29:45.640</a></span> | <span class="t">Attention mechanism, but for now, I just need you to remember that the transformer model is a sequence to sequence model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1792" target="_blank">00:29:52.520</a></span> | <span class="t">which means that you feed it a sequence of embeddings and it outputs a sequence of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1797" target="_blank">00:29:57.480</a></span> | <span class="t">contextualized embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1800" target="_blank">00:30:00.180</a></span> | <span class="t">What we do to encode an image with the vision transformer we take an image and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1807" target="_blank">00:30:07.240</a></span> | <span class="t">Split it into patches and in this case, for example, we can split into 16 patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1813" target="_blank">00:30:13.000</a></span> | <span class="t">So this is the first group of pixels. This is the second group of pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1817" target="_blank">00:30:17.160</a></span> | <span class="t">This is the group of pixels on the bottom right of the image. This one is on the top right top right, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1823" target="_blank">00:30:23.400</a></span> | <span class="t">we extract</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1826" target="_blank">00:30:26.280</a></span> | <span class="t">Information about this patch using a convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1829" target="_blank">00:30:29.020</a></span> | <span class="t">So when you run a convolution you can extract information about a group of pixels from the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1836" target="_blank">00:30:36.120</a></span> | <span class="t">And then for example, this one will produce this output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1839" target="_blank">00:30:39.640</a></span> | <span class="t">This one the convolution of this patch will produce this output. The convolution of this patch will produce this output, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1846" target="_blank">00:30:46.520</a></span> | <span class="t">And then we flatten them. So we lose the positional information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1850" target="_blank">00:30:50.300</a></span> | <span class="t">We just take we don't care if this four is the top right or the bottom left</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1855" target="_blank">00:30:55.800</a></span> | <span class="t">We just concatenate them one with each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1860" target="_blank">00:31:00.200</a></span> | <span class="t">We do we lose the two dimensionality in this case basically so we transform into a sequence of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1865" target="_blank">00:31:05.640</a></span> | <span class="t">patches instead of being a grid of patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1868" target="_blank">00:31:08.760</a></span> | <span class="t">Then we add this position information so we say that okay, this is the patch number one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1875" target="_blank">00:31:15.320</a></span> | <span class="t">So, how do we do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1876" target="_blank">00:31:16.680</a></span> | <span class="t">This patch basically the embedding of this patch that will be the result of this convolution will be a vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1882" target="_blank">00:31:22.600</a></span> | <span class="t">We add to this vector another vector that tells the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1887" target="_blank">00:31:27.800</a></span> | <span class="t">Hey, this is the patch number one and this is the patch number two, and this is the patch number three, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1892" target="_blank">00:31:32.920</a></span> | <span class="t">So we do that by adding so this plus operation you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1896" target="_blank">00:31:36.600</a></span> | <span class="t">and unlike the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1898" target="_blank">00:31:38.920</a></span> | <span class="t">Vanilla transformer or the transformer model that we see for language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1902" target="_blank">00:31:42.600</a></span> | <span class="t">These positional encodings are not calculated using sinusoidal functions, but they are learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1908" target="_blank">00:31:48.040</a></span> | <span class="t">So they are vectors that get added always so the positional encoding number one always gets added to the top left</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1915" target="_blank">00:31:55.720</a></span> | <span class="t">Patch the positional number two always gets added to the second patch from the top left, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1922" target="_blank">00:32:02.040</a></span> | <span class="t">The positional encoding number 16 gets added always to the bottom right patch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1926" target="_blank">00:32:06.680</a></span> | <span class="t">So the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1929" target="_blank">00:32:09.560</a></span> | <span class="t">Has kind of access to this to the 2d representation of the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1933" target="_blank">00:32:13.800</a></span> | <span class="t">So the model will learn basically that the patch number 16 is always on the top right and this is always on the top left</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1939" target="_blank">00:32:19.960</a></span> | <span class="t">We feed it to the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1942" target="_blank">00:32:22.200</a></span> | <span class="t">So this is a series of embeddings because the sum of two embeddings is a series of embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1948" target="_blank">00:32:28.120</a></span> | <span class="t">We feed it to the transformer model for now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1950" target="_blank">00:32:30.760</a></span> | <span class="t">Let's consider it as a black box and later when we code it, we will explore each layer of this transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1955" target="_blank">00:32:35.500</a></span> | <span class="t">The transformer what it does it does the contextualization of these embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1960" target="_blank">00:32:40.680</a></span> | <span class="t">So at input we have this each series of embeddings each of them representing one single patch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1967" target="_blank">00:32:47.640</a></span> | <span class="t">The output of the transformer through the attention mechanism will be a series of embeddings again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1972" target="_blank">00:32:52.920</a></span> | <span class="t">But each of these embeddings is not only capturing information about itself, but also about other patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1978" target="_blank">00:32:58.680</a></span> | <span class="t">In language models, we do what is known as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1982" target="_blank">00:33:02.440</a></span> | <span class="t">We use in the attention mechanism. We use what is known as the causal mask. So this first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1988" target="_blank">00:33:08.280</a></span> | <span class="t">Embedding should be only capturing information only about itself the second one only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1994" target="_blank">00:33:14.360</a></span> | <span class="t">About itself and the previous one the third</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=1997" target="_blank">00:33:17.240</a></span> | <span class="t">About itself and the two previous one the fourth one about itself and the three previous one, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2003" target="_blank">00:33:23.000</a></span> | <span class="t">This is what we do with the language models with visual language models in the with the trust</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2007" target="_blank">00:33:27.880</a></span> | <span class="t">Sorry, not with visual language, but with the vision transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2010" target="_blank">00:33:30.940</a></span> | <span class="t">We don't care about this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2014" target="_blank">00:33:34.280</a></span> | <span class="t">being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2015" target="_blank">00:33:35.720</a></span> | <span class="t">The model being autoregressive we say so we don't want these patches to only encode information about the previous patches because in the in an image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2023" target="_blank">00:33:43.240</a></span> | <span class="t">There is no autoregressiveness. So it's not like the patch number 16 of an image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2028" target="_blank">00:33:48.920</a></span> | <span class="t">It depends only on the previous patches and the patch number one does not depend on any others</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2033" target="_blank">00:33:53.960</a></span> | <span class="t">Because imagine you have an image in which the sun is here or the light source is here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2040" target="_blank">00:34:00.360</a></span> | <span class="t">then this part here will be light will be illuminated, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2045" target="_blank">00:34:05.320</a></span> | <span class="t">So the illumination here depends on what is coming after in the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2050" target="_blank">00:34:10.680</a></span> | <span class="t">So in the image, we don't have this autoregressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2053" target="_blank">00:34:13.180</a></span> | <span class="t">relationship</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2055" target="_blank">00:34:15.400</a></span> | <span class="t">Why in the text without we do because we we write the text from left to right or from right to left</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2061" target="_blank">00:34:21.080</a></span> | <span class="t">But anyway, each word that we write depends on what we have written previously</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2065" target="_blank">00:34:25.400</a></span> | <span class="t">But this doesn't happen with image. So basically this contextualized embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2070" target="_blank">00:34:30.460</a></span> | <span class="t">They capture information about themselves, but also all the other embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2075" target="_blank">00:34:35.260</a></span> | <span class="t">and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2077" target="_blank">00:34:37.800</a></span> | <span class="t">We use this contextualized embedding to capture information about each patch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2083" target="_blank">00:34:43.080</a></span> | <span class="t">But also how it is present in the image. That's why we want them to contextualize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2087" target="_blank">00:34:47.740</a></span> | <span class="t">So we want each patch to include information about its position, which is given by the positional encoding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2093" target="_blank">00:34:53.480</a></span> | <span class="t">But also about what is surrounding this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2095" target="_blank">00:34:55.880</a></span> | <span class="t">patch in the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2098" target="_blank">00:34:58.600</a></span> | <span class="t">By contextualizing them. So when we code it, this will be more clear for now. I just want you to get a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2105" target="_blank">00:35:05.400</a></span> | <span class="t">Idea of what we are going to code. So we are going to code a model that will take an image will apply a convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2113" target="_blank">00:35:13.020</a></span> | <span class="t">To extract a series of embeddings. You can see here. We will add a positional encoding to these ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2119" target="_blank">00:35:19.560</a></span> | <span class="t">Which are learned we will apply the attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2123" target="_blank">00:35:23.480</a></span> | <span class="t">Which is will be a series of layer actually of the transferable model that will contextualize these embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2129" target="_blank">00:35:29.080</a></span> | <span class="t">And then we will use this contextualized embedding as input to the language model for decoding the output of the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2135" target="_blank">00:35:35.240</a></span> | <span class="t">So let's finally start coding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2137" target="_blank">00:35:37.240</a></span> | <span class="t">Now in this video I will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2140" target="_blank">00:35:40.920</a></span> | <span class="t">Using a slightly different approach, which is I will not be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2143" target="_blank">00:35:43.960</a></span> | <span class="t">writing each line</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2145" target="_blank">00:35:45.560</a></span> | <span class="t">I will be copying each line and explaining it step by step because I want this video to be more about explanation than just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2152" target="_blank">00:35:52.040</a></span> | <span class="t">Coding because I want to use the code for explaining what happens under the code under the hood</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2158" target="_blank">00:35:58.280</a></span> | <span class="t">So let's create our first file, which is the modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2163" target="_blank">00:36:03.240</a></span> | <span class="t">Oops, I'm using Chinese</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2165" target="_blank">00:36:05.240</a></span> | <span class="t">Siglip.py</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2167" target="_blank">00:36:07.560</a></span> | <span class="t">And let's start by importing stuff which we need I don't need copilot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2174" target="_blank">00:36:14.060</a></span> | <span class="t">And then we create our first class which is the siglip-config</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2179" target="_blank">00:36:19.100</a></span> | <span class="t">So, what is this basically we will be using this visual encoder and this visual encoder will have some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2187" target="_blank">00:36:27.700</a></span> | <span class="t">Configurations, why do we need a configuration class because uh, polygamma comes in different sizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2193" target="_blank">00:36:33.620</a></span> | <span class="t">Let me put this one. Okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2196" target="_blank">00:36:36.740</a></span> | <span class="t">Polygamma comes in different sizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2199" target="_blank">00:36:39.540</a></span> | <span class="t">Which means that each of this size of polygamma each of these models polygamma models has a different configuration for its vision encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2206" target="_blank">00:36:46.660</a></span> | <span class="t">So let's see each of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2208" target="_blank">00:36:48.420</a></span> | <span class="t">The hidden size basically it's the size of the embedding vector of this vision transformer that we are going to encode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2214" target="_blank">00:36:54.900</a></span> | <span class="t">the intermediate size is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2217" target="_blank">00:36:57.700</a></span> | <span class="t">Linear layer that we use the size of the linear layer that we use in the feed-forward network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2222" target="_blank">00:37:02.340</a></span> | <span class="t">The number of hidden layers is the number of layers of this vision transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2226" target="_blank">00:37:06.820</a></span> | <span class="t">The number of attention heads is the number of attention heads in the multi-head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2230" target="_blank">00:37:10.500</a></span> | <span class="t">The number of channels is how many channels is each image has which is RGB</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2235" target="_blank">00:37:15.080</a></span> | <span class="t">The image size is because polygamma comes in I remember three sizes. So 224, 448 and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2242" target="_blank">00:37:22.580</a></span> | <span class="t">896 something like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2246" target="_blank">00:37:26.180</a></span> | <span class="t">The default information that we put here is the for polygamma 224</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2249" target="_blank">00:37:29.960</a></span> | <span class="t">Which supports of course image of size 224. So if you provide any image, it's first get resized into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2256" target="_blank">00:37:36.980</a></span> | <span class="t">224 by 224</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2259" target="_blank">00:37:39.840</a></span> | <span class="t">The size of each patch. So what is the number?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2262" target="_blank">00:37:42.980</a></span> | <span class="t">It will be divided each image will be divided into patches. Each patch will be 16 by 16</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2268" target="_blank">00:37:48.980</a></span> | <span class="t">and the this way is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2272" target="_blank">00:37:52.260</a></span> | <span class="t">Parameter for the layer normalization. We will see later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2274" target="_blank">00:37:54.420</a></span> | <span class="t">The attention dropout is another parameter that we will not be using in the attention calculation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2278" target="_blank">00:37:58.900</a></span> | <span class="t">Basically, it's a dropout that we use in the attention, but we will not be using it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2282" target="_blank">00:38:02.660</a></span> | <span class="t">And the number of image tokens indicates how many output embeddings this attention mechanism will this transformer vision transformer will output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2291" target="_blank">00:38:11.060</a></span> | <span class="t">which is the how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2293" target="_blank">00:38:13.140</a></span> | <span class="t">Image embeddings we will have for each image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2297" target="_blank">00:38:17.460</a></span> | <span class="t">Now before we saw that each an image encoder is something that converts an image into one single embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2304" target="_blank">00:38:24.340</a></span> | <span class="t">So that represents all the information about that image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2307" target="_blank">00:38:27.140</a></span> | <span class="t">but in the case of the vision transformer we can use all the output of the vision transformer to have because as we saw before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2313" target="_blank">00:38:33.940</a></span> | <span class="t">Vision transformer is a transformer model. So which takes as input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2318" target="_blank">00:38:38.180</a></span> | <span class="t">A list of embeddings and it outputs a contextualized embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2322" target="_blank">00:38:42.820</a></span> | <span class="t">So each of these contextualized embedding will be the tokens of our image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2326" target="_blank">00:38:46.740</a></span> | <span class="t">so it will not be one single embedding that represents the whole image, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2329" target="_blank">00:38:49.940</a></span> | <span class="t">Lists of embeddings that represent a patch of each image, but also information about other patches through the attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2337" target="_blank">00:38:57.460</a></span> | <span class="t">But we will see this later. So now this class is very very basic. It's just a configuration of our cglib</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2343" target="_blank">00:39:03.380</a></span> | <span class="t">Now let's start by coding the structure of this vision transformer. So let me copy this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2353" target="_blank">00:39:13.700</a></span> | <span class="t">How to follow this video now I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2356" target="_blank">00:39:16.260</a></span> | <span class="t">I am copying the code because I have already written before and I want to explain it instead of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2361" target="_blank">00:39:21.780</a></span> | <span class="t">Coding it because I also allows me to copy the comments and also allows me to avoid any mistakes while coding it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2369" target="_blank">00:39:29.220</a></span> | <span class="t">But I recommend that you code it from scratch. So you take this video and you just type whatever I am pasting here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2377" target="_blank">00:39:37.460</a></span> | <span class="t">This is the best way to learn because it's like when you study a mathematical proof</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2382" target="_blank">00:39:42.500</a></span> | <span class="t">You should not just watch the proof on the piece of paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2385" target="_blank">00:39:45.860</a></span> | <span class="t">Because even if it you think it makes sense to you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2389" target="_blank">00:39:49.460</a></span> | <span class="t">It doesn't actually because when you write it by hand, so when you code each of these lines by hand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2395" target="_blank">00:39:55.300</a></span> | <span class="t">Your mind will think why am I typing this? Why am I writing this? Why am I multiplying this number by this number? Why am I?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2403" target="_blank">00:40:03.380</a></span> | <span class="t">Calling this function so you question yourself when typing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2408" target="_blank">00:40:08.180</a></span> | <span class="t">That's why I recommend that you type this code while I am pasting it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2412" target="_blank">00:40:12.420</a></span> | <span class="t">I do it by pasting otherwise this video will be 20 hours</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2415" target="_blank">00:40:15.060</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2417" target="_blank">00:40:17.140</a></span> | <span class="t">The first thing that we do is we create this vision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2419" target="_blank">00:40:19.140</a></span> | <span class="t">Model, this vision model is made up of a transformer and it has a configuration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2423" target="_blank">00:40:23.380</a></span> | <span class="t">So basically what we are doing is we take the pixel values of this our image, which will be loaded with NumPy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2429" target="_blank">00:40:29.300</a></span> | <span class="t">So when you load an image with NumPy it gets converted into an array that is channeled by height by width</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2435" target="_blank">00:40:35.540</a></span> | <span class="t">But we can have a batch of images. That's why we have a batch size here. So the batch dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2441" target="_blank">00:40:41.940</a></span> | <span class="t">And our vision transformer will convert this into a batch size NumPatches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2447" target="_blank">00:40:47.140</a></span> | <span class="t">Which is how many NumImage tokens we have here and each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2451" target="_blank">00:40:51.300</a></span> | <span class="t">Vector will be of a fixed dimension called embeddim here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2456" target="_blank">00:40:56.340</a></span> | <span class="t">So basically our vision model will take an image as you can see a batch of images and it will give us a batch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2464" target="_blank">00:41:04.100</a></span> | <span class="t">List of embeddings one list of embeddings for each image where each embedding is a vector of size embeddim</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2471" target="_blank">00:41:11.480</a></span> | <span class="t">Okay. Now let's code the vision transformer, which is very simple also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2476" target="_blank">00:41:16.760</a></span> | <span class="t">So let's do it also step by step actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2479" target="_blank">00:41:19.960</a></span> | <span class="t">so this vision transformer is basically a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2483" target="_blank">00:41:23.400</a></span> | <span class="t">Torch layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2487" target="_blank">00:41:27.400</a></span> | <span class="t">Where we pass the configuration we save this embeddim, which is the hidden size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2491" target="_blank">00:41:31.560</a></span> | <span class="t">We saw before which is the size of this embedding vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2494" target="_blank">00:41:34.360</a></span> | <span class="t">We first need to extract the embeddings from this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2500" target="_blank">00:41:40.180</a></span> | <span class="t">We need to extract the patches from this image, which will be done with this layer. We will call SigLip vision embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2506" target="_blank">00:41:46.680</a></span> | <span class="t">Then we will run it through a list of layers of the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2511" target="_blank">00:41:51.060</a></span> | <span class="t">Which is this SigLip encoder because it reminds the encoder of the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2515" target="_blank">00:41:55.380</a></span> | <span class="t">Which is a series of layers of transformer and then we will have a layer normalization and we will see later how layer normalization works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2522" target="_blank">00:42:02.100</a></span> | <span class="t">The forward method is very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2527" target="_blank">00:42:07.060</a></span> | <span class="t">So the forward method is basically we take these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2529" target="_blank">00:42:09.700</a></span> | <span class="t">Pixel values, which is the image which is a patch of images and we convert them into embeddings, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2536" target="_blank">00:42:16.100</a></span> | <span class="t">Which basically means that we are extracting the patches from these images. So let's visualize it here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2541" target="_blank">00:42:21.860</a></span> | <span class="t">So what we are doing with this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2545" target="_blank">00:42:25.540</a></span> | <span class="t">Image embeddings we are taking these images. We will run a convolution here to extract patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2552" target="_blank">00:42:32.260</a></span> | <span class="t">Then we will flatten these patches and add the positional encodings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2555" target="_blank">00:42:35.960</a></span> | <span class="t">And this stuff here will be done by this SigLip and vision embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2560" target="_blank">00:42:40.520</a></span> | <span class="t">then we take these embeddings which are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2564" target="_blank">00:42:44.420</a></span> | <span class="t">Patches plus the positional encoding and we run it through this encoder, which is a list of layers of the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2571" target="_blank">00:42:51.300</a></span> | <span class="t">So this stuff here is our encoder. What is the encoder?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2574" target="_blank">00:42:54.340</a></span> | <span class="t">Well, the encoder is a list of layers of the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2577" target="_blank">00:42:57.860</a></span> | <span class="t">So you can think of it as being a list of these layers here. Actually these layers here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2582" target="_blank">00:43:02.820</a></span> | <span class="t">one after another which includes a multi-head attention, a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2587" target="_blank">00:43:07.300</a></span> | <span class="t">normalization, a feed-forward network and the normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2590" target="_blank">00:43:10.440</a></span> | <span class="t">In the case of the visual transformer the normalization is done before the feed-forward and before the multi-head attention, but that's the only difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2597" target="_blank">00:43:17.940</a></span> | <span class="t">So this part here, so a series of layers is called the here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2604" target="_blank">00:43:24.100</a></span> | <span class="t">We call it the encoder because it resembles the encoder side of the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2608" target="_blank">00:43:28.200</a></span> | <span class="t">And then we have a layer normalization. So now let's go to code this vision embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2614" target="_blank">00:43:34.500</a></span> | <span class="t">So we want to extract information about these patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2617" target="_blank">00:43:37.880</a></span> | <span class="t">Let's do it. Where are the vision embeddings? Here. Okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2626" target="_blank">00:43:46.900</a></span> | <span class="t">All right, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2633" target="_blank">00:43:53.860</a></span> | <span class="t">The vision embeddings is basically, okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2636" target="_blank">00:43:56.100</a></span> | <span class="t">Taking again the configuration because each of these models needs to have access to the configuration because they need to extract different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2641" target="_blank">00:44:01.860</a></span> | <span class="t">Information from this configuration. So we have the embedding size, which is the size of the embedding vector, which is the hidden size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2648" target="_blank">00:44:08.020</a></span> | <span class="t">The image size is how big is the image?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2650" target="_blank">00:44:10.980</a></span> | <span class="t">And the patch size is how big is the patch that we want to get from this image. So basically we are talking about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2658" target="_blank">00:44:18.260</a></span> | <span class="t">this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2660" target="_blank">00:44:20.900</a></span> | <span class="t">In this case the patch size I remember is a 16</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2663" target="_blank">00:44:23.940</a></span> | <span class="t">Which means that we are going to take this patch here is going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2669" target="_blank">00:44:29.140</a></span> | <span class="t">16 by 16 pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2672" target="_blank">00:44:32.000</a></span> | <span class="t">How do we extract these patches? We do that through a convolution that is a 2d convolution, which it takes as input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2678" target="_blank">00:44:38.740</a></span> | <span class="t">The number of channels of the image so three channels are gb and it produces all channels equal to the embedding size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2686" target="_blank">00:44:46.100</a></span> | <span class="t">So the hidden size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2689" target="_blank">00:44:49.620</a></span> | <span class="t">The kernel size so as you remember the convolution works like this, so let's use the ipad actually to draw so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2696" target="_blank">00:44:56.020</a></span> | <span class="t">The convolution works like this. So we have an image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2698" target="_blank">00:44:58.900</a></span> | <span class="t">Which is made up of let's say pixels. So suppose this is the grid of pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2705" target="_blank">00:45:05.400</a></span> | <span class="t">And we have a lot of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2709" target="_blank">00:45:09.780</a></span> | <span class="t">Basically the convolution works like this imagine the kernel size is three by three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2716" target="_blank">00:45:16.020</a></span> | <span class="t">So we take a three by three group of pixels. We apply this convolution kernel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2721" target="_blank">00:45:21.220</a></span> | <span class="t">So if you are not familiar with how convolutions work, I will not be reviewing that here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2726" target="_blank">00:45:26.100</a></span> | <span class="t">But basically it means that we have a matrix here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2728" target="_blank">00:45:28.260</a></span> | <span class="t">You multiply each number of this matrix by the value of the pixel on which it is applied to it will produce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2735" target="_blank">00:45:35.780</a></span> | <span class="t">features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2738" target="_blank">00:45:38.020</a></span> | <span class="t">one feature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2739" target="_blank">00:45:39.700</a></span> | <span class="t">And then you slide this kernel to the next group of pixel then you slide it again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2744" target="_blank">00:45:44.900</a></span> | <span class="t">Slide it again, etc, etc, and it will produce many features in the output features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2749" target="_blank">00:45:49.700</a></span> | <span class="t">However at as input we have three channels which you can think of it as three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2755" target="_blank">00:45:55.700</a></span> | <span class="t">Parallel images one that is only red one that is only green and one that is only blue</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2761" target="_blank">00:46:01.460</a></span> | <span class="t">We run this kernel on all of these channels and it will produce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2765" target="_blank">00:46:05.220</a></span> | <span class="t">Features how many kernels do we have?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2769" target="_blank">00:46:09.920</a></span> | <span class="t">Depending on how many output channels we want. So for each output channel, we have a one kernel that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2775" target="_blank">00:46:15.440</a></span> | <span class="t">We have three kernels actually that is used for one for each of this number channels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2782" target="_blank">00:46:22.960</a></span> | <span class="t">The stride tells us how we should slide this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2787" target="_blank">00:46:27.440</a></span> | <span class="t">Kernel from one group of pixel to the next and we are using a stride that is equal to the patch size of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2794" target="_blank">00:46:34.240</a></span> | <span class="t">Kernels, which is equal to the kernel size. So which means that we take the first oops</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2800" target="_blank">00:46:40.400</a></span> | <span class="t">We take the first group of let's say three by three kernels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2803" target="_blank">00:46:43.440</a></span> | <span class="t">Then we skip three kernels to we slide it to the next group of three by three. So there is no overlap</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2809" target="_blank">00:46:49.600</a></span> | <span class="t">So we take this kernel here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2811" target="_blank">00:46:51.680</a></span> | <span class="t">Then we slide it to this group of pixel here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2814" target="_blank">00:46:54.400</a></span> | <span class="t">Then we slide it to this group of pixel here so that there is no overlap. So basically what we are taking is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2819" target="_blank">00:46:59.280</a></span> | <span class="t">list of features each extracted by a independent patch of this image that we run the kernel on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2827" target="_blank">00:47:07.840</a></span> | <span class="t">And the padding if valid means that there is no padding added</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2831" target="_blank">00:47:11.200</a></span> | <span class="t">So basically this patch embedding is extracting information from our image patch by patch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2838" target="_blank">00:47:18.000</a></span> | <span class="t">Where there is no overlap between these patches. How many patches do we have?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2841" target="_blank">00:47:21.920</a></span> | <span class="t">Well, it's the size of the image which is 224 in the base version of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2847" target="_blank">00:47:27.360</a></span> | <span class="t">PaliGamma divided by the patch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2851" target="_blank">00:47:31.200</a></span> | <span class="t">So image size is the number of pixels divided by how big is each patch and then to the power of two because we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2858" target="_blank">00:47:38.000</a></span> | <span class="t">Along two dimensions this image. So we run the patch. The patch is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2861" target="_blank">00:47:41.840</a></span> | <span class="t">It's a square. So it's a 16 by 16 or 3 by 3 or whatever the number patch size is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2869" target="_blank">00:47:49.600</a></span> | <span class="t">How many positions we have? So how many?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2872" target="_blank">00:47:52.880</a></span> | <span class="t">Positional encodings we need well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2875" target="_blank">00:47:55.360</a></span> | <span class="t">It's equal to the number of patches that we have because we need to encode information about where this patch came from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2881" target="_blank">00:48:01.280</a></span> | <span class="t">So how many positional encodings we need equal to the number of patches that we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2886" target="_blank">00:48:06.080</a></span> | <span class="t">And what is each of this positional encoding? It's a vector. It's a vector of the same size of the patch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2891" target="_blank">00:48:11.920</a></span> | <span class="t">So it's equal to embeddings. You can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2894" target="_blank">00:48:14.480</a></span> | <span class="t">And it's a learned embedding. So it's a positional encoding that is a learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2900" target="_blank">00:48:20.160</a></span> | <span class="t">Embedding how many we have we have noon positions of them each of them with this size here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2906" target="_blank">00:48:26.320</a></span> | <span class="t">And we will see later that each of them is added to the information extracted from the convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2912" target="_blank">00:48:32.160</a></span> | <span class="t">So that each convolution output encodes information about where it came from in the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2917" target="_blank">00:48:37.360</a></span> | <span class="t">we register these positional IDs in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2920" target="_blank">00:48:40.800</a></span> | <span class="t">In the module which is just a list of numbers and we will use it later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2927" target="_blank">00:48:47.440</a></span> | <span class="t">So this is just a range of numbers so between zero and noon positions mine one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2932" target="_blank">00:48:52.720</a></span> | <span class="t">Now let's implement the forward method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2938" target="_blank">00:48:58.240</a></span> | <span class="t">This is the reason I like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2940" target="_blank">00:49:00.320</a></span> | <span class="t">Copy and paste the code because I can copy all the comments without typing them one by one. Otherwise, it will take me forever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2946" target="_blank">00:49:06.000</a></span> | <span class="t">So what we do now is okay. We had our image which is a pixel values here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2950" target="_blank">00:49:10.640</a></span> | <span class="t">The pixel values came from noon pi so we will see later how we load the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2955" target="_blank">00:49:15.760</a></span> | <span class="t">but basically you have to think that you load the image with noon pi and noon pi loads a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2960" target="_blank">00:49:20.880</a></span> | <span class="t">Batch of images, which is a channel height and width. It's a tensor with three channels and with the height of the image and the width of the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2968" target="_blank">00:49:28.880</a></span> | <span class="t">We will see that this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2971" target="_blank">00:49:31.840</a></span> | <span class="t">Height and width is equal to the same because we resize each image to the input size of the image expected by the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2978" target="_blank">00:49:38.320</a></span> | <span class="t">So we will resize in the case. We are using the smallest polygama. We will resize each image to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2982" target="_blank">00:49:42.960</a></span> | <span class="t">224 by 224</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2987" target="_blank">00:49:47.040</a></span> | <span class="t">We extract this patch embeddings to this convolution so you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2991" target="_blank">00:49:51.520</a></span> | <span class="t">So this will basically take our image which is a batch of images and convert it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=2997" target="_blank">00:49:57.200</a></span> | <span class="t">Into a list of embeddings of this size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3000" target="_blank">00:50:00.400</a></span> | <span class="t">So each image will be a list of embeddings of size embed dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3006" target="_blank">00:50:06.420</a></span> | <span class="t">How many patches we have well the number of patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3010" target="_blank">00:50:10.400</a></span> | <span class="t">For the height and the number of patches for the weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3014" target="_blank">00:50:14.720</a></span> | <span class="t">In this case, it will always be the same so you can think of it as a number of patches a total number of patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3020" target="_blank">00:50:20.720</a></span> | <span class="t">Each of patches with the dimension embedding dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3026" target="_blank">00:50:26.900</a></span> | <span class="t">And as we saw before we flatten these ones, so we extract them here. Let me delete it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3034" target="_blank">00:50:34.480</a></span> | <span class="t">So we extract these patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3038" target="_blank">00:50:38.960</a></span> | <span class="t">So we run the convolution and then we flatten them here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3043" target="_blank">00:50:43.440</a></span> | <span class="t">So basically the convolution will give us 1 2 3 4 5 6 up to 16 or whatever the number of patches is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3049" target="_blank">00:50:49.920</a></span> | <span class="t">and then we convert it into a tensor where the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3052" target="_blank">00:50:52.800</a></span> | <span class="t">The patches are flattened</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3055" target="_blank">00:50:55.120</a></span> | <span class="t">So the first patch is here and the last patch is the last element of this tensor and this is what we do here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3060" target="_blank">00:51:00.880</a></span> | <span class="t">Here because the output of the convolution is a 2x2 grid, but we don't want a 2x2 grid</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3067" target="_blank">00:51:07.520</a></span> | <span class="t">We only want a one-dimensional long list of patches and this is done by this flatten method here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3073" target="_blank">00:51:13.520</a></span> | <span class="t">Then we transpose because we want the number of patches to come before the embedding dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3079" target="_blank">00:51:19.300</a></span> | <span class="t">Because as input to the transfer we need to give a sequence of embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3084" target="_blank">00:51:24.480</a></span> | <span class="t">So that's why we want this num_patches dimension to come before so that it becomes a batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3089" target="_blank">00:51:29.600</a></span> | <span class="t">of sequence of embeddings and each embedding is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3093" target="_blank">00:51:33.360</a></span> | <span class="t">vector of size embedding dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3097" target="_blank">00:51:37.360</a></span> | <span class="t">Each of these embeddings we add the positional encodings which positional encodings? Well the position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3102" target="_blank">00:51:42.400</a></span> | <span class="t">Extracted from this embedding layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3106" target="_blank">00:51:46.140</a></span> | <span class="t">But which embedding do we want to extract? All the embeddings. So from 0 to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3110" target="_blank">00:51:50.160</a></span> | <span class="t">Suppose we have 16 patches from 0 to 15</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3113" target="_blank">00:51:53.440</a></span> | <span class="t">What is the where is this information 0 to 15 is in this self dot position and this which is a range</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3120" target="_blank">00:52:00.080</a></span> | <span class="t">So as you remember a range is just a generates a list of numbers between 0 and the argument minus 1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3126" target="_blank">00:52:06.960</a></span> | <span class="t">So we add we extract this the all the positional encodings from this position embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3132" target="_blank">00:52:12.240</a></span> | <span class="t">Layer, which is this embedding layer here. We add it to the embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3136" target="_blank">00:52:16.880</a></span> | <span class="t">So what we are doing basically is we flatten this embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3140" target="_blank">00:52:20.320</a></span> | <span class="t">We did that before then we add a positional encoding vector extracted from the positional encoding layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3145" target="_blank">00:52:25.600</a></span> | <span class="t">And these positional encodings are learned. So learned why because this embedding layer here is a list of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3152" target="_blank">00:52:32.320</a></span> | <span class="t">embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3154" target="_blank">00:52:34.800</a></span> | <span class="t">That when the model is trained these embeddings will change according to the need of the model and basically we encode them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3162" target="_blank">00:52:42.640</a></span> | <span class="t">So it's not like we are telling the model. This is position number one. This is position number two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3168" target="_blank">00:52:48.000</a></span> | <span class="t">We add another embedding that is added to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3171" target="_blank">00:52:51.280</a></span> | <span class="t">patch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3172" target="_blank">00:52:52.960</a></span> | <span class="t">each of these patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3174" target="_blank">00:52:54.480</a></span> | <span class="t">And then the model will learn to modify this positional embedding vector in such a way that they should encode the position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3181" target="_blank">00:53:01.820</a></span> | <span class="t">Information because each of this position embedding is always added to the same patch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3187" target="_blank">00:53:07.020</a></span> | <span class="t">So the first patch always receives the position number zero the second patch always the position number one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3191" target="_blank">00:53:11.580</a></span> | <span class="t">We hope that the model actually tries to change this position embedding in such a way that they encode the positional information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3197" target="_blank">00:53:17.580</a></span> | <span class="t">and actually it does because the model actually learns then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3200" target="_blank">00:53:20.700</a></span> | <span class="t">to relate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3203" target="_blank">00:53:23.580</a></span> | <span class="t">Patch with each other by using their positional information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3207" target="_blank">00:53:27.660</a></span> | <span class="t">And the only way for the model to do that is to change this position embedding in such a way that they encode the position information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3213" target="_blank">00:53:33.840</a></span> | <span class="t">If you remember from the vanilla transformer, we use the sinusoidal functions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3218" target="_blank">00:53:38.300</a></span> | <span class="t">So if you want to look at the original transformer if you remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3221" target="_blank">00:53:41.580</a></span> | <span class="t">here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3223" target="_blank">00:53:43.740</a></span> | <span class="t">We have this position information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3225" target="_blank">00:53:45.740</a></span> | <span class="t">Where is it here? So we create this position encoding using sinusoidal functions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3232" target="_blank">00:53:52.780</a></span> | <span class="t">So instead of learning them we actually pre-compute them and then we force the model to learn the pattern</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3238" target="_blank">00:53:58.780</a></span> | <span class="t">Encoded by these sinusoidal functions in this case. We are not forcing the model to learn any pattern</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3244" target="_blank">00:54:04.060</a></span> | <span class="t">We want the model to create the pattern that is most useful for the model itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3248" target="_blank">00:54:08.220</a></span> | <span class="t">so we hope that the model will try to create this embedding layer in such a way that it creates some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3255" target="_blank">00:54:15.260</a></span> | <span class="t">embeddings that are helpful for the model to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3257" target="_blank">00:54:17.800</a></span> | <span class="t">to understand the position information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3260" target="_blank">00:54:20.780</a></span> | <span class="t">and this is the meaning of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3262" target="_blank">00:54:22.780</a></span> | <span class="t">position embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3264" target="_blank">00:54:24.540</a></span> | <span class="t">Now we skipped before the normalization layer. So let's go actually to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3269" target="_blank">00:54:29.020</a></span> | <span class="t">Understand what is normalization and how it works so that we always don't leave anything behind that is not explained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3276" target="_blank">00:54:36.620</a></span> | <span class="t">All right. Let's talk about normalization. So imagine we have a list of linear layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3282" target="_blank">00:54:42.460</a></span> | <span class="t">Now a linear layer is defined by two parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3286" target="_blank">00:54:46.700</a></span> | <span class="t">One is called the input features and one is called the output features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3290" target="_blank">00:54:50.220</a></span> | <span class="t">Imagine we have input feature is equal to four and output feature is equal to four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3294" target="_blank">00:54:54.300</a></span> | <span class="t">Actually, there is another parameter called bias</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3296" target="_blank">00:54:56.860</a></span> | <span class="t">So it indicates if the linear layer also has a bias term and suppose that it's true</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3302" target="_blank">00:55:02.540</a></span> | <span class="t">To the input of the linear layer usually we have a batch of items and each item is made up of features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3311" target="_blank">00:55:11.260</a></span> | <span class="t">Suppose that for now as input there is only one item and it's made up of four features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3315" target="_blank">00:55:15.820</a></span> | <span class="t">And as you can see the input features are four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3318" target="_blank">00:55:18.380</a></span> | <span class="t">What will happen with four output features is this the linear layer you can think of it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3324" target="_blank">00:55:24.220</a></span> | <span class="t">As a number of neurons where the number of neurons equal to the number of output feature of this linear layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3331" target="_blank">00:55:31.180</a></span> | <span class="t">what each neuron does is basically it has a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3334" target="_blank">00:55:34.780</a></span> | <span class="t">weight vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3337" target="_blank">00:55:37.900</a></span> | <span class="t">As you can see here made up of four weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3341" target="_blank">00:55:41.100</a></span> | <span class="t">How many weights does it have? Well equal to the number of input features that this layer accepts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3347" target="_blank">00:55:47.900</a></span> | <span class="t">So which is a four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3349" target="_blank">00:55:49.980</a></span> | <span class="t">What each neuron will do it will do the dot product of the incoming vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3355" target="_blank">00:55:55.100</a></span> | <span class="t">So the input vector x multiply dot product with the weight vector of this neuron plus the bias term</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3362" target="_blank">00:56:02.940</a></span> | <span class="t">Which is one number for each neuron</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3365" target="_blank">00:56:05.740</a></span> | <span class="t">And this basically dot product plus this bias will produce one output feature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3370" target="_blank">00:56:10.540</a></span> | <span class="t">Because we have four neurons. We will have four output features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3374" target="_blank">00:56:14.380</a></span> | <span class="t">So each neuron will do the same job, but each neuron will have its own weight vector and its own bias number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3380" target="_blank">00:56:20.540</a></span> | <span class="t">So this one here will have its own weight vector different from the other ones and its own bias term here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3385" target="_blank">00:56:25.900</a></span> | <span class="t">Then suppose that we have another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3388" target="_blank">00:56:28.860</a></span> | <span class="t">Vector that takes as input four features and produces two output features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3394" target="_blank">00:56:34.140</a></span> | <span class="t">So you can think of it as a linear layer with the two neurons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3398" target="_blank">00:56:38.140</a></span> | <span class="t">where the first neuron has a weight vector made up of four numbers because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3403" target="_blank">00:56:43.740</a></span> | <span class="t">The incoming vector has four features and then one bias term here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3407" target="_blank">00:56:47.740</a></span> | <span class="t">It will produce an output vector of two items</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3411" target="_blank">00:56:51.420</a></span> | <span class="t">The first item will be this number here and the second item</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3414" target="_blank">00:56:54.860</a></span> | <span class="t">The second dimension will be the dot product of the weight vector of this second neuron with the input vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3421" target="_blank">00:57:01.260</a></span> | <span class="t">plus the bias term of the second neuron</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3424" target="_blank">00:57:04.460</a></span> | <span class="t">Now, what is the problem with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3426" target="_blank">00:57:06.460</a></span> | <span class="t">With the linear layers, but actually with all layers in general</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3432" target="_blank">00:57:12.140</a></span> | <span class="t">The problem is this it's called the covariate shift. The problem is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3436" target="_blank">00:57:16.220</a></span> | <span class="t">When you have an input vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3438" target="_blank">00:57:18.860</a></span> | <span class="t">That changes from one batch to another in magnitude</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3444" target="_blank">00:57:24.240</a></span> | <span class="t">Then the output of the layer will also change in magnitude a lot depending on what is the incoming vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3452" target="_blank">00:57:32.860</a></span> | <span class="t">So for example, imagine this the first input vector is all the numbers are more or less around one and two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3460" target="_blank">00:57:40.460</a></span> | <span class="t">And the output is also more or less around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3463" target="_blank">00:57:43.580</a></span> | <span class="t">suppose around two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3465" target="_blank">00:57:45.980</a></span> | <span class="t">Then if the next vector that is coming to this layer is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3469" target="_blank">00:57:49.660</a></span> | <span class="t">Much different in magnitude from the first one then the output will also be much different in magnitude</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3475" target="_blank">00:57:55.360</a></span> | <span class="t">And this is a problem for the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3478" target="_blank">00:57:58.220</a></span> | <span class="t">So the problem is that if the input of a layer changes, then the output of this layer will also change a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3484" target="_blank">00:58:04.140</a></span> | <span class="t">So if the input changes drastically the output will also change a lot drastically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3488" target="_blank">00:58:08.160</a></span> | <span class="t">then because the loss of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3490" target="_blank">00:58:10.940</a></span> | <span class="t">Of a model during training depends on the output then the loss will also change a lot because the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3497" target="_blank">00:58:17.820</a></span> | <span class="t">Then determines the gradient during backpropagation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3501" target="_blank">00:58:21.200</a></span> | <span class="t">It means that if the loss changes a lot then also the gradient will change a lot and if the gradient changes a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3507" target="_blank">00:58:27.020</a></span> | <span class="t">Then because the gradient determines how we update the weights of the model during training then also the update of these weights will also change a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3514" target="_blank">00:58:34.300</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3516" target="_blank">00:58:36.300</a></span> | <span class="t">basically what happens is that the if the input the distribution of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3521" target="_blank">00:58:41.340</a></span> | <span class="t">Dimensions of this vector that is coming to the input of a layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3525" target="_blank">00:58:45.660</a></span> | <span class="t">Changes drastically from one batch to the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3529" target="_blank">00:58:49.260</a></span> | <span class="t">Then the output of the model will also change and then the loss will change then the gradient will change then the update of the weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3535" target="_blank">00:58:55.500</a></span> | <span class="t">Will change so what we will see that the loss will oscillate a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3539" target="_blank">00:58:59.020</a></span> | <span class="t">And also the weights will try to keep up with this changing input distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3543" target="_blank">00:59:03.840</a></span> | <span class="t">Which basically will result in a model that trains slowly. So here I have made a simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3549" target="_blank">00:59:09.900</a></span> | <span class="t">How to say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3553" target="_blank">00:59:13.580</a></span> | <span class="t">Summary of what is happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3554" target="_blank">00:59:14.700</a></span> | <span class="t">So a big change in the input of a layer will result in a big change in the output of a layer which will result</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3560" target="_blank">00:59:20.540</a></span> | <span class="t">In a big change in the loss of the model which will change result in a big change in the gradient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3565" target="_blank">00:59:25.840</a></span> | <span class="t">Of the during black propagation which will result in a big change in the weights of the network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3571" target="_blank">00:59:31.580</a></span> | <span class="t">And what is the result of this is that the network will learn very slowly because the network will spend most of its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3577" target="_blank">00:59:37.020</a></span> | <span class="t">Time but okay most of the effort trying to keep up with this distribution change in the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3583" target="_blank">00:59:43.580</a></span> | <span class="t">Instead of actually learning the features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3586" target="_blank">00:59:46.140</a></span> | <span class="t">How to map the input to the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3590" target="_blank">00:59:50.300</a></span> | <span class="t">So the the first solution to this problem was batch normalization, which was introduced in this paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3595" target="_blank">00:59:55.660</a></span> | <span class="t">And with batch normalization what we do basically is that we have usually not a single item as input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3601" target="_blank">01:00:01.740</a></span> | <span class="t">We have a batch of items suppose that we are training a classification image classification model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3607" target="_blank">01:00:07.260</a></span> | <span class="t">So we have as input a list of images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3610" target="_blank">01:00:10.460</a></span> | <span class="t">For example the image of a cat the image of a dog of a zebra of a tree of a stone etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3616" target="_blank">01:00:16.220</a></span> | <span class="t">So you can think these are the dimensions of the vector that represent the cat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3620" target="_blank">01:00:20.220</a></span> | <span class="t">These are the dimensions of the vector that represent the dog. These are the dimensions of the vector that represent the zebra etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3625" target="_blank">01:00:25.820</a></span> | <span class="t">So what we do with batch normalization is that we calculate a statistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3630" target="_blank">01:00:30.240</a></span> | <span class="t">For each dimension of each item</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3635" target="_blank">01:00:35.100</a></span> | <span class="t">Which statistic do we calculate the mean and the the variance and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3642" target="_blank">01:00:42.680</a></span> | <span class="t">Normalize each item by subtracting the mean and divide it by the standard deviation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3648" target="_blank">01:00:48.620</a></span> | <span class="t">this will basically make each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3651" target="_blank">01:00:51.020</a></span> | <span class="t">Dimension of each item be distributed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3654" target="_blank">01:00:54.380</a></span> | <span class="t">According to a Gaussian with mean zero and the variance of one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3658" target="_blank">01:00:58.780</a></span> | <span class="t">so basically what will happen is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3661" target="_blank">01:01:01.580</a></span> | <span class="t">each if we normalize each number if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3665" target="_blank">01:01:05.420</a></span> | <span class="t">Because the image of a cat is much different from the image of the zebra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3670" target="_blank">01:01:10.380</a></span> | <span class="t">Because the color distribution is different. The rgb distribution is different. So the pixel intensity is much different from each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3676" target="_blank">01:01:16.780</a></span> | <span class="t">What will happen is that the model will not see this change in magnitude</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3681" target="_blank">01:01:21.580</a></span> | <span class="t">but it will see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3683" target="_blank">01:01:23.100</a></span> | <span class="t">And also will not see a change in distribution because all of these items will be distributed according to a mean of zero and the variance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3690" target="_blank">01:01:30.140</a></span> | <span class="t">of one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3691" target="_blank">01:01:31.420</a></span> | <span class="t">So what will happen is that the model will oscillate less in the output. So it will oscillate less in the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3696" target="_blank">01:01:36.860</a></span> | <span class="t">So it will oscillate less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3699" target="_blank">01:01:39.260</a></span> | <span class="t">In the gradient, so it will make the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3701" target="_blank">01:01:41.500</a></span> | <span class="t">Weights of the model oscillate less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3704" target="_blank">01:01:44.300</a></span> | <span class="t">So the model the training will be more stable. It will be it will converge faster basically this way. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3710" target="_blank">01:01:50.940</a></span> | <span class="t">To summarize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3714" target="_blank">01:01:54.860</a></span> | <span class="t">Why do we need normalization is because the input of the model which depends on imagine you are training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3720" target="_blank">01:02:00.860</a></span> | <span class="t">Classification or the image classification model then the input depends on the image and the image can be much different from each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3727" target="_blank">01:02:07.580</a></span> | <span class="t">If the image changes a lot, we don't want the model to feel this change in magnitude of the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3733" target="_blank">01:02:13.500</a></span> | <span class="t">We want the distribution of the inputs to be remain constant. Let's say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3737" target="_blank">01:02:17.340</a></span> | <span class="t">So that the model doesn't oscillate so that this doesn't force the model to kind of just to keep up with the distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3744" target="_blank">01:02:24.560</a></span> | <span class="t">This change in distribution. How do we do that? We we try to keep the distributions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3749" target="_blank">01:02:29.520</a></span> | <span class="t">Constant so always try to have the input features to be distributed according to a fixed distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3755" target="_blank">01:02:35.100</a></span> | <span class="t">Which is mean of 0 and 1 and we do that with this formula here, which comes from probability statistics basically each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3762" target="_blank">01:02:42.060</a></span> | <span class="t">Distribution if you subtract its mean divided by the standard deviation, it will result in a Gaussian distribution of mean 0 and variance of 1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3769" target="_blank">01:02:49.980</a></span> | <span class="t">Of course, this is valid also only for Gaussian distributions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3774" target="_blank">01:02:54.480</a></span> | <span class="t">And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3778" target="_blank">01:02:58.220</a></span> | <span class="t">And this will basically result in a more stable training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3782" target="_blank">01:03:02.060</a></span> | <span class="t">Now the best distribution actually worked fine. However, it has a problem with the problem is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3787" target="_blank">01:03:07.580</a></span> | <span class="t">Which best normalization each of these statistics so the mu and the sigma are calculated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3793" target="_blank">01:03:13.840</a></span> | <span class="t">Along the batch dimension. So we calculate the mu and the sigma for the dimension number one of each of these vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3801" target="_blank">01:03:21.820</a></span> | <span class="t">Along the batch dimension. So basically to calculate this mean we are summing up the first dimension of each of these vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3809" target="_blank">01:03:29.420</a></span> | <span class="t">And divided by the number of items that we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3811" target="_blank">01:03:31.740</a></span> | <span class="t">So we are mixing the features of different items</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3815" target="_blank">01:03:35.820</a></span> | <span class="t">So we are mixing the dimension number one of the cat with the dimension number one of the dog</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3819" target="_blank">01:03:39.980</a></span> | <span class="t">And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3822" target="_blank">01:03:42.940</a></span> | <span class="t">so basically to to have good results, we need to use a big batch because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3827" target="_blank">01:03:47.660</a></span> | <span class="t">If we use for example a cat and the dog it will result in one mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3832" target="_blank">01:03:52.780</a></span> | <span class="t">But imagine in the next batch, we have the cat and the zebra it will result in a completely different mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3838" target="_blank">01:03:58.620</a></span> | <span class="t">And then the next supposing the next batch we have a cat and the tree maybe it results in another different mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3844" target="_blank">01:04:04.700</a></span> | <span class="t">So also we will still have this problem of covariance shift because the mean is changing a lot between each iteration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3851" target="_blank">01:04:11.120</a></span> | <span class="t">So the only solution to this actually is to use a very big batch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3855" target="_blank">01:04:15.340</a></span> | <span class="t">So we are forced to use a big batch size in order to alleviate this problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3859" target="_blank">01:04:19.660</a></span> | <span class="t">Of kind of mixing the dimensions along the batch dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3865" target="_blank">01:04:25.980</a></span> | <span class="t">We introduce the layer normalization with layer normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3868" target="_blank">01:04:28.860</a></span> | <span class="t">What we do is instead of calculating the statistics along the batch dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3873" target="_blank">01:04:33.900</a></span> | <span class="t">We calculate them along the item dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3876" target="_blank">01:04:36.220</a></span> | <span class="t">So the mu and the sigma that will be used to standardize the cat will only be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3881" target="_blank">01:04:41.900</a></span> | <span class="t">Dependent on the dimensions of the cat not on the whatever the cat comes with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3888" target="_blank">01:04:48.300</a></span> | <span class="t">So we are still doing each item minus its mean divided by the standard deviation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3895" target="_blank">01:04:55.580</a></span> | <span class="t">But instead of this standard deviation and this mean coming from the first dimension of each item</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3900" target="_blank">01:05:00.620</a></span> | <span class="t">It comes from the average of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3903" target="_blank">01:05:03.180</a></span> | <span class="t">All the dimensions of the each item independently from the others</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3907" target="_blank">01:05:07.420</a></span> | <span class="t">So it doesn't matter which other item the cat comes with it will always result in more or less the same mu and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3914" target="_blank">01:05:14.140</a></span> | <span class="t">Same sigma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3917" target="_blank">01:05:17.660</a></span> | <span class="t">And this makes the training even more stable because we are not forced to use a big batch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3924" target="_blank">01:05:24.620</a></span> | <span class="t">And this is why we use normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3927" target="_blank">01:05:27.120</a></span> | <span class="t">Okay, we have seen what is normalization now we should implement what is this thing called the encoder so this is Sigleap encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3936" target="_blank">01:05:36.700</a></span> | <span class="t">Now the encoder is made up of multiple layers of the transformer model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3941" target="_blank">01:05:41.980</a></span> | <span class="t">And the architecture more or less if you look at the vision transformer paper, it is like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3947" target="_blank">01:05:47.580</a></span> | <span class="t">So I changed it a little bit because I wanted to use the exact names that we will be using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3953" target="_blank">01:05:53.660</a></span> | <span class="t">So we have first of all what we have so far is this thing called the Sigleap vision embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3958" target="_blank">01:05:58.460</a></span> | <span class="t">Which is basically taking the image it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3960" target="_blank">01:06:00.540</a></span> | <span class="t">Taking some patches of this image using a convolution each of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3965" target="_blank">01:06:05.740</a></span> | <span class="t">Output of this convolution is an embedding is used as an embedding. It's a vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3970" target="_blank">01:06:10.380</a></span> | <span class="t">And this embedding vector is added to another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3974" target="_blank">01:06:14.300</a></span> | <span class="t">Vector called the positional encoding which is learned and then we feed this stuff to this thing called the encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3981" target="_blank">01:06:21.260</a></span> | <span class="t">So we convert it into embeddings at the positional encoding then we feed it to the encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3985" target="_blank">01:06:25.340</a></span> | <span class="t">And at the input of the encoder you need to think that we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3988" target="_blank">01:06:28.620</a></span> | <span class="t">These layers repeated n times here. It's written l times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3993" target="_blank">01:06:33.340</a></span> | <span class="t">One after another such that the output of one becomes the input of the next layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=3998" target="_blank">01:06:38.780</a></span> | <span class="t">the thing that you need to understand about the transformer is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4002" target="_blank">01:06:42.460</a></span> | <span class="t">I repeat it is that the transformer is a sequence-to-sequence model that converts a sequence of embeddings into contextualized embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4011" target="_blank">01:06:51.280</a></span> | <span class="t">What does it mean? It means that at the input you have a list of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4014" target="_blank">01:06:54.560</a></span> | <span class="t">Here embeddings each representing a patch of the image as an independent patch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4021" target="_blank">01:07:01.520</a></span> | <span class="t">So this embedding here only captures information about the first group of pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4026" target="_blank">01:07:06.000</a></span> | <span class="t">This embedding here captures all information about the second group of pixels, etc, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4030" target="_blank">01:07:10.560</a></span> | <span class="t">But then some through some magic called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4033" target="_blank">01:07:13.760</a></span> | <span class="t">Attention mechanism this contextualized these embeddings become contextualized at the output of the transformer and we will see in detail this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4041" target="_blank">01:07:21.520</a></span> | <span class="t">attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4043" target="_blank">01:07:23.600</a></span> | <span class="t">Such that this embedding here at the output of the transformer the first embedding is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4048" target="_blank">01:07:28.240</a></span> | <span class="t">represents information about the first patch plus other it includes information not only about the first part but also about other patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4056" target="_blank">01:07:36.080</a></span> | <span class="t">And so is the second the third the fourth and the last one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4060" target="_blank">01:07:40.320</a></span> | <span class="t">So they become contextualized in the sense that they capture information about the context in which they appear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4066" target="_blank">01:07:46.400</a></span> | <span class="t">Which is different from language models in which each token captures information about the previous tokens in the case of the vision transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4074" target="_blank">01:07:54.560</a></span> | <span class="t">Each patch includes information about all the other patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4077" target="_blank">01:07:57.600</a></span> | <span class="t">Now each of these layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4081" target="_blank">01:08:01.440</a></span> | <span class="t">is made up of so we have the this is the input of the encoder let's say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4087" target="_blank">01:08:07.360</a></span> | <span class="t">And we will have the first layer of this encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4090" target="_blank">01:08:10.480</a></span> | <span class="t">The first thing that we do is we apply a layer normalization and we saw how it works and why we use it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4095" target="_blank">01:08:15.840</a></span> | <span class="t">The output of this layer normalization is a cop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4098" target="_blank">01:08:18.800</a></span> | <span class="t">First the input of this linear normalization is saved for a skip connection that we do later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4103" target="_blank">01:08:23.680</a></span> | <span class="t">Then the output of this layer normalization is sent to the self-attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4108" target="_blank">01:08:28.260</a></span> | <span class="t">It's this one here and this self-attention mechanism takes the output of the layer normalization as a query key and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4117" target="_blank">01:08:37.520</a></span> | <span class="t">It calculates the attention just like the usual formula</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4120" target="_blank">01:08:40.000</a></span> | <span class="t">So softmax of the query multiplied by the transpose of the key divided by the square root of the model multiplied by v etc etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4126" target="_blank">01:08:46.000</a></span> | <span class="t">The output of this self-attention is then summed up with this skip connection here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4131" target="_blank">01:08:51.920</a></span> | <span class="t">Then the output of this summation is sent to this layer normalization along with the skip connection that is used later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4138" target="_blank">01:08:58.480</a></span> | <span class="t">Then the output of the normalization is sent to this multi-layer perceptron, which is a list of linear layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4143" target="_blank">01:09:03.840</a></span> | <span class="t">We will see later and then we do another summation here with the skip connection plus the output of the multi-layer perceptron</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4150" target="_blank">01:09:10.180</a></span> | <span class="t">And then we do another layer like this and another another another and the output of the last layer is the output of our vision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4158" target="_blank">01:09:18.320</a></span> | <span class="t">transformer. So as you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4160" target="_blank">01:09:20.380</a></span> | <span class="t">the vision transformer takes as an input an image converted into patches. Patches are then fed to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4168" target="_blank">01:09:28.160</a></span> | <span class="t">Encoder which is a list of layers and the output is a contextualized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4171" target="_blank">01:09:31.140</a></span> | <span class="t">patches or embeddings of these patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4173" target="_blank">01:09:33.860</a></span> | <span class="t">So let's code this encoder, which is basically this structure here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4179" target="_blank">01:09:39.120</a></span> | <span class="t">And we will code each part of this structure and while coding each part we will go inside on how it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4186" target="_blank">01:09:46.880</a></span> | <span class="t">So the normalization we already know how it works, but we still have to explore what is this stuff here called the self-attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4192" target="_blank">01:09:52.580</a></span> | <span class="t">What is this stuff here called multi-layer perceptron?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4196" target="_blank">01:09:56.240</a></span> | <span class="t">I believe it's convenient for us to go first through multi-layer perceptron and then we go to the self-attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4202" target="_blank">01:10:02.080</a></span> | <span class="t">I think because the self-attention is a little longer to do. So let me do the simple part first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4206" target="_blank">01:10:06.480</a></span> | <span class="t">Okay, let's code this encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4209" target="_blank">01:10:09.920</a></span> | <span class="t">Now I will copy the first part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4213" target="_blank">01:10:13.440</a></span> | <span class="t">This one here, so let's copy it here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4217" target="_blank">01:10:17.520</a></span> | <span class="t">So the encoder is made up of again, the constructor is made up of the configuration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4222" target="_blank">01:10:22.240</a></span> | <span class="t">We save some stuff which is the hidden size and then we have a block called the self-attention block in this call this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4228" target="_blank">01:10:28.000</a></span> | <span class="t">Here it's called the siglib attention. Now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4231" target="_blank">01:10:31.200</a></span> | <span class="t">Note about the naming I'm using. So I am using the same names as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4235" target="_blank">01:10:35.600</a></span> | <span class="t">the HuggingFace implementation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4238" target="_blank">01:10:38.560</a></span> | <span class="t">For only simple reason which is I want to be able to load the pre-trained weights from HuggingFace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4244" target="_blank">01:10:44.240</a></span> | <span class="t">So the pre-trained weights for the polygam are available on the HuggingFace hub</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4249" target="_blank">01:10:49.600</a></span> | <span class="t">So we want to be able to load them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4251" target="_blank">01:10:51.680</a></span> | <span class="t">But each of these pre-load pre-trained models they have this dictionary of weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4257" target="_blank">01:10:57.040</a></span> | <span class="t">So where the dictionary tells you where to load each of these weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4261" target="_blank">01:11:01.520</a></span> | <span class="t">And if the names do not match you need to create some conversion script</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4264" target="_blank">01:11:04.720</a></span> | <span class="t">So I didn't want to do that and also it would just complicate the code uselessly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4268" target="_blank">01:11:08.980</a></span> | <span class="t">So I just use the same names so that we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4272" target="_blank">01:11:12.240</a></span> | <span class="t">Load basically the pre-trained weights from HuggingFace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4277" target="_blank">01:11:17.440</a></span> | <span class="t">Also because my code is based on the HuggingFace implementation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4280" target="_blank">01:11:20.480</a></span> | <span class="t">So to create my code I use the HuggingFace implementation, but simplified a lot a lot a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4285" target="_blank">01:11:25.680</a></span> | <span class="t">For example, I remade my own KVCache. I did a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4289" target="_blank">01:11:29.040</a></span> | <span class="t">Modifications to simplify it but it's based on the HuggingFace implementation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4294" target="_blank">01:11:34.100</a></span> | <span class="t">anyway</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4296" target="_blank">01:11:36.080</a></span> | <span class="t">So we have this thing called the self-attention then we have a layer normalization. So we saw it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4300" target="_blank">01:11:40.400</a></span> | <span class="t">Where is it? And we have this layer normalization here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4303" target="_blank">01:11:43.360</a></span> | <span class="t">Then we have this multi-layer perceptron, which is this stuff here. And then we have another layer normalization, which is this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4309" target="_blank">01:11:49.920</a></span> | <span class="t">So we have two layer normalization. So now let's implement the forward method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4314" target="_blank">01:11:54.480</a></span> | <span class="t">And the forward method I will copy it line by line so we can understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4318" target="_blank">01:11:58.960</a></span> | <span class="t">Okay this forward method. Now. The first thing we do is we save a residual connection, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4325" target="_blank">01:12:05.680</a></span> | <span class="t">We basically save the input that we feed to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4329" target="_blank">01:12:09.260</a></span> | <span class="t">Encoder because we need to reuse it later. So we are saving this skip connection because we will need to use it here later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4334" target="_blank">01:12:14.860</a></span> | <span class="t">Then we run it through the layer normalization the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4339" target="_blank">01:12:19.500</a></span> | <span class="t">And it's done here. So the layer normalization does not change the shape of the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4345" target="_blank">01:12:25.020</a></span> | <span class="t">It's just normalizing each of these dimensions such that they they all come up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4350" target="_blank">01:12:30.700</a></span> | <span class="t">It's like they came out from a Gaussian of mean zero and variance of one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4356" target="_blank">01:12:36.860</a></span> | <span class="t">Then we apply this magic thing that we will explore later called the self-attention and the self-attention system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4362" target="_blank">01:12:42.380</a></span> | <span class="t">Also does not change the shape of the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4364" target="_blank">01:12:44.700</a></span> | <span class="t">Tensor, but as we saw before the attention mechanism is something that takes as input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4370" target="_blank">01:12:50.140</a></span> | <span class="t">Embeddings and gives you contextualized embeddings. So it does not change the shape of these embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4375" target="_blank">01:12:55.600</a></span> | <span class="t">But we will implement it later. So for now just think of it as a black box that you feed in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4380" target="_blank">01:13:00.700</a></span> | <span class="t">Embeddings and it gives you contextualized embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4383" target="_blank">01:13:03.980</a></span> | <span class="t">Then we have a residual connection and we can see that here. So this residual connection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4389" target="_blank">01:13:09.500</a></span> | <span class="t">Skip connection was called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4392" target="_blank">01:13:12.220</a></span> | <span class="t">Which is this first plus here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4394" target="_blank">01:13:14.060</a></span> | <span class="t">So we are taking what we saved before with the output of the self-attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4398" target="_blank">01:13:18.300</a></span> | <span class="t">So what we saved before is this residual stuff here plus the output of the self-attention, which is this hidden states here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4403" target="_blank">01:13:23.740</a></span> | <span class="t">This the result of the summation is saved again because there is another skip connection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4409" target="_blank">01:13:29.100</a></span> | <span class="t">after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4411" target="_blank">01:13:31.580</a></span> | <span class="t">I don't know why my alt tab is not working. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4413" target="_blank">01:13:33.580</a></span> | <span class="t">We save again another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4416" target="_blank">01:13:36.380</a></span> | <span class="t">This stuff here. So we save it because later we need to use it here for the skip connection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4420" target="_blank">01:13:40.860</a></span> | <span class="t">Then we do I guess another linear layer normalization which also does not change the shape of the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4429" target="_blank">01:13:49.340</a></span> | <span class="t">tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4432" target="_blank">01:13:52.060</a></span> | <span class="t">And then we have this thing called the multilayer perceptron. Now the multilayer perceptron is something that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4437" target="_blank">01:13:57.820</a></span> | <span class="t">It's not easy to explain what is used for but basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4441" target="_blank">01:14:01.100</a></span> | <span class="t">The multilayer perceptron we will see later is a series of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4445" target="_blank">01:14:05.100</a></span> | <span class="t">Linear layers that takes each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4449" target="_blank">01:14:09.740</a></span> | <span class="t">input embedding and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4453" target="_blank">01:14:13.500</a></span> | <span class="t">Transforms it independently from each other from the others</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4457" target="_blank">01:14:17.820</a></span> | <span class="t">So while in the self-attention there is kind of a mixing of the patches incoming so that you get contextualized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4464" target="_blank">01:14:24.380</a></span> | <span class="t">In the multilayer perceptron, there is no mixing between these let's call them tokens or patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4469" target="_blank">01:14:29.180</a></span> | <span class="t">Each of them is transformed independently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4472" target="_blank">01:14:32.560</a></span> | <span class="t">And the multilayer perceptron allow us to increase basically first of all it adds parameters to the model. So the model has more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4480" target="_blank">01:14:40.060</a></span> | <span class="t">Degrees of freedom to learn whatever it's trying to learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4483" target="_blank">01:14:43.980</a></span> | <span class="t">and the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4486" target="_blank">01:14:46.380</a></span> | <span class="t">Objective of the multilayer perceptron is that it allow to prepare</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4490" target="_blank">01:14:50.220</a></span> | <span class="t">Let's say prepare the the sequence of patches for the next layer. So if the next layer expect these patches to be somehow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4497" target="_blank">01:14:57.980</a></span> | <span class="t">Different the multilayer perceptron allow to transform them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4502" target="_blank">01:15:02.300</a></span> | <span class="t">Also, it adds a non-linearity. So the multilayer perceptron also includes a non-linearity which adds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4508" target="_blank">01:15:08.060</a></span> | <span class="t">Which basically allow as you know non-linearities allow you to model more complex transformations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4515" target="_blank">01:15:15.900</a></span> | <span class="t">So if you just create a list of linear layers without any non-linearities that you cannot model complex functions so that for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4522" target="_blank">01:15:22.220</a></span> | <span class="t">in the classification you cannot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4524" target="_blank">01:15:24.300</a></span> | <span class="t">Map non-linearly separable data, but with by adding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4529" target="_blank">01:15:29.900</a></span> | <span class="t">Non-linear transformations you add complexity to the model. So the model is able to map complex transformations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4538" target="_blank">01:15:38.400</a></span> | <span class="t">So the multilayer perceptron just adds parameters and this non-linearity which is helpful to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4545" target="_blank">01:15:45.420</a></span> | <span class="t">To to allow the model to learn whatever complexity it needs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4549" target="_blank">01:15:49.180</a></span> | <span class="t">To to map the input to the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4552" target="_blank">01:15:52.620</a></span> | <span class="t">After the multilayer perceptron, I guess we have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4557" target="_blank">01:15:57.740</a></span> | <span class="t">Yeah, we have another skip connection and then we return the output of this skip connection here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4564" target="_blank">01:16:04.140</a></span> | <span class="t">and also the skip connection does not change the shape of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4567" target="_blank">01:16:07.260</a></span> | <span class="t">Of the tensors of the embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4570" target="_blank">01:16:10.880</a></span> | <span class="t">Now, let's code first this multilayer perceptron. It's the easiest stuff to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4575" target="_blank">01:16:15.100</a></span> | <span class="t">So let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4577" target="_blank">01:16:17.100</a></span> | <span class="t">uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4578" target="_blank">01:16:18.300</a></span> | <span class="t">Let's go here. I I will also always copy first the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4581" target="_blank">01:16:21.980</a></span> | <span class="t">Constructor and then the forward method so we can explore a little bit the structure and then we explore the logic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4587" target="_blank">01:16:27.660</a></span> | <span class="t">So this multilayer perceptron just like in the vanilla transformer is made up of two layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4593" target="_blank">01:16:33.660</a></span> | <span class="t">plus a non-linear transformation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4596" target="_blank">01:16:36.780</a></span> | <span class="t">So the first layer takes each of the embeddings which are we we can also call them tokens or patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4603" target="_blank">01:16:43.820</a></span> | <span class="t">Because most of the time we are dealing with language models and expands them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4607" target="_blank">01:16:47.980</a></span> | <span class="t">So each of these vectors which is of size hidden size is expanded into this thing called intermediate size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4615" target="_blank">01:16:55.180</a></span> | <span class="t">Usually it's chosen as three times the hidden size or four times the hidden size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4620" target="_blank">01:17:00.380</a></span> | <span class="t">I remember in the vanilla transformer it was four times the hidden size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4623" target="_blank">01:17:03.260</a></span> | <span class="t">Then we apply a non-linearity to this expanded tensor and then we compress it back to the hidden size dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4632" target="_blank">01:17:12.780</a></span> | <span class="t">So let's do the forward method now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4634" target="_blank">01:17:14.780</a></span> | <span class="t">Which is this one here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4637" target="_blank">01:17:17.420</a></span> | <span class="t">So the first thing we do is we convert each of these embedded dimensions into intermediate sizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4643" target="_blank">01:17:23.340</a></span> | <span class="t">So again, we have a batch of images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4646" target="_blank">01:17:26.060</a></span> | <span class="t">Each image is made up of num_patches number of patches each of this patch is represented by a vector of size embedding dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4653" target="_blank">01:17:33.420</a></span> | <span class="t">With the first fully connected layer, we are expanding each of these patches into the intermediate size and then we apply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4662" target="_blank">01:17:42.460</a></span> | <span class="t">A non-linear transformation in this case. It's the gelu function now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4666" target="_blank">01:17:46.380</a></span> | <span class="t">You may be wondering why are we using the gelu function or the zwiglu function or whatever non-linearity there is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4672" target="_blank">01:17:52.620</a></span> | <span class="t">The reason is always practical. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4675" target="_blank">01:17:55.660</a></span> | <span class="t">Basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4678" target="_blank">01:17:58.540</a></span> | <span class="t">There is a there is no like a rule of thumb for choosing the non-linearities to use for a specific case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4685" target="_blank">01:18:05.020</a></span> | <span class="t">There are just some heuristics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4687" target="_blank">01:18:07.820</a></span> | <span class="t">And the heuristics is that initially the transformer when it was introduced it was with the gelu function as non-linearities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4693" target="_blank">01:18:13.840</a></span> | <span class="t">between these two fully connected layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4696" target="_blank">01:18:16.540</a></span> | <span class="t">But then people explored other non-linearities and they saw that they work better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4701" target="_blank">01:18:21.500</a></span> | <span class="t">Now non-linearity is actually there is also some logic behind the choice of a non-linearity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4705" target="_blank">01:18:25.980</a></span> | <span class="t">So because the non-linearity define also the flow of the gradient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4709" target="_blank">01:18:29.820</a></span> | <span class="t">So for example, if you use the gelu function, if you look at the graph of the gelu function, let me draw it actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4716" target="_blank">01:18:36.940</a></span> | <span class="t">The graph of the gelu function is something like this. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4719" target="_blank">01:18:39.580</a></span> | <span class="t">Why I cannot draw it, okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4723" target="_blank">01:18:43.020</a></span> | <span class="t">So basically anything that is negative is zero. Let me use another color</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4729" target="_blank">01:18:49.100</a></span> | <span class="t">Anything that is negative is becomes zero basically and everything else is forwarded without any scaling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4736" target="_blank">01:18:56.880</a></span> | <span class="t">So this means that if the input of the gelu function is negative the output will be zero and actually for any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4746" target="_blank">01:19:06.220</a></span> | <span class="t">Negative input there will be no gradient because the gradient will be multiplied by zero. So it will not flow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4750" target="_blank">01:19:10.860</a></span> | <span class="t">That's why for example, we introduced the leaky relu and other like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4754" target="_blank">01:19:14.940</a></span> | <span class="t">In the relu family, there are other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4758" target="_blank">01:19:18.060</a></span> | <span class="t">Functions that allow also a little bit of gradient flow from the negative side</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4763" target="_blank">01:19:23.660</a></span> | <span class="t">So the non-linearity basically tells you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4767" target="_blank">01:19:27.020</a></span> | <span class="t">How the gradient will flow during back propagation. So having a non-linearity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4775" target="_blank">01:19:35.980</a></span> | <span class="t">that allows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4777" target="_blank">01:19:37.980</a></span> | <span class="t">That allows the gradient to flow back even when it's negative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4780" target="_blank">01:19:40.940</a></span> | <span class="t">It means that the signal the model is not forced to always have the activation to be positive to have some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4786" target="_blank">01:19:46.860</a></span> | <span class="t">Feedback from the loss function to optimize its weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4789" target="_blank">01:19:49.900</a></span> | <span class="t">And why we are using the gelu because people have tried it and probably it works better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4796" target="_blank">01:19:56.780</a></span> | <span class="t">compared to the relu function for the same class of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4800" target="_blank">01:20:00.140</a></span> | <span class="t">applications so in the vision transformer you see the gelu function, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4805" target="_blank">01:20:05.020</a></span> | <span class="t">In the lama, for example, they use the zwiglu function in other scenarios</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4808" target="_blank">01:20:08.300</a></span> | <span class="t">They use other functions and it's mostly based on heuristics on how they work in practice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4813" target="_blank">01:20:13.980</a></span> | <span class="t">also, because a model is usually made up of billions and billions and billions of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4819" target="_blank">01:20:19.180</a></span> | <span class="t">of parameters and it's not easy to find the regular regularity to understand why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4824" target="_blank">01:20:24.860</a></span> | <span class="t">Specific non-linearity is working better than the other one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4830" target="_blank">01:20:30.380</a></span> | <span class="t">Now, okay, then we apply the second linear layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4833" target="_blank">01:20:33.980</a></span> | <span class="t">Which is basically recompressing back this intermediate state into the embedding size and then we return it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4839" target="_blank">01:20:39.980</a></span> | <span class="t">and this is our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4842" target="_blank">01:20:42.860</a></span> | <span class="t">multilayer perceptron</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4844" target="_blank">01:20:44.860</a></span> | <span class="t">our next part is going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4847" target="_blank">01:20:47.340</a></span> | <span class="t">we are going to code this attention mechanism for the vision transformer and we will see that it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4853" target="_blank">01:20:53.340</a></span> | <span class="t">Different than from those of language models because we don't have any causal mask or attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4859" target="_blank">01:20:59.980</a></span> | <span class="t">All right guys, so we have seen the multilayer perceptron now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4864" target="_blank">01:21:04.460</a></span> | <span class="t">Let's go to the multi-head attention and for that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4867" target="_blank">01:21:07.180</a></span> | <span class="t">I want to use the slides because I believe it's a little faster to explain on the slides and then we proceed with the code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4873" target="_blank">01:21:13.420</a></span> | <span class="t">So what is the multi-head attention? The multi-head attention is a way of contextualizing stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4879" target="_blank">01:21:19.420</a></span> | <span class="t">Which means that you start with a sequence of for example patches and you can think we have for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4886" target="_blank">01:21:26.140</a></span> | <span class="t">Four patches each of this patch is represented by a single vector of 1024 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4892" target="_blank">01:21:32.620</a></span> | <span class="t">So you need to think of this as a vector of 1024 dimensions. So you need to think there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4897" target="_blank">01:21:37.340</a></span> | <span class="t">1024 numbers in this row vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4900" target="_blank">01:21:40.700</a></span> | <span class="t">Then we have the patch number two the patch number three and the patch number four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4904" target="_blank">01:21:44.700</a></span> | <span class="t">Each of this patch was extracted from a group of pixels from the initial image and it's only representing information about the patch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4911" target="_blank">01:21:51.980</a></span> | <span class="t">It was extracted from so the part of the image it came from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4916" target="_blank">01:21:56.300</a></span> | <span class="t">With the multi-head attention system. We uh, what we mechanism what we are doing is we are contextualizing these patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4923" target="_blank">01:22:03.820</a></span> | <span class="t">Which means that the output of the multi-head attention is a tensor of the same size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4928" target="_blank">01:22:08.300</a></span> | <span class="t">As the input so this is a tensor of size 4 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4932" target="_blank">01:22:12.480</a></span> | <span class="t">the output will be a tensor of size 4 by 1024, but where each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4939" target="_blank">01:22:19.260</a></span> | <span class="t">Embeddings now does not capture information only about itself, but also about the other patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4945" target="_blank">01:22:25.820</a></span> | <span class="t">in the in the sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4947" target="_blank">01:22:27.820</a></span> | <span class="t">This is for vision transformer for the language models we want something slightly different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4954" target="_blank">01:22:34.220</a></span> | <span class="t">So for language models, we do have an input sequence, which is a sequence of tokens each token representing one single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4961" target="_blank">01:22:41.020</a></span> | <span class="t">I don't want to use the term word because it's wrong but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4964" target="_blank">01:22:44.780</a></span> | <span class="t">In my videos, I always make the simplification that each token is a word and each word is a token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4969" target="_blank">01:22:49.740</a></span> | <span class="t">But this is not the case actually in tokenizer. So usually a token can be just any sequence of characters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4976" target="_blank">01:22:56.320</a></span> | <span class="t">Does not does not necessarily be um, it does not need to be necessarily a word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4981" target="_blank">01:23:01.660</a></span> | <span class="t">But for us let's treat them as word. It's just simplifies the explanation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4985" target="_blank">01:23:05.840</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4987" target="_blank">01:23:07.340</a></span> | <span class="t">We have a list of tokens. Each token is represented as an embedding. Let's say of 1024 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4994" target="_blank">01:23:14.140</a></span> | <span class="t">So it's a vector of 1024 dimensions. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=4997" target="_blank">01:23:17.400</a></span> | <span class="t">1024 numbers for this one 1024 numbers for this one, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5001" target="_blank">01:23:21.720</a></span> | <span class="t">The multi-head attention in the case of language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5005" target="_blank">01:23:25.480</a></span> | <span class="t">What we want is we want to contextualize each token with the all the tokens that come before it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5011" target="_blank">01:23:31.640</a></span> | <span class="t">So the output of the multi-head attention in the case of language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5015" target="_blank">01:23:35.560</a></span> | <span class="t">And this is this would be known as the self-attention mechanism with causal mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5023" target="_blank">01:23:43.160</a></span> | <span class="t">Is a sequence with the same shape as the input sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5027" target="_blank">01:23:47.320</a></span> | <span class="t">So this vector this matrix here is a 4 by 1024. So the output will be 4 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5033" target="_blank">01:23:53.180</a></span> | <span class="t">And each of these tokens is not capturing information only about itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5040" target="_blank">01:24:00.120</a></span> | <span class="t">But also about all the past tokens now the word I does not have any past token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5044" target="_blank">01:24:04.920</a></span> | <span class="t">So it will only capture information about itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5047" target="_blank">01:24:07.720</a></span> | <span class="t">But the word love will capture information also about the token I because it comes before it and the word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5053" target="_blank">01:24:13.160</a></span> | <span class="t">Pepperoni will capture information about I and love because they come before it etc, etc until the last token which capture information about all the sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5061" target="_blank">01:24:21.080</a></span> | <span class="t">Why do we want to do this in language models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5065" target="_blank">01:24:25.160</a></span> | <span class="t">Let me give you a little understanding of why we do it in this way with language models and why the transformer is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5072" target="_blank">01:24:32.280</a></span> | <span class="t">revolutionary for language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5075" target="_blank">01:24:35.480</a></span> | <span class="t">This is going a little off topic with respect to the vision transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5078" target="_blank">01:24:38.600</a></span> | <span class="t">But I think if you understand this then you will understand the big part of the transformer and why it even exists</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5083" target="_blank">01:24:43.640</a></span> | <span class="t">So let's copy this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5086" target="_blank">01:24:46.120</a></span> | <span class="t">Let's open a new page</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5088" target="_blank">01:24:48.600</a></span> | <span class="t">Now what we do with the language models is you need to think that a language model is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5093" target="_blank">01:24:53.640</a></span> | <span class="t">Something that we need to we retrain on what is known as the next token prediction task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5099" target="_blank">01:24:59.480</a></span> | <span class="t">Which means that given a prompt the language model try to understand what is the next token that completes this prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5105" target="_blank">01:25:05.560</a></span> | <span class="t">How do we generate text with the language model? We start with some tokens, which are the prompt we generate the next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5111" target="_blank">01:25:11.480</a></span> | <span class="t">We put it back into the prompt and we ask again the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5114" target="_blank">01:25:14.120</a></span> | <span class="t">What is the next token the language model gives us the next token?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5116" target="_blank">01:25:16.680</a></span> | <span class="t">Then we put it back into the prompt and then we ask again. What is the next token etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5120" target="_blank">01:25:20.280</a></span> | <span class="t">So we need to train a language model to train a language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5124" target="_blank">01:25:24.600</a></span> | <span class="t">We need to train a model to predict the next token given the past tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5129" target="_blank">01:25:29.320</a></span> | <span class="t">And the transformer allow us to do that in parallel when training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5135" target="_blank">01:25:35.000</a></span> | <span class="t">Which means that we start with an input that is a series of embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5139" target="_blank">01:25:39.340</a></span> | <span class="t">Which are uncontextualized so we start with this one and each of these actually is one single token. So this is only I this is only love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5147" target="_blank">01:25:47.960</a></span> | <span class="t">This is a pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5150" target="_blank">01:25:50.760</a></span> | <span class="t">And this is a pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5154" target="_blank">01:25:54.600</a></span> | <span class="t">The output of the transformer of the self-attention mechanism will be a series of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5161" target="_blank">01:26:01.400</a></span> | <span class="t">embeddings that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5164" target="_blank">01:26:04.420</a></span> | <span class="t">Uncontextualized in such a way that each token captures information of only about itself, but also about all the past tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5171" target="_blank">01:26:11.240</a></span> | <span class="t">How do we train and the transformer can do it in parallel?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5174" target="_blank">01:26:14.840</a></span> | <span class="t">So the self-attention mechanism will take this as input and generate this output in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5179" target="_blank">01:26:19.800</a></span> | <span class="t">So it's not will generate one token at a time, but it will generate all of them in the in parallel using this multi-head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5187" target="_blank">01:26:27.240</a></span> | <span class="t">How do we train a language model basically?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5191" target="_blank">01:26:31.340</a></span> | <span class="t">As we saw before the language model is something that given a prompt needs to predict the output. So what we want is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5199" target="_blank">01:26:39.020</a></span> | <span class="t">We can we take the input which is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5203" target="_blank">01:26:43.020</a></span> | <span class="t">This sentence here. We feed it to the transformer the transformer will transform it into a sequence of embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5209" target="_blank">01:26:49.340</a></span> | <span class="t">Contextualized embedding and then we need some labels to train this language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5214" target="_blank">01:26:54.060</a></span> | <span class="t">So the labels what will be well, we will we want whenever the language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5220" target="_blank">01:27:00.300</a></span> | <span class="t">Is given the word I to predict the word love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5223" target="_blank">01:27:03.420</a></span> | <span class="t">So big, oh, I think i'm using not the pen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5227" target="_blank">01:27:07.740</a></span> | <span class="t">here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5229" target="_blank">01:27:09.420</a></span> | <span class="t">the word love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5231" target="_blank">01:27:11.180</a></span> | <span class="t">whenever the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5232" target="_blank">01:27:12.620</a></span> | <span class="t">Language model sees the word I love it should predict the word pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5236" target="_blank">01:27:16.640</a></span> | <span class="t">Whenever it sees the word the sequence I love pepperoni it should predict pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5246" target="_blank">01:27:26.620</a></span> | <span class="t">Whenever it sees the sequence I love pepperoni pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5249" target="_blank">01:27:29.820</a></span> | <span class="t">It should predict the token end of sentence, which is a special token telling hey, I'm done with the generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5256" target="_blank">01:27:36.000</a></span> | <span class="t">Because the transformer can generate all of these contextualized embeddings in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5261" target="_blank">01:27:41.820</a></span> | <span class="t">we can also calculate the loss for each of these predictions in parallel and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5266" target="_blank">01:27:46.300</a></span> | <span class="t">Calculate the with backpropagation updates the weights of the model to tell in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5273" target="_blank">01:27:53.020</a></span> | <span class="t">How the model should predict each of this token given the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5276" target="_blank">01:27:56.780</a></span> | <span class="t">The previous tokens. So when we are given a sentence and we train language model the language model can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5282" target="_blank">01:28:02.540</a></span> | <span class="t">Can be trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5285" target="_blank">01:28:05.820</a></span> | <span class="t">With only one forward pass on how to predict the next token inside of this sentence given the previous tokens as context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5293" target="_blank">01:28:13.180</a></span> | <span class="t">In only one single pass of the transformer. That's why the transformer is so powerful because this contextualization happens in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5299" target="_blank">01:28:19.900</a></span> | <span class="t">So we can calculate the output in parallel for each position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5302" target="_blank">01:28:22.540</a></span> | <span class="t">And because we know already know what is the label because the label is just the next token given the previous tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5308" target="_blank">01:28:28.220</a></span> | <span class="t">we can calculate the loss in parallel for each positions and the model will learn in parallel how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5313" target="_blank">01:28:33.180</a></span> | <span class="t">Generate exactly this sentence in in one pass only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5317" target="_blank">01:28:37.820</a></span> | <span class="t">so the model will not learn to generate one token at a time given the previous but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5323" target="_blank">01:28:43.100</a></span> | <span class="t">All the sentence in one pass and that's why it's so powerful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5327" target="_blank">01:28:47.740</a></span> | <span class="t">Now let's go back to our vision transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5329" target="_blank">01:28:49.740</a></span> | <span class="t">Okay, so we have seen what is the difference between the vision transformer and the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5334" target="_blank">01:28:54.220</a></span> | <span class="t">So in the vision transformer, we want to contextualize tokens or patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5337" target="_blank">01:28:57.980</a></span> | <span class="t">In such a way that they capture information about all the other patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5342" target="_blank">01:29:02.220</a></span> | <span class="t">But in the language model, we want each token to only capture information about itself and the previous tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5346" target="_blank">01:29:06.940</a></span> | <span class="t">How does this self-attention mechanism work?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5350" target="_blank">01:29:10.300</a></span> | <span class="t">We start with of course an input sequence. Our goal is to create an output sequence that is contextualized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5356" target="_blank">01:29:16.380</a></span> | <span class="t">And there are many intermediate steps. So now we will see what are these intermediate steps one at a time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5361" target="_blank">01:29:21.500</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5363" target="_blank">01:29:23.340</a></span> | <span class="t">Let's start by creating the class of this this attention mechanism and we will create it. Let's create it here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5369" target="_blank">01:29:29.900</a></span> | <span class="t">Okay, so in the input we have the configuration of the model we save some stuff that we will need later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5377" target="_blank">01:29:37.580</a></span> | <span class="t">So the hidden size the number of attention heads because we are dealing with multi-head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5383" target="_blank">01:29:43.660</a></span> | <span class="t">Head dimension we will see later what is it and why it's used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5387" target="_blank">01:29:47.020</a></span> | <span class="t">The scale is basically the if you remember the formula for the attention is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5391" target="_blank">01:29:51.260</a></span> | <span class="t">The queries multiplied by the transposed of the keys divided by the square root of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5397" target="_blank">01:29:57.340</a></span> | <span class="t">And this is one over the square root of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5399" target="_blank">01:29:59.740</a></span> | <span class="t">So the stuff that we need to divide the query multiplied by the keys with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5405" target="_blank">01:30:05.100</a></span> | <span class="t">Then we have this dropout which is zero. I never saw it used in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5410" target="_blank">01:30:10.780</a></span> | <span class="t">In polygamma, but I believe there are other cglib models that use it. So they they put it here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5415" target="_blank">01:30:15.580</a></span> | <span class="t">But it you can think of it like non-existent for now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5419" target="_blank">01:30:19.180</a></span> | <span class="t">and then we have these three linear layers called w, k, w, q and w, v which are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5425" target="_blank">01:30:25.580</a></span> | <span class="t">Parameter matrices that are also present in the vanilla transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5429" target="_blank">01:30:29.180</a></span> | <span class="t">We will see later what they are used for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5431" target="_blank">01:30:31.260</a></span> | <span class="t">And then we have this output projection which in the paper of the transformer is called the wo matrix and we will see later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5436" target="_blank">01:30:36.940</a></span> | <span class="t">What is it is used for?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5439" target="_blank">01:30:39.580</a></span> | <span class="t">Let's start by implementing the forward. So the forward method is this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5443" target="_blank">01:30:43.900</a></span> | <span class="t">What is the input of the forward method?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5446" target="_blank">01:30:46.060</a></span> | <span class="t">Well, the input of the forward method of this attention mechanism is basically what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5450" target="_blank">01:30:50.540</a></span> | <span class="t">Is the output of the layer normalization in this encoder layer class</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5455" target="_blank">01:30:55.580</a></span> | <span class="t">So the output of the layer normalization is fed to this self-attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5460" target="_blank">01:31:00.000</a></span> | <span class="t">So it is something of this shape. So it's a batch size by non-patches by embedding dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5468" target="_blank">01:31:08.380</a></span> | <span class="t">So what is does it mean? It means that we have a batch of images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5472" target="_blank">01:31:12.220</a></span> | <span class="t">Each of these images is made up of some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5474" target="_blank">01:31:14.460</a></span> | <span class="t">patches how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5476" target="_blank">01:31:16.780</a></span> | <span class="t">defined by this number non-patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5478" target="_blank">01:31:18.780</a></span> | <span class="t">And each of this patch is represented by a vector with the size embed dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5484" target="_blank">01:31:24.700</a></span> | <span class="t">You can think of it as a vector of 1024 dimensions. I don't remember the exact number of dimensions right now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5490" target="_blank">01:31:30.940</a></span> | <span class="t">You can also think as this non-patches as a sequence length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5495" target="_blank">01:31:35.740</a></span> | <span class="t">So before we saw that a language model is made up of a sequence of tokens here. You can think of it as a sequence of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5500" target="_blank">01:31:40.940</a></span> | <span class="t">Patches where the sequence length is this non-patches here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5505" target="_blank">01:31:45.020</a></span> | <span class="t">The first thing that we do in the self-attention mechanism is we take the input and we run it through three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5512" target="_blank">01:31:52.060</a></span> | <span class="t">Transformations one is called wq one is called wk and one is called wv and after we run it through these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5518" target="_blank">01:31:58.140</a></span> | <span class="t">Transformations the output will become query key and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5522" target="_blank">01:32:02.300</a></span> | <span class="t">So let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5525" target="_blank">01:32:05.900</a></span> | <span class="t">And it's this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5527" target="_blank">01:32:07.900</a></span> | <span class="t">So we take the input sequence, which is this hidden states and we run it through wq here. It's called the qproj</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5534" target="_blank">01:32:14.620</a></span> | <span class="t">Wk here is called the kproj w here is called vproj</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5539" target="_blank">01:32:19.020</a></span> | <span class="t">The shape of the tensor does not change. Basically. These are parameter matrices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5544" target="_blank">01:32:24.960</a></span> | <span class="t">So they just add parameters to our self-attention that transform the input sequence so that they become query key and value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5553" target="_blank">01:32:33.100</a></span> | <span class="t">So it's the query key and value is just a transformation of the input sequence. However</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5557" target="_blank">01:32:37.740</a></span> | <span class="t">In this case each token still is independent from the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5562" target="_blank">01:32:42.140</a></span> | <span class="t">So there has been no contextualization happening with the linear layers. So linear layers always treat each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5567" target="_blank">01:32:47.500</a></span> | <span class="t">Independently from the others just like the multi-layer perceptron each token in the multi-layer perceptron is expanded and then reduced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5574" target="_blank">01:32:54.300</a></span> | <span class="t">Here, it's not even not expanded nor reduced. It's just transformed because the size is from embedding dimension to embedding dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5581" target="_blank">01:33:01.980</a></span> | <span class="t">So it's just a transformation of the single token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5584" target="_blank">01:33:04.780</a></span> | <span class="t">Why we want to do it? Because the self-attention mechanism needs to see the same sequence in three different ways as query key and value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5592" target="_blank">01:33:12.620</a></span> | <span class="t">So we do three different transformations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5594" target="_blank">01:33:14.620</a></span> | <span class="t">Later, we will see why they are called query key and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5597" target="_blank">01:33:17.820</a></span> | <span class="t">The second thing we do is basically we split this each of these tokens into smaller tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5608" target="_blank">01:33:28.540</a></span> | <span class="t">How many smaller tokens based on how many heads we have and now we see why so let me do something strange</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5615" target="_blank">01:33:35.420</a></span> | <span class="t">Which is i'm not copying the entire line. I'm copying a part of it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5618" target="_blank">01:33:38.460</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5620" target="_blank">01:33:40.380</a></span> | <span class="t">We take this query state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5622" target="_blank">01:33:42.140</a></span> | <span class="t">Which is a tensor of batch size numpatches embedding dimension and we are splitting the embeddim dimension into smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5629" target="_blank">01:33:49.500</a></span> | <span class="t">parts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5631" target="_blank">01:33:51.100</a></span> | <span class="t">Called head dimension. How many of this head dimension we have? We have numheads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5636" target="_blank">01:33:56.560</a></span> | <span class="t">Okay, let me copy it all otherwise, I think it's going to be confusing. Sorry</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5642" target="_blank">01:34:02.080</a></span> | <span class="t">We also have this transposition later. We will see how it works. We will visualize the tensor operations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5649" target="_blank">01:34:09.040</a></span> | <span class="t">We do it for the query the key and value, let's do it and then we see what is it about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5656" target="_blank">01:34:16.320</a></span> | <span class="t">Okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5659" target="_blank">01:34:19.360</a></span> | <span class="t">So let's go to the slides</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5664" target="_blank">01:34:24.000</a></span> | <span class="t">So at the input of this fission transformer, we have a sequence of patches you can think of it as a sequence of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5671" target="_blank">01:34:31.120</a></span> | <span class="t">vectors each vector made up of let's say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5673" target="_blank">01:34:33.680</a></span> | <span class="t">1024 dimensions or you can think of it as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5677" target="_blank">01:34:37.600</a></span> | <span class="t">Sequence of tokens in case we are working with the language model and each token is represented by 1024 dimensions vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5684" target="_blank">01:34:44.720</a></span> | <span class="t">The first thing that we do is we convert this input sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5688" target="_blank">01:34:48.640</a></span> | <span class="t">Which we will call x into query key and value and we do it through three transformations. One is called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5694" target="_blank">01:34:54.000</a></span> | <span class="t">Wq one is called wk and wbn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5696" target="_blank">01:34:56.800</a></span> | <span class="t">Which is basically a matrix multiplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5699" target="_blank">01:34:59.380</a></span> | <span class="t">Now if you look at the shape of the input sequence here, it's 4 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5704" target="_blank">01:35:04.820</a></span> | <span class="t">So here you can see the input sequence is 4 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5708" target="_blank">01:35:08.260</a></span> | <span class="t">Where 4 is representing the sequence dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5712" target="_blank">01:35:12.320</a></span> | <span class="t">So how many tokens or how many patches you have and the hidden size represents how many what is the size of this embedding vector?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5719" target="_blank">01:35:19.760</a></span> | <span class="t">We multiply it each of these with wq wk and wv</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5725" target="_blank">01:35:25.040</a></span> | <span class="t">Now if you look at the dimensions here wq wk wv they are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5729" target="_blank">01:35:29.360</a></span> | <span class="t">The size is embedding dimension to embedding dimension. However here I have represented it as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5735" target="_blank">01:35:35.040</a></span> | <span class="t">embedding dimension to 8 multiplied by 128 so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5740" target="_blank">01:35:40.800</a></span> | <span class="t">The overall size is the same. So it's 1024 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5744" target="_blank">01:35:44.340</a></span> | <span class="t">However, i'm splitting this second 1024 into eight groups and later we will see why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5751" target="_blank">01:35:51.840</a></span> | <span class="t">so you can think of it as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5754" target="_blank">01:35:54.640</a></span> | <span class="t">matrix multiplication that takes a matrix multiplication between this tensor here 4 by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5762" target="_blank">01:36:02.560</a></span> | <span class="t">1024 and this other tensor which is also 1000 by 24 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5768" target="_blank">01:36:08.880</a></span> | <span class="t">However in which the second dimension is split into sub</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5772" target="_blank">01:36:12.080</a></span> | <span class="t">Groups, how many eight groups because eight is the number of heads we are going to work with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5778" target="_blank">01:36:18.080</a></span> | <span class="t">each having 128 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5780" target="_blank">01:36:20.900</a></span> | <span class="t">if you do this matrix multiplication, it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5783" target="_blank">01:36:23.760</a></span> | <span class="t">It will result in this output here. So basically it's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5787" target="_blank">01:36:27.680</a></span> | <span class="t">1024 multiply this dimension here cancels out as you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5794" target="_blank">01:36:34.480</a></span> | <span class="t">And then we have the second dimension that remains so in the matrix multiplication the inner dimensions cancel out and the outer dimensions remain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5801" target="_blank">01:36:41.360</a></span> | <span class="t">Now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5804" target="_blank">01:36:44.880</a></span> | <span class="t">You can if you are confused by this you can think of it like this. So it's like a 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5809" target="_blank">01:36:49.140</a></span> | <span class="t">And it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5813" target="_blank">01:36:53.360</a></span> | <span class="t">1024 nothing has changed. I'm just grouping the dimensions. So that's why it's possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5821" target="_blank">01:37:01.920</a></span> | <span class="t">But it this grouping is helpful. And now we will see why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5825" target="_blank">01:37:05.840</a></span> | <span class="t">Let's visualize this tensor operation at the max matrix level</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5830" target="_blank">01:37:10.000</a></span> | <span class="t">So when we do query this x multiplied by wq we have nx which is a 4 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5835" target="_blank">01:37:15.540</a></span> | <span class="t">so it's a sequence of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5838" target="_blank">01:37:18.480</a></span> | <span class="t">tokens, each token is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5840" target="_blank">01:37:20.700</a></span> | <span class="t">1024 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5842" target="_blank">01:37:22.480</a></span> | <span class="t">And we are multiplying by a very big matrix, which is 1024 by 8 by 128. How to visualize this matrix?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5850" target="_blank">01:37:30.080</a></span> | <span class="t">Well, this is a wq. So it's a parameter matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5853" target="_blank">01:37:33.360</a></span> | <span class="t">It's also wq and wv. So they all have the same dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5857" target="_blank">01:37:37.780</a></span> | <span class="t">You can visualize this like this. You can think of it as a matrix made up of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5862" target="_blank">01:37:42.400</a></span> | <span class="t">1024 rows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5865" target="_blank">01:37:45.740</a></span> | <span class="t">Each row is made up of smaller vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5869" target="_blank">01:37:49.600</a></span> | <span class="t">How many smaller vectors? 8 of them and each of these smaller vectors is made up of 128 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5878" target="_blank">01:37:58.180</a></span> | <span class="t">The overall size of this matrix is still 1024 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5882" target="_blank">01:38:02.660</a></span> | <span class="t">But each of these let's say these vectors are split into 8 groups</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5888" target="_blank">01:38:08.020</a></span> | <span class="t">So that the output is also a matrix in which each of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5894" target="_blank">01:38:14.740</a></span> | <span class="t">Tokens is a split into multiple subgroups. So it's a matrix that is 4 rows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5901" target="_blank">01:38:21.060</a></span> | <span class="t">So as you can see, this is 4 is the number of rows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5904" target="_blank">01:38:24.900</a></span> | <span class="t">Each row contains 8 groups of smaller embeddings and each of these smaller embeddings is made up of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5911" target="_blank">01:38:31.780</a></span> | <span class="t">128 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5914" target="_blank">01:38:34.260</a></span> | <span class="t">So why are we even doing this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5916" target="_blank">01:38:36.260</a></span> | <span class="t">With multi-head attention, basically what we want to do if we want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5920" target="_blank">01:38:40.500</a></span> | <span class="t">The multi-head attention is a way to relate tokens with each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5924" target="_blank">01:38:44.980</a></span> | <span class="t">We don't want to relate tokens to each other by watching the full embedding of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5933" target="_blank">01:38:53.060</a></span> | <span class="t">We want to do it with 8 different heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5936" target="_blank">01:38:56.420</a></span> | <span class="t">Such that each head works with a smaller part of the embedding of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5942" target="_blank">01:39:02.020</a></span> | <span class="t">So the head number 1 will only watch the first 128 dimensions of each token in the entire sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5951" target="_blank">01:39:11.300</a></span> | <span class="t">The head number 2 will watch the next group of 128 dimensions. So the dimension from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5958" target="_blank">01:39:18.820</a></span> | <span class="t">129 to 256 of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5963" target="_blank">01:39:23.060</a></span> | <span class="t">So this head will learn to relate all these tokens by only watching this part of the embedding of this each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5968" target="_blank">01:39:28.340</a></span> | <span class="t">This head will learn to relate tokens by only watching this part of the embedding of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5974" target="_blank">01:39:34.020</a></span> | <span class="t">And this last head will watch to we learn to relate tokens by only watching the last part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5979" target="_blank">01:39:39.540</a></span> | <span class="t">Last 128 dimensions of the embedding of each token. Why?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5987" target="_blank">01:39:47.780</a></span> | <span class="t">In</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5989" target="_blank">01:39:49.620</a></span> | <span class="t">Many languages a word may have different meaning depending on the context in which it appears</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=5996" target="_blank">01:39:56.180</a></span> | <span class="t">If we don't have multi-head attention because the multi-head attention we will see it later is based on what is known as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6002" target="_blank">01:40:02.260</a></span> | <span class="t">What is a dot product?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6004" target="_blank">01:40:04.580</a></span> | <span class="t">If we compute the dot product over all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6008" target="_blank">01:40:08.500</a></span> | <span class="t">all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6011" target="_blank">01:40:11.300</a></span> | <span class="t">Token then there is only way of calculating the dot product between two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6016" target="_blank">01:40:16.180</a></span> | <span class="t">Which is the full embedding of the first token with all the full embedding of the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6021" target="_blank">01:40:21.060</a></span> | <span class="t">So there is only one way of relating two tokens with each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6024" target="_blank">01:40:24.740</a></span> | <span class="t">By splitting each token into smaller groups</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6028" target="_blank">01:40:28.420</a></span> | <span class="t">Each dedicated to one head. So this is head 1, head 2 and head 8 and all the intermediate heads are here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6036" target="_blank">01:40:36.820</a></span> | <span class="t">We learn to relate tokens to each other differently because each head is watching different parts of the embedding of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6044" target="_blank">01:40:44.020</a></span> | <span class="t">And this is useful for language modeling, for example, because in language modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6048" target="_blank">01:40:48.260</a></span> | <span class="t">Especially for example in Chinese</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6051" target="_blank">01:40:51.380</a></span> | <span class="t">Each word may have different meaning depending on the context in which appears</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6055" target="_blank">01:40:55.460</a></span> | <span class="t">So it may be a noun in some context. It may be a verb in some other context or an adverb in some other context, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6062" target="_blank">01:41:02.980</a></span> | <span class="t">So we hope that this head here, for example learns to relate this token as a verb</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6068" target="_blank">01:41:08.020</a></span> | <span class="t">This head here will learn to relate this token as a noun and this head here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6072" target="_blank">01:41:12.820</a></span> | <span class="t">Maybe will learn to relate this token as an adverb or some other property that this token has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6077" target="_blank">01:41:17.700</a></span> | <span class="t">And this multi-head attention also has another advantage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6081" target="_blank">01:41:21.320</a></span> | <span class="t">Because the multi-head attention is based on dot products between tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6084" target="_blank">01:41:24.980</a></span> | <span class="t">This head here will do the dot product of this first 128 dimensions of this token with the first 128 dimensions of this token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6093" target="_blank">01:41:33.140</a></span> | <span class="t">And this head because it watches this part of the token embedding and this other head watches this part of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6100" target="_blank">01:41:40.340</a></span> | <span class="t">Embedding they can work independently from each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6104" target="_blank">01:41:44.020</a></span> | <span class="t">And so because they can work independently from each other this computation can be parallelized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6108" target="_blank">01:41:48.920</a></span> | <span class="t">That's why in the attention is all you need paper when they talk about the multi-head attention. They make this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6118" target="_blank">01:41:58.260</a></span> | <span class="t">Drawing with multiple drawings behind you can see here with the head dimension appearing here, which means that each of this head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6125" target="_blank">01:42:05.380</a></span> | <span class="t">Is computing this scale dot product attention in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6130" target="_blank">01:42:10.120</a></span> | <span class="t">With the other heads because each of them is working with a different part of the embedding of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6135" target="_blank">01:42:15.860</a></span> | <span class="t">So they can work independently from each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6137" target="_blank">01:42:17.860</a></span> | <span class="t">And this is what we are doing here. So we group this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6142" target="_blank">01:42:22.100</a></span> | <span class="t">This the embedding of each token into multiple subgroups</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6147" target="_blank">01:42:27.560</a></span> | <span class="t">Each dedicated to one head because we want this multi-head attention to happen in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6153" target="_blank">01:42:33.500</a></span> | <span class="t">Because each head is working with a different part of the embedding of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6157" target="_blank">01:42:37.960</a></span> | <span class="t">And so it it becomes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6160" target="_blank">01:42:40.600</a></span> | <span class="t">Much faster because we can compute all this stuff in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6164" target="_blank">01:42:44.440</a></span> | <span class="t">anyway</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6166" target="_blank">01:42:46.360</a></span> | <span class="t">What we have done in the code is as follows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6168" target="_blank">01:42:48.440</a></span> | <span class="t">So we have taken our input sequence now here for the drawing. I have chosen a 4 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6174" target="_blank">01:42:54.840</a></span> | <span class="t">but in the code it should be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6176" target="_blank">01:42:56.840</a></span> | <span class="t">Depending on how many patches we have so numPatches by embedDimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6180" target="_blank">01:43:00.860</a></span> | <span class="t">We have multiplied each of them by the Q K and V</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6185" target="_blank">01:43:05.000</a></span> | <span class="t">And then we split them here as you can see in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6189" target="_blank">01:43:09.240</a></span> | <span class="t">In multiple heads, so we add this head dimension here in my slide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6195" target="_blank">01:43:15.560</a></span> | <span class="t">I just pretend I am multiplying directly with a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6199" target="_blank">01:43:19.080</a></span> | <span class="t">Parameter matrix that is already split into multiple heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6203" target="_blank">01:43:23.240</a></span> | <span class="t">Why am I doing differently here than compared to the code because we will be it will be useful for this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6209" target="_blank">01:43:29.240</a></span> | <span class="t">Visualizing it this way is will be useful for when we will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6212" target="_blank">01:43:32.920</a></span> | <span class="t">Talking about the language model and especially we will be talking about grouped query attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6216" target="_blank">01:43:36.920</a></span> | <span class="t">Because with grouped query attention, we will see that the number of heads for the query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6220" target="_blank">01:43:40.600</a></span> | <span class="t">Is much bigger than the number of heads for the keys and the values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6225" target="_blank">01:43:45.240</a></span> | <span class="t">So here in the vision transformer the number of heads of the query key and values is the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6229" target="_blank">01:43:49.560</a></span> | <span class="t">So we don't use the grouped query attention and that's why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6232" target="_blank">01:43:52.680</a></span> | <span class="t">We use the same number of heads for the query key and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6235" target="_blank">01:43:55.480</a></span> | <span class="t">Then we do this transposition and now we see what is this transposition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6239" target="_blank">01:43:59.720</a></span> | <span class="t">So when you do this multiplication here, so you multiply the input by the Q projection. It will return the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6246" target="_blank">01:44:06.040</a></span> | <span class="t">input shape</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6248" target="_blank">01:44:08.600</a></span> | <span class="t">When you do this view, it will just split this last dimension. So this embedDimension into smaller parts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6255" target="_blank">01:44:15.320</a></span> | <span class="t">So it will become num</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6257" target="_blank">01:44:17.400</a></span> | <span class="t">It will become like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6262" target="_blank">01:44:22.200</a></span> | <span class="t">Uh patches by heads, so we are splitting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6265" target="_blank">01:44:25.340</a></span> | <span class="t">This dimension into these two smaller dimensions. So numHeads by headDimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6271" target="_blank">01:44:31.180</a></span> | <span class="t">So basically, what is this headDimension? headDimension is the embedding full embedding divided by the number of heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6278" target="_blank">01:44:38.120</a></span> | <span class="t">So this one imagine this is 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6280" target="_blank">01:44:40.380</a></span> | <span class="t">Then imagine this is 8</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6283" target="_blank">01:44:43.240</a></span> | <span class="t">Then this will be 128 because it's 1024 divided by 8</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6291" target="_blank">01:44:51.080</a></span> | <span class="t">and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6293" target="_blank">01:44:53.080</a></span> | <span class="t">Because we are not reducing the number of parameters or we are not throwing away anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6297" target="_blank">01:44:57.800</a></span> | <span class="t">We are just grouping differently each of these embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6300" target="_blank">01:45:00.940</a></span> | <span class="t">With this transpose here, we are changing the position of the two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6307" target="_blank">01:45:07.560</a></span> | <span class="t">Two dimensions which dimension the position the dimension number one and the dimension number two, which is the numPatches with the numHeads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6314" target="_blank">01:45:14.780</a></span> | <span class="t">So basically we are doing numHeads and numPatches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6320" target="_blank">01:45:20.040</a></span> | <span class="t">So this will be the output of all this expression. So it will be a tensor of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6325" target="_blank">01:45:25.880</a></span> | <span class="t">Of this shape batchSize numHeads numPatches headDim. Why are we doing this transposition? Let's see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6334" target="_blank">01:45:34.760</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6336" target="_blank">01:45:36.680</a></span> | <span class="t">we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6338" target="_blank">01:45:38.040</a></span> | <span class="t">When we multiply by this wqwk and wv which is already includes the grouping. We are grouping each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6344" target="_blank">01:45:44.360</a></span> | <span class="t">Vectors into sub groups each dedicated to one head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6349" target="_blank">01:45:49.880</a></span> | <span class="t">Now what we have here is a sequence of tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6353" target="_blank">01:45:53.080</a></span> | <span class="t">Each token is made up of eight group of embeddings. Each group of embedding is made up of 128 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6359" target="_blank">01:45:59.960</a></span> | <span class="t">what we want, however</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6362" target="_blank">01:46:02.120</a></span> | <span class="t">is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6363" target="_blank">01:46:03.560</a></span> | <span class="t">because we want to compute the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6365" target="_blank">01:46:05.560</a></span> | <span class="t">Multi head attention in parallel, which means that each head should be able to visualize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6371" target="_blank">01:46:11.500</a></span> | <span class="t">The entire sequence but a smaller part of the embedding of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6377" target="_blank">01:46:17.800</a></span> | <span class="t">We need to transpose these two dimensions. So we exchange the sequence dimension with the head dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6383" target="_blank">01:46:23.580</a></span> | <span class="t">and a way to visualize this is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6387" target="_blank">01:46:27.240</a></span> | <span class="t">that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6390" target="_blank">01:46:30.120</a></span> | <span class="t">Let's do it. So we have this sequence of tokens each token is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6395" target="_blank">01:46:35.560</a></span> | <span class="t">Divided into eight groups. Each group is made up of 128 dimensions. We want to convert it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6403" target="_blank">01:46:43.320</a></span> | <span class="t">Into multiple sequences made up of only the part of the embedding dedicated to each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6409" target="_blank">01:46:49.480</a></span> | <span class="t">So when you do the transposition of these two dimensions here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6412" target="_blank">01:46:52.920</a></span> | <span class="t">They become like this. So 8, 4, 128</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6416" target="_blank">01:46:56.620</a></span> | <span class="t">How can you visualize this matrix? You can visualize it as follows. It's a big matrix that contains eight smaller matrices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6425" target="_blank">01:47:05.160</a></span> | <span class="t">each smaller matrices contains four tokens and each token contains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6430" target="_blank">01:47:10.180</a></span> | <span class="t">128 dimensions, which is exactly the dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6433" target="_blank">01:47:13.720</a></span> | <span class="t">That are dedicated to each of this head. So you can think of it as a sequence eight sequences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6441" target="_blank">01:47:21.800</a></span> | <span class="t">where each sequence is made up of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6444" target="_blank">01:47:24.760</a></span> | <span class="t">tokens and each tokens contain only the part of the embedding dedicated to each of the head that it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6451" target="_blank">01:47:31.720</a></span> | <span class="t">each of the eight heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6453" target="_blank">01:47:33.880</a></span> | <span class="t">It's composed of so this sequence here will only contain the first 128 dimensions of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6460" target="_blank">01:47:40.440</a></span> | <span class="t">This sequence here will contain the next 128 dimensions of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6465" target="_blank">01:47:45.560</a></span> | <span class="t">And the last sequence here will be a sequence of four tokens and each token will be made up of the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6471" target="_blank">01:47:51.400</a></span> | <span class="t">128 dimensions of the initial tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6474" target="_blank">01:47:54.600</a></span> | <span class="t">Why are we doing this? Because now we can compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6479" target="_blank">01:47:59.720</a></span> | <span class="t">The multi-head attention using this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6482" target="_blank">01:48:02.040</a></span> | <span class="t">Independently from this one independently from this one independently from this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6487" target="_blank">01:48:07.400</a></span> | <span class="t">because each head has a sequence of four tokens and each token is made up of 128 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6496" target="_blank">01:48:16.220</a></span> | <span class="t">And we end up in what we saw here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6499" target="_blank">01:48:19.720</a></span> | <span class="t">So we can compute this scale.product attention using the query key and values where the query key values are not the entire</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6507" target="_blank">01:48:27.380</a></span> | <span class="t">Embedding of the token but are only the part of the token dedicated to that specific head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6512" target="_blank">01:48:32.660</a></span> | <span class="t">So this head here suppose the head number one will be using the first 128 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6518" target="_blank">01:48:38.180</a></span> | <span class="t">This second head will be using the second 128 dimension. The last head will be using the last 128 dimensions, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6525" target="_blank">01:48:45.460</a></span> | <span class="t">So we have created the that's why we did this transposition because we now we can treat each head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6533" target="_blank">01:48:53.200</a></span> | <span class="t">Independently each head is made up of is working with the four tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6537" target="_blank">01:48:57.200</a></span> | <span class="t">Which is the sequence dimension and each token is made up of the part of the embedding dedicated to that head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6542" target="_blank">01:49:02.960</a></span> | <span class="t">And this is why we do this transpose here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6546" target="_blank">01:49:06.240</a></span> | <span class="t">The next thing that we do in multi-head attention is well, we have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6551" target="_blank">01:49:11.200</a></span> | <span class="t">Query key and values. What should we do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6553" target="_blank">01:49:13.440</a></span> | <span class="t">We should do query multiplied by the transpose of the key divided by the square root of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6557" target="_blank">01:49:17.840</a></span> | <span class="t">And that's it. Yeah, so let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6562" target="_blank">01:49:22.560</a></span> | <span class="t">Let's calculate the attention weights, which is this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6566" target="_blank">01:49:26.720</a></span> | <span class="t">So we take the query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6569" target="_blank">01:49:29.440</a></span> | <span class="t">Multiplied by the transpose of the keys where we are transposing the second and the third dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6574" target="_blank">01:49:34.400</a></span> | <span class="t">What is the second and the third dimension?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6576" target="_blank">01:49:36.320</a></span> | <span class="t">It's the numPatches with the head dimension because the query is pet size numHeads numPatches head dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6583" target="_blank">01:49:43.200</a></span> | <span class="t">to multiply it with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6585" target="_blank">01:49:45.520</a></span> | <span class="t">the keys we need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6587" target="_blank">01:49:47.520</a></span> | <span class="t">exchange the last two dimensions, otherwise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6590" target="_blank">01:49:50.240</a></span> | <span class="t">You so multiply it we need like this. We need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6593" target="_blank">01:49:53.520</a></span> | <span class="t">This stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6597" target="_blank">01:49:57.360</a></span> | <span class="t">Then we need head dimension and numPatches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6602" target="_blank">01:50:02.020</a></span> | <span class="t">Such that if you remember in the matrix multiplication the inner dimensions cancel out and the outer dimensions remain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6610" target="_blank">01:50:10.320</a></span> | <span class="t">so the outer dimensions basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6612" target="_blank">01:50:12.400</a></span> | <span class="t">Is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6615" target="_blank">01:50:15.200</a></span> | <span class="t">numPatches numHeads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6618" target="_blank">01:50:18.080</a></span> | <span class="t">then the hidden this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6620" target="_blank">01:50:20.080</a></span> | <span class="t">Head dimension will cancel out with this one and we will be left with numPatches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6625" target="_blank">01:50:25.540</a></span> | <span class="t">So the output of this multi head attention basically, it's a matrix that is numPatches by numPatches for each head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6632" target="_blank">01:50:32.160</a></span> | <span class="t">Let me delete this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6635" target="_blank">01:50:35.760</a></span> | <span class="t">So I know it's not easy to visualize it like this. So let's visualize it on the slides</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6641" target="_blank">01:50:41.440</a></span> | <span class="t">So what we are doing is we are multiplying the query with the transpose of the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6645" target="_blank">01:50:45.280</a></span> | <span class="t">And then we are dividing by the square root of the model, but we already computed it here. So this is the square root of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6651" target="_blank">01:50:51.120</a></span> | <span class="t">And we just because it's already one over square root so we just multiply it we don't need to divide by it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6658" target="_blank">01:50:58.080</a></span> | <span class="t">So let's visualize in the slides how this multiplication works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6663" target="_blank">01:51:03.120</a></span> | <span class="t">Okay, we already saw why we do the multi head attention because we want to parallelize the computation etc. So now what we are doing is we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6673" target="_blank">01:51:13.520</a></span> | <span class="t">for each head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6675" target="_blank">01:51:15.280</a></span> | <span class="t">each head as we saw before is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6677" target="_blank">01:51:17.280</a></span> | <span class="t">Made up of one sequence of embeddings where each embedding is not the full embedding of the token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6683" target="_blank">01:51:23.920</a></span> | <span class="t">But it's a part of the embedding of each token. So it's a smaller embedding. Let's say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6687" target="_blank">01:51:27.920</a></span> | <span class="t">So each head basically will do the following matrix multiplication when you do query multiplied by the transpose of the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6694" target="_blank">01:51:34.400</a></span> | <span class="t">Each head is made up of a sequence of tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6698" target="_blank">01:51:38.560</a></span> | <span class="t">And each token is not the full embedding of the token, but it's the first 128 dimensions of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6705" target="_blank">01:51:45.440</a></span> | <span class="t">When we do the transpose of the keys each of these row vectors becomes a column vector as you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6712" target="_blank">01:51:52.080</a></span> | <span class="t">And when we do this matrix multiplication for each head we will be getting this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6719" target="_blank">01:51:59.120</a></span> | <span class="t">Matrix as output which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6724" target="_blank">01:52:04.280</a></span> | <span class="t">Sequence by sequence because as you can see when you multiply this matrix here by this matrix here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6729" target="_blank">01:52:09.180</a></span> | <span class="t">You get four by four matrix as output because the inner dimensions cancel out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6733" target="_blank">01:52:13.260</a></span> | <span class="t">What does this matrix represent?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6736" target="_blank">01:52:16.860</a></span> | <span class="t">Each of these numbers represents the dot product of one token with another token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6743" target="_blank">01:52:23.340</a></span> | <span class="t">So you can think of the rows as being the queries and the columns as being the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6750" target="_blank">01:52:30.060</a></span> | <span class="t">This one here is the dot product of the first token of the queries suppose that the each of these tokens represent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6757" target="_blank">01:52:37.100</a></span> | <span class="t">A sentence like I love pepperoni pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6760" target="_blank">01:52:40.380</a></span> | <span class="t">Then this is the word I this is word the word love this is the word pepperoni and this is the word pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6767" target="_blank">01:52:47.740</a></span> | <span class="t">Then this number here represents the dot product of the word I with itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6775" target="_blank">01:52:55.020</a></span> | <span class="t">So the first query with the first key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6779" target="_blank">01:52:59.340</a></span> | <span class="t">This one here represents the dot product of the first query with the second key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6785" target="_blank">01:53:05.340</a></span> | <span class="t">This one represents the dot product of the first query with the third key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6790" target="_blank">01:53:10.780</a></span> | <span class="t">And we do all the possible dot products as you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6795" target="_blank">01:53:15.500</a></span> | <span class="t">now you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6797" target="_blank">01:53:17.740</a></span> | <span class="t">Are and what does this matrix represent? This represents somehow the relationship between two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6804" target="_blank">01:53:24.380</a></span> | <span class="t">So the bigger the dot product the more intense is the relationship between two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6809" target="_blank">01:53:29.340</a></span> | <span class="t">Actually, it's then defined later. We will see that we apply the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6813" target="_blank">01:53:33.120</a></span> | <span class="t">But you can think of the dot product as being how the self-attention mechanism is relating to tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6819" target="_blank">01:53:39.420</a></span> | <span class="t">How intense is the relationship of these two tokens?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6822" target="_blank">01:53:42.140</a></span> | <span class="t">Why do we have this square root of the model as the denominator because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6829" target="_blank">01:53:49.340</a></span> | <span class="t">We want to scale this dot product based on because usually when you train a model you train multiple variants of it, for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6836" target="_blank">01:53:56.300</a></span> | <span class="t">and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6838" target="_blank">01:53:58.860</a></span> | <span class="t">We when we and suppose some for example, imagine you want to try you train multiple variants and you have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6845" target="_blank">01:54:05.820</a></span> | <span class="t">You try multiple number of heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6848" target="_blank">01:54:08.940</a></span> | <span class="t">You don't want the magnitude of these numbers to change between one try and the next one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6854" target="_blank">01:54:14.220</a></span> | <span class="t">So basically by dividing by the square root of the model you keep the magnitude constant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6859" target="_blank">01:54:19.440</a></span> | <span class="t">um</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6861" target="_blank">01:54:21.440</a></span> | <span class="t">Now what are what is this matrix doing so this matrix tells us how two tokens are related to each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6869" target="_blank">01:54:29.440</a></span> | <span class="t">Now in language modeling we also apply what is known as the attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6875" target="_blank">01:54:35.760</a></span> | <span class="t">So we don't want the word I to be related to future tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6880" target="_blank">01:54:40.000</a></span> | <span class="t">So usually we don't want to compute this dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6882" target="_blank">01:54:42.560</a></span> | <span class="t">We don't want to compute this dot product and we don't want to compute this dot product because we don't want the token I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6887" target="_blank">01:54:47.520</a></span> | <span class="t">To be related to all any other token because there is no previous tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6891" target="_blank">01:54:51.440</a></span> | <span class="t">We also don't want the word love to be related to the word the pepperoni and the pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6896" target="_blank">01:54:56.560</a></span> | <span class="t">Because they come after it, but we want of course the word pepperoni to be related to the word love. So this this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6902" target="_blank">01:55:02.080</a></span> | <span class="t">There should be a number here. So we don't want to mask out this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6905" target="_blank">01:55:05.680</a></span> | <span class="t">This is called a attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6908" target="_blank">01:55:08.240</a></span> | <span class="t">And how do we apply that basically?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6910" target="_blank">01:55:10.960</a></span> | <span class="t">If we don't want some interaction between token to happen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6915" target="_blank">01:55:15.040</a></span> | <span class="t">we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6917" target="_blank">01:55:17.120</a></span> | <span class="t">Calculate the matrix as usual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6918" target="_blank">01:55:18.640</a></span> | <span class="t">So query multiplied by the transpose of the keys and then we replace all the numbers all the relationships that we don't want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6924" target="_blank">01:55:24.640</a></span> | <span class="t">With minus infinity. So here we can replace this number here with minus infinity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6929" target="_blank">01:55:29.620</a></span> | <span class="t">Here we can replace this number with minus infinity and then we can replace this number with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6936" target="_blank">01:55:36.160</a></span> | <span class="t">Minus infinity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6941" target="_blank">01:55:41.200</a></span> | <span class="t">So that after we need to apply the softmax the softmax will convert each of these numbers into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6949" target="_blank">01:55:49.360</a></span> | <span class="t">probability score</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6951" target="_blank">01:55:51.840</a></span> | <span class="t">because we want the relationship of one token with other tokens to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6956" target="_blank">01:55:56.880</a></span> | <span class="t">Between zero and one and also we want each row to sum to one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6961" target="_blank">01:56:01.760</a></span> | <span class="t">Later, we will see why because actually the when we do the contextualization we are doing a weighted sum, but okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6968" target="_blank">01:56:08.880</a></span> | <span class="t">Let's forget it about now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6971" target="_blank">01:56:11.040</a></span> | <span class="t">Anyway, the point is we apply the softmax row by row. So if we don't want the relationship of two tokens to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6977" target="_blank">01:56:17.360</a></span> | <span class="t">be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6979" target="_blank">01:56:19.440</a></span> | <span class="t">Considered by the attention mechanism. We replace that particular dot product with minus infinity before we apply the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6986" target="_blank">01:56:26.560</a></span> | <span class="t">Because the softmax we saw before is an exponential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6989" target="_blank">01:56:29.840</a></span> | <span class="t">It's e to the power of x when e is to the power of minus infinity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=6994" target="_blank">01:56:34.000</a></span> | <span class="t">It will become zero. So the output of the softmax will become zero for all the interaction that we didn't want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7000" target="_blank">01:56:40.080</a></span> | <span class="t">So that's why we replace it with minus infinity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7002" target="_blank">01:56:42.260</a></span> | <span class="t">Now, let me put back whatever we had before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7006" target="_blank">01:56:46.160</a></span> | <span class="t">Okay, so this is uh where we apply the mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7010" target="_blank">01:56:50.800</a></span> | <span class="t">So as you can see if we apply the mask before we apply the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7014" target="_blank">01:56:54.080</a></span> | <span class="t">It will replace with zero all the interactions that we don't want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7016" target="_blank">01:56:56.960</a></span> | <span class="t">And this is um</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7020" target="_blank">01:57:00.640</a></span> | <span class="t">what is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7022" target="_blank">01:57:02.560</a></span> | <span class="t">This matrix here is known as attention weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7025" target="_blank">01:57:05.280</a></span> | <span class="t">so it tells us how intense is the relationship between two tokens and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7030" target="_blank">01:57:10.000</a></span> | <span class="t">This matrix here is calculated independently for each single head because here I show you only one matrix here 4 by 128</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7038" target="_blank">01:57:18.900</a></span> | <span class="t">But we have eight of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7042" target="_blank">01:57:22.400</a></span> | <span class="t">And each of them is calculated in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7045" target="_blank">01:57:25.840</a></span> | <span class="t">So you need to think that you have eight of this matrix if you have eight attention heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7051" target="_blank">01:57:31.200</a></span> | <span class="t">And in this case in the code, you can see that the output is a list of it's a batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7057" target="_blank">01:57:37.200</a></span> | <span class="t">Because maybe we have multiple images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7059" target="_blank">01:57:39.440</a></span> | <span class="t">Each of these images is managed by multiple heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7062" target="_blank">01:57:42.960</a></span> | <span class="t">Each of these heads will learn to relate tokens differently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7066" target="_blank">01:57:46.720</a></span> | <span class="t">So each of these heads will give us a numPatches by numPatches matrix or sequence by sequence matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7072" target="_blank">01:57:52.000</a></span> | <span class="t">Where each of this number represents how this head is relating two patches with each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7079" target="_blank">01:57:59.440</a></span> | <span class="t">So now we have seen how to calculate this attention weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7082" target="_blank">01:58:02.240</a></span> | <span class="t">Which basically it's a matrix that tells you how two tokens are related with each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7086" target="_blank">01:58:06.400</a></span> | <span class="t">It's kind of a score of how the attention mechanism thinks two tokens are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7090" target="_blank">01:58:10.320</a></span> | <span class="t">Related to each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7093" target="_blank">01:58:13.840</a></span> | <span class="t">We continue our journey</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7095" target="_blank">01:58:15.840</a></span> | <span class="t">The first thing we do. Okay, we verify the dimension of this matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7099" target="_blank">01:58:19.520</a></span> | <span class="t">And then we apply the softmax the softmax as we saw before is a way to convert these attention scores into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7108" target="_blank">01:58:28.560</a></span> | <span class="t">Numbers that are between 0 and 1 and also such that they sum up to 1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7112" target="_blank">01:58:32.560</a></span> | <span class="t">And we do it by soft with the softmax function, which is applied by rows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7117" target="_blank">01:58:37.760</a></span> | <span class="t">And that's this dimension. This is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7121" target="_blank">01:58:41.200</a></span> | <span class="t">What is the meaning of this dimension parameter which tells you how you want to apply it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7125" target="_blank">01:58:45.600</a></span> | <span class="t">So we are applying it to the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7127" target="_blank">01:58:47.760</a></span> | <span class="t">Dimension you can think of this as the row dimension. This is the column</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7132" target="_blank">01:58:52.960</a></span> | <span class="t">So if you apply it on entire all the columns, it means you are applying it by rows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7137" target="_blank">01:58:57.920</a></span> | <span class="t">then we have the dropout but as I said before we don't use the dropout because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7144" target="_blank">01:59:04.480</a></span> | <span class="t">I didn't see it in the parameters of the polygamma ever being used. So we have it, but we don't use it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7152" target="_blank">01:59:12.000</a></span> | <span class="t">And as you remember the dropout basically takes random</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7155" target="_blank">01:59:15.920</a></span> | <span class="t">With the probability p it will set some activations to zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7160" target="_blank">01:59:20.240</a></span> | <span class="t">So some numbers of this input matrix to zero, but we don't use it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7163" target="_blank">01:59:23.680</a></span> | <span class="t">And it only happens during training and it's a way to reduce overfitting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7168" target="_blank">01:59:28.180</a></span> | <span class="t">But as it's not used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7170" target="_blank">01:59:30.180</a></span> | <span class="t">The next thing that we do in the multi-head attention is we are multiplying this attention weights matrix with the v sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7177" target="_blank">01:59:37.940</a></span> | <span class="t">the value sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7179" target="_blank">01:59:39.940</a></span> | <span class="t">So we multiply this matmul means matrix multiplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7183" target="_blank">01:59:43.000</a></span> | <span class="t">We are multiplying this attention weights with the value states, which is the value sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7188" target="_blank">01:59:48.500</a></span> | <span class="t">which is a transformation of the input sequence through this wv matrix and also by grouped by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7195" target="_blank">01:59:55.860</a></span> | <span class="t">Heads, let's visualize this operation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7197" target="_blank">01:59:57.960</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7200" target="_blank">02:00:00.260</a></span> | <span class="t">Let's go here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7201" target="_blank">02:00:01.860</a></span> | <span class="t">so the output of the attention mechanism of the query multiplied by the keys is this matrix here where each number represents the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7209" target="_blank">02:00:09.540</a></span> | <span class="t">How two tokens are related to each other by applying the softmax this number become between zero and one in each row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7216" target="_blank">02:00:16.020</a></span> | <span class="t">And also in such a way that they sum up to one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7218" target="_blank">02:00:18.740</a></span> | <span class="t">So here you can see it's 1.0 because there is only one number here. It's 0.4 and 0.6</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7225" target="_blank">02:00:25.140</a></span> | <span class="t">So they sum up to one and here is 0.2, 0.4, 0.4. So they sum up to one etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7231" target="_blank">02:00:31.140</a></span> | <span class="t">Now when I say that these numbers represent the intensity of how the attention mechanism relates to token is because now when we multiply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7239" target="_blank">02:00:39.720</a></span> | <span class="t">This matrix here, which is in the code is written as attention weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7245" target="_blank">02:00:45.220</a></span> | <span class="t">We multiply it by the v matrix. So the v sequence for the value sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7252" target="_blank">02:00:52.500</a></span> | <span class="t">We are computing a weighted sum. Why?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7255" target="_blank">02:00:55.460</a></span> | <span class="t">When we do this matrix multiplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7257" target="_blank">02:00:57.780</a></span> | <span class="t">We are multiplying for example a 4 by 4 matrix by a 4 by 128 matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7263" target="_blank">02:01:03.860</a></span> | <span class="t">Where each of this v matrix is one for each attention head just like each of this matrix here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7270" target="_blank">02:01:10.340</a></span> | <span class="t">Attention weights is one for each attention head. So each of these attention heads will be doing this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7275" target="_blank">02:01:15.060</a></span> | <span class="t">Product in parallel. So each attention heads does query multiplied by the transpose of the keys in parallel the softmax in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7283" target="_blank">02:01:23.300</a></span> | <span class="t">and this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7285" target="_blank">02:01:25.520</a></span> | <span class="t">multiplication with the v matrix in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7288" target="_blank">02:01:28.020</a></span> | <span class="t">I mean not these operations in parallel. It's the attention heads that work in parallel. The operations are sequential, of course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7296" target="_blank">02:01:36.260</a></span> | <span class="t">now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7299" target="_blank">02:01:39.140</a></span> | <span class="t">What is the output of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7301" target="_blank">02:01:41.780</a></span> | <span class="t">Product it's a 4 by 4 multiplied by 4 128. So the output is a 4 by 128 because the inner dimensions cancel out and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7309" target="_blank">02:01:49.140</a></span> | <span class="t">the outer dimensions remain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7311" target="_blank">02:01:51.140</a></span> | <span class="t">Let's analyze this output matrix here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7314" target="_blank">02:01:54.500</a></span> | <span class="t">So it will be a matrix with four tokens each token represented by not the full dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7321" target="_blank">02:02:01.140</a></span> | <span class="t">But because we are working with multi-head attention each head will have a smaller part of the embedding of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7327" target="_blank">02:02:07.460</a></span> | <span class="t">So it will have 128 dimensions in case we have eight heads and the embedding dimension is 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7333" target="_blank">02:02:13.240</a></span> | <span class="t">this first number here will be the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7336" target="_blank">02:02:16.900</a></span> | <span class="t">Will be the dot product of the first row of this matrix with the first column of this matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7344" target="_blank">02:02:24.500</a></span> | <span class="t">And as we can see from this row here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7347" target="_blank">02:02:27.780</a></span> | <span class="t">All the values are zero except the first one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7352" target="_blank">02:02:32.180</a></span> | <span class="t">which means that only this token here will contribute to the output here, which means that this and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7358" target="_blank">02:02:38.660</a></span> | <span class="t">The second number in this matrix here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7361" target="_blank">02:02:41.220</a></span> | <span class="t">So this stuff here will be the dot product of the first row of this matrix with the second column of this matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7368" target="_blank">02:02:48.500</a></span> | <span class="t">But most of the values here are zero except the first one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7372" target="_blank">02:02:52.420</a></span> | <span class="t">Which means that only this token here will contribute to this second number here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7377" target="_blank">02:02:57.140</a></span> | <span class="t">So all the dimensions in this row will be contributed only by the first token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7382" target="_blank">02:03:02.100</a></span> | <span class="t">multiplied each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7385" target="_blank">02:03:05.120</a></span> | <span class="t">The dimension of the first token multiplied by the number one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7389" target="_blank">02:03:09.620</a></span> | <span class="t">Because all the other tokens will be multiplied by zero zero and zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7394" target="_blank">02:03:14.900</a></span> | <span class="t">Let's look at the second row of this matrix here this one here the first number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7400" target="_blank">02:03:20.900</a></span> | <span class="t">So the first dimension of the second row of the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7404" target="_blank">02:03:24.660</a></span> | <span class="t">Matrix will be the dot product of the second row of this matrix with the first column</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7410" target="_blank">02:03:30.020</a></span> | <span class="t">now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7411" target="_blank">02:03:31.860</a></span> | <span class="t">The first two numbers are non-zero and the second two numbers are zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7415" target="_blank">02:03:35.700</a></span> | <span class="t">Which means that only the dimensions of the first two tokens will contribute to this output embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7421" target="_blank">02:03:41.400</a></span> | <span class="t">For each of these dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7423" target="_blank">02:03:43.460</a></span> | <span class="t">So for all the dimensions here will only be contributed by the first two tokens because all the other tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7428" target="_blank">02:03:48.980</a></span> | <span class="t">Whatever there is now the number is here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7432" target="_blank">02:03:52.100</a></span> | <span class="t">They will be multiplied by zeros. So they will not contribute to this output embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7436" target="_blank">02:03:56.660</a></span> | <span class="t">That's why we can say that this is a contextualized embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7440" target="_blank">02:04:00.200</a></span> | <span class="t">In which the contribution to this contextualization only comes from the first two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7446" target="_blank">02:04:06.740</a></span> | <span class="t">How are they these two tokens contributing? Well each of these numbers in the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7452" target="_blank">02:04:12.580</a></span> | <span class="t">Token will be multiplied by 0.4 and each of the number in the first token will be multiplied by 0.6</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7460" target="_blank">02:04:20.820</a></span> | <span class="t">This you can see it as the first token contributing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7463" target="_blank">02:04:23.880</a></span> | <span class="t">60 percent of the information to this contextualization and the second token contributing 0.4 to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7470" target="_blank">02:04:30.900</a></span> | <span class="t">40 percent to this contextualized embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7473" target="_blank">02:04:33.880</a></span> | <span class="t">And you can do the same for the third output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7477" target="_blank">02:04:37.300</a></span> | <span class="t">So this output here the first number will be the dot product of this third row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7482" target="_blank">02:04:42.740</a></span> | <span class="t">Multiplied by this first column and as you can see here, we have a zero because of the causal mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7490" target="_blank">02:04:50.100</a></span> | <span class="t">Which means that only the first three tokens will contribute to the third embedding here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7495" target="_blank">02:04:55.220</a></span> | <span class="t">How much each token will contribute? Well, it depends on how are these numbers distributed?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7500" target="_blank">02:05:00.440</a></span> | <span class="t">The first token will contribute 20 percent. The second token will contribute 40 percent and the third token will contribute also 40 percent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7508" target="_blank">02:05:08.740</a></span> | <span class="t">So that's why when we talk about the attention width matrix, we talk about how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7513" target="_blank">02:05:13.460</a></span> | <span class="t">the matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7515" target="_blank">02:05:15.540</a></span> | <span class="t">the attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7518" target="_blank">02:05:18.500</a></span> | <span class="t">Is telling us how intense is the relationship between two tokens so that each token will contribute that token will contribute more to the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7526" target="_blank">02:05:26.020</a></span> | <span class="t">embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7528" target="_blank">02:05:28.260</a></span> | <span class="t">So if the the word let's say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7530" target="_blank">02:05:30.500</a></span> | <span class="t">pizza and I are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7533" target="_blank">02:05:33.120</a></span> | <span class="t">Very related to each other when then the embedding of the word I will contribute most to the output of embedding of this fourth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7541" target="_blank">02:05:41.220</a></span> | <span class="t">contextualized position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7544" target="_blank">02:05:44.660</a></span> | <span class="t">So it means that then the fourth was contextualized position will be 40 percent based on the information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7550" target="_blank">02:05:50.660</a></span> | <span class="t">contained in the token I and 20 percent of the information contained in the word the love and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7555" target="_blank">02:05:55.860</a></span> | <span class="t">30 percent in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7558" target="_blank">02:05:58.180</a></span> | <span class="t">In the word the pepperoni, etc, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7560" target="_blank">02:06:00.980</a></span> | <span class="t">So this is why it's known as a weighted sum because you are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7565" target="_blank">02:06:05.460</a></span> | <span class="t">Summing the contribution of each token if it's not masked out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7571" target="_blank">02:06:11.540</a></span> | <span class="t">Weighted with the attention score</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7573" target="_blank">02:06:13.620</a></span> | <span class="t">associated by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7576" target="_blank">02:06:16.100</a></span> | <span class="t">Calculated using the attention weights matrix here and we do this for each of this head in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7582" target="_blank">02:06:22.200</a></span> | <span class="t">So each head is watching a part of the embedding of each token and it's learning to relate them differently and then doing this weighted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7590" target="_blank">02:06:30.100</a></span> | <span class="t">sum differently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7592" target="_blank">02:06:32.180</a></span> | <span class="t">And each head will contribute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7595" target="_blank">02:06:35.060</a></span> | <span class="t">Will output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7596" target="_blank">02:06:36.500</a></span> | <span class="t">a list of contextualized embedding but each of this contextualized embedding will not be a full token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7603" target="_blank">02:06:43.060</a></span> | <span class="t">It will be part of what is the full token and now we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7606" target="_blank">02:06:46.180</a></span> | <span class="t">We see how we can merge the result of this multi-head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7610" target="_blank">02:06:50.500</a></span> | <span class="t">And for that we need to look at the original paper. So if you look at the original paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7614" target="_blank">02:06:54.660</a></span> | <span class="t">We calculated this multi-head attention in parallel. And how can we merge the result of this multi-head attention?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7622" target="_blank">02:07:02.340</a></span> | <span class="t">Well, we we we we go here and we basically concat these heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7626" target="_blank">02:07:06.820</a></span> | <span class="t">So we take the output of the first head we concat it with the next we concat with the third head with the fourth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7633" target="_blank">02:07:13.460</a></span> | <span class="t">The fifth etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7635" target="_blank">02:07:15.300</a></span> | <span class="t">All the heads so until we get the full dimension of the original token back because each head is made up of 100</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7642" target="_blank">02:07:22.340</a></span> | <span class="t">In case suppose 128 dimensions, so this will be the first 128 dimension then the next 100 and the third 100 etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7650" target="_blank">02:07:30.100</a></span> | <span class="t">Until the last 120 dimensions, so we get back the 1024 dimensions back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7654" target="_blank">02:07:34.820</a></span> | <span class="t">And we do this stuff. Let's go back here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7659" target="_blank">02:07:39.460</a></span> | <span class="t">here, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7662" target="_blank">02:07:42.180</a></span> | <span class="t">each head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7664" target="_blank">02:07:44.180</a></span> | <span class="t">Will return a contextualized embedding for each position, but it's a contextualized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7670" target="_blank">02:07:50.040</a></span> | <span class="t">Embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7673" target="_blank">02:07:53.940</a></span> | <span class="t">That does not include all the original token contextualized but a part of it because each head is working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7679" target="_blank">02:07:59.940</a></span> | <span class="t">In parallel with a part of the embedding of each token, then we concatenate them. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7685" target="_blank">02:08:05.140</a></span> | <span class="t">What we do is we basically we want to arrive to this stuff here. So we have a contextualized embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7692" target="_blank">02:08:12.360</a></span> | <span class="t">Here one for each of the heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7695" target="_blank">02:08:15.300</a></span> | <span class="t">Okay, first we need to do I believe a transposition so we need to transpose back because before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7703" target="_blank">02:08:23.300</a></span> | <span class="t">We transpose right? So we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7705" target="_blank">02:08:25.300</a></span> | <span class="t">We put the head dimension first and then the sequence dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7709" target="_blank">02:08:29.460</a></span> | <span class="t">So now we need again the sequence dimension and then the head dimension after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7713" target="_blank">02:08:33.380</a></span> | <span class="t">so that each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7715" target="_blank">02:08:35.860</a></span> | <span class="t">We go from this configuration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7717" target="_blank">02:08:37.860</a></span> | <span class="t">Which is for each head. We have a contextualized list of tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7723" target="_blank">02:08:43.220</a></span> | <span class="t">We want to get a list of tokens in which each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7728" target="_blank">02:08:48.500</a></span> | <span class="t">Head is contributing its 128 dimensions, which are contextualized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7733" target="_blank">02:08:53.000</a></span> | <span class="t">Embeddings, smaller embeddings, let's say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7736" target="_blank">02:08:56.800</a></span> | <span class="t">So let's do this transposition also in code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7739" target="_blank">02:08:59.700</a></span> | <span class="t">I believe it's here. So I think there is another checking of the output dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7746" target="_blank">02:09:06.420</a></span> | <span class="t">We transpose back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7750" target="_blank">02:09:10.820</a></span> | <span class="t">So we do this transposition back. So we did the first transposition here to exchange the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7756" target="_blank">02:09:16.660</a></span> | <span class="t">Number of heads with the sequence dimension. Now we transpose back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7759" target="_blank">02:09:19.780</a></span> | <span class="t">So we go back to the num_patches and num_heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7764" target="_blank">02:09:24.100</a></span> | <span class="t">So it's a sequence each sequence is made up of smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7768" target="_blank">02:09:28.180</a></span> | <span class="t">Eight groups or num_heads group and each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7771" target="_blank">02:09:31.140</a></span> | <span class="t">Head is made up of head dimension dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7775" target="_blank">02:09:35.000</a></span> | <span class="t">We do this contiguous because we want to reshape. Okay, it doesn't matter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7780" target="_blank">02:09:40.260</a></span> | <span class="t">You don't have to know why we do this contiguous, but basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7785" target="_blank">02:09:45.920</a></span> | <span class="t">Contiguous means that we want the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7787" target="_blank">02:09:47.920</a></span> | <span class="t">The tensor to represent the information in the memory in a contiguous way so that the next operation that we are going to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7795" target="_blank">02:09:55.600</a></span> | <span class="t">the reshape is basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7797" target="_blank">02:09:57.920</a></span> | <span class="t">Does not require any computation because when you do a reshaping or a viewing of a transfer of a tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7804" target="_blank">02:10:04.240</a></span> | <span class="t">There is no change in the memory layout of the tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7808" target="_blank">02:10:08.880</a></span> | <span class="t">Actually, the PyTorch will just change what is known as the stride of the tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7814" target="_blank">02:10:14.480</a></span> | <span class="t">So if you go to a tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7816" target="_blank">02:10:16.480</a></span> | <span class="t">We are going a little off</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7818" target="_blank">02:10:18.960</a></span> | <span class="t">off topic, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7820" target="_blank">02:10:20.960</a></span> | <span class="t">There is this thing called the stride which tells you how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7824" target="_blank">02:10:24.080</a></span> | <span class="t">To go from one dimension to the next without changing the layout of how this tensor is allocated in the memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7830" target="_blank">02:10:30.560</a></span> | <span class="t">So when you do a view</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7832" target="_blank">02:10:32.480</a></span> | <span class="t">or a reshape</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7834" target="_blank">02:10:34.480</a></span> | <span class="t">The PyTorch will just change these numbers on the stride. Okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7838" target="_blank">02:10:38.640</a></span> | <span class="t">I will do another video on how this works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7841" target="_blank">02:10:41.600</a></span> | <span class="t">But anyway, but this contiguous allow us to have this tensor all in the memory as a contiguous memory allocation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7848" target="_blank">02:10:48.160</a></span> | <span class="t">So that this reshape operation can be done without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7850" target="_blank">02:10:50.720</a></span> | <span class="t">Without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7854" target="_blank">02:10:54.460</a></span> | <span class="t">computational overhead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7856" target="_blank">02:10:56.320</a></span> | <span class="t">Now let's get back on track. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7858" target="_blank">02:10:58.320</a></span> | <span class="t">We did a reshape operation in the slides</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7862" target="_blank">02:11:02.240</a></span> | <span class="t">So after we have to do a reshape, we did the transpose operation and now we need to do a reshape operation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7867" target="_blank">02:11:07.520</a></span> | <span class="t">So the transpose operation basically allow us to get again at the first dimension the sequence dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7873" target="_blank">02:11:13.840</a></span> | <span class="t">Then the grouping of the group of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7876" target="_blank">02:11:16.640</a></span> | <span class="t">dimensions of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7879" target="_blank">02:11:19.260</a></span> | <span class="t">And each group contains 128 dimensions. Now, we need to concatenate them. How can we concatenate them?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7885" target="_blank">02:11:25.680</a></span> | <span class="t">Well, we just want to merge these heads again together into one single token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7890" target="_blank">02:11:30.480</a></span> | <span class="t">And we do that with this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7893" target="_blank">02:11:33.660</a></span> | <span class="t">Reshape operation. So with reshape basically, we are going from numHeadsHeadDim to EmbedDim, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7900" target="_blank">02:11:40.460</a></span> | <span class="t">In this case, it's 124</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7904" target="_blank">02:11:44.060</a></span> | <span class="t">So, how does it work the reshape basically the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7907" target="_blank">02:11:47.900</a></span> | <span class="t">The PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7911" target="_blank">02:11:51.580</a></span> | <span class="t">will take each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7913" target="_blank">02:11:53.580</a></span> | <span class="t">Groups and will just merge them. So it will just concatenate them with each other. So instead of being a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7921" target="_blank">02:12:01.020</a></span> | <span class="t">matrix that contains sub-arrays where each sub-array contains multiple sub-arrays and each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7928" target="_blank">02:12:08.140</a></span> | <span class="t">sub-sub-array contains 128 dimensions, it will just become a matrix that contains one array that is made up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7935" target="_blank">02:12:15.900</a></span> | <span class="t">1024 dimensions, which is the concatenation of all these heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7940" target="_blank">02:12:20.940</a></span> | <span class="t">So this is how we merge the information of all this multi-head attention that was done in parallel into one single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7950" target="_blank">02:12:30.780</a></span> | <span class="t">Token that is a contextualized version of the initial token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7954" target="_blank">02:12:34.460</a></span> | <span class="t">So we as you can see we got back the initial shape</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7958" target="_blank">02:12:38.460</a></span> | <span class="t">So we started with before at the beginning of the multi-head attention. We started with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7962" target="_blank">02:12:42.780</a></span> | <span class="t">4 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7965" target="_blank">02:12:45.660</a></span> | <span class="t">Input sequence and we end up with 4 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7969" target="_blank">02:12:49.840</a></span> | <span class="t">Sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7973" target="_blank">02:12:53.100</a></span> | <span class="t">There is one last part that we need to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7975" target="_blank">02:12:55.420</a></span> | <span class="t">that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7977" target="_blank">02:12:57.960</a></span> | <span class="t">Multiplication with this WO. So if you look at this concatenation that we have done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7983" target="_blank">02:13:03.000</a></span> | <span class="t">The concatenation basically takes the this tensor this first token here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7989" target="_blank">02:13:09.160</a></span> | <span class="t">Is just the concatenation of the first 128 dimensions, which are the output of the first head then the second 128 dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=7996" target="_blank">02:13:16.760</a></span> | <span class="t">Then the third 128 dimension and then the last 128 dimension. In total there are 1024 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8003" target="_blank">02:13:23.880</a></span> | <span class="t">But there has been no mixing between the result of these heads. So it's just a concatenation of multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8011" target="_blank">02:13:31.080</a></span> | <span class="t">of independent calculations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8013" target="_blank">02:13:33.800</a></span> | <span class="t">Each calculation done by one head independently from the others</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8017" target="_blank">02:13:37.720</a></span> | <span class="t">But we want the token to not be a concatenation of independent calculations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8023" target="_blank">02:13:43.720</a></span> | <span class="t">We also want to kind of mix the result of these heads with each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8028" target="_blank">02:13:48.600</a></span> | <span class="t">And the mixing happens when you do this multiplication by WO. The WO matrix is a matrix that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8034" target="_blank">02:13:54.920</a></span> | <span class="t">embedding size by embedding size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8037" target="_blank">02:13:57.720</a></span> | <span class="t">Which basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8040" target="_blank">02:14:00.680</a></span> | <span class="t">As you can see does not change the shape of the input. So we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8043" target="_blank">02:14:03.400</a></span> | <span class="t">The input of this WO will be a 4 by 1024. We multiply by 1024 by 1024. So it results the same input shape</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8052" target="_blank">02:14:12.360</a></span> | <span class="t">But it will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8055" target="_blank">02:14:15.480</a></span> | <span class="t">because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8056" target="_blank">02:14:16.520</a></span> | <span class="t">Let's look at this number here. This number here is the dot product of the first row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8061" target="_blank">02:14:21.320</a></span> | <span class="t">So the first token with the first column of this matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8064" target="_blank">02:14:24.840</a></span> | <span class="t">And the first column of this matrix is 1024 parameters. So all of these heads, so the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8071" target="_blank">02:14:31.880</a></span> | <span class="t">128 dimensions of the first head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8074" target="_blank">02:14:34.500</a></span> | <span class="t">128 dimensions of the second head, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8078" target="_blank">02:14:38.520</a></span> | <span class="t">Will all participate in the same dot product giving up one single number here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8083" target="_blank">02:14:43.880</a></span> | <span class="t">So there have been a mixing of the results of this head. If we don't multiply with the WO there is not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8089" target="_blank">02:14:49.800</a></span> | <span class="t">There is no mixing between the result of each head which happened independently in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8095" target="_blank">02:14:55.160</a></span> | <span class="t">And that's why we multiply it by WO</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8097" target="_blank">02:14:57.400</a></span> | <span class="t">So we don't want each token to be a contextualized version of multiple subtokens each calculated independently from each other by the multi-head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8105" target="_blank">02:15:05.400</a></span> | <span class="t">We want of course it to happen because we want to parallelize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8108" target="_blank">02:15:08.760</a></span> | <span class="t">But then we want to mix the result of this multi-head attention and we do that by multiplying by WO</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8114" target="_blank">02:15:14.620</a></span> | <span class="t">and now let's do it so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8116" target="_blank">02:15:16.620</a></span> | <span class="t">For now, we just merge. So this reshape is basically doing the concat that we saw before in the attention paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8123" target="_blank">02:15:23.020</a></span> | <span class="t">Now we do the multiplication with the WO which is this stuff here. So out projection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8128" target="_blank">02:15:28.540</a></span> | <span class="t">It won't change the shape of the tensor that is input to it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8132" target="_blank">02:15:32.700</a></span> | <span class="t">And then we return it along with the attention weights. Actually, we will not be using the attention weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8137" target="_blank">02:15:37.020</a></span> | <span class="t">And now finally we have implemented the multi-head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8141" target="_blank">02:15:41.340</a></span> | <span class="t">I just realized we forget something guys. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8143" target="_blank">02:15:43.900</a></span> | <span class="t">We forgot to implement this encoder. So we created the layer of the encoder, but we didn't create the encoder itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8151" target="_blank">02:15:51.660</a></span> | <span class="t">So what we created basically in this vision transformer is this stuff here. So let me open the slides</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8158" target="_blank">02:15:58.160</a></span> | <span class="t">We created one single layer like this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8162" target="_blank">02:16:02.700</a></span> | <span class="t">But we didn't create the sequence of these layers because an encoder is a sequence of these layers. So let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8168" target="_blank">02:16:08.620</a></span> | <span class="t">It's it's very simple. So this is a single layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8171" target="_blank">02:16:11.900</a></span> | <span class="t">But we need to create a sequence of them because we apply one after another such that the output of one is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8177" target="_blank">02:16:17.180</a></span> | <span class="t">Used as input for the next one. It's a very simple class. So let's create it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8181" target="_blank">02:16:21.340</a></span> | <span class="t">Let's create the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8185" target="_blank">02:16:25.340</a></span> | <span class="t">Constructor so it's just very simple. It's a okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8188" target="_blank">02:16:28.620</a></span> | <span class="t">We save the configuration then each we create a sequence of layers where each layer is this encoder layer to which we pass the configuration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8197" target="_blank">02:16:37.260</a></span> | <span class="t">How many we create based on how many layers it should have so the transformer layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8201" target="_blank">02:16:41.820</a></span> | <span class="t">And the forward is very simple. I can just copy it all. It's basically says, okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8208" target="_blank">02:16:48.780</a></span> | <span class="t">We have the input we give the input to the first layer and the output of this layer becomes the input to the next one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8215" target="_blank">02:16:55.820</a></span> | <span class="t">So we do a for loop and then we return the the output of the last layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8220" target="_blank">02:17:00.380</a></span> | <span class="t">This is a very simple and as you can see between each layer, there is no change in the shape of the tensor that is fed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8227" target="_blank">02:17:07.020</a></span> | <span class="t">I believe I think we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8230" target="_blank">02:17:10.380</a></span> | <span class="t">Coded all of the cglip. So which is our vision transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8234" target="_blank">02:17:14.560</a></span> | <span class="t">You may think that I have lied to you by saying that at the beginning when we were talking about contrastive learning you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8241" target="_blank">02:17:21.820</a></span> | <span class="t">Okay, actually, let's look at it. Otherwise, we will have the doubt so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8247" target="_blank">02:17:27.580</a></span> | <span class="t">When we were talking about contrastive learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8249" target="_blank">02:17:29.580</a></span> | <span class="t">We were talking about generating one single embedding for each image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8255" target="_blank">02:17:35.180</a></span> | <span class="t">But here we are generating a sequence of contextualized embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8258" target="_blank">02:17:38.880</a></span> | <span class="t">So how can the image generate one single embedding?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8263" target="_blank">02:17:43.680</a></span> | <span class="t">For a single image so in the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8267" target="_blank">02:17:47.600</a></span> | <span class="t">Is a sequence to sequence model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8269" target="_blank">02:17:49.740</a></span> | <span class="t">So you give it a list of patches as input and it will give you a sequence of contextualized patches as output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8276" target="_blank">02:17:56.540</a></span> | <span class="t">When working with something like clip, for example, if you want only one single embedding for each image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8282" target="_blank">02:18:02.940</a></span> | <span class="t">You can just take the first output contextualized embedding from the transformer as a representative for the whole image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8289" target="_blank">02:18:09.820</a></span> | <span class="t">Because it will force the model to put all the information in the first contextualized embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8296" target="_blank">02:18:16.060</a></span> | <span class="t">So that's one way to do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8297" target="_blank">02:18:17.820</a></span> | <span class="t">Another way is to just take the average of all the output embeddings by the transformer to generate one single embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8304" target="_blank">02:18:24.540</a></span> | <span class="t">Anyway, this was just a closing note before we move to the next part, which is our language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8310" target="_blank">02:18:30.620</a></span> | <span class="t">So let's go back to the architecture, which is here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8313" target="_blank">02:18:33.180</a></span> | <span class="t">So we have coded this part here the vision encoder so we feed an image it will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8320" target="_blank">02:18:40.780</a></span> | <span class="t">The vision encoder extracts some patches each of these patches become an embedding to this embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8327" target="_blank">02:18:47.100</a></span> | <span class="t">We add a positional encoding which is learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8329" target="_blank">02:18:49.740</a></span> | <span class="t">We send it to this magic box called the transformer layer, which will contextualize them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8334" target="_blank">02:18:54.540</a></span> | <span class="t">We take the output of this contextualization and this becomes our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8338" target="_blank">02:18:58.380</a></span> | <span class="t">Image embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8342" target="_blank">02:19:02.140</a></span> | <span class="t">Now before we can feed it to the language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8344" target="_blank">02:19:04.860</a></span> | <span class="t">These embeddings may not be of the same size of the embeddings used by the text layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8350" target="_blank">02:19:10.300</a></span> | <span class="t">So we will need to introduce this linear projection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8354" target="_blank">02:19:14.460</a></span> | <span class="t">So in the next part of the video, we are going to code the language model including this linear projection here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8360" target="_blank">02:19:20.540</a></span> | <span class="t">And we will learn how to merge these tokens the image tokens and the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8365" target="_blank">02:19:25.740</a></span> | <span class="t">Okay, let's start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8368" target="_blank">02:19:28.540</a></span> | <span class="t">So the next part that we are going to code is basically how to load the image from the disk to convert it into a tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8375" target="_blank">02:19:35.100</a></span> | <span class="t">And also how to tokenize the text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8377" target="_blank">02:19:37.500</a></span> | <span class="t">And we need we will see that we need to do the preparation of the text has to be done in a particular way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8383" target="_blank">02:19:43.660</a></span> | <span class="t">Let's see actually why we have it has to be done in a particular way. So let's open the slides</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8388" target="_blank">02:19:48.220</a></span> | <span class="t">Oops, I think I closed it. So let me open it again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8391" target="_blank">02:19:51.660</a></span> | <span class="t">All right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8394" target="_blank">02:19:54.060</a></span> | <span class="t">So as you can see, we need to find a way to combine the image tokens with the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8400" target="_blank">02:20:00.060</a></span> | <span class="t">So first we need to tokenize the text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8402" target="_blank">02:20:02.220</a></span> | <span class="t">But we need to create some placeholders for where we will put the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8409" target="_blank">02:20:09.260</a></span> | <span class="t">Tokens before the text token. So I will use the term image tokens and image embeddings interchangeably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8415" target="_blank">02:20:15.760</a></span> | <span class="t">because you can think of the image embeddings as kind of tokens that represents the image or and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8421" target="_blank">02:20:21.900</a></span> | <span class="t">Text are the embeddings that represent the text that is the prompt from the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8426" target="_blank">02:20:26.700</a></span> | <span class="t">so the first thing that we need to do is we need to learn how to load this image into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8432" target="_blank">02:20:32.300</a></span> | <span class="t">tensor because then as you can see from our cglib code the input to the cglib is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8439" target="_blank">02:20:39.020</a></span> | <span class="t">A tensor that is has the channel the height and the width dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8442" target="_blank">02:20:42.720</a></span> | <span class="t">which is then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8444" target="_blank">02:20:44.780</a></span> | <span class="t">transformed into patches and contextualized, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8447" target="_blank">02:20:47.420</a></span> | <span class="t">Then we need to tokenize the text. We need to create this list here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8452" target="_blank">02:20:52.540</a></span> | <span class="t">But we we will create first a list of tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8456" target="_blank">02:20:56.140</a></span> | <span class="t">Each corresponding to the text tokens and then we will add some placeholders for where we will put the image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8463" target="_blank">02:21:03.500</a></span> | <span class="t">and then it will be the transformer that will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8468" target="_blank">02:21:08.300</a></span> | <span class="t">Take these placeholders and replace it with the image. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8471" target="_blank">02:21:11.180</a></span> | <span class="t">I know it's a lot of things to remember. So don't worry. Let's code it and we will see it step by step. So let's go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8478" target="_blank">02:21:18.460</a></span> | <span class="t">We create a new file called, let me check here processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8484" target="_blank">02:21:24.560</a></span> | <span class="t">processing.py</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8487" target="_blank">02:21:27.800</a></span> | <span class="t">We do some imports</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8492" target="_blank">02:21:32.540</a></span> | <span class="t">Okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8495" target="_blank">02:21:35.820</a></span> | <span class="t">We create these two constants and later we will see why we need them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8500" target="_blank">02:21:40.140</a></span> | <span class="t">For now, just create them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8503" target="_blank">02:21:43.340</a></span> | <span class="t">Okay, let's start from the beginning. So let's create this class called the polygamma processor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8508" target="_blank">02:21:48.960</a></span> | <span class="t">This stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8513" target="_blank">02:21:53.020</a></span> | <span class="t">It has a constructor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8515" target="_blank">02:21:55.020</a></span> | <span class="t">Which is this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8517" target="_blank">02:21:57.020</a></span> | <span class="t">It will take as input the tokenizer how many image tokens?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8522" target="_blank">02:22:02.460</a></span> | <span class="t">We need to generate for the image and what is the image size that this particular gamma will work with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8528" target="_blank">02:22:08.780</a></span> | <span class="t">We save it. We save these two values and then what we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8533" target="_blank">02:22:13.660</a></span> | <span class="t">We need to add some special tokens to our tokenizer. So now I show you why we need to do it and how it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8541" target="_blank">02:22:21.100</a></span> | <span class="t">So the tokenizer that polygamma is using is the tokenizer of the gamma model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8546" target="_blank">02:22:26.940</a></span> | <span class="t">But the tokenizer of the gamma model was not created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8550" target="_blank">02:22:30.320</a></span> | <span class="t">With the special tokens for the image. So what they did was they basically created these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8556" target="_blank">02:22:36.940</a></span> | <span class="t">additional tokens called the because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8560" target="_blank">02:22:40.620</a></span> | <span class="t">Polygamma can be used for multiple purposes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8563" target="_blank">02:22:43.640</a></span> | <span class="t">So what we saw here in my slide is basically here is trying to extract information from an image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8570" target="_blank">02:22:50.140</a></span> | <span class="t">So we have an image we have a prompt and the polygamma so which is basically the gamma model here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8577" target="_blank">02:22:57.100</a></span> | <span class="t">will decode the response by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8579" target="_blank">02:22:59.500</a></span> | <span class="t">interpreting the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8581" target="_blank">02:23:01.420</a></span> | <span class="t">Prompt and using this one as additional information for the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8585" target="_blank">02:23:05.180</a></span> | <span class="t">the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8587" target="_blank">02:23:07.180</a></span> | <span class="t">Polygamma actually can do much more than this a polygamma can also do image segmentation so it can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8594" target="_blank">02:23:14.220</a></span> | <span class="t">Segment the part of the image that for example for this leg</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8597" target="_blank">02:23:17.740</a></span> | <span class="t">It can do object detection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8599" target="_blank">02:23:19.980</a></span> | <span class="t">So it can detect all the instances for of of tree for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8604" target="_blank">02:23:24.220</a></span> | <span class="t">If we do object detection for trees, it will probably give us this this okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8609" target="_blank">02:23:29.020</a></span> | <span class="t">This is not a bounding box this box here telling that this is a tree</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8612" target="_blank">02:23:32.380</a></span> | <span class="t">If we do it ask it to detect all the feeds it will give us two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8616" target="_blank">02:23:36.380</a></span> | <span class="t">Boxes one for this one one for this one, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8619" target="_blank">02:23:39.580</a></span> | <span class="t">So polygamma can do a lot of this and the way it does it by using special</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8624" target="_blank">02:23:44.380</a></span> | <span class="t">tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8626" target="_blank">02:23:46.380</a></span> | <span class="t">For the segmentation they are called the segmentation tokens and for object detection. They are called local location tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8633" target="_blank">02:23:53.580</a></span> | <span class="t">And but we will not be using them. So our goal here is just to inference polygamma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8639" target="_blank">02:23:59.340</a></span> | <span class="t">So we will not be working with the object detection or object segmentation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8643" target="_blank">02:24:03.120</a></span> | <span class="t">But if you want more information on how these tokens work, there is a very nice article</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8648" target="_blank">02:24:08.940</a></span> | <span class="t">Not only this one from google. So here in google they say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8652" target="_blank">02:24:12.300</a></span> | <span class="t">That polygamma uses the gamma tokenizer, but they extend it with these further tokens that are used to tell</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8659" target="_blank">02:24:19.580</a></span> | <span class="t">In the output of the model, where is the segments?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8663" target="_blank">02:24:23.420</a></span> | <span class="t">where is the bounding box position that it has detected or where is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8666" target="_blank">02:24:26.860</a></span> | <span class="t">location of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8669" target="_blank">02:24:29.580</a></span> | <span class="t">Of the segmentation mask that the model has detected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8673" target="_blank">02:24:33.980</a></span> | <span class="t">Another article that I recommend is the hugging face blog article about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8677" target="_blank">02:24:37.980</a></span> | <span class="t">Polygamma, let me find it. I believe it is this one here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8683" target="_blank">02:24:43.180</a></span> | <span class="t">In which they describe how this attention masks work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8687" target="_blank">02:24:47.100</a></span> | <span class="t">So as you can see polygamma can detect the cat and will give us this output which is a lock</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8692" target="_blank">02:24:52.460</a></span> | <span class="t">Tokens, as you can see lock 0094, 00256</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8697" target="_blank">02:24:57.100</a></span> | <span class="t">Which this number 0094, 0256 tell us the position of the top left</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8703" target="_blank">02:25:03.820</a></span> | <span class="t">Top right bottom left and bottom right corner of this bounding box here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8709" target="_blank">02:25:09.180</a></span> | <span class="t">But we will not be using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8711" target="_blank">02:25:11.900</a></span> | <span class="t">Here because we are only interested in using the polygamma as a conditional model for generating an output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8718" target="_blank">02:25:18.060</a></span> | <span class="t">Conditioned on the image that we feed it in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8722" target="_blank">02:25:22.540</a></span> | <span class="t">But anyway because the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8724" target="_blank">02:25:24.540</a></span> | <span class="t">Used by polygamma is adding these special tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8727" target="_blank">02:25:27.740</a></span> | <span class="t">We also add them here and how to add them and how many to add them is described in this article</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8732" target="_blank">02:25:32.460</a></span> | <span class="t">You can see here. And so basically we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8734" target="_blank">02:25:34.700</a></span> | <span class="t">1024 location tokens for image detection and then 128 tokens for object segmentation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8742" target="_blank">02:25:42.720</a></span> | <span class="t">Okay, we save the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8747" target="_blank">02:25:47.100</a></span> | <span class="t">Then what do we need to do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8748" target="_blank">02:25:48.860</a></span> | <span class="t">We have we also need to create this constant called image token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8752" target="_blank">02:25:52.380</a></span> | <span class="t">what is this constant basically when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8755" target="_blank">02:25:55.980</a></span> | <span class="t">when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8757" target="_blank">02:25:57.880</a></span> | <span class="t">process our text with the gamma tokenizer the gamma tokenizer will only generate of course the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8764" target="_blank">02:26:04.220</a></span> | <span class="t">The tokens for the text but later we need to also insert in these tokens the image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8771" target="_blank">02:26:11.820</a></span> | <span class="t">So what we need to do what we do basically is we insert some placeholder tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8777" target="_blank">02:26:17.260</a></span> | <span class="t">That will then be replaced by the embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8779" target="_blank">02:26:19.760</a></span> | <span class="t">Extracted by the visual encoder and this placeholder tokens that we will be using is this image token here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8786" target="_blank">02:26:26.300</a></span> | <span class="t">And we add it also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8788" target="_blank">02:26:28.860</a></span> | <span class="t">And we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8792" target="_blank">02:26:32.300</a></span> | <span class="t">We add it here in the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8794" target="_blank">02:26:34.300</a></span> | <span class="t">Now how to use this polygamma processor. So the polygamma processor is a special class that given an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8800" target="_blank">02:26:40.780</a></span> | <span class="t">Text which is the prompt of the user and an image will load the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8806" target="_blank">02:26:46.840</a></span> | <span class="t">Reprocess it so resize it rescale it. Whatever the vision model needs to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8811" target="_blank">02:26:51.800</a></span> | <span class="t">And we'll create this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8814" target="_blank">02:26:54.520</a></span> | <span class="t">Text tokens with the placeholder for the image tokens. So let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8819" target="_blank">02:26:59.000</a></span> | <span class="t">We create this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8822" target="_blank">02:27:02.120</a></span> | <span class="t">Method here the call why we create the call method. Well, basically this allows the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8826" target="_blank">02:27:06.920</a></span> | <span class="t">the instance of the processor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8830" target="_blank">02:27:10.040</a></span> | <span class="t">To to be called like a function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8832" target="_blank">02:27:12.840</a></span> | <span class="t">So when you create the processor you will we will create it like this like polygamma processor and then we can use it like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8839" target="_blank">02:27:19.720</a></span> | <span class="t">Passing the arguments here. So this is why we implement the call method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8844" target="_blank">02:27:24.040</a></span> | <span class="t">And the call method takes as input a list of text and the list of images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8848" target="_blank">02:27:28.600</a></span> | <span class="t">but we will actually only accept one text and one images because I don't want to deal with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8854" target="_blank">02:27:34.200</a></span> | <span class="t">Padding otherwise, it will complicate our code. Our goal is not to make it universally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8859" target="_blank">02:27:39.420</a></span> | <span class="t">Perfect. Our goal is to learn by doing and how it works. Actually, this is this code will be usable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8865" target="_blank">02:27:45.160</a></span> | <span class="t">So we will actually run the inference later, but it will only work with one image and one prompt at a time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8870" target="_blank">02:27:50.200</a></span> | <span class="t">It doesn't matter because later we can later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8872" target="_blank">02:27:52.760</a></span> | <span class="t">I will try to make the code for fine-tuning this model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8875" target="_blank">02:27:55.400</a></span> | <span class="t">And we will see that we will change this code a little bit to to accommodate for the padding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8882" target="_blank">02:28:02.680</a></span> | <span class="t">Anyway, we need to process these images and we will use a special method called process images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8889" target="_blank">02:28:09.400</a></span> | <span class="t">So if we take each of these images and we need to resize it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8892" target="_blank">02:28:12.920</a></span> | <span class="t">We resize it to the image size that is accepted by this polygamma version. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8898" target="_blank">02:28:18.120</a></span> | <span class="t">As you can see the weights of polygamma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8900" target="_blank">02:28:20.680</a></span> | <span class="t">Actually show there is multiple weights, but this is two to four only resizes the images to the size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8908" target="_blank">02:28:28.100</a></span> | <span class="t">124 by 224 and generates 128 tokens for this in each image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8913" target="_blank">02:28:33.780</a></span> | <span class="t">then we rescale this image and later we will see why we do it and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8918" target="_blank">02:28:38.100</a></span> | <span class="t">We normalize it using the mean and the standard deviation of ImageNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8923" target="_blank">02:28:43.540</a></span> | <span class="t">It's not really the ImageNet mean and standard deviation, but later we will see how it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8927" target="_blank">02:28:47.620</a></span> | <span class="t">Anyway, suppose that this method here will load the image will rescale it will normalize it etc and convert it into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8937" target="_blank">02:28:57.460</a></span> | <span class="t">A tensor that can be then processed by the vision model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8940" target="_blank">02:29:00.340</a></span> | <span class="t">We do it here so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8944" target="_blank">02:29:04.980</a></span> | <span class="t">We create here a tensor. So because this will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8948" target="_blank">02:29:08.020</a></span> | <span class="t">Return a list of tensor. We need to create a one single tensor with the batch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8953" target="_blank">02:29:13.540</a></span> | <span class="t">So we stack them stack basically means that if we have a list of tensor, it will create one single big tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8958" target="_blank">02:29:18.980</a></span> | <span class="t">Where it adds one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8961" target="_blank">02:29:21.620</a></span> | <span class="t">another dimension called the batch size one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8965" target="_blank">02:29:25.220</a></span> | <span class="t">So instead of becoming a list of tensor it will become one big tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8968" target="_blank">02:29:28.500</a></span> | <span class="t">This is a NumPy tensor it is converted into a torch tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8973" target="_blank">02:29:33.860</a></span> | <span class="t">And then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8977" target="_blank">02:29:37.620</a></span> | <span class="t">Create the input to the model. So later we will expand this method. So now I just create them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8984" target="_blank">02:29:44.020</a></span> | <span class="t">What is this method going to do? Well, this method is going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8989" target="_blank">02:29:49.780</a></span> | <span class="t">Let's check here. It's going to create the tokens of the text and create the placeholder for the image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8996" target="_blank">02:29:56.280</a></span> | <span class="t">and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=8999" target="_blank">02:29:59.620</a></span> | <span class="t">We tokenize it using the placeholder tokens for the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9004" target="_blank">02:30:04.340</a></span> | <span class="t">And then we return it. So now let's expand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9008" target="_blank">02:30:08.100</a></span> | <span class="t">This stuff I know that I have copied a lot of code. Now, I will explain it one by one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9013" target="_blank">02:30:13.460</a></span> | <span class="t">So let's start at input. We have a list of text and the list of images. Let's process these images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9019" target="_blank">02:30:19.300</a></span> | <span class="t">So let's create this process image function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9021" target="_blank">02:30:21.620</a></span> | <span class="t">What is it going to do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9024" target="_blank">02:30:24.260</a></span> | <span class="t">Let's copy it. It's very simple actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9026" target="_blank">02:30:26.980</a></span> | <span class="t">Okay, the process image takes as input a list of images what is the size that we want of these images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9035" target="_blank">02:30:35.700</a></span> | <span class="t">What is the kind of resampling that we want to do when resizing this image? You can do linear, you can be cubic, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9044" target="_blank">02:30:44.160</a></span> | <span class="t">Rescale factor if we want to rescale this image and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9047" target="_blank">02:30:47.360</a></span> | <span class="t">the normalization mean and the standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9050" target="_blank">02:30:50.580</a></span> | <span class="t">And this has the same meaning as the normalization that we do in the neural networks. So we want the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9057" target="_blank">02:30:57.280</a></span> | <span class="t">The image no matter what it represents to always have the same distribution more or less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9063" target="_blank">02:31:03.120</a></span> | <span class="t">So centered on zero and the variance of one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9065" target="_blank">02:31:05.680</a></span> | <span class="t">And the way we do it is basically we take the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9070" target="_blank">02:31:10.000</a></span> | <span class="t">Values so the tensor we subtract the mean of all the images that we have in our data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9076" target="_blank">02:31:16.240</a></span> | <span class="t">And usually we use the mean of the image net data set and the standard deviation of the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9081" target="_blank">02:31:21.840</a></span> | <span class="t">Net data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9084" target="_blank">02:31:24.480</a></span> | <span class="t">I don't know why in the hugging phase they use 0.5 because it's actually not really 0.5</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9088" target="_blank">02:31:28.880</a></span> | <span class="t">It's very close to 0.5 each of these numbers, but it's not really so maybe it works anyway</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9095" target="_blank">02:31:35.920</a></span> | <span class="t">And we have one for each channel of the image. So one for r one for g and one for p</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9100" target="_blank">02:31:40.560</a></span> | <span class="t">So what is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9104" target="_blank">02:31:44.000</a></span> | <span class="t">Function going to do first it resizes the image by using this resampling method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9107" target="_blank">02:31:47.760</a></span> | <span class="t">Then it will convert the image into a numpy array</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9110" target="_blank">02:31:50.400</a></span> | <span class="t">Then it will rescale it so that the pixel values instead of being between 0 and 255 will be between 0 and 1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9117" target="_blank">02:31:57.440</a></span> | <span class="t">Then it will normalize using the mean and the standard deviation of image net</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9121" target="_blank">02:32:01.280</a></span> | <span class="t">And then it will move the channel dimension to be the first dimension. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9126" target="_blank">02:32:06.320</a></span> | <span class="t">Instead of being a height width channel, it will become channel height width</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9131" target="_blank">02:32:11.120</a></span> | <span class="t">Let's implement this very simple method. So there is first the resize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9136" target="_blank">02:32:16.980</a></span> | <span class="t">The resize is just going to resize the image using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9141" target="_blank">02:32:21.600</a></span> | <span class="t">methods already implemented by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9144" target="_blank">02:32:24.720</a></span> | <span class="t">The pill library. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9147" target="_blank">02:32:27.120</a></span> | <span class="t">This one called the python imaging library</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9151" target="_blank">02:32:31.520</a></span> | <span class="t">So it will take the image and it will resize it using this resampling method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9156" target="_blank">02:32:36.160</a></span> | <span class="t">Then we have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9159" target="_blank">02:32:39.920</a></span> | <span class="t">rescale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9161" target="_blank">02:32:41.360</a></span> | <span class="t">The rescale is just going to rescale the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9163" target="_blank">02:32:43.680</a></span> | <span class="t">So it will convert each pixel value instead of being between 0 and 255. It will rescale it into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9169" target="_blank">02:32:49.920</a></span> | <span class="t">Between 0 and 1. Why? Because as you can see here, we pass a scale factor of 1 over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9176" target="_blank">02:32:56.060</a></span> | <span class="t">255. So that's why we are multiplying it by this scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9181" target="_blank">02:33:01.420</a></span> | <span class="t">The next thing that we are doing is normalizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9184" target="_blank">02:33:04.800</a></span> | <span class="t">normalizing means that we want the each of these values to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9189" target="_blank">02:33:09.340</a></span> | <span class="t">distributed like it's coming from a Gaussian of mean 0 and variance of 1 and we do it by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9194" target="_blank">02:33:14.380</a></span> | <span class="t">Subtracting the mean and dividing by the standard deviation as you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9202" target="_blank">02:33:22.140</a></span> | <span class="t">I believe we have already implemented everything for the process images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9205" target="_blank">02:33:25.980</a></span> | <span class="t">Now, let's go further. So we have these images we are processing them. So they are still a list of images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9212" target="_blank">02:33:32.700</a></span> | <span class="t">We convert them into they are converted into a list of numpy arrays and we do that here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9218" target="_blank">02:33:38.780</a></span> | <span class="t">As you can see first we convert them into numpy arrays then we rescale, normalize, transpose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9224" target="_blank">02:33:44.160</a></span> | <span class="t">So we have a list of numpy arrays</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9226" target="_blank">02:33:46.860</a></span> | <span class="t">This list of numpy arrays is converted into a single tensor instead of being a list of tensor is becoming one big tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9233" target="_blank">02:33:53.260</a></span> | <span class="t">And then we convert it into a torch tensor. This torch tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9237" target="_blank">02:33:57.900</a></span> | <span class="t">Is the pixel values that will be fed to the model to the image encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9243" target="_blank">02:34:03.100</a></span> | <span class="t">Now we need to take our text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9246" target="_blank">02:34:06.060</a></span> | <span class="t">And we need to tokenize it but we need to tokenize it by already accommodating for the position in which we will put the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9253" target="_blank">02:34:13.500</a></span> | <span class="t">embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9255" target="_blank">02:34:15.980</a></span> | <span class="t">And we do that by processing this each of this text through this function called add image tokens to prompt which as the name implies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9263" target="_blank">02:34:23.260</a></span> | <span class="t">We'll add this image token placeholders to the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9266" target="_blank">02:34:26.140</a></span> | <span class="t">And the way it's done is here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9269" target="_blank">02:34:29.020</a></span> | <span class="t">It's very simple actually also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9271" target="_blank">02:34:31.740</a></span> | <span class="t">We can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9274" target="_blank">02:34:34.300</a></span> | <span class="t">Save it here. It's a long comment because I found a little bug in this one, but okay later I explain to you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9280" target="_blank">02:34:40.300</a></span> | <span class="t">But basically we add some image token placeholders. How many of them? Well, depending on how many image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9286" target="_blank">02:34:46.540</a></span> | <span class="t">Tokens this model needs in the case of polygama 224. We need 128</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9292" target="_blank">02:34:52.320</a></span> | <span class="t">tokens, I believe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9295" target="_blank">02:34:55.420</a></span> | <span class="t">Oh, no, this is not this is the text tokens, I think it's 256 I remember correctly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9301" target="_blank">02:35:01.120</a></span> | <span class="t">Later we can check. I think it's in the config.json. Let's go here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9309" target="_blank">02:35:09.080</a></span> | <span class="t">256</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9311" target="_blank">02:35:11.080</a></span> | <span class="t">Image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9314" target="_blank">02:35:14.460</a></span> | <span class="t">Then we add the beginning of sentence token and then we add the prompt of the user. It's called the prefix prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9320" target="_blank">02:35:20.700</a></span> | <span class="t">How did I come up with this function I didn't come up with it I copied from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9326" target="_blank">02:35:26.860</a></span> | <span class="t">Hugging face implementation, but how did hugging face come up with this actually?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9331" target="_blank">02:35:31.340</a></span> | <span class="t">It's from the paper of polygama</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9334" target="_blank">02:35:34.300</a></span> | <span class="t">So if we go to the polygama paper, let's go here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9339" target="_blank">02:35:39.100</a></span> | <span class="t">here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9340" target="_blank">02:35:40.780</a></span> | <span class="t">Here they show you how to prepare the input for the gamma model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9344" target="_blank">02:35:44.060</a></span> | <span class="t">So we have a list of image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9347" target="_blank">02:35:47.740</a></span> | <span class="t">Then we have the prompt of the user that tells us what the language model needs to do with these images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9354" target="_blank">02:35:54.380</a></span> | <span class="t">So if as you saw the example before in in the introduction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9357" target="_blank">02:35:57.920</a></span> | <span class="t">Here the prefix is this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9360" target="_blank">02:36:00.380</a></span> | <span class="t">So we want the language model to tell us where is the photographer resting by looking at this image and the model will generate this output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9367" target="_blank">02:36:07.500</a></span> | <span class="t">So this is called the the prefix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9369" target="_blank">02:36:09.900</a></span> | <span class="t">So this is the prefix and the prefix is built by first taking okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9374" target="_blank">02:36:14.460</a></span> | <span class="t">We take the image tokens and we are adding them here and based on how many this model particular size of polygama needs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9381" target="_blank">02:36:21.580</a></span> | <span class="t">then we have the beginning of sentence token and this one then we have the tokens of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9387" target="_blank">02:36:27.260</a></span> | <span class="t">Prefix, which is the task that we want the language model to perform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9392" target="_blank">02:36:32.140</a></span> | <span class="t">And then we have a separator the separator token is a slash n. So it's the new line</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9398" target="_blank">02:36:38.220</a></span> | <span class="t">new line character</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9401" target="_blank">02:36:41.740</a></span> | <span class="t">So we have this beginning of sentence token. So then we have the token the the task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9407" target="_blank">02:36:47.100</a></span> | <span class="t">The the prompt by the user based on what task we want the language model to do and then we have the separator token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9414" target="_blank">02:36:54.380</a></span> | <span class="t">Which is a slash n now in the paper. They say that they tokenize the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9420" target="_blank">02:37:00.540</a></span> | <span class="t">Token separately</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9422" target="_blank">02:37:02.540</a></span> | <span class="t">so the slash n needs to be tokenized separately from the rest of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9426" target="_blank">02:37:06.940</a></span> | <span class="t">Input because we don't want the slash n to be merged with this with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9433" target="_blank">02:37:13.260</a></span> | <span class="t">With the prompt by the tokenizer, so as you know the tokenizer will convert a sequence of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9439" target="_blank">02:37:19.580</a></span> | <span class="t">Characters into tokens and if in the dictionary of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9447" target="_blank">02:37:27.100</a></span> | <span class="t">The language model there is one character suppose that we ask the language model to tell me where is the photographer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9454" target="_blank">02:37:34.000</a></span> | <span class="t">And suppose that the in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9457" target="_blank">02:37:37.900</a></span> | <span class="t">and then we have this new line suppose that in the vocabulary of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9463" target="_blank">02:37:43.260</a></span> | <span class="t">Language model there is a token that is like this. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9467" target="_blank">02:37:47.020</a></span> | <span class="t">rougher</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9468" target="_blank">02:37:48.940</a></span> | <span class="t">And escape and it will become one single one single token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9472" target="_blank">02:37:52.860</a></span> | <span class="t">So suppose that this one becomes the token number three and then there is another token that is a space protog</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9478" target="_blank">02:37:58.620</a></span> | <span class="t">It becomes the token number five and then the token the d is another token. So it's the token number six, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9485" target="_blank">02:38:05.180</a></span> | <span class="t">So we don't want the escape and to be merged with whatever comes before it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9489" target="_blank">02:38:09.340</a></span> | <span class="t">So they in the paper, they recommend to tokenize it separately. So that's why I I wrote this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9494" target="_blank">02:38:14.860</a></span> | <span class="t">Comment here to to note that it should be tokenized separately, but I don't know why in hanging phase they do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9501" target="_blank">02:38:21.580</a></span> | <span class="t">Without tokenizing it separately</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9503" target="_blank">02:38:23.580</a></span> | <span class="t">It could be a bug or it could be some other indication that I am missing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9507" target="_blank">02:38:27.660</a></span> | <span class="t">So I just write it now later. I will investigate and probably ping the hanging phase team</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9511" target="_blank">02:38:31.900</a></span> | <span class="t">But for now, we just need to think how we prepare the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9515" target="_blank">02:38:35.500</a></span> | <span class="t">So the input is prepared like this a number of input image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9519" target="_blank">02:38:39.500</a></span> | <span class="t">What is each of this image token? It's this placeholder token that we created here this image token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9526" target="_blank">02:38:46.940</a></span> | <span class="t">how many of them depending on the size of the model and we have this beginning of sentence token and then we have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9532" target="_blank">02:38:52.220</a></span> | <span class="t">Prefix the prompt of the user and then we have the slash n. We take all of this and we tokenize it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9539" target="_blank">02:38:59.180</a></span> | <span class="t">Using our tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9542" target="_blank">02:39:02.380</a></span> | <span class="t">And we return this stuff here. So we return this input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9545" target="_blank">02:39:05.740</a></span> | <span class="t">Which is the input IDs and the attention mask that will be generated by the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9551" target="_blank">02:39:11.200</a></span> | <span class="t">In this case, we are not using any padding. So the attention mask will be just a list of ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9556" target="_blank">02:39:16.060</a></span> | <span class="t">So what is the input IDs? As you remember tokenizer converts the text into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9561" target="_blank">02:39:21.580</a></span> | <span class="t">A list of numbers where each number represents the position in the vocabulary of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9567" target="_blank">02:39:27.020</a></span> | <span class="t">So these are not embeddings. These are just input IDs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9570" target="_blank">02:39:30.700</a></span> | <span class="t">So it's a list of numbers where each number represents the token position in the vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9575" target="_blank">02:39:35.440</a></span> | <span class="t">So imagine our vocabulary is made up of words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9578" target="_blank">02:39:38.940</a></span> | <span class="t">So the word hello the sentence hello world may be tokenized as follows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9585" target="_blank">02:39:45.100</a></span> | <span class="t">so world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9587" target="_blank">02:39:47.100</a></span> | <span class="t">It may be tokenized as a list of two tokens, for example, three tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9592" target="_blank">02:39:52.300</a></span> | <span class="t">For example, the first one corresponding to the word hello</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9594" target="_blank">02:39:54.860</a></span> | <span class="t">Then the one corresponding to the space and then one corresponding to the word world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9599" target="_blank">02:39:59.980</a></span> | <span class="t">Suppose it's the token number nine. So these are called input IDs. So it's not an embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9605" target="_blank">02:40:05.100</a></span> | <span class="t">It's just one number for each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9607" target="_blank">02:40:07.740</a></span> | <span class="t">Then by the embedding layer, this will be converted into embeddings, which will be one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9614" target="_blank">02:40:14.540</a></span> | <span class="t">Vector for each token. So with the suppose 1024 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9619" target="_blank">02:40:19.440</a></span> | <span class="t">So this one will be for the first token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9623" target="_blank">02:40:23.180</a></span> | <span class="t">1024 dimensions then for the second token another 1024 dimensions, etc, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9629" target="_blank">02:40:29.340</a></span> | <span class="t">So this is how we prepare the input. So for now, we have resized the image converted into a tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9635" target="_blank">02:40:35.740</a></span> | <span class="t">Then we have taken our prompt. We have added some placeholder tokens for the image then we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9641" target="_blank">02:40:41.980</a></span> | <span class="t">Added the prompt of the user and then the slash and character as indicated by polygamma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9647" target="_blank">02:40:47.440</a></span> | <span class="t">And now our processor will return this stuff. Now, we need to understand what to do with this stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9653" target="_blank">02:40:53.500</a></span> | <span class="t">So we need to code our language model. All right guys, so let's continue our journey by creating another file here called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9660" target="_blank">02:41:00.620</a></span> | <span class="t">modeling_gamma.py</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9663" target="_blank">02:41:03.160</a></span> | <span class="t">Which will be our language model. So the language model that will decode the answer of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9669" target="_blank">02:41:09.980</a></span> | <span class="t">the answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9671" target="_blank">02:41:11.740</a></span> | <span class="t">Using the prompt or given by the user and the image that we have provided as input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9676" target="_blank">02:41:16.300</a></span> | <span class="t">So we create this file. We import a little bit of stuff the usual stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9681" target="_blank">02:41:21.740</a></span> | <span class="t">So torch, some math, typing and then we import siglib model that we have created before so the visual model and the configuration that it needs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9689" target="_blank">02:41:29.580</a></span> | <span class="t">Let's do a bottom-up approach which means that we first create the structure of the model and then we create each single component</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9700" target="_blank">02:41:40.400</a></span> | <span class="t">So let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9702" target="_blank">02:41:42.400</a></span> | <span class="t">Let's do it this one. All right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9706" target="_blank">02:41:46.720</a></span> | <span class="t">Our main class will be called the polygamma for conditional generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9712" target="_blank">02:41:52.720</a></span> | <span class="t">So why it's called conditional generation? Because we are conditioning the generation of text on the image that is provided as input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9719" target="_blank">02:41:59.680</a></span> | <span class="t">This is why it's called conditional generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9721" target="_blank">02:42:01.680</a></span> | <span class="t">and also actually it's because of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9724" target="_blank">02:42:04.240</a></span> | <span class="t">how we create the attention mask that we will see later because we are attending to all the tokens of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9729" target="_blank">02:42:09.760</a></span> | <span class="t">prompt of the user and all the tokens of the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9734" target="_blank">02:42:14.400</a></span> | <span class="t">Without any causality so it's used like a condition, but we will see that later. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9740" target="_blank">02:42:20.640</a></span> | <span class="t">The constructor accepts a configuration file, which we are going to create now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9744" target="_blank">02:42:24.960</a></span> | <span class="t">It will create an instance of the vision model. So the encoder of the image it will create this multi-modal projector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9752" target="_blank">02:42:32.000</a></span> | <span class="t">Which is a linear layer. Let's actually visualize it all these components</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9755" target="_blank">02:42:35.940</a></span> | <span class="t">So we go here and then we open this stuff. So basically the multi-modal projector is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9763" target="_blank">02:42:43.840</a></span> | <span class="t">linear layer you can see here linear projection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9767" target="_blank">02:42:47.140</a></span> | <span class="t">and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9768" target="_blank">02:42:48.960</a></span> | <span class="t">the vision model is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9770" target="_blank">02:42:50.960</a></span> | <span class="t">Contrastive vision encoder and then we have gamma for causal language modeling, which is this our transformer decoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9778" target="_blank">02:42:58.000</a></span> | <span class="t">So this class basically polygamma for conditional generation is actually the class that will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9782" target="_blank">02:43:02.080</a></span> | <span class="t">Make make connect all these components together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9785" target="_blank">02:43:05.760</a></span> | <span class="t">I don't know why my pen is not working my ipad pen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9789" target="_blank">02:43:09.920</a></span> | <span class="t">Oh now it's working. It looks like so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9792" target="_blank">02:43:12.640</a></span> | <span class="t">Yeah now it's working. Okay, let's continue</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9795" target="_blank">02:43:15.520</a></span> | <span class="t">All right, so we have created this it will create an instance of the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9800" target="_blank">02:43:20.880</a></span> | <span class="t">It will save some stuff like what is the language model? What is the vision tower, which is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9806" target="_blank">02:43:26.960</a></span> | <span class="t">image encoder the multi-modal projector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9808" target="_blank">02:43:28.720</a></span> | <span class="t">which is the linear layer that will convert the size of the embedding output by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9812" target="_blank">02:43:32.720</a></span> | <span class="t">Vision encoder into the size of the embedding of each text token so that they can be concatenated with together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9820" target="_blank">02:43:40.560</a></span> | <span class="t">We also save the padding token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9823" target="_blank">02:43:43.200</a></span> | <span class="t">We need to create another method called tie weights and we will see later what is this about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9831" target="_blank">02:43:51.200</a></span> | <span class="t">Or actually we can check now what this is about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9835" target="_blank">02:43:55.280</a></span> | <span class="t">so tie weights basically means this so let's go back to our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9839" target="_blank">02:43:59.440</a></span> | <span class="t">Here and let's open the attention mechanism. And actually let's open the transformer model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9845" target="_blank">02:44:05.760</a></span> | <span class="t">so weight tying is a technique for kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9848" target="_blank">02:44:08.800</a></span> | <span class="t">reusing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9851" target="_blank">02:44:11.820</a></span> | <span class="t">parameters of one layer into another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9854" target="_blank">02:44:14.080</a></span> | <span class="t">And specifically in the case of language model most language models are in decoder only language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9859" target="_blank">02:44:19.600</a></span> | <span class="t">Which means that they are only made up of this part of the transformer without the cross attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9865" target="_blank">02:44:25.840</a></span> | <span class="t">So there is no this block here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9867" target="_blank">02:44:27.840</a></span> | <span class="t">So it's they are made up of a self-attention with the normalization then a feed forward with the normalization a lot of layers like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9875" target="_blank">02:44:35.840</a></span> | <span class="t">so one after another then we have a final linear layer that projects the embedding output by these layers into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9882" target="_blank">02:44:42.800</a></span> | <span class="t">Logits, and then we have the softmax to understand which of these tokens has the maximum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9888" target="_blank">02:44:48.540</a></span> | <span class="t">Probability score given by the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9890" target="_blank">02:44:50.540</a></span> | <span class="t">now in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9892" target="_blank">02:44:52.540</a></span> | <span class="t">the job of this linear layer is basically to convert the embedding of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9896" target="_blank">02:44:56.940</a></span> | <span class="t">Contextualized embedding output by the last layer of this series of layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9902" target="_blank">02:45:02.060</a></span> | <span class="t">Into the vocabulary size, which is exactly the opposite that this job</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9907" target="_blank">02:45:07.500</a></span> | <span class="t">Layer is doing so the embedding layer the embedding layer is converting the token ids</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9914" target="_blank">02:45:14.140</a></span> | <span class="t">So the position of each token in the vocabulary into an embedding while this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9918" target="_blank">02:45:18.300</a></span> | <span class="t">Linear layer here is doing exactly the opposite converting an embedding into its position in the vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9923" target="_blank">02:45:23.440</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9925" target="_blank">02:45:25.660</a></span> | <span class="t">Many language models not all of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9927" target="_blank">02:45:27.660</a></span> | <span class="t">use a technique called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9930" target="_blank">02:45:30.300</a></span> | <span class="t">Weight tying which basically shares the parameters of this layer and this layer because they are doing basically one the inverse job of the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9937" target="_blank">02:45:37.580</a></span> | <span class="t">Which is also a technique actually to reduce the total parameters of the model because if you are sharing these parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9943" target="_blank">02:45:43.900</a></span> | <span class="t">you will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9945" target="_blank">02:45:45.900</a></span> | <span class="t">You will reduce the number of parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9947" target="_blank">02:45:47.900</a></span> | <span class="t">And in many language models this depending on the vocabulary size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9951" target="_blank">02:45:51.180</a></span> | <span class="t">These parameters can be actually quite expensive on the overall total number of parameters of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9956" target="_blank">02:45:56.220</a></span> | <span class="t">So it could be like 10% of the parameters in this layer here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9959" target="_blank">02:45:59.180</a></span> | <span class="t">So if you are sharing them, you are actually reducing the number of parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9963" target="_blank">02:46:03.020</a></span> | <span class="t">Let's say by 10% because depending on the how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9965" target="_blank">02:46:05.420</a></span> | <span class="t">Tokens you have in your vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9968" target="_blank">02:46:08.300</a></span> | <span class="t">So we created this method here tie weight and later we will implement it also in the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9973" target="_blank">02:46:13.420</a></span> | <span class="t">So in the gamma decoder language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9975" target="_blank">02:46:15.740</a></span> | <span class="t">That will tie the weights of these two layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9978" target="_blank">02:46:18.780</a></span> | <span class="t">Okay, now that we have seen also this one. Let's go further, which is the implementation of the forward method. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9986" target="_blank">02:46:26.060</a></span> | <span class="t">So we implemented the forward method as follows so it accepts the input ids</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9992" target="_blank">02:46:32.940</a></span> | <span class="t">What are the input ids? The input ids will be the input ids extracted from this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=9999" target="_blank">02:46:39.480</a></span> | <span class="t">Polygama processor which will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10001" target="_blank">02:46:41.480</a></span> | <span class="t">the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10002" target="_blank">02:46:42.920</a></span> | <span class="t">Some image tokens. So a lot of tokens like this one image image image image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10007" target="_blank">02:46:47.720</a></span> | <span class="t">How many depending on the size of polygama we are using?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10010" target="_blank">02:46:50.600</a></span> | <span class="t">Then it will contain a beginning of sentence token. Then it will contain the prompt of the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10016" target="_blank">02:46:56.840</a></span> | <span class="t">So for example, tell me where is this photographer and then a new line</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10021" target="_blank">02:47:01.560</a></span> | <span class="t">Character the token corresponding to the new line character</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10027" target="_blank">02:47:07.800</a></span> | <span class="t">Yeah, text, okay, so, then we have the pixel values which is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10032" target="_blank">02:47:12.200</a></span> | <span class="t">Again is the image extracted from this polygama processor, which is the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10038" target="_blank">02:47:18.040</a></span> | <span class="t">loaded by this polygama processor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10041" target="_blank">02:47:21.000</a></span> | <span class="t">rescaled resized and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10043" target="_blank">02:47:23.300</a></span> | <span class="t">Normalized using the mean and the standard deviation of this image net standard mean and standard deviation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10051" target="_blank">02:47:31.020</a></span> | <span class="t">It is converted into a pair into a tensor and then provided as is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10057" target="_blank">02:47:37.480</a></span> | <span class="t">Then the goal of this polygama for conditional generation will be to take this image and feed it to the image encoder to get extracted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10064" target="_blank">02:47:44.120</a></span> | <span class="t">the image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10065" target="_blank">02:47:45.640</a></span> | <span class="t">Then we have this attention mask. The attention mask is provided directly by the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10069" target="_blank">02:47:49.880</a></span> | <span class="t">So whenever you tokenize text using a tokenizer, it gives you two output. One is the input ids and one is the attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10075" target="_blank">02:47:55.880</a></span> | <span class="t">Because we will not be using any padding the attention mask will be a series of one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10080" target="_blank">02:48:00.360</a></span> | <span class="t">Later, we will see how we also need to modify the attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10085" target="_blank">02:48:05.640</a></span> | <span class="t">But actually we will not be modifying because we will not be using any padding so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10089" target="_blank">02:48:09.800</a></span> | <span class="t">Yeah, then we have the KB cache, which we will talk about later when we actually use it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10094" target="_blank">02:48:14.920</a></span> | <span class="t">So for now just consider it as something that you don't know anything about and later we will discuss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10099" target="_blank">02:48:19.400</a></span> | <span class="t">Okay, so let's see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10104" target="_blank">02:48:24.280</a></span> | <span class="t">Okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10107" target="_blank">02:48:27.880</a></span> | <span class="t">We have first we make sure that we are not using any padding because I didn't implement the code to manage the padding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10114" target="_blank">02:48:34.440</a></span> | <span class="t">Then we extract the input embeddings of the text tokens and the image placeholder tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10120" target="_blank">02:48:40.200</a></span> | <span class="t">So in the language model, we have added a fictional token called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10124" target="_blank">02:48:44.840</a></span> | <span class="t">Image, so this token here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10127" target="_blank">02:48:47.640</a></span> | <span class="t">Which will be converted into an input id so it will be converted into a number which corresponds to its position in the vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10133" target="_blank">02:48:53.980</a></span> | <span class="t">What we are doing is we are converting all the input tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10138" target="_blank">02:48:58.520</a></span> | <span class="t">Which are the image tokens the beginning of sentence token the tokens of the prompt plus the new line character</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10145" target="_blank">02:49:05.240</a></span> | <span class="t">into embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10146" target="_blank">02:49:06.920</a></span> | <span class="t">of course the embeddings produced by the image placeholder tokens will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10150" target="_blank">02:49:10.280</a></span> | <span class="t">Junk because we will not be using them because they do not correspond to the actual image features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10154" target="_blank">02:49:14.920</a></span> | <span class="t">But later we will replace them inside of this one with the correct one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10159" target="_blank">02:49:19.400</a></span> | <span class="t">so now we have this input embeddings the first thing we do is we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10164" target="_blank">02:49:24.200</a></span> | <span class="t">Extract the features of the image and we do it like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10167" target="_blank">02:49:27.320</a></span> | <span class="t">So we feed the pixel values of the image, which is a tensor directly to the vision tower. So the vision tower is our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10174" target="_blank">02:49:34.280</a></span> | <span class="t">Siglip vision model. So it means that we are using the forward method here. So we are feeding the pixel values here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10181" target="_blank">02:49:41.640</a></span> | <span class="t">It will extract what it will extract some patches with their contextualized embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10188" target="_blank">02:49:48.440</a></span> | <span class="t">So it will for each image it will give us n</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10192" target="_blank">02:49:52.340</a></span> | <span class="t">Patches and each of these patches is a contextualized patch actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10196" target="_blank">02:49:56.180</a></span> | <span class="t">The second thing we are going to do is we are going to resize this embeddings image embeddings into the same size of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10205" target="_blank">02:50:05.380</a></span> | <span class="t">language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10207" target="_blank">02:50:07.780</a></span> | <span class="t">Embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10210" target="_blank">02:50:10.100</a></span> | <span class="t">And for that we do this other line</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10212" target="_blank">02:50:12.100</a></span> | <span class="t">So we take the image embeddings extracted by the vision encoder and then we resize them using a linear layer called the multi-modal projector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10220" target="_blank">02:50:20.340</a></span> | <span class="t">So later we will see this is actually just a linear layer that will convert this embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10225" target="_blank">02:50:25.300</a></span> | <span class="t">So this embed dimension extracted from the vision encoder into the hidden size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10229" target="_blank">02:50:29.540</a></span> | <span class="t">Which is the same embedding size used by the language model for each of this each of its tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10234" target="_blank">02:50:34.420</a></span> | <span class="t">Now we need to merge the tokens extracted from the vision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10241" target="_blank">02:50:41.300</a></span> | <span class="t">Model with the text token extracted from these embeddings which already contain some placeholders for where we should put the image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10250" target="_blank">02:50:50.420</a></span> | <span class="t">And for that we will create another method called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10252" target="_blank">02:50:52.980</a></span> | <span class="t">Let me first paste it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10255" target="_blank">02:50:55.700</a></span> | <span class="t">Called merge input ids with image features in which we pass the image features extracted from the vision encoder the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10262" target="_blank">02:51:02.740</a></span> | <span class="t">Embeddings extracted from the language model with which already contains the placeholders</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10267" target="_blank">02:51:07.720</a></span> | <span class="t">the input ids which are the original input ids fed to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10271" target="_blank">02:51:11.620</a></span> | <span class="t">The tokens fed to the language model and the attention mask given by it and the KB cache later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10277" target="_blank">02:51:17.540</a></span> | <span class="t">We'll see why we need the KB cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10280" target="_blank">02:51:20.500</a></span> | <span class="t">Suppose that these input features have been merged so we will get these input embeddings these input embeddings. What are they?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10287" target="_blank">02:51:27.620</a></span> | <span class="t">Well, let's visualize it on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10289" target="_blank">02:51:29.700</a></span> | <span class="t">Oh, wait, where is it? My okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10293" target="_blank">02:51:33.300</a></span> | <span class="t">Uh, oops</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10296" target="_blank">02:51:36.980</a></span> | <span class="t">So let's go here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10299" target="_blank">02:51:39.460</a></span> | <span class="t">Okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10301" target="_blank">02:51:41.940</a></span> | <span class="t">So what we are doing is basically we are creating this stuff here. So we are taking the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10306" target="_blank">02:51:46.660</a></span> | <span class="t">First we are taking the image features extracted by the vision encoder and these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10309" target="_blank">02:51:49.860</a></span> | <span class="t">Features are here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10312" target="_blank">02:51:52.500</a></span> | <span class="t">Then we are resizing them using this multimodal projector, which is this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10317" target="_blank">02:51:57.300</a></span> | <span class="t">Which will resize the each embedding vector to the correct size so that they can be concatenated with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10323" target="_blank">02:52:03.300</a></span> | <span class="t">embeddings of the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10326" target="_blank">02:52:06.240</a></span> | <span class="t">the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10328" target="_blank">02:52:08.660</a></span> | <span class="t">When we tokenize them, they already contain some placeholder tokens, which are those image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10334" target="_blank">02:52:14.500</a></span> | <span class="t">We saw before in the processing_polygamma.py file</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10337" target="_blank">02:52:17.460</a></span> | <span class="t">Our goal is to replace each of them with the features extracted from this vision encoder after it has been resized by the multimodal projector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10346" target="_blank">02:52:26.260</a></span> | <span class="t">And for that we will use this method here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10349" target="_blank">02:52:29.060</a></span> | <span class="t">So this method takes the image features extracted after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10351" target="_blank">02:52:31.940</a></span> | <span class="t">They have been resized the input embedding extracted from the language model which contains the text tokens and the placeholders</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10357" target="_blank">02:52:37.940</a></span> | <span class="t">And it will replace this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10360" target="_blank">02:52:40.580</a></span> | <span class="t">So suppose that now it everything has been replaced. So we treat it as a black box</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10364" target="_blank">02:52:44.580</a></span> | <span class="t">What we are going to do we are going to feed all this sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10367" target="_blank">02:52:47.300</a></span> | <span class="t">Which is a sequence of image features and the text tokens to the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10371" target="_blank">02:52:51.620</a></span> | <span class="t">which will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10373" target="_blank">02:52:53.540</a></span> | <span class="t">Use the prompt of the user which are these tokens and the image fed by the user to generate some text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10379" target="_blank">02:52:59.380</a></span> | <span class="t">So let's implement this part here, which is just calling a method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10384" target="_blank">02:53:04.100</a></span> | <span class="t">And it's very easy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10389" target="_blank">02:53:09.540</a></span> | <span class="t">Because it's just calling a method and later we will implement this language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10393" target="_blank">02:53:13.620</a></span> | <span class="t">So for now, I created the structure of what we are doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10396" target="_blank">02:53:16.420</a></span> | <span class="t">So we extract first we tokenize the text the text already contains placeholders</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10401" target="_blank">02:53:21.060</a></span> | <span class="t">We replace these placeholders with the features extracted from the vision encoder. We feed everything to the language model. The language model will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10407" target="_blank">02:53:27.060</a></span> | <span class="t">Generate some output and we return this output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10410" target="_blank">02:53:30.020</a></span> | <span class="t">Now our goal is of course to implement all of these blocks that we have created that we have taken for granted for now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10416" target="_blank">02:53:36.820</a></span> | <span class="t">The first thing that we can do is to implement this polygamma config which will give us some understanding of what are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10421" target="_blank">02:53:41.700</a></span> | <span class="t">What is the kind of configuration that this polygamma needs?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10424" target="_blank">02:53:44.500</a></span> | <span class="t">For that we create it we need to create this polygamma config</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10431" target="_blank">02:53:51.800</a></span> | <span class="t">Okay, the polygamma config basically takes as input so the polygamma is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10440" target="_blank">02:54:00.340</a></span> | <span class="t">So what is gamma? What is polygamma? And what is cglib?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10445" target="_blank">02:54:05.300</a></span> | <span class="t">I think you should already have an understanding of it now. So polygamma is all of this stuff here all this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10451" target="_blank">02:54:11.060</a></span> | <span class="t">So it's a combination of a vision encoder and a text decoder language model. So a gamma model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10457" target="_blank">02:54:17.060</a></span> | <span class="t">So it's composed of two parts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10458" target="_blank">02:54:18.980</a></span> | <span class="t">It's composed of a cglib vision encoder along with a linear layer that will change the embedding size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10464" target="_blank">02:54:24.660</a></span> | <span class="t">And it's made up of a language model called gamma language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10469" target="_blank">02:54:29.540</a></span> | <span class="t">So the polygamma needs of course the configuration for this block here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10473" target="_blank">02:54:33.860</a></span> | <span class="t">So the language model and the configuration for the vision encoder so that it can create an instance of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10479" target="_blank">02:54:39.300</a></span> | <span class="t">This cglib class and of this gamma language model passing their own configuration to them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10485" target="_blank">02:54:45.220</a></span> | <span class="t">And this is what you see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10487" target="_blank">02:54:47.300</a></span> | <span class="t">So you have the vision config which is the configuration of the vision encoder the text config which is the configuration of the text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10493" target="_blank">02:54:53.140</a></span> | <span class="t">decoder which is gamma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10496" target="_blank">02:54:56.340</a></span> | <span class="t">The ignore index is not used. We will not be using it for labels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10500" target="_blank">02:55:00.340</a></span> | <span class="t">So if you are training, but we will only doing inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10502" target="_blank">02:55:02.820</a></span> | <span class="t">The image token index is the token corresponding to the placeholder image token. So the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10508" target="_blank">02:55:08.500</a></span> | <span class="t">This token here. So let's this this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10511" target="_blank">02:55:11.780</a></span> | <span class="t">The vocabulary size. So what is the vocabulary size of the model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10516" target="_blank">02:55:16.420</a></span> | <span class="t">the projection dimension is how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10519" target="_blank">02:55:19.300</a></span> | <span class="t">What is the final dimension that the image features should be resized to before feeding to the language model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10525" target="_blank">02:55:25.940</a></span> | <span class="t">So what is basically the output size of this linear layer?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10530" target="_blank">02:55:30.580</a></span> | <span class="t">Then we have the hidden size which is the embedding size of the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10535" target="_blank">02:55:35.460</a></span> | <span class="t">So the language model has some tokens. These tokens are embeddings and these embeddings have a dimensions. How many dimensions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10541" target="_blank">02:55:41.780</a></span> | <span class="t">2048 in the base version of gamma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10544" target="_blank">02:55:44.900</a></span> | <span class="t">This stuff is something that HuggingFace needs we will not be using it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10550" target="_blank">02:55:50.980</a></span> | <span class="t">We save the padding token id if in case it's fast, so we save the vision encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10555" target="_blank">02:55:55.060</a></span> | <span class="t">We save the text encoder and then we need the configuration of the text language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10559" target="_blank">02:55:59.220</a></span> | <span class="t">Which is the gamma model to which we pass the of course the text configuration and to the vision encoder. We pass the vision configuration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10565" target="_blank">02:56:05.400</a></span> | <span class="t">We have how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10568" target="_blank">02:56:08.100</a></span> | <span class="t">number of tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10570" target="_blank">02:56:10.100</a></span> | <span class="t">For image tokens each image will generate which is basically the size of the image divided by the patch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10577" target="_blank">02:56:17.140</a></span> | <span class="t">So it's actually how many patches you get for each image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10581" target="_blank">02:56:21.300</a></span> | <span class="t">Um, which is also corresponds to how many image tokens you get here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10586" target="_blank">02:56:26.500</a></span> | <span class="t">Because of course if you divide the image by four you get four patches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10591" target="_blank">02:56:31.700</a></span> | <span class="t">If you divide it in smaller parts, you get more patches and each a polygamma size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10596" target="_blank">02:56:36.420</a></span> | <span class="t">So polygamma two to four, I think it has 256 tokens. Another one has more etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10604" target="_blank">02:56:44.100</a></span> | <span class="t">Um, the projection dimension is how we want to resize this image tokens, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10609" target="_blank">02:56:49.620</a></span> | <span class="t">So now let's create also the configuration for the gamma model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10612" target="_blank">02:56:52.660</a></span> | <span class="t">which is just the configuration of any language model because it has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10617" target="_blank">02:56:57.060</a></span> | <span class="t">A vocabulary size how much tokens we have in our vocabulary the hidden sizes. So what is the size of the embedding?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10624" target="_blank">02:57:04.820</a></span> | <span class="t">Embedding vector of each token the intermediate size of the feed-forward layer as we saw before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10632" target="_blank">02:57:12.020</a></span> | <span class="t">In Sigleap the number of hidden layers. So how many layers our transformer has in this gamma language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10638" target="_blank">02:57:18.740</a></span> | <span class="t">How many attention heads we have? Okay here we have a difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10642" target="_blank">02:57:22.340</a></span> | <span class="t">This is called the grouped query attention when you have a different number of heads for the query and for the key and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10648" target="_blank">02:57:28.340</a></span> | <span class="t">the number of heads here refers to the number of heads for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10652" target="_blank">02:57:32.420</a></span> | <span class="t">Queries and the number of heads for the key and values is this parameter here. We will see later how it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10658" target="_blank">02:57:38.180</a></span> | <span class="t">The head dimension is how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10660" target="_blank">02:57:40.180</a></span> | <span class="t">Dimensions each head will work with as we saw before we divide this big embedding into smaller groups one dedicated to each head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10667" target="_blank">02:57:47.860</a></span> | <span class="t">This is how many dimensions each head will watch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10670" target="_blank">02:57:50.580</a></span> | <span class="t">Now this configuration. It's a hard-coded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10673" target="_blank">02:57:53.560</a></span> | <span class="t">But actually it will come from the configuration file of the polygamma model that we will load</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10679" target="_blank">02:57:59.460</a></span> | <span class="t">So if you go to hugging face, you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10682" target="_blank">02:58:02.100</a></span> | <span class="t">Hugging face, polygamma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10687" target="_blank">02:58:07.540</a></span> | <span class="t">You go to two to four you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10689" target="_blank">02:58:09.860</a></span> | <span class="t">We will load all this configuration from this config.json file</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10693" target="_blank">02:58:13.700</a></span> | <span class="t">Which as you can see contains this text config this visual config which contains exactly the information that we need here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10700" target="_blank">02:58:20.500</a></span> | <span class="t">This max positional encodings indicates how much the maximum number of positions our model has been trained upon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10708" target="_blank">02:58:28.740</a></span> | <span class="t">Which is necessary for the rotary positional encodings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10713" target="_blank">02:58:33.380</a></span> | <span class="t">RMS norm is we will see later. What is the rms normalization, but just like the layer normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10719" target="_blank">02:58:39.460</a></span> | <span class="t">We have this parameter called rms norm fps. Okay, I will explain it later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10723" target="_blank">02:58:43.940</a></span> | <span class="t">Actually, the rope data is another parameter of the rotary positional encoding, which is the base frequency</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10729" target="_blank">02:58:49.640</a></span> | <span class="t">And also we will see later. What is it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10732" target="_blank">02:58:52.100</a></span> | <span class="t">the attention bias</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10734" target="_blank">02:58:54.100</a></span> | <span class="t">Indicates if in the attention matrices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10736" target="_blank">02:58:56.420</a></span> | <span class="t">We are we want the bias because as you remember we have the wqwk and wv matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10740" target="_blank">02:59:00.900</a></span> | <span class="t">These are linear layers and we can have also the bias term, but we I believe we never use the bias for this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10747" target="_blank">02:59:07.300</a></span> | <span class="t">And it looks like we yeah, we don't use any bias for it. So if they don't overwrite it then it remains false</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10754" target="_blank">02:59:14.340</a></span> | <span class="t">Dropout just like before we are not going to use it and the padding token id and we save all this stuff. So nothing so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10761" target="_blank">02:59:21.920</a></span> | <span class="t">Sophisticated here now the first thing that we are going to do since we have already implemented polygama for conditional generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10768" target="_blank">02:59:28.160</a></span> | <span class="t">I believe that the first thing that we can do is this method here merge input ids with image features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10773" target="_blank">02:59:33.760</a></span> | <span class="t">But for that we will need to understand. What is the kb cache?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10777" target="_blank">02:59:37.120</a></span> | <span class="t">All right. So let's start coding this method. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10780" target="_blank">02:59:40.800</a></span> | <span class="t">Let me go also here in the code that I have already written. So I will code it piece by piece</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10787" target="_blank">02:59:47.440</a></span> | <span class="t">So that we don't get lost in the explanation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10791" target="_blank">02:59:51.760</a></span> | <span class="t">So we create this method which has this signature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10794" target="_blank">02:59:54.340</a></span> | <span class="t">If you don't see it all it's this one here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10798" target="_blank">02:59:58.240</a></span> | <span class="t">And let's extract. Okay. The first thing we do is we extract some information from the inputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10805" target="_blank">03:00:05.460</a></span> | <span class="t">Which are what is the embedding dimension from the image features because we need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10811" target="_blank">03:00:11.600</a></span> | <span class="t">Which are already resized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10814" target="_blank">03:00:14.400</a></span> | <span class="t">Because we pass them after sending them through this multimodal projector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10818" target="_blank">03:00:18.320</a></span> | <span class="t">So they have already been resized to the same size of the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10822" target="_blank">03:00:22.000</a></span> | <span class="t">Then we have these input ids which tells us how many tokens we have the input ids</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10826" target="_blank">03:00:26.480</a></span> | <span class="t">If you remember correctly is the not the embedding of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10830" target="_blank">03:00:30.080</a></span> | <span class="t">It's the number indicating the position of each token in the vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10833" target="_blank">03:00:33.060</a></span> | <span class="t">While the input embeddings are the embedding of each token after they have been extracted from the embedding layer of the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10840" target="_blank">03:00:40.880</a></span> | <span class="t">And that's why we have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10843" target="_blank">03:00:43.680</a></span> | <span class="t">It's a vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10847" target="_blank">03:00:47.520</a></span> | <span class="t">now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10848" target="_blank">03:00:48.400</a></span> | <span class="t">The first thing that we do is we scale these image features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10851" target="_blank">03:00:51.680</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10854" target="_blank">03:00:54.000</a></span> | <span class="t">We scale these image features which also helps. It's like the same kind of scaling that we use in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10860" target="_blank">03:01:00.400</a></span> | <span class="t">In the attention mechanism, so we do query multiply by transpose of the key divided by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10866" target="_blank">03:01:06.080</a></span> | <span class="t">Square root of the model here. We do the simple the same kind of scaling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10871" target="_blank">03:01:11.760</a></span> | <span class="t">Because probably they have tried multiple variations of the model and we want the magnitude of the numbers to remain the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10878" target="_blank">03:01:18.480</a></span> | <span class="t">That's why we divide it by the the size of the hidden side. So if they if you want to double the for example the embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10885" target="_blank">03:01:25.440</a></span> | <span class="t">Size of the image features you want the magnitude of numbers more or less to remain the same. That's why you you scale them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10895" target="_blank">03:01:35.360</a></span> | <span class="t">Now the first thing that we need to do is to create the final tensor that will hold the combined</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10901" target="_blank">03:01:41.380</a></span> | <span class="t">Features of the image tokens and the text tokens and this is and it's this tensor here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10906" target="_blank">03:01:46.560</a></span> | <span class="t">It's made up of zeros and it has the size of batch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10910" target="_blank">03:01:50.000</a></span> | <span class="t">Sequence length. So what is sequence length? The sequence length is the number of input ids we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10915" target="_blank">03:01:55.520</a></span> | <span class="t">What are these input ids? The input ids that are coming from this processing polygamma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10920" target="_blank">03:02:00.340</a></span> | <span class="t">class</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10922" target="_blank">03:02:02.720</a></span> | <span class="t">which are the placeholder for the image tokens the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10926" target="_blank">03:02:06.000</a></span> | <span class="t">beginning of sentence text the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10928" target="_blank">03:02:08.640</a></span> | <span class="t">tokens of the prompt and the new line character</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10931" target="_blank">03:02:11.760</a></span> | <span class="t">So the token corresponding to the new line character</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10935" target="_blank">03:02:15.140</a></span> | <span class="t">So we create this sequence of empty embeddings of which size of embedding size dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10943" target="_blank">03:02:23.140</a></span> | <span class="t">Embedding dimension which is the same size of the embedding vector of language model because the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10949" target="_blank">03:02:29.120</a></span> | <span class="t">Tokens and the text token will have the same size which is embedded dim here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10953" target="_blank">03:02:33.680</a></span> | <span class="t">We want to be of the same size of the same d type</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10957" target="_blank">03:02:37.520</a></span> | <span class="t">So if it's floating point 32 of the input embeds and we put it on the same device</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10963" target="_blank">03:02:43.120</a></span> | <span class="t">The first thing that we do is we create some masks that will be useful for understanding which is a placeholder token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10970" target="_blank">03:02:50.160</a></span> | <span class="t">Which is a text token and which is a padding token, even though we will not be using any padding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10974" target="_blank">03:02:54.640</a></span> | <span class="t">So I just took the original implementation, which was already handling the padding, but we will actually never have padding tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10980" target="_blank">03:03:00.720</a></span> | <span class="t">How to understand which one is a text token?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10983" target="_blank">03:03:03.600</a></span> | <span class="t">Well, a text token is something that is not an image placeholder token and it's not a padding token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10988" target="_blank">03:03:08.880</a></span> | <span class="t">What is an image token?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10990" target="_blank">03:03:10.560</a></span> | <span class="t">Well something that is equal to the image placeholder token and the padding tokens are the tokens that correspond to the padding token id</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=10998" target="_blank">03:03:18.480</a></span> | <span class="t">this mask will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11001" target="_blank">03:03:21.360</a></span> | <span class="t">useful for us to understand where to put the embeddings of the image tokens in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11005" target="_blank">03:03:25.920</a></span> | <span class="t">Final embedding tensor where to put the text token in this final embedding tensor and where to put the padding tokens in this final</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11012" target="_blank">03:03:32.080</a></span> | <span class="t">embedding tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11014" target="_blank">03:03:34.080</a></span> | <span class="t">We expand them so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11017" target="_blank">03:03:37.440</a></span> | <span class="t">Here we see them and later we will see why we need to expand them. So basically we are creating I believe the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11024" target="_blank">03:03:44.160</a></span> | <span class="t">few dimensions more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11026" target="_blank">03:03:46.960</a></span> | <span class="t">because we need to create the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11029" target="_blank">03:03:49.120</a></span> | <span class="t">batch size dimension and the sequence dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11032" target="_blank">03:03:52.100</a></span> | <span class="t">I don't know. We already have the sequence dimension because it's already given by the input ids</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11039" target="_blank">03:03:59.600</a></span> | <span class="t">We are creating the batch dimension and then we are expanding it to this embed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11044" target="_blank">03:04:04.320</a></span> | <span class="t">dim dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11047" target="_blank">03:04:07.200</a></span> | <span class="t">Later we will see why we need it. So basically this means that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11050" target="_blank">03:04:10.560</a></span> | <span class="t">The text mask here. So let me draw a sample of how it may look like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11057" target="_blank">03:04:17.600</a></span> | <span class="t">Oops, what did I do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11059" target="_blank">03:04:19.440</a></span> | <span class="t">here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11060" target="_blank">03:04:20.400</a></span> | <span class="t">the text mask here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11062" target="_blank">03:04:22.400</a></span> | <span class="t">Will be something like this. So if suppose that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11065" target="_blank">03:04:25.520</a></span> | <span class="t">The input ids are the tokens corresponding to the image. So suppose that it's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11071" target="_blank">03:04:31.920</a></span> | <span class="t">567 so we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11074" target="_blank">03:04:34.780</a></span> | <span class="t">So we have many tokens corresponding to the placeholder for the image then we have the beginning of sentence token suppose usually it's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11082" target="_blank">03:04:42.320</a></span> | <span class="t">token number one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11084" target="_blank">03:04:44.480</a></span> | <span class="t">Then we have the prompt of the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11086" target="_blank">03:04:46.880</a></span> | <span class="t">So suppose that it's a token number 56 78</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11090" target="_blank">03:04:50.180</a></span> | <span class="t">and 99 and 21 and 11 then we have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11095" target="_blank">03:04:55.040</a></span> | <span class="t">Slash and token. So it's suppose it's the token number two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11099" target="_blank">03:04:59.760</a></span> | <span class="t">What we the text mask here will be basically something that is like this so it will be zero zero zero zero zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11110" target="_blank">03:05:10.000</a></span> | <span class="t">And then it will be one one one one one one and then it will be zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11116" target="_blank">03:05:16.480</a></span> | <span class="t">uh, actually one because the slash n is still part of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11120" target="_blank">03:05:20.080</a></span> | <span class="t">text the image tokens mask will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11124" target="_blank">03:05:24.400</a></span> | <span class="t">one one one one one and then a series of zero because all the others are text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11130" target="_blank">03:05:30.800</a></span> | <span class="t">And the padding will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11134" target="_blank">03:05:34.400</a></span> | <span class="t">Equal to all zeros. So I don't write all of them, but you can understand all zero because we don't have any padding token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11143" target="_blank">03:05:43.280</a></span> | <span class="t">Then we are expanding them to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11145" target="_blank">03:05:45.280</a></span> | <span class="t">This expand basically repeats these zeros and ones along this dimension the embedding dimension that we are adding here with this unsqueeze</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11153" target="_blank">03:05:53.940</a></span> | <span class="t">And we will need it later for the for another method, which is the wear method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11159" target="_blank">03:05:59.040</a></span> | <span class="t">So for now, just keep in mind. We are just expanding this token by repeating this series of zero and one along a new dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11165" target="_blank">03:06:05.060</a></span> | <span class="t">So the first thing that we do is we copy the text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11169" target="_blank">03:06:09.660</a></span> | <span class="t">Embeddings into this final embeddings and we do this by using this method. So we say this final embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11176" target="_blank">03:06:16.000</a></span> | <span class="t">This wear method basically says that if this condition is true</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11180" target="_blank">03:06:20.620</a></span> | <span class="t">It will take the input from the second argument. Otherwise, it will copy the third argument</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11186" target="_blank">03:06:26.620</a></span> | <span class="t">So if wherever this condition is true, it will copy this stuff here wherever this condition is false. It will copy this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11193" target="_blank">03:06:33.980</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11196" target="_blank">03:06:36.300</a></span> | <span class="t">We are saying that whenever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11199" target="_blank">03:06:39.100</a></span> | <span class="t">Um</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11200" target="_blank">03:06:40.140</a></span> | <span class="t">The the text mask is one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11202" target="_blank">03:06:42.380</a></span> | <span class="t">We copy the embedding from the input embeds which correspond to the text inputs plus the placeholder for the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11209" target="_blank">03:06:49.740</a></span> | <span class="t">But we will only be copying the text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11211" target="_blank">03:06:51.740</a></span> | <span class="t">Text tokens because for the image image tokens, we will have zero in this mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11218" target="_blank">03:06:58.940</a></span> | <span class="t">Otherwise just keep the final embedding as it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11222" target="_blank">03:07:02.700</a></span> | <span class="t">Then we add the image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11226" target="_blank">03:07:06.860</a></span> | <span class="t">As you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11228" target="_blank">03:07:08.860</a></span> | <span class="t">Which is using another method called the must scatter and we cannot use the torch dot where because the sequence length of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11237" target="_blank">03:07:17.980</a></span> | <span class="t">Image scaled is not equal to the sequence length of the final embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11242" target="_blank">03:07:22.300</a></span> | <span class="t">But basically this does the same job as the where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11245" target="_blank">03:07:25.500</a></span> | <span class="t">So what we are saying is that copy from the scaled image features where this stuff is true</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11253" target="_blank">03:07:33.500</a></span> | <span class="t">So we are copying the image features where where the image mask is true where the image mask is true</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11258" target="_blank">03:07:38.620</a></span> | <span class="t">Where we have the placeholder tokens for the image so we are copying in the final embedding the image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11264" target="_blank">03:07:44.140</a></span> | <span class="t">Where before we had the placeholders?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11266" target="_blank">03:07:46.640</a></span> | <span class="t">Then we copy the padding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11270" target="_blank">03:07:50.620</a></span> | <span class="t">And the padding we just zero out everything because we don't care about what is in the paddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11275" target="_blank">03:07:55.840</a></span> | <span class="t">So what we are saying is that wherever the padding mask is true</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11279" target="_blank">03:07:59.100</a></span> | <span class="t">Just copy a zero a tensor made up of zero. Otherwise keep the final embedding as it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11283" target="_blank">03:08:03.980</a></span> | <span class="t">Now comes the interesting part so for now we have created the final embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11290" target="_blank">03:08:10.620</a></span> | <span class="t">What is the final embeddings is this stuff here. So let me show you again from the ipad. It's this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11296" target="_blank">03:08:16.620</a></span> | <span class="t">So now here we have the first image token embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11300" target="_blank">03:08:20.140</a></span> | <span class="t">second image token embedding third image token embedding blah blah up to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11305" target="_blank">03:08:25.960</a></span> | <span class="t">256 image token embeddings in the base version of polygama if I remember correctly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11310" target="_blank">03:08:30.360</a></span> | <span class="t">And then we have the embeddings of the tokens corresponding to the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11315" target="_blank">03:08:35.080</a></span> | <span class="t">Plus the padding but the padding we will never have because I excluded it from my implementation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11320" target="_blank">03:08:40.620</a></span> | <span class="t">So now we come to the interesting part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11324" target="_blank">03:08:44.440</a></span> | <span class="t">Which is the creation of the attention mask and the attention mask has to be created in a particular way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11330" target="_blank">03:08:50.280</a></span> | <span class="t">based on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11332" target="_blank">03:08:52.120</a></span> | <span class="t">How we are working with the KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11335" target="_blank">03:08:55.320</a></span> | <span class="t">And for that I need to introduce the KV cache. So that's why this part is interesting. So let's go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11339" target="_blank">03:08:59.880</a></span> | <span class="t">So let's talk about this thing called KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11342" target="_blank">03:09:02.920</a></span> | <span class="t">But before we talk about the KV cache, we need to understand what is the problem that the KV cache is solving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11348" target="_blank">03:09:08.280</a></span> | <span class="t">So when we train a language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11350" target="_blank">03:09:10.840</a></span> | <span class="t">So as I we saw before the transformer can be thought of as a model as it's a sequence to sequence model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11356" target="_blank">03:09:16.680</a></span> | <span class="t">Which means that you feed it a sequence of n tokens and you get as output n tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11362" target="_blank">03:09:22.440</a></span> | <span class="t">These n tokens as output are not normal tokens anymore</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11365" target="_blank">03:09:25.960</a></span> | <span class="t">They are contextualized tokens means that each of them is not capturing information only about itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11370" target="_blank">03:09:30.920</a></span> | <span class="t">But also about other tokens which depend on the mask that you use if you use the causal mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11375" target="_blank">03:09:35.880</a></span> | <span class="t">It means that only each token will only capture information about itself and all the previous tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11381" target="_blank">03:09:41.320</a></span> | <span class="t">If you are not using any causal mask, then each token will encapsulate information about all the other tokens in the sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11387" target="_blank">03:09:47.800</a></span> | <span class="t">Which is what we do with vision encoders like the image encoder we saw before the Sigleap one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11392" target="_blank">03:09:52.280</a></span> | <span class="t">Because the transformer is a sequence to sequence model, so let's open our ipad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11399" target="_blank">03:09:59.400</a></span> | <span class="t">Now because the transformer is a sequence to sequence model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11402" target="_blank">03:10:02.760</a></span> | <span class="t">It's very useful during training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11405" target="_blank">03:10:05.960</a></span> | <span class="t">So suppose that we want to train we train a language model on the following sentence. So it's always the same which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11412" target="_blank">03:10:12.440</a></span> | <span class="t">I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11413" target="_blank">03:10:13.800</a></span> | <span class="t">love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11415" target="_blank">03:10:15.240</a></span> | <span class="t">pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11417" target="_blank">03:10:17.400</a></span> | <span class="t">Pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11419" target="_blank">03:10:19.400</a></span> | <span class="t">Pardon my calligraphy I write very fast recently we feed it to this black box that we will call the transformer model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11430" target="_blank">03:10:30.040</a></span> | <span class="t">Each of these stuff here each of these uh tokens is actually an embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11437" target="_blank">03:10:37.880</a></span> | <span class="t">So we will get an as output a list of embeddings, but they will be contextualized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11444" target="_blank">03:10:44.260</a></span> | <span class="t">Contextualized one for the first token one for the second token. So this is the second embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11449" target="_blank">03:10:49.140</a></span> | <span class="t">This is the third embedding and this is the fourth embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11452" target="_blank">03:10:52.260</a></span> | <span class="t">I am again making the simplification that each word is a token and each token is a word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11456" target="_blank">03:10:56.500</a></span> | <span class="t">How we train a language model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11458" target="_blank">03:10:58.900</a></span> | <span class="t">Well, we force the language model to predict the next token given the contextualized embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11464" target="_blank">03:11:04.980</a></span> | <span class="t">So this contextualized embedding here contains information only about the word I in case we are using the causal mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11471" target="_blank">03:11:11.860</a></span> | <span class="t">so let's here is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11474" target="_blank">03:11:14.580</a></span> | <span class="t">This only contains information about the token I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11477" target="_blank">03:11:17.060</a></span> | <span class="t">This contains information about the token I but also the token love this contains information about the token. I love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11484" target="_blank">03:11:24.820</a></span> | <span class="t">Pepperoni pep and this contains information about all the other tokens. I love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11491" target="_blank">03:11:31.700</a></span> | <span class="t">pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11494" target="_blank">03:11:34.800</a></span> | <span class="t">Pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11496" target="_blank">03:11:36.820</a></span> | <span class="t">What labels do we use when training a language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11499" target="_blank">03:11:39.460</a></span> | <span class="t">Well, in this case, we want the first language model that given the prompt it should predict. What is the next token?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11505" target="_blank">03:11:45.460</a></span> | <span class="t">So given only I the the language model should predict the word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11509" target="_blank">03:11:49.780</a></span> | <span class="t">Love so the the the label here is love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11513" target="_blank">03:11:53.860</a></span> | <span class="t">Given only the token love. I love so the prompt. I love that the language model should predict the token pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11524" target="_blank">03:12:04.580</a></span> | <span class="t">Given the token the prompt I love pepperoni the language model should predict pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11529" target="_blank">03:12:09.720</a></span> | <span class="t">And given all the sentence it should say end of sentence so it means hey i'm done with the generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11537" target="_blank">03:12:17.080</a></span> | <span class="t">Now this is how we train a language model. How do we actually inference a language model is the same way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11544" target="_blank">03:12:24.740</a></span> | <span class="t">So we start with what is known as a prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11547" target="_blank">03:12:27.220</a></span> | <span class="t">so suppose that the user only gives us one token as a prompt the word I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11552" target="_blank">03:12:32.340</a></span> | <span class="t">And suppose that our language model has been trained on the sentence before so I love pepperoni pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11557" target="_blank">03:12:37.220</a></span> | <span class="t">How can we generate the entire sentence? Well, we feed this single token to our black box, which is our transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11564" target="_blank">03:12:44.420</a></span> | <span class="t">So now I will write it reversed because I don't have space above</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11568" target="_blank">03:12:48.100</a></span> | <span class="t">transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11570" target="_blank">03:12:50.980</a></span> | <span class="t">The transformer will generate it's a sequence to sequence model, which means that it takes as input one embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11576" target="_blank">03:12:56.960</a></span> | <span class="t">Corresponding to our prompt token I and it will generate one contextualized embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11582" target="_blank">03:13:02.420</a></span> | <span class="t">So it will be one embedding what do we do with the language models we project this single embedding into logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11590" target="_blank">03:13:10.740</a></span> | <span class="t">so we use the linear layer at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11593" target="_blank">03:13:13.360</a></span> | <span class="t">Output of the of the transformer, which is this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11598" target="_blank">03:13:18.640</a></span> | <span class="t">To generate logits for this token. So let's go back here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11606" target="_blank">03:13:26.160</a></span> | <span class="t">This this is the output embedding so out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11609" target="_blank">03:13:29.200</a></span> | <span class="t">put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11611" target="_blank">03:13:31.420</a></span> | <span class="t">embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11613" target="_blank">03:13:33.120</a></span> | <span class="t">We convert it through the linear layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11615" target="_blank">03:13:35.200</a></span> | <span class="t">into logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11618" target="_blank">03:13:38.400</a></span> | <span class="t">This logits tell us what is the score assigned by the language model to each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11625" target="_blank">03:13:45.200</a></span> | <span class="t">So how likely that particular token is the next one to convert it into a probability score?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11631" target="_blank">03:13:51.600</a></span> | <span class="t">So something that sums up to one we use the softmax. So suppose that we have already applied the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11637" target="_blank">03:13:57.700</a></span> | <span class="t">Actually, let's apply it softmax. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11641" target="_blank">03:14:01.680</a></span> | <span class="t">It will remain a single embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11644" target="_blank">03:14:04.880</a></span> | <span class="t">Sorry a single logits token, but the difference is that now they sum up all to one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11650" target="_blank">03:14:10.960</a></span> | <span class="t">Which one we select the one with the highest number usually this is called a greedy strategy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11656" target="_blank">03:14:16.240</a></span> | <span class="t">There is another strategy called the top p which means that we sample from the top the tokens with the top score</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11663" target="_blank">03:14:23.920</a></span> | <span class="t">Up to 90 percent. So suppose that there are three tokens here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11668" target="_blank">03:14:28.240</a></span> | <span class="t">Okay, actually the top we will see later when we implement the inference for now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11671" target="_blank">03:14:31.760</a></span> | <span class="t">Just think that we are always sampling the one with the highest probability score. So we use the greedy strategy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11676" target="_blank">03:14:36.800</a></span> | <span class="t">by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11678" target="_blank">03:14:38.960</a></span> | <span class="t">using the greedy strategy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11680" target="_blank">03:14:40.560</a></span> | <span class="t">What will happen is that probably the model if it has been trained well, it will tell us that the next token is very likely the token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11688" target="_blank">03:14:48.080</a></span> | <span class="t">Love so this is how we know. What is the next token?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11691" target="_blank">03:14:51.840</a></span> | <span class="t">How do we generate then the next next token? We take this token love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11696" target="_blank">03:14:56.400</a></span> | <span class="t">This token love and we put it back into the input of the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11702" target="_blank">03:15:02.320</a></span> | <span class="t">So now we feed a new input to the language model. Let's remove this stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11708" target="_blank">03:15:08.560</a></span> | <span class="t">Delete</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11710" target="_blank">03:15:10.560</a></span> | <span class="t">Now we are feeding two tokens to the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11713" target="_blank">03:15:13.280</a></span> | <span class="t">Language model is our transformer model. So it's a sequence to sequence model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11717" target="_blank">03:15:17.520</a></span> | <span class="t">It means that it takes as input two tokens. It will output two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11721" target="_blank">03:15:21.200</a></span> | <span class="t">So it's taking as input two embeddings. I am drawing here the text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11725" target="_blank">03:15:25.920</a></span> | <span class="t">But actually you need to consider that these are two embeddings of these two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11730" target="_blank">03:15:30.160</a></span> | <span class="t">So we feed two embeddings. It will output two embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11733" target="_blank">03:15:33.860</a></span> | <span class="t">one corresponding to the token I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11738" target="_blank">03:15:38.320</a></span> | <span class="t">One corresponding to the token I love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11740" target="_blank">03:15:40.640</a></span> | <span class="t">Very ugly writing. So let me write it better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11745" target="_blank">03:15:45.040</a></span> | <span class="t">one corresponds to the token I so the first position one corresponds to the second position which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11751" target="_blank">03:15:51.040</a></span> | <span class="t">Because this is a contextualized embedding. It will include information about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11755" target="_blank">03:15:55.280</a></span> | <span class="t">I and love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11758" target="_blank">03:15:58.000</a></span> | <span class="t">Now before what we did was to project this output embedding into logits here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11763" target="_blank">03:16:03.920</a></span> | <span class="t">We have two embeddings which one should we project into logits? Of course. It's the second one. Why?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11770" target="_blank">03:16:10.560</a></span> | <span class="t">because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11773" target="_blank">03:16:13.120</a></span> | <span class="t">This embedding includes information about the two tokens. So it's like we are using the entire prompt. So what we do is we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11780" target="_blank">03:16:20.000</a></span> | <span class="t">Send it to our linear layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11783" target="_blank">03:16:23.920</a></span> | <span class="t">Linear layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11787" target="_blank">03:16:27.520</a></span> | <span class="t">It will become logits. So let's write actually logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11791" target="_blank">03:16:31.300</a></span> | <span class="t">Then we apply this thing called softmax which will convert this logits into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11797" target="_blank">03:16:37.600</a></span> | <span class="t">probability scores</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11800" target="_blank">03:16:40.080</a></span> | <span class="t">How do we understand what is the next token?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11802" target="_blank">03:16:42.080</a></span> | <span class="t">Using I love as prompt. Well, we sample from the softmax which one the one with the highest score. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11808" target="_blank">03:16:48.240</a></span> | <span class="t">We take the one with the highest score as the next token so if the language model has been trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11814" target="_blank">03:16:54.960</a></span> | <span class="t">Well, it will be the token pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11817" target="_blank">03:16:57.680</a></span> | <span class="t">So it will be the token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11819" target="_blank">03:16:59.680</a></span> | <span class="t">Pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11823" target="_blank">03:17:03.680</a></span> | <span class="t">Now, what do we do? How do we generate the next next next token? We take this word pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11828" target="_blank">03:17:08.720</a></span> | <span class="t">We feed it back into the language model and we ask again the language model. Hey generate the next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11834" target="_blank">03:17:14.080</a></span> | <span class="t">Let's delete this stuff here I love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11839" target="_blank">03:17:19.520</a></span> | <span class="t">Pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11846" target="_blank">03:17:26.480</a></span> | <span class="t">We feed it to the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11848" target="_blank">03:17:28.160</a></span> | <span class="t">We are feeding three tokens to the language model which are converted into three embeddings then are fed to the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11853" target="_blank">03:17:33.600</a></span> | <span class="t">The transformer will output three output embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11856" target="_blank">03:17:36.660</a></span> | <span class="t">one corresponding to each position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11859" target="_blank">03:17:39.280</a></span> | <span class="t">Now without writing the first position will correspond to a contextualized embedding that only includes information about the token I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11868" target="_blank">03:17:48.560</a></span> | <span class="t">the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11870" target="_blank">03:17:50.560</a></span> | <span class="t">Embedding contextualized embedding will include information about I and the love the third contextualized embedding will include information about I love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11878" target="_blank">03:17:58.240</a></span> | <span class="t">Pepperoni, which one should we project?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11880" target="_blank">03:18:00.540</a></span> | <span class="t">Of course the third one because it's the one that encapsulates information about all the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11885" target="_blank">03:18:05.760</a></span> | <span class="t">So this way we keep doing this way and we generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11889" target="_blank">03:18:09.600</a></span> | <span class="t">text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11891" target="_blank">03:18:11.360</a></span> | <span class="t">Now, what is the problem here? The problem is that at every step of inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11895" target="_blank">03:18:15.280</a></span> | <span class="t">We are generating a lot of embeddings. Suppose that the prompt is very large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11900" target="_blank">03:18:20.320</a></span> | <span class="t">A lot of embeddings that we are not using so we are creating them because the transformer is a sequence to sequence model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11905" target="_blank">03:18:25.680</a></span> | <span class="t">It's generating them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11906" target="_blank">03:18:26.960</a></span> | <span class="t">But then we are only projecting one single embedding to the logits and then to the softmax to understand what is the next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11913" target="_blank">03:18:33.760</a></span> | <span class="t">And as you know, the transformer model uses this thing called attention mechanism and the attention mechanism generates this matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11920" target="_blank">03:18:40.800</a></span> | <span class="t">That is a sequence by sequence, which is the attention scores matrix that we saw before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11924" target="_blank">03:18:44.560</a></span> | <span class="t">which means that when you have a thousand tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11928" target="_blank">03:18:48.960</a></span> | <span class="t">It will generate a matrix that is a thousand by one thousand. So it's a one million numbers in that way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11934" target="_blank">03:18:54.240</a></span> | <span class="t">So it's a huge matrix and then you only need to use a part of this matrix that will generate this embedding here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11940" target="_blank">03:19:00.480</a></span> | <span class="t">So is there a way to not generate the embeddings that we are not going to project into logits?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11946" target="_blank">03:19:06.160</a></span> | <span class="t">But only generate the one that we only need to generate the next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11950" target="_blank">03:19:10.320</a></span> | <span class="t">Yes, and it's possible through what is known as the kb cache and the trick is here. So now let's open this other slide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11958" target="_blank">03:19:18.000</a></span> | <span class="t">The trick is this one. So when we calculate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11961" target="_blank">03:19:21.200</a></span> | <span class="t">attention matrix, so the query multiplied by the transpose of the keys divided by the square root of d</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11967" target="_blank">03:19:27.360</a></span> | <span class="t">Model or d head in case we have a multi multi head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11971" target="_blank">03:19:31.040</a></span> | <span class="t">What we are getting is suppose that we want to generate the word pizza by using the prompt I love pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11979" target="_blank">03:19:39.060</a></span> | <span class="t">If we do it naively we will pass all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11984" target="_blank">03:19:44.620</a></span> | <span class="t">Embeddings, so I love and pepperoni to the transformer. The transformer will convert them into query key and values using the projection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11991" target="_blank">03:19:51.340</a></span> | <span class="t">wq wk and wv</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11993" target="_blank">03:19:53.480</a></span> | <span class="t">Let me check if my yeah, it's still working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11995" target="_blank">03:19:55.820</a></span> | <span class="t">um</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=11998" target="_blank">03:19:58.700</a></span> | <span class="t">It will convert them into query key and values and now then we use the query key and values to calculate this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12004" target="_blank">03:20:04.940</a></span> | <span class="t">Matrix here. So the query multiplied by the transpose of the keys, which is this matrix here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12010" target="_blank">03:20:10.860</a></span> | <span class="t">Then we multiply this matrix by the v matrix with by the v sequence and it will give us the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12017" target="_blank">03:20:17.180</a></span> | <span class="t">of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12019" target="_blank">03:20:19.240</a></span> | <span class="t">Attention, which is contextualized embedding you can see here and we saw also before that when we multiply by v</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12024" target="_blank">03:20:24.460</a></span> | <span class="t">We are doing what is known as a weighted sum using these weights as weights in this weighted sum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12030" target="_blank">03:20:30.300</a></span> | <span class="t">now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12032" target="_blank">03:20:32.780</a></span> | <span class="t">When this is the input of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12034" target="_blank">03:20:34.620</a></span> | <span class="t">So the input of the model is I love pepperoni and the output that we are getting is a three contextualized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12039" target="_blank">03:20:39.440</a></span> | <span class="t">Embeddings so the embedding corresponding to only to the word I the embedding corresponding to the word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12045" target="_blank">03:20:45.020</a></span> | <span class="t">I love and the embedding corresponding to the I love pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12047" target="_blank">03:20:47.760</a></span> | <span class="t">We know that we only need this one here because this is the only one that we need to project into logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12053" target="_blank">03:20:53.980</a></span> | <span class="t">And then to generate the next token. So is there a way to not compute these two stuff here that we will not be using?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12060" target="_blank">03:21:00.940</a></span> | <span class="t">Yes, and the trick is here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12063" target="_blank">03:21:03.420</a></span> | <span class="t">The trick is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12065" target="_blank">03:21:05.420</a></span> | <span class="t">Embedding contextualized embedding here is the result of the multiplication of this matrix by this matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12072" target="_blank">03:21:12.700</a></span> | <span class="t">but not all of this matrix by the v sequence, but only the last row of this matrix by the v sequence because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12080" target="_blank">03:21:20.700</a></span> | <span class="t">This number here comes the the number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12084" target="_blank">03:21:24.300</a></span> | <span class="t">Let me okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12085" target="_blank">03:21:25.500</a></span> | <span class="t">Then this number here comes from the result of the dot product of this row here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12091" target="_blank">03:21:31.820</a></span> | <span class="t">With all the columns of this matrix here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12094" target="_blank">03:21:34.220</a></span> | <span class="t">So this number here comes from the dot product of the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12098" target="_blank">03:21:38.700</a></span> | <span class="t">The last row of this matrix with the first column of this matrix the second number in this matrix output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12104" target="_blank">03:21:44.540</a></span> | <span class="t">Vector comes from the dot product of the last row of this matrix with the second column of this matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12111" target="_blank">03:21:51.580</a></span> | <span class="t">the third number here comes from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12115" target="_blank">03:21:55.500</a></span> | <span class="t">Dot product of the last row of this matrix with the third column of this matrix, etc, etc for all the 128 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12122" target="_blank">03:22:02.720</a></span> | <span class="t">So what we need to generate only this one is the last row of this matrix, but all the v sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12129" target="_blank">03:22:09.420</a></span> | <span class="t">So basically to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12133" target="_blank">03:22:13.900</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12135" target="_blank">03:22:15.500</a></span> | <span class="t">Because the attention matrix as we saw before we can consider the rows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12140" target="_blank">03:22:20.460</a></span> | <span class="t">To be the queries and the columns to be the keys to have only this last row here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12146" target="_blank">03:22:26.540</a></span> | <span class="t">We need only the last token as query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12150" target="_blank">03:22:30.060</a></span> | <span class="t">But all the previous tokens including itself as keys and we need also all the tokens as values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12157" target="_blank">03:22:37.740</a></span> | <span class="t">That's why what we do is the following when we generate text with a language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12164" target="_blank">03:22:44.460</a></span> | <span class="t">What we do is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12166" target="_blank">03:22:46.940</a></span> | <span class="t">Imagine we have a prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12169" target="_blank">03:22:49.020</a></span> | <span class="t">Um</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12170" target="_blank">03:22:50.300</a></span> | <span class="t">Let me draw in such a way that it's not confusing. So I think we can continue here. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12175" target="_blank">03:22:55.900</a></span> | <span class="t">Imagine we start again the process of generation of text, but this time we do it with the kv cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12182" target="_blank">03:23:02.380</a></span> | <span class="t">So we start with one token. Let me do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12185" target="_blank">03:23:05.420</a></span> | <span class="t">Top to bottom. Otherwise, it gets confusing because before I did top to bottom. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12190" target="_blank">03:23:10.140</a></span> | <span class="t">Okay, we use only the token i as input to the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12194" target="_blank">03:23:14.620</a></span> | <span class="t">The language model will convert it into an embedding blah blah blah, then we feed it to the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12199" target="_blank">03:23:19.120</a></span> | <span class="t">Suppose that it's only made up of one layer. Actually, it's a series of layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12203" target="_blank">03:23:23.260</a></span> | <span class="t">uh this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12206" target="_blank">03:23:26.140</a></span> | <span class="t">Single token will be converted into query key and values. So it will be a sequence of tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12212" target="_blank">03:23:32.540</a></span> | <span class="t">But in this case, we only have one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12214" target="_blank">03:23:34.620</a></span> | <span class="t">So the q sequence will be one token. The k sequence will be one token. The v sequence will be one token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12220" target="_blank">03:23:40.380</a></span> | <span class="t">We do this thing called self attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12224" target="_blank">03:23:44.240</a></span> | <span class="t">uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12226" target="_blank">03:23:46.240</a></span> | <span class="t">Which will calculate that matrix so the query multiplied by transpose of the keys which will be a matrix that is one by one because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12232" target="_blank">03:23:52.080</a></span> | <span class="t">We only have one token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12234" target="_blank">03:23:54.080</a></span> | <span class="t">And then we multiply it by v so it will result in only one contextualized embedding as output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12239" target="_blank">03:23:59.920</a></span> | <span class="t">So it's this stuff here what we do we project it into logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12243" target="_blank">03:24:03.700</a></span> | <span class="t">Which is another vector then we convert it into softmax which is another vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12251" target="_blank">03:24:11.920</a></span> | <span class="t">uh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12253" target="_blank">03:24:13.920</a></span> | <span class="t">And then we sample the next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12260" target="_blank">03:24:20.720</a></span> | <span class="t">The difference with the kv cache is that whenever we pass a token to the input of this self attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12268" target="_blank">03:24:28.580</a></span> | <span class="t">We cache the key sequence and the v sequence into a buffer called the kv cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12275" target="_blank">03:24:35.280</a></span> | <span class="t">so now imagine that there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12277" target="_blank">03:24:37.600</a></span> | <span class="t">There is a box here called the kv cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12280" target="_blank">03:24:40.240</a></span> | <span class="t">That initially is empty. But after we pass the token I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12283" target="_blank">03:24:43.760</a></span> | <span class="t">It will contain the embedding. So the q embedding. Sorry the k embedding corresponding to the token I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12290" target="_blank">03:24:50.960</a></span> | <span class="t">And also this is the kv cache. So it is made up of the key cache and the v cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12296" target="_blank">03:24:56.240</a></span> | <span class="t">This is the key cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12299" target="_blank">03:24:59.040</a></span> | <span class="t">Then we have the v cache which is initially empty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12301" target="_blank">03:25:01.440</a></span> | <span class="t">But after we send in the first token, we save this v sequence. It only contains one token. So we save it here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12308" target="_blank">03:25:08.320</a></span> | <span class="t">So it's the token I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12310" target="_blank">03:25:10.320</a></span> | <span class="t">We compute the self attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12314" target="_blank">03:25:14.080</a></span> | <span class="t">Using the query key and values. It will result in only one output embedding. We project it into logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12321" target="_blank">03:25:21.120</a></span> | <span class="t">We project it into softmax. We sample. What is the next token? Very probably it will be the token love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12326" target="_blank">03:25:26.640</a></span> | <span class="t">What do we do now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12330" target="_blank">03:25:30.560</a></span> | <span class="t">What we did before was that we took this word love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12333" target="_blank">03:25:33.920</a></span> | <span class="t">Put it back inside of the prompt and then ask the language model again. What is the next token?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12338" target="_blank">03:25:38.480</a></span> | <span class="t">But with the kv cache we do something different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12340" target="_blank">03:25:40.640</a></span> | <span class="t">With the kv cache. We always take the previously generated token. So in this case is the token love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12347" target="_blank">03:25:47.200</a></span> | <span class="t">We use it as input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12350" target="_blank">03:25:50.400</a></span> | <span class="t">Only the single token love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12354" target="_blank">03:25:54.880</a></span> | <span class="t">Let me delete a little bit here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12359" target="_blank">03:25:59.440</a></span> | <span class="t">And we use this single token as input to the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12363" target="_blank">03:26:03.520</a></span> | <span class="t">Now what happens is that we feed the transform this single token love into its embedding which is an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12370" target="_blank">03:26:10.720</a></span> | <span class="t">Uncontextualized embedding we feed it to the first layer of the transformer as a query key and values for now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12376" target="_blank">03:26:16.720</a></span> | <span class="t">The query key and value contains only one token the token correspond the embedding corresponding to the token love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12382" target="_blank">03:26:22.960</a></span> | <span class="t">however</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12385" target="_blank">03:26:25.200</a></span> | <span class="t">when doing self attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12387" target="_blank">03:26:27.280</a></span> | <span class="t">We don't use only one single token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12389" target="_blank">03:26:29.600</a></span> | <span class="t">for love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12391" target="_blank">03:26:31.760</a></span> | <span class="t">For the key for the keys and values we take this single token love we append it to this buffer called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12399" target="_blank">03:26:39.200</a></span> | <span class="t">Kv cache. So now it contains love here for the values. Also it contains love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12405" target="_blank">03:26:45.120</a></span> | <span class="t">And then we use this buffer as the key and value sequence in the self attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12410" target="_blank">03:26:50.640</a></span> | <span class="t">So we take this token love we convert it into query key and value the query key and values are one single token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12417" target="_blank">03:26:57.600</a></span> | <span class="t">But the query the key and value we append them each of them into their respective buffer here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12423" target="_blank">03:27:03.520</a></span> | <span class="t">And then we use the content of this buffer to calculate the self attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12428" target="_blank">03:27:08.400</a></span> | <span class="t">What happens is that we have only one query, but now we have two keys and two values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12433" target="_blank">03:27:13.440</a></span> | <span class="t">Which will result in exactly the calculation of this last row of this matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12441" target="_blank">03:27:21.360</a></span> | <span class="t">That the last row that we are interested in to predict only the next token and not generate all the other contextualized embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12448" target="_blank">03:27:28.800</a></span> | <span class="t">In this case, we are only seeing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12451" target="_blank">03:27:31.520</a></span> | <span class="t">Two tokens, but later we will see with the third token. It will be exactly the last row of that matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12456" target="_blank">03:27:36.560</a></span> | <span class="t">anyway</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12459" target="_blank">03:27:39.360</a></span> | <span class="t">The output of this self attention because we have one query two keys and two values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12463" target="_blank">03:27:43.680</a></span> | <span class="t">I can guarantee mathematically it will be one single embedding you can verify by yourself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12468" target="_blank">03:27:48.800</a></span> | <span class="t">But basically if you have one query as you saw before the self attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12472" target="_blank">03:27:52.820</a></span> | <span class="t">Will generate a matrix that is a sequence by sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12475" target="_blank">03:27:55.760</a></span> | <span class="t">But in this case, it's the the roles of this matrix are defined by how many queries you have. So we have only one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12481" target="_blank">03:28:01.360</a></span> | <span class="t">And we have however two keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12484" target="_blank">03:28:04.240</a></span> | <span class="t">So the key number one and the key number two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12486" target="_blank">03:28:06.400</a></span> | <span class="t">So it will be a matrix that is one by two and it will result in only one output embedding token when you multiply it by b</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12496" target="_blank">03:28:16.240</a></span> | <span class="t">And we saw that before actually when we calculated the dimensions of the output embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12500" target="_blank">03:28:20.800</a></span> | <span class="t">We saw that it's only the last row that generates the last embeddings and this is exactly what we are doing here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12506" target="_blank">03:28:26.320</a></span> | <span class="t">Anyway, this the self attention calculated like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12510" target="_blank">03:28:30.240</a></span> | <span class="t">So using the query the single token, but as keys and value the content of the buffers the keys and the kv cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12516" target="_blank">03:28:36.960</a></span> | <span class="t">To calculate the self attention we result in only one output embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12521" target="_blank">03:28:41.200</a></span> | <span class="t">Which is exactly the contextualized embedding that we are interested in to generate the next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12526" target="_blank">03:28:46.160</a></span> | <span class="t">We project it into logics. We'll project it to the softwares and it will result in the next token being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12530" target="_blank">03:28:50.560</a></span> | <span class="t">pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12533" target="_blank">03:28:53.500</a></span> | <span class="t">Naively what we did before was take this for the pepperoni and feed it back into the prompt and then feed all the prompt to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12540" target="_blank">03:29:00.240</a></span> | <span class="t">The language model but with the kv cache it's different. So we use the last generated token pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12548" target="_blank">03:29:08.960</a></span> | <span class="t">Let me write it all pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12550" target="_blank">03:29:10.960</a></span> | <span class="t">We feed it to we convert it into a single embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12555" target="_blank">03:29:15.140</a></span> | <span class="t">So the query key and value here are one single token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12560" target="_blank">03:29:20.080</a></span> | <span class="t">But before computing the self attention, we put this key and value inside each of their buffers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12567" target="_blank">03:29:27.520</a></span> | <span class="t">So now the buffer for the k contains pepperoni as well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12571" target="_blank">03:29:31.280</a></span> | <span class="t">And also the v contains pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12576" target="_blank">03:29:36.080</a></span> | <span class="t">Then to calculate the self attention we don't use this key and v we use the content of the kv cache because it contains three tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12583" target="_blank">03:29:43.360</a></span> | <span class="t">So as query we use only one token, which is the word pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12586" target="_blank">03:29:46.660</a></span> | <span class="t">But as key and v we use the content of the kv cache. So it will result in a matrix that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12591" target="_blank">03:29:51.360</a></span> | <span class="t">Exactly the last row that we saw here because it's exactly this one now because we have as a query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12598" target="_blank">03:29:58.480</a></span> | <span class="t">Only the word pepperoni and as key is the token. I love pepperoni</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12603" target="_blank">03:30:03.440</a></span> | <span class="t">Which will result when multiplied with the v sequence, which is three tokens because we have also the v cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12608" target="_blank">03:30:08.640</a></span> | <span class="t">Will result exactly in the computation of this output embedding here, which is only one single embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12615" target="_blank">03:30:15.780</a></span> | <span class="t">Which is exactly the one that we need to predict the next token, which will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12620" target="_blank">03:30:20.480</a></span> | <span class="t">the token pizza, I guess</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12623" target="_blank">03:30:23.120</a></span> | <span class="t">Etc etc. So this is the kv cache this kv cache basically allow us to during inferences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12630" target="_blank">03:30:30.640</a></span> | <span class="t">So during token generation to avoid generating all the embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12634" target="_blank">03:30:34.580</a></span> | <span class="t">Of all the input sequence, but only generate the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12638" target="_blank">03:30:38.400</a></span> | <span class="t">Embedding contextualized embedding which is exactly the one that we need to we need to predict the next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12644" target="_blank">03:30:44.960</a></span> | <span class="t">There is another thing that we used to know about kv cache, which is the pre-filling the pre-filling is basically we started here with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12653" target="_blank">03:30:53.280</a></span> | <span class="t">With a single token as a prompt of the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12656" target="_blank">03:30:56.720</a></span> | <span class="t">So we only use the word I but usually the prompt is a little longer. So it's not only one token from the user the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12663" target="_blank">03:31:03.840</a></span> | <span class="t">maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12664" target="_blank">03:31:04.960</a></span> | <span class="t">Suppose that the user uses multiple tokens, so it uses the word I love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12669" target="_blank">03:31:09.280</a></span> | <span class="t">What we do is because we have already access to all the tokens of the prompt of the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12677" target="_blank">03:31:17.040</a></span> | <span class="t">We are not generating them. We can pre-fill instantly using all of the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12681" target="_blank">03:31:21.440</a></span> | <span class="t">of the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12683" target="_blank">03:31:23.520</a></span> | <span class="t">All the kv cache corresponding to the prompt of the user so we can do instead of doing first adding I and then adding love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12690" target="_blank">03:31:30.320</a></span> | <span class="t">We add both of them in the same forward pass. How to do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12694" target="_blank">03:31:34.480</a></span> | <span class="t">We take we use both of them. We convert them into embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12698" target="_blank">03:31:38.080</a></span> | <span class="t">So it will result in two embeddings. We feed it to the language model as query key and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12702" target="_blank">03:31:42.320</a></span> | <span class="t">Initially, the kv cache is empty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12704" target="_blank">03:31:44.720</a></span> | <span class="t">This will result in a cool sequence of two tokens the k sequence of two tokens and the v sequence of two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12712" target="_blank">03:31:52.960</a></span> | <span class="t">We put the k and the v inside of their respective buffer called the k buffer and the v buffer which comprise the kv cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12719" target="_blank">03:31:59.920</a></span> | <span class="t">So now it contains I and love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12723" target="_blank">03:32:03.120</a></span> | <span class="t">this contains I and love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12726" target="_blank">03:32:06.240</a></span> | <span class="t">then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12729" target="_blank">03:32:09.360</a></span> | <span class="t">Calculated the self-attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12730" target="_blank">03:32:10.560</a></span> | <span class="t">So now we have two tokens for the query two for the keys two for the values because the content of the kv cache contains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12736" target="_blank">03:32:16.000</a></span> | <span class="t">two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12737" target="_blank">03:32:17.440</a></span> | <span class="t">Which will result in a two by two matrix, so it will result in two output embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12743" target="_blank">03:32:23.460</a></span> | <span class="t">And two output softmax which one we project in the um in the logits only the last one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12752" target="_blank">03:32:32.640</a></span> | <span class="t">Because we are we are not interested in predicting the word love. We are only interested in knowing what comes after love. So we only take the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12760" target="_blank">03:32:40.800</a></span> | <span class="t">Embedding corresponding to the position of the word love we project it into logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12767" target="_blank">03:32:47.460</a></span> | <span class="t">And we project it into softmax to understand what is the next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12770" target="_blank">03:32:50.740</a></span> | <span class="t">So only during this pre-filling phase we actually allow the generation of multiple output embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12777" target="_blank">03:32:57.960</a></span> | <span class="t">And then we discard the one that we don't need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12780" target="_blank">03:33:00.900</a></span> | <span class="t">Why do we do it because we don't want to add one single token at a time because it will be too slow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12786" target="_blank">03:33:06.180</a></span> | <span class="t">If you have a lot of tokens, you just add them all at once in the kv cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12790" target="_blank">03:33:10.260</a></span> | <span class="t">And then you use this kv cache which is pre-filled now to generate one token at a time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12796" target="_blank">03:33:16.420</a></span> | <span class="t">The reason we do it is because the gpu is very fast at parallelizing stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12800" target="_blank">03:33:20.740</a></span> | <span class="t">So it's very good at parallelizing computations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12802" target="_blank">03:33:22.900</a></span> | <span class="t">So actually by doing all of these computations inside of the gpu</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12806" target="_blank">03:33:26.740</a></span> | <span class="t">Will result in a much less wall clock time instead of adding one token at a time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12810" target="_blank">03:33:30.820</a></span> | <span class="t">And this is guys the kv cache. So now we can finally code it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12814" target="_blank">03:33:34.340</a></span> | <span class="t">Okay, let's code the next part. So we copy this part here and all of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12821" target="_blank">03:33:41.380</a></span> | <span class="t">And all of this actually let's copy it all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12826" target="_blank">03:33:46.180</a></span> | <span class="t">So now that we know what is the kv cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12828" target="_blank">03:33:48.100</a></span> | <span class="t">We know that we have two parts to do when we work with the kv cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12831" target="_blank">03:33:51.700</a></span> | <span class="t">The one part is called pre-filling and one is token generation during the pre-filling. We send all the prompt of the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12837" target="_blank">03:33:57.220</a></span> | <span class="t">to the kv cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12840" target="_blank">03:34:00.340</a></span> | <span class="t">To the model using as a query key and value and this will create the initial cache that will then be used by subsequent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12847" target="_blank">03:34:07.320</a></span> | <span class="t">During token generation. So where we generate one token at a time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12851" target="_blank">03:34:11.300</a></span> | <span class="t">Why do we do this two phase because we want the the prompt is already available to us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12855" target="_blank">03:34:15.540</a></span> | <span class="t">We don't want to edit one token at a time while the token generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12859" target="_blank">03:34:19.300</a></span> | <span class="t">We want to generate one token at a time because we don't have these tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12862" target="_blank">03:34:22.100</a></span> | <span class="t">so to create the attention mask for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12865" target="_blank">03:34:25.140</a></span> | <span class="t">for working with the kv cache basically, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12868" target="_blank">03:34:28.500</a></span> | <span class="t">when we are working with the pre-filling phase, we will have that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12872" target="_blank">03:34:32.980</a></span> | <span class="t">Number of queries key and value will be the number of the tokens inside of the prompt. So we generate a mask that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12880" target="_blank">03:34:40.180</a></span> | <span class="t">sequence by sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12882" target="_blank">03:34:42.180</a></span> | <span class="t">Because it will be used in the attention mask. So let's visualize it actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12886" target="_blank">03:34:46.260</a></span> | <span class="t">so suppose that we are doing the following so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12890" target="_blank">03:34:50.900</a></span> | <span class="t">This suppose that we receive a prompt that is I love pepperoni and we want to generate the next token, which is pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12898" target="_blank">03:34:58.180</a></span> | <span class="t">The attention calculation will result in the following attention score</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12902" target="_blank">03:35:02.660</a></span> | <span class="t">So it's a matrix that is three by three in which we want to mask out some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12907" target="_blank">03:35:07.840</a></span> | <span class="t">interactions between tokens especially for each query cannot attend to future keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12912" target="_blank">03:35:12.400</a></span> | <span class="t">And the way we do that is we create an attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12916" target="_blank">03:35:16.560</a></span> | <span class="t">Of the same size of the attention matrix as you can see so three by three. So sequence by sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12921" target="_blank">03:35:21.680</a></span> | <span class="t">in which we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12924" target="_blank">03:35:24.400</a></span> | <span class="t">Before we apply the softmax. We add this thing called mask to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12928" target="_blank">03:35:28.560</a></span> | <span class="t">matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12931" target="_blank">03:35:31.280</a></span> | <span class="t">And this mask is made up of minus infinities for all the position in which we don't want any interaction to happen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12938" target="_blank">03:35:38.160</a></span> | <span class="t">And this is what we are doing here. So at the beginning we create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12941" target="_blank">03:35:41.920</a></span> | <span class="t">We are inserting the prompt of the user and we should mask out future tokens, however</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12949" target="_blank">03:35:49.600</a></span> | <span class="t">in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12951" target="_blank">03:35:51.680</a></span> | <span class="t">And we create a mask that is a token sequence by sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12954" target="_blank">03:35:54.960</a></span> | <span class="t">So this is during the pre-filling so when the KB cache is not or the KB cache does not contain any item means that we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12961" target="_blank">03:36:01.040</a></span> | <span class="t">Doing it for the first time. So we are pre-filling the prompt of the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12964" target="_blank">03:36:04.160</a></span> | <span class="t">Now we are not adding any minus infinity value to this KB is to this attention mask during the pre-filling. Why?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12972" target="_blank">03:36:12.560</a></span> | <span class="t">For to understand that we need to understand how polygamma attends to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12977" target="_blank">03:36:17.120</a></span> | <span class="t">Image tokens and to the prompt of the user. So for that, let's open the page of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12984" target="_blank">03:36:24.540</a></span> | <span class="t">polygamma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12986" target="_blank">03:36:26.540</a></span> | <span class="t">And here we can see the attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12988" target="_blank">03:36:28.540</a></span> | <span class="t">So a prompt in polygamma is made up of the image tokens, which are 256 in the case of the smallest polygamma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=12997" target="_blank">03:36:37.760</a></span> | <span class="t">Then we have the prompt of the user which is a beginning of sentence token plus the prompt of the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13003" target="_blank">03:36:43.180</a></span> | <span class="t">So for example, the prompt of the user may say extract where the photographer is in this picture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13008" target="_blank">03:36:48.060</a></span> | <span class="t">And then we have a separator token, which is the new line token we saw before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13013" target="_blank">03:36:53.420</a></span> | <span class="t">As you can see the attention mask here is not masking out anything for the part that corresponds to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13020" target="_blank">03:37:00.300</a></span> | <span class="t">Prompt because the prompt of the user is made up of the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13024" target="_blank">03:37:04.220</a></span> | <span class="t">So the textual prompt plus the image and we don't mask out anything. Why? Because and it's quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13031" target="_blank">03:37:11.420</a></span> | <span class="t">and it's different than what we usually do with language models because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13035" target="_blank">03:37:15.500</a></span> | <span class="t">for the image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13037" target="_blank">03:37:17.900</a></span> | <span class="t">We can understand that we don't mask out anything because each text token that we will generate needs to access all the image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13045" target="_blank">03:37:25.020</a></span> | <span class="t">So it will be conditioned on all the image tokens. That's why it's called conditional generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13049" target="_blank">03:37:29.120</a></span> | <span class="t">And that's fine because we saw that each image is each image feature each image embedding is encoding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13056" target="_blank">03:37:36.080</a></span> | <span class="t">Not only itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13057" target="_blank">03:37:37.740</a></span> | <span class="t">But also all the other embeddings and we want each text token to watch all the image to be predicted and that's fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13063" target="_blank">03:37:43.500</a></span> | <span class="t">the point is why in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13066" target="_blank">03:37:46.540</a></span> | <span class="t">The prompt is not causal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13069" target="_blank">03:37:49.740</a></span> | <span class="t">So as you can see the first token of the prompt, which is this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13073" target="_blank">03:37:53.500</a></span> | <span class="t">so suppose that the prompt is two tokens, for example, I love and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13076" target="_blank">03:37:56.940</a></span> | <span class="t">We want to generate the word pepperoni and pizza, which should be the first output token and the second output token you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13085" target="_blank">03:38:05.180</a></span> | <span class="t">Why are we not applying any causal mask to the tokens of the textual prompt?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13094" target="_blank">03:38:14.780</a></span> | <span class="t">Because the textual prompt is usually very short</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13097" target="_blank">03:38:17.420</a></span> | <span class="t">And we want and it usually describes what is the task that we want the vision language model to perform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13103" target="_blank">03:38:23.660</a></span> | <span class="t">and it's a choice that the palygamma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13106" target="_blank">03:38:26.720</a></span> | <span class="t">authors made which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13109" target="_blank">03:38:29.420</a></span> | <span class="t">because usually this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13111" target="_blank">03:38:31.180</a></span> | <span class="t">This prompt represents the task that we want the language model to perform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13114" target="_blank">03:38:34.380</a></span> | <span class="t">We want all the tokens that will be generated to watch all of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13118" target="_blank">03:38:38.940</a></span> | <span class="t">tokens in the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13121" target="_blank">03:38:41.480</a></span> | <span class="t">Moreover, we want each token in the prompt to watch even future tokens of the prompt itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13127" target="_blank">03:38:47.400</a></span> | <span class="t">So you can think of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13130" target="_blank">03:38:50.600</a></span> | <span class="t">As the query this one as the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13135" target="_blank">03:38:55.160</a></span> | <span class="t">When we will do prefilling what we will have is the following so we will have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13140" target="_blank">03:39:00.360</a></span> | <span class="t">The prompts let's use a different color. So we will have all the tokens of the prompt which are the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13146" target="_blank">03:39:06.440</a></span> | <span class="t">Textual prompt which is the textual prompt that we will send to the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13151" target="_blank">03:39:11.080</a></span> | <span class="t">plus the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13152" target="_blank">03:39:12.760</a></span> | <span class="t">tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13154" target="_blank">03:39:14.280</a></span> | <span class="t">And we do not need to generate any mask here because each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13158" target="_blank">03:39:18.840</a></span> | <span class="t">Text prompt can watch even future tokens of the text prompt because you can see that this is the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13166" target="_blank">03:39:26.200</a></span> | <span class="t">This is the query number one of the text prompt and this is the key number one of the text prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13172" target="_blank">03:39:32.360</a></span> | <span class="t">This is the key number two of the text prompt and as you can see the query number one of the text prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13176" target="_blank">03:39:36.760</a></span> | <span class="t">So this beginning of send the token can attend to the key number two of the text token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13181" target="_blank">03:39:41.880</a></span> | <span class="t">It's a choice that the palygamum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13185" target="_blank">03:39:45.000</a></span> | <span class="t">Authors made so they they said okay, usually the prefix of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13190" target="_blank">03:39:50.040</a></span> | <span class="t">Because we are not generating this prefix, which is the prompt that we send to the model telling what the model needs to do with the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13197" target="_blank">03:39:57.960</a></span> | <span class="t">We do not need to add any causality because we do not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13202" target="_blank">03:40:02.840</a></span> | <span class="t">Need the model to be causal with respect to this prefix because we are not going to generate it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13207" target="_blank">03:40:07.960</a></span> | <span class="t">however, the only thing that we are going to generate is this thing called suffix which are the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13213" target="_blank">03:40:13.560</a></span> | <span class="t">Output tokens predicted by the model using the prompt textual prompt and the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13218" target="_blank">03:40:18.600</a></span> | <span class="t">And this needs to be causal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13220" target="_blank">03:40:20.920</a></span> | <span class="t">So the first token output by the model needs to attend all the previous keys, which are the image token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13227" target="_blank">03:40:27.480</a></span> | <span class="t">So these three image tokens plus the four tokens of the text prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13232" target="_blank">03:40:32.760</a></span> | <span class="t">Then the next token predicted by the model should be able to access again all the image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13239" target="_blank">03:40:39.000</a></span> | <span class="t">So the first three tokens then the four tokens of the textual prompt plus the last generated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13245" target="_blank">03:40:45.080</a></span> | <span class="t">token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13246" target="_blank">03:40:46.760</a></span> | <span class="t">By the model then when we generated the next next token, it will need to access</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13251" target="_blank">03:40:51.320</a></span> | <span class="t">the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13253" target="_blank">03:40:53.560</a></span> | <span class="t">First three image tokens then the next four text tokens of the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13258" target="_blank">03:40:58.280</a></span> | <span class="t">And the two tokens predicted by the model before so it is causal only in the generated text not in the prefix part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13267" target="_blank">03:41:07.240</a></span> | <span class="t">Which is different than normal language models in normal language models when we prefill even the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13273" target="_blank">03:41:13.080</a></span> | <span class="t">When we prefill the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13278" target="_blank">03:41:18.120</a></span> | <span class="t">the prompt the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13280" target="_blank">03:41:20.840</a></span> | <span class="t">Itself is prefilled using the causal mask because the the prompt is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13285" target="_blank">03:41:25.160</a></span> | <span class="t">A part of what the model would generate if it would start with only the first token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13290" target="_blank">03:41:30.440</a></span> | <span class="t">But this is not the case in PaliGamma. It's a choice that the PaliGamma team made</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13295" target="_blank">03:41:35.240</a></span> | <span class="t">So it's not like the language model has to work in this way or there is any advantage or disadvantage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13300" target="_blank">03:41:40.700</a></span> | <span class="t">The only advantage if we want to say is that the information about the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13305" target="_blank">03:41:45.880</a></span> | <span class="t">Is replicated in each of these tokens because each of these tokens basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13310" target="_blank">03:41:50.440</a></span> | <span class="t">Includes information also about future tokens that are part of the prompt and this happened when they train the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13316" target="_blank">03:41:56.120</a></span> | <span class="t">so when you train the model also you don't mask out the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13319" target="_blank">03:41:59.320</a></span> | <span class="t">The future tokens inside of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13323" target="_blank">03:42:03.320</a></span> | <span class="t">Textual prompt you only mask out what you expect the model to generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13329" target="_blank">03:42:09.340</a></span> | <span class="t">Using the image token and the textual prompt. So to rehearse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13335" target="_blank">03:42:15.160</a></span> | <span class="t">Let's go back to this image. What is the text prompt? So when we inference a language model we provide a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13340" target="_blank">03:42:20.920</a></span> | <span class="t">Visual text visual language model. We provide an image as condition and then we provide some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13347" target="_blank">03:42:27.080</a></span> | <span class="t">Text prompt which is a description of what we want the language model to do with this image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13352" target="_blank">03:42:32.280</a></span> | <span class="t">For example tell us where is the photographer in this picture?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13354" target="_blank">03:42:34.920</a></span> | <span class="t">And then the model will generate some tokens as outputs telling us where the photographer in this case is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13361" target="_blank">03:42:41.880</a></span> | <span class="t">and what we do when we train this language model is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13365" target="_blank">03:42:45.080</a></span> | <span class="t">Let's go back here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13367" target="_blank">03:42:47.800</a></span> | <span class="t">We do not mask the tokens of the textual prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13371" target="_blank">03:42:51.560</a></span> | <span class="t">So when we ask the language model what to do with this image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13374" target="_blank">03:42:54.360</a></span> | <span class="t">We do not mask out during training and also during inference, of course because the model needs to work in the same way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13379" target="_blank">03:42:59.560</a></span> | <span class="t">But we mask out only what we expect the model to generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13383" target="_blank">03:43:03.800</a></span> | <span class="t">So the causality is only in the generated tokens and it's a choice that you make with the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13389" target="_blank">03:43:09.000</a></span> | <span class="t">It's not necessarily it has to work with this way because normal language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13393" target="_blank">03:43:13.640</a></span> | <span class="t">They actually mask out all the tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13395" target="_blank">03:43:15.720</a></span> | <span class="t">There is no like not masking out of the prompt because usually the prompt itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13400" target="_blank">03:43:20.120</a></span> | <span class="t">You can consider it as something generated by the model, even if it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13403" target="_blank">03:43:23.480</a></span> | <span class="t">So this is a more of a philosophical question that's a technical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13408" target="_blank">03:43:28.200</a></span> | <span class="t">But the reason is that it's a choice made by the polygamous authors also in visual language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13412" target="_blank">03:43:32.920</a></span> | <span class="t">Especially like polygamous the task so the prompt the textual prompt is usually very short</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13417" target="_blank">03:43:37.800</a></span> | <span class="t">It tells the model what to do with the image that it's being fed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13420" target="_blank">03:43:40.760</a></span> | <span class="t">so for example localize where is the cat in this image or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13423" target="_blank">03:43:43.480</a></span> | <span class="t">Extract all the numbers or tell me where is the photographer in this image, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13430" target="_blank">03:43:50.200</a></span> | <span class="t">And also the usually the generated output of the model is very short</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13433" target="_blank">03:43:53.960</a></span> | <span class="t">So we don't use at least polygamous models like polygamous are not used for generating very long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13439" target="_blank">03:43:59.320</a></span> | <span class="t">Content but they can be of course fine-tuned to do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13444" target="_blank">03:44:04.520</a></span> | <span class="t">So, let me delete this part. Otherwise it remains here forever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13448" target="_blank">03:44:08.280</a></span> | <span class="t">Okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13451" target="_blank">03:44:11.320</a></span> | <span class="t">All right, so now we have seen how we generate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13454" target="_blank">03:44:14.200</a></span> | <span class="t">The the mask for the pre-filling so in the past for the pre-filling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13458" target="_blank">03:44:18.360</a></span> | <span class="t">We do not mask out anything because we do not mask out the text prompt and we do not mask out the image prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13464" target="_blank">03:44:24.520</a></span> | <span class="t">The interesting part is that when we generate the text we have we generate one token at a time with the KB cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13472" target="_blank">03:44:32.280</a></span> | <span class="t">Which is this this else part here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13475" target="_blank">03:44:35.160</a></span> | <span class="t">We also do not mask out anything. Why?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13478" target="_blank">03:44:38.440</a></span> | <span class="t">Because let's go back to the polygama here picture. So here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13483" target="_blank">03:44:43.640</a></span> | <span class="t">When you generate the first token, the first token needs to access all the image tokens and the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13490" target="_blank">03:44:50.360</a></span> | <span class="t">So does not we don't need to mask out anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13492" target="_blank">03:44:52.840</a></span> | <span class="t">When we generate the next token as you can see it needs to access all the image tokens and all the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13499" target="_blank">03:44:59.320</a></span> | <span class="t">Plus the last generated token here. So we do not need to mask out anything then again for the next next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13505" target="_blank">03:45:05.320</a></span> | <span class="t">We need to access all the previous tokens plus the two previously generated tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13509" target="_blank">03:45:09.960</a></span> | <span class="t">So we do not need to mask out anything because we are generating one token at a time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13513" target="_blank">03:45:13.800</a></span> | <span class="t">So it needs to access all the previous tokens plus the image tokens plus the textual prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13518" target="_blank">03:45:18.920</a></span> | <span class="t">So we never need to mask out anything. So you may be wondering why are we never masking out anything?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13525" target="_blank">03:45:25.000</a></span> | <span class="t">Because we are working with the KB cache and with the KB cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13527" target="_blank">03:45:27.480</a></span> | <span class="t">We only generate one single row of this matrix at a time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13532" target="_blank">03:45:32.040</a></span> | <span class="t">And as you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13533" target="_blank">03:45:33.320</a></span> | <span class="t">We always generate the last row and the last row is always the last token that needs to access all the previous tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13538" target="_blank">03:45:38.920</a></span> | <span class="t">So we never need to mask out anything. However during training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13542" target="_blank">03:45:42.200</a></span> | <span class="t">when you train a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13544" target="_blank">03:45:44.920</a></span> | <span class="t">on something then you need to mask out because the model will generate all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13548" target="_blank">03:45:48.920</a></span> | <span class="t">Contextualized embedding in parallel and you want each contextualized embedding to only be contextualized on the previous token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13554" target="_blank">03:45:54.600</a></span> | <span class="t">So you need to mask out. So during training we will have a causal mask, but during inference, which is our case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13560" target="_blank">03:46:00.200</a></span> | <span class="t">We don't have any causal mask at least when working with the KB cache and at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13564" target="_blank">03:46:04.040</a></span> | <span class="t">When working with models like polygamma if you work with a normal language model like normal like llama</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13569" target="_blank">03:46:09.880</a></span> | <span class="t">For example when you do the pre-filling you actually need to mask out the pre-filling part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13574" target="_blank">03:46:14.200</a></span> | <span class="t">But in the case of polygamma because of the choices made by the polygamma team. We do not need to mask out anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13579" target="_blank">03:46:19.640</a></span> | <span class="t">And this is why we do not need to mask out anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13582" target="_blank">03:46:22.840</a></span> | <span class="t">So when we will in the future plan to make another video on how to fine-tune this model that we have made</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13587" target="_blank">03:46:27.720</a></span> | <span class="t">And we will see that we will need to introduce some kind of mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13591" target="_blank">03:46:31.080</a></span> | <span class="t">And the mask will have to be generated exactly like shown by the polygamma paper. So let me check if my it's still working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13599" target="_blank">03:46:39.080</a></span> | <span class="t">Sometimes I lose connection with my cam. So I need to check every once in a while. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13603" target="_blank">03:46:43.160</a></span> | <span class="t">We add then okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13606" target="_blank">03:46:46.920</a></span> | <span class="t">we have created this mask which is filled with zeros because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13609" target="_blank">03:46:49.480</a></span> | <span class="t">We need to fill up minus infinities to all the positions where we want to mask out something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13615" target="_blank">03:46:55.000</a></span> | <span class="t">But we never mask out anything. So we always make this tensor full of zeros</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13618" target="_blank">03:46:58.920</a></span> | <span class="t">when we are pre-filling we generate a sequence by sequence mask, but when we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13624" target="_blank">03:47:04.760</a></span> | <span class="t">Generating tokens, we only generated the last row of that metric. So we have only one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13631" target="_blank">03:47:11.080</a></span> | <span class="t">Query, so as you can see assert query is equal one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13633" target="_blank">03:47:13.800</a></span> | <span class="t">So we only have one query and then we have how many keys we want which is how many keys there are in the KVCache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13639" target="_blank">03:47:19.720</a></span> | <span class="t">We add the plus one to this KVCache because before using the KVCache we add this current token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13645" target="_blank">03:47:25.480</a></span> | <span class="t">So the query token inside of the KVCache then we extract it before calculating the self-attention like we saw before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13651" target="_blank">03:47:31.000</a></span> | <span class="t">As you know the KVCache when we do the attention computation, we have one attention computation for each head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13657" target="_blank">03:47:37.720</a></span> | <span class="t">So we need to add the head dimension because there will be one attention matrix for each head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13662" target="_blank">03:47:42.120</a></span> | <span class="t">And that's why we add this head dimension here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13664" target="_blank">03:47:44.440</a></span> | <span class="t">Okay. Now we have generated the KVCache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13667" target="_blank">03:47:47.240</a></span> | <span class="t">Let me check what else we need to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13670" target="_blank">03:47:50.200</a></span> | <span class="t">We need to generate the positions of the tokens that will be used by the rotary positional encodings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13676" target="_blank">03:47:56.380</a></span> | <span class="t">So when we are working with the pre-filling part of the KVCache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13681" target="_blank">03:48:01.240</a></span> | <span class="t">It means that we have n tokens that are part of the prompt of the user which are the image tokens plus the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13687" target="_blank">03:48:07.720</a></span> | <span class="t">Then we need to generate enough positions to apply the rotary positional encoding. So which the positional encoding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13693" target="_blank">03:48:13.480</a></span> | <span class="t">How many of them we need we need up to how many tokens there are in the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13700" target="_blank">03:48:20.360</a></span> | <span class="t">Which is indicated also by the number of ones in the attention mask which is generated by this processing polygamma code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13706" target="_blank">03:48:26.520</a></span> | <span class="t">So when you generate the tokenized text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13708" target="_blank">03:48:28.840</a></span> | <span class="t">It will give you the input IDs and another tensor of the same size as the input IDs with all ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13715" target="_blank">03:48:35.300</a></span> | <span class="t">Indicating that we do not mask out anything and if you count the number of ones it also gives you how many tokens there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13721" target="_blank">03:48:41.140</a></span> | <span class="t">In the input IDs, so that's what we are doing here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13723" target="_blank">03:48:43.380</a></span> | <span class="t">We generate enough positions. So when we are doing the pre-filling suppose that the pre-filling is made up of 256 image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13732" target="_blank">03:48:52.660</a></span> | <span class="t">And then three tokens of the textual prompt. So what we will this will generate basically 0, 1, 2, blah, blah, blah</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13740" target="_blank">03:49:00.800</a></span> | <span class="t">255, 256, 257, and 258</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13745" target="_blank">03:49:05.520</a></span> | <span class="t">A sequence like this. This sequence will be then used to understand which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13749" target="_blank">03:49:09.920</a></span> | <span class="t">Rotary positional encoding we need to apply to each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13753" target="_blank">03:49:13.040</a></span> | <span class="t">when we are however doing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13755" target="_blank">03:49:15.760</a></span> | <span class="t">Token generation we only have one single query to which we need to apply the positional encoding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13763" target="_blank">03:49:23.700</a></span> | <span class="t">And for that we only take the one token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13767" target="_blank">03:49:27.040</a></span> | <span class="t">So this will generate only a one single mask, which is the position corresponding to the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13771" target="_blank">03:49:31.680</a></span> | <span class="t">To the last token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13776" target="_blank">03:49:36.640</a></span> | <span class="t">Okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13777" target="_blank">03:49:37.360</a></span> | <span class="t">So when we do token generation basically we have some tokens that are already saved in the KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13781" target="_blank">03:49:41.840</a></span> | <span class="t">And then we have one new token, which is the last predicted token, which we use as a query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13786" target="_blank">03:49:46.080</a></span> | <span class="t">To understand what is the position of this token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13789" target="_blank">03:49:49.120</a></span> | <span class="t">We also pass the attention mask in the case of the attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13792" target="_blank">03:49:52.640</a></span> | <span class="t">It will indicate that it's all made up of ones how many ones well indicate well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13797" target="_blank">03:49:57.200</a></span> | <span class="t">Based on how many tokens there are in the KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13800" target="_blank">03:50:00.000</a></span> | <span class="t">Plus one because we also have the new token that we need to add to the KV cache before doing the self attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13805" target="_blank">03:50:05.040</a></span> | <span class="t">So what we are doing here is the same. So we are counting how many ones there are in the KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13809" target="_blank">03:50:09.920</a></span> | <span class="t">Which is already plus one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13812" target="_blank">03:50:12.000</a></span> | <span class="t">And then we take this last number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13815" target="_blank">03:50:15.120</a></span> | <span class="t">And we this is how we generate the position IDs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13821" target="_blank">03:50:21.280</a></span> | <span class="t">And then we return this stuff here, so let me return this stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13826" target="_blank">03:50:26.720</a></span> | <span class="t">Okay, so we have implemented this method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13829" target="_blank">03:50:29.840</a></span> | <span class="t">So what this does this method do this method basically takes as input the image features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13834" target="_blank">03:50:34.800</a></span> | <span class="t">It takes as input the input IDs and the input embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13838" target="_blank">03:50:38.240</a></span> | <span class="t">What are the input embeddings are the image the embeddings of the image placeholder, which we will not use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13845" target="_blank">03:50:45.280</a></span> | <span class="t">And then the image features our goal is to put all the image features in the right places in this input embeddings based on where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13852" target="_blank">03:50:52.240</a></span> | <span class="t">Are these image embeddings placeholder positions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13855" target="_blank">03:50:55.300</a></span> | <span class="t">And we did we do it here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13858" target="_blank">03:50:58.000</a></span> | <span class="t">then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13859" target="_blank">03:50:59.200</a></span> | <span class="t">Here actually then we create the attention mask, which is basically just made up of zeros which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13864" target="_blank">03:51:04.720</a></span> | <span class="t">Do not confuse the zeros in the attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13867" target="_blank">03:51:07.520</a></span> | <span class="t">We are creating here with what we are probably commonly used to see in the attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13871" target="_blank">03:51:11.920</a></span> | <span class="t">So let me show you actually this one also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13875" target="_blank">03:51:15.120</a></span> | <span class="t">So usually you are probably used to see the attention mask as a bunch of num ones and zero and the zero indicates which number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13881" target="_blank">03:51:21.440</a></span> | <span class="t">Should be masked and the one which indicates what is the number that should not be masked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13885" target="_blank">03:51:25.600</a></span> | <span class="t">This ones and zero is actually then converted into a number of in a series of minus infinities and zeros before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13893" target="_blank">03:51:33.200</a></span> | <span class="t">Being added to the attention matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13896" target="_blank">03:51:36.000</a></span> | <span class="t">Instead of creating a ones and zero which then converted into minus infinities and zeros</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13901" target="_blank">03:51:41.200</a></span> | <span class="t">We are already creating the mask that can be directly added to the attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13905" target="_blank">03:51:45.280</a></span> | <span class="t">So we are creating a bunch of zeros, which basically means that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13908" target="_blank">03:51:48.480</a></span> | <span class="t">You add a bunch of zeros to this matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13911" target="_blank">03:51:51.280</a></span> | <span class="t">So it's like you are not masking out anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13913" target="_blank">03:51:53.440</a></span> | <span class="t">If you want to mask out something then you need to add some minus infinities in this mask, but we never add any minus infinities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13920" target="_blank">03:52:00.240</a></span> | <span class="t">So we are not masking out anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13922" target="_blank">03:52:02.240</a></span> | <span class="t">And this is our method that combines the image features with the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13927" target="_blank">03:52:07.680</a></span> | <span class="t">Our next goal is to create the structure of the polygama</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13931" target="_blank">03:52:11.220</a></span> | <span class="t">Actually, we can create this polygama multimodal projector. Yeah</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13935" target="_blank">03:52:15.280</a></span> | <span class="t">All right. So let's create this polygama multimodal projector. Let me put away this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13941" target="_blank">03:52:21.840</a></span> | <span class="t">We just copy it. It's very simple. I just I don't even need to copy first the constructor and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13948" target="_blank">03:52:28.400</a></span> | <span class="t">So the polygama multimodal projector is just that linear layer that converts the size of the image features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13954" target="_blank">03:52:34.620</a></span> | <span class="t">Extracted from the vision encoder into the same size of the embedding size that is used by the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13961" target="_blank">03:52:41.900</a></span> | <span class="t">So it's just a linear layer that converts the hidden size of the vision model into the projection dimension, which is equal to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13969" target="_blank">03:52:49.900</a></span> | <span class="t">embedding size of the text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13972" target="_blank">03:52:52.440</a></span> | <span class="t">text model here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13975" target="_blank">03:52:55.420</a></span> | <span class="t">So this project projection dim is equal to the you can see it here is equal to the hidden size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13981" target="_blank">03:53:01.740</a></span> | <span class="t">That is been then used by the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13984" target="_blank">03:53:04.460</a></span> | <span class="t">So it's basically resizing the the embeddings so that they can be concatenated with the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13991" target="_blank">03:53:11.020</a></span> | <span class="t">Let's go back here. So as you can see, we are just applying this linear layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=13995" target="_blank">03:53:15.980</a></span> | <span class="t">Our next step is to code the language model itself. So the language model the gamma language model is a transformer model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14003" target="_blank">03:53:23.420</a></span> | <span class="t">So it it will code a language model. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14005" target="_blank">03:53:25.900</a></span> | <span class="t">Transformer model so we create this gamma for causal language modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14010" target="_blank">03:53:30.860</a></span> | <span class="t">Which takes the configuration of the gamma model as input and the gamma model, which we will create later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14016" target="_blank">03:53:36.060</a></span> | <span class="t">Basically in the hugging phase whenever you see something something for causal language modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14022" target="_blank">03:53:42.860</a></span> | <span class="t">It is a transformer model plus a language modeling head, which is the linear layer in the transformer that projects each embedding into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14029" target="_blank">03:53:49.820</a></span> | <span class="t">logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14032" target="_blank">03:53:52.300</a></span> | <span class="t">So this is basically the transformer model this gamma model and then this is gamma for causal lm is the gamma model plus a linear layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14039" target="_blank">03:53:59.820</a></span> | <span class="t">That's why we are reusing this instance plus a linear layer. So the forward method will be very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14045" target="_blank">03:54:05.180</a></span> | <span class="t">We need to implement these two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14048" target="_blank">03:54:08.620</a></span> | <span class="t">methods which are used for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14051" target="_blank">03:54:11.020</a></span> | <span class="t">Weight tying so we saw before that weight tying basically means that we share the weights of the embedding back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14057" target="_blank">03:54:17.180</a></span> | <span class="t">Layer with the logits layer. So this is what we are doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14060" target="_blank">03:54:20.380</a></span> | <span class="t">So when we type weights, we just copy from the embeddings to the language modeling head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14065" target="_blank">03:54:25.420</a></span> | <span class="t">Which is the linear layer that converts the embedding into logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14069" target="_blank">03:54:29.920</a></span> | <span class="t">Then we have the forward method which is also very simple because it will not do anything except for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14076" target="_blank">03:54:36.480</a></span> | <span class="t">Applying sending the stuff to the language model and then applying this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14080" target="_blank">03:54:40.400</a></span> | <span class="t">Linear language modeling head which is the linear layer to convert into logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14084" target="_blank">03:54:44.800</a></span> | <span class="t">So as you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14087" target="_blank">03:54:47.680</a></span> | <span class="t">We send the input directly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14090" target="_blank">03:54:50.000</a></span> | <span class="t">So the attention mask the position IDs the input embeddings the kvcache we send it to this language model, which we will implement later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14096" target="_blank">03:54:56.960</a></span> | <span class="t">The output of this language model will be a series of embeddings, but we do not want embeddings. We want logits. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14102" target="_blank">03:55:02.720</a></span> | <span class="t">This is what we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14104" target="_blank">03:55:04.880</a></span> | <span class="t">We take the outputs. We take the hidden states from these outputs, which are the series of embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14110" target="_blank">03:55:10.560</a></span> | <span class="t">We apply the language modeling head. So it's the linear layer. We make sure it's a floating point numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14115" target="_blank">03:55:15.920</a></span> | <span class="t">we return and return whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14119" target="_blank">03:55:19.920</a></span> | <span class="t">Result is it so we return the logits and if the user specified the kvcache, we also return the updated kvcache. That's it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14127" target="_blank">03:55:27.680</a></span> | <span class="t">Because here there is no logic the logic will be here in gamma model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14132" target="_blank">03:55:32.320</a></span> | <span class="t">Yeah, so let's go to implement the gamma model, all right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14137" target="_blank">03:55:37.120</a></span> | <span class="t">So what is a language model a language model is an embedding layer plus a series of transformer layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14144" target="_blank">03:55:44.000</a></span> | <span class="t">And then we have the language modeling head. The language modeling head is already implemented here in gamma for causal language modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14150" target="_blank">03:55:50.160</a></span> | <span class="t">So we just need to create the other part which is the embedding layer and the list of transformer layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14155" target="_blank">03:55:55.440</a></span> | <span class="t">Let's do that. So we create first the constructor. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14159" target="_blank">03:55:59.680</a></span> | <span class="t">gamma model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14162" target="_blank">03:56:02.000</a></span> | <span class="t">which takes the configuration some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14164" target="_blank">03:56:04.000</a></span> | <span class="t">Information that it needs so the vocabulary size why we need a couple vocabulary size because we need to create the embeddings how many embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14170" target="_blank">03:56:10.880</a></span> | <span class="t">we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14172" target="_blank">03:56:12.480</a></span> | <span class="t">Depending on the number of tokens in our vocabulary each embedding vector will be of size a hidden size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14179" target="_blank">03:56:19.600</a></span> | <span class="t">This indicates the position of the embedding token inside of the vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14183" target="_blank">03:56:23.060</a></span> | <span class="t">And basically I think the embedding layer takes it as input so that it does not update the gradient for this token here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14190" target="_blank">03:56:30.000</a></span> | <span class="t">And then we have a list of layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14192" target="_blank">03:56:32.880</a></span> | <span class="t">for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14194" target="_blank">03:56:34.960</a></span> | <span class="t">For our transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14197" target="_blank">03:56:37.440</a></span> | <span class="t">These are called here are called gamma decoder layers. So they are the transformer layers. We have how many of them we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14205" target="_blank">03:56:45.440</a></span> | <span class="t">Depending on this parameter num_hidden_layers. And then we have a final normalization, which is a rms normalization, which I will describe later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14212" target="_blank">03:56:52.880</a></span> | <span class="t">What is it and why it's different from a layer normalization?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14216" target="_blank">03:56:56.020</a></span> | <span class="t">We need to implement this method here get_input_embeddings, which is used by the language modeling head. So as you can see we use it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14225" target="_blank">03:57:05.120</a></span> | <span class="t">here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14227" target="_blank">03:57:07.760</a></span> | <span class="t">We use it here to extract the initial embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14230" target="_blank">03:57:10.960</a></span> | <span class="t">From the language model which are then combined with the image features we saw before here and then send to the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14236" target="_blank">03:57:16.800</a></span> | <span class="t">So the language model here is receiving not the input IDs, but it's receiving the embeddings already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14241" target="_blank">03:57:21.840</a></span> | <span class="t">So the image embeddings plus the text embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14244" target="_blank">03:57:24.420</a></span> | <span class="t">Which is the same embeddings that we will receive here in the forward method of gamma model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14250" target="_blank">03:57:30.000</a></span> | <span class="t">Now, let's make the forward method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14253" target="_blank">03:57:33.280</a></span> | <span class="t">Which is also very simple because we do not implement much logic here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14259" target="_blank">03:57:39.600</a></span> | <span class="t">So we receive the attention_mask, the position_ids, which are the position that we will apply for each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14265" target="_blank">03:57:45.200</a></span> | <span class="t">How to apply the positional encoding to each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14268" target="_blank">03:57:48.800</a></span> | <span class="t">We didn't talk about the positional encoding yet because we apply the rotary positional encoding in this case, which are applied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14275" target="_blank">03:57:55.120</a></span> | <span class="t">During the calculation of the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14277" target="_blank">03:57:57.200</a></span> | <span class="t">So they are not applied at the beginning like we saw before with the Sigleap or with the vanilla transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14282" target="_blank">03:58:02.320</a></span> | <span class="t">But they are applied just before calculating the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14286" target="_blank">03:58:06.160</a></span> | <span class="t">We have the input embeddings which we saw before are the image features plus the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14291" target="_blank">03:58:11.520</a></span> | <span class="t">And in case we have the KB cache also the instance of the KB cache, which we didn't implement yet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14296" target="_blank">03:58:16.320</a></span> | <span class="t">But we already know how it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14298" target="_blank">03:58:18.320</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14300" target="_blank">03:58:20.960</a></span> | <span class="t">Let's do it. So the first thing that it does it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14304" target="_blank">03:58:24.560</a></span> | <span class="t">Taking and applying some kind of normalization, which is the same reason we apply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14311" target="_blank">03:58:31.020</a></span> | <span class="t">Normalization also to the input of the image features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14313" target="_blank">03:58:33.500</a></span> | <span class="t">We want the kind of the magnitude of the numbers to remain the same even if the number of dimensions increases</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14318" target="_blank">03:58:38.560</a></span> | <span class="t">then this language model is made up of a series of layers of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14323" target="_blank">03:58:43.660</a></span> | <span class="t">Transformer layers. So what we do is the output of one layer becomes the input of the next one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14329" target="_blank">03:58:49.340</a></span> | <span class="t">And that's what we are going to do here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14331" target="_blank">03:58:51.340</a></span> | <span class="t">Oops, I've copied it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14336" target="_blank">03:58:56.860</a></span> | <span class="t">So we take the decoder layer we send it the first hidden state which is the input of this forward after it's been normalized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14344" target="_blank">03:59:04.160</a></span> | <span class="t">We send the attention mask. We send the positional encodings the KB cache and it will return something which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14350" target="_blank">03:59:10.380</a></span> | <span class="t">Contextualized embeddings which become the input of the next layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14354" target="_blank">03:59:14.860</a></span> | <span class="t">So we replace basically these hidden states with the output of the first layer so that it becomes the input of the next layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14360" target="_blank">03:59:20.940</a></span> | <span class="t">And we do it for all the layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14364" target="_blank">03:59:24.380</a></span> | <span class="t">The output of the last layer we send it to a normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14368" target="_blank">03:59:28.240</a></span> | <span class="t">Layer which is the rms normalization, which we didn't see yet, but we will talk shortly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14375" target="_blank">03:59:35.740</a></span> | <span class="t">So I want to actually redraw what we are doing so far. So we have arrived</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14381" target="_blank">03:59:41.580</a></span> | <span class="t">So for that, let's go back to the ipad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14385" target="_blank">03:59:45.840</a></span> | <span class="t">All right, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14393" target="_blank">03:59:53.340</a></span> | <span class="t">What we are doing basically is this so we have created the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14396" target="_blank">03:59:56.620</a></span> | <span class="t">Embeddings before we have merged them with the image tokens and the text tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14401" target="_blank">04:00:01.420</a></span> | <span class="t">We did not apply any positional encodings because we are doing the rotary positional encodings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14406" target="_blank">04:00:06.800</a></span> | <span class="t">Which are applied exactly when we calculate the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14410" target="_blank">04:00:10.560</a></span> | <span class="t">So if we were to draw the the gamma architecture, it would be like this. So we have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14415" target="_blank">04:00:15.820</a></span> | <span class="t">embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14422" target="_blank">04:00:22.620</a></span> | <span class="t">Then I remember there is some kind of normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14425" target="_blank">04:00:25.040</a></span> | <span class="t">Doing but it's not a linear not a normalization layer. It's just we are normalizing the embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14431" target="_blank">04:00:31.420</a></span> | <span class="t">So it's not a layer actually so we do not have to draw it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14434" target="_blank">04:00:34.300</a></span> | <span class="t">Then we have a series of layers and we have n of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14437" target="_blank">04:00:37.900</a></span> | <span class="t">Each of these layers is made up of a normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14442" target="_blank">04:00:42.160</a></span> | <span class="t">RMS normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14446" target="_blank">04:00:46.700</a></span> | <span class="t">Then we have self-attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14448" target="_blank">04:00:48.700</a></span> | <span class="t">So attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14451" target="_blank">04:00:51.420</a></span> | <span class="t">then we have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14453" target="_blank">04:00:53.340</a></span> | <span class="t">Plus so a skip connection here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14455" target="_blank">04:00:55.660</a></span> | <span class="t">Uh, I think I made it too small. So let's make it a bigger</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14460" target="_blank">04:01:00.300</a></span> | <span class="t">This layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14463" target="_blank">04:01:03.180</a></span> | <span class="t">Then we take the output of this one and send it to another normalization, which is an again in rms normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14469" target="_blank">04:01:09.280</a></span> | <span class="t">Then we send it to a feed forward network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14472" target="_blank">04:01:12.640</a></span> | <span class="t">The output of this one is sent again to another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14480" target="_blank">04:01:20.460</a></span> | <span class="t">Skip connection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14482" target="_blank">04:01:22.060</a></span> | <span class="t">Then the output of the last layer will be sent to again another normalization, which is the rms normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14488" target="_blank">04:01:28.640</a></span> | <span class="t">Then we send it to a linear layer for the logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14492" target="_blank">04:01:32.480</a></span> | <span class="t">Linear and let me shift it down and then we have the softmax so so far</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14503" target="_blank">04:01:43.820</a></span> | <span class="t">So far what we have made is basically we are now creating this structure here, but without coding the single block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14510" target="_blank">04:01:50.540</a></span> | <span class="t">So we are just creating this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14512" target="_blank">04:01:52.620</a></span> | <span class="t">Forward method that will run the output of the embeddings to each of this layer one after another and will apply the final normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14520" target="_blank">04:02:00.800</a></span> | <span class="t">Rms normalization, which is this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14524" target="_blank">04:02:04.380</a></span> | <span class="t">And then it will be sent to the linear layer when it will be sent to this linear layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14529" target="_blank">04:02:09.900</a></span> | <span class="t">With gamma for causal lm because as you can see gamma for causal lm will take the output of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14534" target="_blank">04:02:14.860</a></span> | <span class="t">Model, what is this model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14536" target="_blank">04:02:16.940</a></span> | <span class="t">It's everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14538" target="_blank">04:02:18.540</a></span> | <span class="t">Except the linear layer and then we'll apply this linear layer called the language modeling head which will convert it into logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14545" target="_blank">04:02:25.420</a></span> | <span class="t">And after we will apply the softmax, but that is for sampling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14549" target="_blank">04:02:29.020</a></span> | <span class="t">So now we need to create this decoder layer. So what is this decoder layer?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14552" target="_blank">04:02:32.940</a></span> | <span class="t">This decoder layer is this stuff here. We need to code the normalization. We need to code the attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14558" target="_blank">04:02:38.940</a></span> | <span class="t">We need to code the field forward network and of course all the skip connections. So let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14563" target="_blank">04:02:43.580</a></span> | <span class="t">All right. The first thing that we can implement actually very easily is the rms normalization. So let's explore it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14570" target="_blank">04:02:50.060</a></span> | <span class="t">So I have a slide ready there for that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14572" target="_blank">04:02:52.220</a></span> | <span class="t">So as we saw before with layer normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14574" target="_blank">04:02:54.620</a></span> | <span class="t">What we are doing is that we are normalizing each value using some statistic collected from the value from each item itself in the batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14583" target="_blank">04:03:03.100</a></span> | <span class="t">So each item in the batch suppose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14585" target="_blank">04:03:05.500</a></span> | <span class="t">It's a batch of pictures and the first picture is that of the cat in the layer normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14589" target="_blank">04:03:09.740</a></span> | <span class="t">What we are doing is for each dimension of this vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14592" target="_blank">04:03:12.620</a></span> | <span class="t">We calculate a statistic using this vector which is the mean and the standard deviation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14598" target="_blank">04:03:18.480</a></span> | <span class="t">And then we normalize each value in this vector using these two statistics. How do we normalize? Well, we recenter it around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14607" target="_blank">04:03:27.260</a></span> | <span class="t">Here it's not written, but I can show you the formula here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14610" target="_blank">04:03:30.300</a></span> | <span class="t">You basically subtract the mean that you calculated and you divide it by the standard deviation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14615" target="_blank">04:03:35.760</a></span> | <span class="t">And the layer normalization actually works fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14619" target="_blank">04:03:39.980</a></span> | <span class="t">But recently in most language models, we are seeing another kind of normalization that is known as root mean square normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14627" target="_blank">04:03:47.120</a></span> | <span class="t">Basically what we do with this normalization is that each of these features in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14635" target="_blank">04:03:55.900</a></span> | <span class="t">Each item of the batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14637" target="_blank">04:03:57.740</a></span> | <span class="t">We are normalizing it in such a way that it becomes like it's coming out from a distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14643" target="_blank">04:04:03.120</a></span> | <span class="t">Gaussian distribution with a center of zero and a variance of one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14648" target="_blank">04:04:08.620</a></span> | <span class="t">What they claim in the root mean square normalization paper is that they say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14654" target="_blank">04:04:14.300</a></span> | <span class="t">that the success of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14657" target="_blank">04:04:17.260</a></span> | <span class="t">Layer normalization is not because of its recentering invariance, but because of its rescaling invariance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14665" target="_blank">04:04:25.340</a></span> | <span class="t">which means that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14666" target="_blank">04:04:26.860</a></span> | <span class="t">To actually reduce this internal covariate shift, which is the reason we use normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14672" target="_blank">04:04:32.240</a></span> | <span class="t">The model does not need to see the values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14676" target="_blank">04:04:36.700</a></span> | <span class="t">Centered around zero. It just needs to see the values mostly surrounded around whatever mean they are centered upon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14685" target="_blank">04:04:45.420</a></span> | <span class="t">So the values of this cat, for example, they do not need to be all around zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14691" target="_blank">04:04:51.900</a></span> | <span class="t">They could be all around 500 or all around minus 100 as long as they are more or less around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14698" target="_blank">04:04:58.300</a></span> | <span class="t">500 or more or less around minus 100 all of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14702" target="_blank">04:05:02.060</a></span> | <span class="t">That's the meaning of reducing the variance to one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14706" target="_blank">04:05:06.140</a></span> | <span class="t">So we want most of the values to be around whatever mean it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14709" target="_blank">04:05:09.900</a></span> | <span class="t">And this is a hypothesis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14712" target="_blank">04:05:12.700</a></span> | <span class="t">Made by this paper and it's actually verified because most language models right now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14718" target="_blank">04:05:18.060</a></span> | <span class="t">They do not suffer from the internal covariance shift because they can be trained successfully very fast just like the layer normalization ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14725" target="_blank">04:05:25.420</a></span> | <span class="t">But by using this root mean square normalization, why it is advantageous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14731" target="_blank">04:05:31.660</a></span> | <span class="t">Instead of layer normalization because instead of computing two statistics for the mean and the variance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14739" target="_blank">04:05:39.100</a></span> | <span class="t">We only need to compute one statistic, which is this root mean square statistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14744" target="_blank">04:05:44.380</a></span> | <span class="t">Why we do not compute just the standard deviation like we do with the layer normalization because to compute the standard deviation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14751" target="_blank">04:05:51.180</a></span> | <span class="t">You need to have the mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14753" target="_blank">04:05:53.260</a></span> | <span class="t">But we do not want to compute the mean because we do not want to recenter them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14758" target="_blank">04:05:58.620</a></span> | <span class="t">So we do and because we don't compute the mean we cannot compute the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14762" target="_blank">04:06:02.940</a></span> | <span class="t">the standard deviation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14765" target="_blank">04:06:05.900</a></span> | <span class="t">So we replace this standard deviation with another statistic that allow us to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14771" target="_blank">04:06:11.100</a></span> | <span class="t">Reduce the variance, which is this root mean square statistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14774" target="_blank">04:06:14.640</a></span> | <span class="t">Which is calculated as follows. So we take each item in this vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14779" target="_blank">04:06:19.660</a></span> | <span class="t">So this item, this item, this item, this item, this item, this item</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14782" target="_blank">04:06:22.540</a></span> | <span class="t">We make the power of two of each of this item. We sum them up all together. We calculate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14789" target="_blank">04:06:29.120</a></span> | <span class="t">The mean of this summation so divide by n basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14793" target="_blank">04:06:33.020</a></span> | <span class="t">Square root and this gives us the square root mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14798" target="_blank">04:06:38.540</a></span> | <span class="t">Square statistic for this item then we take each of this item and we divide it by this statistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14804" target="_blank">04:06:44.380</a></span> | <span class="t">Multiplied by a learnable parameter called gamma, which is one for each feature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14810" target="_blank">04:06:50.380</a></span> | <span class="t">So basically with root mean square normalization, we are obtaining the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14816" target="_blank">04:06:56.620</a></span> | <span class="t">covariate, internal covariate shift</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14819" target="_blank">04:06:59.580</a></span> | <span class="t">I mean, it solves the same problem of the internal covariate shift as layer normalization, but by computing one less statistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14827" target="_blank">04:07:07.340</a></span> | <span class="t">So we compute less statistics. So it is faster basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14830" target="_blank">04:07:10.380</a></span> | <span class="t">and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14832" target="_blank">04:07:12.940</a></span> | <span class="t">Okay. Yeah, so let's implement it. Let me put away this stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14837" target="_blank">04:07:17.740</a></span> | <span class="t">All right, so now we copy this class we put it here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14844" target="_blank">04:07:24.940</a></span> | <span class="t">Then we later we explain it it's very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14850" target="_blank">04:07:30.220</a></span> | <span class="t">Uh, let me copy all the forward method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14855" target="_blank">04:07:35.180</a></span> | <span class="t">It's very simple. Okay. So what we are doing with rms normalization is that okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14859" target="_blank">04:07:39.740</a></span> | <span class="t">we are creating a weight matrix, which is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14861" target="_blank">04:07:41.820</a></span> | <span class="t">number of parameters one for each feature in the vector to which we apply this root mean normalization how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14868" target="_blank">04:07:48.700</a></span> | <span class="t">Dimensions will have this vector well the same as the tokens because we are we will go we're going to normalize tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14875" target="_blank">04:07:55.820</a></span> | <span class="t">So this dim will be the hidden dimension of our language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14880" target="_blank">04:08:00.300</a></span> | <span class="t">We compute this root mean square statistic as follows. So we calculate the power of two of each item</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14886" target="_blank">04:08:06.060</a></span> | <span class="t">We compute the mean of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14888" target="_blank">04:08:08.220</a></span> | <span class="t">Power of two. So what we are calculating here is basically this term here. So let me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14894" target="_blank">04:08:14.060</a></span> | <span class="t">Show you this term here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14896" target="_blank">04:08:16.700</a></span> | <span class="t">Then we do one the square root of this which is this r sqrt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14901" target="_blank">04:08:21.340</a></span> | <span class="t">but actually we are not doing the square root we are actually calculating the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14905" target="_blank">04:08:25.500</a></span> | <span class="t">One over the square root of whatever is the argument of the r sqrt. So stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14911" target="_blank">04:08:31.260</a></span> | <span class="t">And instead of dividing each item we are multiplying with one over sqrt, which is exactly like dividing by one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14919" target="_blank">04:08:39.340</a></span> | <span class="t">by the square root</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14921" target="_blank">04:08:41.820</a></span> | <span class="t">Why do we have this item here plus self dot eps in the argument of the square the square root</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14931" target="_blank">04:08:51.900</a></span> | <span class="t">Well, because this r sqrt is one over the square root of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14936" target="_blank">04:08:56.380</a></span> | <span class="t">Whatever is inside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14938" target="_blank">04:08:58.780</a></span> | <span class="t">But if the computation of this statistic produces a number that is very close to zero in this division</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14945" target="_blank">04:09:05.500</a></span> | <span class="t">We are basically dividing by zero which will make the output of this division this number here very big. So instead of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14952" target="_blank">04:09:12.780</a></span> | <span class="t">To avoid this division by zero we add to the denominator of this division. So this denominator we add a very small number called eps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14962" target="_blank">04:09:22.080</a></span> | <span class="t">As you can see, it's a very small number to avoid this division by zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14965" target="_blank">04:09:25.200</a></span> | <span class="t">And it's the same parameter that we also pass in the layer normalization as you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14969" target="_blank">04:09:29.600</a></span> | <span class="t">We pass this parameter, which is a very small number to avoid this division by zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14973" target="_blank">04:09:33.280</a></span> | <span class="t">So the forward method is basically just doing this normalization and then we multiply each of this number by this gamma parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14981" target="_blank">04:09:41.120</a></span> | <span class="t">Which is a learnable parameter as you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14983" target="_blank">04:09:43.920</a></span> | <span class="t">Here, so we have here we have this gamma parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14989" target="_blank">04:09:49.840</a></span> | <span class="t">And then we return it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14991" target="_blank">04:09:51.840</a></span> | <span class="t">That's it. This is normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14993" target="_blank">04:09:53.840</a></span> | <span class="t">Now we can move to the next part, which is the coding of this decoder layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=14999" target="_blank">04:09:59.440</a></span> | <span class="t">All right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15001" target="_blank">04:10:01.920</a></span> | <span class="t">Let me check gamma model so we can create the decoder layer. So let's copy some code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15013" target="_blank">04:10:13.440</a></span> | <span class="t">All right, so the decoder layer as we saw before it's this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15017" target="_blank">04:10:17.680</a></span> | <span class="t">So we need to create something that manages all these blocks here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15022" target="_blank">04:10:22.400</a></span> | <span class="t">So something that takes an input a list of embeddings apply a normalization then apply a transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15027" target="_blank">04:10:27.940</a></span> | <span class="t">Attention, sorry</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15029" target="_blank">04:10:29.600</a></span> | <span class="t">Then it applies a skip connection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15031" target="_blank">04:10:31.200</a></span> | <span class="t">Then the output is sent to another normalization then to a feedforward layer block then again another skip connection then produces some output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15038" target="_blank">04:10:38.240</a></span> | <span class="t">So we will just create this simple block which is the same structure as the decoder layer that we have the encoder layer that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15044" target="_blank">04:10:44.080</a></span> | <span class="t">We have created in cglib. So it's the equivalent of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15046" target="_blank">04:10:46.560</a></span> | <span class="t">This block here the encoder layer. It will be doing the same job</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15050" target="_blank">04:10:50.880</a></span> | <span class="t">So, let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15054" target="_blank">04:10:54.640</a></span> | <span class="t">So what we are doing is we are saving some stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15057" target="_blank">04:10:57.520</a></span> | <span class="t">So the hidden size of the model then we are creating the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15060" target="_blank">04:11:00.800</a></span> | <span class="t">Block, which we will code later the multi-layer perceptron, which is the feedforward network block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15066" target="_blank">04:11:06.240</a></span> | <span class="t">The first normalization and the second normalization because in the decoder block we have two normalizations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15070" target="_blank">04:11:10.900</a></span> | <span class="t">So as you can see here, we have one normalization here and one here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15074" target="_blank">04:11:14.640</a></span> | <span class="t">So the forward method is the same very similar to the one we have coded for cglib</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15080" target="_blank">04:11:20.800</a></span> | <span class="t">so we take some hidden states, which is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15083" target="_blank">04:11:23.440</a></span> | <span class="t">Input to this layer the attention mask, which will be sent to the attention mechanism the position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15088" target="_blank">04:11:28.800</a></span> | <span class="t">Ids which also will be sent to the attention mechanism because we are using the rotary positional encodings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15093" target="_blank">04:11:33.920</a></span> | <span class="t">And the kb cache which also will be sent to the attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15096" target="_blank">04:11:36.660</a></span> | <span class="t">So let's actually let me just copy it and then I explain it because it's the same as the encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15102" target="_blank">04:11:42.960</a></span> | <span class="t">So we take the input we apply the first normalization to this input which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15107" target="_blank">04:11:47.680</a></span> | <span class="t">This stuff here this normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15110" target="_blank">04:11:50.720</a></span> | <span class="t">Then we send the output of the normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15113" target="_blank">04:11:53.460</a></span> | <span class="t">This hidden state we send it to the self-attention block along with the attention mask the positional encodings and the kb cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15120" target="_blank">04:12:00.320</a></span> | <span class="t">And this will produce an output which will be then summed up with the skip connection here, which is this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15126" target="_blank">04:12:06.080</a></span> | <span class="t">So we take the output which is hidden states plus this residual which we saved before to create the skip connection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15131" target="_blank">04:12:11.840</a></span> | <span class="t">then we create another skip connection and we send the output of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15136" target="_blank">04:12:16.960</a></span> | <span class="t">of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15139" target="_blank">04:12:19.660</a></span> | <span class="t">Self-attention to the second normalization, which is this stuff here this normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15145" target="_blank">04:12:25.060</a></span> | <span class="t">The output of the normalization is sent to the multi-layer perceptron, which is this one here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15150" target="_blank">04:12:30.880</a></span> | <span class="t">And then we take the output of the multi-layer perceptron</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15153" target="_blank">04:12:33.600</a></span> | <span class="t">Which is the feed forward network plus the skip connection that we saved before which is this residual stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15158" target="_blank">04:12:38.960</a></span> | <span class="t">And that's this plus sign here and the output is then returned and this is the decoder layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15165" target="_blank">04:12:45.280</a></span> | <span class="t">Now we need to code the multi-layer perceptron and the self-attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15169" target="_blank">04:12:49.620</a></span> | <span class="t">Block, I believe the the faster stuff to do is the multi-layer perceptron. So let's do that first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15178" target="_blank">04:12:58.160</a></span> | <span class="t">So let me go there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15180" target="_blank">04:13:00.160</a></span> | <span class="t">It's also very similar to the multi-layer perceptron that we have already coded for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15185" target="_blank">04:13:05.520</a></span> | <span class="t">Sigleap, but it's slightly different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15188" target="_blank">04:13:08.240</a></span> | <span class="t">So the multi-layer perceptron here, which is also known as feed forward network is basically as we saw before in the sigleap</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15194" target="_blank">04:13:14.560</a></span> | <span class="t">It is something that two linear layers that first expands the embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15200" target="_blank">04:13:20.000</a></span> | <span class="t">Vector applies some non-linearity and then reduces it back to the original size and this is what is done here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15207" target="_blank">04:13:27.520</a></span> | <span class="t">But in this case, we also have another linear layer called the gate projection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15212" target="_blank">04:13:32.580</a></span> | <span class="t">Which is used by the activation function that this gamma language model is using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15217" target="_blank">04:13:37.600</a></span> | <span class="t">We saw that different language models have different activation functions, which is based mostly on heuristics on how they work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15225" target="_blank">04:13:45.520</a></span> | <span class="t">So let's implement the forward method, which is very simple here and we will see why we need this gate projection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15233" target="_blank">04:13:53.360</a></span> | <span class="t">I made a code to convert this very long. I mean this very long this this this line into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15240" target="_blank">04:14:00.000</a></span> | <span class="t">Series of steps so that you can see each single step being done independently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15244" target="_blank">04:14:04.980</a></span> | <span class="t">but let me describe it what we are doing here basically is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15248" target="_blank">04:14:08.480</a></span> | <span class="t">First we are applying the gate projection to the input to this feed forward network, which is a list of embeddings as we saw before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15257" target="_blank">04:14:17.920</a></span> | <span class="t">And the function that we are using is the gelu function, which I believe is the same that we are using also for the sigleap</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15263" target="_blank">04:14:23.680</a></span> | <span class="t">Let me check</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15266" target="_blank">04:14:26.560</a></span> | <span class="t">Uh, yeah the same function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15270" target="_blank">04:14:30.000</a></span> | <span class="t">But we also have this gate projection here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15273" target="_blank">04:14:33.600</a></span> | <span class="t">So basically it's adding some learnable parameters before sending it to this activation function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15279" target="_blank">04:14:39.600</a></span> | <span class="t">We multiply the output of this activation function with the up projection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15285" target="_blank">04:14:45.120</a></span> | <span class="t">The up projection is basically the one that takes the embedding size from the original embedding to the intermediate size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15291" target="_blank">04:14:51.040</a></span> | <span class="t">So it's expanded size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15293" target="_blank">04:14:53.120</a></span> | <span class="t">And then the result of this multiplication, which is a vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15297" target="_blank">04:14:57.920</a></span> | <span class="t">Which is a tensor of size batch size sequence length and the intermediate size is then reduced back to the original size by this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15304" target="_blank">04:15:04.960</a></span> | <span class="t">Down projection because with the up projection you are expanding and the down projection you are putting it back to the original size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15311" target="_blank">04:15:11.440</a></span> | <span class="t">So the down projection will take the intermediate size back into the hidden size and this is the multi-layer perceptron of gamma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15317" target="_blank">04:15:17.200</a></span> | <span class="t">It's slightly different than the other one because we have this gate projection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15321" target="_blank">04:15:21.360</a></span> | <span class="t">Which is additional parameters basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15323" target="_blank">04:15:23.360</a></span> | <span class="t">And it's the same kind of gate projection that we also have if I remember correctly in lama in which we have this regular function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15329" target="_blank">04:15:29.520</a></span> | <span class="t">With its own gate projection. It's just parameters that are learnable before applying the non-linearity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15335" target="_blank">04:15:35.220</a></span> | <span class="t">We also said that the non-linearity is chosen based on heuristic on how they work well in particular case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15341" target="_blank">04:15:41.280</a></span> | <span class="t">But also on some properties that we want from them with respect to the gradient. So some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15346" target="_blank">04:15:46.160</a></span> | <span class="t">Activation functions allow the gradient to flow for negative values. Some others don't allow it, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15352" target="_blank">04:15:52.640</a></span> | <span class="t">So it's all based on practical application. Someone trained tried using it so that it works better and then we start using it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15360" target="_blank">04:16:00.560</a></span> | <span class="t">Okay, now we also have the multi-layer perceptron now comes the biggest part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15365" target="_blank">04:16:05.600</a></span> | <span class="t">And but not the hardest because we are already familiar with the attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15369" target="_blank">04:16:09.280</a></span> | <span class="t">So we need we need to code the attention mechanism which will comprise the self-attention the use of the KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15374" target="_blank">04:16:14.960</a></span> | <span class="t">The grouped query attention which is something new and the rotary positional encoding. So it will be a little bit of learning experience. So let's start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15382" target="_blank">04:16:22.400</a></span> | <span class="t">All right. So let's start coding the next part, which is gamma attention. So we start by creating the class</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15390" target="_blank">04:16:30.320</a></span> | <span class="t">Let me copy it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15393" target="_blank">04:16:33.120</a></span> | <span class="t">And I will do it slowly because this one has a lot of innovations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15396" target="_blank">04:16:36.820</a></span> | <span class="t">So let's start by creating the constructor, which is our usual constructor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15401" target="_blank">04:16:41.540</a></span> | <span class="t">It takes in the configuration of gamma. We also take another parameter, which is the id of the layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15407" target="_blank">04:16:47.760</a></span> | <span class="t">so the position of the layer in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15410" target="_blank">04:16:50.000</a></span> | <span class="t">Transformer because as you know the decoder the gamma is a decoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15414" target="_blank">04:16:54.080</a></span> | <span class="t">Only model it's made up of many layers and each of these layers will have its own KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15422" target="_blank">04:17:02.480</a></span> | <span class="t">So to know which KV cache to use because there is one cache for each layer. We need to also pass the layer index</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15429" target="_blank">04:17:09.600</a></span> | <span class="t">To each layer so it knows where to put its key and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15435" target="_blank">04:17:15.120</a></span> | <span class="t">Then we save some parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15438" target="_blank">04:17:18.080</a></span> | <span class="t">So the attention dropout which we will not use the hidden size is the size of the embedding vector of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15444" target="_blank">04:17:24.560</a></span> | <span class="t">the number of attention heads for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15446" target="_blank">04:17:26.560</a></span> | <span class="t">queries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15449" target="_blank">04:17:29.040</a></span> | <span class="t">The number of the head dimension which is how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15453" target="_blank">04:17:33.520</a></span> | <span class="t">Dimensions each head will work with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15457" target="_blank">04:17:37.840</a></span> | <span class="t">In the multi-head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15461" target="_blank">04:17:41.680</a></span> | <span class="t">Which is a part of the entire embedding of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15465" target="_blank">04:17:45.200</a></span> | <span class="t">How many heads we have for the number for the keys and values in the multi-head attention?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15472" target="_blank">04:17:52.320</a></span> | <span class="t">And this is different from those for the query because we are going to talk about grouped query attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15477" target="_blank">04:17:57.280</a></span> | <span class="t">So we can calculate how many groups we have in this grouped query attention, but later I will explain how it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15482" target="_blank">04:18:02.000</a></span> | <span class="t">The maximum positional embeddings which are how many positions we can encode in the positional encoding using the rotary positional encoding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15490" target="_blank">04:18:10.400</a></span> | <span class="t">And what is the base frequency of the rotary positional encodings?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15492" target="_blank">04:18:12.980</a></span> | <span class="t">Now we have some other stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15496" target="_blank">04:18:16.640</a></span> | <span class="t">So first of all, we make sure that the hidden size is divisible by the number of heads because as you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15502" target="_blank">04:18:22.880</a></span> | <span class="t">Each head has to watch a part of the embedding of the entire token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15506" target="_blank">04:18:26.560</a></span> | <span class="t">So it must be divisible by the number of heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15508" target="_blank">04:18:28.560</a></span> | <span class="t">Then we create our projections which are the wq wk and wv projections that we saw in the multi-head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15516" target="_blank">04:18:36.960</a></span> | <span class="t">But in this case, we can see that we have not hidden size as input as output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15524" target="_blank">04:18:44.480</a></span> | <span class="t">number of features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15527" target="_blank">04:18:47.200</a></span> | <span class="t">But the number of features are calculated as the number of heads multiplied by the head dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15532" target="_blank">04:18:52.320</a></span> | <span class="t">Now why this is different from the multi-head attention that we have implemented for Sigleap?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15537" target="_blank">04:18:57.440</a></span> | <span class="t">So if we go to look at Sigleap and we look at the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15541" target="_blank">04:19:01.840</a></span> | <span class="t">you can see that each of these wq wk and wv metrics matrices is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15546" target="_blank">04:19:06.640</a></span> | <span class="t">Hidden size by hidden size here. It's called the embedding dimension, but okay, it's the same thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15551" target="_blank">04:19:11.200</a></span> | <span class="t">So it's the size of the entire token with the output features being also the same number of dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15557" target="_blank">04:19:17.620</a></span> | <span class="t">Here, however, it's slightly different. Why?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15562" target="_blank">04:19:22.160</a></span> | <span class="t">If we look at what is the numHeads numHeads is the number of heads for the query and this is actually the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15566" target="_blank">04:19:26.960</a></span> | <span class="t">the full the number of heads for the query in grouped query attention is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15572" target="_blank">04:19:32.320</a></span> | <span class="t">Equal to the is bigger than the number of heads for the than for the keys and values later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15579" target="_blank">04:19:39.280</a></span> | <span class="t">We will see why but for now, let's concentrate on the dimensions. So in this case this wq matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15584" target="_blank">04:19:44.720</a></span> | <span class="t">So it's called the qproj which stands for which is the wq</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15588" target="_blank">04:19:48.800</a></span> | <span class="t">Matrix in the multi-head attention has an output a number of output features. So suppose that the number of heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15595" target="_blank">04:19:55.440</a></span> | <span class="t">So number of heads is equal to 8 and suppose that the hidden size is equal to 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15602" target="_blank">04:20:02.740</a></span> | <span class="t">So the wq matrix will be a matrix that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15607" target="_blank">04:20:07.040</a></span> | <span class="t">1024 by 8 multiplied by the head dimension, but the head dimension is what the head dimension is how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15615" target="_blank">04:20:15.820</a></span> | <span class="t">Dimensions it had will watch by using the number of heads of the query as a reference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15621" target="_blank">04:20:21.020</a></span> | <span class="t">So 1024 divided by 8 which is 128</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15625" target="_blank">04:20:25.280</a></span> | <span class="t">I think so. Yeah</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15628" target="_blank">04:20:28.300</a></span> | <span class="t">So it's 8 multiplied by 120. So actually the wq matrix is 1024 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15635" target="_blank">04:20:35.440</a></span> | <span class="t">What changes in grouped query attention is the wk and wv projection actually wk actually will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15643" target="_blank">04:20:43.480</a></span> | <span class="t">4 because that's the hidden size as input and the output features will be the number of heads for the key values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15651" target="_blank">04:20:51.400</a></span> | <span class="t">Which actually we can check here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15654" target="_blank">04:20:54.040</a></span> | <span class="t">In the configuration we can see that the number of heads for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15658" target="_blank">04:20:58.440</a></span> | <span class="t">Queries is 8 and the number of heads for the key and values is only one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15664" target="_blank">04:21:04.600</a></span> | <span class="t">So actually this is the case of not of grouped query attention. It's multi query attention. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15669" target="_blank">04:21:09.240</a></span> | <span class="t">Let's say okay. Suppose that we have only one head here. Also one multiplied by 128. So it's equal to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15675" target="_blank">04:21:15.480</a></span> | <span class="t">1024 by 128</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15678" target="_blank">04:21:18.820</a></span> | <span class="t">And the same size is also for wv because as you can see the expression in wv is the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15685" target="_blank">04:21:25.480</a></span> | <span class="t">it's the number of heads for the key value multiplied by the head dimension and then we have the output projection, which is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15691" target="_blank">04:21:31.400</a></span> | <span class="t">then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15693" target="_blank">04:21:33.640</a></span> | <span class="t">Hidden size by hidden size because the number of heads multiplied by the head dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15697" target="_blank">04:21:37.480</a></span> | <span class="t">So it's actually number of heads is 8 which is always referencing the number of heads of the queries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15703" target="_blank">04:21:43.320</a></span> | <span class="t">So this is 1024 by 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15705" target="_blank">04:21:45.720</a></span> | <span class="t">So as you can see the difference with the grouped query attention is that we have less head for the keys and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15711" target="_blank">04:21:51.160</a></span> | <span class="t">Which results in a smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15713" target="_blank">04:21:53.400</a></span> | <span class="t">Projection for the embedding of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15717" target="_blank">04:21:57.320</a></span> | <span class="t">When it's used as keys and value. Let's see why so let me open a new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15724" target="_blank">04:22:04.120</a></span> | <span class="t">Page and let's switch to the ipad which is here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15727" target="_blank">04:22:07.800</a></span> | <span class="t">Okay, when we do um</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15730" target="_blank">04:22:10.520</a></span> | <span class="t">Normal multi head attention what we have is that each token is divided into multiple groups of dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15737" target="_blank">04:22:17.400</a></span> | <span class="t">One dedicated to each head suppose that we have an initial token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15741" target="_blank">04:22:21.800</a></span> | <span class="t">Let me use a pen and let's use a smaller size. So imagine that we have a token with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15748" target="_blank">04:22:28.360</a></span> | <span class="t">1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15752" target="_blank">04:22:32.260</a></span> | <span class="t">Dimensions in total if we divide that in eight heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15756" target="_blank">04:22:36.340</a></span> | <span class="t">We will have that each of the head will manage 128 dimensions of this token so one to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15765" target="_blank">04:22:45.060</a></span> | <span class="t">128 then the second head will manage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15768" target="_blank">04:22:48.660</a></span> | <span class="t">129 to 256</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15772" target="_blank">04:22:52.480</a></span> | <span class="t">Etc, etc until the last one which will be I don't know how to do the calculation. Let me check</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15778" target="_blank">04:22:58.020</a></span> | <span class="t">896 I guess</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15781" target="_blank">04:23:01.900</a></span> | <span class="t">896 up to 1024, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15786" target="_blank">04:23:06.820</a></span> | <span class="t">128 yeah should be correct. So this is the head number eight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15793" target="_blank">04:23:13.940</a></span> | <span class="t">This is the head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15798" target="_blank">04:23:18.420</a></span> | <span class="t">Two and this is the head one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15800" target="_blank">04:23:20.900</a></span> | <span class="t">When we do the product query multiplied by the transpose of the keys each of the query is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15809" target="_blank">04:23:29.360</a></span> | <span class="t">Multiplied so dot product with each of the keys, but only in the part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15814" target="_blank">04:23:34.800</a></span> | <span class="t">Dedicated to each head because each head is working independently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15818" target="_blank">04:23:38.500</a></span> | <span class="t">So suppose that this is our query. So this is our query. Let me write it with a different color. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15825" target="_blank">04:23:45.060</a></span> | <span class="t">this is our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15827" target="_blank">04:23:47.540</a></span> | <span class="t">Query and then we have some key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15829" target="_blank">04:23:49.860</a></span> | <span class="t">And this key also in the normal multi head attention. We have the same number of heads for the query and the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15837" target="_blank">04:23:57.220</a></span> | <span class="t">So suppose that we have the same number of heads also here so we can copy this stuff, I guess</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15842" target="_blank">04:24:02.760</a></span> | <span class="t">Too hard to copy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15848" target="_blank">04:24:08.160</a></span> | <span class="t">Okay copy paste</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15852" target="_blank">04:24:12.640</a></span> | <span class="t">So what will happen with the multi head the normal multi head attention is that each head will do the dot product of the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15862" target="_blank">04:24:22.200</a></span> | <span class="t">Head of the head number one. For example, we'll do the dot product of the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15867" target="_blank">04:24:27.500</a></span> | <span class="t">128 dimensions of the query with each of the keys because you need to think that we don't have one key. We have multiple keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15875" target="_blank">04:24:35.160</a></span> | <span class="t">Because it's a matrix. The matrix is a sequence by sequence. So each head each query is attending to all the past keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15883" target="_blank">04:24:43.280</a></span> | <span class="t">So here we can write</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15887" target="_blank">04:24:47.800</a></span> | <span class="t">Key number one key number two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15889" target="_blank">04:24:49.680</a></span> | <span class="t">So key number one key number two and key number three and this is the query number one and we do it for all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15894" target="_blank">04:24:54.640</a></span> | <span class="t">Queries so for each token each token will attend all the past tokens as keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15899" target="_blank">04:24:59.600</a></span> | <span class="t">At least in the language modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15902" target="_blank">04:25:02.400</a></span> | <span class="t">So what will happen is that we are doing a dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15906" target="_blank">04:25:06.320</a></span> | <span class="t">With the first head will do a dot product of the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15909" target="_blank">04:25:09.560</a></span> | <span class="t">128 dimensions between the query and the key then again between this query and this key and then between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15916" target="_blank">04:25:16.520</a></span> | <span class="t">This query and this key in parallel the head number two will do the same stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15922" target="_blank">04:25:22.200</a></span> | <span class="t">so the head number two will take the next group of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15925" target="_blank">04:25:25.560</a></span> | <span class="t">128 dimensions or the dimensions from 129 to 256 and will do the dot product with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15932" target="_blank">04:25:32.800</a></span> | <span class="t">next group of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15935" target="_blank">04:25:35.080</a></span> | <span class="t">128 dimensions for each of the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15937" target="_blank">04:25:37.380</a></span> | <span class="t">So it will do the dot product of this query with this key and then this query with this key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15944" target="_blank">04:25:44.560</a></span> | <span class="t">And then this query with this key all in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15948" target="_blank">04:25:48.160</a></span> | <span class="t">in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15951" target="_blank">04:25:51.080</a></span> | <span class="t">Each head is working in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15953" target="_blank">04:25:53.080</a></span> | <span class="t">Now what happens is that and we do it for all the heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15958" target="_blank">04:25:58.560</a></span> | <span class="t">The problem with the multi head attention is that the and this was described in the multi query paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15966" target="_blank">04:26:06.720</a></span> | <span class="t">So if you want I can give you the reference to the paper. It's called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15970" target="_blank">04:26:10.400</a></span> | <span class="t">multi query paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15974" target="_blank">04:26:14.200</a></span> | <span class="t">Multi-query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15975" target="_blank">04:26:15.640</a></span> | <span class="t">attention paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15977" target="_blank">04:26:17.640</a></span> | <span class="t">And it's this one here in this paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15980" target="_blank">04:26:20.840</a></span> | <span class="t">Basically, Noam Shazir described what is the problem with multi head attention at least from a computation point of view</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15987" target="_blank">04:26:27.840</a></span> | <span class="t">He claims that with multi head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15991" target="_blank">04:26:31.320</a></span> | <span class="t">The problem is not in the number of computations that we are doing which is the bottleneck of the computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=15997" target="_blank">04:26:37.760</a></span> | <span class="t">but rather the number of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16000" target="_blank">04:26:40.480</a></span> | <span class="t">Data transfer that is happening in the GPU because of this multi head attention and for that we need to talk about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16006" target="_blank">04:26:46.800</a></span> | <span class="t">How the GPUs work so in a GPU what we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16012" target="_blank">04:26:52.600</a></span> | <span class="t">Is this a GPU has a very big memory called the high bandwidth memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16019" target="_blank">04:26:59.400</a></span> | <span class="t">Which is in the order of gigabyte or tens of gigabyte. I think the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16024" target="_blank">04:27:04.880</a></span> | <span class="t">100 goes up to 80 gigabyte. Then we have some smaller memory called local memory. So local</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16032" target="_blank">04:27:12.080</a></span> | <span class="t">memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16034" target="_blank">04:27:14.360</a></span> | <span class="t">And this one is in the order of the megabyte. I don't know if it's 10 of megabyte</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16039" target="_blank">04:27:19.040</a></span> | <span class="t">I think in the tens of megabytes, so it's a one a magnitude of order smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16044" target="_blank">04:27:24.920</a></span> | <span class="t">three magnitudes of order smaller and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16047" target="_blank">04:27:27.640</a></span> | <span class="t">and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16050" target="_blank">04:27:30.040</a></span> | <span class="t">Then we have the cores</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16052" target="_blank">04:27:32.080</a></span> | <span class="t">The cores are many and they all work in parallel all of these cores</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16056" target="_blank">04:27:36.600</a></span> | <span class="t">So when you do a matrix multiplication, what happens is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16060" target="_blank">04:27:40.120</a></span> | <span class="t">You have the matrix that you are trying to multiply in the high bandwidth memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16064" target="_blank">04:27:44.820</a></span> | <span class="t">The the kernel that manages this matrix multiplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16070" target="_blank">04:27:50.120</a></span> | <span class="t">Which is a CUDA kernel in case you are using an Nvidia</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16073" target="_blank">04:27:53.240</a></span> | <span class="t">GPU will copy for example the first part of the matrix from the high bandwidth memory to the local memory and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16080" target="_blank">04:28:00.920</a></span> | <span class="t">Each core will work with a part of this big matrix to compute this matrix multiplication in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16089" target="_blank">04:28:09.040</a></span> | <span class="t">So each one is will be working with a smaller part of this matrix to calculate this this part in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16094" target="_blank">04:28:14.680</a></span> | <span class="t">it's much easier to visualize with the summation because for example if you are summing two matrices like this matrix and this matrix and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16101" target="_blank">04:28:21.880</a></span> | <span class="t">You get this matrix as output. What happens if you divide it into four parts is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16108" target="_blank">04:28:28.920</a></span> | <span class="t">The result of this part of the matrix only depends on these numbers and these numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16113" target="_blank">04:28:33.620</a></span> | <span class="t">So the first head can work with these two parts the second core</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16117" target="_blank">04:28:37.960</a></span> | <span class="t">Sorry, not head the second core can work with these two parts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16121" target="_blank">04:28:41.480</a></span> | <span class="t">sum them up to produce this one the third core can work with these two parts and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16127" target="_blank">04:28:47.840</a></span> | <span class="t">Resulting in this part and then the last core can work on this part which will result in this part of the matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16134" target="_blank">04:28:54.800</a></span> | <span class="t">So as you can see the metric summation can be done in parallel by multiple cores each working with a part of the matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16141" target="_blank">04:29:01.120</a></span> | <span class="t">What happens when we do multi head attention is that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16146" target="_blank">04:29:06.280</a></span> | <span class="t">the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16148" target="_blank">04:29:08.960</a></span> | <span class="t">The dimension suppose that because the heads are working in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16152" target="_blank">04:29:12.940</a></span> | <span class="t">the first head will copy the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16156" target="_blank">04:29:16.560</a></span> | <span class="t">128 dimensions of the query to the local memory of the GPU which will then be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16163" target="_blank">04:29:23.720</a></span> | <span class="t">Accessed by the cores to compute these dot products</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16166" target="_blank">04:29:26.880</a></span> | <span class="t">Meanwhile the second head at the same time needs to copy the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16173" target="_blank">04:29:33.100</a></span> | <span class="t">128 dimension of the each token to the local memory and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16178" target="_blank">04:29:38.680</a></span> | <span class="t">Then needs to also copy for each query the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16182" target="_blank">04:29:42.640</a></span> | <span class="t">128 dimensions from the high bandwidth memory to the local memory so that the cores can work with it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16189" target="_blank">04:29:49.880</a></span> | <span class="t">Now what happens in the multi query attention paper. So this paper here what they say is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16195" target="_blank">04:29:55.680</a></span> | <span class="t">The bottleneck of the computation of the attention is not in how many dot products we are doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16202" target="_blank">04:30:02.960</a></span> | <span class="t">But how much it how much time it takes to copy the memory from the high bandwidth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16208" target="_blank">04:30:08.200</a></span> | <span class="t">Bandwidth memory to the local memory so that the cores can work with it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16212" target="_blank">04:30:12.160</a></span> | <span class="t">Why because in the GPU we have a lot of cores that are very fast at computing computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16218" target="_blank">04:30:18.240</a></span> | <span class="t">But the GPU is not so fast at copying stuff around so the memory copying is very slow compared to how much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16225" target="_blank">04:30:25.040</a></span> | <span class="t">Computations it can perform. For example, let's open the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16228" target="_blank">04:30:28.760</a></span> | <span class="t">A100 GPU data sheet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16231" target="_blank">04:30:31.680</a></span> | <span class="t">It's here you can see that the A100 has okay 80 gigabyte of memory in the high bandwidth memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16240" target="_blank">04:30:40.840</a></span> | <span class="t">And it can do this kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16246" target="_blank">04:30:46.160</a></span> | <span class="t">Teraflops operations per second if you are working with the 32-bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16250" target="_blank">04:30:50.080</a></span> | <span class="t">But as you can see the GPU memory bandwidth is much slower than the number of operations it can do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16257" target="_blank">04:30:57.060</a></span> | <span class="t">Because the teraflow floating-point operations per second means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16261" target="_blank">04:31:01.320</a></span> | <span class="t">billions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16263" target="_blank">04:31:03.640</a></span> | <span class="t">thousands of millions of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16265" target="_blank">04:31:05.640</a></span> | <span class="t">Billions of operations per second so it means thousands of giga operations per second while here we have only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16272" target="_blank">04:31:12.840</a></span> | <span class="t">2,000 gigabyte per second of memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16275" target="_blank">04:31:15.880</a></span> | <span class="t">transfer speed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16278" target="_blank">04:31:18.640</a></span> | <span class="t">So basically in in a lot of computations that we do in the GPU</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16282" target="_blank">04:31:22.320</a></span> | <span class="t">The bottleneck is not how much compute we are using but how much data transfer is happening for this compute and as a matter of fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16289" target="_blank">04:31:29.560</a></span> | <span class="t">Flash attention basically exploits this difference in computation and memory transfer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16296" target="_blank">04:31:36.760</a></span> | <span class="t">To reduce the memory transfer and redo computations because you it's faster than to redo computations twice instead of copying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16304" target="_blank">04:31:44.560</a></span> | <span class="t">a different stuff from the GPU</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16306" target="_blank">04:31:46.560</a></span> | <span class="t">To</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16309" target="_blank">04:31:49.480</a></span> | <span class="t">For the computation. So basically what we do is we are willing to sacrifice computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16315" target="_blank">04:31:55.160</a></span> | <span class="t">To reduce the data transfer. This is what we do with flash attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16319" target="_blank">04:31:59.400</a></span> | <span class="t">This is also one of the reason we use the gradient checkpointing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16322" target="_blank">04:32:02.800</a></span> | <span class="t">So gradient checkpointing basically means that during the backward pass we redo some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16326" target="_blank">04:32:06.720</a></span> | <span class="t">computations instead of saving them because if we save them then we need to recopy them from the high bandwidth memory to the local</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16332" target="_blank">04:32:12.380</a></span> | <span class="t">Memory, so it's faster to redo them instead of copying them the already processed one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16337" target="_blank">04:32:17.520</a></span> | <span class="t">To speed up the computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16341" target="_blank">04:32:21.180</a></span> | <span class="t">So the one clock time which means the total time to compute the attention is determined</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16346" target="_blank">04:32:26.080</a></span> | <span class="t">Actually is bottlenecked not by the number of dot products that we are doing but how much data transfer happens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16351" target="_blank">04:32:31.800</a></span> | <span class="t">So how to reduce the data transfer that we do when we do the multi head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16356" target="_blank">04:32:36.560</a></span> | <span class="t">One way is to use less heads for the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16361" target="_blank">04:32:41.280</a></span> | <span class="t">so what will happen is that the first head imagine we only use one head for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16367" target="_blank">04:32:47.800</a></span> | <span class="t">keys instead of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16370" target="_blank">04:32:50.240</a></span> | <span class="t">Having multi head also for the keys and values. So we don't have this part anymore</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16374" target="_blank">04:32:54.400</a></span> | <span class="t">we only have a multi head for the we have many heads for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16380" target="_blank">04:33:00.480</a></span> | <span class="t">Let's see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16382" target="_blank">04:33:02.480</a></span> | <span class="t">We only have one we only have multi head for the queries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16386" target="_blank">04:33:06.840</a></span> | <span class="t">So we don't have multi head for the keys or we have less heads for the key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16391" target="_blank">04:33:11.000</a></span> | <span class="t">Imagine that we are in the extreme case in which we only have one head for the key and value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16396" target="_blank">04:33:16.080</a></span> | <span class="t">But we have multi head for the query. What will happen is that the first core will copy the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16401" target="_blank">04:33:21.080</a></span> | <span class="t">128 dimensions for the queries from the high bandwidth memory to the local memory and also the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16408" target="_blank">04:33:28.440</a></span> | <span class="t">128 dimensions for each token for the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16411" target="_blank">04:33:31.720</a></span> | <span class="t">It will perform the computation now. Meanwhile, the also the second head needs to do its computation. So in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16419" target="_blank">04:33:39.200</a></span> | <span class="t">So, how can it do it needs to copy the 128 dimensions for the query?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16423" target="_blank">04:33:43.640</a></span> | <span class="t">but it does not need to copy then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16427" target="_blank">04:33:47.440</a></span> | <span class="t">next group of 128 heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16430" target="_blank">04:33:50.740</a></span> | <span class="t">Dimensions from for each of the keys because it can be it can reuse the one for the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16437" target="_blank">04:33:57.440</a></span> | <span class="t">so they each group of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16439" target="_blank">04:33:59.440</a></span> | <span class="t">Heads of the queries is sharing some heads for the keys so that they don't need to copy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16446" target="_blank">04:34:06.080</a></span> | <span class="t">Again for different heads these dimensions, but they can share the already copied ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16452" target="_blank">04:34:12.480</a></span> | <span class="t">So this is the extreme case of having only one head for the keys, but we can have a group of heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16459" target="_blank">04:34:19.440</a></span> | <span class="t">So we can do for example that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16462" target="_blank">04:34:22.560</a></span> | <span class="t">Instead of we have eight heads for the query and then we have four heads for the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16467" target="_blank">04:34:27.740</a></span> | <span class="t">so the head number one and two for example for the query will share this head here and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16473" target="_blank">04:34:33.720</a></span> | <span class="t">Then the head number three and four will share this head here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16478" target="_blank">04:34:38.720</a></span> | <span class="t">So the head number one and two for the query will share this head here so that the total amount of transfer for the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16484" target="_blank">04:34:44.720</a></span> | <span class="t">is only this part here and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16487" target="_blank">04:34:47.080</a></span> | <span class="t">Then the head number let's add here add number three and the head number four will share a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16493" target="_blank">04:34:53.720</a></span> | <span class="t">Head of the keys, but it's shared as you can see every two head. We are sharing one head of the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16500" target="_blank">04:35:00.880</a></span> | <span class="t">So these two head will not need to copy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16503" target="_blank">04:35:03.520</a></span> | <span class="t">128 dimensions each but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16507" target="_blank">04:35:07.080</a></span> | <span class="t">128 dimensions in total for both of these heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16510" target="_blank">04:35:10.440</a></span> | <span class="t">This reduces data transfer which speeds up the computation of the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16515" target="_blank">04:35:15.120</a></span> | <span class="t">And this is the reason we have here in the computation of the attention the projection for the WK and WV</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16523" target="_blank">04:35:23.000</a></span> | <span class="t">Has less parameters because we are trying to compress these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16527" target="_blank">04:35:27.120</a></span> | <span class="t">tokens into smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16530" target="_blank">04:35:30.240</a></span> | <span class="t">tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16532" target="_blank">04:35:32.720</a></span> | <span class="t">Equal to the number of heads that we need for this projection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16537" target="_blank">04:35:37.360</a></span> | <span class="t">So for the keys, for example, if we have only two heads for the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16541" target="_blank">04:35:41.920</a></span> | <span class="t">we will compress these tokens into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16544" target="_blank">04:35:44.420</a></span> | <span class="t">256 dimensions so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16547" target="_blank">04:35:47.520</a></span> | <span class="t">every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16549" target="_blank">04:35:49.960</a></span> | <span class="t">Four heads of the query will have one head for the key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16554" target="_blank">04:35:54.300</a></span> | <span class="t">Imagine we have four heads for the keys and values then we will have this one will be four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16559" target="_blank">04:35:59.000</a></span> | <span class="t">So what will happen is that every two heads of the query will be using one and this one will become 512</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16566" target="_blank">04:36:06.640</a></span> | <span class="t">Every two head of the query will share one head of the keys. So the total data transfer is reduced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16573" target="_blank">04:36:13.240</a></span> | <span class="t">So we speed up the computation of the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16575" target="_blank">04:36:15.920</a></span> | <span class="t">Of course, you may be wondering but this should also reduce the quality of the model because we have less parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16582" target="_blank">04:36:22.120</a></span> | <span class="t">We have less expressive power for the keys and values and it's true</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16586" target="_blank">04:36:26.040</a></span> | <span class="t">So if you look at the paper, they say that in the multi query attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16590" target="_blank">04:36:30.300</a></span> | <span class="t">It reduces the quality of the model, but not much so it's something that we can afford to lose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16596" target="_blank">04:36:36.360</a></span> | <span class="t">and the group query attention is basically a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16599" target="_blank">04:36:39.080</a></span> | <span class="t">Let's check group query attention paper, which is this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16604" target="_blank">04:36:44.560</a></span> | <span class="t">So in the multi query attention, you have one head for the keys and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16610" target="_blank">04:36:50.120</a></span> | <span class="t">Which is shared for all the heads of the queries in the group query attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16614" target="_blank">04:36:54.480</a></span> | <span class="t">We have a group of heads for the queries sharing one head of the key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16621" target="_blank">04:37:01.280</a></span> | <span class="t">So when you have multi query attention, you have only one head here for the query and the keys and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16627" target="_blank">04:37:07.440</a></span> | <span class="t">When you have a group query attention, you have multiple heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16631" target="_blank">04:37:11.160</a></span> | <span class="t">Of the keys sharing one head of the queries sharing one head of the keys and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16636" target="_blank">04:37:16.760</a></span> | <span class="t">So basically the multi query attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16639" target="_blank">04:37:19.260</a></span> | <span class="t">Multi query attention, which is only using one head for the keys and values reduces a lot of the quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16644" target="_blank">04:37:24.720</a></span> | <span class="t">a good compromise is between the full multi head attention and multi query attention is the group query attention which reduces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16652" target="_blank">04:37:32.700</a></span> | <span class="t">Slightly less the quality of the model, but still gives you this computational advantage of reducing the quantity of data transfer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16659" target="_blank">04:37:39.960</a></span> | <span class="t">another very big advantage of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16662" target="_blank">04:37:42.440</a></span> | <span class="t">Group query attention is that you reduce the size of the KB cache because as you remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16667" target="_blank">04:37:47.480</a></span> | <span class="t">We have one KB cache for each layer and in each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16670" target="_blank">04:37:50.720</a></span> | <span class="t">KB cache we need to save each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16674" target="_blank">04:37:54.320</a></span> | <span class="t">so if we compress these tokens the total amount of memory required for the KB cache reduces them and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16681" target="_blank">04:38:01.120</a></span> | <span class="t">Actually, the KB cache is also one of the bottlenecks in today's language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16686" target="_blank">04:38:06.280</a></span> | <span class="t">So we have these big language models that are like 70 billion parameters or whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16692" target="_blank">04:38:12.940</a></span> | <span class="t">But the the problem using them is not even actually the GPU memory requirement just for storing the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16700" target="_blank">04:38:20.700</a></span> | <span class="t">But actually for storing this big KB cache because you have to store each single token in each of the layers of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16706" target="_blank">04:38:26.920</a></span> | <span class="t">Which actually grows very fast if you have a lot of tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16709" target="_blank">04:38:29.960</a></span> | <span class="t">Okay. Now that we have seen how the group query attention works, we can proceed further</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16715" target="_blank">04:38:35.520</a></span> | <span class="t">Let's continue our journey</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16720" target="_blank">04:38:40.400</a></span> | <span class="t">So the next part that we need is this beautiful thing called the rotary positional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16725" target="_blank">04:38:45.560</a></span> | <span class="t">Encodings that I will not explain right now. We I will explain them after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16729" target="_blank">04:38:49.260</a></span> | <span class="t">Explaining completing the attention module</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16732" target="_blank">04:38:52.380</a></span> | <span class="t">for now, we just consider them as a black box that adds some information encodes the information of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16738" target="_blank">04:38:58.300</a></span> | <span class="t">Position in the tokens and later we will see how it works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16741" target="_blank">04:39:01.700</a></span> | <span class="t">Let's implement the forward method. So the forward method is this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16747" target="_blank">04:39:07.140</a></span> | <span class="t">so basically it takes the hidden states, which is the input to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16752" target="_blank">04:39:12.140</a></span> | <span class="t">After the in the decoder layer is the output of the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16756" target="_blank">04:39:16.300</a></span> | <span class="t">RMS normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16759" target="_blank">04:39:19.180</a></span> | <span class="t">Then we have the attention mask the position in the position that we need to apply to each token because we need to apply the positional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16765" target="_blank">04:39:25.300</a></span> | <span class="t">Encodings and then the KB cache in case we are using it and now we will implement it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16770" target="_blank">04:39:30.020</a></span> | <span class="t">So the computation of the attention is the same as before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16773" target="_blank">04:39:33.220</a></span> | <span class="t">Let me copy a big part. So like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16778" target="_blank">04:39:38.180</a></span> | <span class="t">The first thing we do is we extract the batch size and what how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16781" target="_blank">04:39:41.880</a></span> | <span class="t">What is the length of the queries?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16785" target="_blank">04:39:45.120</a></span> | <span class="t">So what is the length of the input sequence because as you remember when we do token generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16790" target="_blank">04:39:50.220</a></span> | <span class="t">During the prefilling the QLAN will be all the inputs prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16794" target="_blank">04:39:54.900</a></span> | <span class="t">But then during token generation the Q will only be one single token because we want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16800" target="_blank">04:40:00.060</a></span> | <span class="t">Generate all the last part of the attention matrix. So the last row so we need only one query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16805" target="_blank">04:40:05.580</a></span> | <span class="t">But how can we have all the keys to attend to because we have something called the KB cache which will store all the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16811" target="_blank">04:40:11.580</a></span> | <span class="t">So what we are computing here is the same as before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16815" target="_blank">04:40:15.860</a></span> | <span class="t">So we are converting the input sequence into query key and values and then we are splitting this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16822" target="_blank">04:40:22.300</a></span> | <span class="t">Embeddings into groups of dimensions based on how many heads we have for the query key and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16831" target="_blank">04:40:31.020</a></span> | <span class="t">For the query, we will split it into numHeads number of groups</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16835" target="_blank">04:40:35.100</a></span> | <span class="t">Each number or each group will have headDim number of dimensions and for the keys and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16841" target="_blank">04:40:41.420</a></span> | <span class="t">We will have numKeyValueHeads number of groups and each group will have headDim number of dimensions to manage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16848" target="_blank">04:40:48.620</a></span> | <span class="t">Then we do this transposition so I can show you again. What does this transposition do? So let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16855" target="_blank">04:40:55.500</a></span> | <span class="t">Let's go back to our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16858" target="_blank">04:40:58.780</a></span> | <span class="t">here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16860" target="_blank">04:41:00.980</a></span> | <span class="t">So the first part that we are doing here big up to the transposition is this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16866" target="_blank">04:41:06.740</a></span> | <span class="t">So we are multiplying the input sequence with WQWK and WV and splitting these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16873" target="_blank">04:41:13.220</a></span> | <span class="t">embeddings into heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16875" target="_blank">04:41:15.780</a></span> | <span class="t">So that each embedding is a group is a list of groups where each group is managing some dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16883" target="_blank">04:41:23.780</a></span> | <span class="t">So now what we end up is basically a sequence of what?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16888" target="_blank">04:41:28.100</a></span> | <span class="t">Tokens where each token is made up of groups and each group is managing for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16893" target="_blank">04:41:33.020</a></span> | <span class="t">128 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16895" target="_blank">04:41:35.420</a></span> | <span class="t">Then we use this transposition because we want to have at the first dimension the heads dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16902" target="_blank">04:41:42.660</a></span> | <span class="t">So that we have a structure like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16905" target="_blank">04:41:45.260</a></span> | <span class="t">So instead of having a sequence of tokens where each token has groups of dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16911" target="_blank">04:41:51.300</a></span> | <span class="t">We want a list of groups where each group is a head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16915" target="_blank">04:41:55.420</a></span> | <span class="t">Each head has some tokens how many equal to the sequence length and each token is a mini token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16923" target="_blank">04:42:03.840</a></span> | <span class="t">Which is the dimensions dedicated to that specific head. So the head number one will have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16929" target="_blank">04:42:09.460</a></span> | <span class="t">128 dimensions the head number two will have the next number group of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16934" target="_blank">04:42:14.420</a></span> | <span class="t">120 dimensions etc until the last one which will have the last group of 128 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16940" target="_blank">04:42:20.580</a></span> | <span class="t">This allow us to compute the multi-head attention this for this using this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16946" target="_blank">04:42:26.180</a></span> | <span class="t">Sequence this sequence this sequence and this sequence all in parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16951" target="_blank">04:42:31.620</a></span> | <span class="t">Okay, and this is the meaning of this transposition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16957" target="_blank">04:42:37.520</a></span> | <span class="t">Transpose the next thing that we do is we apply the rotary positional encodings and now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16964" target="_blank">04:42:44.020</a></span> | <span class="t">We didn't talk about the rotary positional encodings and we will talk about later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16968" target="_blank">04:42:48.540</a></span> | <span class="t">But for now, you need to think that we are not changing the shape of these keys and queries and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16975" target="_blank">04:42:55.220</a></span> | <span class="t">We are just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16977" target="_blank">04:42:57.100</a></span> | <span class="t">modifying them by adding some information that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16980" target="_blank">04:43:00.540</a></span> | <span class="t">Encodes their position and it will be done by this method called apply rotary positional embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16986" target="_blank">04:43:06.580</a></span> | <span class="t">We will see later how it works for now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16990" target="_blank">04:43:10.060</a></span> | <span class="t">just think that in the query and the keys we have encoded some information which will be leveraged by the attention mechanism to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=16998" target="_blank">04:43:18.020</a></span> | <span class="t">Relate tokens to each other differently based on their position basically, but we will see that later. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17004" target="_blank">04:43:24.100</a></span> | <span class="t">Suppose that we have already encoded the positional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17007" target="_blank">04:43:27.200</a></span> | <span class="t">Information. So now we need to as you remember when we do work with the KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17012" target="_blank">04:43:32.460</a></span> | <span class="t">we pass only one single token as input to the layers of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17018" target="_blank">04:43:38.620</a></span> | <span class="t">Transformer and this single token is added to the KV cache in the keys and the values cache of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17027" target="_blank">04:43:47.020</a></span> | <span class="t">Particular layer then we retrieve the content of this KV cache which includes the newly added the token and all the previously saved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17034" target="_blank">04:43:54.660</a></span> | <span class="t">token and then we use this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17036" target="_blank">04:43:56.940</a></span> | <span class="t">Output of this KV cache to calculate the attention. So let's implement this KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17042" target="_blank">04:44:02.980</a></span> | <span class="t">so it's very simple because it's only one method to implement which basically will just take the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17048" target="_blank">04:44:08.500</a></span> | <span class="t">Single token that we are sending in which is this key states will add it to the key cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17053" target="_blank">04:44:13.940</a></span> | <span class="t">will take this value states which is one single token add it to the value cache and then retrieve all the content of the cache as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17060" target="_blank">04:44:20.860</a></span> | <span class="t">Output so all the past token it has seen plus the current one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17065" target="_blank">04:44:25.060</a></span> | <span class="t">So let's implement it and we go to the beginning of the file</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17070" target="_blank">04:44:30.100</a></span> | <span class="t">here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17073" target="_blank">04:44:33.500</a></span> | <span class="t">Class KV cache. Let's do it like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17078" target="_blank">04:44:38.740</a></span> | <span class="t">So we create a constructor as you can see it is a kind of a buffer where that includes one buffer for each layer of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17084" target="_blank">04:44:44.940</a></span> | <span class="t">the model one for the keys and one for the values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17088" target="_blank">04:44:48.980</a></span> | <span class="t">We also have this helper method that allow that tells us how many items the KV cache currently stores</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17096" target="_blank">04:44:56.780</a></span> | <span class="t">So if this KV cache does not contain any item we say zero if it contains something then we return</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17103" target="_blank">04:45:03.060</a></span> | <span class="t">What is the number of items it stores which as you remember when we add the something to the KV cache we are adding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17110" target="_blank">04:45:10.100</a></span> | <span class="t">This tensor here, which is the key value states and value states which are tensors of this shape</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17117" target="_blank">04:45:17.700</a></span> | <span class="t">So batch size and number of heads sequence length and head dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17121" target="_blank">04:45:21.540</a></span> | <span class="t">Which means that the sequence length is the second last dimension. So that's why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17127" target="_blank">04:45:27.700</a></span> | <span class="t">We return the second last dimensions to retrieve the sequence lengths currently stored in the KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17133" target="_blank">04:45:33.060</a></span> | <span class="t">We then implement the update method which is also very simple and I added some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17139" target="_blank">04:45:39.540</a></span> | <span class="t">comments to it to make it simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17141" target="_blank">04:45:41.900</a></span> | <span class="t">So basically it means that it this will add the content of this key states and value states to the KV cache of this layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17149" target="_blank">04:45:49.620</a></span> | <span class="t">And then it will return whatever is stored for this layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17153" target="_blank">04:45:53.820</a></span> | <span class="t">So if we have never added anything to the KV cache of this layer, then we create it. So we basically append this tensors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17160" target="_blank">04:46:00.900</a></span> | <span class="t">It means that we have nothing else to concatenate it with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17164" target="_blank">04:46:04.660</a></span> | <span class="t">However, if we otherwise we are we already have some tokens in the key cache and the value cache of this particular layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17171" target="_blank">04:46:11.540</a></span> | <span class="t">Then we concatenate whatever is already present with the newly incoming token along which dimension along the sequence dimension and the sequence dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17179" target="_blank">04:46:19.620</a></span> | <span class="t">We saw before is the dimension -2. That's why we concatenate them along the dimension -2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17184" target="_blank">04:46:24.960</a></span> | <span class="t">so after concatenating them we retrieve all the content of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17189" target="_blank">04:46:29.340</a></span> | <span class="t">K and V cache and return it for the current layer and this is what is happening here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17195" target="_blank">04:46:35.340</a></span> | <span class="t">Here so we add this incoming key values and key states and value states to the KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17203" target="_blank">04:46:43.420</a></span> | <span class="t">Then we retrieve them and we use them to compute the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17206" target="_blank">04:46:46.900</a></span> | <span class="t">Now you need to remember that when we do use the KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17210" target="_blank">04:46:50.700</a></span> | <span class="t">There are two phases when working with the model with the KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17214" target="_blank">04:46:54.700</a></span> | <span class="t">There is one part called the prefilling in which we have the prompt the prompt in our case will be the image tokens plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17220" target="_blank">04:47:00.640</a></span> | <span class="t">The user prompt so the what the user wants the model to do with this image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17225" target="_blank">04:47:05.920</a></span> | <span class="t">It will be a list of tokens. So this key states and this value states will be a list of tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17232" target="_blank">04:47:12.220</a></span> | <span class="t">So they will be all added to the cache for the first time because initially the cache will be empty and will be retrieved here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17238" target="_blank">04:47:18.380</a></span> | <span class="t">When we do token generation, we use the last token output by the model and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17243" target="_blank">04:47:23.020</a></span> | <span class="t">We add it one at a time to the KV cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17246" target="_blank">04:47:26.660</a></span> | <span class="t">But we always retrieve all the content of the KV cache to compute the attention because the each query needs to attend all the past</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17253" target="_blank">04:47:33.620</a></span> | <span class="t">keys and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17255" target="_blank">04:47:35.620</a></span> | <span class="t">It needs to attend all the past keys which are then used to compute the weighted sum using the values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17262" target="_blank">04:47:42.760</a></span> | <span class="t">Um, okay, what is the next part of the computation of the attention? Well, well, well here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17270" target="_blank">04:47:50.300</a></span> | <span class="t">we have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17273" target="_blank">04:47:53.180</a></span> | <span class="t">repeat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17275" target="_blank">04:47:55.400</a></span> | <span class="t">Now we need this method called the repeat KV which basically will repeat the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17280" target="_blank">04:48:00.560</a></span> | <span class="t">dimension of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17283" target="_blank">04:48:03.560</a></span> | <span class="t">Of the keys and values that are missing for the heads of the query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17291" target="_blank">04:48:11.880</a></span> | <span class="t">Um, okay, let me explain it with the iPad because it's much easier to draw than to explain by words. So let's go here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17299" target="_blank">04:48:19.880</a></span> | <span class="t">Let's go here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17303" target="_blank">04:48:23.980</a></span> | <span class="t">Okay. So what happens with this repeat method is that we have the projection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17310" target="_blank">04:48:30.160</a></span> | <span class="t">Through WK and WV of the token that results in a smaller token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17316" target="_blank">04:48:36.680</a></span> | <span class="t">Which gives us some benefit from the KV cache point of view for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17320" target="_blank">04:48:40.500</a></span> | <span class="t">But to compute the attention each head needs to share the heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17325" target="_blank">04:48:45.360</a></span> | <span class="t">Each query heads needs to share the head with other query heads when working with the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17332" target="_blank">04:48:52.440</a></span> | <span class="t">so for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17333" target="_blank">04:48:53.760</a></span> | <span class="t">The first two heads of the query needs to share one head for the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17337" target="_blank">04:48:57.920</a></span> | <span class="t">Then the second two heads for the query needs to share one head for the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17341" target="_blank">04:49:01.920</a></span> | <span class="t">what we do is basically we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17345" target="_blank">04:49:05.360</a></span> | <span class="t">Repeat this because we are working with the naive implementation of the attention which does not really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17352" target="_blank">04:49:12.040</a></span> | <span class="t">Actually benefit from this optimization. So what we do is basically we just repeat the missing heads as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17358" target="_blank">04:49:18.940</a></span> | <span class="t">You can see here. So we we take the heads that are missing and we just repeat them to match the heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17366" target="_blank">04:49:26.360</a></span> | <span class="t">to match the heads of the query so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17371" target="_blank">04:49:31.580</a></span> | <span class="t">Like this one so that it's like each head each query head which has its own head also for the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17377" target="_blank">04:49:37.480</a></span> | <span class="t">This is because actually we are not creating a custom CUDA kernel for the computation of the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17383" target="_blank">04:49:43.240</a></span> | <span class="t">So we repeat it and we just pretend like the grouped query attention never happened</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17389" target="_blank">04:49:49.840</a></span> | <span class="t">but for example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17390" target="_blank">04:49:50.760</a></span> | <span class="t">If you use a flash attention flash attention actually leverages the reduced number of heads of the keys and values to optimize the computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17398" target="_blank">04:49:58.680</a></span> | <span class="t">of the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17400" target="_blank">04:50:00.560</a></span> | <span class="t">So basically we are kind of reversing the effect of grouped query attention when calculating the attention because we don't have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17407" target="_blank">04:50:07.440</a></span> | <span class="t">Custom CUDA kernel that can leverage this by not copying the missing heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17411" target="_blank">04:50:11.720</a></span> | <span class="t">The repeatKV function is very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17416" target="_blank">04:50:16.680</a></span> | <span class="t">So we can implement that as well because it will just repeat the heads that are missing for the keys and values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17423" target="_blank">04:50:23.000</a></span> | <span class="t">So let's implement it here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17427" target="_blank">04:50:27.360</a></span> | <span class="t">As you can see if we have a tensor and we know that this tensor has the following shape</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17432" target="_blank">04:50:32.920</a></span> | <span class="t">So the batch the number of heads the sequence length and the head dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17436" target="_blank">04:50:36.840</a></span> | <span class="t">If we only need to repeat it once then we just return it because we don't have to repeat anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17441" target="_blank">04:50:41.720</a></span> | <span class="t">otherwise, we introduce a new dimension, which is how many times we want to repeat this number of heads and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17449" target="_blank">04:50:49.180</a></span> | <span class="t">We do this reshaping which will basically repeat this number of heads that much number of time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17457" target="_blank">04:50:57.040</a></span> | <span class="t">Actually, the repetition is done by the expand method here. So we introduce a new dimension here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17462" target="_blank">04:51:02.640</a></span> | <span class="t">Which is the number of repetitions and then we expand it. This expansion basically repeats whatever content is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17469" target="_blank">04:51:09.440</a></span> | <span class="t">This content here for each of the heads in the nrep heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17475" target="_blank">04:51:15.540</a></span> | <span class="t">So basically we are repeating whatever comes after these two dimensions this number of times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17482" target="_blank">04:51:22.680</a></span> | <span class="t">and then we remove this helper dimension that we have created the nrep dimension that we only created to repeat the number of heads and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17490" target="_blank">04:51:30.680</a></span> | <span class="t">How do we do it? We must multiply the number of repetitions that we need with the number of key value heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17497" target="_blank">04:51:37.320</a></span> | <span class="t">So at the output of this method the number of heads that you will have is the same as the number of heads of the query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17503" target="_blank">04:51:43.600</a></span> | <span class="t">So let's go back here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17505" target="_blank">04:51:45.920</a></span> | <span class="t">So now it will this key states and value states will have the same number of heads as the query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17511" target="_blank">04:51:51.400</a></span> | <span class="t">So now we can just compute the attention like we have always been doing so by doing the query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17515" target="_blank">04:51:55.640</a></span> | <span class="t">Multiplied by the transpose of the keys divided by the square root of the model, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17519" target="_blank">04:51:59.760</a></span> | <span class="t">So let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17522" target="_blank">04:52:02.440</a></span> | <span class="t">We also add the attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17525" target="_blank">04:52:05.880</a></span> | <span class="t">so we compute the attention weights just like this standard formula query multiplied by the transpose of the keys divided by the square root of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17532" target="_blank">04:52:12.520</a></span> | <span class="t">The D model the model is the number of dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17535" target="_blank">04:52:15.200</a></span> | <span class="t">managed by each head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17538" target="_blank">04:52:18.120</a></span> | <span class="t">We then add the attention mask right before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17541" target="_blank">04:52:21.800</a></span> | <span class="t">Using the softmax. So the attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17545" target="_blank">04:52:25.360</a></span> | <span class="t">That's why we in our case will always be made of zeros because we don't have any padding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17550" target="_blank">04:52:30.440</a></span> | <span class="t">so we don't need to mask anything and also during the prefilling we don't mask anything because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17554" target="_blank">04:52:34.360</a></span> | <span class="t">We always let the prompt the user prompt. So the text prompt to also attend feature tokens. Why? Because the polygamma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17562" target="_blank">04:52:42.500</a></span> | <span class="t">Autors made this decision and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17566" target="_blank">04:52:46.800</a></span> | <span class="t">They decided that the prompt the user prompt or the task prompt does not need to be causal because anyway</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17573" target="_blank">04:52:53.480</a></span> | <span class="t">It will never be generated by the model. It will always be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17575" target="_blank">04:52:55.840</a></span> | <span class="t">set by the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17578" target="_blank">04:52:58.680</a></span> | <span class="t">So we apply the softmax and then the dropout but the dropout we never have so this stuff here is very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17586" target="_blank">04:53:06.560</a></span> | <span class="t">So we apply the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17588" target="_blank">04:53:08.480</a></span> | <span class="t">Row by row then we apply the dropout but the dropout is always zero and we as you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17593" target="_blank">04:53:13.380</a></span> | <span class="t">The dropout is only applied during training but just ignore it like it's not there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17597" target="_blank">04:53:17.960</a></span> | <span class="t">Then the output of the multi head attention is multiplied by the value states</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17604" target="_blank">04:53:24.160</a></span> | <span class="t">So this attention weights is multiplied by the value state value matrix, which will result in that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17611" target="_blank">04:53:31.700</a></span> | <span class="t">weighted sum we saw before so each token is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17615" target="_blank">04:53:35.920</a></span> | <span class="t">an aggregation of previous tokens based on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17620" target="_blank">04:53:40.440</a></span> | <span class="t">Score defined in the attention matrix. So if you want to visualize it again, I can show it to you again. So let's go here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17627" target="_blank">04:53:47.640</a></span> | <span class="t">When we do the multiplication with the V which is here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17632" target="_blank">04:53:52.860</a></span> | <span class="t">Basically this output token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17636" target="_blank">04:53:56.240</a></span> | <span class="t">Let's say this one here is a contextualized token and that will include information about three tokens. I love pepperoni and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17643" target="_blank">04:54:03.640</a></span> | <span class="t">It will be a weighted sum of these three tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17648" target="_blank">04:54:08.240</a></span> | <span class="t">So I love pepperoni based on the following weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17651" target="_blank">04:54:11.440</a></span> | <span class="t">So basically the token I will contribute to 20% of information the token love will contribute to 40% of information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17658" target="_blank">04:54:18.640</a></span> | <span class="t">The token pepperoni will contribute 40% of information and the last token will not contribute any information because it has been masked out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17665" target="_blank">04:54:25.880</a></span> | <span class="t">So this is what happens when you multiply the V that you are doing a weighted sum using the attention weights as weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17675" target="_blank">04:54:35.840</a></span> | <span class="t">Then what else we need to do we need to check okay the output shape and that's fine I can do that so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17683" target="_blank">04:54:43.060</a></span> | <span class="t">we do this one and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17685" target="_blank">04:54:45.680</a></span> | <span class="t">Then we transpose back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17688" target="_blank">04:54:48.160</a></span> | <span class="t">Like we did before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17691" target="_blank">04:54:51.360</a></span> | <span class="t">So we transpose back to have again the sequence length as the second dimension then the num heads as the third dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17698" target="_blank">04:54:58.200</a></span> | <span class="t">then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17701" target="_blank">04:55:01.000</a></span> | <span class="t">Concatenate all the heads together just like we saw before so now each token is back to the head hidden size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17708" target="_blank">04:55:08.400</a></span> | <span class="t">Dimension where this hidden size is the concatenation of the output of each head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17713" target="_blank">04:55:13.740</a></span> | <span class="t">but we if you just concatenate the output of these heads then the each embedding will just be an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17721" target="_blank">04:55:21.800</a></span> | <span class="t">Independent calculation of each head concatenated together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17725" target="_blank">04:55:25.640</a></span> | <span class="t">So we need some kind of mixing mechanism and this mixing mechanism is given by WO which will mix all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17732" target="_blank">04:55:32.880</a></span> | <span class="t">Dimensions with each other so that the result of each head is kind of mixed with each other through this WO projection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17740" target="_blank">04:55:40.240</a></span> | <span class="t">So that this output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17742" target="_blank">04:55:42.400</a></span> | <span class="t">Token from this multi head attention is not just a concatenation of multiple independent heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17749" target="_blank">04:55:49.520</a></span> | <span class="t">But it's something that is also mixing the results of this independent heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17754" target="_blank">04:55:54.600</a></span> | <span class="t">And then we result will return the result of this multi head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17759" target="_blank">04:55:59.240</a></span> | <span class="t">Now one thing that we have considered as a black box so far is the rotary positional encoding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17765" target="_blank">04:56:05.280</a></span> | <span class="t">So we have said okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17766" target="_blank">04:56:06.800</a></span> | <span class="t">we are encoding somehow the positional encodings in these queries and keys and then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17773" target="_blank">04:56:13.040</a></span> | <span class="t">Multi head attention will leverage it now. It's time to expand on that and understand how it works. So let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17780" target="_blank">04:56:20.320</a></span> | <span class="t">All right. So let's talk about positional encoding guys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17783" target="_blank">04:56:23.800</a></span> | <span class="t">so traditionally we are used to work with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17787" target="_blank">04:56:27.720</a></span> | <span class="t">Positional encodings applied directly at the entrance of the transformer, which means that we take some embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17794" target="_blank">04:56:34.400</a></span> | <span class="t">So we transform we have our tokens which indicates the position of the token in the vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17800" target="_blank">04:56:40.180</a></span> | <span class="t">We convert them into embeddings using the embedding layer, which is this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17805" target="_blank">04:56:45.040</a></span> | <span class="t">And then we add some other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17810" target="_blank">04:56:50.020</a></span> | <span class="t">Vectors to these embeddings that encode the position information of each token because otherwise the model has no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17816" target="_blank">04:56:56.200</a></span> | <span class="t">notion of position the model treats each token as you as you saw before each head just does a dot product of two tokens and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17824" target="_blank">04:57:04.320</a></span> | <span class="t">If the position information is not encoded in these two tokens that the dot product can only access the embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17830" target="_blank">04:57:10.840</a></span> | <span class="t">So it does not have any notion of which token comes first and which comes later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17836" target="_blank">04:57:16.180</a></span> | <span class="t">So to encode this information, we basically traditionally we are used to add a positional encoding here to the embeddings of each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17844" target="_blank">04:57:24.080</a></span> | <span class="t">Token and so that the embeddings basically encode the information of the position in the original transformer paper. They proposed this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17851" target="_blank">04:57:31.540</a></span> | <span class="t">sinusoidal positional encodings which are also known as absolute positional encodings because they encode the absolute position in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17859" target="_blank">04:57:39.240</a></span> | <span class="t">Inside each token. So the token number one will have some dimensions some vector that will encode the position number one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17865" target="_blank">04:57:45.980</a></span> | <span class="t">The token number five in the sentence will have the position number five added to it, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17871" target="_blank">04:57:51.060</a></span> | <span class="t">What we use in most language models nowadays is the rotary positional encodings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17877" target="_blank">04:57:57.580</a></span> | <span class="t">Which are in the family of the relative positional encodings and they work as follows. So let's open the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17883" target="_blank">04:58:03.420</a></span> | <span class="t">They were introduced in this paper called the raw former enhanced transformer with rotary positional embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17893" target="_blank">04:58:13.740</a></span> | <span class="t">Basically the idea with the this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17895" target="_blank">04:58:15.820</a></span> | <span class="t">Positional encodings is that we do not add them directly to the embedding of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17902" target="_blank">04:58:22.420</a></span> | <span class="t">so that each token encodes the information of its position, but they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17906" target="_blank">04:58:26.060</a></span> | <span class="t">modify the attention mechanism in such a way that the attention mechanism takes into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17912" target="_blank">04:58:32.100</a></span> | <span class="t">Consideration the position of the tokens to relate them differently based on their position. Let's see how they did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17918" target="_blank">04:58:38.580</a></span> | <span class="t">So basically in the paper they say okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17922" target="_blank">04:58:42.580</a></span> | <span class="t">We have this multi multi head attention mechanism that uses the dot product as to relate tokens to each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17929" target="_blank">04:58:49.720</a></span> | <span class="t">so they said okay, can we find an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17932" target="_blank">04:58:52.780</a></span> | <span class="t">encoding of the embedding vectors of tokens such that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17938" target="_blank">04:58:58.080</a></span> | <span class="t">When we do the dot product, which is an inner product. So this sign here means the inner product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17943" target="_blank">04:59:03.980</a></span> | <span class="t">So can we find an encoding for the token called FQ for the query and FK for the keys?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17951" target="_blank">04:59:11.380</a></span> | <span class="t">that encodes the position information inside the embedding XM for the query and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17957" target="_blank">04:59:17.940</a></span> | <span class="t">XN for the keys such that when we do the dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17962" target="_blank">04:59:22.900</a></span> | <span class="t">So this function G</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17964" target="_blank">04:59:24.580</a></span> | <span class="t">this dot product, the output of this dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17967" target="_blank">04:59:27.140</a></span> | <span class="t">Only depends on the embedding of the first token the embedding of the second token and the relative distance between them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17975" target="_blank">04:59:35.120</a></span> | <span class="t">So that's why they are called relative positional encodings because they depend the dot product is modified</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17980" target="_blank">04:59:40.660</a></span> | <span class="t">so the attention mechanism is modified such that the dot product should depend only on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17986" target="_blank">04:59:46.660</a></span> | <span class="t">Embedding of the first token on the embedding of the second token and the relative distance between them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17992" target="_blank">04:59:52.940</a></span> | <span class="t">So we need to find a way to encode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=17996" target="_blank">04:59:56.120</a></span> | <span class="t">information inside of our embedding such that this dot product will depend only on the embedding of the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18003" target="_blank">05:00:03.740</a></span> | <span class="t">embedding of the second and the relative distance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18006" target="_blank">05:00:06.900</a></span> | <span class="t">so how to encode this information inside the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18010" target="_blank">05:00:10.060</a></span> | <span class="t">Embeddings. Well, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18012" target="_blank">05:00:12.740</a></span> | <span class="t">Proposed the following case for the 2D case. So imagine we have an embedding vector made up of only two dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18020" target="_blank">05:00:20.740</a></span> | <span class="t">How to encode the information of the position in this two-dimensional vector as follows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18029" target="_blank">05:00:29.420</a></span> | <span class="t">basically, we create a matrix that is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18034" target="_blank">05:00:34.260</a></span> | <span class="t">Rotation matrix. So if you have ever worked with the rotation matrix like when you do rotation of a vector in 2D space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18041" target="_blank">05:00:41.720</a></span> | <span class="t">you basically multiply the vector by this matrix here where the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18045" target="_blank">05:00:45.640</a></span> | <span class="t">Argument of the cosine and the sine is a multiple of an angle that defines by how much you want to rotate this vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18052" target="_blank">05:00:52.700</a></span> | <span class="t">by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18055" target="_blank">05:00:55.380</a></span> | <span class="t">So if we basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18058" target="_blank">05:00:58.380</a></span> | <span class="t">Multiply the two dimensions of this vector by this matrix here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18063" target="_blank">05:01:03.180</a></span> | <span class="t">Which is we will see what is it and then this matrix here, which is a rotation matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18068" target="_blank">05:01:08.700</a></span> | <span class="t">Then basically we are rotating this vector by some angle defined by this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18074" target="_blank">05:01:14.940</a></span> | <span class="t">M theta angle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18078" target="_blank">05:01:18.100</a></span> | <span class="t">This will encode the information so the output of this operation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18083" target="_blank">05:01:23.660</a></span> | <span class="t">So the output of this operation will be a 2D vector which will encode the information of the position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18090" target="_blank">05:01:30.260</a></span> | <span class="t">based on this position M</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18092" target="_blank">05:01:32.460</a></span> | <span class="t">Such that when we do the dot product of two vectors encoded like this, this dot product is guaranteed to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18100" target="_blank">05:01:40.740</a></span> | <span class="t">To be a function of the embedding of the first vector, embedding of the second vector and the relative distance that was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18110" target="_blank">05:01:50.620</a></span> | <span class="t">encoded into them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18112" target="_blank">05:01:52.980</a></span> | <span class="t">The difference of the distance that was encoded into them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18116" target="_blank">05:01:56.160</a></span> | <span class="t">Basically, but we usually when we have an embedding we do not have a 2D vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18124" target="_blank">05:02:04.540</a></span> | <span class="t">We have a multi-dimensional vector, maybe 1000 dimensions or 2000 dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18129" target="_blank">05:02:09.940</a></span> | <span class="t">So they take the 2D case to the general case and the general case basically they say okay instead of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18137" target="_blank">05:02:17.380</a></span> | <span class="t">multiplying the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18139" target="_blank">05:02:19.500</a></span> | <span class="t">token by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18141" target="_blank">05:02:21.820</a></span> | <span class="t">So instead of using this 2D rotation matrix, we need to have this big rotation matrix here for an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18147" target="_blank">05:02:27.900</a></span> | <span class="t">D-dimensional vector. So here is the d-dimensional vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18151" target="_blank">05:02:31.980</a></span> | <span class="t">If you look at this vector this matrix here as you can see it is a sparse matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18158" target="_blank">05:02:38.820</a></span> | <span class="t">Which means that it is mostly made up of zeros and only some elements are non zeros</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18164" target="_blank">05:02:44.580</a></span> | <span class="t">So if we encode the information using this transformation here by using this matrix here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18170" target="_blank">05:02:50.860</a></span> | <span class="t">We will be doing a computation that will result in the following property being verified</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18176" target="_blank">05:02:56.380</a></span> | <span class="t">which is that the when we do the dot product this dot product will only depend on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18181" target="_blank">05:03:01.140</a></span> | <span class="t">Embedding of the first token the embedding of the second token and the relative distance of the two positions that were that was encoded into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18188" target="_blank">05:03:08.580</a></span> | <span class="t">these tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18189" target="_blank">05:03:09.980</a></span> | <span class="t">But we will be doing a lot of unnecessary computations because a lot of zeros will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18194" target="_blank">05:03:14.780</a></span> | <span class="t">Will be multiplied by other elements which will result in zero. So we are doing a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18200" target="_blank">05:03:20.180</a></span> | <span class="t">computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18201" target="_blank">05:03:21.940</a></span> | <span class="t">Uselessly because in a sparse matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18203" target="_blank">05:03:23.940</a></span> | <span class="t">If most of the elements are non zeros and only some of them are non zeros</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18209" target="_blank">05:03:29.780</a></span> | <span class="t">That means that you are doing a lot of computations uselessly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18212" target="_blank">05:03:32.620</a></span> | <span class="t">Because you already know that in advance that they are going there. They are zeros</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18217" target="_blank">05:03:37.220</a></span> | <span class="t">So is there a better way to compute this encoding mechanism to reduce this unnecessary?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18224" target="_blank">05:03:44.860</a></span> | <span class="t">Computations knowing already that most of them are zeros and we also know where they should be zeros</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18230" target="_blank">05:03:50.660</a></span> | <span class="t">Well, yes, there is it is possible and they propose another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18234" target="_blank">05:03:54.500</a></span> | <span class="t">more computationally efficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18237" target="_blank">05:03:57.180</a></span> | <span class="t">realization of this matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18239" target="_blank">05:03:59.540</a></span> | <span class="t">Which basically says that if you want to encode the position information inside your tensor inside your embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18246" target="_blank">05:04:06.140</a></span> | <span class="t">You need to take the embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18248" target="_blank">05:04:08.900</a></span> | <span class="t">Here this so a d-dimensional vector because we know it's a d-dimensional vector. So where d can be 1000, 2000</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18254" target="_blank">05:04:14.940</a></span> | <span class="t">Whatever it is. Suppose in our case, it's 1024</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18258" target="_blank">05:04:18.180</a></span> | <span class="t">You multiply it element wise. So this is element wise multiplication by another matrix constructed as follows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18266" target="_blank">05:04:26.580</a></span> | <span class="t">Where the first element is a cosine of m theta 1 and the second element is cosine of m theta 1 etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18273" target="_blank">05:04:33.460</a></span> | <span class="t">Where m is the position that you want to encode in this vector and the theta 1 theta 2 are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18280" target="_blank">05:04:40.540</a></span> | <span class="t">Computed using the following formula here. So they show it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18284" target="_blank">05:04:44.900</a></span> | <span class="t">here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18287" target="_blank">05:04:47.500</a></span> | <span class="t">Theta I is equal to the 10,000 to the power of minus 2 I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18292" target="_blank">05:04:52.020</a></span> | <span class="t">Divide by D where I is from 0 to D divide by 2. I remember correctly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18297" target="_blank">05:04:57.620</a></span> | <span class="t">They show it here. Yeah, I goes from 1 to D divide by 2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18303" target="_blank">05:05:03.220</a></span> | <span class="t">so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18305" target="_blank">05:05:05.220</a></span> | <span class="t">Let's go back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18307" target="_blank">05:05:07.500</a></span> | <span class="t">So basically what we are doing is we are multiplying each dimension of this vector by a cosine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18313" target="_blank">05:05:13.140</a></span> | <span class="t">Where where the argument of the cosine is a multiple of a base theta</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18319" target="_blank">05:05:19.380</a></span> | <span class="t">Multiplied by the position of the token that we want to encode into this token plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18326" target="_blank">05:05:26.340</a></span> | <span class="t">The dimensions of this vector but rotated and with changed signs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18332" target="_blank">05:05:32.940</a></span> | <span class="t">Multiplied element wise with the sign of the same arguments that we use for the cosine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18338" target="_blank">05:05:38.780</a></span> | <span class="t">And if you encode your vector like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18342" target="_blank">05:05:42.540</a></span> | <span class="t">And when you do the dot product of two vectors encoded like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18347" target="_blank">05:05:47.060</a></span> | <span class="t">What will happen is that the dot product is guaranteed to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18350" target="_blank">05:05:50.980</a></span> | <span class="t">The number that comes out of this dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18354" target="_blank">05:05:54.460</a></span> | <span class="t">Will be depending on the embedding of the first vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18358" target="_blank">05:05:58.340</a></span> | <span class="t">So the information that was encoded before adding the positional encoding the embedding of the second vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18364" target="_blank">05:06:04.360</a></span> | <span class="t">So the information that was encoded in the vector before adding the positional encoding and the relative distance plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18370" target="_blank">05:06:10.580</a></span> | <span class="t">they also say that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18372" target="_blank">05:06:12.980</a></span> | <span class="t">Basically the rotary positional encoding also have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18377" target="_blank">05:06:17.260</a></span> | <span class="t">decaying effect based on the distance between two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18381" target="_blank">05:06:21.260</a></span> | <span class="t">which means that the dot product as we know the dot product is converted into a score by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18387" target="_blank">05:06:27.980</a></span> | <span class="t">Softmax, so it tells us how intense is the relationship between two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18393" target="_blank">05:06:33.020</a></span> | <span class="t">So the bigger the dot products the more that that token will contribute to the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18398" target="_blank">05:06:38.940</a></span> | <span class="t">Contextualized embedding as we saw before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18401" target="_blank">05:06:41.140</a></span> | <span class="t">So each of the attention scores tells us how much information that token will contribute to the output contextualized embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18408" target="_blank">05:06:48.900</a></span> | <span class="t">So with the rotary positional encoding what happened is that this dot product will modified in such a way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18416" target="_blank">05:06:56.500</a></span> | <span class="t">That the dot product will be high when two tokens are close and as they move apart</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18423" target="_blank">05:07:03.740</a></span> | <span class="t">So the distance between the two tokens for which we are doing the dot products grows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18428" target="_blank">05:07:08.940</a></span> | <span class="t">The dot product will decay will decrease in magnitude</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18433" target="_blank">05:07:13.820</a></span> | <span class="t">So the output number will be smaller and smaller and smaller based on the relative distance between the two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18439" target="_blank">05:07:19.740</a></span> | <span class="t">And they give a relative upper bound based on the relative distance between two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18446" target="_blank">05:07:26.380</a></span> | <span class="t">So, rehearse, to encode the positional information of a token using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18452" target="_blank">05:07:32.500</a></span> | <span class="t">Rotary positional encoding we need to do the following computation where we take the vector of the token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18459" target="_blank">05:07:39.380</a></span> | <span class="t">We multiply it by a special matrix constructed like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18462" target="_blank">05:07:42.820</a></span> | <span class="t">plus again the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18465" target="_blank">05:07:45.380</a></span> | <span class="t">Vector of the the token itself, but with dimensions changed in position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18471" target="_blank">05:07:51.260</a></span> | <span class="t">So first we create a special vector where we put first the second dimension of the vector, but with the change sign</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18478" target="_blank">05:07:58.300</a></span> | <span class="t">then the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18480" target="_blank">05:08:00.820</a></span> | <span class="t">Dimension then the fourth dimension with its sign change then the third dimension, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18486" target="_blank">05:08:06.860</a></span> | <span class="t">And then multiplied by a sign this matrix constructed as follows using the theta values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18493" target="_blank">05:08:13.940</a></span> | <span class="t">calculated according to this formula here this one here and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18499" target="_blank">05:08:19.820</a></span> | <span class="t">The each of this sign and cosine is basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18504" target="_blank">05:08:24.180</a></span> | <span class="t">Working with an argument that is a multiple of this base theta multiplied by the position that we want to encode into this token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18513" target="_blank">05:08:33.460</a></span> | <span class="t">And if you want to visualize in the rotary positional encoding paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18518" target="_blank">05:08:38.940</a></span> | <span class="t">They also say what is the meaning of this rotary positional encoding?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18522" target="_blank">05:08:42.860</a></span> | <span class="t">So basically each two dimension as you can see from this matrix here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18526" target="_blank">05:08:46.580</a></span> | <span class="t">Each two dimension are being rotated by the same angle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18530" target="_blank">05:08:50.300</a></span> | <span class="t">So basically it's we are have a token that is made up of many dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18535" target="_blank">05:08:55.780</a></span> | <span class="t">So each pair of dimensions is getting rotated like a 2d vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18540" target="_blank">05:09:00.500</a></span> | <span class="t">So each two dimensions are considered like a two dimensional vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18545" target="_blank">05:09:05.340</a></span> | <span class="t">Which is getting rotated by an angle that is a multiple of the base angle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18550" target="_blank">05:09:10.460</a></span> | <span class="t">Multiple with respect to the position that you want to encode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18555" target="_blank">05:09:15.020</a></span> | <span class="t">And this is the the meaning of the rotary positional encoding. So the rotary positional encoding to rehearse again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18561" target="_blank">05:09:21.820</a></span> | <span class="t">modify the attention mechanism in such a way that the attention score that is generated is dependent on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18569" target="_blank">05:09:29.580</a></span> | <span class="t">Relative distance between two tokens and they also prove in the paper that this attention score</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18574" target="_blank">05:09:34.940</a></span> | <span class="t">Decays as the distance between the token grows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18577" target="_blank">05:09:37.940</a></span> | <span class="t">Okay, now that we have seen how it works. Let's code it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18583" target="_blank">05:09:43.940</a></span> | <span class="t">And actually in the code that we are going to write you will see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18586" target="_blank">05:09:46.660</a></span> | <span class="t">I am going to use the HuggingFace implementation of the rotary positional encodings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18591" target="_blank">05:09:51.240</a></span> | <span class="t">And we will see that the rotary positional encoding that it's implemented in the HuggingFace library. It's slightly different from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18598" target="_blank">05:09:58.500</a></span> | <span class="t">Hugging with the formula that you see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18601" target="_blank">05:10:01.540</a></span> | <span class="t">Here this one here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18604" target="_blank">05:10:04.580</a></span> | <span class="t">But it according to the authors it results in the same computation. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18610" target="_blank">05:10:10.020</a></span> | <span class="t">They they do it this way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18612" target="_blank">05:10:12.020</a></span> | <span class="t">They I will also share the blog post in which they they explain why they do it this way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18617" target="_blank">05:10:17.060</a></span> | <span class="t">So it's a slightly difference, but the idea is the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18620" target="_blank">05:10:20.340</a></span> | <span class="t">So it will result in a slightly different calculation, but the effect is the same. So let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18624" target="_blank">05:10:24.980</a></span> | <span class="t">All right, let's implement this rotary positional encoding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18628" target="_blank">05:10:28.180</a></span> | <span class="t">So the first thing we need to create is this gamma rotary positional encoding class</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18633" target="_blank">05:10:33.060</a></span> | <span class="t">So for that we can do it. I think here it's same no problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18639" target="_blank">05:10:39.460</a></span> | <span class="t">Let's do it here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18641" target="_blank">05:10:41.460</a></span> | <span class="t">Okay, so then we are giving some parameters dim is the head dimensions because each head because the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18648" target="_blank">05:10:48.820</a></span> | <span class="t">Rotary positional encodings modify the attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18651" target="_blank">05:10:51.720</a></span> | <span class="t">The attention mechanism is performed independently for each attention heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18656" target="_blank">05:10:56.420</a></span> | <span class="t">So each head will have its own positional encoding applied to the tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18661" target="_blank">05:11:01.540</a></span> | <span class="t">So this dim is the set to the head dimension. So the number of dimensions managed by each head in the multi-head attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18669" target="_blank">05:11:09.060</a></span> | <span class="t">Then we have the max positional embeddings, which tells us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18671" target="_blank">05:11:11.700</a></span> | <span class="t">What is the maximum number of positions we can encode?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18675" target="_blank">05:11:15.460</a></span> | <span class="t">this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18677" target="_blank">05:11:17.540</a></span> | <span class="t">Set to 8000 actually in the gamma configuration here. It's initialized to 2000, but actually it will be overwritten</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18683" target="_blank">05:11:23.480</a></span> | <span class="t">And then we have the base parameter theta which is set to 10000 also in the original paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18689" target="_blank">05:11:29.940</a></span> | <span class="t">So let me show you from the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18692" target="_blank">05:11:32.100</a></span> | <span class="t">Let's go here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18699" target="_blank">05:11:39.220</a></span> | <span class="t">I think I can find it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18701" target="_blank">05:11:41.220</a></span> | <span class="t">Here as you can see, it's 10000 to the power of minus 2 id. So this stuff here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18707" target="_blank">05:11:47.460</a></span> | <span class="t">and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18709" target="_blank">05:11:49.540</a></span> | <span class="t">Then we have this inverse frequency. So this inverse frequency is just the formula you can see here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18715" target="_blank">05:11:55.380</a></span> | <span class="t">So 10000 to the power of minus 2 i divided by d where i goes from it's written here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18721" target="_blank">05:12:01.700</a></span> | <span class="t">i goes from 0 to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18724" target="_blank">05:12:04.100</a></span> | <span class="t">1 to d divided by half</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18726" target="_blank">05:12:06.580</a></span> | <span class="t">so d divided by 2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18728" target="_blank">05:12:08.580</a></span> | <span class="t">And so the formula we are using is actually I think this one here to calculate it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18733" target="_blank">05:12:13.940</a></span> | <span class="t">So 10000 to the power of minus 2 i divided by d</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18738" target="_blank">05:12:18.260</a></span> | <span class="t">So it's 10000 divided</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18740" target="_blank">05:12:20.900</a></span> | <span class="t">It's 10000 to the power of minus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18744" target="_blank">05:12:24.660</a></span> | <span class="t">Minus something but when you have the negative power, it means one over the same thing with the positive power</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18752" target="_blank">05:12:32.740</a></span> | <span class="t">So that's why we have one over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18756" target="_blank">05:12:36.080</a></span> | <span class="t">10000 to the power of the positive power. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18758" target="_blank">05:12:38.880</a></span> | <span class="t">Let me write it. Actually when you have x to the power of minus 3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18765" target="_blank">05:12:45.440</a></span> | <span class="t">It means 1 over x to the power of 3. So that's why you have 1 over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18771" target="_blank">05:12:51.200</a></span> | <span class="t">10000 to the power of something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18774" target="_blank">05:12:54.160</a></span> | <span class="t">And what is this something that we are raising to the power 10000 to?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18777" target="_blank">05:12:57.840</a></span> | <span class="t">It's a list of numbers that goes from 0 to dimension divided by 2 which is the i</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18785" target="_blank">05:13:05.280</a></span> | <span class="t">Divide by d where d is the number of dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18789" target="_blank">05:13:09.760</a></span> | <span class="t">So of the vector to which we will apply the rotary positional encoding which is according to this formula here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18796" target="_blank">05:13:16.320</a></span> | <span class="t">so i goes from 0 to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18798" target="_blank">05:13:18.560</a></span> | <span class="t">d divided by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18800" target="_blank">05:13:20.880</a></span> | <span class="t">d divided by 2 and d is the number of dimensions of the vector to which we apply the rotary positional encodings in our case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18806" target="_blank">05:13:26.800</a></span> | <span class="t">It's equal to the head dimensions because each head will have it positional encodings applied to it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18812" target="_blank">05:13:32.480</a></span> | <span class="t">We use this arrangement to generate a list of numbers from 0 to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18817" target="_blank">05:13:37.200</a></span> | <span class="t">d divided by 2. So basically it's a 0 to dim by skipping every 2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18823" target="_blank">05:13:43.040</a></span> | <span class="t">What else we need to do here I believe we need to go let me check</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18831" target="_blank">05:13:51.120</a></span> | <span class="t">Okay, so now we can implement the forward method of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18838" target="_blank">05:13:58.880</a></span> | <span class="t">So to calculate the rotary positional encodings we need to generate so now let me check the go back to the paper and then explain the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18846" target="_blank">05:14:06.720</a></span> | <span class="t">Forward method so to calculate to apply the rotary positional encodings. We need the vector itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18853" target="_blank">05:14:13.120</a></span> | <span class="t">Oops</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18854" target="_blank">05:14:14.800</a></span> | <span class="t">The vector itself and then we need to multiply each dimensions by some cosine and each dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18861" target="_blank">05:14:21.220</a></span> | <span class="t">Rotated and with its change its sign changed with some signs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18866" target="_blank">05:14:26.300</a></span> | <span class="t">computed as follows so given some positions we can for each position m compute the cosine and the sine that will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18874" target="_blank">05:14:34.300</a></span> | <span class="t">Needed to multiply by these vectors and this is what we do in the forward method here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18879" target="_blank">05:14:39.420</a></span> | <span class="t">We actually extract the cosines and the sines that will be applied to each tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18884" target="_blank">05:14:44.140</a></span> | <span class="t">Depending on the positions of these tokens. So for each token, we will have a different position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18890" target="_blank">05:14:50.700</a></span> | <span class="t">So this m parameter indicates the position of the token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18894" target="_blank">05:14:54.860</a></span> | <span class="t">So for each m we can compute the cosines and the sines and this is what we do in the forward method here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18900" target="_blank">05:15:00.220</a></span> | <span class="t">So we take the inverse frequency we add another the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18903" target="_blank">05:15:03.820</a></span> | <span class="t">Another dimension, which is I believe it's for the batch dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18908" target="_blank">05:15:08.880</a></span> | <span class="t">And then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18912" target="_blank">05:15:12.060</a></span> | <span class="t">Disable the auto cast so the auto cast in torch is for mixed precision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18916" target="_blank">05:15:16.700</a></span> | <span class="t">so I don't want to go too much into the detail of this stuff, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18921" target="_blank">05:15:21.500</a></span> | <span class="t">Mixed precision is basically when you train a when you train a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18925" target="_blank">05:15:25.500</a></span> | <span class="t">You don't have to work with the floating point 32 numbers always because the most modern gpus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18931" target="_blank">05:15:31.580</a></span> | <span class="t">They also support working with the 16 bit numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18934" target="_blank">05:15:34.940</a></span> | <span class="t">Which makes computations faster and also reduces the memory of these computations. Of course, you use a little bit of precision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18942" target="_blank">05:15:42.400</a></span> | <span class="t">But the the precision that you need for some operations is not necessary for some operations. You don't need that much precision. So the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18951" target="_blank">05:15:51.240</a></span> | <span class="t">multi-automatic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18953" target="_blank">05:15:53.240</a></span> | <span class="t">mixed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18954" target="_blank">05:15:54.680</a></span> | <span class="t">Precision, I think it's called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18956" target="_blank">05:15:56.680</a></span> | <span class="t">Handles this automatically for you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18960" target="_blank">05:16:00.280</a></span> | <span class="t">So it will use the smaller precision for the numbers when computing certain operations and higher precision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18966" target="_blank">05:16:06.600</a></span> | <span class="t">So 32-bit when computing other operations such that we are kind of we never lose much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18972" target="_blank">05:16:12.760</a></span> | <span class="t">quality in the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18976" target="_blank">05:16:16.280</a></span> | <span class="t">Probably here for the rotary positional encodings. We want to retain the full quality of so the full</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18982" target="_blank">05:16:22.600</a></span> | <span class="t">Precision, so we disable this automatic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18985" target="_blank">05:16:25.720</a></span> | <span class="t">Auto custom</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18989" target="_blank">05:16:29.400</a></span> | <span class="t">Okay, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18991" target="_blank">05:16:31.960</a></span> | <span class="t">We are basically multiplying each frequency by each position that we want to encode because as you can see from the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=18998" target="_blank">05:16:38.520</a></span> | <span class="t">So let's go here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19000" target="_blank">05:16:40.760</a></span> | <span class="t">We need to multiply this m by the base frequency. We have already the base frequencies in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19006" target="_blank">05:16:46.200</a></span> | <span class="t">infrequent freq expanded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19008" target="_blank">05:16:48.820</a></span> | <span class="t">So we are multiplying it by each m. So we are computing the arguments of this cosines and sines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19015" target="_blank">05:16:55.480</a></span> | <span class="t">here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19018" target="_blank">05:16:58.120</a></span> | <span class="t">We concatenate this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19020" target="_blank">05:17:00.120</a></span> | <span class="t">Cosines and sines. Why? Because we have them for dim divided by two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19025" target="_blank">05:17:05.640</a></span> | <span class="t">So for half the vector, but we need it for the entire vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19030" target="_blank">05:17:10.520</a></span> | <span class="t">And we are concatenating here. Now. This is actually different from what we do in the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19035" target="_blank">05:17:15.960</a></span> | <span class="t">because in the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19038" target="_blank">05:17:18.600</a></span> | <span class="t">We need to repeat each argument twice for each successive dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19045" target="_blank">05:17:25.240</a></span> | <span class="t">So for each two dimension, we need the same argument</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19048" target="_blank">05:17:28.200</a></span> | <span class="t">what we are doing here with the concatenation is actually we are taking this one then this one then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19055" target="_blank">05:17:35.400</a></span> | <span class="t">The theta 3 then theta 4 and then again, we are repeating theta 1 theta 2 theta 3 theta 4 instead of doing theta 1 theta 1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19062" target="_blank">05:17:42.200</a></span> | <span class="t">theta 2 theta 2 theta 3 theta 3 so the overall numbers of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19066" target="_blank">05:17:46.200</a></span> | <span class="t">Numbers that we will produce in the arguments that we produce is the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19071" target="_blank">05:17:51.480</a></span> | <span class="t">But instead of being like in the paper theta 1 theta 1 theta 2 theta 2 theta 3 theta 3 theta 4 theta 4 blah blah</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19079" target="_blank">05:17:59.000</a></span> | <span class="t">We are actually doing theta 1 theta 2 theta 3 and then we are repeating them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19085" target="_blank">05:18:05.080</a></span> | <span class="t">Theta 1 theta 2 theta 3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19087" target="_blank">05:18:07.720</a></span> | <span class="t">Why are we doing this? Now, it's a very long story, but basically it looks like when HuggingFace converted the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19096" target="_blank">05:18:16.200</a></span> | <span class="t">Weights of the model for example llama from the original pre-trained model into the HuggingFace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19105" target="_blank">05:18:25.100</a></span> | <span class="t">they permuted the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19107" target="_blank">05:18:27.800</a></span> | <span class="t">Projection the query and the key projection which is the embedding of the token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19115" target="_blank">05:18:35.320</a></span> | <span class="t">Each dimension was permuted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19117" target="_blank">05:18:37.580</a></span> | <span class="t">And then to accommodate for this permuted dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19122" target="_blank">05:18:42.940</a></span> | <span class="t">They are doing again a different computation for the rotary positional encodings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19128" target="_blank">05:18:48.840</a></span> | <span class="t">So the overall effect that will result from this computation is the same as the original paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19134" target="_blank">05:18:54.600</a></span> | <span class="t">but they are doing this double permutation because one permutation was already done when doing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19140" target="_blank">05:19:00.740</a></span> | <span class="t">Conversion of the script from the original pre-trained model to the HuggingFace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19144" target="_blank">05:19:04.260</a></span> | <span class="t">format</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19147" target="_blank">05:19:07.140</a></span> | <span class="t">And this issue is explored in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19149" target="_blank">05:19:09.940</a></span> | <span class="t">in the HuggingFace transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19153" target="_blank">05:19:13.300</a></span> | <span class="t">repository by this user who posted why the positional encodings are done differently than the paper and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19160" target="_blank">05:19:20.180</a></span> | <span class="t">authors the HuggingFace explained saying that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19164" target="_blank">05:19:24.020</a></span> | <span class="t">When they converted the weights from the original model to the HuggingFace model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19170" target="_blank">05:19:30.020</a></span> | <span class="t">They permuted the dimensions of the wq and wk and wq and wk are the projection metrics that are used to compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19177" target="_blank">05:19:37.940</a></span> | <span class="t">The query and the keys we apply the rotary positional encodings to the query and the keys. So we need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19183" target="_blank">05:19:43.140</a></span> | <span class="t">recompute do another permutation to counter effect the effect of the first permutation. So that's why the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19189" target="_blank">05:19:49.700</a></span> | <span class="t">The computation we are doing does not reflect exactly the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19193" target="_blank">05:19:53.380</a></span> | <span class="t">Let's go forward so we have created the argument of the cosine and the sine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19199" target="_blank">05:19:59.620</a></span> | <span class="t">so now we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19200" target="_blank">05:20:00.820</a></span> | <span class="t">compute the cosine and the sine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19202" target="_blank">05:20:02.820</a></span> | <span class="t">Doing with this argument. So when you calculate call the cosine function on a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19207" target="_blank">05:20:07.700</a></span> | <span class="t">tensor it will calculate the cosine using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19211" target="_blank">05:20:11.140</a></span> | <span class="t">Dimensions of this vector as arguments for the cosine and the same we do it for the sine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19216" target="_blank">05:20:16.340</a></span> | <span class="t">So the output of this forward method here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19219" target="_blank">05:20:19.860</a></span> | <span class="t">in the paper is basically this two thing here that we need for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19225" target="_blank">05:20:25.860</a></span> | <span class="t">Applying the rotary positional encoding to each vector and we have computed the cosine and the sine for each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19231" target="_blank">05:20:31.700</a></span> | <span class="t">Position that we have in our sequence. So for each m that we have in our sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19237" target="_blank">05:20:37.620</a></span> | <span class="t">So let me delete this stuff. Otherwise it remains in my notes forever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19241" target="_blank">05:20:41.700</a></span> | <span class="t">Let's go forward now. We need to implement another method called apply rotary positional embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19248" target="_blank">05:20:48.680</a></span> | <span class="t">Which we include here and which I also copied from HuggingFace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19254" target="_blank">05:20:54.580</a></span> | <span class="t">What we'll do basically, okay, this will add another dimension, which is the head dimension to these cosines and and sines that we pre-computed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19261" target="_blank">05:21:01.880</a></span> | <span class="t">Where did we pre-compute them? Well, we computed them here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19265" target="_blank">05:21:05.540</a></span> | <span class="t">So as you can see, we extract the cosines and the sines using the rotary positional encoding class that we have created before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19271" target="_blank">05:21:11.060</a></span> | <span class="t">Using the value states is not used. It's just used to extract the data type of the resulting vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19277" target="_blank">05:21:17.380</a></span> | <span class="t">And the position ids that we want to encode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19280" target="_blank">05:21:20.340</a></span> | <span class="t">So the m parameter of each of the arguments of the cosine and the sine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19284" target="_blank">05:21:24.420</a></span> | <span class="t">So we compute the cosines and the sine and then we use them to apply the rotary positional encoding to the query and the keys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19289" target="_blank">05:21:29.540</a></span> | <span class="t">Which will result in the output query and the keys with the rotary positional encoding applied. So now we are implementing this method here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19296" target="_blank">05:21:36.420</a></span> | <span class="t">Which will encode the queries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19300" target="_blank">05:21:40.100</a></span> | <span class="t">While multiplying the dimension of the vector query with the cosines, which is this part of the formula</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19307" target="_blank">05:21:47.380</a></span> | <span class="t">So as you can see the vector multiplied by the cosine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19311" target="_blank">05:21:51.140</a></span> | <span class="t">And then the rotated vector so with its dimensions changed and the signs changed multiplied by the sign</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19318" target="_blank">05:21:58.260</a></span> | <span class="t">Which is this part of the formula here. We need to implement this method here rotate half</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19323" target="_blank">05:22:03.700</a></span> | <span class="t">Which is again not equal to what is in the paper because we need to change the we need to permute the dimensions because the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19331" target="_blank">05:22:11.620</a></span> | <span class="t">original vectors so the q and k are permuted by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19335" target="_blank">05:22:15.700</a></span> | <span class="t">This query projection and this key projection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19340" target="_blank">05:22:20.980</a></span> | <span class="t">This rotate half method basically will take the first part of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19344" target="_blank">05:22:24.740</a></span> | <span class="t">Embedding and then it will take the second part of the embedding with its sign changed. I believe here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19352" target="_blank">05:22:32.820</a></span> | <span class="t">And it will concatenate it it's different than the paper because in the paper we need to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19359" target="_blank">05:22:39.540</a></span> | <span class="t">Here we need to create minus x2 then x1 minus x4 x3. But here what we are doing is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19367" target="_blank">05:22:47.540</a></span> | <span class="t">minus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19368" target="_blank">05:22:48.900</a></span> | <span class="t">Let me check imagine the token is made up of 1000 dimensions. So we are doing minus 500</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19374" target="_blank">05:22:54.520</a></span> | <span class="t">5124 dimensions. This is minus 1 513 minus 514 minus 515 blah blah blah</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19382" target="_blank">05:23:02.740</a></span> | <span class="t">And then we have 0 1 2 3 up to 512</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19386" target="_blank">05:23:06.440</a></span> | <span class="t">So it's different than this one here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19389" target="_blank">05:23:09.780</a></span> | <span class="t">But because of the permutation that was done to the wk and wv wq and wk projections</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19396" target="_blank">05:23:16.840</a></span> | <span class="t">So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19398" target="_blank">05:23:18.840</a></span> | <span class="t">Okay, now we have also implemented the rotary positional encodings which encode the position information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19404" target="_blank">05:23:24.940</a></span> | <span class="t">Right before the attention so that the attention mechanism will reflect this encoded information inside of each token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19412" target="_blank">05:23:32.840</a></span> | <span class="t">It matches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19414" target="_blank">05:23:34.840</a></span> | <span class="t">with the dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19416" target="_blank">05:23:36.840</a></span> | <span class="t">What else do we need to build here? I believe we have everything. So let me do a very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19425" target="_blank">05:23:45.560</a></span> | <span class="t">Check I think we have everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19427" target="_blank">05:23:47.720</a></span> | <span class="t">Guys, I think now we can proceed to the inference code. So we need to use this method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19433" target="_blank">05:23:53.240</a></span> | <span class="t">So these classes that we have built to actually inference something. Let's do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19437" target="_blank">05:23:57.320</a></span> | <span class="t">All right, guys, let's go to the inference code. So let's create a new file called inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19443" target="_blank">05:24:03.260</a></span> | <span class="t">.py</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19446" target="_blank">05:24:06.520</a></span> | <span class="t">I also have prepared the test image that I will be using to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19451" target="_blank">05:24:11.160</a></span> | <span class="t">Inference the language model. I will ask the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19453" target="_blank">05:24:13.640</a></span> | <span class="t">What is this building and the language model should tell me that what is the name of this building?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19457" target="_blank">05:24:17.640</a></span> | <span class="t">You can prepare any any image that you like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19460" target="_blank">05:24:20.360</a></span> | <span class="t">So I also have this inference.py. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19464" target="_blank">05:24:24.280</a></span> | <span class="t">Let's start by writing some code. I will copy a large amount of code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19469" target="_blank">05:24:29.640</a></span> | <span class="t">Because it's very nothing. No much machine learning here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19474" target="_blank">05:24:34.120</a></span> | <span class="t">So basically i'm using a library called fire. So let's import stuff first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19480" target="_blank">05:24:40.040</a></span> | <span class="t">Uh, oops this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19483" target="_blank">05:24:43.720</a></span> | <span class="t">Let's import some stuff so i'm importing a pill for the image loading torch fire fire is a library that allows you to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19491" target="_blank">05:24:51.640</a></span> | <span class="t">Pass the command line arguments to a file to a script as parameters to a function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19499" target="_blank">05:24:59.080</a></span> | <span class="t">So it will do automatically the parsing of the command line parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19502" target="_blank">05:25:02.780</a></span> | <span class="t">And what I need to pass as the as command line is the model path</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19507" target="_blank">05:25:07.720</a></span> | <span class="t">So what are the weights of the model the prompt that we will be using to inference the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19512" target="_blank">05:25:12.520</a></span> | <span class="t">The image that we'll be using as condition for this prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19515" target="_blank">05:25:15.880</a></span> | <span class="t">And the max number of tokens to generate the temperature that we want to apply later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19520" target="_blank">05:25:20.520</a></span> | <span class="t">We will see what is it the top p</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19522" target="_blank">05:25:22.520</a></span> | <span class="t">The later we will see the do sample if we don't want to use the greedy strategy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19526" target="_blank">05:25:26.520</a></span> | <span class="t">And if you don't want to use the cuda or the nps in case you are on the macbook</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19531" target="_blank">05:25:31.180</a></span> | <span class="t">So we forced to use the cpu as device for the computation in the neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19537" target="_blank">05:25:37.880</a></span> | <span class="t">The first thing that this method will do is okay, we'll print which device we use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19541" target="_blank">05:25:41.640</a></span> | <span class="t">Then it will load the model using this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19544" target="_blank">05:25:44.600</a></span> | <span class="t">Method that we will implement later with the load hugging face model given the path and the device will load the model with the hugging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19552" target="_blank">05:25:52.040</a></span> | <span class="t">from the hugging face</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19554" target="_blank">05:25:54.440</a></span> | <span class="t">By copying each tensor in the right position, but because we kept the name the same as the hugging face model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19560" target="_blank">05:26:00.680</a></span> | <span class="t">So we don't need to do any name conversion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19564" target="_blank">05:26:04.120</a></span> | <span class="t">We copy some we basically take the input and we process it using this polygamma processor which will take his input the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19572" target="_blank">05:26:12.220</a></span> | <span class="t">And the the prompt and the image and it will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19578" target="_blank">05:26:18.520</a></span> | <span class="t">Transform it is input for our gamma model, which will then decode it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19583" target="_blank">05:26:23.480</a></span> | <span class="t">And we will do that this in test inference method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19587" target="_blank">05:26:27.720</a></span> | <span class="t">So for now, we are just creating the polygamma processor and the model itself using this load hugging face model, which we will create later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19594" target="_blank">05:26:34.760</a></span> | <span class="t">Actually, no, let's do it now. So let's create a new file called utils</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19599" target="_blank">05:26:39.100</a></span> | <span class="t">And this utils file needs to have the following code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19604" target="_blank">05:26:44.440</a></span> | <span class="t">So it's importing some stuff and then it's loading the hugging face method. So it's loading the tokenizer, which I said we will be using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19614" target="_blank">05:26:54.920</a></span> | <span class="t">Hugging face one. So we will not be coding the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19617" target="_blank">05:26:57.500</a></span> | <span class="t">But the weights of the model we can load them and if you look at the hugging face model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19623" target="_blank">05:27:03.560</a></span> | <span class="t">If you go to the repository of the model, you will see that each model is a list of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19629" target="_blank">05:27:09.160</a></span> | <span class="t">Safe tensor files each of these safe tensor files is actually a dictionary that contains the weights of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19636" target="_blank">05:27:16.120</a></span> | <span class="t">So you can actually click on this icon here and it will show you what each of these them contains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19641" target="_blank">05:27:21.800</a></span> | <span class="t">As you can see this one contains the multi-modal projector weight and bias</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19645" target="_blank">05:27:25.640</a></span> | <span class="t">This one contains the vision tower embeddings, encoder layers one, layer two, layer three, etc, etc for all the layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19652" target="_blank">05:27:32.440</a></span> | <span class="t">And for each layer it contains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19654" target="_blank">05:27:34.920</a></span> | <span class="t">The wq projection, wk projection, wv projection, the weights and the bias</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19660" target="_blank">05:27:40.200</a></span> | <span class="t">The weights, the bias of the layer normalization, the weight of the layer normalization, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19666" target="_blank">05:27:46.600</a></span> | <span class="t">and each file contains a dictionary that contains some part of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19671" target="_blank">05:27:51.880</a></span> | <span class="t">Weights of this model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19673" target="_blank">05:27:53.240</a></span> | <span class="t">So what i'm doing here is I find all the safe tensor files and then I load them each of them into a dictionary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19679" target="_blank">05:27:59.020</a></span> | <span class="t">And then I use this dictionary to load the state dict of our neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19683" target="_blank">05:28:03.960</a></span> | <span class="t">I also create the model using the config.json file that is present in the repository of the hugging face</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19692" target="_blank">05:28:12.200</a></span> | <span class="t">Model, so every hugging face model has this config.json</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19697" target="_blank">05:28:17.160</a></span> | <span class="t">So we create the configuration that is used to create our model using this configuration file</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19702" target="_blank">05:28:22.840</a></span> | <span class="t">and then I call tie weights which will copy the weights of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19707" target="_blank">05:28:27.000</a></span> | <span class="t">Embedding layer to the language modeling head which is the linear layer that projects the embeddings into logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19713" target="_blank">05:28:33.800</a></span> | <span class="t">And then we return the model and the tokenizer. So here there is no machine learning. I'm just loading the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19719" target="_blank">05:28:39.720</a></span> | <span class="t">The weights of the model from the safe tensor files creating the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19726" target="_blank">05:28:46.920</a></span> | <span class="t">Model using the configuration saved in config.json</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19729" target="_blank">05:28:49.900</a></span> | <span class="t">And then loading this state dict which means that I am loading the weights into our class</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19736" target="_blank">05:28:56.120</a></span> | <span class="t">This this class here into this model class and then i'm tying the weights and returning the tokenizer and the weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19742" target="_blank">05:29:02.920</a></span> | <span class="t">So now we can launch the inference. So we have the model and the tokenizer. We have created the processor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19748" target="_blank">05:29:08.200</a></span> | <span class="t">So we have initialized it then we need to launch the inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19751" target="_blank">05:29:11.160</a></span> | <span class="t">Let's see how the inference works. So let's go back to here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19756" target="_blank">05:29:16.360</a></span> | <span class="t">This test inference is also not so hard, but we need to do some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19762" target="_blank">05:29:22.280</a></span> | <span class="t">Explanation on some parts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19765" target="_blank">05:29:25.460</a></span> | <span class="t">So what we are doing is first of all, we take this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19768" target="_blank">05:29:28.760</a></span> | <span class="t">Inputs so the image and the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19772" target="_blank">05:29:32.280</a></span> | <span class="t">Which is a text and we pass it to the processor and the processor will give us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19777" target="_blank">05:29:37.560</a></span> | <span class="t">As you can see from the processing polygamma, it will return us the pixel values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19782" target="_blank">05:29:42.520</a></span> | <span class="t">And the input ids and the attention mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19785" target="_blank">05:29:45.320</a></span> | <span class="t">So we get this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19788" target="_blank">05:29:48.200</a></span> | <span class="t">These values from the processor. So we need to create this function which is also a simple helper function that allows to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19795" target="_blank">05:29:55.720</a></span> | <span class="t">Get the output from the processor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19799" target="_blank">05:29:59.180</a></span> | <span class="t">So we load the image we create the prompt which because the processor expects as input the text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19805" target="_blank">05:30:05.640</a></span> | <span class="t">As a list and the image as a list even if it only works with one of them with a list of size one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19811" target="_blank">05:30:11.800</a></span> | <span class="t">it takes the output of the processor which is the input ids the attention mask and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19816" target="_blank">05:30:16.120</a></span> | <span class="t">Pixel values of the image then it moves to the right device each of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19820" target="_blank">05:30:20.680</a></span> | <span class="t">So move to the right device is also a simple function that moves each tensor to the device specified by this function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19827" target="_blank">05:30:27.640</a></span> | <span class="t">this parameter device</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19829" target="_blank">05:30:29.960</a></span> | <span class="t">And then returns it so now we have the input ids we have the attention mask we have the pixel values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19836" target="_blank">05:30:36.440</a></span> | <span class="t">We create a KV cache, which is empty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19840" target="_blank">05:30:40.040</a></span> | <span class="t">And what we do for based on how many tokens we need to generate. Oh, I already removed the label</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19845" target="_blank">05:30:45.400</a></span> | <span class="t">So let me remove it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19846" target="_blank">05:30:46.920</a></span> | <span class="t">Based on how many tokens we want to generate with we launch the inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19851" target="_blank">05:30:51.640</a></span> | <span class="t">At the beginning this input ids only includes the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19856" target="_blank">05:30:56.040</a></span> | <span class="t">So it includes the image tokens and the text tokens without of course any output tokens because we need to generate the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19863" target="_blank">05:31:03.240</a></span> | <span class="t">So what we are doing at the first iteration of this for loop is the prefilling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19868" target="_blank">05:31:08.440</a></span> | <span class="t">So the KV cache is empty the input ids contain the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19871" target="_blank">05:31:11.560</a></span> | <span class="t">image tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19873" target="_blank">05:31:13.880</a></span> | <span class="t">Placeholders and the text tokens the pixel values contains the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19879" target="_blank">05:31:19.080</a></span> | <span class="t">Loaded as a numpy array and then the attention mask, which is just a list of ones because we are never working with padding now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19886" target="_blank">05:31:26.520</a></span> | <span class="t">the model itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19889" target="_blank">05:31:29.240</a></span> | <span class="t">So the polygamma model, which is this here will merge the image features that we are passing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19896" target="_blank">05:31:36.520</a></span> | <span class="t">So these pixel values it will run them through the image encoder, which will return some image features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19902" target="_blank">05:31:42.200</a></span> | <span class="t">These image features are replaced with them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19906" target="_blank">05:31:46.040</a></span> | <span class="t">We replace the image placeholder tokens with the image features extracted from the image encoder. So now we have a list of embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19913" target="_blank">05:31:53.660</a></span> | <span class="t">Where the first embeddings are the image embeddings and then the text embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19918" target="_blank">05:31:58.060</a></span> | <span class="t">And then we send it to the language model for decoding. So let's go back to the inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19923" target="_blank">05:32:03.480</a></span> | <span class="t">So the first iteration of this for loop is the prefilling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19926" target="_blank">05:32:06.380</a></span> | <span class="t">Which means that the query key and values are the same sequence length and they contain the tokens of the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19933" target="_blank">05:32:13.080</a></span> | <span class="t">The output of the prefilling is a list of embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19937" target="_blank">05:32:17.820</a></span> | <span class="t">Which we project into logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19940" target="_blank">05:32:20.780</a></span> | <span class="t">But we take only the last logit to predict the next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19945" target="_blank">05:32:25.000</a></span> | <span class="t">So that's why we take out the logits and we take only the last logit here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19949" target="_blank">05:32:29.160</a></span> | <span class="t">So this is the sequence dimension and we take the last item in this sequence dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19953" target="_blank">05:32:33.480</a></span> | <span class="t">Now, what do we do with this logits?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19956" target="_blank">05:32:36.040</a></span> | <span class="t">So now let's go to the iPad actually because I want to explain how top p works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19962" target="_blank">05:32:42.040</a></span> | <span class="t">So let's go. Let me check if this is working. Yeah still working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19967" target="_blank">05:32:47.080</a></span> | <span class="t">So now we can do this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19970" target="_blank">05:32:50.040</a></span> | <span class="t">Oops</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19972" target="_blank">05:32:52.120</a></span> | <span class="t">This one. Okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19975" target="_blank">05:32:55.160</a></span> | <span class="t">Let's open a new page. So when you generate logits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19979" target="_blank">05:32:59.320</a></span> | <span class="t">basically, it corresponds to a kind of a distribution after you apply the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19985" target="_blank">05:33:05.260</a></span> | <span class="t">So the logit is a vector. So let me draw here is a vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=19991" target="_blank">05:33:11.240</a></span> | <span class="t">Where the number of dimensions is equal to the vocabulary size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20001" target="_blank">05:33:21.400</a></span> | <span class="t">So you have one number for each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20003" target="_blank">05:33:23.480</a></span> | <span class="t">Token in the vocabulary and it indicates it's an indication by the model on what the model thinks should be the next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20012" target="_blank">05:33:32.120</a></span> | <span class="t">What we do is we can do to understand. What is the next token?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20016" target="_blank">05:33:36.680</a></span> | <span class="t">We need to apply the softmax which will convert each of these numbers. So each of these numbers into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20022" target="_blank">05:33:42.920</a></span> | <span class="t">Probability score so something that sums up to one and it's always non-negative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20029" target="_blank">05:33:49.000</a></span> | <span class="t">And we could take for example the highest one to predict what is the net to understand what is the next token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20034" target="_blank">05:33:54.280</a></span> | <span class="t">another way is to use the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20036" target="_blank">05:33:56.520</a></span> | <span class="t">Sampling method. So this is a list of numbers, right one for each position in the vocabulary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20042" target="_blank">05:34:02.700</a></span> | <span class="t">So for example for the token hello, the model could say some score the token pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20047" target="_blank">05:34:07.560</a></span> | <span class="t">It should give another score for the token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20049" target="_blank">05:34:09.880</a></span> | <span class="t">I don't know car it will give another score, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20055" target="_blank">05:34:15.240</a></span> | <span class="t">We can also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20056" target="_blank">05:34:16.760</a></span> | <span class="t">Do sampling which means that we sort all of these numbers that we get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20061" target="_blank">05:34:21.720</a></span> | <span class="t">So all of these numbers that we get we sort them in decreasing order</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20065" target="_blank">05:34:25.720</a></span> | <span class="t">And then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20070" target="_blank">05:34:30.040</a></span> | <span class="t">take the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20071" target="_blank">05:34:31.640</a></span> | <span class="t">the top ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20073" target="_blank">05:34:33.640</a></span> | <span class="t">Such that sum up to a probability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20077" target="_blank">05:34:37.180</a></span> | <span class="t">Score so with top p what we are doing with the top p of 0.9</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20084" target="_blank">05:34:44.060</a></span> | <span class="t">Suppose that to the token. Hello, we have assigned the model has assigned a probability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20088" target="_blank">05:34:48.940</a></span> | <span class="t">Let's say of 0.2. This one is a 0.5 and this one is 0.1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20093" target="_blank">05:34:53.580</a></span> | <span class="t">Then we have some other token. Let's say 0.05 and then another token. That is 0.1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20099" target="_blank">05:34:59.660</a></span> | <span class="t">Again, I don't know if this sum up to one but okay and then some other token and some other token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20105" target="_blank">05:35:05.260</a></span> | <span class="t">We sort them in decreasing order which means that we sort them like this. So we take hello</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20111" target="_blank">05:35:11.500</a></span> | <span class="t">zero, oh no, the first one should be pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20114" target="_blank">05:35:14.060</a></span> | <span class="t">Pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20118" target="_blank">05:35:18.060</a></span> | <span class="t">0.5 then we have a hello</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20120" target="_blank">05:35:20.200</a></span> | <span class="t">0.2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20124" target="_blank">05:35:24.700</a></span> | <span class="t">And then we have a car</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20126" target="_blank">05:35:26.940</a></span> | <span class="t">0.1 then we have something else that 0.1. Then we have something else that is 0.05, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20133" target="_blank">05:35:33.660</a></span> | <span class="t">With the top p, let's say of 0.0, not 0.9. It's a little bit more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20139" target="_blank">05:35:39.740</a></span> | <span class="t">0.0, not 0.9. It's a little too much. Let's say top p</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20143" target="_blank">05:35:43.180</a></span> | <span class="t">Of 0.7</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20147" target="_blank">05:35:47.020</a></span> | <span class="t">We will basically sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20149" target="_blank">05:35:49.180</a></span> | <span class="t">from this distribution by only considering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20153" target="_blank">05:35:53.200</a></span> | <span class="t">The token such that their cumulative score is at least this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20158" target="_blank">05:35:58.780</a></span> | <span class="t">So we will take basically all the tokens that when they sum up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20163" target="_blank">05:36:03.820</a></span> | <span class="t">We sum them up with their probability score. They sum up to this amount and then we sample from them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20169" target="_blank">05:36:09.420</a></span> | <span class="t">sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20171" target="_blank">05:36:11.500</a></span> | <span class="t">kind of a weighted sample in which we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20173" target="_blank">05:36:13.740</a></span> | <span class="t">Take into consider for example with the 0.7. We will consider only these two tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20178" target="_blank">05:36:18.620</a></span> | <span class="t">and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20180" target="_blank">05:36:20.780</a></span> | <span class="t">Sample from we then rearrange these numbers such that again, they sum up to one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20186" target="_blank">05:36:26.540</a></span> | <span class="t">So suppose that after applying again the softmax this sum up to this will be changed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20192" target="_blank">05:36:32.700</a></span> | <span class="t">So this will become let's say 0.75 and this will become 0.25</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20197" target="_blank">05:36:37.040</a></span> | <span class="t">Then we sample again from this distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20201" target="_blank">05:36:41.600</a></span> | <span class="t">So basically what will happen is that 75% of the time we will choose this token and 25% of the time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20208" target="_blank">05:36:48.700</a></span> | <span class="t">We will choose this token. This is the meaning of top p. So among all the tokens we talk we sort them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20214" target="_blank">05:36:54.300</a></span> | <span class="t">we take only the one that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20216" target="_blank">05:36:56.780</a></span> | <span class="t">With who that with the cumulative probability score that reaches this top p</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20222" target="_blank">05:37:02.060</a></span> | <span class="t">And then we some sample from them just like they are a distribution by themselves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20226" target="_blank">05:37:06.960</a></span> | <span class="t">Before sampling them because they need to be a distribution so we need to apply the softmax again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20233" target="_blank">05:37:13.580</a></span> | <span class="t">So this is what we do with the top p instead what we do with greedy is that we just take the highest one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20238" target="_blank">05:37:18.860</a></span> | <span class="t">And that's it. But with the top p we are actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20241" target="_blank">05:37:21.740</a></span> | <span class="t">sampling from this distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20244" target="_blank">05:37:24.940</a></span> | <span class="t">But we are not considering everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20246" target="_blank">05:37:26.940</a></span> | <span class="t">To sample because some of them are basically the model is saying don't use this token because the probability score assigned to it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20254" target="_blank">05:37:34.060</a></span> | <span class="t">It's very very slow. So why should we even consider it? So that's why we use top p</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20257" target="_blank">05:37:37.740</a></span> | <span class="t">We only consider the most likely one chosen by the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20261" target="_blank">05:37:41.340</a></span> | <span class="t">So we don't introduce any noise in the generation process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20265" target="_blank">05:37:45.200</a></span> | <span class="t">What else I think nothing so let's go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20270" target="_blank">05:37:50.540</a></span> | <span class="t">So what we are doing here we are sampling with the top p if we decided to sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20274" target="_blank">05:37:54.540</a></span> | <span class="t">Otherwise, we just take the one with the highest probability score, which is the greedy strategy if we don't want to sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20279" target="_blank">05:37:59.740</a></span> | <span class="t">There is also this thing called temperature. So what is temperature temperature basically means that we want to divide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20286" target="_blank">05:38:06.160</a></span> | <span class="t">The as you can see here we divide the logits before applying the softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20293" target="_blank">05:38:13.280</a></span> | <span class="t">So that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20297" target="_blank">05:38:17.020</a></span> | <span class="t">Basically what happens is that before we apply the softmax these numbers are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20301" target="_blank">05:38:21.020</a></span> | <span class="t">Probability score so they not sum up to one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20304" target="_blank">05:38:24.620</a></span> | <span class="t">So for example, this may be 10. This may be 7. This may be 5. This may be 2. This may be 1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20311" target="_blank">05:38:31.420</a></span> | <span class="t">This may be 0.1, etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20313" target="_blank">05:38:33.980</a></span> | <span class="t">When we apply the softmax, we are basically sorry when we are applying the temperature we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20321" target="_blank">05:38:41.820</a></span> | <span class="t">Making the difference between them a little smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20325" target="_blank">05:38:45.580</a></span> | <span class="t">So we basically if the model is giving us the following distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20329" target="_blank">05:38:49.980</a></span> | <span class="t">So it's telling us that this token is likely but this is very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20333" target="_blank">05:38:53.100</a></span> | <span class="t">Much more likely and this is less likely and this is less likely etc, etc</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20338" target="_blank">05:38:58.460</a></span> | <span class="t">What we are trying to do with the temperature is basically we are reducing the gap between these peaks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20345" target="_blank">05:39:05.340</a></span> | <span class="t">So that the when we do the sampling here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20348" target="_blank">05:39:08.860</a></span> | <span class="t">We are more likely to choose more diverse tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20352" target="_blank">05:39:12.300</a></span> | <span class="t">Because then with the temperature what will happen is that the hello instead of being chosen 25% of the time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20358" target="_blank">05:39:18.700</a></span> | <span class="t">It will be chosen. Let's say 33% of the time and this will become</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20362" target="_blank">05:39:22.140</a></span> | <span class="t">0.66. So basically we are introducing some noise in the choice that we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20368" target="_blank">05:39:28.780</a></span> | <span class="t">But only restricted to the top 0.70%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20372" target="_blank">05:39:32.460</a></span> | <span class="t">tokens chosen by the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20376" target="_blank">05:39:36.380</a></span> | <span class="t">I know it's a little difficult to visualize but basically with the temperature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20380" target="_blank">05:39:40.060</a></span> | <span class="t">We are trying to make it more likely to choose more diverse tokens because we are reducing the gaps between the probability scores</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20387" target="_blank">05:39:47.500</a></span> | <span class="t">of the tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20389" target="_blank">05:39:49.580</a></span> | <span class="t">And then we do sampling with top p which I will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20392" target="_blank">05:39:52.700</a></span> | <span class="t">Put later is a simple method that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20395" target="_blank">05:39:55.900</a></span> | <span class="t">Does what we saw before so we sort by descending order and then we sample from the distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20401" target="_blank">05:40:01.980</a></span> | <span class="t">So actually let's do it. I think it's let's do it one by one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20405" target="_blank">05:40:05.260</a></span> | <span class="t">So sample top p</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20407" target="_blank">05:40:07.260</a></span> | <span class="t">Sample top p we can put it here. So as you can see we are sorting in descending order</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20414" target="_blank">05:40:14.300</a></span> | <span class="t">We are calculating the cumulative sum. We are only taking the one that have the cumulative sum equal to the p parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20420" target="_blank">05:40:20.880</a></span> | <span class="t">We do it here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20422" target="_blank">05:40:22.700</a></span> | <span class="t">so we mask out all the others and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20425" target="_blank">05:40:25.340</a></span> | <span class="t">Normalize again so that they sum up to one because we have removed some tokens from this distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20432" target="_blank">05:40:32.860</a></span> | <span class="t">And then we sample from this distribution using this multinomial and then we take the token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20437" target="_blank">05:40:37.580</a></span> | <span class="t">chosen by this sampling operation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20440" target="_blank">05:40:40.300</a></span> | <span class="t">So we have applied the top p so now we know what is the next token we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20446" target="_blank">05:40:46.300</a></span> | <span class="t">Take this token and we add it to this generated tokens array</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20451" target="_blank">05:40:51.340</a></span> | <span class="t">If the next token corresponds to the stop token, which is the end of sentence token, then we stop the generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20457" target="_blank">05:40:57.440</a></span> | <span class="t">Otherwise we keep generating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20460" target="_blank">05:41:00.300</a></span> | <span class="t">And then we take these input IDs as you can see then as for the next iteration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20466" target="_blank">05:41:06.160</a></span> | <span class="t">Because we are using the KVCache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20468" target="_blank">05:41:08.860</a></span> | <span class="t">At at each inference step we use as query only the last predicted token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20476" target="_blank">05:41:16.300</a></span> | <span class="t">So this is what we are doing here. So at the second iteration of this for loop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20479" target="_blank">05:41:19.900</a></span> | <span class="t">Our input IDs will only become one single token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20483" target="_blank">05:41:23.660</a></span> | <span class="t">And so the first iteration we are doing the prefilling. So the input IDs is all the tokens of the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20490" target="_blank">05:41:30.140</a></span> | <span class="t">So the image tokens and the text tokens of what we want to do with this image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20494" target="_blank">05:41:34.300</a></span> | <span class="t">At the second iteration these input IDs will only be one token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20499" target="_blank">05:41:39.260</a></span> | <span class="t">So how can the model will work with only one token because the model always has access to all the previous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20505" target="_blank">05:41:45.500</a></span> | <span class="t">Keys and values because they are have been saved in the KVCache. So when we calculate the attention the model will add this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20512" target="_blank">05:41:52.540</a></span> | <span class="t">Single token to the KVCache retrieve whatever is inside the KVCache and use it to calculate the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20520" target="_blank">05:42:00.060</a></span> | <span class="t">This way we generate tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20522" target="_blank">05:42:02.060</a></span> | <span class="t">We keep increasing the attention mask by adding one because we want to attend to all the past token in the KVCache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20528" target="_blank">05:42:08.940</a></span> | <span class="t">Because we don't have any padding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20531" target="_blank">05:42:11.020</a></span> | <span class="t">Usually you are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20533" target="_blank">05:42:13.580</a></span> | <span class="t">You are used to think of the padding as something that is present on the right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20536" target="_blank">05:42:16.860</a></span> | <span class="t">But actually padding can also be done on the left</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20539" target="_blank">05:42:19.020</a></span> | <span class="t">So because on the left, we don't have any padding token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20542" target="_blank">05:42:22.540</a></span> | <span class="t">So the attention mask is always made up of ones and also in my implementation. I am not never working with the paddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20549" target="_blank">05:42:29.580</a></span> | <span class="t">We generate these tokens we concatenate them together because we save them into an array</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20553" target="_blank">05:42:33.980</a></span> | <span class="t">So we need to generate a tensor which is then sent to the tokenizer for decoding and then we print</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20559" target="_blank">05:42:39.420</a></span> | <span class="t">print the output of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20562" target="_blank">05:42:42.140</a></span> | <span class="t">And now we can finally run the generation. So the inference so I will copy the script that I have already prepared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20568" target="_blank">05:42:48.960</a></span> | <span class="t">And this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20572" target="_blank">05:42:52.140</a></span> | <span class="t">I have already saved the weights of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20574" target="_blank">05:42:54.620</a></span> | <span class="t">So if you want to run this code, you need to download the repository of this model clone it locally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20580" target="_blank">05:43:00.060</a></span> | <span class="t">and then you use it as a you send the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20583" target="_blank">05:43:03.100</a></span> | <span class="t">you set the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20585" target="_blank">05:43:05.900</a></span> | <span class="t">Path to where you save it you give the prompt that my prompt is this building is and the model should tell me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20591" target="_blank">05:43:11.580</a></span> | <span class="t">What is this building and the image file is this building here. It's a building in Xi'an, China</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20597" target="_blank">05:43:17.260</a></span> | <span class="t">And then we use this temperature the top p and we do not sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20603" target="_blank">05:43:23.020</a></span> | <span class="t">I want the greedy strategy and I also want to use CUDA. We run the script like this. So now let's run it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20609" target="_blank">05:43:29.100</a></span> | <span class="t">I hope there are no problems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20611" target="_blank">05:43:31.740</a></span> | <span class="t">I think yeah should be no problem. So launch inference. Let's see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20618" target="_blank">05:43:38.780</a></span> | <span class="t">All right guys, so after I have launched the inference actually my computer went a little crazy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20625" target="_blank">05:43:45.580</a></span> | <span class="t">So I had to switch back to using the cpu</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20628" target="_blank">05:43:48.780</a></span> | <span class="t">And then it worked because I don't know why my CUDA sometimes doesn't work and it blocks all my computer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20634" target="_blank">05:43:54.460</a></span> | <span class="t">So if you run the inference using the code that we have made it should give this output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20640" target="_blank">05:44:00.220</a></span> | <span class="t">So this building is the oldest clock tower in the world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20643" target="_blank">05:44:03.180</a></span> | <span class="t">Which is actually I don't know if it's the oldest tower in the world, but actually this is called the jungle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20648" target="_blank">05:44:08.220</a></span> | <span class="t">So it's a clock tower in Xi'an. So it's a very famous building and looks like the output is correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20653" target="_blank">05:44:13.900</a></span> | <span class="t">So thank you guys for watching this video. I know it has been a very very long journey</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20658" target="_blank">05:44:18.860</a></span> | <span class="t">And I had to do a lot of explanations. I had to kind of improvise sometimes to do this explanation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20664" target="_blank">05:44:24.780</a></span> | <span class="t">So there it is possible that may there may be some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20667" target="_blank">05:44:27.660</a></span> | <span class="t">Imprecisions in my way of explaining because I don't have a transcript that i'm reading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20672" target="_blank">05:44:32.060</a></span> | <span class="t">For all of the things that I have talked about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20674" target="_blank">05:44:34.460</a></span> | <span class="t">So sometimes, you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20676" target="_blank">05:44:36.220</a></span> | <span class="t">I just look at the code to try to come up with the right words to how to explain it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20681" target="_blank">05:44:41.420</a></span> | <span class="t">And of course you cannot find always the right words immediately</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20685" target="_blank">05:44:45.420</a></span> | <span class="t">Maybe you need to watch it at least for one minute to get the right words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20688" target="_blank">05:44:48.620</a></span> | <span class="t">but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20690" target="_blank">05:44:50.220</a></span> | <span class="t">Hopefully at least 90% of the content is super</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20692" target="_blank">05:44:52.780</a></span> | <span class="t">Correct and the other 10% maybe will have some noises</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20696" target="_blank">05:44:56.220</a></span> | <span class="t">So I will try to clarify the things that I have not been explained correctly in the comments or in the description of the video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20702" target="_blank">05:45:02.060</a></span> | <span class="t">Thank you guys for watching this video. So please share it with your friends and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20707" target="_blank">05:45:07.020</a></span> | <span class="t">Like it if you like it and subscribe to my channel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20711" target="_blank">05:45:11.260</a></span> | <span class="t">A lot of people have asked me. What is the best way to contribute economically?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20715" target="_blank">05:45:15.600</a></span> | <span class="t">To me to support me, but I believe I I thankful thank god. I don't need any economic support for now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20722" target="_blank">05:45:22.780</a></span> | <span class="t">If I would ever need it, I would be the first one to ask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20725" target="_blank">05:45:25.740</a></span> | <span class="t">So if you want to help someone economically, there are many people in the world that you can help</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20729" target="_blank">05:45:29.740</a></span> | <span class="t">So there are people in war areas in palestine in ukraine. You can help them economically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20734" target="_blank">05:45:34.880</a></span> | <span class="t">But for me, I just need you guys to follow me and to share my video. This is the best way to help me out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20740" target="_blank">05:45:40.620</a></span> | <span class="t">Also, I work at a company known as writer and my team is currently hiring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20744" target="_blank">05:45:44.620</a></span> | <span class="t">We are looking for amazing researchers and you can find more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20748" target="_blank">05:45:48.060</a></span> | <span class="t">information in the description of the video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20750" target="_blank">05:45:50.940</a></span> | <span class="t">We train our own models. We have plenty of gpus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20754" target="_blank">05:45:54.060</a></span> | <span class="t">So if you are a researcher in dealing with the language models, but any area of machine learning you are feel free to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vAmKB7iPkWw&t=20760" target="_blank">05:46:00.220</a></span> | <span class="t">Send your resume. So thank you guys and have a nice day</span></div></div></body></html>