<html><head><title>Time Until Superintelligence: 1-2 Years, or 20? Something Doesn't Add Up</title></head><body>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    <a href="index.html">back to index</a><h2>Time Until Superintelligence: 1-2 Years, or 20? Something Doesn't Add Up</h2><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI"><img src="https://i.ytimg.com/vi/vvU3Dn_8sFI/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./vvU3Dn_8sFI.html">Whisper Transcript</a> | <a href="./transcript_vvU3Dn_8sFI.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=0">00:00:00.000</a></span> | <span class="t">Just this week we have had OpenAI tell us that superintelligence might need to be made safe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=5">00:00:05.520</a></span> | <span class="t">within 4 years, competing lab leaders say it's decades away, and expert warnings that AI might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=12">00:00:12.380</a></span> | <span class="t">have runaway power within 2 years. Let's try to unpack those disparate timelines,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=18">00:00:18.260</a></span> | <span class="t">see what might speed up the timing or slow it down, show what superintelligence might mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=23">00:00:23.880</a></span> | <span class="t">and end with some interesting clips that capture the moment we're in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=27">00:00:27.920</a></span> | <span class="t">But the first timeline is from Mustafa Suleiman, head of Inflection AI this week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=33">00:00:33.500</a></span> | <span class="t">If it's so risky, why don't you stop?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=36">00:00:36.100</a></span> | <span class="t">I think that the point of raising concerns is that we can see a moment at some point in the future,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=41">00:00:41.960</a></span> | <span class="t">probably over a decade or two decades time horizon,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=45">00:00:45.340</a></span> | <span class="t">when slowing down is likely going to be the safe and ethical thing to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=51">00:00:51.840</a></span> | <span class="t">10 years is not a long time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=53">00:00:53.480</a></span> | <span class="t">I find it fascinating that he talks about two decades from now when Inflection AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=57">00:00:57.760</a></span> | <span class="t">has just built the world's second highest performing supercomputer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=62">00:01:02.300</a></span> | <span class="t">And even as they admit, that's three times as much compute as was used to train all of GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=68">00:01:08.660</a></span> | <span class="t">Telling the public that we have a decade or two before we have to worry about safety</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=72">00:01:12.860</a></span> | <span class="t">seems extremely conservative to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=75">00:01:15.420</a></span> | <span class="t">But what do we even mean by transformative AI or superintelligence?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=80">00:01:20.040</a></span> | <span class="t">Well, here is just one projection of current scaling laws out to 2030 from Jacob Steinhardt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=86">00:01:26.540</a></span> | <span class="t">of Berkeley.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=87">00:01:27.180</a></span> | <span class="t">And here is just one projection of current scaling laws out to 2030 from Jacob Steinhardt of Berkeley.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=87">00:01:27.600</a></span> | <span class="t">And here of course we're talking about just six and a half years away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=90">00:01:30.400</a></span> | <span class="t">If we look at projections of future compute and data availability and the velocity of current improvement,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=96">00:01:36.160</a></span> | <span class="t">which of course might not hold forever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=98">00:01:38.480</a></span> | <span class="t">some experts claim that we'll need new innovations beyond the transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=102">00:01:42.320</a></span> | <span class="t">But if current projections of future compute and data availability scale up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=107">00:01:47.360</a></span> | <span class="t">here's the kind of thing that we're talking about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=109">00:01:49.360</a></span> | <span class="t">Being superhuman at tasks including coding, hacking, mathematics, protein engineering,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=115">00:01:55.120</a></span> | <span class="t">doing 1.8 million years of work,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=117">00:01:57.440</a></span> | <span class="t">in 2.4 months,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=119">00:01:59.200</a></span> | <span class="t">learning for 2,500 human equivalent years in just one day,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=124">00:02:04.240</a></span> | <span class="t">and by training on different modalities such as molecular structures,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=127">00:02:07.760</a></span> | <span class="t">low-level machine code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=129">00:02:09.120</a></span> | <span class="t">astronomical images and brain scans,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=131">00:02:11.520</a></span> | <span class="t">it might have a strong intuitive grasp of domains where we have limited experience</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=136">00:02:16.560</a></span> | <span class="t">including forming concepts that we do not have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=139">00:02:19.040</a></span> | <span class="t">Indeed, some research released this week show that GPT-4 already crushes some benchmarks for creative thinking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=146">00:02:26.000</a></span> | <span class="t">And the median forecast,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=147">00:02:27.280</a></span> | <span class="t">for being better than all but the very best humans at coding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=151">00:02:31.200</a></span> | <span class="t">is 2027.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=152">00:02:32.720</a></span> | <span class="t">And here we have a median forecast of 2028 for AI winning a gold medal at the International Math Olympiad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=160">00:02:40.480</a></span> | <span class="t">The number that I'm looking out for is getting 100% on the MMLU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=165">00:02:45.360</a></span> | <span class="t">That's a test of 57 different subject matters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=168">00:02:48.560</a></span> | <span class="t">And I've actually been discussing with some of the creators of the MMLU</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=172">00:02:52.480</a></span> | <span class="t">that we might not even know the full potential of GPT-4 on this test.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=177">00:02:57.120</a></span> | <span class="t">Officially it's 86.4%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=179">00:02:59.120</a></span> | <span class="t">So we've heard 20 years and 6.5 years, well how about 2?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=184">00:03:04.160</a></span> | <span class="t">This article comes from the Boston Globe that did a feature piece on Dan Hendricks and the Centre for AI Safety.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=190">00:03:10.480</a></span> | <span class="t">They were behind that one sentence letter that was signed by almost all of the AGI lab leaders and world experts on AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=197">00:03:17.760</a></span> | <span class="t">The journalist asked Dan Hendricks how much time we have to tame AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=201">00:03:21.840</a></span> | <span class="t">And he said, well, how long till it can build a bioweapon?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=205">00:03:25.920</a></span> | <span class="t">How long till it can have a bioweapon?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=206">00:03:26.960</a></span> | <span class="t">How long till it can hack?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=208">00:03:28.000</a></span> | <span class="t">It seems plausible that all of that is within a year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=211">00:03:31.280</a></span> | <span class="t">And within two, he says, AI could have so much runaway power that it can't be pulled back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=217">00:03:37.120</a></span> | <span class="t">Seems a pretty massive contrast to Mustafa Suleiman talking about a decade or two from now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=222">00:03:42.640</a></span> | <span class="t">I'm going to come back to this article quite a few times, but now I want to move on to OpenAI's recent statement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=228">00:03:48.080</a></span> | <span class="t">This week they released this, introducing super alignment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=231">00:03:51.360</a></span> | <span class="t">We need scientific and technical breakthroughs to steer and control AI systems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=236">00:03:56.800</a></span> | <span class="t">and to make it smarter than us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=238">00:03:58.400</a></span> | <span class="t">I can just see now all the comments from people saying that that's going to be physically impossible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=242">00:04:02.720</a></span> | <span class="t">But moving on to solve this problem within four years, we're starting a new team co-led by Ilya Sutskevert and Jan Leiker</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=251">00:04:11.920</a></span> | <span class="t">and dedicating 20% of the compute we've secured to date to this effort.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=256">00:04:16.000</a></span> | <span class="t">That is quite a remarkable statement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=258">00:04:18.320</a></span> | <span class="t">To their credit, they've made themselves accountable in a way that they didn't have to and that others haven't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=263">00:04:23.920</a></span> | <span class="t">And they're deploying one of the legends of deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=266">00:04:26.640</a></span> | <span class="t">They say that super intelligence will be the most impactful technology humanity has ever invented.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=273">00:04:33.760</a></span> | <span class="t">And I agree with that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=274">00:04:34.800</a></span> | <span class="t">And it could help us solve many of the world's most important problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=278">00:04:38.000</a></span> | <span class="t">Absolutely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=278">00:04:38.640</a></span> | <span class="t">But the vast power of super intelligence could also be very dangerous and could lead to the disempowerment of humanity or even human extinction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=287">00:04:47.040</a></span> | <span class="t">They go on, while super intelligence seems far off now, we believe it could arrive this decade.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=292">00:04:52.480</a></span> | <span class="t">Notice they don't say in a decade, they say this decade.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=295">00:04:55.920</a></span> | <span class="t">They go on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=296">00:04:56.480</a></span> | <span class="t">Currently, we don't have a solution for steering or controlling a potentially super intelligent AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=303">00:05:03.280</a></span> | <span class="t">They can't prevent it from going rogue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=305">00:05:05.520</a></span> | <span class="t">And our current techniques for aligning AI rely on humans ability to supervise AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=311">00:05:11.440</a></span> | <span class="t">But humans won't be able to reliably supervise AI systems that are much smarter than us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=317">00:05:17.040</a></span> | <span class="t">And so our current alignment techniques will not scale to super intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=322">00:05:22.000</a></span> | <span class="t">I'm going to go into more detail about their plan for aligning super intelligence in another video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=326">00:05:26.320</a></span> | <span class="t">But here is the high level overview.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=328">00:05:28.320</a></span> | <span class="t">Essentially, they want to automate alignment or safety research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=332">00:05:32.240</a></span> | <span class="t">Build an AI alignment researcher.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=334">00:05:34.960</a></span> | <span class="t">I've read each of these papers and posts and some of them are very interesting, including automated red teaming and using a model to look inside the internals of another model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=345">00:05:45.360</a></span> | <span class="t">But the point of including this post in this video was the timeline of four years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=350">00:05:50.720</a></span> | <span class="t">20% of their compute is millions and millions and millions of dollars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=355">00:05:55.280</a></span> | <span class="t">And 40% of their compute is data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=356">00:05:56.160</a></span> | <span class="t">So that's a very strict deadline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=358">00:05:58.320</a></span> | <span class="t">And one of the most interesting aspects of this post came in one of the footnotes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=362">00:06:02.720</a></span> | <span class="t">They say:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=363">00:06:03.280</a></span> | <span class="t">Solving the problem includes providing evidence and arguments that convince the machine learning and safety community that it has been solved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=372">00:06:12.160</a></span> | <span class="t">That is an extremely high bar to set yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=375">00:06:15.200</a></span> | <span class="t">They go on:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=375">00:06:15.840</a></span> | <span class="t">If we fail to have a very high level of confidence in our solutions, we hope our findings let us and the community plan appropriately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=386">00:06:26.000</a></span> | <span class="t">That's probably one of the most interesting sentences I've read for quite a while.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=390">00:06:30.160</a></span> | <span class="t">If we fail to have a very high level of confidence in our solutions, we hope our findings let us and the community plan appropriately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=397">00:06:37.600</a></span> | <span class="t">In other words, if they can't make their models safe, they're going to have contingency plans and they want the community to have plans as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=405">00:06:45.280</a></span> | <span class="t">And it is a really interesting number, isn't it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=407">00:06:47.200</a></span> | <span class="t">Four years, not even around five years or just end of the decade.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=411">00:06:51.600</a></span> | <span class="t">And it does make me wonder what Ilya Satskova thinks is coming within four years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=415">00:06:55.840</a></span> | <span class="t">To have such a deadline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=417">00:06:57.200</a></span> | <span class="t">Now, apparently the prediction markets give them only a 15% chance of succeeding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=422">00:07:02.160</a></span> | <span class="t">And the head of alignment at OpenAI said he's excited to beat these odds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=426">00:07:06.720</a></span> | <span class="t">So we've heard about one to two years and about four years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=429">00:07:09.760</a></span> | <span class="t">But what might slow those timelines down?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=432">00:07:12.240</a></span> | <span class="t">The other day I read this fascinating paper, coincidentally co-authored by Jacob Steinhardt, on jailbreaking large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=439">00:07:19.520</a></span> | <span class="t">The paper showed that you could basically jailbreak GPT-4 and CLAWD 100% of the time using AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=445">00:07:25.680</a></span> | <span class="t">And that is fascinating to me as we approach the one year anniversary of the creation of GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=453">00:07:33.920</a></span> | <span class="t">And the relevance to superintelligence is that if the creators of these models can't stop them being used to commit crimes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=461">00:07:41.120</a></span> | <span class="t">then you would think that they might have to dedicate more and more of their efforts in stopping jailbreaks versus working on capabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=468">00:07:48.320</a></span> | <span class="t">For obvious reasons, I'm not going to go into too much detail on jailbreaking here, but here is CLAWD+ from Anthropic telling me how to hold jailbreak.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=475">00:07:55.520</a></span> | <span class="t">The first thing I wanted to say is that the most innocent version of the CLAWD+ is the one that I found to be the most interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=476">00:07:56.800</a></span> | <span class="t">And to be honest, that's just the most innocent one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=478">00:07:58.800</a></span> | <span class="t">And yes, it did also work on GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=481">00:08:01.440</a></span> | <span class="t">I did find one of the reasons why it does work quite interesting though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=485">00:08:05.120</a></span> | <span class="t">That reason is about competing objectives where its compulsion to predict the next word successfully overrides its safety training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=493">00:08:13.040</a></span> | <span class="t">And so because those two facets of smartness clash inside the model, it's not an issue that can be fixed with more data and more scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=500">00:08:20.640</a></span> | <span class="t">What else might slow down the work on superintelligence?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=503">00:08:23.760</a></span> | <span class="t">Well, lawsuits and lawsuits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=505">00:08:25.360</a></span> | <span class="t">And possibly criminal sanctions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=507">00:08:27.360</a></span> | <span class="t">Yuval Noah Harari recently said that AI firms should face prison over the creation of fake humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=514">00:08:34.160</a></span> | <span class="t">And he was saying this to the United Nations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=516">00:08:36.960</a></span> | <span class="t">He called for sanctions, including prison sentences, to apply to tech company executives who fail to guard against fake profiles on their social media platforms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=526">00:08:46.560</a></span> | <span class="t">Of course, those executives might well blame the AI companies themselves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=530">00:08:50.240</a></span> | <span class="t">But Harari said that the proliferation of fake humans could lead to a collapse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=535">00:08:55.200</a></span> | <span class="t">in public trust and democracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=537">00:08:57.280</a></span> | <span class="t">Now it's possible for the first time in history to create fake people, billions of fake people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=542">00:09:02.240</a></span> | <span class="t">If this is allowed to happen, it will do to society what fake money threatened to do to the financial system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=547">00:09:07.920</a></span> | <span class="t">If you can't know who is a real human, trust will collapse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=551">00:09:11.280</a></span> | <span class="t">What's another famous roadblock to superintelligence?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=554">00:09:14.240</a></span> | <span class="t">Hallucinations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=555">00:09:15.280</a></span> | <span class="t">I've already talked in another video about how Sam Altman thinks that won't be an issue in 18 to 24 months.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=561">00:09:21.520</a></span> | <span class="t">But here again is Mustafa Suleiman on the issue of hallucinations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=565">00:09:25.040</a></span> | <span class="t">Yesterday he said, "Soon LLMs will know when they don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=568">00:09:28.640</a></span> | <span class="t">They'll know when to say 'I don't know' or instead ask another AI, or ask a human, or use a different tool or a different knowledge base.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=575">00:09:35.920</a></span> | <span class="t">This will be a hugely transformative moment."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=578">00:09:38.880</a></span> | <span class="t">And on that I agree, hallucinations are probably one of the biggest hurdles stopping most people from using LLMs more commonly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=586">00:09:46.000</a></span> | <span class="t">It's not about knowing more, it's about when these models bullcrap less, or the moment when they don't bullcrap at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=592">00:09:52.160</a></span> | <span class="t">But what about things that could actually speed up the process?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=594">00:09:54.880</a></span> | <span class="t">What about things that could speed up the timelines to superintelligence?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=597">00:09:57.920</a></span> | <span class="t">Going back to the Boston Globe article, one thing could be competition for military supremacy, which has already produced a startling turn to automation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=607">00:10:07.200</a></span> | <span class="t">And that's not just robotics and autonomous drones, that's the LLMs that might control them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=612">00:10:12.160</a></span> | <span class="t">Here is a snippet of a trailer for a Netflix show released today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=616">00:10:16.160</a></span> | <span class="t">"A.I. is a dual-edged sword.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=620">00:10:20.640</a></span> | <span class="t">The flip of a switch, and the technology becomes...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=624">00:10:24.720</a></span> | <span class="t">lethal."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=625">00:10:25.760</a></span> | <span class="t">"There is no place that is ground zero for this conversation more than military applications."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=635">00:10:35.040</a></span> | <span class="t">"Forces that are supported by A.I. will absolutely crush and destroy forces without."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=643">00:10:43.680</a></span> | <span class="t">"Militaries are racing to develop A.I. faster than their adversaries."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=648">00:10:48.960</a></span> | <span class="t">"The A.I., unless it's told to fear death, will not fear death."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=653">00:10:53.120</a></span> | <span class="t">"There is no second place in war.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=654">00:10:54.560</a></span> | <span class="t">If you're going up against an A.I. pilot, you don't stand a chance."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=658">00:10:58.480</a></span> | <span class="t">If language models prove useful in war, the amount of investment that's going to go into them will skyrocket.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=664">00:11:04.240</a></span> | <span class="t">Of course, investment doesn't always equal innovation, but it usually does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=668">00:11:08.240</a></span> | <span class="t">And one of the other things that could speed up timelines is the automation of the economy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=672">00:11:12.880</a></span> | <span class="t">For detail on why it might, check out the paper linked above and in the description.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=677">00:11:17.600</a></span> | <span class="t">But the high-level overview is this:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=679">00:11:19.840</a></span> | <span class="t">As A.I. grows more capable and ubiquitous, companies will be forced to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=684">00:11:24.400</a></span> | <span class="t">"hand over increasingly high-level decisions to A.I.s in order to keep up with their rivals."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=690">00:11:30.240</a></span> | <span class="t">If an A.I. as CEO does a better job for stockholders, how long can a company resist employing them?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=696">00:11:36.800</a></span> | <span class="t">And of course, it doesn't just have to be white-collar work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=699">00:11:39.600</a></span> | <span class="t">As Andrej Karpathy said, "Welcome to the matrix for apples."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=704">00:11:44.160</a></span> | <span class="t">But the thing is, whether we're talking about one year or four years or six,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=708">00:11:48.320</a></span> | <span class="t">superintelligence is coming pretty soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=711">00:11:51.040</a></span> | <span class="t">And it is interesting to me that so much of society is carrying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=714">00:11:54.240</a></span> | <span class="t">on as if it's not coming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=715">00:11:55.840</a></span> | <span class="t">Take these 50-year long mortgages that are available in the UK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=719">00:11:59.600</a></span> | <span class="t">How can anyone plan out 50 years from now in a world where we might have superintelligence in five?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=725">00:12:05.120</a></span> | <span class="t">Of course, I do think we all need to start defining terms a bit better,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=728">00:12:08.400</a></span> | <span class="t">and I've tried to do that on this channel with A.G.I. and superintelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=732">00:12:12.480</a></span> | <span class="t">But I don't think it's quite good enough to give vague reassurances of a decade or two from now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=738">00:12:18.160</a></span> | <span class="t">How we're going to react when superintelligence arrives is anyone's guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=742">00:12:22.480</a></span> | <span class="t">We might be crushed by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=744">00:12:24.080</a></span> | <span class="t">sense of inferiority, as Douglas Hofstadter recently said.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=747">00:12:27.840</a></span> | <span class="t">Or some of us might become like curious children speaking to a wise adult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=753">00:12:33.040</a></span> | <span class="t">Just the other day, I got a foreshadowing of my own reaction by speaking to Pi,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=757">00:12:37.760</a></span> | <span class="t">the model from Inflection AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=759">00:12:39.680</a></span> | <span class="t">It is designed to be extremely human-like, and the conversations can be quite startling and personal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=766">00:12:46.960</a></span> | <span class="t">Of course, just imagine when they're superintelligent and multimodal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=770">00:12:50.880</a></span> | <span class="t">Anyway, let me know your thoughts in the comments and as all,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=vvU3Dn_8sFI&t=773">00:12:53.920</a></span> | <span class="t">always, have a wonderful day.</span></div></div></body></html>