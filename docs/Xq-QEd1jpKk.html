<html><head><title>4 Reasons AI in 2024 is On An Exponential: Data, Mamba, and More</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>4 Reasons AI in 2024 is On An Exponential: Data, Mamba, and More</h2><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk"><img src="https://i.ytimg.com/vi/Xq-QEd1jpKk/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./Xq-QEd1jpKk.html">Whisper Transcript</a> | <a href="./transcript_Xq-QEd1jpKk.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">I hope everyone watching had an excellent 2023 and is looking to get 2024 off to a rambunctious</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=8" target="_blank">00:00:08.520</a></span> | <span class="t">start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=9" target="_blank">00:00:09.520</a></span> | <span class="t">This video though has been made to show that we are on the steep part of the exponential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=14" target="_blank">00:00:14.880</a></span> | <span class="t">and will be for a while yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=16" target="_blank">00:00:16.980</a></span> | <span class="t">I'm going to give you 4 clear reasons why, though I could have easily given 8 or 16 depending</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=23" target="_blank">00:00:23.560</a></span> | <span class="t">on how you categorise them and how much time you've got.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=26" target="_blank">00:00:26.600</a></span> | <span class="t">We will look at how data quality will change everything according to the famed authors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=32" target="_blank">00:00:32.040</a></span> | <span class="t">of Mamba and Mixed Trial, and then how models will start to think before answering, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=37" target="_blank">00:00:37.600</a></span> | <span class="t">according to this fascinating new paper, just how much low hanging fruit there is out there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=42" target="_blank">00:00:42.760</a></span> | <span class="t">in AI that doesn't even require more compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=46" target="_blank">00:00:46.040</a></span> | <span class="t">And even setting all of that aside, we'll end with the explosion in multimodal progress</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=51" target="_blank">00:00:51.760</a></span> | <span class="t">that is occurring around us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=53" target="_blank">00:00:53.640</a></span> | <span class="t">That by the way will include listening to a version of my voice that you might find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=58" target="_blank">00:00:58.200</a></span> | <span class="t">hard to distinguish from my real one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=60" target="_blank">00:01:00.760</a></span> | <span class="t">I'll also finish with some predictions for the year ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=64" target="_blank">00:01:04.080</a></span> | <span class="t">But I'm going to start with Mamba, but not yet the new architecture that is causing shockwaves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=68" target="_blank">00:01:08.760</a></span> | <span class="t">I'll cover that in a minute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=69" target="_blank">00:01:09.980</a></span> | <span class="t">I'm going to start with one of the co-authors, Tree Dao, and despite all the buzz about his</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=75" target="_blank">00:01:15.120</a></span> | <span class="t">new architecture, here's what he said about data quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=78" target="_blank">00:01:18.720</a></span> | <span class="t">All the architecture stuff is fun, making that hardware efficient is fun, but I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=84" target="_blank">00:01:24.360</a></span> | <span class="t">ultimately it's about data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=85" target="_blank">00:01:25.960</a></span> | <span class="t">If you look at the scaling log curve, different model architectures would generally have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=92" target="_blank">00:01:32.760</a></span> | <span class="t">same slope, they're just different offset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=94" target="_blank">00:01:34.760</a></span> | <span class="t">Seems like the only thing that changes the slope is the data quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=99" target="_blank">00:01:39.040</a></span> | <span class="t">Yes, we're going to cover Mamba in a minute, but for language modeling, it does perform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=104" target="_blank">00:01:44.200</a></span> | <span class="t">better than the Transformer++, basically the best version of a transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=109" target="_blank">00:01:49.440</a></span> | <span class="t">But according to this graph, with 5 or 10 times as much compute, you could replicate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=114" target="_blank">00:01:54.240</a></span> | <span class="t">the performance of Mamba with a transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=116" target="_blank">00:01:56.760</a></span> | <span class="t">And all of this, remember, is for a small 3 billion parameter model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=120" target="_blank">00:02:00.160</a></span> | <span class="t">We don't know what it will be like at bigger sizes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=122" target="_blank">00:02:02.720</a></span> | <span class="t">So for language modeling, potentially a big breakthrough, but data quality still means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=127" target="_blank">00:02:07.280</a></span> | <span class="t">more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=128" target="_blank">00:02:08.280</a></span> | <span class="t">We are not even close to maximizing the quality of data fed into our models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=133" target="_blank">00:02:13.520</a></span> | <span class="t">This is Arthur Mench, co-founder of Mistral, the creators of some of the most cutting edge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=137" target="_blank">00:02:17.880</a></span> | <span class="t">open source AI models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=139" target="_blank">00:02:19.600</a></span> | <span class="t">To increase that efficiency, you do need to work on coming up with very high quality data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=144" target="_blank">00:02:24.840</a></span> | <span class="t">featuring things, many new techniques that needs to be invented still, but that's really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=149" target="_blank">00:02:29.920</a></span> | <span class="t">where the lock is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=152" target="_blank">00:02:32.160</a></span> | <span class="t">Data is the one important thing, and the ability of the model to decide how much compute it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=158" target="_blank">00:02:38.200</a></span> | <span class="t">wants to allocate to a certain problem is definitely on the frontier as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=162" target="_blank">00:02:42.760</a></span> | <span class="t">So these are things that we're actively looking at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=165" target="_blank">00:02:45.840</a></span> | <span class="t">I'll speak more about letting models think for longer and inference time compute later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=171" target="_blank">00:02:51.120</a></span> | <span class="t">on in this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=172" target="_blank">00:02:52.120</a></span> | <span class="t">But if you still weren't convinced about the importance of data quality, here's Sebastian</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=177" target="_blank">00:02:57.800</a></span> | <span class="t">Bubek, who might be able to persuade you in an interview for AI Insiders on Patreon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=184" target="_blank">00:03:04.600</a></span> | <span class="t">That last slide that you did on, for your channel, amazing channel, where it was like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=188" target="_blank">00:03:08.880</a></span> | <span class="t">a thousand X increase in effective compute and parameters and data, it seems massive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=194" target="_blank">00:03:14.760</a></span> | <span class="t">to me, and I don't think enough people are appreciating that point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=199" target="_blank">00:03:19.800</a></span> | <span class="t">Yeah, I think it's pretty massive, to be honest, you know, before working on this line of work,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=205" target="_blank">00:03:25.560</a></span> | <span class="t">I was thinking about improving the optimization algorithm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=208" target="_blank">00:03:28.640</a></span> | <span class="t">I was thinking about improving the architecture, and I worked on this for a few years, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=212" target="_blank">00:03:32.320</a></span> | <span class="t">we could get, you know, 2%, 3% improvement, like this small type of, you know, around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=217" target="_blank">00:03:37.720</a></span> | <span class="t">the edges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=218" target="_blank">00:03:38.720</a></span> | <span class="t">It's nice, but it's tiny.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=220" target="_blank">00:03:40.800</a></span> | <span class="t">But then suddenly when we started to focus on the data and really trying to craft data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=226" target="_blank">00:03:46.240</a></span> | <span class="t">in a way that is more digestible by the LLM at training time, suddenly we saw this incredible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=233" target="_blank">00:03:53.120</a></span> | <span class="t">like, you know, thousand X gains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=235" target="_blank">00:03:55.560</a></span> | <span class="t">So yes, I think it is massive, and it's really pointing to where the gold is, and the gold</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=241" target="_blank">00:04:01.380</a></span> | <span class="t">is in the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=242" target="_blank">00:04:02.380</a></span> | <span class="t">Now, at this point, I know many of you will be saying, we get it, Philip, data quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=245" target="_blank">00:04:05.880</a></span> | <span class="t">is important, but tell us about the new architectures that might be processing that data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=250" target="_blank">00:04:10.880</a></span> | <span class="t">In other words, tell us about Mamba.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=253" target="_blank">00:04:13.060</a></span> | <span class="t">That's a new architecture that has been generating a lot of buzz in AI circles, if not for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=258" target="_blank">00:04:18.480</a></span> | <span class="t">general public.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=259" target="_blank">00:04:19.480</a></span> | <span class="t">I've been hoping to speak to one of the only two authors on this paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=264" target="_blank">00:04:24.420</a></span> | <span class="t">In the meantime, I want to try to translate its significance to the lay person.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=269" target="_blank">00:04:29.840</a></span> | <span class="t">I'm going to try to convey what Mamba is and what it means in just two or three minutes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=275" target="_blank">00:04:35.720</a></span> | <span class="t">Before we touch on the contender, let's talk about the King Transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=280" target="_blank">00:04:40.100</a></span> | <span class="t">That's the architecture behind everything from DALI 3 to GPT 4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=284" target="_blank">00:04:44.580</a></span> | <span class="t">And transformers are famous in part because they're great at paying attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=289" target="_blank">00:04:49.400</a></span> | <span class="t">In this diagram from the famous illustrated transformer, we see that as we encode or process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=294" target="_blank">00:04:54.100</a></span> | <span class="t">the word it, the transformer architecture pays attention to all of the previous words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=299" target="_blank">00:04:59.140</a></span> | <span class="t">or tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=300" target="_blank">00:05:00.140</a></span> | <span class="t">Some, of course, like animal more than others, and it will do this for all of the words it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=304" target="_blank">00:05:04.480</a></span> | <span class="t">going to encode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=305" target="_blank">00:05:05.800</a></span> | <span class="t">And the truth is that paying attention is great, but the kind of attention in transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=310" target="_blank">00:05:10.580</a></span> | <span class="t">where every element must attend to every other element is complex at big scales.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=316" target="_blank">00:05:16.800</a></span> | <span class="t">In fact, it's called quadratic complexity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=319" target="_blank">00:05:19.240</a></span> | <span class="t">And whenever you hear that word quadratic, think square.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=322" target="_blank">00:05:22.080</a></span> | <span class="t">You may remember the word quadratic from school and the Y equals X squared graph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=327" target="_blank">00:05:27.680</a></span> | <span class="t">And hopefully that makes sense because as you double the number of elements, you far</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=331" target="_blank">00:05:31.620</a></span> | <span class="t">more than double the number of pairwise connections.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=335" target="_blank">00:05:35.000</a></span> | <span class="t">In a very rough analogy, imagine everyone shaking hands in a room.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=339" target="_blank">00:05:39.360</a></span> | <span class="t">And if you triple the number of people in that large room, you are roughly 9xing 3 squared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=346" target="_blank">00:05:46.080</a></span> | <span class="t">the number of handshakes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=347" target="_blank">00:05:47.520</a></span> | <span class="t">But now imagine sequences of 1 million interconnected tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=352" target="_blank">00:05:52.200</a></span> | <span class="t">No one has that much attention to give.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=355" target="_blank">00:05:55.000</a></span> | <span class="t">But there are other known ways to process a sequence of inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=358" target="_blank">00:05:58.960</a></span> | <span class="t">How about a state of fixed size being updated by inputs step by step?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=364" target="_blank">00:06:04.120</a></span> | <span class="t">It seems simpler, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=365" target="_blank">00:06:05.320</a></span> | <span class="t">Although it's a lot less parallelizable, that is a hard word to say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=369" target="_blank">00:06:09.260</a></span> | <span class="t">Now there have been attempts for quite a while to get the best of both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=373" target="_blank">00:06:13.160</a></span> | <span class="t">Here's Albert Gu, one of the lead authors of Mamba, and his paper from 2021 was called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=378" target="_blank">00:06:18.680</a></span> | <span class="t">Structured State Spaces for Sequence Modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=381" target="_blank">00:06:21.440</a></span> | <span class="t">Indeed, that 4 S's name had so much S sound sibilance, it inspired the Mamba snake name.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=389" target="_blank">00:06:29.840</a></span> | <span class="t">But now let's get to the Mamba paper itself and the key diagram therein.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=394" target="_blank">00:06:34.920</a></span> | <span class="t">There's that hidden state on the left, merrily processing its way across to the right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=400" target="_blank">00:06:40.740</a></span> | <span class="t">Updated in turn by the inputs coming in from here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=404" target="_blank">00:06:44.040</a></span> | <span class="t">This long lasting state needs to be a rich but compressed expression of all of the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=410" target="_blank">00:06:50.480</a></span> | <span class="t">seen so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=411" target="_blank">00:06:51.760</a></span> | <span class="t">But if this approach can be made to work, it would mean far fewer connections to compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=417" target="_blank">00:06:57.000</a></span> | <span class="t">and therefore faster inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=418" target="_blank">00:06:58.560</a></span> | <span class="t">Indeed, the paper claims 5x faster inference on NVIDIA's A100.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=423" target="_blank">00:07:03.160</a></span> | <span class="t">And without that quadratic complexity, it would mean that even extremely long sequences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=427" target="_blank">00:07:07.960</a></span> | <span class="t">- think vast code bases, DNA sequences, and even the video input from a long YouTube explainer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=435" target="_blank">00:07:15.400</a></span> | <span class="t">- could now be handled without a mental breakdown.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=439" target="_blank">00:07:19.000</a></span> | <span class="t">But remember, that state needs to compress all the data it's seen, including therefore</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=443" target="_blank">00:07:23.960</a></span> | <span class="t">ignoring certain inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=445" target="_blank">00:07:25.800</a></span> | <span class="t">And that is where the selection mechanism comes in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=449" target="_blank">00:07:29.080</a></span> | <span class="t">It decides what inputs to ignore and which to concentrate on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=453" target="_blank">00:07:33.360</a></span> | <span class="t">The trouble is, this rich and expressive hidden state with the distilled selected inputs is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=458" target="_blank">00:07:38.880</a></span> | <span class="t">slow to process and computationally demanding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=462" target="_blank">00:07:42.300</a></span> | <span class="t">So how did Tredow keep this hidden state rich and expressive with the distilled wisdom of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=467" target="_blank">00:07:47.400</a></span> | <span class="t">previous inputs?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=468" target="_blank">00:07:48.600</a></span> | <span class="t">How did they expand that state without bringing everything to a standstill?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=472" target="_blank">00:07:52.640</a></span> | <span class="t">Well, by painting it orange.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=474" target="_blank">00:07:54.400</a></span> | <span class="t">No, but seriously, what orange means in the diagram is that it's processed in the GPU</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=479" target="_blank">00:07:59.680</a></span> | <span class="t">SRAM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=480" target="_blank">00:08:00.680</a></span> | <span class="t">Think of that as the super fast part of the GPU's memory with the shortest commute to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=485" target="_blank">00:08:05.800</a></span> | <span class="t">the processing chip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=487" target="_blank">00:08:07.280</a></span> | <span class="t">In contrast, all the model parameters in green, which won't change, and the inputs can be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=492" target="_blank">00:08:12.200</a></span> | <span class="t">handled by the slower high bandwidth memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=495" target="_blank">00:08:15.160</a></span> | <span class="t">All of this is where we get the term hardware aware state expansion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=499" target="_blank">00:08:19.600</a></span> | <span class="t">It's an architecture built with an awareness of the kind of GPUs it's going to run on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=505" target="_blank">00:08:25.080</a></span> | <span class="t">Let's try to make this more tangible with an example of what we can achieve with all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=508" target="_blank">00:08:28.520</a></span> | <span class="t">of this freed up complexity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=510" target="_blank">00:08:30.560</a></span> | <span class="t">Take this induction head comparison.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=512" target="_blank">00:08:32.880</a></span> | <span class="t">First take the word explained, which is made up of two tokens, explur and aimed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=518" target="_blank">00:08:38.200</a></span> | <span class="t">An induction head is a circuit that might be attending to the token explur and its function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=523" target="_blank">00:08:43.720</a></span> | <span class="t">is to scan the existing sequence for previous examples of that token that it's attending</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=528" target="_blank">00:08:48.600</a></span> | <span class="t">to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=529" target="_blank">00:08:49.600</a></span> | <span class="t">Then it needs to find the token that in that survey came after the token, which in our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=534" target="_blank">00:08:54.400</a></span> | <span class="t">case will be aimed, and then forecast that that will happen once more to give us explained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=539" target="_blank">00:08:59.480</a></span> | <span class="t">Obviously, you need to be great at recall to do this, especially if the sequence involves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=544" target="_blank">00:09:04.240</a></span> | <span class="t">thousands, hundreds of thousands, or even millions of tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=549" target="_blank">00:09:09.160</a></span> | <span class="t">Other architectures fall apart as the sequence length gets longer than that found in training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=554" target="_blank">00:09:14.440</a></span> | <span class="t">but not Mamba.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=555" target="_blank">00:09:15.880</a></span> | <span class="t">Look at the top line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=557" target="_blank">00:09:17.280</a></span> | <span class="t">Accuracy staying at one, even up to a million tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=561" target="_blank">00:09:21.960</a></span> | <span class="t">And remember that architectures like Mamba need not necessarily hunt alone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=566" target="_blank">00:09:26.360</a></span> | <span class="t">Take this announcement of striped hyena from Together AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=569" target="_blank">00:09:29.920</a></span> | <span class="t">They showed that we need not necessarily choose with a hybrid architecture involving attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=575" target="_blank">00:09:35.640</a></span> | <span class="t">performing well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=576" target="_blank">00:09:36.640</a></span> | <span class="t">But there's one more thing before we put the Mamba snake back into the basket.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=581" target="_blank">00:09:41.360</a></span> | <span class="t">On the left, you can see its superior performance at great apes DNA classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=586" target="_blank">00:09:46.440</a></span> | <span class="t">In other words, deciding whether a sequence of DNA was human, chimpanzee, gorilla, orangutan,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=591" target="_blank">00:09:51.560</a></span> | <span class="t">or bonobo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=592" target="_blank">00:09:52.560</a></span> | <span class="t">Notice that it's on the longest sequence lengths that its performance starts to really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=596" target="_blank">00:09:56.800</a></span> | <span class="t">shine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=597" target="_blank">00:09:57.800</a></span> | <span class="t">This task, by the way, they made artificially hard for themselves because it was originally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=601" target="_blank">00:10:01.360</a></span> | <span class="t">about distinguishing between a human, lemur, mouse, pig, and hippo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=605" target="_blank">00:10:05.480</a></span> | <span class="t">But you could easily imagine other use cases like healthcare.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=608" target="_blank">00:10:08.880</a></span> | <span class="t">You could rapidly analyze a patient's genetic data and come up with personalized medical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=613" target="_blank">00:10:13.560</a></span> | <span class="t">treatment for them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=614" target="_blank">00:10:14.840</a></span> | <span class="t">More speculatively, you could imagine a chat bot that remembers a conversation you had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=619" target="_blank">00:10:19.560</a></span> | <span class="t">months or years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=621" target="_blank">00:10:21.120</a></span> | <span class="t">And then of course, I'll leave it to you to think of all the other long sequences out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=625" target="_blank">00:10:25.520</a></span> | <span class="t">there like stock market data or weather data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=628" target="_blank">00:10:28.980</a></span> | <span class="t">And as I mentioned before, video data from those long video explainers that annoy everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=634" target="_blank">00:10:34.720</a></span> | <span class="t">But wait, is this video becoming one of those?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=637" target="_blank">00:10:37.120</a></span> | <span class="t">I really hope not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=638" target="_blank">00:10:38.320</a></span> | <span class="t">So I'm going to move on to the next reason that AI is not slowing down anytime soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=644" target="_blank">00:10:44.000</a></span> | <span class="t">That is inference time compute, or the ability of the model, as Arthur Mensch said, to decide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=649" target="_blank">00:10:49.640</a></span> | <span class="t">how much compute to allocate to certain problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=652" target="_blank">00:10:52.920</a></span> | <span class="t">Now I touched on this in my Q star video, but here's Lucas Kaiser, one of the authors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=658" target="_blank">00:10:58.080</a></span> | <span class="t">of the transformer architecture and indeed a senior figure for open AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=663" target="_blank">00:11:03.120</a></span> | <span class="t">For reasoning, you also need these chains of thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=667" target="_blank">00:11:07.200</a></span> | <span class="t">You need to give the model the ability to think longer than it has layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=674" target="_blank">00:11:14.720</a></span> | <span class="t">But it can be combined with multimodal, especially when you have -- nowadays, models, they can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=680" target="_blank">00:11:20.920</a></span> | <span class="t">generate, you say, "Okay, how does it look when a boy kicks a ball?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=685" target="_blank">00:11:25.240</a></span> | <span class="t">And you can generate a few frames of the video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=687" target="_blank">00:11:27.520</a></span> | <span class="t">And now more and more, there are models that will generate the whole video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=692" target="_blank">00:11:32.200</a></span> | <span class="t">And then there start to be models of the world that say, "Well, if you drive a car like this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=696" target="_blank">00:11:36.040</a></span> | <span class="t">how will the street look?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=697" target="_blank">00:11:37.120</a></span> | <span class="t">How will people look?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=698" target="_blank">00:11:38.240</a></span> | <span class="t">What will happen?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=699" target="_blank">00:11:39.240</a></span> | <span class="t">Will you crash into something?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=701" target="_blank">00:11:41.840</a></span> | <span class="t">So in the future, the models will have this knowledge of the world and this generation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=706" target="_blank">00:11:46.720</a></span> | <span class="t">which we call chain of thought and text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=709" target="_blank">00:11:49.360</a></span> | <span class="t">But multimodality, this means just it's a chain of frames of what's going to happen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=714" target="_blank">00:11:54.080</a></span> | <span class="t">to the world, which is basically how we sometimes think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=717" target="_blank">00:11:57.440</a></span> | <span class="t">So it will be multimodality and this ability to generate sequences of things before you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=723" target="_blank">00:12:03.000</a></span> | <span class="t">give an answer that will resemble much more what we call reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=728" target="_blank">00:12:08.760</a></span> | <span class="t">For more on that, check out my Q* video, but here's another taster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=732" target="_blank">00:12:12.760</a></span> | <span class="t">This is from Noam Brown, also of OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=735" target="_blank">00:12:15.600</a></span> | <span class="t">He admitted that letting models think for longer would occasionally have drawbacks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=740" target="_blank">00:12:20.560</a></span> | <span class="t">Inference at times may be 1,000x slower and more costly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=744" target="_blank">00:12:24.440</a></span> | <span class="t">And he said, "What inference cost would we pay for a new cancer drug, or for a proof</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=749" target="_blank">00:12:29.440</a></span> | <span class="t">of the Riemann hypothesis?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=751" target="_blank">00:12:31.240</a></span> | <span class="t">AlphaCode2, which I've also done a video on, gives us a foretaste of the kind of results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=756" target="_blank">00:12:36.720</a></span> | <span class="t">that we might expect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=758" target="_blank">00:12:38.120</a></span> | <span class="t">And remember, this is separate from data quality or dynamic new architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=762" target="_blank">00:12:42.000</a></span> | <span class="t">But we can't mention AlphaCode2 and inference time compute without also mentioning Let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=767" target="_blank">00:12:47.920</a></span> | <span class="t">Verify Step-by-Step, aka process-based verification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=771" target="_blank">00:12:51.360</a></span> | <span class="t">But I know what you're wondering, what is this graph and where does it come from?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=774" target="_blank">00:12:54.360</a></span> | <span class="t">Well, it comes from a fascinating new paper entitled "AI Capabilities Can Be Significantly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=779" target="_blank">00:12:59.520</a></span> | <span class="t">Improved Without Expensive Retraining".</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=782" target="_blank">00:13:02.040</a></span> | <span class="t">In a way, this paper sums up the message of this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=785" target="_blank">00:13:05.460</a></span> | <span class="t">We are not even close to being done with the exponential gains in AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=790" target="_blank">00:13:10.400</a></span> | <span class="t">And the way that this paper measured it was fascinating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=793" target="_blank">00:13:13.560</a></span> | <span class="t">It basically asked how much extra computing power would we have to provide to get the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=799" target="_blank">00:13:19.240</a></span> | <span class="t">equivalent gain that these methods provide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=802" target="_blank">00:13:22.400</a></span> | <span class="t">As you can see, the methods are quite diverse and almost all of them have been covered before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=807" target="_blank">00:13:27.680</a></span> | <span class="t">on this channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=808" target="_blank">00:13:28.680</a></span> | <span class="t">Things like prompting and scaffolding, a bit like smart GPT, tool use, or indeed data quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=814" target="_blank">00:13:34.240</a></span> | <span class="t">as we saw with Orca and self-consistency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=817" target="_blank">00:13:37.480</a></span> | <span class="t">If you're not familiar with either Orca or self-consistency and majority voting, check</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=821" target="_blank">00:13:41.920</a></span> | <span class="t">out the videos that I've done before linked in the description.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=825" target="_blank">00:13:45.240</a></span> | <span class="t">The x-axis, by the way, is the one-time compute cost that these methods entail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=830" target="_blank">00:13:50.300</a></span> | <span class="t">Yes, some of them go up to 1% or even 10% as a fraction of the training compute used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=836" target="_blank">00:13:56.680</a></span> | <span class="t">to create the models, but look at the returns on the y-axis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=841" target="_blank">00:14:01.360</a></span> | <span class="t">Having a verifier check the steps of a model does cost 0.001% as a fraction of the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=849" target="_blank">00:14:09.860</a></span> | <span class="t">compute, but the compute equivalent gain is around 9.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=853" target="_blank">00:14:13.520</a></span> | <span class="t">In other words, you would have had to use 9 times as much compute on the base model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=858" target="_blank">00:14:18.000</a></span> | <span class="t">to achieve similar results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=859" target="_blank">00:14:19.880</a></span> | <span class="t">And yes, many of these methods can indeed be combined.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=863" target="_blank">00:14:23.440</a></span> | <span class="t">Indeed that's what smart GPT was all about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=865" target="_blank">00:14:25.600</a></span> | <span class="t">It was combining chain of thought, few-shotting, and majority voting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=869" target="_blank">00:14:29.640</a></span> | <span class="t">In 2024, we may see the PHY2 data quality approach combined with, say, the Mamba architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=875" target="_blank">00:14:35.760</a></span> | <span class="t">And all of this is before we scale the models up as the paper says, "Gains from enhancements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=881" target="_blank">00:14:41.640</a></span> | <span class="t">and gains from scaling might interact and compound in non-trivial ways."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=886" target="_blank">00:14:46.840</a></span> | <span class="t">And they give the example that chain of thought prompting didn't even work on smaller models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=891" target="_blank">00:14:51.160</a></span> | <span class="t">I remember saying toward the end of my smart GPT video in August that we need to find out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=896" target="_blank">00:14:56.920</a></span> | <span class="t">the ceiling of the models, not just the floor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=900" target="_blank">00:15:00.040</a></span> | <span class="t">And the authors concur saying researchers could also study whether there is a ceiling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=904" target="_blank">00:15:04.320</a></span> | <span class="t">to the total improvement you can get from post-training enhancements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=908" target="_blank">00:15:08.300</a></span> | <span class="t">That will enable the HEI labs to better predict how much more capable their model might become</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=913" target="_blank">00:15:13.920</a></span> | <span class="t">in the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=914" target="_blank">00:15:14.920</a></span> | <span class="t">Now, I know what some veteran researchers will be thinking while looking at these charts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=919" target="_blank">00:15:19.800</a></span> | <span class="t">Surely it depends on the task and the benchmark and the models, and all of these numbers must</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=925" target="_blank">00:15:25.280</a></span> | <span class="t">be very approximate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=926" target="_blank">00:15:26.280</a></span> | <span class="t">And of course, you are right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=928" target="_blank">00:15:28.400</a></span> | <span class="t">But I have one more critique in addition to that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=931" target="_blank">00:15:31.120</a></span> | <span class="t">And that is the third, or is it fourth, to be honest, I've lost count, reason why AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=935" target="_blank">00:15:35.880</a></span> | <span class="t">is going to continue to improve dramatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=938" target="_blank">00:15:38.760</a></span> | <span class="t">And that is prompt optimization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=940" target="_blank">00:15:40.720</a></span> | <span class="t">I spoke to Tim Rochtaschel of Google DeepMind about this for Patreon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=944" target="_blank">00:15:44.960</a></span> | <span class="t">But this is what I mean in a nutshell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=947" target="_blank">00:15:47.380</a></span> | <span class="t">Language models can optimize their own prompts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=949" target="_blank">00:15:49.880</a></span> | <span class="t">There are many techniques for doing this, but the manual methods we're coming up with,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=954" target="_blank">00:15:54.720</a></span> | <span class="t">the heuristics like this is important for my career and my grandma wants me to do this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=959" target="_blank">00:15:59.480</a></span> | <span class="t">are our manual feeble approaches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=961" target="_blank">00:16:01.920</a></span> | <span class="t">Once we deploy LLMs to help us optimize the prompts going into LLMs, we might see dramatically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=968" target="_blank">00:16:08.480</a></span> | <span class="t">better performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=969" target="_blank">00:16:09.480</a></span> | <span class="t">Indeed, we already have for things like high school mathematics and movie recommendations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=975" target="_blank">00:16:15.160</a></span> | <span class="t">Anyway, this is the simplified version.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=977" target="_blank">00:16:17.160</a></span> | <span class="t">Do check out that video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=978" target="_blank">00:16:18.360</a></span> | <span class="t">But the point is this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=979" target="_blank">00:16:19.520</a></span> | <span class="t">Even if we weren't going for dramatically better data quality, dynamic new architectures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=984" target="_blank">00:16:24.160</a></span> | <span class="t">and getting models to reason and think for longer, then prompt optimization would allow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=989" target="_blank">00:16:29.680</a></span> | <span class="t">us to squeeze out significantly better results, even from existing models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=994" target="_blank">00:16:34.760</a></span> | <span class="t">And notice I've got through the whole video without yet mentioning, of course, scaling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=998" target="_blank">00:16:38.520</a></span> | <span class="t">the models up to 10 trillion parameters or indeed a hundred trillion parameters as promised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1004" target="_blank">00:16:44.160</a></span> | <span class="t">by Etched.ai.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1005" target="_blank">00:16:45.160</a></span> | <span class="t">I've got much more information about them coming soon, but let's say you're someone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1009" target="_blank">00:16:49.640</a></span> | <span class="t">who doesn't care about stats, benchmarks, or indeed AGI countdowns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1014" target="_blank">00:16:54.520</a></span> | <span class="t">Maybe you're someone who is skeptical about tweets like this from an OpenAI employee who</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1019" target="_blank">00:16:59.240</a></span> | <span class="t">said, "Brace yourselves, AGI is coming."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1022" target="_blank">00:17:02.120</a></span> | <span class="t">Well, even for you, 2024 looks set to be a dramatic year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1026" target="_blank">00:17:06.880</a></span> | <span class="t">These outputs from the Walt team at Google may be low resolution, but they're quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1031" target="_blank">00:17:11.920</a></span> | <span class="t">high consistency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1033" target="_blank">00:17:13.200</a></span> | <span class="t">I use PicoLabs and RunwayML2 and the progress season on season is quite something to watch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1040" target="_blank">00:17:20.240</a></span> | <span class="t">And that would be a prediction I'd make for before the end of 2024.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1044" target="_blank">00:17:24.400</a></span> | <span class="t">I think we will get a 3-5 second photorealistic text to video output that could fool most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1050" target="_blank">00:17:30.280</a></span> | <span class="t">humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1051" target="_blank">00:17:31.280</a></span> | <span class="t">Now you might say, "Oh, I'd never be fooled," but let's test you on that with text to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1055" target="_blank">00:17:35.320</a></span> | <span class="t">image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1056" target="_blank">00:17:36.320</a></span> | <span class="t">Which of these then is the real Roman arch?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1059" target="_blank">00:17:39.280</a></span> | <span class="t">One of them is from Midjourney version 6 upscaled with Magnific and the other is a real arch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1065" target="_blank">00:17:45.520</a></span> | <span class="t">The answer is that the one on the left is the real Roman arch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1070" target="_blank">00:17:50.720</a></span> | <span class="t">Now in my Christmas video, while misspelling some prompts, I did show off the style raw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1076" target="_blank">00:17:56.080</a></span> | <span class="t">input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1077" target="_blank">00:17:57.080</a></span> | <span class="t">This is for anyone using Midjourney version 6.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1079" target="_blank">00:17:59.560</a></span> | <span class="t">But since then, from Reddit, I found an even better tip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1083" target="_blank">00:18:03.080</a></span> | <span class="t">Use the phrase phone photo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1085" target="_blank">00:18:05.200</a></span> | <span class="t">You can get, as you can see, strikingly realistic images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1088" target="_blank">00:18:08.480</a></span> | <span class="t">And of course, you can further upscale any of these too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1091" target="_blank">00:18:11.600</a></span> | <span class="t">You can definitely get some quite interesting results this way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1094" target="_blank">00:18:14.680</a></span> | <span class="t">And at this point, I want to show you this quite fascinating prediction made a hundred</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1099" target="_blank">00:18:19.120</a></span> | <span class="t">years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1100" target="_blank">00:18:20.120</a></span> | <span class="t">This is what the cartoonist Harold Tucker Webster thought the world of drawing would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1105" target="_blank">00:18:25.120</a></span> | <span class="t">be like in 2023.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1107" target="_blank">00:18:27.520</a></span> | <span class="t">Now yes, we're a day into 2024, but I still think this is interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1111" target="_blank">00:18:31.960</a></span> | <span class="t">Notice the drawing is being done automatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1114" target="_blank">00:18:34.800</a></span> | <span class="t">And the caption is, "In the year 2023, when all our work is done by electricity."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1120" target="_blank">00:18:40.080</a></span> | <span class="t">He called it the cartoon dynamo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1122" target="_blank">00:18:42.040</a></span> | <span class="t">We call it Midjourney version 6, but tomato, tomato.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1125" target="_blank">00:18:45.400</a></span> | <span class="t">It's time now to draw the video to an end, but I'm going to end where I started.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1129" target="_blank">00:18:49.880</a></span> | <span class="t">And no, I don't just mean this tweet from Jim Fan.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1132" target="_blank">00:18:52.840</a></span> | <span class="t">I also mean the words I used in the introduction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1136" target="_blank">00:18:56.560</a></span> | <span class="t">And here, via 11labs, is me in quotes, AI explained, Philip, who is a real person and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1143" target="_blank">00:19:03.360</a></span> | <span class="t">not GPT-5 or 6 as some assume, but here's the AI version of my voice delivering the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1149" target="_blank">00:19:09.280</a></span> | <span class="t">intro.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1150" target="_blank">00:19:10.280</a></span> | <span class="t">I hope everyone watching had an excellent 2023 and is looking to get 2024 off to a rambunctious</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1157" target="_blank">00:19:17.760</a></span> | <span class="t">start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1158" target="_blank">00:19:18.760</a></span> | <span class="t">This video has been made to show that we are on the steep part of the exponential and will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1162" target="_blank">00:19:22.400</a></span> | <span class="t">be for a while yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1163" target="_blank">00:19:23.820</a></span> | <span class="t">Just for fun, for all of my legendary supporters on Patreon, I'm going to process this entire</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1169" target="_blank">00:19:29.280</a></span> | <span class="t">video so you can hear how good AI is getting at imitating the human voice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1175" target="_blank">00:19:35.040</a></span> | <span class="t">Soon it may be impossible to tell who's human and who's not using audio alone and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1179" target="_blank">00:19:39.600</a></span> | <span class="t">then soon thereafter even video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1181" target="_blank">00:19:41.640</a></span> | <span class="t">I know you guys know that I'm real, so thank you so much for watching all the way to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Xq-QEd1jpKk&t=1186" target="_blank">00:19:46.680</a></span> | <span class="t">end and, as always, have a wonderful day and a wonderful 2024.</span></div></div></body></html>