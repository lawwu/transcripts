<html><head><title>Deep Learning for Speech Recognition (Adam Coates, Baidu)</title></head><body><a href="index.html">back to index</a><h2>Deep Learning for Speech Recognition (Adam Coates, Baidu)</h2><a href="https://www.youtube.com/watch?v=g-sndkf7mCs"><img src="https://i.ytimg.com/vi_webp/g-sndkf7mCs/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=0">0:0</a> <Untitled Chapter 1><br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=15">0:15</a> Speech recognition<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=287">4:47</a> Traditional ASR pipeline<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=649">10:49</a> Deep Learning in ASR<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=899">14:59</a> Scale model<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=949">15:49</a> Outline<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1043">17:23</a> Raw audio<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1108">18:28</a> Pre-processing<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1186">19:46</a> Spectrogram<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1317">21:57</a> Acoustic Model<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2134">35:34</a> Connectionist Temporal Classification (CTC)<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2347">39:7</a> Training tricks<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2893">48:13</a> Max Decoding<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3139">52:19</a> Language models<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3523">58:43</a> Decoding with LMs: Examples<br><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3554">59:14</a> Rescoring<br><br><div style="text-align: left;"><a href="./g-sndkf7mCs.html">Whisper Transcript</a> | <a href="./transcript_g-sndkf7mCs.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=0">00:00:00.000</a></span> | <span class="t">So I want to tell you guys about speech recognition and deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4">00:00:04.840</a></span> | <span class="t">I think deep learning has been playing an increasingly large role in speech recognition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=10">00:00:10.360</a></span> | <span class="t">And one of the things I think is most exciting about this field is that speech recognition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=15">00:00:15.040</a></span> | <span class="t">is at a place right now where it's becoming good enough to enable really exciting applications</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=20">00:00:20.480</a></span> | <span class="t">that end up in the hands of users.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=23">00:00:23.800</a></span> | <span class="t">So for example, if we want to caption video content and make it accessible to everyone,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=28">00:00:28.680</a></span> | <span class="t">it used to be that we would sort of try to do this, but you still need a human to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=32">00:00:32.960</a></span> | <span class="t">really good captioning for something like a lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=36">00:00:36.480</a></span> | <span class="t">But it's possible that we can do a lot of this with higher quality in the future with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=39">00:00:39.880</a></span> | <span class="t">deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=40">00:00:40.920</a></span> | <span class="t">We can do things like hands-free interfaces in cars, make it safer to use technology while</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=46">00:00:46.040</a></span> | <span class="t">we're on the go and keep people's eyes on the road.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=48">00:00:48.040</a></span> | <span class="t">Of course, it would make mobile devices, home devices much easier, much more efficient and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=53">00:00:53.460</a></span> | <span class="t">enjoyable to use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=56">00:00:56.040</a></span> | <span class="t">But another actually sort of fun recent study that some folks at Baidu participated in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=62">00:01:02.680</a></span> | <span class="t">along with Stanford and UW, was to show that for even something straightforward that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=66">00:01:06.640</a></span> | <span class="t">sort of take for granted as an application of speech, which is just texting someone with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=71">00:01:11.960</a></span> | <span class="t">voice or writing a piece of text, the study showed that you can actually go three times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=76">00:01:16.720</a></span> | <span class="t">faster with voice recognition systems that are available today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=80">00:01:20.680</a></span> | <span class="t">So it's not just like a little bit faster now, even with the errors that a speech recognition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=85">00:01:25.520</a></span> | <span class="t">system can make.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=86">00:01:26.520</a></span> | <span class="t">It's actually a lot faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=88">00:01:28.800</a></span> | <span class="t">And the reason I wanted to highlight this result, which is pretty recent, is that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=94">00:01:34.320</a></span> | <span class="t">speech engine that was used for this study is actually powered by a lot of the deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=99">00:01:39.040</a></span> | <span class="t">methods that I'm going to tell you about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=100">00:01:40.840</a></span> | <span class="t">So hopefully when you walk away today, you have an appreciation or an understanding of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=105">00:01:45.120</a></span> | <span class="t">the sort of high-level ideas that make a result like this possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=110">00:01:50.560</a></span> | <span class="t">So there are a whole bunch of different components that make up a complete speech application.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=117">00:01:57.280</a></span> | <span class="t">So for example, there's speech transcription.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=120">00:02:00.360</a></span> | <span class="t">So if I just talk, I want to come up with words that represent whatever I just said.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=127">00:02:07.740</a></span> | <span class="t">There's also other tasks, though, like word spotting or triggering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=131">00:02:11.080</a></span> | <span class="t">So for example, if my phone is sitting over there and I want to say, "Hey, phone, go do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=134">00:02:14.560</a></span> | <span class="t">something for me," it actually has to be listening continuously for me to say that word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=140">00:02:20.240</a></span> | <span class="t">And likewise, there are things like speaker identification or verification, so that if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=145">00:02:25.120</a></span> | <span class="t">I want to authenticate myself or I want to be able to tell apart different users in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=148">00:02:28.920</a></span> | <span class="t">room, I've got to be able to recognize your voice, even though I don't know what you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=152">00:02:32.440</a></span> | <span class="t">saying.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=153">00:02:33.440</a></span> | <span class="t">So these are different tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=154">00:02:34.440</a></span> | <span class="t">I'm not going to cover all of them today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=156">00:02:36.720</a></span> | <span class="t">Instead, I'm going to just focus on the bread and butter of speech recognition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=160">00:02:40.760</a></span> | <span class="t">We're going to focus on building a speech engine that can accurately transcribe audio</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=165">00:02:45.820</a></span> | <span class="t">into words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=167">00:02:47.420</a></span> | <span class="t">So that's our main goal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=168">00:02:48.880</a></span> | <span class="t">This is a very basic goal of artificial intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=173">00:02:53.680</a></span> | <span class="t">Historically, people are very, very good at listening to someone talk, just like you guys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=179">00:02:59.680</a></span> | <span class="t">are listening to me right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=181">00:03:01.520</a></span> | <span class="t">And you can very quickly turn audio into words and into meaning on your own, almost effortlessly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=190">00:03:10.280</a></span> | <span class="t">And for machines, this has historically been incredibly hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=193">00:03:13.480</a></span> | <span class="t">So you think of this as like one of those sort of consummate AI tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=198">00:03:18.160</a></span> | <span class="t">So the goal of building a speech pipeline is, if you just give me a raw audio wave,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=203">00:03:23.040</a></span> | <span class="t">like you recorded on your laptop or your cell phone, I want to somehow build a speech recognizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=208">00:03:28.360</a></span> | <span class="t">that can do this very simple task of printing out "Hello, world" when I actually say "Hello,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=213">00:03:33.920</a></span> | <span class="t">world."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=215">00:03:35.040</a></span> | <span class="t">So before I dig into the deep learning part, I want to step back a little bit and spend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=222">00:03:42.320</a></span> | <span class="t">maybe 10 minutes talking about how a traditional speech recognition pipeline is working, for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=228">00:03:48.160</a></span> | <span class="t">two reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=229">00:03:49.600</a></span> | <span class="t">If you're out in the wild, you're doing an internship, you're trying to build a speech</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=234">00:03:54.800</a></span> | <span class="t">recognition system with a lot of the tools that are out there, you're going to bump into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=239">00:03:59.160</a></span> | <span class="t">a lot of systems that are built on technologies that look like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=242">00:04:02.880</a></span> | <span class="t">So I want you to understand a little bit of the vocabulary and how those things are put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=247">00:04:07.040</a></span> | <span class="t">together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=248">00:04:08.200</a></span> | <span class="t">And also, this will sort of give you a story for what deep learning is doing in speech</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=253">00:04:13.440</a></span> | <span class="t">recognition today that is kind of special and that I think paves the way for much bigger</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=260">00:04:20.140</a></span> | <span class="t">results in the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=262">00:04:22.900</a></span> | <span class="t">So traditional systems break the problem of converting an audio wave, of taking audio</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=271">00:04:31.180</a></span> | <span class="t">and turning it into a transcription, into a bunch of different pieces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=276">00:04:36.280</a></span> | <span class="t">So I'm going to start out with my raw audio, and I'm just going to represent that by X.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=283">00:04:43.160</a></span> | <span class="t">And then usually we have to decide on some kind of feature representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=287">00:04:47.280</a></span> | <span class="t">We have to convert this into some other form that's easier to deal with than a raw audio</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=292">00:04:52.380</a></span> | <span class="t">wave.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=294">00:04:54.160</a></span> | <span class="t">And in a traditional speech system, I often have something called an acoustic model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=298">00:04:58.300</a></span> | <span class="t">And the job of the acoustic model is to learn the relationship between these features that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=304">00:05:04.320</a></span> | <span class="t">represent my audio and the words that someone is trying to say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=310">00:05:10.040</a></span> | <span class="t">And then I'll often have a language model, which encapsulates all of my knowledge about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=314">00:05:14.520</a></span> | <span class="t">what kinds of words, what spellings and what combinations of words are most likely in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=319">00:05:19.960</a></span> | <span class="t">language that I'm trying to transcribe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=322">00:05:22.640</a></span> | <span class="t">And once you have all of these pieces, so these might be -- these different models might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=327">00:05:27.160</a></span> | <span class="t">be driven by machine learning themselves, what you would need to build in a traditional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=331">00:05:31.160</a></span> | <span class="t">system is something called a decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=334">00:05:34.240</a></span> | <span class="t">And the job of a decoder, which itself might involve some modeling efforts and machine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=339">00:05:39.160</a></span> | <span class="t">learning algorithms, is to find the sequence of words W that maximizes this probability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=347">00:05:47.780</a></span> | <span class="t">The probability of the particular sequence W, given your audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=351">00:05:51.720</a></span> | <span class="t">That's straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=353">00:05:53.460</a></span> | <span class="t">But that's equivalent to maximizing the product of the contributions from your acoustic model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=358">00:05:58.560</a></span> | <span class="t">and from your language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=360">00:06:00.840</a></span> | <span class="t">So a traditional speech system is broken down into these pieces, and a lot of the effort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=365">00:06:05.180</a></span> | <span class="t">in getting that system to work is in developing this sort of portion that combines them all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=372">00:06:12.880</a></span> | <span class="t">So it turns out that if you want to just directly transcribe audio, you can't just go straight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=379">00:06:19.120</a></span> | <span class="t">to characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=380">00:06:20.720</a></span> | <span class="t">And the reason is, and it's especially apparent in English, that the way something is spelled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=386">00:06:26.040</a></span> | <span class="t">in characters doesn't always correspond well to the way that it sounds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=390">00:06:30.700</a></span> | <span class="t">So if I give you the word "night," for example, without context, you don't really know whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=396">00:06:36.280</a></span> | <span class="t">I'm talking about a night in armor or whether I'm talking about night like an evening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=401">00:06:41.520</a></span> | <span class="t">And so a way to get around this, to abstract this problem away from a traditional system,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=406">00:06:46.720</a></span> | <span class="t">is to replace this with a sort of intermediate representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=410">00:06:50.920</a></span> | <span class="t">Instead of trying to predict characters, I'll just try to predict something called phonemes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=415">00:06:55.640</a></span> | <span class="t">So as an example, if I want to represent the word "hello," what I might try to do is break</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=421">00:07:01.520</a></span> | <span class="t">it down into these units of sound.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=424">00:07:04.580</a></span> | <span class="t">So the first one is like the "h," that H sound in "hello," and then an "uh" sound, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=430">00:07:10.040</a></span> | <span class="t">is actually only one possible pronunciation of an E, and then an L and an O sound.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=436">00:07:16.120</a></span> | <span class="t">And that would be my string that I try to come up with using all of my different speech</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=442">00:07:22.040</a></span> | <span class="t">components.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=444">00:07:24.120</a></span> | <span class="t">So this, in one sense, makes the modeling problem easier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=447">00:07:27.680</a></span> | <span class="t">My acoustic model and so on can be simpler, because I don't have to worry about spelling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=453">00:07:33.080</a></span> | <span class="t">But it does have this problem that I have to think about where these things come from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=458">00:07:38.180</a></span> | <span class="t">So these phonemes are intuitively, they're the perceptually distinct units of sound that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=465">00:07:45.920</a></span> | <span class="t">we can use to distinguish words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=468">00:07:48.640</a></span> | <span class="t">And they're very approximate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=471">00:07:51.680</a></span> | <span class="t">This might be our imagination that these things actually exist.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=475">00:07:55.240</a></span> | <span class="t">It's not clear how fundamental this is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=477">00:07:57.880</a></span> | <span class="t">But they're sort of standardized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=478">00:07:58.880</a></span> | <span class="t">There are a bunch of different conventions for how to define these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=485">00:08:05.320</a></span> | <span class="t">And if you end up working on a system that uses phonemes, one popular data set is called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=490">00:08:10.760</a></span> | <span class="t">TIMIT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=492">00:08:12.240</a></span> | <span class="t">And so this actually has a corpus of audio frames with examples of each of these phonemes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=499">00:08:19.640</a></span> | <span class="t">So once you have this phoneme representation, unfortunately, it adds even more complexity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=508">00:08:28.120</a></span> | <span class="t">to this traditional pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=510">00:08:30.580</a></span> | <span class="t">Because now, my acoustic model doesn't associate this audio feature with words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=515">00:08:35.720</a></span> | <span class="t">It actually associates them with another kind of transcription, with the transcription into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=519">00:08:39.720</a></span> | <span class="t">phonemes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=521">00:08:41.000</a></span> | <span class="t">And so I have to introduce yet another component into my pipeline that tries to understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=526">00:08:46.680</a></span> | <span class="t">how do I convert the transcriptions in phonemes into actual spellings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=531">00:08:51.760</a></span> | <span class="t">And so I need some kind of dictionary or a lexicon to tell me all of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=536">00:08:56.800</a></span> | <span class="t">So this is a way of taking our knowledge about a language and baking it into this engineered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=541">00:09:01.660</a></span> | <span class="t">pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=543">00:09:03.560</a></span> | <span class="t">And then once you've got all that, again, all of your work now goes into this decoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=548">00:09:08.560</a></span> | <span class="t">that has a slightly more complicated task in order to infer the most likely word transcription</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=554">00:09:14.560</a></span> | <span class="t">given the audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=557">00:09:17.420</a></span> | <span class="t">So this is a tried and true pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=560">00:09:20.040</a></span> | <span class="t">It's been around for a long time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=562">00:09:22.480</a></span> | <span class="t">You'll see a whole bunch of these systems out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=565">00:09:25.660</a></span> | <span class="t">And we're still using a lot of the vocabulary from these systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=570">00:09:30.920</a></span> | <span class="t">But traditionally, the big advantage is that it's very tweakable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=574">00:09:34.800</a></span> | <span class="t">If you want to go add a new pronunciation for a word you've never heard before, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=578">00:09:38.920</a></span> | <span class="t">can just drop it right in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=580">00:09:40.040</a></span> | <span class="t">That's great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=582">00:09:42.340</a></span> | <span class="t">But it's also really hard to get working well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=584">00:09:44.920</a></span> | <span class="t">If you start from scratch with this system and you have no experience in speech recognition,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=590">00:09:50.360</a></span> | <span class="t">it's actually quite confusing and hard to debug.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=593">00:09:53.240</a></span> | <span class="t">It's very difficult to know which of these various models is the one that's behind your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=598">00:09:58.000</a></span> | <span class="t">error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=599">00:09:59.000</a></span> | <span class="t">And especially once we start dealing with things like accents, heavy noise, different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=603">00:10:03.480</a></span> | <span class="t">kinds of ambiguity, that makes the problem even harder to engineer around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=608">00:10:08.080</a></span> | <span class="t">Because trying to think ourselves about how do I tweak my pronunciation model, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=613">00:10:13.540</a></span> | <span class="t">to account for someone's accent that I haven't heard, that's a very hard engineering judgment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=618">00:10:18.180</a></span> | <span class="t">for us to make.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=620">00:10:20.180</a></span> | <span class="t">So there are all kinds of design decisions that go into this pipeline, like choosing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=624">00:10:24.800</a></span> | <span class="t">the feature representation, for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=628">00:10:28.100</a></span> | <span class="t">So the first place that deep learning has started to make an impact in speech recognition,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=635">00:10:35.260</a></span> | <span class="t">starting a few years ago, is to just take one of the core machine learning components</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=640">00:10:40.780</a></span> | <span class="t">of the system and replace it with a deep learning algorithm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=644">00:10:44.660</a></span> | <span class="t">So I mentioned back in this previous pipeline that we had this little model here whose job</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=650">00:10:50.500</a></span> | <span class="t">is to learn the relationship between a sequence of phonemes and the audio that we're hearing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=656">00:10:56.460</a></span> | <span class="t">So this is called the acoustic model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=659">00:10:59.500</a></span> | <span class="t">And there are lots of different methods for training this thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=663">00:11:03.140</a></span> | <span class="t">So take your favorite machine learning algorithm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=666">00:11:06.140</a></span> | <span class="t">You can probably find someone who is trained in acoustic model with that algorithm, whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=669">00:11:09.740</a></span> | <span class="t">it's a Gaussian mixture model or a bunch of decision trees and random forests, anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=675">00:11:15.200</a></span> | <span class="t">for estimating these kinds of densities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=677">00:11:17.980</a></span> | <span class="t">There's a lot of work in trying to make better acoustic models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=681">00:11:21.700</a></span> | <span class="t">So some work by George Dahl and co-authors took what was a state of the art deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=688">00:11:28.940</a></span> | <span class="t">system back in 2011, which is a deep belief network with some pre-training strategies,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=695">00:11:35.420</a></span> | <span class="t">and dropped it into a state of the art pipeline in place of this acoustic model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=701">00:11:41.140</a></span> | <span class="t">And the results are actually pretty striking, because even though we had neural networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=706">00:11:46.460</a></span> | <span class="t">and these pipelines for a while, what ended up happening is that when you replace the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=712">00:11:52.140</a></span> | <span class="t">Gaussian mixture model and HMM system that already existed with this deep belief network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=718">00:11:58.380</a></span> | <span class="t">as an acoustic model, you actually got something between like a 10% and 20% relative improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=723">00:12:03.300</a></span> | <span class="t">in accuracy, which is a huge jump.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=726">00:12:06.320</a></span> | <span class="t">This is highly noticeable to a person.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=729">00:12:09.140</a></span> | <span class="t">And if you compare this to the amount of progress that had been made in preceding years, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=734">00:12:14.940</a></span> | <span class="t">is a giant leap for a single paper to make, compared to progress we'd been able to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=741">00:12:21.020</a></span> | <span class="t">previously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=742">00:12:22.780</a></span> | <span class="t">So this is in some sense the first generation of deep learning for speech recognition, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=748">00:12:28.380</a></span> | <span class="t">is I take one of these components and I swap it out for my favorite deep learning algorithm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=757">00:12:37.060</a></span> | <span class="t">So the picture looks sort of like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=760">00:12:40.480</a></span> | <span class="t">So with these traditional speech recognition pipelines, the problem that we would always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=766">00:12:46.180</a></span> | <span class="t">run into is that if you gave me a lot more data, you gave me a much bigger computer so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=771">00:12:51.540</a></span> | <span class="t">that I could train a huge model, that actually didn't help me because all the problems I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=776">00:12:56.420</a></span> | <span class="t">had were in the construction of this pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=780">00:13:00.580</a></span> | <span class="t">And so eventually, if you gave me more data and a bigger computer, the performance of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=784">00:13:04.780</a></span> | <span class="t">our speech recognition system would just kind of peter out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=788">00:13:08.340</a></span> | <span class="t">It would just reach a ceiling that was very hard to get over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=791">00:13:11.580</a></span> | <span class="t">And so we just start coming up with lots of different strategies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=794">00:13:14.180</a></span> | <span class="t">We start specializing for each application.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=796">00:13:16.740</a></span> | <span class="t">We try to specialize for each user and try to make things a little bit better around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=801">00:13:21.220</a></span> | <span class="t">the edges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=802">00:13:22.500</a></span> | <span class="t">And what these deep learning acoustic models did was in some sense moved that barrier a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=808">00:13:28.540</a></span> | <span class="t">little ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=809">00:13:29.740</a></span> | <span class="t">It made it possible for us to take a bit more data, much faster computers that let us try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=814">00:13:34.860</a></span> | <span class="t">a whole lot of models, and move that ceiling up quite a ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=820">00:13:40.300</a></span> | <span class="t">So the question that many in the research community, including folks at Baidu, have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=824">00:13:44.780</a></span> | <span class="t">been trying to answer is, can we go to a next generation version of this insight?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=831">00:13:51.780</a></span> | <span class="t">Can we, for instance, build a speech engine that is powered by deep learning all the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=836">00:13:56.740</a></span> | <span class="t">from the audio input to the transcription itself?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=840">00:14:00.740</a></span> | <span class="t">Can we replace as much of that traditional system with deep learning as possible so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=845">00:14:05.380</a></span> | <span class="t">over time, as you give researchers more data and bigger computers and the ability to try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=851">00:14:11.620</a></span> | <span class="t">more models, their speech recognition performance just keeps going up and we can potentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=856">00:14:16.340</a></span> | <span class="t">solve speech for everybody?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=858">00:14:18.880</a></span> | <span class="t">So the goal of this tutorial is not to get you up here, which requires a whole bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=866">00:14:26.180</a></span> | <span class="t">of things that I'll tell you about near the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=869">00:14:29.100</a></span> | <span class="t">But what we want to try to do is give you enough to get a point on this curve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=873">00:14:33.460</a></span> | <span class="t">And then once you're on the curve, the idea is that what remains is now a problem of scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=880">00:14:40.740</a></span> | <span class="t">It's about data and about getting bigger computers and coming up with ways to build bigger models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=887">00:14:47.500</a></span> | <span class="t">So that's my objective, so that when you walk away from here, you have a picture of what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=891">00:14:51.700</a></span> | <span class="t">you would need to build to get this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=894">00:14:54.900</a></span> | <span class="t">And then after that, it's hopefully all about scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=899">00:14:59.180</a></span> | <span class="t">So thanks to Vinay Rao, who's been helping put this tutorial together, there is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=904">00:15:04.580</a></span> | <span class="t">to be some starter code live for the basic pipeline, the deep learning part of the pipeline</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=910">00:15:10.540</a></span> | <span class="t">that we're talking about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=912">00:15:12.300</a></span> | <span class="t">So there are some open source implementations of things like CTC, but we wanted to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=918">00:15:18.180</a></span> | <span class="t">sure that there's a system out there that's pretty representative of the acoustic models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=922">00:15:22.220</a></span> | <span class="t">that I'm going to be talking about in the first half of the presentation here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=927">00:15:27.100</a></span> | <span class="t">So this will be enough that you can get a simple pipeline going with something called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=931">00:15:31.760</a></span> | <span class="t">max decoding, which I'll tell you about later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=934">00:15:34.780</a></span> | <span class="t">And the idea is that this is sort of a scale model of the acoustic models that Baidu and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=940">00:15:40.060</a></span> | <span class="t">other places are powering real production speech engines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=944">00:15:44.260</a></span> | <span class="t">So this will get you that point on the curve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=948">00:15:48.020</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=949">00:15:49.740</a></span> | <span class="t">So here's what we're going to talk about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=952">00:15:52.860</a></span> | <span class="t">The first part, I'm just going to introduce a few preliminaries, talk about preprocessing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=957">00:15:57.360</a></span> | <span class="t">So we still have a little bit of preprocessing around, but it's not really fundamental.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=961">00:16:01.460</a></span> | <span class="t">I think it's probably going to go away in the long run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=964">00:16:04.660</a></span> | <span class="t">We'll talk about what is probably the most mature piece of sequence learning technologies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=971">00:16:11.940</a></span> | <span class="t">for deep learning right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=973">00:16:13.500</a></span> | <span class="t">So it turns out that one of the fundamental problems of doing speech recognition is how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=977">00:16:17.740</a></span> | <span class="t">do I build a neural network that can map this audio signal to a transcription that can have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=983">00:16:23.060</a></span> | <span class="t">a quite variable length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=985">00:16:25.580</a></span> | <span class="t">And so CTC is one highly mature method for doing this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=989">00:16:29.580</a></span> | <span class="t">And I think you're actually going to hear about maybe some other solutions later today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=993">00:16:33.820</a></span> | <span class="t">Then I'll say a little bit about training and just what that looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1000">00:16:40.020</a></span> | <span class="t">And then finally say a bit about decoding and language models, which is sort of an addendum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1005">00:16:45.060</a></span> | <span class="t">to the current acoustic models that we can build that make them perform a lot better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1010">00:16:50.580</a></span> | <span class="t">And then once you have this, that's a picture of what you need to get this point on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1015">00:16:55.580</a></span> | <span class="t">curve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1016">00:16:56.660</a></span> | <span class="t">And then I'll talk a little bit about what's remaining.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1019">00:16:59.300</a></span> | <span class="t">How do you scale up from this little scale model up to the full thing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1024">00:17:04.180</a></span> | <span class="t">What does that actually entail?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1025">00:17:05.860</a></span> | <span class="t">And then time permitting, we'll talk a little bit about production.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1028">00:17:08.740</a></span> | <span class="t">How could you put something like this into a cloud server and actually serve real users</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1033">00:17:13.540</a></span> | <span class="t">with it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1035">00:17:15.540</a></span> | <span class="t">Great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1037">00:17:17.260</a></span> | <span class="t">So how is audio represented?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1040">00:17:20.760</a></span> | <span class="t">This should be pretty straightforward, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1044">00:17:24.100</a></span> | <span class="t">Unlike a two-dimensional image where we normally have a 2D grid of pixels, audio is just a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1048">00:17:28.900</a></span> | <span class="t">1D signal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1050">00:17:30.580</a></span> | <span class="t">And there are a bunch of different formats for audio, but typically this one-dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1055">00:17:35.180</a></span> | <span class="t">wave that is actually me saying something like, "Hello, world," is something like 8,000</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1062">00:17:42.580</a></span> | <span class="t">samples per second or 16,000 samples per second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1066">00:17:46.500</a></span> | <span class="t">And each wave is quantized into 8 or 16 bits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1071">00:17:51.020</a></span> | <span class="t">So when we represent this audio signal that's going to go into our pipeline, you could just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1075">00:17:55.020</a></span> | <span class="t">think of that as a one-dimensional vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1077">00:17:57.380</a></span> | <span class="t">So when I had that box called x that represented my audio signal, you can think of this as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1082">00:18:02.540</a></span> | <span class="t">being broken down into samples, x1, x2, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1087">00:18:07.220</a></span> | <span class="t">And if I had a one-second audio clip, this vector would have a length of either, say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1092">00:18:12.300</a></span> | <span class="t">8,000 or 16,000 samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1094">00:18:14.840</a></span> | <span class="t">And each element would be, say, a floating point number that I'd extracted from this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1099">00:18:19.460</a></span> | <span class="t">8 or 16-bit sample.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1101">00:18:21.140</a></span> | <span class="t">So it's really simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1103">00:18:23.800</a></span> | <span class="t">Now once I have an audio clip, we'll do a little bit of preprocessing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1108">00:18:28.700</a></span> | <span class="t">So there are a couple of ways to start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1111">00:18:31.020</a></span> | <span class="t">The first is to just do some vanilla preprocessing, like convert to a simple spectrogram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1117">00:18:37.540</a></span> | <span class="t">So if you look at a traditional speech pipeline, you're going to see things like MFCCs, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1122">00:18:42.660</a></span> | <span class="t">are male frequency kepstral coefficients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1125">00:18:45.740</a></span> | <span class="t">You'll see a whole bunch of plays on spectrograms where you take differences in different kinds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1130">00:18:50.860</a></span> | <span class="t">of features and try to engineer complex representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1135">00:18:55.500</a></span> | <span class="t">But for the stuff that we're going to do today, a simple spectrogram is just fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1139">00:18:59.700</a></span> | <span class="t">And it turns out, as you'll see in a second, we lose a little bit of information when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1144">00:19:04.180</a></span> | <span class="t">do this, but it turns out not to be a huge difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1148">00:19:08.740</a></span> | <span class="t">Now I said a moment ago that I think probably this is going to go away in the long run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1154">00:19:14.260</a></span> | <span class="t">And that's because today you can actually find recent research in trying to do away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1159">00:19:19.540</a></span> | <span class="t">with even this preprocessing part and having your neural network process the audio wave</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1163">00:19:23.860</a></span> | <span class="t">directly and just train its own feature transformation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1167">00:19:27.660</a></span> | <span class="t">So there's some references at the end that you can look at for this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1172">00:19:32.980</a></span> | <span class="t">So here's a quick straw poll.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1175">00:19:35.460</a></span> | <span class="t">How many people have seen a spectrogram or computed a spectrogram before?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1179">00:19:39.020</a></span> | <span class="t">Pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1180">00:19:40.340</a></span> | <span class="t">Maybe 50%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1181">00:19:41.940</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1183">00:19:43.060</a></span> | <span class="t">So the idea behind a spectrogram is that it's sort of like a frequency domain representation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1189">00:19:49.940</a></span> | <span class="t">but instead of representing this entire signal in terms of frequencies, I'm just going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1195">00:19:55.100</a></span> | <span class="t">represent a small window in terms of frequencies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1199">00:19:59.940</a></span> | <span class="t">So to process this audio clip, the first thing I'm going to do is cut out a little window</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1206">00:20:06.660</a></span> | <span class="t">that's typically about 20 milliseconds long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1209">00:20:09.020</a></span> | <span class="t">And when you get down to that scale, it's usually very clear that these audio signals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1212">00:20:12.880</a></span> | <span class="t">are made up of sort of a combination of different frequencies of sine waves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1218">00:20:18.960</a></span> | <span class="t">And then what we do is we compute an FFT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1221">00:20:21.780</a></span> | <span class="t">It basically converts this little signal into the frequency domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1226">00:20:26.460</a></span> | <span class="t">And then we just take the log of the power at each frequency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1231">00:20:31.260</a></span> | <span class="t">And so if you look at what the result of this is, it basically tells us for every frequency</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1239">00:20:39.420</a></span> | <span class="t">of sine wave, what is the magnitude, what's the amount of power represented by that sine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1244">00:20:44.820</a></span> | <span class="t">wave that makes up this original signal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1248">00:20:48.200</a></span> | <span class="t">So over here in this example, we have a very strong low frequency component in the signal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1255">00:20:55.780</a></span> | <span class="t">And then we have differing magnitudes at different differing frequencies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1261">00:21:01.180</a></span> | <span class="t">So we can just think of this as a vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1266">00:21:06.020</a></span> | <span class="t">So now instead of representing this little 20 millisecond slice as sort of a sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1270">00:21:10.560</a></span> | <span class="t">of audio samples, instead I'm going to represent it as a vector here where each element represents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1278">00:21:18.180</a></span> | <span class="t">sort of the strength of each frequency in this little window.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1282">00:21:22.500</a></span> | <span class="t">And the next step beyond this is that if I just told you how to process one little window,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1288">00:21:28.100</a></span> | <span class="t">you can of course apply this to a whole bunch of windows across the entire piece of audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1294">00:21:34.960</a></span> | <span class="t">And that gives you what we call a spectrogram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1297">00:21:37.400</a></span> | <span class="t">And you can use either disjoint windows that are just sort of adjacent or you can apply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1301">00:21:41.800</a></span> | <span class="t">them to overlapping windows if you like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1304">00:21:44.560</a></span> | <span class="t">So there's a little bit of parameter tuning there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1306">00:21:46.980</a></span> | <span class="t">But this is an alternative representation of this audio signal that happens to be easier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1313">00:21:53.000</a></span> | <span class="t">to use for a lot of purposes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1317">00:21:57.760</a></span> | <span class="t">So our goal, starting from this representation, is to build what I'm going to call an acoustic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1324">00:22:04.200</a></span> | <span class="t">model, but which is really, to the extent we can make it happen, is really going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1328">00:22:08.720</a></span> | <span class="t">be an entire speech engine that is represented by a neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1332">00:22:12.780</a></span> | <span class="t">So what we would like to do is build a neural net that if we could train it from a whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1338">00:22:18.740</a></span> | <span class="t">bunch of pairs, X, which is my original audio that I turn into a spectrogram, and Y star,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1345">00:22:25.000</a></span> | <span class="t">that's the ground truth transcription that some human has given me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1349">00:22:29.000</a></span> | <span class="t">If I were to train this big neural network off of these pairs, what I'd like it to produce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1355">00:22:35.600</a></span> | <span class="t">is some kind of output that I'm representing by the character C here, so that I could later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1361">00:22:41.560</a></span> | <span class="t">extract the correct transcription, which I'm going to denote by Y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1366">00:22:46.920</a></span> | <span class="t">So if I said hello, the first thing I'm going to do is run preprocessing to get all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1371">00:22:51.540</a></span> | <span class="t">spectrogram frames.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1373">00:22:53.340</a></span> | <span class="t">And then I'm going to have a recurrent neural network that consumes each frame and processes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1378">00:22:58.440</a></span> | <span class="t">them into some new representation called C. And hopefully, I can engineer my network in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1384">00:23:04.640</a></span> | <span class="t">such a way that I can just read the transcription off of these output neurons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1389">00:23:09.940</a></span> | <span class="t">So that's kind of the intuitive picture of what we want to accomplish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1395">00:23:15.960</a></span> | <span class="t">So as I mentioned back in the outline, there's one obvious fundamental problem here, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1401">00:23:21.920</a></span> | <span class="t">is that the length of the input is not the same as the length of the transcription.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1408">00:23:28.840</a></span> | <span class="t">So if I say hello very slowly, then I can have a very long audio signal, even though</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1415">00:23:35.120</a></span> | <span class="t">I didn't change the length of the transcription.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1416">00:23:36.760</a></span> | <span class="t">Or if I say hello very quickly, then I can have a very short piece of audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1423">00:23:43.120</a></span> | <span class="t">And so that means that this output of my neural network is changing length, and I need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1427">00:23:47.640</a></span> | <span class="t">come up with some way to map that variable length neural network output to this fixed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1433">00:23:53.440</a></span> | <span class="t">length transcription, and also do it in a way that we can actually train this pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1438">00:23:58.940</a></span> | <span class="t">So the traditional way to deal with this problem, if you were building a speech engine several</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1447">00:24:07.020</a></span> | <span class="t">years ago, is to just try to bootstrap the whole system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1451">00:24:11.040</a></span> | <span class="t">So I'd actually train a neural network to correctly predict the sounds at every frame</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1456">00:24:16.160</a></span> | <span class="t">using some kind of data set like Timit, where someone has lovingly annotated all of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1461">00:24:21.320</a></span> | <span class="t">phonemes for me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1463">00:24:23.140</a></span> | <span class="t">And then I'd try to figure out the alignment between my saying hello in a phonetic transcription</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1468">00:24:28.320</a></span> | <span class="t">with the input audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1470">00:24:30.140</a></span> | <span class="t">And then once I've lined up all of the sounds with the input audio, now I don't care about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1475">00:24:35.080</a></span> | <span class="t">length anymore, because I can just make a one-to-one mapping between the audio input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1480">00:24:40.320</a></span> | <span class="t">and the phoneme outputs that I'm trying to target.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1483">00:24:43.440</a></span> | <span class="t">But this alignment process is horribly error-prone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1487">00:24:47.420</a></span> | <span class="t">You have to do a lot of extra work to make it work well, and so we really don't want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1491">00:24:51.160</a></span> | <span class="t">to do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1492">00:24:52.160</a></span> | <span class="t">We really want to have some kind of solution that lets us solve this straightaway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1497">00:24:57.920</a></span> | <span class="t">So there are multiple ways to do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1499">00:24:59.680</a></span> | <span class="t">And as I mentioned, there's some current research on how to use things like attentional models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1504">00:25:04.280</a></span> | <span class="t">sequence-to-sequence models that you'll hear about later, in order to solve this kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1510">00:25:10.960</a></span> | <span class="t">problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1511">00:25:11.960</a></span> | <span class="t">And then, as I said, we'll focus on something called connectionist temporal classification,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1517">00:25:17.280</a></span> | <span class="t">or CTC, that is sort of current state-of-the-art for how to do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1523">00:25:23.000</a></span> | <span class="t">So here's the basic idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1524">00:25:24.960</a></span> | <span class="t">So our recurrent neural network has these output neurons that I'm calling C. And the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1531">00:25:31.680</a></span> | <span class="t">job of these output neurons is to encode a distribution over the output symbols.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1539">00:25:39.560</a></span> | <span class="t">So because of the structure of the recurrent network, the length of this symbol sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1545">00:25:45.480</a></span> | <span class="t">C is the same as the length of my audio input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1548">00:25:48.280</a></span> | <span class="t">So if my audio input, say, was two seconds long, that might have 100 audio frames.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1555">00:25:55.500</a></span> | <span class="t">And that would mean that the length of C is also 100 different values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1561">00:26:01.200</a></span> | <span class="t">So if we were working on a phoneme-based model, then C would be some kind of phoneme representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1567">00:26:07.640</a></span> | <span class="t">And we would also include a blank symbol, which is special for CTC.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1572">00:26:12.640</a></span> | <span class="t">But if, as we'll do in the rest of this talk, we're trying to just predict the graphemes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1579">00:26:19.040</a></span> | <span class="t">trying to predict the characters in this language directly from the audio, then I would just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1584">00:26:24.400</a></span> | <span class="t">let C take on a value that's in my alphabet, or take on a blank or a space, if my language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1590">00:26:30.940</a></span> | <span class="t">has spaces in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1593">00:26:33.520</a></span> | <span class="t">And then the second thing I'm going to do, once my RNN gives me a distribution over these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1599">00:26:39.540</a></span> | <span class="t">symbols C, is that I'm going to try to define some kind of mapping that can convert this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1605">00:26:45.240</a></span> | <span class="t">long transcription C into the final transcription Y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1610">00:26:50.480</a></span> | <span class="t">That's like, hello.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1611">00:26:51.720</a></span> | <span class="t">That's the actual string that I want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1615">00:26:55.000</a></span> | <span class="t">And now, recognizing that C is itself a probabilistic creature, there's a distribution over choices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1621">00:27:01.260</a></span> | <span class="t">of C that correspond to the audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1624">00:27:04.680</a></span> | <span class="t">Once I apply this function, that also means that there's a distribution over Y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1628">00:27:08.760</a></span> | <span class="t">There's a distribution over the possible transcriptions that I could get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1632">00:27:12.680</a></span> | <span class="t">And what I'll want to do to train my network is to maximize the probability of the correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1637">00:27:17.760</a></span> | <span class="t">transcription given the audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1640">00:27:20.600</a></span> | <span class="t">So those are the three steps that we have to accomplish in order to make CTC work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1646">00:27:26.400</a></span> | <span class="t">So let's start with the first one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1649">00:27:29.520</a></span> | <span class="t">So we have these output neurons C, and they represent a distribution over the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1656">00:27:36.240</a></span> | <span class="t">symbols that I could be hearing in the audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1659">00:27:39.680</a></span> | <span class="t">So I've got some audio signal down here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1661">00:27:41.380</a></span> | <span class="t">You can see the spectrogram frames poking up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1664">00:27:44.740</a></span> | <span class="t">And this is being processed by this recurrent neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1668">00:27:48.440</a></span> | <span class="t">And the output is a big bank of softmax neurons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1673">00:27:53.320</a></span> | <span class="t">So for the first frame of audio, I have a neuron that corresponds to each of the symbols</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1679">00:27:59.820</a></span> | <span class="t">that C could represent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1682">00:28:02.680</a></span> | <span class="t">And this set of softmax neurons here, with the output summing to 1, represents the probability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1690">00:28:10.620</a></span> | <span class="t">of, say, C1 having the value A, B, C, and so on, or this special blank character.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1697">00:28:17.680</a></span> | <span class="t">So for example, if I pick one of the neurons over here, then the first row, which represents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1704">00:28:24.280</a></span> | <span class="t">the character B, and the 17th column, which is the 17th frame in time, this represents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1711">00:28:31.760</a></span> | <span class="t">the probability that C17 represents the character B, given the audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1720">00:28:40.920</a></span> | <span class="t">So once I have this, that also means that I can just define a distribution not just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1727">00:28:47.160</a></span> | <span class="t">over the individual characters, but if I just assume that all of the characters are independent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1733">00:28:53.080</a></span> | <span class="t">which is kind of a naive assumption, but if I bake this into the system, I can define</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1737">00:28:57.820</a></span> | <span class="t">a distribution over all possible sequences of characters in this alphabet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1744">00:29:04.520</a></span> | <span class="t">So if I gave you a specific instance, a specific character string using this alphabet, for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1751">00:29:11.960</a></span> | <span class="t">instance, I represent the string hello as H-H-H-E, blank E, blank blank L-L, blank L-O,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1761">00:29:21.080</a></span> | <span class="t">and then a bunch of blanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1762">00:29:22.600</a></span> | <span class="t">This is a string in this alphabet for C, and I can just use this formula to compute the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1768">00:29:28.960</a></span> | <span class="t">probability of this specific sequence of characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1773">00:29:33.560</a></span> | <span class="t">So that's how we compute the probability for a sequence of characters when they have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1778">00:29:38.760</a></span> | <span class="t">same length as the audio input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1783">00:29:43.960</a></span> | <span class="t">So the second step, and this is in some sense the kind of neat trick in CTC, is to define</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1792">00:29:52.440</a></span> | <span class="t">a mapping from this long encoding of the audio into symbols that crunches it down to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1803">00:30:03.240</a></span> | <span class="t">actual transcription that we're trying to predict.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1806">00:30:06.000</a></span> | <span class="t">And the rule is this operator takes this character sequence, and it picks up all the duplicates,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1813">00:30:13.440</a></span> | <span class="t">all of the adjacent characters that are repeated, and discards the duplicates and just keeps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1818">00:30:18.720</a></span> | <span class="t">one of them, and then it drops all of the blanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1823">00:30:23.240</a></span> | <span class="t">So in this example, you see you have three H's together, so I just keep one H, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1829">00:30:29.600</a></span> | <span class="t">I have a blank, I throw that away, and I keep an E, and I have two L's, so I keep one of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1834">00:30:34.640</a></span> | <span class="t">the L's over here, and then another blank, and an L-O.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1838">00:30:38.400</a></span> | <span class="t">And the one key thing to note is that when I have two characters that are different right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1843">00:30:43.280</a></span> | <span class="t">next to each other, I just end up keeping those two characters in my output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1848">00:30:48.680</a></span> | <span class="t">But if I ever have a double character, like L-L in "hello," then I'll need to have a blank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1854">00:30:54.880</a></span> | <span class="t">character that gets put in between.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1858">00:30:58.880</a></span> | <span class="t">But if our neural network gave me this transcription, told me that this was the right answer, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1864">00:31:04.360</a></span> | <span class="t">just have to apply this operator, and we get back the string "hello."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1872">00:31:12.020</a></span> | <span class="t">So now that we have a way to define a distribution over these sequences of symbols that are the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1878">00:31:18.320</a></span> | <span class="t">same length as the audio, and we now have a mapping from those strings into transcriptions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1885">00:31:25.160</a></span> | <span class="t">as I said, this gives us a probability distribution over the possible final transcriptions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1890">00:31:30.920</a></span> | <span class="t">So if I look at the probability distribution over all the different sequences of symbols,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1897">00:31:37.720</a></span> | <span class="t">I might have "hello" written out like on the last slide, and maybe that has probability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1902">00:31:42.620</a></span> | <span class="t">.1, and then I might have "hello" but written a different way, by say replacing this H with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1909">00:31:49.880</a></span> | <span class="t">a blank that has a smaller probability, and I have a whole bunch of different possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1915">00:31:55.160</a></span> | <span class="t">symbol sequences below that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1918">00:31:58.440</a></span> | <span class="t">And what you'll notice is that if I go through every possible combination of symbols here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1926">00:32:06.160</a></span> | <span class="t">there are several combinations that all map to the same transcription.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1930">00:32:10.640</a></span> | <span class="t">So here's one version of "hello," there's a second version of "hello," there's a third</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1935">00:32:15.120</a></span> | <span class="t">version of "hello."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1936">00:32:16.800</a></span> | <span class="t">And so if I now ask, "What's the probability of the transcription 'hello'?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1941">00:32:21.720</a></span> | <span class="t">The way that I compute that is I go through all of the possible character sequences that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1948">00:32:28.080</a></span> | <span class="t">correspond to the transcription "hello," and I add up all of their probabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1953">00:32:33.240</a></span> | <span class="t">So I have to sum over all possible choices of C that could give me that transcription</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1958">00:32:38.680</a></span> | <span class="t">in the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1960">00:32:40.400</a></span> | <span class="t">So you can kind of think of this as searching through all the possible alignments, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1968">00:32:48.080</a></span> | <span class="t">I could shift these characters around a little bit, I could move them forward, backward,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1972">00:32:52.360</a></span> | <span class="t">I could expand them by adding duplicates or squish them up, depending on how fast someone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1976">00:32:56.500</a></span> | <span class="t">is talking, and that corresponds to every possible alignment between the audio and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1984">00:33:04.000</a></span> | <span class="t">characters that I want to transcribe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1985">00:33:05.000</a></span> | <span class="t">It sort of solves the problem of the variable length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1988">00:33:08.760</a></span> | <span class="t">And the way that I get the probability of a specific transcription is to sum up, to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=1994">00:33:14.360</a></span> | <span class="t">marginalize over all the different alignments that could be feasible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2000">00:33:20.920</a></span> | <span class="t">And then if we have a whole bunch of other possibilities in here, like the word "yellow,"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2005">00:33:25.480</a></span> | <span class="t">I'd compute them in the same way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2007">00:33:27.400</a></span> | <span class="t">So this equation just says to sum over all the character sequences C so that when I apply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2012">00:33:32.800</a></span> | <span class="t">this little mapping operator, I end up with the transcription y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2016">00:33:36.160</a></span> | <span class="t">Oh, oh.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2027">00:33:47.880</a></span> | <span class="t">I'm missing a double E. You're talking about this one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2031">00:33:51.920</a></span> | <span class="t">So when we apply this sort of squeezing operator here, we drop this double E to get a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2039">00:33:59.120</a></span> | <span class="t">E in "hello."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2040">00:34:00.120</a></span> | <span class="t">And we remove all the duplicates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2043">00:34:03.320</a></span> | <span class="t">So the same way we did for an H.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2044">00:34:04.320</a></span> | <span class="t">[INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2045">00:34:05.320</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2049">00:34:09.160</a></span> | <span class="t">So whenever you see two characters together like this, where they're adjacent duplicates,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2056">00:34:16.120</a></span> | <span class="t">you sort of squeeze all those duplicates out, and you just keep one of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2059">00:34:19.520</a></span> | <span class="t">But here we have a blank in between.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2061">00:34:21.880</a></span> | <span class="t">So if we drop all the duplicates first, then we still have two L's left, and then we remove</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2067">00:34:27.440</a></span> | <span class="t">all the blanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2069">00:34:29.160</a></span> | <span class="t">So this gives the algorithm a way to represent repeated characters in the transcription.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2073">00:34:33.280</a></span> | <span class="t">There's another one in the back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2078">00:34:38.120</a></span> | <span class="t">[INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2079">00:34:39.120</a></span> | <span class="t">Oh, oh, I see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2082">00:34:42.640</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2083">00:34:43.640</a></span> | <span class="t">This is maybe-- I put a space in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2087">00:34:47.520</a></span> | <span class="t">Really I should have put a space character in here instead of a blank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2091">00:34:51.000</a></span> | <span class="t">Really this could be H-E-L-L-O-H.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2094">00:34:54.920</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2098">00:34:58.120</a></span> | <span class="t">So the space here is erroneous.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2101">00:35:01.240</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2103">00:35:03.240</a></span> | <span class="t">We good?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2106">00:35:06.680</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2108">00:35:08.040</a></span> | <span class="t">So once I've defined this, I just gave you a formula to compute the probability of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2113">00:35:13.600</a></span> | <span class="t">string given the audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2116">00:35:16.360</a></span> | <span class="t">So as with every good starting to a machine learning algorithm, we go and we try to apply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2122">00:35:22.120</a></span> | <span class="t">maximum likelihood.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2123">00:35:23.720</a></span> | <span class="t">I now give you the correct transcription, and your job is to tune the neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2128">00:35:28.440</a></span> | <span class="t">to maximize the probability of that transcription using this model that I just defined.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2134">00:35:34.160</a></span> | <span class="t">So in equations, what I'm going to do is I want to maximize the log probability of y</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2140">00:35:40.960</a></span> | <span class="t">star for a given example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2146">00:35:46.280</a></span> | <span class="t">I want to maximize the probability of the correct transcription given the audio x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2151">00:35:51.680</a></span> | <span class="t">And then I'm just going to sum over all the examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2156">00:35:56.160</a></span> | <span class="t">And then what I want to do is just replace this with the equation that I had on the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2162">00:36:02.040</a></span> | <span class="t">page that says in order to compute the probability of a given transcription, I have to sum over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2167">00:36:07.320</a></span> | <span class="t">all of the possible symbol sequences that could have given me that transcription, sum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2172">00:36:12.120</a></span> | <span class="t">over all the possible alignments that would map that transcription to my audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2178">00:36:18.800</a></span> | <span class="t">So Alex Graves and co-authors in 2006 actually show that because of this independence assumption,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2186">00:36:26.000</a></span> | <span class="t">there is a clever way, there is a dynamic programming algorithm that can efficiently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2189">00:36:29.720</a></span> | <span class="t">compute this summation for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2193">00:36:33.000</a></span> | <span class="t">And not only compute this summation so that you can compute the objective function, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2197">00:36:37.200</a></span> | <span class="t">actually compute its gradient with respect to the output neurons of your neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2202">00:36:42.240</a></span> | <span class="t">So if you look at the paper, the algorithm details are in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2207">00:36:47.000</a></span> | <span class="t">What's cool right now in the history of speech and deep learning is that this is at the level</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2212">00:36:52.200</a></span> | <span class="t">of a technology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2213">00:36:53.540</a></span> | <span class="t">This is something that's now implemented in a bunch of places so that you can download</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2217">00:36:57.500</a></span> | <span class="t">a software package that efficiently will calculate this CTC loss function for you that can calculate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2225">00:37:05.540</a></span> | <span class="t">this likelihood and can also just give you back the gradient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2228">00:37:08.980</a></span> | <span class="t">So I won't go into the equations here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2231">00:37:11.240</a></span> | <span class="t">Instead, I'll tell you that there are a whole bunch of implementations on the web that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2235">00:37:15.760</a></span> | <span class="t">can now use as part of deep learning packages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2239">00:37:19.140</a></span> | <span class="t">So one of them from Baidu implements CTC on the GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2243">00:37:23.120</a></span> | <span class="t">It's called WarpCTC.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2245">00:37:25.960</a></span> | <span class="t">Stanford and the group there, actually one of Andrew's students, has a CTC implementation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2253">00:37:33.360</a></span> | <span class="t">And there's also now CTC losses implemented in packages like TensorFlow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2257">00:37:37.880</a></span> | <span class="t">So this is something that's sufficiently widely distributed that you can use these algorithms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2264">00:37:44.480</a></span> | <span class="t">off the shelf.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2266">00:37:46.880</a></span> | <span class="t">So the way that these work, the way that we go about training, is we start from our audio</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2271">00:37:51.480</a></span> | <span class="t">spectrogram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2272">00:37:52.680</a></span> | <span class="t">We have our neural network structure where you get to choose how it's put together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2278">00:37:58.060</a></span> | <span class="t">And then it outputs this bank of softmax neurons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2281">00:38:01.640</a></span> | <span class="t">And then there are pieces of off-the-shelf software that will compute for you the CTC</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2287">00:38:07.520</a></span> | <span class="t">cost function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2288">00:38:08.520</a></span> | <span class="t">They'll compute this log likelihood given a transcription and the output neurons from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2293">00:38:13.640</a></span> | <span class="t">your recurrent network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2296">00:38:16.440</a></span> | <span class="t">And then the software will also be able to tell you the gradient with respect to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2300">00:38:20.800</a></span> | <span class="t">output neurons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2302">00:38:22.040</a></span> | <span class="t">And once you've got that, you're set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2303">00:38:23.440</a></span> | <span class="t">You can feed them back into the rest of your code and get the gradient with respect to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2307">00:38:27.640</a></span> | <span class="t">all of these parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2309">00:38:29.980</a></span> | <span class="t">So as I said, this is all available now in sort of efficient, off-the-shelf software.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2314">00:38:34.280</a></span> | <span class="t">So you don't have to do this work yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2317">00:38:37.520</a></span> | <span class="t">So that's pretty much all there is to the high-level algorithm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2321">00:38:41.840</a></span> | <span class="t">With this, it's actually enough to get a sort of working drosophila of speech recognition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2328">00:38:48.480</a></span> | <span class="t">going.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2329">00:38:49.800</a></span> | <span class="t">There are a few little tricks, though, that you might need along the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2334">00:38:54.680</a></span> | <span class="t">On easy problems, you might not need these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2337">00:38:57.520</a></span> | <span class="t">But as you get to more difficult data sets with a lot of noise, they can become more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2341">00:39:01.720</a></span> | <span class="t">and more important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2343">00:39:03.360</a></span> | <span class="t">So the first one that we've been calling "sort of grad" in the vein of all of the grad algorithms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2349">00:39:09.080</a></span> | <span class="t">out there is basically a trick to help with recurrent neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2356">00:39:16.600</a></span> | <span class="t">So it turns out that when you try to train one of these big RNN models on some off-the-shelf</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2362">00:39:22.360</a></span> | <span class="t">speech data, one of the things that can really get you is seeing very long utterances early</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2368">00:39:28.680</a></span> | <span class="t">in the process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2370">00:39:30.540</a></span> | <span class="t">Because if you have a really long utterance, then if your neural network is badly initialized,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2376">00:39:36.680</a></span> | <span class="t">you'll often end up with things like underflow and overflow as you try to go and compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2381">00:39:41.000</a></span> | <span class="t">the probabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2382">00:39:42.400</a></span> | <span class="t">And you end up with gradients exploding as you try to do back propagation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2386">00:39:46.320</a></span> | <span class="t">And it can make your optimization a real mess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2389">00:39:49.200</a></span> | <span class="t">And it's coming from the fact that these utterances are really long and really hard, and the neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2393">00:39:53.440</a></span> | <span class="t">network just isn't ready to deal with those transcriptions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2397">00:39:57.280</a></span> | <span class="t">And so one of the fixes that you can use is, during the early parts of training, usually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2402">00:40:02.400</a></span> | <span class="t">in the first epoch, is you just sort all of your audio by length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2407">00:40:07.040</a></span> | <span class="t">And now, when you process a mini-batch, you just take the short utterances first so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2412">00:40:12.040</a></span> | <span class="t">you're working with really short RNNs that are quite easy to train and don't blow up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2416">00:40:16.760</a></span> | <span class="t">and don't have a lot of catastrophic numerical problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2420">00:40:20.480</a></span> | <span class="t">And then as time goes by, you start operating on longer and longer utterances that get more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2425">00:40:25.440</a></span> | <span class="t">and more difficult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2427">00:40:27.440</a></span> | <span class="t">So we call this "sort of grad."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2428">00:40:28.760</a></span> | <span class="t">It's basically a curriculum learning method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2431">00:40:31.480</a></span> | <span class="t">And so you can see some work from Yoshio Bengio and his team on a whole bunch of strategies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2436">00:40:36.520</a></span> | <span class="t">for this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2437">00:40:37.520</a></span> | <span class="t">But you can think of the short utterances as being the easy ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2440">00:40:40.480</a></span> | <span class="t">And if you start out with the easy utterances and move to the longer ones, your optimization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2444">00:40:44.640</a></span> | <span class="t">algorithm can do better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2446">00:40:46.640</a></span> | <span class="t">So here's an example from one of the models that we've trained, where your CTC cost starts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2453">00:40:53.100</a></span> | <span class="t">up here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2454">00:40:54.720</a></span> | <span class="t">And after a while, you optimize, and you sort of bottom out around, I don't know, what?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2459">00:40:59.560</a></span> | <span class="t">A log likelihood of maybe 30.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2462">00:41:02.080</a></span> | <span class="t">And then if you add this sort of grad strategy, after the first epoch, you're actually doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2467">00:41:07.380</a></span> | <span class="t">better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2468">00:41:08.380</a></span> | <span class="t">And you can reach a better optimum than you could without it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2472">00:41:12.120</a></span> | <span class="t">And in addition, another strategy that's extremely helpful for recurrent networks and very deep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2477">00:41:17.120</a></span> | <span class="t">neural networks is batch normalization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2480">00:41:20.760</a></span> | <span class="t">So this is becoming very popular.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2482">00:41:22.880</a></span> | <span class="t">And it's also available as sort of an off-the-shelf package inside of a lot of the different frameworks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2488">00:41:28.120</a></span> | <span class="t">that are available today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2489">00:41:29.520</a></span> | <span class="t">So if you start having trouble, you can consider putting batch normalization into your network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2496">00:41:36.280</a></span> | <span class="t">So our neural network now spits out this big bank of softmax neurons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2501">00:41:41.720</a></span> | <span class="t">We've got a training algorithm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2502">00:41:42.760</a></span> | <span class="t">We're just doing gradient descent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2505">00:41:45.720</a></span> | <span class="t">How do we actually get a transcription?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2507">00:41:47.740</a></span> | <span class="t">This process, as I said, is meant to be as close to characters as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2513">00:41:53.000</a></span> | <span class="t">But we still sort of need to decode these outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2516">00:41:56.600</a></span> | <span class="t">And you might think that one simple solution, which turns out to be approximate, to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2521">00:42:01.720</a></span> | <span class="t">the correct transcription is just go through here and pick the most likely sequence of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2526">00:42:06.960</a></span> | <span class="t">symbols for C, and then apply our little squeeze operator to get back the transcription the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2533">00:42:13.280</a></span> | <span class="t">way that we defined it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2534">00:42:14.960</a></span> | <span class="t">So this turns out not to be the optimal thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2537">00:42:17.560</a></span> | <span class="t">This actually doesn't give you the most likely transcription, because it's not accounting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2542">00:42:22.320</a></span> | <span class="t">for the fact that every transcription might have multiple sequences of Cs, multiple alignments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2548">00:42:28.640</a></span> | <span class="t">in this representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2552">00:42:32.320</a></span> | <span class="t">But you can actually do this, and this is called the max decoding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2556">00:42:36.280</a></span> | <span class="t">And so for this sort of contrived example here, I put little red dots on the most likely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2562">00:42:42.720</a></span> | <span class="t">C. And if you see, there's a couple of blanks, a couple of Cs, there's another blank, A,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2570">00:42:50.560</a></span> | <span class="t">more blanks, Bs, more blanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2572">00:42:52.680</a></span> | <span class="t">And if you apply our little squeeze operator, you just get the word cab.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2578">00:42:58.800</a></span> | <span class="t">If you do this, it is often terrible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2582">00:43:02.200</a></span> | <span class="t">It will often give you a very strange transcription that doesn't look like English necessarily.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2589">00:43:09.280</a></span> | <span class="t">But the reason I mention it is that this is a really handy diagnostic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2593">00:43:13.400</a></span> | <span class="t">If you're kind of wondering what's going on in the network, glancing at a few of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2597">00:43:17.160</a></span> | <span class="t">will often tell you if the network's starting to pick up any signal or if it's just outputting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2601">00:43:21.900</a></span> | <span class="t">gobbledygook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2602">00:43:22.900</a></span> | <span class="t">So I'll give you a more detailed example in a second of how that happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2608">00:43:28.360</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2609">00:43:29.640</a></span> | <span class="t">So these are all the concepts of our very simple pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2612">00:43:32.880</a></span> | <span class="t">And the demo code that we're going to put up on the web will basically let you work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2617">00:43:37.480</a></span> | <span class="t">on all of these pieces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2619">00:43:39.200</a></span> | <span class="t">So once we try to train these, I want to give you an example of the sort of data that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2624">00:43:44.400</a></span> | <span class="t">training on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2625">00:43:45.400</a></span> | <span class="t">>> A tanker is a ship designed to carry large volumes of oil or other liquid cargo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2631">00:43:51.920</a></span> | <span class="t">>> So this is just a person sitting there reading the Wall Street Journal to us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2635">00:43:55.960</a></span> | <span class="t">So this is a sort of simple data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2638">00:43:58.520</a></span> | <span class="t">It's really popular in the speech research community.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2642">00:44:02.240</a></span> | <span class="t">It's published by the Linguistic Data Consortium.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2645">00:44:05.320</a></span> | <span class="t">There's also a free alternative called Libris Speech that's very similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2648">00:44:08.720</a></span> | <span class="t">But instead of people reading the Wall Street Journal, it's people reading Creative Commons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2652">00:44:12.360</a></span> | <span class="t">audiobooks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2655">00:44:15.200</a></span> | <span class="t">So in the demo code that we have, a really simple network that works reasonably well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2662">00:44:22.680</a></span> | <span class="t">looks like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2663">00:44:23.680</a></span> | <span class="t">So there's a sort of family of models that we've been working with, where you start from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2668">00:44:28.120</a></span> | <span class="t">your spectrogram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2669">00:44:29.640</a></span> | <span class="t">You have maybe one layer or several of convolutional filters at the bottom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2675">00:44:35.380</a></span> | <span class="t">And then on top of that, you have some kind of recurrent neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2678">00:44:38.040</a></span> | <span class="t">It might just be a vanilla RNN, but you can also use LSTM or GRU cells, any of your favorite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2687">00:44:47.360</a></span> | <span class="t">RNN creatures from the literature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2690">00:44:50.760</a></span> | <span class="t">And then on top of that, we have some fully connected layers that produce these softmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2694">00:44:54.800</a></span> | <span class="t">outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2695">00:44:55.800</a></span> | <span class="t">And those are the things that go into CTC for training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2699">00:44:59.680</a></span> | <span class="t">So this is pretty straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2701">00:45:01.040</a></span> | <span class="t">The implementation on the web uses the warp CTC code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2705">00:45:05.000</a></span> | <span class="t">And then we would just train this big neural network with stochastic gradient descent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2708">00:45:08.880</a></span> | <span class="t">Nesterov's momentum, all the stuff that you've probably seen in a whole bunch of other talks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2713">00:45:13.120</a></span> | <span class="t">so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2714">00:45:14.120</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2715">00:45:15.120</a></span> | <span class="t">So if you actually run this, what is going on inside?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2721">00:45:21.680</a></span> | <span class="t">So I mentioned that looking at the max decoding is kind of a handy way to see what's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2726">00:45:26.960</a></span> | <span class="t">on inside this creature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2729">00:45:29.920</a></span> | <span class="t">So I wanted to show you an example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2731">00:45:31.840</a></span> | <span class="t">So this is a picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2734">00:45:34.640</a></span> | <span class="t">This is a visualization of those softmax neurons at the top of one of these big neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2740">00:45:40.860</a></span> | <span class="t">So this is the representation of C from all the previous slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2745">00:45:45.880</a></span> | <span class="t">So on the horizontal axis, this is basically time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2748">00:45:48.680</a></span> | <span class="t">This is the frame number or which chunk of the spectrogram we're seeing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2752">00:45:52.800</a></span> | <span class="t">And then on the vertical axis here, you see these are all the characters in the English</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2756">00:45:56.460</a></span> | <span class="t">alphabet or a space or a blank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2759">00:45:59.280</a></span> | <span class="t">So after 300 iterations of training, which is not very much, the system has learned something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2764">00:46:04.960</a></span> | <span class="t">amazing, which is that it should just output blanks and spaces all the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2769">00:46:09.600</a></span> | <span class="t">Because these are by far, because of all the silence and things in your data set, these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2774">00:46:14.040</a></span> | <span class="t">are the most common characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2776">00:46:16.000</a></span> | <span class="t">I just want to fill up the whole space with blanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2778">00:46:18.360</a></span> | <span class="t">But you can see it's kind of randomly poking out a few characters here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2783">00:46:23.300</a></span> | <span class="t">And if you run your little max decoding strategy to see what does the system think the transcription</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2788">00:46:28.440</a></span> | <span class="t">is, it thinks the transcription is "eh."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2793">00:46:33.160</a></span> | <span class="t">But after 300 iterations, that's okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2795">00:46:35.600</a></span> | <span class="t">But this is a sign that the neural network's not going crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2798">00:46:38.360</a></span> | <span class="t">Your gradient isn't busted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2800">00:46:40.240</a></span> | <span class="t">It's at least learned what is the most likely characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2804">00:46:44.560</a></span> | <span class="t">Then after maybe 1,500 or so, you start to get a little bit of structure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2809">00:46:49.680</a></span> | <span class="t">And if you try to like mouth these words, you might be able to sort of see that there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2814">00:46:54.860</a></span> | <span class="t">some English-like sounds in here, like "Beyar justinfrutin."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2820">00:47:00.760</a></span> | <span class="t">Something kind of odd.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2821">00:47:01.760</a></span> | <span class="t">But it's actually looking much better than just "h."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2823">00:47:03.600</a></span> | <span class="t">It's actually starting to output something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2827">00:47:07.120</a></span> | <span class="t">Go a little bit farther.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2828">00:47:08.480</a></span> | <span class="t">It's a little bit more organized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2831">00:47:11.920</a></span> | <span class="t">You can start to see that we have sort of fragments of possibly words starting to form.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2838">00:47:18.980</a></span> | <span class="t">And then after you're getting close to convergence, it's still not a real sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2843">00:47:23.880</a></span> | <span class="t">But does this make sense to people?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2845">00:47:25.160</a></span> | <span class="t">He guessed what the correct transcription might be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2851">00:47:31.640</a></span> | <span class="t">You might have a couple of candidates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2854">00:47:34.160</a></span> | <span class="t">The correct one is actually "there justinfrunt."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2858">00:47:38.440</a></span> | <span class="t">And so you can see that sort of it's sort of sounding it out with English characters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2864">00:47:44.220</a></span> | <span class="t">I have a young son, and I kind of figure I'm eventually going to see him producing max-decoded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2868">00:47:48.600</a></span> | <span class="t">outputs of English.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2871">00:47:51.520</a></span> | <span class="t">And you're just going to sound these things out and be like, "Is it there justinfrunt?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2875">00:47:55.960</a></span> | <span class="t">There?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2876">00:47:56.960</a></span> | <span class="t">But this is why this max-decoding strategy is really handy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2880">00:48:00.200</a></span> | <span class="t">Because you can kind of look at this output and say, yeah, it's starting to get some actual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2883">00:48:03.880</a></span> | <span class="t">signal out of the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2885">00:48:05.080</a></span> | <span class="t">It's not just gobbledygook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2887">00:48:07.240</a></span> | <span class="t">So because this is like my favorite speech recognition party game, I wanted to show you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2891">00:48:11.800</a></span> | <span class="t">a few more of these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2893">00:48:13.480</a></span> | <span class="t">So here's the max-decoded output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2895">00:48:15.920</a></span> | <span class="t">"The poor little things," cried Cynthia, "think of them having been turned to the wall all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2900">00:48:20.720</a></span> | <span class="t">these years."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2901">00:48:21.720</a></span> | <span class="t">And so you can hear like the sound of the breath at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2906">00:48:26.400</a></span> | <span class="t">Turns into a little bit of a word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2909">00:48:29.440</a></span> | <span class="t">"Cynthia" is sort of in this transcription.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2914">00:48:34.040</a></span> | <span class="t">And you'll find that things like proper names and so on tend to get sounded out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2918">00:48:38.240</a></span> | <span class="t">But if those names are not in your audio data, there's no way the network could have learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2922">00:48:42.320</a></span> | <span class="t">how to say the name Cynthia.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2925">00:48:45.080</a></span> | <span class="t">And we'll come back to how to solve that later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2927">00:48:47.000</a></span> | <span class="t">But you see the true label is "The poor little things," cried Cynthia.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2932">00:48:52.160</a></span> | <span class="t">And that the last word is actually "all these years."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2934">00:48:54.560</a></span> | <span class="t">And there isn't a word hanging off at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2938">00:48:58.280</a></span> | <span class="t">So here's another one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2939">00:48:59.280</a></span> | <span class="t">>> That is true, bad dealt gray.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2943">00:49:03.920</a></span> | <span class="t">>> How many people figured out what this is?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2946">00:49:06.160</a></span> | <span class="t">This is the max-decoded transcription.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2948">00:49:08.680</a></span> | <span class="t">It sounds good to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2952">00:49:12.080</a></span> | <span class="t">It sounds good to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2953">00:49:13.080</a></span> | <span class="t">If you told me that this was the ground truth, I'd go, "That's weird.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2956">00:49:16.720</a></span> | <span class="t">I have to go look up what this is."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2959">00:49:19.480</a></span> | <span class="t">Here's the actual true label.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2961">00:49:21.920</a></span> | <span class="t">Turns out this is a French word that means something like "rubbernecking."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2966">00:49:26.840</a></span> | <span class="t">I had no idea what this word was.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2969">00:49:29.440</a></span> | <span class="t">So this is, again, the cool examples of what these neural networks are able to figure out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2974">00:49:34.040</a></span> | <span class="t">with no knowledge of the language itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2978">00:49:38.120</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2980">00:49:40.480</a></span> | <span class="t">So let's go back to decoding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2982">00:49:42.280</a></span> | <span class="t">We just talked about max-decoding, which is sort of an approximate way of going from these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2989">00:49:49.040</a></span> | <span class="t">probability vectors to a transcription Y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2992">00:49:52.240</a></span> | <span class="t">And if you want to find the actual most likely transcription Y, there's actually no algorithm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=2998">00:49:58.400</a></span> | <span class="t">in general that can give you the perfect solution efficiently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3003">00:50:03.840</a></span> | <span class="t">So the reason for that, remember, is that for a single transcription Y, I have an efficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3009">00:50:09.200</a></span> | <span class="t">algorithm to compute its probability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3011">00:50:11.320</a></span> | <span class="t">But if I want to search over every possible transcription, I don't know how to do that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3015">00:50:15.880</a></span> | <span class="t">because there are exponentially many possible transcriptions, and I'd have to run this algorithm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3022">00:50:22.600</a></span> | <span class="t">to compute the probability of all of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3025">00:50:25.400</a></span> | <span class="t">So we have to resort to some kind of generic search strategy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3029">00:50:29.840</a></span> | <span class="t">And so one proposed in the original paper briefly is a sort of prefix-decoding strategy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3036">00:50:36.760</a></span> | <span class="t">So I don't want to spend a ton of time on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3039">00:50:39.200</a></span> | <span class="t">Instead, I want to step to sort of the next piece of the picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3044">00:50:44.480</a></span> | <span class="t">So there were a bunch of examples in there, right, like proper names, like Cynthia and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3049">00:50:49.160</a></span> | <span class="t">things like Baddourie, where unless you had heard this word before, you have no hope of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3057">00:50:57.000</a></span> | <span class="t">getting it right with your neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3059">00:50:59.280</a></span> | <span class="t">And so there are lots of examples like this in the literature of things that are sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3064">00:51:04.680</a></span> | <span class="t">of spelled out phonetically but aren't legitimate English transcriptions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3070">00:51:10.240</a></span> | <span class="t">And so what we'd like to do is come up with a way to fold in just a little bit of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3077">00:51:17.040</a></span> | <span class="t">knowledge about the language, to take a small step backward from a perfect end-to-end system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3082">00:51:22.200</a></span> | <span class="t">and make these transcriptions better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3085">00:51:25.280</a></span> | <span class="t">So as I said, the real problem here is that you don't have enough audio available to learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3091">00:51:31.200</a></span> | <span class="t">all these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3092">00:51:32.200</a></span> | <span class="t">If you had millions and millions of hours of audio sitting around, you could probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3095">00:51:35.560</a></span> | <span class="t">learn all these transcriptions because you just hear enough words that you know how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3099">00:51:39.440</a></span> | <span class="t">spell them all, maybe the way a human does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3102">00:51:42.800</a></span> | <span class="t">But unfortunately, we just don't have enough audio for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3105">00:51:45.960</a></span> | <span class="t">So we have to find a way to get around that data problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3110">00:51:50.120</a></span> | <span class="t">There's also an example of something that in the AI lab we've dubbed the Tchaikovsky</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3113">00:51:53.880</a></span> | <span class="t">problem, which is that there are certain names in the world, right, like proper names, that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3119">00:51:59.360</a></span> | <span class="t">if you've never heard of it before, you have no idea how it's spelled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3123">00:52:03.560</a></span> | <span class="t">And the only way to know it is to have seen this word in text before and to see it in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3128">00:52:08.400</a></span> | <span class="t">context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3130">00:52:10.400</a></span> | <span class="t">So part of the purpose of these language models is to get examples like this correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3134">00:52:14.760</a></span> | <span class="t">So there are a couple of solutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3136">00:52:16.840</a></span> | <span class="t">One would be to just step back to a more traditional pipeline, right, use phonemes, because then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3141">00:52:21.940</a></span> | <span class="t">we can bake new words in along with their phonetic pronunciation and the system will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3147">00:52:27.680</a></span> | <span class="t">just get it right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3149">00:52:29.280</a></span> | <span class="t">But in this case, I want to focus on just fusing in a traditional language model that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3154">00:52:34.960</a></span> | <span class="t">gives us the probability a priori of any sequence of words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3160">00:52:40.000</a></span> | <span class="t">So the reason that this is helpful is that using a language model, we can train these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3165">00:52:45.480</a></span> | <span class="t">things from massive text corpora.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3167">00:52:47.880</a></span> | <span class="t">We have way, way more text in the world than we have transcribed audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3172">00:52:52.640</a></span> | <span class="t">And so that makes it possible to train these giant language models with huge vocabulary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3177">00:52:57.960</a></span> | <span class="t">and they can also pick up the sort of contextual things that will tip you off to the fact that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3182">00:53:02.720</a></span> | <span class="t">Tchaikovsky concerto is a reasonable thing for a person to ask, and that this particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3188">00:53:08.520</a></span> | <span class="t">transcription which we have seen in the past, Tchaikovsky concerto, even though composed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3195">00:53:15.200</a></span> | <span class="t">of legitimate English words, is nonsense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3199">00:53:19.680</a></span> | <span class="t">So there's actually not much to see on the language modeling front for this, except that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3205">00:53:25.840</a></span> | <span class="t">the reasons for sticking with traditional N-gram models are kind of interesting if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3210">00:53:30.520</a></span> | <span class="t">excited about speech applications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3212">00:53:32.960</a></span> | <span class="t">So if you go use a package like KenLM on the web to go build yourself a giant N-gram language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3219">00:53:39.880</a></span> | <span class="t">model, these are really simple and well supported.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3224">00:53:44.240</a></span> | <span class="t">And so that makes them easy to get working.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3227">00:53:47.040</a></span> | <span class="t">And they'll let you train from lots of corpora, but for speech recognition in practice, one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3232">00:53:52.360</a></span> | <span class="t">of the nice things about N-gram models as opposed to trying to, say, use like an RNN</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3238">00:53:58.160</a></span> | <span class="t">model is that we can update these things very quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3240">00:54:00.440</a></span> | <span class="t">If you have a big distributed cluster, you can update that N-gram model very rapidly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3245">00:54:05.160</a></span> | <span class="t">in parallel from new data to keep track of whatever the trending words are today that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3249">00:54:09.600</a></span> | <span class="t">your speech engine might need to deal with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3252">00:54:12.440</a></span> | <span class="t">And we also have the need to query this thing very rapidly inside our decoding loop that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3258">00:54:18.960</a></span> | <span class="t">you'll see in just a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3260">00:54:20.340</a></span> | <span class="t">And so being able to just look up the probabilities in a table the way an N-gram model is structured</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3264">00:54:24.680</a></span> | <span class="t">is very valuable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3266">00:54:26.880</a></span> | <span class="t">So I hope someday all of this will go away and be replaced with an amazing neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3272">00:54:32.760</a></span> | <span class="t">But this is a really best practice today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3277">00:54:37.040</a></span> | <span class="t">So in order to fuse this into the system, since to get the most likely transcription,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3284">00:54:44.880</a></span> | <span class="t">right, probability of Y given X, to maximize that thing, we need to use a generic search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3289">00:54:49.940</a></span> | <span class="t">algorithm anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3291">00:54:51.460</a></span> | <span class="t">This opens up a door.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3294">00:54:54.060</a></span> | <span class="t">Once we're using a generic search scheme to do our decoding and find the most likely transcription,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3298">00:54:58.340</a></span> | <span class="t">we can add some extra cost terms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3300">00:55:00.840</a></span> | <span class="t">So in a previous piece of work from Auni, Hanun, and several co-authors, what you do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3307">00:55:07.820</a></span> | <span class="t">is you take the probability of a given word sequence from your audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3313">00:55:13.480</a></span> | <span class="t">So this is what you would get from your giant RNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3317">00:55:17.920</a></span> | <span class="t">And you can just multiply it by some extra terms, the probability of the word sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3322">00:55:22.560</a></span> | <span class="t">according to your language model raised to some power, and then multiply by the length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3326">00:55:26.480</a></span> | <span class="t">raised to another power.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3328">00:55:28.160</a></span> | <span class="t">And you see that if you just take the log of this objective function, right, then you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3333">00:55:33.840</a></span> | <span class="t">get the log probability that was your original objective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3337">00:55:37.380</a></span> | <span class="t">You get alpha times the log probability of the language model, and beta times the log</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3343">00:55:43.080</a></span> | <span class="t">of the length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3344">00:55:44.380</a></span> | <span class="t">And these alpha and beta parameters let you sort of trade off the importance of getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3349">00:55:49.880</a></span> | <span class="t">a transcription that makes sense to your language model versus getting a transcription that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3353">00:55:53.480</a></span> | <span class="t">makes sense to your acoustic model and actually sounds like the thing that you heard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3359">00:55:59.040</a></span> | <span class="t">And the reason for this extra term over here is that as you're multiplying in all of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3364">00:56:04.520</a></span> | <span class="t">terms, you tend to penalize long transcriptions a bit too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3369">00:56:09.120</a></span> | <span class="t">And so having a little bonus or penalty at the end to tweak to get the transcription</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3373">00:56:13.600</a></span> | <span class="t">length right is very helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3376">00:56:16.700</a></span> | <span class="t">So the basic idea behind this is just to use BeamSearch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3379">00:56:19.920</a></span> | <span class="t">BeamSearch, really popular search algorithm, a whole bunch of instances of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3385">00:56:25.000</a></span> | <span class="t">And the rough strategy is this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3388">00:56:28.840</a></span> | <span class="t">So starting from time 0, starting from t equals 1 at the very beginning of your audio input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3395">00:56:35.120</a></span> | <span class="t">I start out with an empty list that I'm going to populate with prefixes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3400">00:56:40.540</a></span> | <span class="t">And these prefixes are just partial transcriptions that represent what I think I've heard so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3405">00:56:45.300</a></span> | <span class="t">far in the audio up to the current time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3410">00:56:50.200</a></span> | <span class="t">And the way that this proceeds is I'm going to take at the current time step each candidate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3416">00:56:56.440</a></span> | <span class="t">prefix out of this list.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3418">00:56:58.960</a></span> | <span class="t">And then I'm going to try all of the possible characters in my softmax neurons that could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3424">00:57:04.160</a></span> | <span class="t">possibly follow it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3426">00:57:06.040</a></span> | <span class="t">So for example, I can try adding a blank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3428">00:57:08.800</a></span> | <span class="t">I can say if the next element of C is actually supposed to be a blank, then what that would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3435">00:57:15.440</a></span> | <span class="t">mean is that I don't change my prefix, right, because the blanks are just going to get dropped</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3439">00:57:19.680</a></span> | <span class="t">later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3441">00:57:21.020</a></span> | <span class="t">But I need to incorporate the probability of that blank character into the probability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3446">00:57:26.780</a></span> | <span class="t">of this prefix, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3448">00:57:28.440</a></span> | <span class="t">It represents one of the ways that I could reach that prefix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3452">00:57:32.400</a></span> | <span class="t">And so I need to sum that probability into that candidate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3457">00:57:37.060</a></span> | <span class="t">And likewise, whenever I add a space to the end of a prefix, that signals that this prefix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3463">00:57:43.640</a></span> | <span class="t">represents the end of a word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3465">00:57:45.600</a></span> | <span class="t">And so in addition to adding the probability of the space into my current estimate, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3470">00:57:50.400</a></span> | <span class="t">gives me the chance to go look up that word in my language model and fold that into my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3475">00:57:55.540</a></span> | <span class="t">current score.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3477">00:57:57.520</a></span> | <span class="t">And then if I try adding a new character onto this prefix, it's just straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3481">00:58:01.600</a></span> | <span class="t">I just go and update the probabilities based on the probability of that character.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3486">00:58:06.400</a></span> | <span class="t">And then at the end of this, I'm going to have a huge list of possible prefixes that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3491">00:58:11.120</a></span> | <span class="t">could be generated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3492">00:58:12.480</a></span> | <span class="t">And this is where you would normally get the exponential blow up of trying all possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3498">00:58:18.560</a></span> | <span class="t">prefixes to find the best one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3500">00:58:20.880</a></span> | <span class="t">And what BeamSearch does is it just says, take the k most probable prefixes after I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3507">00:58:27.220</a></span> | <span class="t">remove all the duplicates in here, and then go and do this again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3511">00:58:31.360</a></span> | <span class="t">And so if you have a really large k, then your algorithm will be a bit more accurate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3515">00:58:35.400</a></span> | <span class="t">in finding the best possible solution to this maximization problem, but it'll be slower.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3522">00:58:42.860</a></span> | <span class="t">So here's what ends up happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3524">00:58:44.620</a></span> | <span class="t">If you run this decoding algorithm, if you just run it on the RNN outputs, you'll see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3529">00:58:49.720</a></span> | <span class="t">that you get actually better than straight max decoding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3533">00:58:53.680</a></span> | <span class="t">You find slightly better solutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3535">00:58:55.600</a></span> | <span class="t">But you still make things like spelling errors, like Boston with an I.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3540">00:59:00.560</a></span> | <span class="t">But once you add in a language model that can actually tell you that the word Boston</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3545">00:59:05.000</a></span> | <span class="t">with an O is much more probable than Boston with an I.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3554">00:59:14.120</a></span> | <span class="t">So one place that you can also drop in deep learning that I wanted to mention very rapidly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3558">00:59:18.100</a></span> | <span class="t">is just if you're not happy with your N-gram model, because it doesn't have enough context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3562">00:59:22.760</a></span> | <span class="t">or you've seen a really amazing neural language modeling paper that you'd like to fold in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3569">00:59:29.080</a></span> | <span class="t">one really easy way to do this and link it to your current pipeline is to do rescoring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3575">00:59:35.080</a></span> | <span class="t">So when this decoding strategy finishes, it can give you the most probable transcription,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3580">00:59:40.800</a></span> | <span class="t">but it also gives you this big list of the top k transcriptions in terms of probability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3588">00:59:48.560</a></span> | <span class="t">And what you can do is take your recurrent network and just rescore all of these, basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3600">01:00:00.320</a></span> | <span class="t">reorder them according to this new model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3603">01:00:03.940</a></span> | <span class="t">So in the instance of a neural language model, let's say that this is my N best list.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3609">01:00:09.760</a></span> | <span class="t">I have five candidates that were output by my decoding strategy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3615">01:00:15.840</a></span> | <span class="t">And the first one is I'm a connoisseur looking for wine and pork chops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3619">01:00:19.320</a></span> | <span class="t">Sounds good to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3621">01:00:21.120</a></span> | <span class="t">I'm a connoisseur looking for wine and pork chops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3625">01:00:25.400</a></span> | <span class="t">So this is actually quite subtle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3628">01:00:28.000</a></span> | <span class="t">And depending on what kind of connoisseur you are, it's sort of up to interpretation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3634">01:00:34.040</a></span> | <span class="t">what you're looking for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3635">01:00:35.400</a></span> | <span class="t">But perhaps a neural language model is going to be a little bit better at figuring out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3638">01:00:38.840</a></span> | <span class="t">that wine and pork are closely related.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3640">01:00:40.920</a></span> | <span class="t">And if you're a connoisseur, you might be looking for wine and pork chops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3645">01:00:45.000</a></span> | <span class="t">And so what you would hope to happen is that a neural language model trained on a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3648">01:00:48.960</a></span> | <span class="t">of text is going to correctly reorder these things and figure out that the second beam</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3656">01:00:56.080</a></span> | <span class="t">candidate is actually the correct one, even though your N-gram model didn't help you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3663">01:01:03.520</a></span> | <span class="t">So that is really the scale model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3667">01:01:07.160</a></span> | <span class="t">That is the set of concepts that you need to get a working speech recognition engine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3674">01:01:14.200</a></span> | <span class="t">based on deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3676">01:01:16.240</a></span> | <span class="t">And so the thing that's left to go to state of the art performance and start serving users</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3681">01:01:21.320</a></span> | <span class="t">is scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3682">01:01:22.640</a></span> | <span class="t">So I'm going to kind of run through quickly a bunch of the different tactics that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3688">01:01:28.200</a></span> | <span class="t">can use to try to get there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3690">01:01:30.720</a></span> | <span class="t">So the two pieces of scale that I want to cover, of course, are data and computing power.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3695">01:01:35.320</a></span> | <span class="t">Where do you get them?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3697">01:01:37.920</a></span> | <span class="t">So the first thing to know, this is just a number you can keep in the back of your head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3701">01:01:41.080</a></span> | <span class="t">for all purposes, which is that transcribing speech data is not cheap, but it's also not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3705">01:01:45.880</a></span> | <span class="t">prohibitive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3706">01:01:46.880</a></span> | <span class="t">It's about 50 cents to a dollar a minute, depending on the quality you want and who's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3710">01:01:50.460</a></span> | <span class="t">transcribing it and the difficulty of the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3714">01:01:54.320</a></span> | <span class="t">So typical speech benchmarks you'll see out there are maybe hundreds to thousands of hours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3719">01:01:59.920</a></span> | <span class="t">So like the Libri speech data set is maybe hundreds of hours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3724">01:02:04.920</a></span> | <span class="t">There's another data set called VoxForge, and you can kind of cobble these together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3728">01:02:08.240</a></span> | <span class="t">and get maybe hundreds to thousands of hours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3731">01:02:11.120</a></span> | <span class="t">But the real challenge is that the application matters a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3736">01:02:16.080</a></span> | <span class="t">So all the utterances I was playing for you are examples of read speech.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3741">01:02:21.760</a></span> | <span class="t">People are sitting in a nice quiet room, they're reading something wonderful to me, and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3745">01:02:25.880</a></span> | <span class="t">I'm going to end up with a speech engine that's really awesome at listening to the Wall Street</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3749">01:02:29.680</a></span> | <span class="t">Journal, but maybe not so good at listening to someone in a crowded cafe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3755">01:02:35.600</a></span> | <span class="t">So the application that you want to target really needs to match your data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3761">01:02:41.000</a></span> | <span class="t">And so it's worth, at the outset, if you're thinking about going and buying a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3764">01:02:44.160</a></span> | <span class="t">speech data, to think of what is the style of speech you're actually targeting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3769">01:02:49.160</a></span> | <span class="t">Are you worried about read speech, like the ones we're hearing, or do you care about conversational</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3773">01:02:53.520</a></span> | <span class="t">speech?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3775">01:02:55.000</a></span> | <span class="t">It turns out that when people talk in a conversation, when they're spontaneous, they're just coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3780">01:03:00.140</a></span> | <span class="t">up with what to say on the fly versus if they have something that they're just dictating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3784">01:03:04.640</a></span> | <span class="t">and they already know what to say, they behave differently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3787">01:03:07.880</a></span> | <span class="t">And they can exhibit all of these effects like disfluency and stuttering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3794">01:03:14.000</a></span> | <span class="t">And then in addition to that, we have all kinds of environmental factors that might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3797">01:03:17.040</a></span> | <span class="t">matter for an application, like reverb and echo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3800">01:03:20.040</a></span> | <span class="t">We start to care about the quality of microphones and whether they have noise canceling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3804">01:03:24.880</a></span> | <span class="t">There's something called Lombard effect that I'll mention again in a second, and of course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3808">01:03:28.680</a></span> | <span class="t">things like speaker accents, where you really have to think carefully about how you collect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3812">01:03:32.680</a></span> | <span class="t">your data to make sure that you actually represent the kinds of cases you want to test on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3819">01:03:39.600</a></span> | <span class="t">So the reason that read speech is really popular is because we can get a lot of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3824">01:03:44.600</a></span> | <span class="t">And even if it doesn't perfectly match your application, it's cheap and getting a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3829">01:03:49.480</a></span> | <span class="t">of it can still help you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3831">01:03:51.340</a></span> | <span class="t">So I wanted to say a few things about read speech, because for less than $10 an hour,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3835">01:03:55.560</a></span> | <span class="t">often a lot less, you can get a whole bunch of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3838">01:03:58.400</a></span> | <span class="t">And it has the disadvantage that you lose a lot of things like inflection and conversationality,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3846">01:04:06.560</a></span> | <span class="t">but it can still be helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3848">01:04:08.360</a></span> | <span class="t">So one of the things that we've tried doing, and I'm always interested to hear more clever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3853">01:04:13.920</a></span> | <span class="t">schemes for this, is you can kind of engineer the way that people read to try to get the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3858">01:04:18.880</a></span> | <span class="t">effects that you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3861">01:04:21.520</a></span> | <span class="t">So here's one, which is that if you want a little bit more conversationality, you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3866">01:04:26.000</a></span> | <span class="t">to get people out of that kind of humdrum dictation, you can start giving them reading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3870">01:04:30.120</a></span> | <span class="t">material that's a little more exciting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3871">01:04:31.960</a></span> | <span class="t">You can give them movie scripts and books, and people will actually start voice acting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3876">01:04:36.000</a></span> | <span class="t">for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3877">01:04:37.000</a></span> | <span class="t">>> Creep in, said the witch, and see if it is properly heated so that we can put the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3882">01:04:42.960</a></span> | <span class="t">bread in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3886">01:04:46.520</a></span> | <span class="t">>> So these are really wonderful workers; right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3888">01:04:48.600</a></span> | <span class="t">They're kind of really getting into it to give you better data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3899">01:04:59.320</a></span> | <span class="t">>> The wolf is dead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3900">01:05:00.600</a></span> | <span class="t">The wolf is dead and danced for joy around about the well with their mother.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3908">01:05:08.600</a></span> | <span class="t">>> So you have people reading poetry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3910">01:05:10.200</a></span> | <span class="t">They get this sort of lyrical quality into it that you don't get from just reading the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3914">01:05:14.120</a></span> | <span class="t">Wall Street Journal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3916">01:05:16.080</a></span> | <span class="t">And finally, there's something called the Lombard effect that happens when people are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3920">01:05:20.400</a></span> | <span class="t">in noisy environments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3922">01:05:22.200</a></span> | <span class="t">So if you're in a noisy party and you're trying to talk to your friend who's a couple of chairs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3926">01:05:26.640</a></span> | <span class="t">away, you'll catch yourself involuntarily going, "Hey, over there, what are you doing?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3931">01:05:31.760</a></span> | <span class="t">You raise your inflection, and you kind of -- you try to use different tactics to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3937">01:05:37.080</a></span> | <span class="t">your signal-to-noise ratio up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3939">01:05:39.200</a></span> | <span class="t">You'll sort of work around the channel problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3943">01:05:43.040</a></span> | <span class="t">And so this is very problematic when you're trying to do transcription in a noisy environment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3947">01:05:47.600</a></span> | <span class="t">because people will talk to their phones using all these effects, even though the noise canceling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3952">01:05:52.120</a></span> | <span class="t">and everything could actually help them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3954">01:05:54.620</a></span> | <span class="t">So one strategy we've tried with varying levels of success --</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3957">01:05:57.760</a></span> | <span class="t">>> Then they fell asleep and evening passed, but no one came to the poor children.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3962">01:06:02.920</a></span> | <span class="t">>> -- is to actually play loud noise in people's headphones to try to get them to elicit this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3968">01:06:08.840</a></span> | <span class="t">behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3969">01:06:09.840</a></span> | <span class="t">So this person is kind of raising their voice a little bit in a way that they wouldn't if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3974">01:06:14.160</a></span> | <span class="t">they were just reading.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3977">01:06:17.080</a></span> | <span class="t">And similarly, as I mentioned, there are a whole bunch of different augmentation strategies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3983">01:06:23.000</a></span> | <span class="t">So there are all these effects of environment, like reverberation, echo, background noise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3988">01:06:28.640</a></span> | <span class="t">that we would like our speech engine to be robust to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3991">01:06:31.840</a></span> | <span class="t">And one way you could go about trying to solve this is to go collect a bunch of audio from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=3996">01:06:36.000</a></span> | <span class="t">those cases and then transcribe it, but getting that raw audio is really expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4001">01:06:41.440</a></span> | <span class="t">So instead, an alternative is to take the really cheap red speech that's very clean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4006">01:06:46.560</a></span> | <span class="t">and use some, like, off-the-shelf open-source audio toolkit to synthesize all the things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4015">01:06:55.360</a></span> | <span class="t">you want to be robust to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4017">01:06:57.800</a></span> | <span class="t">So for example, if we want to simulate noise in a cafe, here's just me talking to my laptop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4025">01:07:05.240</a></span> | <span class="t">in a quiet room.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4027">01:07:07.440</a></span> | <span class="t">Hello, how are you?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4032">01:07:12.480</a></span> | <span class="t">So I'm just asking, how are you?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4034">01:07:14.120</a></span> | <span class="t">And then here's the sound of a cafe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4039">01:07:19.200</a></span> | <span class="t">So I can obviously collect these independently, very cheaply.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4042">01:07:22.840</a></span> | <span class="t">Then I can synthesize this by just adding these signals together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4045">01:07:25.800</a></span> | <span class="t">Hello, how are you?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4048">01:07:28.000</a></span> | <span class="t">Which actually sounds, I don't know, sounds to me like my talking to my laptop at a Starbucks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4052">01:07:32.440</a></span> | <span class="t">or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4054">01:07:34.320</a></span> | <span class="t">And so for our work on deep speech, we actually take something like 10,000 hours of raw audio</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4059">01:07:39.640</a></span> | <span class="t">that sounds kind of like this, and then we pile on lots and lots of audio tracks from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4065">01:07:45.160</a></span> | <span class="t">Creative Commons videos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4067">01:07:47.520</a></span> | <span class="t">It turns out there's a strange thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4069">01:07:49.160</a></span> | <span class="t">People upload, like, noise tracks to the web that last for hours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4073">01:07:53.520</a></span> | <span class="t">It's, like, really soothing to listen to the highway or something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4077">01:07:57.960</a></span> | <span class="t">And so you can download all this free found data, and you can just overlay it on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4082">01:08:02.920</a></span> | <span class="t">voice, and you can synthesize perhaps hundreds of thousands of hours of unique audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4087">01:08:07.520</a></span> | <span class="t">And so the idea here is that it's just much easier to engineer your data pipeline to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4095">01:08:15.320</a></span> | <span class="t">robust than it is to engineer the speech engine itself to be robust.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4100">01:08:20.200</a></span> | <span class="t">So whenever you encounter an environment that you've never seen before and your speech engine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4103">01:08:23.720</a></span> | <span class="t">is breaking down, you should shift your instinct away from trying to engineer the engine to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4109">01:08:29.000</a></span> | <span class="t">fix it and toward this idea of how do I reproduce it really cheaply in my data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4115">01:08:35.320</a></span> | <span class="t">So here's that Wall Street Journal example again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4117">01:08:37.320</a></span> | <span class="t">>> A tanker is a ship designed to carry large volumes of oil or other liquid cargo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4123">01:08:43.080</a></span> | <span class="t">>> And so if I wanted to, for instance, deal with a person reading Wall Street Journal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4127">01:08:47.960</a></span> | <span class="t">on a tanker, maybe something like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4130">01:08:50.280</a></span> | <span class="t">>> A tanker is a ship designed to carry large volumes of oil or other liquid cargo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4134">01:08:54.640</a></span> | <span class="t">>> There's lots of reverb in this room, so you can't hear the reverb on the audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4138">01:08:58.720</a></span> | <span class="t">But basically, you can synthesize these things with one line of socks on the command line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4145">01:09:05.300</a></span> | <span class="t">So from some of our own work with building a large-scale speech engine with these technologies,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4151">01:09:11.580</a></span> | <span class="t">this helps a ton.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4153">01:09:13.200</a></span> | <span class="t">And you can actually see that when we run on clean and noisy test utterances, as we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4160">01:09:20.960</a></span> | <span class="t">add more and more data all the way up to about 10,000 hours and using a lot of these synthesis</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4167">01:09:27.800</a></span> | <span class="t">strategies, we can just steadily improve the performance of the engine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4172">01:09:32.080</a></span> | <span class="t">And in fact, on things like clean speech, you can get down well below 10% word error</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4177">01:09:37.640</a></span> | <span class="t">rate, which is a pretty strong engine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4182">01:09:42.480</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4184">01:09:44.160</a></span> | <span class="t">Let's talk about computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4186">01:09:46.000</a></span> | <span class="t">Because the caveat on that last slide is, yes, more data will help if you have a big</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4191">01:09:51.480</a></span> | <span class="t">enough model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4192">01:09:52.640</a></span> | <span class="t">And big models usually mean lots of computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4196">01:09:56.800</a></span> | <span class="t">So what I haven't talked about is how big are these neural networks and how big is one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4201">01:10:01.040</a></span> | <span class="t">experiment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4202">01:10:02.040</a></span> | <span class="t">So if you actually want to train one of these things at scale, what are you in for?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4206">01:10:06.000</a></span> | <span class="t">So here's the back of the envelope.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4208">01:10:08.200</a></span> | <span class="t">It's going to take at least the number of connections in your neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4213">01:10:13.040</a></span> | <span class="t">So take one slice of that RNN, the number of unique connections, multiplied by the number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4218">01:10:18.760</a></span> | <span class="t">of frames once you unroll the recurrent network, once you unfold it, multiplied by the number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4224">01:10:24.000</a></span> | <span class="t">of utterances you've got to process in your dataset, times the number of training epics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4229">01:10:29.160</a></span> | <span class="t">the number of times you loop through the dataset, times 3, because you have to do forward prop,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4234">01:10:34.080</a></span> | <span class="t">backward prop, and then a gradient update.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4235">01:10:35.880</a></span> | <span class="t">It's about a factor of 3 increase.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4238">01:10:38.400</a></span> | <span class="t">And then 2 flops for every connection, because there's a multiply and an add.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4243">01:10:43.120</a></span> | <span class="t">So if you multiply this out for some parameters from the deep speech engine at Baidu, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4247">01:10:47.960</a></span> | <span class="t">get something like 1.2 times 10 to the 19 flops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4252">01:10:52.080</a></span> | <span class="t">It's about 10 exaflops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4254">01:10:54.840</a></span> | <span class="t">And if you run this on a Titan X card, this will take about a month.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4259">01:10:59.800</a></span> | <span class="t">Now if you already know what the model is, that might be tolerable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4264">01:11:04.100</a></span> | <span class="t">If you're on your epic run to get your best performance so far, then this is OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4269">01:11:09.380</a></span> | <span class="t">But if you don't know what model's going to work, you're targeting some new scenario,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4272">01:11:12.840</a></span> | <span class="t">then you want it done now so that you can try lots and lots of models quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4277">01:11:17.400</a></span> | <span class="t">So the easy fix is just to try using a bunch more GPUs with data parallelism.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4283">01:11:23.700</a></span> | <span class="t">And the good news is that so far, it looks like speech recognition allows us to use mini-batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4289">01:11:29.440</a></span> | <span class="t">sizes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4290">01:11:30.440</a></span> | <span class="t">We can process enough utterances in parallel that this is actually efficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4295">01:11:35.080</a></span> | <span class="t">So you'd like to keep maybe a bit more than 64 utterances on each GPU, and up to a total</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4301">01:11:41.640</a></span> | <span class="t">mini-batch size of like 1,000 or maybe 2,000 is still useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4307">01:11:47.140</a></span> | <span class="t">And so if you're putting together your infrastructure, you can go out and you can buy a server that'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4313">01:11:53.600</a></span> | <span class="t">fit eight of these Titan GPUs in them, and that'll actually get you to less than a week</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4317">01:11:57.600</a></span> | <span class="t">training time, which is pretty respectable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4321">01:12:01.480</a></span> | <span class="t">So there are a whole bunch of ways to use GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4323">01:12:03.960</a></span> | <span class="t">If I do, we've been using synchronous SGD.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4327">01:12:07.360</a></span> | <span class="t">It turns out that you've got to optimize things like all reduced code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4330">01:12:10.920</a></span> | <span class="t">Once you leave one node, you have to start worrying about your network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4335">01:12:15.520</a></span> | <span class="t">And if you want to keep scaling, then thinking about things like network traffic and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4339">01:12:19.920</a></span> | <span class="t">right strategy for moving all of your data becomes important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4344">01:12:24.680</a></span> | <span class="t">But we've had success scaling really well all the way out to things like 64 GPUs and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4350">01:12:30.820</a></span> | <span class="t">just getting linear speedups all of the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4353">01:12:33.140</a></span> | <span class="t">So if you've got a big cluster available, these things scale really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4358">01:12:38.120</a></span> | <span class="t">And there are a bunch of other solutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4359">01:12:39.440</a></span> | <span class="t">For instance, asynchronous SGD is now kind of a mainstay of distributed deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4364">01:12:44.980</a></span> | <span class="t">There's also been some work recently of trying to go back to synchronous SGD that has a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4368">01:12:48.640</a></span> | <span class="t">of nice properties, but using things like backup workers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4373">01:12:53.600</a></span> | <span class="t">So that's sort of the easy thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4376">01:12:56.640</a></span> | <span class="t">Just throw more GPUs at it and go faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4379">01:12:59.360</a></span> | <span class="t">One word of warning as you're trying to build these systems is to watch for code that isn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4386">01:13:06.660</a></span> | <span class="t">as optimized as you expected it to be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4390">01:13:10.240</a></span> | <span class="t">And so this back-of-the-envelope calculation that we did of figuring out how many flops</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4395">01:13:15.600</a></span> | <span class="t">are involved in our network and then calculating how long it would take to run if our GPU were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4401">01:13:21.800</a></span> | <span class="t">running at full efficiency, you should actually do this for your network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4406">01:13:26.000</a></span> | <span class="t">We call this the speed of light.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4407">01:13:27.720</a></span> | <span class="t">This is the fastest your code could ever run on one GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4411">01:13:31.580</a></span> | <span class="t">And if you find that you're just drastically underperforming that number, what could be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4416">01:13:36.840</a></span> | <span class="t">happening to you is that you've hit a little edge case in one of the libraries that you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4421">01:13:41.860</a></span> | <span class="t">using and you're actually suffering a huge setback that you don't need to be feeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4425">01:13:45.880</a></span> | <span class="t">right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4426">01:13:46.880</a></span> | <span class="t">So one of the things we found back in November is that in libraries like Kublai's, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4431">01:13:51.620</a></span> | <span class="t">actually use mini batch sizes that hit these weird catastrophic cases in the library, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4437">01:13:57.680</a></span> | <span class="t">you could be suffering like a factor of two or three performance reduction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4442">01:14:02.580</a></span> | <span class="t">So that might take your wonderful one-week training time and blow it up to, say, a three-week</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4447">01:14:07.460</a></span> | <span class="t">training time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4449">01:14:09.420</a></span> | <span class="t">So that's why I wanted to go through this and ask you to keep in mind while you're training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4454">01:14:14.100</a></span> | <span class="t">these things, try to figure out how long it ought to be taking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4457">01:14:17.900</a></span> | <span class="t">And if it's going a lot slower, be suspicious that there's some code you could be optimizing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4464">01:14:24.260</a></span> | <span class="t">Another good trick that's particular to speech, you can also use this for other recurrent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4469">01:14:29.980</a></span> | <span class="t">tricks, is to try to keep similar length utterances together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4474">01:14:34.900</a></span> | <span class="t">So if you look at your dataset, like a lot of things, you have this sort of distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4480">01:14:40.700</a></span> | <span class="t">over possible utterance lengths.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4483">01:14:43.400</a></span> | <span class="t">And so you see there's a whole bunch that are, you know, maybe within about 50% of each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4488">01:14:48.380</a></span> | <span class="t">other, but there's also a large number of utterances that are very short.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4492">01:14:52.740</a></span> | <span class="t">And so what happens is when we want to process a whole bunch of these utterances in parallel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4498">01:14:58.580</a></span> | <span class="t">if we just randomly select, say, 1,000 utterances to go into a mini-batch, there's a high probability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4505">01:15:05.620</a></span> | <span class="t">that we're going to get a whole bunch of these little short utterances along with some really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4509">01:15:09.800</a></span> | <span class="t">long utterances.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4511">01:15:11.560</a></span> | <span class="t">And in order to make all the CTC libraries work and all of our recurrent network computations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4516">01:15:16.060</a></span> | <span class="t">easy, what we have to do is pad these audio signals with zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4520">01:15:20.300</a></span> | <span class="t">And that winds up meaning that we're wasting huge amounts of computation, maybe a factor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4524">01:15:24.300</a></span> | <span class="t">of two or more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4526">01:15:26.560</a></span> | <span class="t">And so one way to get around it is just sort all of your utterances by length and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4532">01:15:32.060</a></span> | <span class="t">try to keep the mini-batches to be similar lengths so that you just don't end up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4536">01:15:36.660</a></span> | <span class="t">quite as much waste in each mini-batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4539">01:15:39.940</a></span> | <span class="t">And this kind of modifies your algorithm a little bit, but in the end is worthwhile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4546">01:15:46.140</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4547">01:15:47.140</a></span> | <span class="t">So that's kind of all I want to say about computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4550">01:15:50.740</a></span> | <span class="t">If you've got a few GPUs, keep an eye on your running time so that you know what to optimize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4556">01:15:56.800</a></span> | <span class="t">and pay attention to the easy wins, like keeping your utterances together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4560">01:16:00.660</a></span> | <span class="t">You can actually scale really well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4563">01:16:03.080</a></span> | <span class="t">And I think for a lot of the jobs we see, you can have your GPU running at something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4568">01:16:08.820</a></span> | <span class="t">like 50% of the peak.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4571">01:16:11.200</a></span> | <span class="t">And that's all in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4572">01:16:12.200</a></span> | <span class="t">With network time, with all the bandwidth-bound stuff, you can actually run at two to three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4576">01:16:16.460</a></span> | <span class="t">teraflops on a GPU that can only do five teraflops in the perfect case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4582">01:16:22.860</a></span> | <span class="t">So what can you actually do with this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4585">01:16:25.940</a></span> | <span class="t">One of my favorite results from one of our largest models is actually in Mandarin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4590">01:16:30.220</a></span> | <span class="t">So we have a whole bunch of labeled Mandarin data at Baidu.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4594">01:16:34.160</a></span> | <span class="t">And so one of the things that we did was we scaled up this model, trained it on a huge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4597">01:16:37.720</a></span> | <span class="t">amount of Mandarin data, and then, as we always do, we sit down and we do error analysis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4604">01:16:44.200</a></span> | <span class="t">And what we would do is have a whole bunch of humans sitting around, try to debate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4610">01:16:50.560</a></span> | <span class="t">transcriptions and figure out the ground truth that tend to be very high quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4615">01:16:55.100</a></span> | <span class="t">And then we'd go and we'd run now a sort of holdout test on some new people and on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4619">01:16:59.940</a></span> | <span class="t">speech engine itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4621">01:17:01.740</a></span> | <span class="t">And so if you benchmark a single human being against this deep speech engine in Mandarin</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4628">01:17:08.480</a></span> | <span class="t">that's powered by all the technologies we were just talking about, it turns out that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4633">01:17:13.540</a></span> | <span class="t">the speech engine can get an error rate that's down below 6% character error rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4638">01:17:18.820</a></span> | <span class="t">So only about 6% of the characters are wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4641">01:17:21.500</a></span> | <span class="t">And a single human sitting there listening to these transcriptions actually does quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4645">01:17:25.240</a></span> | <span class="t">a bit worse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4646">01:17:26.240</a></span> | <span class="t">It gets almost 10%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4649">01:17:29.380</a></span> | <span class="t">If you give people a bit of an advantage, which is you now assemble a committee of people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4656">01:17:36.300</a></span> | <span class="t">and you get them a fresh test set so that no one has seen it before and we run this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4660">01:17:40.220</a></span> | <span class="t">test again, it turns out that the two engines, or that the two cases are actually really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4666">01:17:46.260</a></span> | <span class="t">similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4667">01:17:47.260</a></span> | <span class="t">And you can end up with a committee of native Mandarin speakers sitting around debating,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4670">01:17:50.620</a></span> | <span class="t">"No, no, I think this person said this," or "No, they have an accent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4674">01:17:54.380</a></span> | <span class="t">It's from the north.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4675">01:17:55.380</a></span> | <span class="t">I think they're actually saying that."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4677">01:17:57.700</a></span> | <span class="t">And then when you show them the deep speech transcription, they actually go, "Oh, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4682">01:18:02.140</a></span> | <span class="t">what it was."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4684">01:18:04.060</a></span> | <span class="t">And so you can actually get this technology up to a point where it's highly competitive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4689">01:18:09.540</a></span> | <span class="t">with human beings, even human beings working together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4692">01:18:12.620</a></span> | <span class="t">And this is sort of where I think all of the speech recognition systems are heading, thanks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4697">01:18:17.220</a></span> | <span class="t">to deep learning and the technologies that we're talking about here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4702">01:18:22.080</a></span> | <span class="t">Any questions so far?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4704">01:18:24.100</a></span> | <span class="t">Yeah, go ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4706">01:18:26.540</a></span> | <span class="t">So how do you know the actual label of the data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4713">01:18:33.540</a></span> | <span class="t">Yep.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4714">01:18:34.540</a></span> | <span class="t">Sorry?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4715">01:18:35.540</a></span> | <span class="t">Repeat the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4716">01:18:36.540</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4717">01:18:37.540</a></span> | <span class="t">So the question is, if humans have such a hard time coming up with the correct transcription,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4718">01:18:38.660</a></span> | <span class="t">how do you know what the truth is?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4720">01:18:40.500</a></span> | <span class="t">And the real answer is you don't really.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4723">01:18:43.720</a></span> | <span class="t">Sometimes you might have a little bit of user feedback, but in this instance, we have very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4728">01:18:48.140</a></span> | <span class="t">high-quality transcriptions that are coming from many labelers teamed up with a speech</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4732">01:18:52.580</a></span> | <span class="t">engine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4734">01:18:54.260</a></span> | <span class="t">And so that could be wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4736">01:18:56.540</a></span> | <span class="t">We do occasionally find errors where we just think that's a label error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4740">01:19:00.660</a></span> | <span class="t">But when you have a committee of humans around, the really astonishing thing is that you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4745">01:19:05.100</a></span> | <span class="t">look at the output of the speech engines, and the humans will suddenly jump ship and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4749">01:19:09.980</a></span> | <span class="t">say, oh, no, no, no, no.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4751">01:19:11.340</a></span> | <span class="t">The speech engine is actually correct, because it'll often come up with an obscure word or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4755">01:19:15.380</a></span> | <span class="t">place that they weren't aware of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4758">01:19:18.860</a></span> | <span class="t">Once they see the label, can they be biased towards that label?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4763">01:19:23.300</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4764">01:19:24.300</a></span> | <span class="t">So this is an inherently ambiguous result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4766">01:19:26.980</a></span> | <span class="t">But let's say that a committee of human beings tend to disagree with another committee of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4771">01:19:31.980</a></span> | <span class="t">human beings about the same amount as a speech engine does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4775">01:19:35.660</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4776">01:19:36.660</a></span> | <span class="t">So this is basically doing a sequence-to-sequence sort of task, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4782">01:19:42.660</a></span> | <span class="t">So we're going to hear about a really different approach to that later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4789">01:19:49.660</a></span> | <span class="t">Can you say anything about the -- Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4790">01:19:50.660</a></span> | <span class="t">So this is using the CTC cost, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4793">01:19:53.780</a></span> | <span class="t">That's really the core component of this system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4796">01:19:56.260</a></span> | <span class="t">It's how you deal with mapping one variable-length sequence to another.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4801">01:20:01.140</a></span> | <span class="t">When the CTC cost is not perfect, it has this assumption of independence baked into the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4806">01:20:06.660</a></span> | <span class="t">probabilistic model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4808">01:20:08.660</a></span> | <span class="t">And because of that assumption, we're introducing some bias into the system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4812">01:20:12.900</a></span> | <span class="t">And for languages like English, where the characters are obviously not independent of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4817">01:20:17.700</a></span> | <span class="t">each other, this might be a limitation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4820">01:20:20.660</a></span> | <span class="t">In practice, the thing that we see is that as you add a lot of data and your model gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4825">01:20:25.020</a></span> | <span class="t">much more powerful, you can still find your way around it, but it might take more data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4829">01:20:29.940</a></span> | <span class="t">and a bigger model than necessary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4832">01:20:32.500</a></span> | <span class="t">And of course, we hope that all the new state-of-the-art methods coming out of the deep learning community</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4836">01:20:36.380</a></span> | <span class="t">are going to give us an even better solution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4838">01:20:38.780</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4839">01:20:39.780</a></span> | <span class="t">Go ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4840">01:20:40.780</a></span> | <span class="t">In this spectrogram, you're saying that there's a 20 milliseconds sample that you take.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4851">01:20:51.780</a></span> | <span class="t">Is there a reason for the prediction that you can have a bigger or smaller --</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4852">01:20:52.780</a></span> | <span class="t">Empirically determined.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4853">01:20:53.780</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4854">01:20:54.780</a></span> | <span class="t">So the question is, for a spectrogram with -- We talked about these little spectrogram</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4858">01:20:58.380</a></span> | <span class="t">frames being computed from 20 milliseconds of audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4861">01:21:01.180</a></span> | <span class="t">And is that number special?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4862">01:21:02.180</a></span> | <span class="t">Is there a reason for it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4865">01:21:05.180</a></span> | <span class="t">So this is really determined from years and years of experience.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4868">01:21:08.380</a></span> | <span class="t">This is captured from the traditional speech community.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4872">01:21:12.180</a></span> | <span class="t">We know this works pretty well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4874">01:21:14.020</a></span> | <span class="t">There's actually some fun things you can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4875">01:21:15.980</a></span> | <span class="t">You can take a spectrogram, go back and find the best audio that corresponds to that spectrogram</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4882">01:21:22.860</a></span> | <span class="t">to listen to it and see if you lost anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4885">01:21:25.700</a></span> | <span class="t">And spectrograms of about this level of quantization, you can kind of tell what people are saying.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4890">01:21:30.860</a></span> | <span class="t">It's a little bit garbled, but it's still actually pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4894">01:21:34.580</a></span> | <span class="t">So amongst all the hyperparameters you could choose, this one's kind of a good tradeoff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4898">01:21:38.420</a></span> | <span class="t">in keeping the information, but also saving a little bit of the phase by doing it frequently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4904">01:21:44.300</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4905">01:21:45.300</a></span> | <span class="t">Are you doing overlapping things?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4910">01:21:50.220</a></span> | <span class="t">I think in a lot of the models in the demo, for example, we don't use overlapping windows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4915">01:21:55.660</a></span> | <span class="t">They're just adjacent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4916">01:21:56.660</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4917">01:21:57.660</a></span> | <span class="t">You mentioned you get linear scale up across CPU and GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4918">01:21:58.660</a></span> | <span class="t">Is that, does it really matter?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4919">01:21:59.660</a></span> | <span class="t">Like, what do you get when you do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4920">01:22:00.660</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4921">01:22:01.660</a></span> | <span class="t">So those results are from in-house software at Baidu.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4931">01:22:11.540</a></span> | <span class="t">If you use something like OpenMPI, for example, on a cluster of GPUs, it actually works pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4937">01:22:17.700</a></span> | <span class="t">well on a bunch of machines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4941">01:22:21.540</a></span> | <span class="t">But I think some of the algorithms all reduce once you start moving huge amounts of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4947">01:22:27.500</a></span> | <span class="t">They're not optimal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4948">01:22:28.580</a></span> | <span class="t">You'll suffer a hit once you start going to that many GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4952">01:22:32.900</a></span> | <span class="t">Within a single box, if you use the CUDA libraries to move data back and forth just on a local</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4960">01:22:40.660</a></span> | <span class="t">box, that stuff is pretty well optimized, and you can often do it yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4966">01:22:46.020</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4967">01:22:47.020</a></span> | <span class="t">So I want to take a few more questions at the end, and maybe we can run into the break</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4971">01:22:51.100</a></span> | <span class="t">a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4972">01:22:52.100</a></span> | <span class="t">I wanted to just dive right through a few comments about production here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4977">01:22:57.940</a></span> | <span class="t">So of course, the ultimate goal of solving speech recognition is to improve people's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4985">01:23:05.860</a></span> | <span class="t">lives and enable exciting products, and so that means even though so far we've trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4991">01:23:11.260</a></span> | <span class="t">a bunch of acoustic and language models, we also want to get these things in production.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4996">01:23:16.340</a></span> | <span class="t">And users tend to care about more than just accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=4999">01:23:19.700</a></span> | <span class="t">Accuracy of course matters a lot, but we also care about things like latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5003">01:23:23.740</a></span> | <span class="t">Users want to see the engine send them some feedback very quickly so that they know that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5007">01:23:27.900</a></span> | <span class="t">it's responding and that it's understanding what they're saying.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5011">01:23:31.460</a></span> | <span class="t">And we also need this to be economical so that we can serve lots of users without breaking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5015">01:23:35.620</a></span> | <span class="t">the bank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5017">01:23:37.220</a></span> | <span class="t">So in practice, a lot of the neural networks that we use in research papers, because they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5021">01:23:41.140</a></span> | <span class="t">awesome for beating benchmark results, turn out not to work that well on a production</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5026">01:23:46.260</a></span> | <span class="t">engine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5027">01:23:47.260</a></span> | <span class="t">So one in particular that I think is worth keeping an eye on is that it's really common</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5032">01:23:52.740</a></span> | <span class="t">to use bidirectional recurrent neural networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5035">01:23:55.900</a></span> | <span class="t">And so throughout the talk, I've been drawing my RNN with connections that just go forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5040">01:24:00.420</a></span> | <span class="t">in time, but you'll see a lot of research results that also have a path that goes backward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5045">01:24:05.780</a></span> | <span class="t">in time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5047">01:24:07.140</a></span> | <span class="t">And this works fine if you just want to process data offline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5051">01:24:11.500</a></span> | <span class="t">But the problem is that if I want to compute this neuron's output up at the top of my network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5056">01:24:16.580</a></span> | <span class="t">I have to wait until I see the entire audio segment so that I can compute this backward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5061">01:24:21.620</a></span> | <span class="t">recurrence and get this response.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5064">01:24:24.660</a></span> | <span class="t">So this sort of anti-causal part of my neural network that gets to see the future means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5069">01:24:29.900</a></span> | <span class="t">that I can't respond to a user on the fly because I need to wait for the end of their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5074">01:24:34.260</a></span> | <span class="t">signal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5076">01:24:36.380</a></span> | <span class="t">So if you start out with these bidirectional RNNs that are actually much easier to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5081">01:24:41.700</a></span> | <span class="t">working and then you jump to using a recurrent network that is forward only, it'll turn out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5087">01:24:47.660</a></span> | <span class="t">that you're going to lose some accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5090">01:24:50.420</a></span> | <span class="t">And you might kind of hope that CTC, because it doesn't care about the alignment, would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5095">01:24:55.060</a></span> | <span class="t">somehow magically learn to shift the output over to get better accuracy and just artificially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5101">01:25:01.620</a></span> | <span class="t">delay the response so that it could get more context on its own.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5105">01:25:05.620</a></span> | <span class="t">But it kind of turns out to only do that a little bit in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5109">01:25:09.900</a></span> | <span class="t">It's really tough to control it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5111">01:25:11.500</a></span> | <span class="t">And so if you find that you're doing much worse, sometimes you have to sort of engage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5115">01:25:15.620</a></span> | <span class="t">in model engineering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5117">01:25:17.620</a></span> | <span class="t">So even though I've been talking about these recurrent networks, I want you to bear in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5120">01:25:20.620</a></span> | <span class="t">mind that there's this dual optimization going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5124">01:25:24.940</a></span> | <span class="t">You want to find a model structure that gives you really good accuracy, but you also have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5128">01:25:28.780</a></span> | <span class="t">to think carefully about how you set up the structure so that this little neuron at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5133">01:25:33.460</a></span> | <span class="t">top can actually see enough context to get an accurate answer and not depend too much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5139">01:25:39.620</a></span> | <span class="t">on the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5141">01:25:41.420</a></span> | <span class="t">So for example, what we could do is tweak this model so that this neuron at the top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5146">01:25:46.660</a></span> | <span class="t">that's trying to output the character L in hello can see some future frames, but it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5153">01:25:53.420</a></span> | <span class="t">have this backward recurrence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5155">01:25:55.040</a></span> | <span class="t">So it only gets to see a little bit of context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5157">01:25:57.660</a></span> | <span class="t">That lets us kind of contain the amount of latency in the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5162">01:26:02.380</a></span> | <span class="t">I'm going to skip over this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5164">01:26:04.860</a></span> | <span class="t">So in terms of other online aspects, of course, we want this to be efficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5172">01:26:12.380</a></span> | <span class="t">We want to serve lots of users on a small number of machines if possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5177">01:26:17.260</a></span> | <span class="t">And one of the things that you might find if you have a really big deep neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5182">01:26:22.020</a></span> | <span class="t">or recurrent neural network is that it's really hard to deploy them on conventional CPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5187">01:26:27.300</a></span> | <span class="t">CPUs are awesome for serial jobs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5190">01:26:30.940</a></span> | <span class="t">You just want to go as fast as you can for this one string of instructions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5195">01:26:35.660</a></span> | <span class="t">But as we've discovered with so much of deep learning, GPUs are really fantastic because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5200">01:26:40.420</a></span> | <span class="t">when we work with neural networks, we love processing lots and lots of arithmetic in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5204">01:26:44.580</a></span> | <span class="t">parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5206">01:26:46.080</a></span> | <span class="t">But it's really only efficient if the batch that we're working on, the hunks of audio</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5210">01:26:50.300</a></span> | <span class="t">that we're working on, are in a big enough batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5216">01:26:56.280</a></span> | <span class="t">So if we just process one stream of audio so that my GPU is multiplying matrices times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5220">01:27:00.900</a></span> | <span class="t">vectors, then my GPU is going to be really inefficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5225">01:27:05.300</a></span> | <span class="t">So for example, on like a K1200 GPU, so something you could put in a server in the cloud, what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5232">01:27:12.100</a></span> | <span class="t">you'll find is that you get really poor throughput considering the dollar value of this hardware</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5239">01:27:19.240</a></span> | <span class="t">if you're only processing one piece of audio at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5242">01:27:22.020</a></span> | <span class="t">Whereas if you could somehow batch up audio to have, say, 10 or 32 streams going at once,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5248">01:27:28.480</a></span> | <span class="t">then you can actually squeeze out a lot more performance from that piece of hardware.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5254">01:27:34.180</a></span> | <span class="t">So one of the things that we've been working on that works really well and is not too bad</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5259">01:27:39.200</a></span> | <span class="t">to implement is to just batch all of the packets as data comes in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5263">01:27:43.700</a></span> | <span class="t">So if I have a whole bunch of users talking to my server and they're sending me little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5267">01:27:47.620</a></span> | <span class="t">hundred millisecond packets of audio, what I can do is I can sit and I can listen to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5273">01:27:53.500</a></span> | <span class="t">all these users, and when I catch a whole batch of utterances coming in or a whole bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5278">01:27:58.480</a></span> | <span class="t">of audio packets coming in from different people that start around the same time, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5283">01:28:03.580</a></span> | <span class="t">plug those all into my GPU and I process those matrix multiplications together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5288">01:28:08.780</a></span> | <span class="t">So instead of multiplying a matrix times only one little audio piece, I get to multiply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5292">01:28:12.800</a></span> | <span class="t">it by a batch of, say, four audio pieces, and it's much more efficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5298">01:28:18.420</a></span> | <span class="t">And if you actually do this on a live server and you plow a whole bunch of audio streams</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5303">01:28:23.140</a></span> | <span class="t">through it, you could support maybe 10, 20, 30 users in parallel, and as the load on that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5309">01:28:29.300</a></span> | <span class="t">server goes up, I have more and more users piling on, what happens is that the GPU will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5314">01:28:34.420</a></span> | <span class="t">naturally start batching up more and more packets into single matrix multiplications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5320">01:28:40.140</a></span> | <span class="t">So as you get more users, you actually get much more efficient as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5325">01:28:45.660</a></span> | <span class="t">And so in practice, when you have a whole bunch of users on one machine, you usually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5329">01:28:49.660</a></span> | <span class="t">don't see matrix multiplications happening with fewer than maybe batch sizes of four.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5336">01:28:56.660</a></span> | <span class="t">So the summary of all of this is that deep learning is really making the first steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5344">01:29:04.060</a></span> | <span class="t">to building a state-of-the-art speech engine easier than they've ever been.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5347">01:29:07.220</a></span> | <span class="t">So if you want to build a new state-of-the-art speech engine for some new language, all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5351">01:29:11.420</a></span> | <span class="t">the components that you need are things that we've covered so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5355">01:29:15.860</a></span> | <span class="t">And the performance now is really significantly driven by data and models, and I think, as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5360">01:29:20.740</a></span> | <span class="t">we were discussing earlier, I think future models from deep learning are going to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5364">01:29:24.420</a></span> | <span class="t">that influence of data and computing power even stronger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5369">01:29:29.740</a></span> | <span class="t">And of course, data and compute is important so that we can try lots and lots of models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5374">01:29:34.300</a></span> | <span class="t">and keep making progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5376">01:29:36.460</a></span> | <span class="t">And I think this technology is now at a stage where it's not just a research system anymore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5382">01:29:42.420</a></span> | <span class="t">We're seeing that the end-to-end deep learning technologies are now mature enough that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5386">01:29:46.700</a></span> | <span class="t">can get them into productions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5388">01:29:48.180</a></span> | <span class="t">I think you guys are going to be seeing deep learning play a bigger, bigger role in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5392">01:29:52.300</a></span> | <span class="t">speech engines that are powering all the devices that we use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5395">01:29:55.460</a></span> | <span class="t">So thank you very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5396">01:29:56.460</a></span> | <span class="t">[APPLAUSE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5397">01:29:57.460</a></span> | <span class="t">So I think we're right at the end of time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5405">01:30:05.660</a></span> | <span class="t">[INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5406">01:30:06.660</a></span> | <span class="t">Sounds good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5407">01:30:07.660</a></span> | <span class="t">All right, we had one in the back who was waiting patiently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5410">01:30:10.660</a></span> | <span class="t">Go ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5411">01:30:11.660</a></span> | <span class="t">[INAUDIBLE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5412">01:30:12.660</a></span> | <span class="t">More than one voice simultaneously?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5419">01:30:19.780</a></span> | <span class="t">So the question is, how does the engine handle more than one voice simultaneously?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5424">01:30:24.580</a></span> | <span class="t">So right now, there's nothing in this formalism that allows you to account for multiple speakers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5432">01:30:32.220</a></span> | <span class="t">And so usually, when you listen to an audio clip in practice, it's clear that there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5437">01:30:37.500</a></span> | <span class="t">one dominant speaker.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5439">01:30:39.760</a></span> | <span class="t">And so this speech engine, of course, learns whatever it was taught from the labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5444">01:30:44.540</a></span> | <span class="t">And it will try to filter out background speakers and just transcribe the dominant one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5449">01:30:49.580</a></span> | <span class="t">But if it's really ambiguous, then undefined results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5453">01:30:53.860</a></span> | <span class="t">Can you customize the transcription to the specific characteristics of a particular speaker?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5464">01:31:04.260</a></span> | <span class="t">So we're not doing that in these pipelines right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5468">01:31:08.780</a></span> | <span class="t">But of course, a lot of different strategies have been developed in the traditional speech</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5474">01:31:14.420</a></span> | <span class="t">literature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5475">01:31:15.420</a></span> | <span class="t">There are things like iVectors that try to quantify someone's voice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5478">01:31:18.420</a></span> | <span class="t">And those make useful features for improving speech engines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5481">01:31:21.980</a></span> | <span class="t">You could also imagine taking a lot of the concepts like embeddings, for example, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5486">01:31:26.540</a></span> | <span class="t">tossing them in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5488">01:31:28.380</a></span> | <span class="t">So I think a lot of that is left open to future work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5491">01:31:31.740</a></span> | <span class="t">Adam, question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5495">01:31:35.100</a></span> | <span class="t">I think we have to break for time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5497">01:31:37.220</a></span> | <span class="t">But I'll step off stage here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5499">01:31:39.820</a></span> | <span class="t">And you guys can come to me with your questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5501">01:31:41.540</a></span> | <span class="t">Thank you so much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5502">01:31:42.540</a></span> | <span class="t">[APPLAUSE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5503">01:31:43.540</a></span> | <span class="t">Thanks, Adam.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=g-sndkf7mCs&t=5504">01:31:44.540</a></span> | <span class="t">So we'll reconvene at 2.45 for a presentation by Alex.</span></div></div></body></html>