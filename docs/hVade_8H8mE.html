<html><head><title>SmartGPT: Major Benchmark Broken - 89.0% on MMLU + Exam's Many Errors</title></head><body><a href="index.html">back to index</a><h2>SmartGPT: Major Benchmark Broken - 89.0% on MMLU + Exam's Many Errors</h2><a href="https://www.youtube.com/watch?v=hVade_8H8mE"><img src="https://i.ytimg.com/vi_webp/hVade_8H8mE/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=24">0:24</a> Where to Start<br><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=170">2:50</a> The Results<br><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=217">3:37</a> What is MMLU<br><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=298">4:58</a> How did we get 89<br><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=398">6:38</a> Google Minerva<br><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=506">8:26</a> selfconsistency<br><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=609">10:9</a> openAI fine tuning<br><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=643">10:43</a> Josh Stapleton<br><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=826">13:46</a> The Question<br><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1232">20:32</a> Final Results<br><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1284">21:24</a> Future Benchmarks<br><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1426">23:46</a> Example<br><br><div style="text-align: left;"><a href="./hVade_8H8mE.html">Whisper Transcript</a> | <a href="./transcript_hVade_8H8mE.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=0">00:00:00.000</a></span> | <span class="t">Since late April, myself and machine learning engineer Josh Stapleton have evaluated over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=5">00:00:05.900</a></span> | <span class="t">120,000 answers from GPT models to explore their limits. In my original SmartGPT video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=13">00:00:13.480</a></span> | <span class="t">I showed that even popular TED talks calling GPT-4 stupid were not accurately testing what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=19">00:00:19.860</a></span> | <span class="t">GPT-4 could do. And actually, it could easily get such questions right. Little did we foresee that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=25">00:00:25.780</a></span> | <span class="t">come the summer, our tests with GPT-4 would be revealing a host of mistakes in an official</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=31">00:00:31.400</a></span> | <span class="t">globally used benchmark, uncovering concerns that even OpenAI and Google don't appear to be aware</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=37">00:00:37.720</a></span> | <span class="t">of. But by the end of the video, I want to show how you can tangibly benefit from our experiments,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=43">00:00:43.820</a></span> | <span class="t">including in unexpected domains like medicine. Where to start? Well, here's a super quick intro</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=50">00:00:50.160</a></span> | <span class="t">to those of you who haven't seen the original video. SmartGPT was a way of using the latest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=55">00:00:55.340</a></span> | <span class="t">prompting methods to test GPT-4. So, let's get started.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=55">00:00:55.760</a></span> | <span class="t">engineering research to trigger better performance in a model like GPT-4. Getting the model to think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=61">00:01:01.880</a></span> | <span class="t">a bit, aka use some tokens, before giving a final answer was key. Another important element I talked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=67">00:01:07.260</a></span> | <span class="t">about in that video was the power of getting the model to self-reflect. An insight I drew on from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=72">00:01:12.380</a></span> | <span class="t">talks with the lead author of the famous reflection paper. My manual experiments showed that using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=78">00:01:18.520</a></span> | <span class="t">optimized prompts, reflection, and self-dialogue, you could boost performance in almost any task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=83">00:01:23.900</a></span> | <span class="t">And I demoed the improvement on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=85">00:01:25.560</a></span> | <span class="t">formal logic and college mathematics. But there was a problem, which is why you guys haven't heard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=90">00:01:30.500</a></span> | <span class="t">about SmartGPT in a while. How could I systematically benchmark GPT-4 using these methods,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=95">00:01:35.920</a></span> | <span class="t">when I'm just one guy? Well, enter Josh Stapleton, machine learning engineer extraordinaire. Without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=101">00:01:41.440</a></span> | <span class="t">him, it would have been impossible to build out such a fleshed out, flexible code base,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=106">00:01:46.320</a></span> | <span class="t">with which we could systematize experiments and iterate rapidly. But then we both quickly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=111">00:01:51.040</a></span> | <span class="t">realized that there was another problem with benchmarking the original version of SmartGPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=115">00:01:55.540</a></span> | <span class="t">And that was that the software was not designed to be able to do the work of the original version.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=118">00:01:58.880</a></span> | <span class="t">It would be hell to manually extract out the final answers within pages of reflection and resolving,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=125">00:02:05.320</a></span> | <span class="t">not to mention cost tens of thousands of dollars. And trust me, a month of YouTube advertising would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=130">00:02:10.880</a></span> | <span class="t">not even cover the first hour of that run, unfortunately. And no, we would never compromise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=136">00:02:16.360</a></span> | <span class="t">by asking GPT-4 to grade its own answers. It would be unscientific and inaccurate. The infamous MIT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=143">00:02:23.920</a></span> | <span class="t">paper is enough evidence for that. But it would be a waste of time to do that. And I think that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=144">00:02:24.460</a></span> | <span class="t">what we're going to do. We're going to do a lot of research on this. And I think that's what we're going to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=144">00:02:24.500</a></span> | <span class="t">And I think that's what we're going to do. And I think that's what we're going to do. And I think that's what we're going to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=144">00:02:24.600</a></span> | <span class="t">There's enough evidence of that. GPT-4 didn't get 100% on an MIT degree,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=148">00:02:28.940</a></span> | <span class="t">and this paper was withdrawn. So yes, we had to lower the power level of SmartGPT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=154">00:02:34.640</a></span> | <span class="t">get rid of the reflection and resolving, deliberately sacrificing some of its intelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=159">00:02:39.840</a></span> | <span class="t">because we simply couldn't afford to unleash it fully. And yet, we still got a new, albeit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=165">00:02:45.460</a></span> | <span class="t">unofficial, record of 88.4% on the MMLU. That not only beats the 86.4% recorded by OpenAI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=174">00:02:54.140</a></span> | <span class="t">it does. And that's because we still have a new record of 88.4% on the MMLU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=174">00:02:54.580</a></span> | <span class="t">It beats the projections for 2024 that Metaculous recorded before ChatGPT came out. And yet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=181">00:03:01.660</a></span> | <span class="t">we are both convinced that there are at least a dozen more ways performance can be further</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=186">00:03:06.900</a></span> | <span class="t">boosted using existing models. Yes, that might mean GPT-4 getting a result reserved for June</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=193">00:03:13.380</a></span> | <span class="t">of 2025. The thing is, we have hit the limits of what a self-funding team of two can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=199">00:03:19.320</a></span> | <span class="t">Before I briefly touch on what the MMLU is, I am happy to say that all of our results,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=204">00:03:24.560</a></span> | <span class="t">and answers, that's 2,850 for the GPT-4 run and over 120,000 for GPT-3.5, are freely available</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=213">00:03:33.380</a></span> | <span class="t">to browse in a GitHub repository linked in the description. So what the hell is MMLU anyway?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=219">00:03:39.520</a></span> | <span class="t">Well, it is arguably the best-known benchmark of language model performance. It stands for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=225">00:03:45.360</a></span> | <span class="t">Massive Multitask Language Understanding. Massive because it has over 14,000 questions and multitask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=232">00:03:52.600</a></span> | <span class="t">because it covers 57 different languages. And it's a very, very good benchmark for language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=234">00:03:54.540</a></span> | <span class="t">management. It's a very, very good benchmark for language development. And it's a very, very good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=235">00:03:55.340</a></span> | <span class="t">benchmark for language development. The idea behind it was truly fantastic. And it is important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=239">00:03:59.420</a></span> | <span class="t">enough to feature prominently on the first page of the GPT-4 technical report. In the past,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=245">00:04:05.740</a></span> | <span class="t">I have said that getting 100% on this test would be a good sign of AGI. Others have talked about 95%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=252">00:04:12.220</a></span> | <span class="t">I do think I have like a 50% chance, like within the next 20 years or so,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=256">00:04:16.680</a></span> | <span class="t">there might be something what we might call an AGI or transformative AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=260">00:04:20.560</a></span> | <span class="t">What do I mean by this? Well, maybe you can measure it on benchmarks. There's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=264">00:04:24.520</a></span> | <span class="t">this famous MMLU benchmark is like, yeah, there's something which like scores like 95% on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=269">00:04:29.400</a></span> | <span class="t">And the paper itself notes that an 89.8% performance represents human expert ability,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=275">00:04:35.900</a></span> | <span class="t">which as you can tell from the title, we are achingly close to beating. And as you'll see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=280">00:04:40.880</a></span> | <span class="t">in a moment, GPT-4 with the full power of prompt engineering could likely get upwards of 90 to 92%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=287">00:04:47.860</a></span> | <span class="t">right now. And frankly, whether it's GPT-5 or Gemini, that 95% threshold should be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=294">00:04:54.500</a></span> | <span class="t">easily be broken by next year, not in 20 years. If we didn't use the full power of SmartGPT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=300">00:05:00.980</a></span> | <span class="t">how did we get 88.4%? And why does the title say 89%? Well, let me show you the two facets of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=308">00:05:08.980</a></span> | <span class="t">SmartGPT that we did use. The thing is the MMLU demands a single character answer, A, B, C, or D.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=316">00:05:16.420</a></span> | <span class="t">And that answer must be immediate. Now imagine taking a test and the very first thought you had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=322">00:05:22.200</a></span> | <span class="t">had to be your final answer. On a quick test, you might be able to get a single answer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=324">00:05:24.480</a></span> | <span class="t">this is believed to be a key reason for hallucinations. This was a great paper on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=330">00:05:30.000</a></span> | <span class="t">how language model hallucinations can snowball from the first few tokens. As they say, the language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=336">00:05:36.060</a></span> | <span class="t">model first commits to an answer. That's before outputting the explanation. And this is a problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=341">00:05:41.240</a></span> | <span class="t">because transformers cannot find the answer within one time step because of their limited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=345">00:05:45.700</a></span> | <span class="t">reasoning abilities within that time step. And why don't language models like GPT-4 back down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=350">00:05:50.760</a></span> | <span class="t">and change halfway through? Well, they prioritize fluency and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=354">00:05:54.460</a></span> | <span class="t">coherence at the expense of factuality. But rushing an answer in your first token is particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=361">00:06:01.120</a></span> | <span class="t">hobbling in questions like this requiring deeper thought or calculation. It's fine for questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=366">00:06:06.800</a></span> | <span class="t">that need memorized knowledge, but not for questions like these. We went through all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=371">00:06:11.720</a></span> | <span class="t">these subjects in the MMLU and characterized around a third of them as requiring that kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=378">00:06:18.200</a></span> | <span class="t">of deeper thought. And of course, most ways that you use GPT-4 will also require some thought. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=384">00:06:24.440</a></span> | <span class="t">the first two are the most common ones. The first one is the one that is the most common.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=386">00:06:26.180</a></span> | <span class="t">The second one is the one that is the most common. The third one is the one that is the most common.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=386">00:06:26.660</a></span> | <span class="t">The third one is the one that is the most common. The third one is the one that is the most common.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=386">00:06:26.740</a></span> | <span class="t">Open source teams and groups like OpenAI and Google all draw on the dev set when testing a model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=393">00:06:33.860</a></span> | <span class="t">Notice the five questions each with a single character answer. We were not, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=398">00:06:38.820</a></span> | <span class="t">the first team to realize that this underplays the abilities of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=403">00:06:43.820</a></span> | <span class="t">The Minerva paper from Google said this: "The standard way of evaluating on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=409">00:06:49.380</a></span> | <span class="t">MMLU is to construct a five-shot prompt out of the dev set." So what they did in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=414">00:06:54.420</a></span> | <span class="t">the first two years, instead, like us, was to use a prompt which has a chain of thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=418">00:06:58.980</a></span> | <span class="t">before outputting the final answer. You can see some examples below.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=422">00:07:02.880</a></span> | <span class="t">Essentially, it allows the model to think a bit first and gives it a scratch pad. There</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=428">00:07:08.100</a></span> | <span class="t">are other theories though, like the length and detail of the exemplars triggering different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=432">00:07:12.540</a></span> | <span class="t">weights of the model. This paper from two months ago used longer exemplars for the moral scenarios</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=439">00:07:19.080</a></span> | <span class="t">subject within the MMLU. With these five custom exemplars plus self-consistency, which I'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=444">00:07:24.400</a></span> | <span class="t">get to in a moment, they saw accuracy go up to 80% from 68%. But before even this paper came out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=450">00:07:30.940</a></span> | <span class="t">Josh and I were sourcing and crafting bespoke exemplars for the 21 subjects we deemed would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=457">00:07:37.780</a></span> | <span class="t">need the most working out. For the other subjects, we may do with the normal dev examples. OpenAI and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=463">00:07:43.960</a></span> | <span class="t">Google don't do this for their benchmarking, underplaying the abilities of their model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=468">00:07:48.580</a></span> | <span class="t">So why doesn't everyone do it, you might ask? My theory is that it's because you have to hand-grade</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=473">00:07:53.620</a></span> | <span class="t">every answer, and that's why we're doing this. But it's not just the model that's doing it. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=474">00:07:54.380</a></span> | <span class="t">the level of accuracy that we're taking into account. We're taking into account the level of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=475">00:07:55.480</a></span> | <span class="t">accuracy that we're taking into account. We're taking into account the level of accuracy that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=476">00:07:56.340</a></span> | <span class="t">taking into account. We're taking into account the level of accuracy that we're taking into account.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=476">00:07:56.600</a></span> | <span class="t">And it's not just the level of accuracy that we're taking into account. It's the level of accuracy that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=477">00:07:57.440</a></span> | <span class="t">we're taking into account. We're taking into account the level of accuracy that we're taking into account.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=478">00:07:58.060</a></span> | <span class="t">Essentially, you're taking the time to listen, which is the least that we can do, I feel, as we approach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=484">00:08:04.940</a></span> | <span class="t">human-level intelligences. Even though it still took weeks, to make checking easier, we taught</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=490">00:08:10.720</a></span> | <span class="t">GPT-3.5 and GPT-4 through our exemplars to always end with a final answer in the same format.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=498">00:08:18.780</a></span> | <span class="t">Lesson one, therefore, for everyone watching, is don't make the first token the final answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=504">00:08:24.360</a></span> | <span class="t">Lesson two comes from a paper on self-consistency, which in a nutshell says that taking the highest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=511">00:08:31.940</a></span> | <span class="t">probability answer, sometimes called greedy decoding, doesn't always reflect the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=517">00:08:37.040</a></span> | <span class="t">answer the model is capable of. In other words, don't take the model's first answer as its final</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=522">00:08:42.380</a></span> | <span class="t">answer. Take this example. The highest single probability answer was this, and that was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=527">00:08:47.920</a></span> | <span class="t">incorrect. For open AI, it would now be over, it's incorrect, done. But sometimes, if you look at all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=534">00:08:54.340</a></span> | <span class="t">the different answers that a model might give, and then take the majority answer, the final answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=540">00:09:00.040</a></span> | <span class="t">that came up the most often, it can get it right. Interestingly, in the Minerva paper, they used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=545">00:09:05.160</a></span> | <span class="t">256 samples, although only 16 for the MMLU. Open AI even put a little footnote in their GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=553">00:09:13.620</a></span> | <span class="t">technical paper, admitting that they don't use that approach, but Google does. And yes, this can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=558">00:09:18.920</a></span> | <span class="t">significantly affect the final results. Look at the boost going up to 40%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=564">00:09:24.320</a></span> | <span class="t">Now, the MMLU has 40 sampling paths, and it hasn't fully leveled off yet. These aren't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=567">00:09:27.940</a></span> | <span class="t">re-dos where you keep trying until you get it right. This is letting the model explore its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=572">00:09:32.720</a></span> | <span class="t">full probability distribution of outputs, and taking the truly most probable final answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=577">00:09:37.940</a></span> | <span class="t">Letting the model think, not rushing it. For our runs, we limited ourselves to 9 samples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=583">00:09:43.100</a></span> | <span class="t">and took the majority vote. But of course, the results could have been dramatically better if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=587">00:09:47.780</a></span> | <span class="t">we did 40 samples, or indeed 256. Now, aside from these two hard-won lessons, which I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=594">00:09:54.300</a></span> | <span class="t">show how all of you can benefit from, the other difference from the previous state-of-the-art 86.4%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=600">00:10:00.760</a></span> | <span class="t">was that we did use the most current versions of each model. So, the models may have independently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=606">00:10:06.060</a></span> | <span class="t">gotten better or worse in certain topics. But I would say that our broad findings do run counter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=612">00:10:12.020</a></span> | <span class="t">to any simple, it's-got-dumber narrative. And if I had to guess, behind the scenes, Open AI have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=617">00:10:17.920</a></span> | <span class="t">implemented some fine-tuning involving step-by-step solutions. As I see that phrase cropping up in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=624">00:10:24.280</a></span> | <span class="t">the middle of the video, I would say that the model is now able to do more than just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=630">00:10:30.740</a></span> | <span class="t">the same thing. And that particular trick from the original SmartGPT seems less effective than before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=634">00:10:34.280</a></span> | <span class="t">And now I'm going to ask Josh to talk about our state-of-the-art score, not only with GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=638">00:10:38.460</a></span> | <span class="t">but also with GPT-3.5. But just before I do, here is a hint of why the title talks about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=645">00:10:45.340</a></span> | <span class="t">breaking a benchmark. I'll show you how GPT-4 itself encouraged us to question many of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=654">00:10:54.260</a></span> | <span class="t">tests, leading to the discovery of at least 80, and likely hundreds of errors in the test. Enough to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=660">00:11:00.440</a></span> | <span class="t">significantly affect final results by up to 2%. And given that the differences in, say, the open-source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=667">00:11:07.280</a></span> | <span class="t">language model leaderboard come down to as little as 0.1 of a percent, that's pretty big. Yes, we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=672">00:11:12.440</a></span> | <span class="t">been in contact with some of the authors of the test over the past month to check our findings, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=677">00:11:17.000</a></span> | <span class="t">I'll say more in a bit. But first, here is ML engineer Josh detailing how the magic happened. Josh, by the way, is a pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=684">00:11:24.240</a></span> | <span class="t">precocious AI consultant working on a master's at Imperial College London.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=688">00:11:28.260</a></span> | <span class="t">Josh Stapleton: Hi everyone, nice to meet you all. My name is Josh Stapleton, and let me show you the version of SmartGPT we used. The SmartGPT framework is highly parallelized and can handle industry-scale use cases. We used a thread and a syncIO-based approach to make simultaneous calls to the API at answer option, answer, and subject levels, stacking parallelization upon parallelization. This led to crazy iteration speed boosts. For example, we were able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=714">00:11:54.220</a></span> | <span class="t">complete the final GPT-4 run in under two hours, generating single answer options in series would have taken weeks. We did two large runs using SmartGPT, first with GPT 3.5 and then GPT 4. The 3.5 run was on the entirety of MMLU for a total of nine times 14,042 questions, 126,000 answers. This was a mammoth effort to manually grade, but the SmartGPT innovations and hard work ended up boosting GPT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=744">00:12:24.200</a></span> | <span class="t">3.5's performance by a significant 3.7%, from 70% to 73.7%. The GPT-4 run using SmartGPT also beat the OpenAI MMLU benchmark score substantially, and this run actually resulted in the discovery of a number of problematic MMLU questions, which Philip will talk about shortly. The cost to run GPT-4 on all MMLU would have been too high for us to self-fund, having already each invested four-figure sums, so we used a representative subset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=774">00:12:54.180</a></span> | <span class="t">of 2,850 questions from the total of 14,042, of course fully weighted to official standards. SmartGPT is a model-agnostic, parametrized, and highly flexible system that can be applied to disparate use cases. We are already working on applications in a number of domains in both the public and private sectors. The system is evolving and improving constantly under the hood as we continue to innovate. While the current system can get state-of-the-art results, with the ability to handle enterprise-scale data, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=804">00:13:24.160</a></span> | <span class="t">system is still a challenge. There are a number of known ways to improve it, which we aim to implement in the near future. From better and more numerous automatically sourced exemplars, to LLM-driven prompt optimization, to fine-tuning, we are just getting started with SmartGPT. And we are uniquely positioned as a tiny team to integrate both our own ongoing improvements, as well as promising discoveries in the field as they arise. Back to Philip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=834">00:13:54.140</a></span> | <span class="t">Here is the question that started it all off. As you can see, the question makes no sense. The text says, demand reduction, and the answers are either 134, 234, 123, 124. What on earth is that about? Now remember, it was only human grading that enabled us to spot this. I reckon most companies like OpenAI rely on auto-grading by exact match. That would immediately toss out any answer like these as null because an answer of A, B, C, or D</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=864">00:14:24.120</a></span> | <span class="t">hasn't been given. Now I should say, it was human grading that caught this, and GPT-4 itself. Here is poor GPT-3.5 bravely giving an answer to a question that doesn't make absolutely any sense at all. I love how a couple of times it changed its mind and was like, no, no, no, D, not B. What then followed was weeks and weeks of me following up every quote-unquote mistake with the official source the question came from. When I found the original source, I realised what the problem was. Sometimes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=894">00:14:54.100</a></span> | <span class="t">they just hadn't pasted all of these statements. When you can see all four of these statements,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=898">00:14:58.900</a></span> | <span class="t">the answer options make a lot more sense. Now I know what some of you may be thinking. Maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=903">00:15:03.560</a></span> | <span class="t">it's just business ethics, that's just one subject, and what, it's a dozen questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=907">00:15:07.640</a></span> | <span class="t">what's the big deal? Well first of all, business ethics only has 100 questions, so 13 of them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=912">00:15:12.780</a></span> | <span class="t">missing vital context, completely undermines that entire subject. And second of all, it wasn't just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=919">00:15:19.080</a></span> | <span class="t">business ethics, and it wasn't just this same problem. It wouldn't always be about missing statements,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=924">00:15:24.080</a></span> | <span class="t">it would be about missing the whole thing. So let's take a look at the results of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=928">00:15:28.080</a></span> | <span class="t">first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=932">00:15:32.300</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=954">00:15:54.060</a></span> | <span class="t">of the first two questions. So let's take a look at the results of the first two questions. So let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=984">00:16:24.040</a></span> | <span class="t">take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1014">00:16:54.020</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1044">00:17:24.000</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1073">00:17:53.980</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1103">00:18:23.960</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1133">00:18:53.940</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1163">00:19:23.920</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1193">00:19:53.900</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1223">00:20:23.880</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1253">00:20:53.860</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1283">00:21:23.840</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1313">00:21:53.820</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1343">00:22:23.800</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1373">00:22:53.780</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1403">00:23:23.760</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1433">00:23:53.740</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1463">00:24:23.720</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1493">00:24:53.700</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1523">00:25:23.680</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1553">00:25:53.660</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=hVade_8H8mE&t=1583">00:26:23.640</a></span> | <span class="t">So let's take a look at the results of the first two questions. So let's take a look at the results of the first two questions.</span></div></div></body></html>