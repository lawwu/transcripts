<html><head><title>Training Albatross  An Expert Finance LLM: Leo Pekelis</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Training Albatross  An Expert Finance LLM: Leo Pekelis</h2><a href="https://www.youtube.com/watch?v=of-SV35YqvY"><img src="https://i.ytimg.com/vi_webp/of-SV35YqvY/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./of-SV35YqvY.html">Whisper Transcript</a> | <a href="./transcript_of-SV35YqvY.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hi, everyone. I'm Leo. I'm the Chief Scientist at Gradient. And today, I'll be talking about how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=21" target="_blank">00:00:21.040</a></span> | <span class="t">we trained large language models to be finance experts. Yeah, let's go ahead and dive right into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=27" target="_blank">00:00:27.920</a></span> | <span class="t">it. So before I start getting into the details here, I wanted to make a couple of observations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=34" target="_blank">00:00:34.640</a></span> | <span class="t">And the first one is that foundational models have been growing at an exponential rate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=41" target="_blank">00:00:41.280</a></span> | <span class="t">right? So not only do you kind of bespoke AI companies each have their own foundational models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=48" target="_blank">00:00:48.480</a></span> | <span class="t">but data companies, general tech companies, they all have their own flavor of the language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=55" target="_blank">00:00:55.680</a></span> | <span class="t">each with its own features, and use cases. And another observation, which is pretty related,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=62" target="_blank">00:01:02.480</a></span> | <span class="t">is that the context length, right, the number of tokens that you can fit into a prompt has increased</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=69" target="_blank">00:01:09.120</a></span> | <span class="t">quite a bit over the past year. The largest context length models about a year ago were something like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=75" target="_blank">00:01:15.120</a></span> | <span class="t">100K. And in the past year, they've grown to about 40 times that, just in models released in the past few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=83" target="_blank">00:01:23.200</a></span> | <span class="t">months, including one released by Gradient. And both of these observations are evidence to kind of one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=92" target="_blank">00:01:32.080</a></span> | <span class="t">point, and that's the large language models are not one size fits all. Especially when you get to kind of more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=98" target="_blank">00:01:38.480</a></span> | <span class="t">complicated use cases, taking a generalist language model, or a base language model kind of off the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=105" target="_blank">00:01:45.840</a></span> | <span class="t">shelf isn't really going to get you too far. And I realize I'm talking at the open models track of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=112" target="_blank">00:01:52.320</a></span> | <span class="t">conference, I probably don't need to convince you guys too much of this statement. But it is pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=118" target="_blank">00:01:58.560</a></span> | <span class="t">important for us at Gradient, and it's actually our foundational pieces for what we built, which is an AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=125" target="_blank">00:02:05.360</a></span> | <span class="t">Foundry. And for us, what an AI Foundry is, is it's a collection of custom language models, as well as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=133" target="_blank">00:02:13.280</a></span> | <span class="t">number of workflow primitives. And what we do is we take all these pieces and components together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=138" target="_blank">00:02:18.960</a></span> | <span class="t">to create solutions that are a custom fit for our customers. And today, I'm going to talk about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=144" target="_blank">00:02:24.640</a></span> | <span class="t">specifically, our solutions for the finance domain, right, building financial experts. And for those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=152" target="_blank">00:02:32.080</a></span> | <span class="t">solutions, really, two components have been incredibly useful. One should be fairly, fairly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=158" target="_blank">00:02:38.960</a></span> | <span class="t">straightforward is our domain specific finance language model. And the other one is a context length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=165" target="_blank">00:02:45.840</a></span> | <span class="t">extension that we've worked on. And so why are these important specifically for finance? Well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=172" target="_blank">00:02:52.480</a></span> | <span class="t">a little while ago, we got together and wrote down kind of six requirements for finance applications</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=178" target="_blank">00:02:58.160</a></span> | <span class="t">of language models that generalist models tend to lack or fall a little bit short on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=182" target="_blank">00:03:02.960</a></span> | <span class="t">You know, if you look at these requirements, they're fairly general, they kind of apply across</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=189" target="_blank">00:03:09.520</a></span> | <span class="t">industries, but in particular for finance, they seem pretty important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=193" target="_blank">00:03:13.600</a></span> | <span class="t">And today, I'm just going to talk about two of them that happen to be paired with the two solutions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=201" target="_blank">00:03:21.440</a></span> | <span class="t">that I also want to talk about the finance language model and the extended context length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=205" target="_blank">00:03:25.680</a></span> | <span class="t">So jumping, jumping right into it, the first one is the finance language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=215" target="_blank">00:03:35.040</a></span> | <span class="t">You know, you might be wondering, why, why even have a domain specific language model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=222" target="_blank">00:03:42.240</a></span> | <span class="t">Why is domain knowledge important? The reason is, is that your general purpose language models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=228" target="_blank">00:03:48.400</a></span> | <span class="t">like the GPTs of the world, they are trained on a very broad set of data, kind of broad and not deep,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=237" target="_blank">00:03:57.520</a></span> | <span class="t">especially in kind of like more technical situations, like technical financial information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=241" target="_blank">00:04:01.920</a></span> | <span class="t">And as kind of like an illustrative example on why this is important, here's a chart from a recent research paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=250" target="_blank">00:04:10.080</a></span> | <span class="t">where it shows that even for very large models, right, the red line at the top there is for 176 billion parameter model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=257" target="_blank">00:04:17.680</a></span> | <span class="t">You need something on the order of thousands of relevant documents in the models pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=263" target="_blank">00:04:23.600</a></span> | <span class="t">In order for the model to get decent, I mean, here, it's even above 50% accuracy on answering a related question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=271" target="_blank">00:04:31.120</a></span> | <span class="t">Right. And so kind of what this implies is that if you ask a language model questions about data that's kind of like in the tails of its training data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=281" target="_blank">00:04:41.120</a></span> | <span class="t">then it's going to do a poor job at answering those questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=284" target="_blank">00:04:44.960</a></span> | <span class="t">Right. And so, you know, the natural way to fix this is the case is to say, OK, base model doesn't know a lot about finance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=294" target="_blank">00:04:54.000</a></span> | <span class="t">Let's train it some finance. An issue there, and here I'm going to talk about kind of how we trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=301" target="_blank">00:05:01.680</a></span> | <span class="t">our finance-specific language model is -- so an issue there is that there's a whole lot of financial data out there, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=308" target="_blank">00:05:08.800</a></span> | <span class="t">Like way more than you could possibly review or look at manually. And so that requires creating an automated data pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=318" target="_blank">00:05:18.480</a></span> | <span class="t">And that's what we did. We created one. Probably the most compelling or interesting part of this data pipeline is the automated data curation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=326" target="_blank">00:05:26.800</a></span> | <span class="t">where we borrowed ideas from the membership inference literature. And so what we do is we amass a whole large corpus of training data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=338" target="_blank">00:05:38.160</a></span> | <span class="t">And then we use techniques to try to see if a particular document, if there's a high chance that it was already in the model's training data, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=348" target="_blank">00:05:48.000</a></span> | <span class="t">So maybe you have like a Lama-based model, you have a document, and you can run some of these techniques to get a probability of whether or not the model's already seen that data in training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=356" target="_blank">00:05:56.320</a></span> | <span class="t">So you filter out all the data that the model hasn't seen before. What you're left with is a much smaller set of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=362" target="_blank">00:06:02.480</a></span> | <span class="t">Now that's manageable to look at through human review. And then finally pass through to synthetic data augmentation, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=371" target="_blank">00:06:11.120</a></span> | <span class="t">Both to upsample data and to handle some variations in data representation and formatting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=377" target="_blank">00:06:17.440</a></span> | <span class="t">And kind of like the last part of the recipe for how to train domain-specific language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=389" target="_blank">00:06:29.280</a></span> | <span class="t">is to take that data set that you created and to pass it through a training pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=394" target="_blank">00:06:34.560</a></span> | <span class="t">I think by now a training pipeline like this is fairly standard. There's two main parts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=402" target="_blank">00:06:42.560</a></span> | <span class="t">One is the continuous pre-training. So you take that data set that you created on the previous slide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=409" target="_blank">00:06:49.120</a></span> | <span class="t">and you do kind of next token prediction on it off of a base existing model, right? So again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=415" target="_blank">00:06:55.520</a></span> | <span class="t">we're taking a base foundational model like a Lama model to start with. And then the second part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=422" target="_blank">00:07:02.240</a></span> | <span class="t">is you run alignment on the model here, you've re-ran both supervised fine tuning and preference optimization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=430" target="_blank">00:07:10.480</a></span> | <span class="t">And kind of the way I like to think about the division between these two tasks is pre-training is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=438" target="_blank">00:07:18.240</a></span> | <span class="t">something like if you had a bunch of textbooks and you wanted a model to read all those textbooks and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=443" target="_blank">00:07:23.520</a></span> | <span class="t">understand all that information or retain all that information. And alignment is kind of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=450" target="_blank">00:07:30.080</a></span> | <span class="t">then instructing the model on how to use that information or best practices and what to do with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=454" target="_blank">00:07:34.640</a></span> | <span class="t">that. And so if pre-training is like reading textbooks, alignment is like maybe like taking an exam</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=460" target="_blank">00:07:40.640</a></span> | <span class="t">on a class or working on a project. Right. And that's really all I wanted to say about the domain-specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=468" target="_blank">00:07:48.160</a></span> | <span class="t">language model. Now I want to talk about the, see how much time I have, great, about the other part,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=474" target="_blank">00:07:54.640</a></span> | <span class="t">which is the extended context and how extended context or long context language models help us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=481" target="_blank">00:08:01.920</a></span> | <span class="t">address hallucinations. Right. To give a quick refresher, what are hallucinations? Well, it's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=487" target="_blank">00:08:07.600</a></span> | <span class="t">pretty broad term and it's used quite frequently nowadays. It's whenever you run inference on a model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=495" target="_blank">00:08:15.280</a></span> | <span class="t">when you give it a query and it generates content that is irrelevant or made up or inconsistent with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=500" target="_blank">00:08:20.240</a></span> | <span class="t">input data. There's been a fair amount of research as to the cause of hallucinations. A lot of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=507" target="_blank">00:08:27.600</a></span> | <span class="t">research points to deficiencies in the underlying training data. Right. So some, some causes might be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=514" target="_blank">00:08:34.720</a></span> | <span class="t">just the training data is outdated. Right. You're asking the model a question on information that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=519" target="_blank">00:08:39.760</a></span> | <span class="t">now updated since the training data. Another one is a lot of the training data practices require automated data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=528" target="_blank">00:08:48.000</a></span> | <span class="t">data collection. And if there's ever inconsistencies or bugs in that data collection, um, you can get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=534" target="_blank">00:08:54.640</a></span> | <span class="t">source reference divergence, right? So the model is just trained on data that doesn't quite make sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=538" target="_blank">00:08:58.640</a></span> | <span class="t">Uh, and, and there's a few other reasons. All of these, uh, can, uh, encode information in the model's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=545" target="_blank">00:09:05.360</a></span> | <span class="t">memory banks that there isn't quite accurate, uh, and, and that'll cause the model to hallucinate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=550" target="_blank">00:09:10.160</a></span> | <span class="t">And while, uh, alignment or, or, uh, continued training of the model can alleviate hallucinations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=558" target="_blank">00:09:18.240</a></span> | <span class="t">um, at gradient, we find that actually in context learning. So, uh, working directly on the prompt</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=565" target="_blank">00:09:25.440</a></span> | <span class="t">during the execution pipeline, uh, is the most direct and, and sample efficient way to reduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=570" target="_blank">00:09:30.880</a></span> | <span class="t">hallucinations. Right. Because, uh, what you can do is you can put in a relatively small amount of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=576" target="_blank">00:09:36.320</a></span> | <span class="t">information directly into the prompt, uh, kind of at inference time, uh, and sort of, uh, plaster over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=582" target="_blank">00:09:42.800</a></span> | <span class="t">or bandaid over, uh, issues, uh, with, with the model's training data. Um, and so that's great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=588" target="_blank">00:09:48.640</a></span> | <span class="t">In context learning works really well. Um, the issue is it works so well that when you start doing it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=594" target="_blank">00:09:54.640</a></span> | <span class="t">you want to do more and more of it. And, and then kind of, you run into the, one of the biggest pain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=599" target="_blank">00:09:59.600</a></span> | <span class="t">points, uh, uh, with this practice, uh, or one of the biggest bottlenecks, uh, which is the context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=604" target="_blank">00:10:04.800</a></span> | <span class="t">length. Um, and I'm guessing that this is an issue that, that many of you in this room have, have come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=610" target="_blank">00:10:10.640</a></span> | <span class="t">across yourselves. Um, and that's, uh, you, you just run out of prompt, uh, in, in terms of, for in context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=617" target="_blank">00:10:17.120</a></span> | <span class="t">learning. Um, a few examples, uh, for why that can be an issue. Uh, if you're trying to put in a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=624" target="_blank">00:10:24.000</a></span> | <span class="t">shot examples into the prompt, you're running out of prompt space before you run out of examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=628" target="_blank">00:10:28.320</a></span> | <span class="t">So now you have to spend a lot of time in choosing the particular example or, or working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=632" target="_blank">00:10:32.640</a></span> | <span class="t">on some kind of like lossy summarization technique, um, for more complex product problems that may</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=638" target="_blank">00:10:38.560</a></span> | <span class="t">require some brittle, uh, pre-processing pipelines, each can have errors. Um, and also if you do some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=645" target="_blank">00:10:45.120</a></span> | <span class="t">kind of external memory management, such as RAG, uh, those systems tend to have poor performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=651" target="_blank">00:10:51.440</a></span> | <span class="t">when the chunks that get pulled, uh, require them to be interrelated, right? So if you pull one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=657" target="_blank">00:10:57.440</a></span> | <span class="t">chunk and another chunk that you need to pull, uh, has to reference a previous chunk to, to know if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=662" target="_blank">00:11:02.880</a></span> | <span class="t">it needs to get, uh, queried, right? And RAG does, uh, typically does a pretty poor job with that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=668" target="_blank">00:11:08.000</a></span> | <span class="t">Um, right. So context length, uh, is the bottleneck for this. So the most natural thing to do is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=675" target="_blank">00:11:15.440</a></span> | <span class="t">extend the context length. Um, and, and so that's, that's what we did with, with some of our models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=681" target="_blank">00:11:21.680</a></span> | <span class="t">Uh, and here really, I just wanted to talk about a couple of examples of what suddenly becomes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=688" target="_blank">00:11:28.000</a></span> | <span class="t">possible, uh, when you have a context length that, that's sort of in the realm of, of a million tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=694" target="_blank">00:11:34.160</a></span> | <span class="t">long. Um, here on, on the left-hand side, uh, is an example showing that you can now actually put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=700" target="_blank">00:11:40.880</a></span> | <span class="t">thousands of examples directly into the prompt. Uh, and that kind of gets you back into this kind of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=706" target="_blank">00:11:46.160</a></span> | <span class="t">domain learning regime that I talked about earlier. Uh, it's just now it is, uh, on the fly and at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=712" target="_blank">00:11:52.000</a></span> | <span class="t">inference time, right? So it can be very adaptive to the problem. Um, and, uh, you, you do find that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=717" target="_blank">00:11:57.760</a></span> | <span class="t">uh, for a lot of tasks out there, this like thousands of examples mark is actually necessary, uh, to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=724" target="_blank">00:12:04.400</a></span> | <span class="t">kind of production grade accuracy or, or dangerous levels of accuracy for a model. Um, and, and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=730" target="_blank">00:12:10.560</a></span> | <span class="t">other example is, uh, with the long context length, um, you can leverage what transformer models are, are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=738" target="_blank">00:12:18.000</a></span> | <span class="t">natively really good at, which is being able to attend to every single token in the prompt. Um, and by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=744" target="_blank">00:12:24.000</a></span> | <span class="t">doing that, you can actually have the model perform, uh, fairly complicated reasoning, uh, implicitly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=749" target="_blank">00:12:29.520</a></span> | <span class="t">just, just in through, through going through its, uh, layers and attention layers. Um, and an example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=755" target="_blank">00:12:35.440</a></span> | <span class="t">that, um, that we kind of, uh, cooked up, uh, in house, uh, was we took, uh, books that were written</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=763" target="_blank">00:12:43.920</a></span> | <span class="t">by Mark Twain, the author, uh, and first we scrubbed the books of any kind of identifying information,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=769" target="_blank">00:12:49.280</a></span> | <span class="t">right? So, so no mention of the author or anything like that. Uh, and then we gave that into the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=774" target="_blank">00:12:54.160</a></span> | <span class="t">uh, into its prompt, into its context and asked the model to generate, uh, new stories in the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=779" target="_blank">00:12:59.120</a></span> | <span class="t">style. Uh, and after kind of five books of, of reference prompts, the model was, uh, able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=785" target="_blank">00:13:05.040</a></span> | <span class="t">generate stories, um, that convinced, uh, a separate critic model, uh, that those short stories could have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=791" target="_blank">00:13:11.680</a></span> | <span class="t">been actually written, uh, by that same author, right? Uh, and, and in pretty actually like deep and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=797" target="_blank">00:13:17.440</a></span> | <span class="t">intricate ways, not just kind of like stylistic similarity or language, uh, but down to theme and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=803" target="_blank">00:13:23.360</a></span> | <span class="t">characters and setting and things like that. So, uh, kind of the punchline is, is that long context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=808" target="_blank">00:13:28.720</a></span> | <span class="t">language models give you more, uh, grounded and robust systems and there's fewer moving parts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=814" target="_blank">00:13:34.080</a></span> | <span class="t">much more is contained in the language model, which, which is the thing that we all care about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=818" target="_blank">00:13:38.640</a></span> | <span class="t">Um, and, and that in turn reduces hallucinations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=821" target="_blank">00:13:41.040</a></span> | <span class="t">Right. So, um, you know, those are basically the, the two components, um, two solutions of our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=832" target="_blank">00:13:52.560</a></span> | <span class="t">platform that I wanted to, to describe to you all today. Um, one of the things that, that we believe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=838" target="_blank">00:13:58.160</a></span> | <span class="t">in pretty strongly at Gradient is to have transparent and verifiable benchmarks. Uh, and also we're pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=844" target="_blank">00:14:04.800</a></span> | <span class="t">passionate and giving back to the open source community because a lot of what we've, uh, built</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=849" target="_blank">00:14:09.120</a></span> | <span class="t">our work on are, are open source, uh, models and techniques themselves. Uh, and so for both of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=855" target="_blank">00:14:15.280</a></span> | <span class="t">solutions, we've open source models, uh, on our, um, company page at Hugging Face. Um, one of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=861" target="_blank">00:14:21.600</a></span> | <span class="t">is the, the, the, the alpha trust model. So that's the result of applying our, uh, finance domain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=867" target="_blank">00:14:27.440</a></span> | <span class="t">training on a llama two base model. Um, and here the, the benchmarks show that after doing that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=873" target="_blank">00:14:33.520</a></span> | <span class="t">uh, uh, it ends up being competitive, uh, and actually better, uh, competitive at kind of open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=879" target="_blank">00:14:39.440</a></span> | <span class="t">LLM general, uh, benchmarks and better at finance specific benchmarks, uh, to models in the same class</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=886" target="_blank">00:14:46.000</a></span> | <span class="t">to its peers. And the other model is, um, a 1 million context length extension of, uh, a llama three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=894" target="_blank">00:14:54.000</a></span> | <span class="t">base model that we released pretty recently. Um, and with it, uh, we were able to get, uh, a hundred</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=900" target="_blank">00:15:00.480</a></span> | <span class="t">percent needle in a haystack scores actually, uh, above 1 million context lengths. That's the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=906" target="_blank">00:15:06.560</a></span> | <span class="t">image. Uh, and also had a pretty substantial performance improvement, uh, over the base model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=913" target="_blank">00:15:13.120</a></span> | <span class="t">on a ruler long context length benchmark. That's a benchmark put out by Nvidia. Um, and that brings this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=919" target="_blank">00:15:19.920</a></span> | <span class="t">model kind of in the realm of, uh, flagship long context models, uh, like Gemini 1.5 pro GPT 4 and,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=928" target="_blank">00:15:28.560</a></span> | <span class="t">and command R plus. Right. And so the, these models are open source publicly available and invite you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=934" target="_blank">00:15:34.960</a></span> | <span class="t">all to go and check them out. Um, and about a, about a minute left. So, uh, I'll finish off, uh, here. Uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=944" target="_blank">00:15:44.880</a></span> | <span class="t">Uh, there's of course, lots more to building, uh, an AI financial expert. These are just two pieces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=950" target="_blank">00:15:50.160</a></span> | <span class="t">of the puzzle, even though they're two important ones. Uh, and if you guys are interested in finding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=954" target="_blank">00:15:54.480</a></span> | <span class="t">out more, uh, feel free to check us out on our, on our website or reach out and contact us. Cool. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=of-SV35YqvY&t=964" target="_blank">00:16:04.320</a></span> | <span class="t">Thank you.</span></div></div></body></html>