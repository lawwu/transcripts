<html><head><title>Five hard earned lessons about Evals — Ankur Goyal, Braintrust</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Five hard earned lessons about Evals — Ankur Goyal, Braintrust</h2><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA"><img src="https://i.ytimg.com/vi_webp/a4BV0gGmXgA/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=0">0:0</a> Introduction to 5 Lessons in AI Product Development<br><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=19">0:19</a> Lesson 1: Effective Evals Speak for Themselves<br><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=129">2:9</a> Lesson 2: Great Evals Need to Be Intentionally Engineered<br><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=243">4:3</a> Lesson 3: Context Engineering is the New Prompt Engineering<br><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=397">6:37</a> Lesson 4: Be Prepared for a New Model to Change Everything<br><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=549">9:9</a> Lesson 5: Optimize the Entire Evaluation System, Not Just the Prompts<br><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=741">12:21</a> Recap of the Five Lessons<br><br><div style="text-align: left;"><a href="./a4BV0gGmXgA.html">Whisper Transcript</a> | <a href="./transcript_a4BV0gGmXgA.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Let's talk about some of the interesting things we've learned over time. So the first thing is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=20" target="_blank">00:00:20.680</a></span> | <span class="t">I think it's super important for you to understand and define whether evals are actually providing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=27" target="_blank">00:00:27.360</a></span> | <span class="t">value for your organization or not. And I tried to come up with three signs that you should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=33" target="_blank">00:00:33.100</a></span> | <span class="t">look for that are good. So the first is if a new model comes out, you should be prepared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=42" target="_blank">00:00:42.480</a></span> | <span class="t">via your evals to be able to launch an update to your product within 24 hours that incorporates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=48" target="_blank">00:00:48.200</a></span> | <span class="t">the new model. Sarah from Notion, she talked yesterday, she talked about this specifically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=54" target="_blank">00:00:54.680</a></span> | <span class="t">but for the past several model releases, every time something comes out, Notion's able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=59" target="_blank">00:00:59.540</a></span> | <span class="t">incorporate the new model within 24 hours. And I think that's a really good sign of success.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=64" target="_blank">00:01:04.340</a></span> | <span class="t">If you can't do that, then it means that you have some work to do on your evals.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=71" target="_blank">00:01:11.140</a></span> | <span class="t">Another sign of success is if a user complains about something, do you have a very clear and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=76" target="_blank">00:01:16.480</a></span> | <span class="t">straightforward path to take their complaint and add it into your evals? If you do, then you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=82" target="_blank">00:01:22.220</a></span> | <span class="t">a shot at actually incorporating user feedback, pulling it into your evals, and ultimately doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=87" target="_blank">00:01:27.980</a></span> | <span class="t">it better. If you don't, then you're going to lose a lot of valuable information into the ether. So again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=93" target="_blank">00:01:33.040</a></span> | <span class="t">I think this is a really important kind of threshold or milestone to hit. And the last one, which I'm actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=100" target="_blank">00:01:40.220</a></span> | <span class="t">going to talk about a little bit more throughout the presentation is you should really start using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=105" target="_blank">00:01:45.080</a></span> | <span class="t">evals to play offense and understand which use cases you can solve and how well you can solve them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=111" target="_blank">00:01:51.260</a></span> | <span class="t">before you actually ship things, not like unit tests, which allow you to just test for regressions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=116" target="_blank">00:01:56.360</a></span> | <span class="t">So if you really adopt evals, then I think before you launch a new product, you have a really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=122" target="_blank">00:02:02.700</a></span> | <span class="t">good idea of how well the product might work given what your evals say.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=130" target="_blank">00:02:10.760</a></span> | <span class="t">The second lesson is that great evals, they have to be engineered. They don't just come for free</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=137" target="_blank">00:02:17.360</a></span> | <span class="t">with synthetic data sets and random LLM-as-a-judge scores that you read about online. And I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=145" target="_blank">00:02:25.280</a></span> | <span class="t">there's maybe two ways of thinking about this. There's no data set that is perfectly aligned with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=150" target="_blank">00:02:30.740</a></span> | <span class="t">reality. I think in the cases that there are, there's like basically nothing to do and the use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=155" target="_blank">00:02:35.920</a></span> | <span class="t">cases already work, which there are a few that are kind of like that, like solving competition math</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=161" target="_blank">00:02:41.360</a></span> | <span class="t">problems, for example. But for most real world use cases, any data set that you can come up with ahead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=166" target="_blank">00:02:46.760</a></span> | <span class="t">of time is not going to represent what users are actually experiencing. And I think the best data sets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=172" target="_blank">00:02:52.640</a></span> | <span class="t">are those that you can continuously reconcile as you actually experience what happens in reality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=178" target="_blank">00:02:58.100</a></span> | <span class="t">And doing that well requires quite a bit of engineering. Of course, brain trust can help you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=183" target="_blank">00:03:03.200</a></span> | <span class="t">with that. But I think the point is, you have to think about a data set as an engineering problem,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=188" target="_blank">00:03:08.240</a></span> | <span class="t">not just something that's given to you. And the same is true with scorers. I think a lot of people we talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=194" target="_blank">00:03:14.960</a></span> | <span class="t">to ask, "Hey, what scorers does brain trust come with? And how can we use those so that we don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=200" target="_blank">00:03:20.420</a></span> | <span class="t">need to think about scoring?" And we actually have a really powerful open source library called auto</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=205" target="_blank">00:03:25.880</a></span> | <span class="t">evals. But it's very open source and flexible for a reason, which is that every company that we work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=212" target="_blank">00:03:32.480</a></span> | <span class="t">with that's sufficiently advanced is writing their own scoring functions and modifying them constantly. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=218" target="_blank">00:03:38.720</a></span> | <span class="t">I think one way to think about scorers is they're like a spec or like a PRD for your AI application.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=225" target="_blank">00:03:45.180</a></span> | <span class="t">And if you think about them that way, one, it actually justifies making an investment in scoring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=230" target="_blank">00:03:50.820</a></span> | <span class="t">beyond just using something off the shelf. And two, hopefully it's fairly obvious that if you just use,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=235" target="_blank">00:03:55.660</a></span> | <span class="t">you know, an open source or generic scorer, that's a spec for someone else's project, not yours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=240" target="_blank">00:04:00.720</a></span> | <span class="t">There's been a real shift towards context in prompts. That's not just the system prompt that you write.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=251" target="_blank">00:04:11.820</a></span> | <span class="t">And I actually think that just traditional prompt engineering, people say this in different ways, but I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=256" target="_blank">00:04:16.980</a></span> | <span class="t">think traditional prompt engineering is evolving quite a bit. And it's very important to think about context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=261" target="_blank">00:04:21.960</a></span> | <span class="t">not just a prompt. So this is an example of what kind of a modern prompt looks like for an agent. Usually you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=269" target="_blank">00:04:29.760</a></span> | <span class="t">have a system prompt and then a for loop, which, you know, runs LLM calls, issues tool calls, incorporates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=277" target="_blank">00:04:37.260</a></span> | <span class="t">the tool calls into the prompt, and then iterates and iterates. And I actually took a few trajectories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=285" target="_blank">00:04:45.360</a></span> | <span class="t">from agents that we see in the wild and summarize these numbers. And as you can see, a vast majority</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=291" target="_blank">00:04:51.660</a></span> | <span class="t">of the tokens in the average prompt are not from the system prompt. And so, yes, it's very important to write a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=298" target="_blank">00:04:58.800</a></span> | <span class="t">system prompt and continue to improve it. But if you're not very precise about how you define tools and how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=305" target="_blank">00:05:05.460</a></span> | <span class="t">you define their outputs, then you're leaving a lot on the table. And I think one of the most important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=310" target="_blank">00:05:10.200</a></span> | <span class="t">things we've learned together with some customers is that you can't just take tools as a reflection of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=318" target="_blank">00:05:18.300</a></span> | <span class="t">your APIs or your product as it exists today. You have to think about tools in terms of what the LLM wants</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=324" target="_blank">00:05:24.960</a></span> | <span class="t">LLM wants to see and how you can use, you know, exactly what you present to the LLM to make it work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=331" target="_blank">00:05:31.620</a></span> | <span class="t">really well. And I think that in most projects, it's actually very disruptive when you write good tools. It's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=339" target="_blank">00:05:39.900</a></span> | <span class="t">something that's just like an API layer on top of the stuff that you already have. And the same is true with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=344" target="_blank">00:05:44.460</a></span> | <span class="t">their outputs. There's one example that we worked on recently for an internal project where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=351" target="_blank">00:05:51.120</a></span> | <span class="t">shifting the output of a tool from JSON to YAML actually made a significant difference. And I know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=357" target="_blank">00:05:57.460</a></span> | <span class="t">that's a little bit of a meme in the AI universe, but it's just so much more token efficient and easy for an LLM to look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=365" target="_blank">00:06:05.160</a></span> | <span class="t">YAML-shaped data while doing analysis than extremely verbose JSON. Now, if you're writing code and you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=373" target="_blank">00:06:13.660</a></span> | <span class="t">plugging something into, you know, a charting library, it makes no difference because to JavaScript, YAML and JSON are both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=380" target="_blank">00:06:20.620</a></span> | <span class="t">structured data. But to an LLM, they're very different. And so I think you have to be very, very thoughtful about, you know, how you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=388" target="_blank">00:06:28.000</a></span> | <span class="t">actually construct the definition of a tool and how you construct its output for the LLM to maximally benefit from it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=394" target="_blank">00:06:34.000</a></span> | <span class="t">So, I think one of the most important things we've learned, and actually, I would credit some of the folks at Repl.it for really pioneering this pattern,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=407" target="_blank">00:06:47.340</a></span> | <span class="t">but, you know, every time a new model comes out, everything might change. And I think you need to engineer your product, engineer your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=416" target="_blank">00:06:56.200</a></span> | <span class="t">team, engineer your, you know, mindset, so that when a new model comes out, if it changes everything for you, you can jump on that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=424" target="_blank">00:07:04.000</a></span> | <span class="t">opportunity, and ship something that maybe wasn't possible before. And I'm going to show you some numbers for a product feature that we're actually launching, and I'm going to show you a little bit of it today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=436" target="_blank">00:07:16.000</a></span> | <span class="t">But we've had an eval for a while that tells us how well this feature might work. And we run it every few months. And you can see, you know, it wasn't that long ago that GPT-4.0 was the best model out there. But things have changed. And, you know, progressively, GPT-4.1 did a little bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=457" target="_blank">00:07:37.000</a></span> | <span class="t">GPT-3.0 is much better. And GPT-4.0 is much better. And GPT-4.0 is actually even more remarkably better. And what that's meant for us is that this feature that, you know, at 10% would really not be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=471" target="_blank">00:07:51.000</a></span> | <span class="t">viable for our users to use, suddenly becomes viable. And so, you know, GPT-4.0 actually came out two weeks ago. And we're shipping the first version of this feature today, which is just two weeks later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=483" target="_blank">00:08:03.000</a></span> | <span class="t">But we were able to jump on that opportunity, because we ran this eval, we were ready to do it. And we saw that, okay, great, we've actually finally crossed this threshold.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=493" target="_blank">00:08:13.000</a></span> | <span class="t">So everyone that I personally work with or talk to, I encourage to create evals that are very, very ambitious, and likely not viable with today's models, and construct them in a way that when a new model comes out, you can just plug the new model in and try it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=511" target="_blank">00:08:31.000</a></span> | <span class="t">In Braintrust, we have this tool called the Braintrust Proxy. There's a lot of similar tools, you could use ours, or you could use something else. But really, the point is that you don't need to change any code to work across model providers. And so, you know, Google just launched the newest version of Gemini.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=529" target="_blank">00:08:49.000</a></span> | <span class="t">Gemini, actually, Gemini 2.5 Pro.0520 scores 1% on this benchmark. So we didn't even put it on here. But maybe the thing they launched today actually does a lot better. We can find out, you know, with just a few keystrokes, maybe right after this talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=548" target="_blank">00:09:08.000</a></span> | <span class="t">And the last thing is, it's super important if you think about optimizing your prompts to optimize the entire system. So that means thinking holistically about your AI system as the data that you use for your evals,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=567" target="_blank">00:09:27.000</a></span> | <span class="t">the task, which is, you know, the prompt, the agentic system tools, etc., and the scoring functions. And every time you think about making, you know, your app better, you need to think about improving this overall system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=582" target="_blank">00:09:42.000</a></span> | <span class="t">We actually ran a benchmark, which is the same benchmark that I showed previously. It auto-optimizes prompts using an LLM. And we ran it once by just giving it the prompt and saying, like, hey, please optimize the prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=600" target="_blank">00:10:00.000</a></span> | <span class="t">And a second time giving it the prompt, the dataset, and the scores and said, please optimize this whole system. And you can see there's a very dramatic difference. So, again, something goes from unviable to viable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=612" target="_blank">00:10:12.000</a></span> | <span class="t">But it's just super important to optimize the entire system, not just the prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=619" target="_blank">00:10:19.000</a></span> | <span class="t">And actually, this is a new product feature that we are starting to launch today. If you're a Braintrust user, you can go to the feature flag section of Braintrust and turn on a new feature flag called Loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=634" target="_blank">00:10:34.000</a></span> | <span class="t">And Loop is this amazing, cool new feature that actually auto-optimizes your evals directly within Braintrust.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=644" target="_blank">00:10:44.000</a></span> | <span class="t">So, you can work in our playground and give it, you know, a prompt, a dataset, and some scores. And it can actually create prompts, datasets, and scores, too, and just, you know, work with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=658" target="_blank">00:10:58.000</a></span> | <span class="t">The kinds of things that we've seen work really well are optimize this prompt, or what am I missing from this dataset that would be really good to test for this use case?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=669" target="_blank">00:11:09.000</a></span> | <span class="t">Why is my score so low? Or why is my score so high? Can you please help me write a score that is, you know, harsher than the one that I have right now?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=679" target="_blank">00:11:19.000</a></span> | <span class="t">You can also try it out with different models. So, as you can see from this, we've definitely seen the best performance with Claude 4 Sonnet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=688" target="_blank">00:11:28.000</a></span> | <span class="t">And Claude 4 Opus performs a couple of percentage points better. But we encourage you to try it out with different models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=695" target="_blank">00:11:35.000</a></span> | <span class="t">You can use O3. You can use O4 Mini. You can use Gemini. Maybe you're building your own LLM or fine-tuned model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=702" target="_blank">00:11:42.000</a></span> | <span class="t">You can try that as well. And yeah, we're very excited for this. I think I'm going to talk about this a little bit later, and I'm happy to do it with some Q&A as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=712" target="_blank">00:11:52.000</a></span> | <span class="t">But I actually, I really think that the workflow around evals is going to dramatically change. Now that LLMs are capable of looking at prompts and looking at data and actually making, you know, constructive improvements automatically, a lot of the manual labor that went into iterating with evals,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=731" target="_blank">00:12:11.000</a></span> | <span class="t">doesn't need to be there anymore. So, it's really exciting. We're excited to ship this and start to get some feedback.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=741" target="_blank">00:12:21.000</a></span> | <span class="t">So, just to recap, five lessons that I think are really important. Effective evals speak for themselves. It's important to understand whether you've kind of reached a point of eval competence in your organization or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=753" target="_blank">00:12:33.000</a></span> | <span class="t">It's okay if you haven't. It's not easy. But it's important to be honest about that and work towards it. When you're working on evals, it's very important to engineer the entire system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=765" target="_blank">00:12:45.000</a></span> | <span class="t">So, don't just think about the prompt. Don't just think about improving the prompt. Please don't just use synthetic data or hugging face datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=773" target="_blank">00:12:53.000</a></span> | <span class="t">I know they're awesome, but please use more than just that. Please don't use off-the-shelf scores only. Write your own. Think very deliberately about how you can craft the spec of what you're working on into your scoring functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=787" target="_blank">00:13:07.000</a></span> | <span class="t">Think very carefully about context. And I think, in particular, what helps me personally is to think about writing tools like I would think about writing a prompt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=797" target="_blank">00:13:17.000</a></span> | <span class="t">It's my opportunity to communicate with an LLM and set it up for success. And how I define the API interface of the tool and I define its output has a very dramatic impact on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=810" target="_blank">00:13:30.000</a></span> | <span class="t">Make sure that you're ready for new models to come out and to just change everything. So, if a new model comes out, you want to be prepared to know that immediately, ideally the day that it comes out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=823" target="_blank">00:13:43.000</a></span> | <span class="t">and also be prepared to rip out everything and replace it with a fundamentally new architecture that takes advantage of that new model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=831" target="_blank">00:13:51.000</a></span> | <span class="t">And I think part of that is obviously having the right evals. Part of it is engineering your product in a way that actually allows you to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=839" target="_blank">00:13:59.000</a></span> | <span class="t">And then finally, when you think about optimizing or improving your eval performance, you have to think about optimizing the whole system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=848" target="_blank">00:14:08.000</a></span> | <span class="t">the data and how you get that data, the task itself, which, you know, the prompt tools, et cetera, and the scoring functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=859" target="_blank">00:14:19.000</a></span> | <span class="t">And with that, we have some time for Q&A.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=862" target="_blank">00:14:22.000</a></span> | <span class="t">Yeah, there's two microphones up here, one on the left side, one on the right side. Feel free to stand up and ask your questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=871" target="_blank">00:14:31.000</a></span> | <span class="t">Hi, this is Jyoti. One of your slides said take feedback and turn it into an eval. Are you concerned about overfitting evals at that point where every feedback then turns into an eval?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=889" target="_blank">00:14:49.000</a></span> | <span class="t">Oh, that's a great question. Also, nice to see you. So the question was, one of the slides was about taking feedback from, you know, real data and adding it to a dataset and incorporating it in an eval. Are you worried about overfitting?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=905" target="_blank">00:15:05.000</a></span> | <span class="t">And I think the answer is, I'm actually way more worried about overfitting to the dataset without the user's feedback than I am to adjusting the fit to incorporate the user's feedback.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=917" target="_blank">00:15:17.000</a></span> | <span class="t">Like, the most important thing about a dataset is not the state of the dataset at any point in time. It is how well you are equipped to reconcile the dataset with the reality that you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=929" target="_blank">00:15:29.000</a></span> | <span class="t">And I actually think one of the things that we discourage in the product, and some people complain to us about this. I get it if you're one of those people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=937" target="_blank">00:15:37.000</a></span> | <span class="t">But we don't automatically take user feedback and add it to datasets right now. We actually want a human who has some taste and maybe can build some intuition about the problem to find the data points from users that are interesting and add them to the dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=954" target="_blank">00:15:54.000</a></span> | <span class="t">And I think that is your opportunity as a user to apply some judgment about, like, oh, okay, this user is trying to do something that should obviously work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=962" target="_blank">00:16:02.000</a></span> | <span class="t">It's really sad that it doesn't work in my product. Let me add it to the dataset so I can make sure it does. Excuse me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=969" target="_blank">00:16:09.000</a></span> | <span class="t">You had a slide, I think, in the tool descriptions about, like, with some percentages on it. Yeah, this one. What is that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=977" target="_blank">00:16:17.000</a></span> | <span class="t">Yeah, so we took a few agents. Like, we, you know, have a lot of traces. And we analyzed the relative number of tokens for different message types.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=990" target="_blank">00:16:30.000</a></span> | <span class="t">So the system prompt is one message type. Tool definitions are, you know, the spec of what tools the model can call. User and assistant are tokens from user and assistant, just text interactions. And then tool responses are tokens from the, you know, the tool generates itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1012" target="_blank">00:16:52.000</a></span> | <span class="t">Oh, and this is the percentage of tokens?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1014" target="_blank">00:16:54.000</a></span> | <span class="t">Correct. And this is the relative percentage of those tokens. Yeah. Yeah. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1019" target="_blank">00:16:59.000</a></span> | <span class="t">Yeah, so the point that we're trying to make here is that I think in modern agentic systems, tools actually, like, very, very significantly dominate the token budget of the LLM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1033" target="_blank">00:17:13.000</a></span> | <span class="t">And I think that it's very important to think about how you define the definition of tools and how you define their outputs, so that you, you know, engineer the LLM for success, not just sort of take, you know, your GraphQL API and give it as a bunch of, you know, tool calls to the LLM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1052" target="_blank">00:17:32.000</a></span> | <span class="t">First off, that point about the thumbs down is such a good point. I'm working with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1059" target="_blank">00:17:39.720</a></span> | <span class="t">government and people don't like the answer they got, for example, about taxes and they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1065" target="_blank">00:17:45.160</a></span> | <span class="t">give it a thumbs down. Yeah. Right. So like adding that human aspect is a really good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1070" target="_blank">00:17:50.180</a></span> | <span class="t">idea. We actually even added a little thing that said, "The answer is right, but I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1074" target="_blank">00:17:54.680</a></span> | <span class="t">don't like it." That's awesome. But my question is about your point that the new model changes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1081" target="_blank">00:18:01.520</a></span> | <span class="t">everything. We've updated our models several times and use Cloud and OpenAI, and we haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1089" target="_blank">00:18:09.320</a></span> | <span class="t">found huge differences other than recently someone really cheap wanted to use 4.1 mini,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1096" target="_blank">00:18:16.540</a></span> | <span class="t">and like it seemed to ignore every... I swear it ignored the system problem completely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1103" target="_blank">00:18:23.000</a></span> | <span class="t">Yeah. But what kind of things, when you say it changes everything, can you tell me a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1107" target="_blank">00:18:27.320</a></span> | <span class="t">more about what kind of changes you're seeing? For sure. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1111" target="_blank">00:18:31.040</a></span> | <span class="t">the use case that we just shipped with Loop is a really good example of that. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1115" target="_blank">00:18:35.040</a></span> | <span class="t">is a very ambitious agent. It's looking at prompts and data sets and scores and automatically optimizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1123" target="_blank">00:18:43.640</a></span> | <span class="t">the prompts based on the data sets and scores. And this is something that, you know, we wrote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1129" target="_blank">00:18:49.260</a></span> | <span class="t">a benchmark for a while ago, and we ran with every consecutive model launch, and the numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1135" target="_blank">00:18:55.560</a></span> | <span class="t">looked more like what you see for GPT 4.0 for a very long time. This isn't true for every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1140" target="_blank">00:19:00.560</a></span> | <span class="t">benchmark. So as part of this exercise, we actually have a bunch of evals that Loop optimizes. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1148" target="_blank">00:19:08.040</a></span> | <span class="t">our eval set. And there's some evals like classifying, taking movie quotes and figuring out what movie</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1154" target="_blank">00:19:14.840</a></span> | <span class="t">they're coming from that have worked really well since GPT 3.5. And so there's certain use cases</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1160" target="_blank">00:19:20.840</a></span> | <span class="t">where it just doesn't matter. There are other use cases where they're so ambitious that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1165" target="_blank">00:19:25.960</a></span> | <span class="t">just don't work today. And I think you want to create evals so that if there's something ambitious</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1171" target="_blank">00:19:31.320</a></span> | <span class="t">that you want to do in the future, you are very well prepared when a new model comes out to just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1175" target="_blank">00:19:35.880</a></span> | <span class="t">push a button and find that out. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=a4BV0gGmXgA&t=1180" target="_blank">00:19:40.840</a></span> | <span class="t">We'll see you next time.</span></div></div></body></html>