<html><head><title>[Paper Club] Intro to Diffusion Models and OpenAI sCM: Simple, Stable, Scalable Consistency Models</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>[Paper Club] Intro to Diffusion Models and OpenAI sCM: Simple, Stable, Scalable Consistency Models</h2><a href="https://www.youtube.com/watch?v=epwgOz8mZMw"><img src="https://i.ytimg.com/vi/epwgOz8mZMw/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./epwgOz8mZMw.html">Whisper Transcript</a> | <a href="./transcript_epwgOz8mZMw.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">It should just record to my account so that I can upload it to YouTube.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=6" target="_blank">00:00:06.000</a></span> | <span class="t">Is done. I did it. Okay, great. Oops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=11" target="_blank">00:00:11.000</a></span> | <span class="t">All right, great. So, we're off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=14" target="_blank">00:00:14.000</a></span> | <span class="t">So, Hi everybody I'm RJ.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=19" target="_blank">00:00:19.000</a></span> | <span class="t">And we're going to talk about this paper, I hope people had a chance to at least pick through it I know this is one of the hardest papers I've read in a long time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=32" target="_blank">00:00:32.000</a></span> | <span class="t">So I understand if you didn't understand everything that's going on I certainly didn't, and I had to dig through a bunch of other papers to have the context also to understand it so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=43" target="_blank">00:00:43.000</a></span> | <span class="t">And then there's a lot of proofs that are like take too long to read and are not as important understanding the paper so like there's a lot, a lot there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=52" target="_blank">00:00:52.000</a></span> | <span class="t">But without so without further ado, this, this SCM, there's a simple stable and scalable and they actually just this authors do a great job of actually going through all three of those things in the paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=68" target="_blank">00:01:08.000</a></span> | <span class="t">There's a consistency model, we'll talk about what that means in a little bit, but that's them and then, like, why are they doing this well because these continuous time consistency models show promise, but they're, but, but they're hard to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=86" target="_blank">00:01:26.000</a></span> | <span class="t">and hard to scale. So the paper kind of present some techniques for getting over those challenges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=94" target="_blank">00:01:34.000</a></span> | <span class="t">So I'm going to, you know, as in, so we're talking about in the beginning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=101" target="_blank">00:01:41.000</a></span> | <span class="t">There's, I think it is good to have just a recap of diffusion in general and this is more complex version of diffusion but I thought a lot of people have seen this diagram so it'd be useful to talk about what we're talking about here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=117" target="_blank">00:01:57.000</a></span> | <span class="t">And in, in reference to, you know, sort of stable diffusion and latent diffusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=124" target="_blank">00:02:04.000</a></span> | <span class="t">So, the, the, you know, sort of the left space is the, the variational auto encoder and that lifts the pixels into latent space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=136" target="_blank">00:02:16.000</a></span> | <span class="t">And so we're not going to talk about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=140" target="_blank">00:02:20.000</a></span> | <span class="t">And then the right hand side is the conditioning for on images and text so that's how you actually prompt the model, instead of just standing generating random images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=150" target="_blank">00:02:30.000</a></span> | <span class="t">And so we're also not going to really talk about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=153" target="_blank">00:02:33.000</a></span> | <span class="t">But suffice these mechanisms are, um, they, they, they're compatible with the existing technologies, or these things, so you can just view it kind of as a drop in replacement for the screen part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=170" target="_blank">00:02:50.000</a></span> | <span class="t">And actually keep this diagram in mind, the unit in the sort of in the middle the big part in the middle with the attention blocks there are is is basically identical even.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=183" target="_blank">00:03:03.000</a></span> | <span class="t">So, a lot of a lot of this diagram is the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=187" target="_blank">00:03:07.000</a></span> | <span class="t">It's really about the training process and, you know, some tweaks to make the, the main network work well with that training process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=198" target="_blank">00:03:18.000</a></span> | <span class="t">And, and, you know, specifically, with, with the regular diffusion models that we all know and love. They have to iterate multiple times generally to generate a good image, whereas the, these consistency models are designed so they can generate a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=220" target="_blank">00:03:40.000</a></span> | <span class="t">image with only one pass through the network and there's a mechanism by which you can iterate to refine if you want to but that you. The idea is that you don't need to even even one shot through the network is enough to get a really good image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=236" target="_blank">00:03:56.000</a></span> | <span class="t">I tried to put all the links that I took images and other things from, so I'll share this and everyone can everyone can click on those if they want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=250" target="_blank">00:04:10.000</a></span> | <span class="t">So, please, and also please, if you guys have questions I know they go in the chat. I'm not watching the chat so let me know if you want to interrupt and ask a question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=261" target="_blank">00:04:21.000</a></span> | <span class="t">So, you know, this is just regular diffusion, and the idea is quite simple you're just adding step by step, some amount of noise, and there's this is actually scheduled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=275" target="_blank">00:04:35.000</a></span> | <span class="t">This that is not actually, it's, um, it, you know, like it's not adding a constant amount of noise at a time, it does work that way and so the top images like that they found in this paper that it's actually inefficient that you end up with a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=294" target="_blank">00:04:54.000</a></span> | <span class="t">of wasted away wasted backwards process backwards diffusion steps that you don't need, and you can cut out a whole bunch of it just by using a cosine schedule.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=306" target="_blank">00:05:06.000</a></span> | <span class="t">So the intensity of the noise is modulated by this cosine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=311" target="_blank">00:05:11.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=313" target="_blank">00:05:13.000</a></span> | <span class="t">And then I think this is where it gets interesting the reverse diffusion process and I actually learned a little bit about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=322" target="_blank">00:05:22.000</a></span> | <span class="t">During when I was studying this, because my impression was that the, you know, you sort of like crank in the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=331" target="_blank">00:05:31.000</a></span> | <span class="t">And it just sort of like progressively refines and refines and refines but that's not actually quite what's happening. And this, this diagram here kind of shows this, and so I want to, we're gonna have to look at the next one to really understand what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=347" target="_blank">00:05:47.000</a></span> | <span class="t">going on here, maybe fully but the, the. If you look on the right, maybe starting on the right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=354" target="_blank">00:05:54.000</a></span> | <span class="t">You see that like the predicted noise every step is actually like you can't really make any sense of it right it's all just noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=362" target="_blank">00:06:02.000</a></span> | <span class="t">And then the middle column, you have like slightly more, more and more refined picture and then on the left you have this like sort of full noise removed column.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=378" target="_blank">00:06:18.000</a></span> | <span class="t">And the weird thing is that like if I look at, for example, on the T equals 40 row.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=388" target="_blank">00:06:28.000</a></span> | <span class="t">And then I look at the T was 30 the full noise removed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=393" target="_blank">00:06:33.000</a></span> | <span class="t">That doesn't look like, like the one in the full noise remove column looks a lot more refined than the one in the input at T.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=401" target="_blank">00:06:41.000</a></span> | <span class="t">Right. And so like in the 30, you would expect 30, the output at 30 would be more than, like, nicer than the input at 40, and it's actually not the case and the reason is because that's not exactly what's happening right it's not the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=415" target="_blank">00:06:55.000</a></span> | <span class="t">goes into the input, but rather the, the input is only being used to improve the noise estimate that's in the right hand column.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=426" target="_blank">00:07:06.000</a></span> | <span class="t">So, so that noise estimate is is added to the noise in the, like, from the, like sort of generated noise is added the right hand column is added to that generated noise to get the left hand column.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=446" target="_blank">00:07:26.000</a></span> | <span class="t">So in the in the middle column is only input to the model in order to refine how to generate that is that I hope that I want that thought to make sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=457" target="_blank">00:07:37.000</a></span> | <span class="t">And I'll switch this page but if anyone wants to ask a question that now would be a good time, because I think, and I try to illuminate a little bit what's happening here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=470" target="_blank">00:07:50.000</a></span> | <span class="t">But I want to. Okay, so I'll if please interrupt if you want to ask about this. It's good so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=476" target="_blank">00:07:56.000</a></span> | <span class="t">Okay, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=477" target="_blank">00:07:57.000</a></span> | <span class="t">Um, so, uh, so now what's happening. And this is sort of like a bad illustration of the same concept, but in a different way, so that if you look on the T equals 10 right hand column that's like just random noise that was generated as input into the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=498" target="_blank">00:08:18.000</a></span> | <span class="t">And then on the right hand column.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=501" target="_blank">00:08:21.000</a></span> | <span class="t">You have denoised versions of that noise. And so, if you look at like, let's look at the bottom t equals eight. Right, so time goes kind of backwards here so left and left hand is t equals zero right hand is t equals 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=517" target="_blank">00:08:37.000</a></span> | <span class="t">And then t equals eight is two to the left of equals 10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=521" target="_blank">00:08:41.000</a></span> | <span class="t">And, and so then because the backwards diffusion process goes backwards in time. So, that t equals eight, what's happening here is that, that the, the, the lot the thing at the top of the line is actually the input to the model it goes through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=539" target="_blank">00:08:59.000</a></span> | <span class="t">That, that thing with the attention block, and then it outputs something to add to t equals 10. And then when you add those two things together you get the thing it equals zero down at the very left, lower left.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=552" target="_blank">00:09:12.000</a></span> | <span class="t">Right, so then, as time goes on, we get to t five, and we have a better estimate of that noise because we've gone through several steps, and then we add that to the t equals 10, and we get that airplane.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=567" target="_blank">00:09:27.000</a></span> | <span class="t">It's kind of blurry to the, in the top, top left and then he was three and then finally we get to something that's really close to the original data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=576" target="_blank">00:09:36.000</a></span> | <span class="t">So, so I'm making this distinction because it's very different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=582" target="_blank">00:09:42.000</a></span> | <span class="t">This is clear because it's different than this is sort of the motivation for how to understand what's happening with these trajectories in the paper is that you can see that these, these are separate trajectories and I've intentionally drawn that it's not just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=597" target="_blank">00:09:57.000</a></span> | <span class="t">like me being inaccurate. I've intentionally drawn it that way because the, the locations that you're learning are not basically on the same trajectory in the, in this latent space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=611" target="_blank">00:10:11.000</a></span> | <span class="t">They're, they're not in the same trajectory, as, as each other, right so that like in this causes a lot of inefficiency and that's sort of the whole point to this, these consistency models and other flow matching and other things that uses technique is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=632" target="_blank">00:10:32.000</a></span> | <span class="t">is to sort of like be more efficient about the places you're sampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=637" target="_blank">00:10:37.000</a></span> | <span class="t">And you're saying that you're saying that the trajectories are not the same, like T equals eight, T equals five, T equals three, they're not the same trajectories on each other, in the sense that with T equals three, you could not have gotten what you have gotten at T equals five.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=650" target="_blank">00:10:50.000</a></span> | <span class="t">That, that's right, that's right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=652" target="_blank">00:10:52.000</a></span> | <span class="t">No, don't restart your computer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=657" target="_blank">00:10:57.000</a></span> | <span class="t">Okay, I understand that intuition. Thank you. And why is that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=662" target="_blank">00:11:02.000</a></span> | <span class="t">I, so I, this is slightly vague in my mind but basically because the, you know, all that the like the.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=672" target="_blank">00:11:12.000</a></span> | <span class="t">Maybe I've drawn them like further than they might be in reality right they'll probably be pretty close but the point is that when they're, when the input to the model is like the T equals 10 and the T equals eight noise at the top.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=689" target="_blank">00:11:29.000</a></span> | <span class="t">Right. And that doesn't necessarily like, and I'm just trying to generate something that I can add to T equals 10 to do a little better than that equals a one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=701" target="_blank">00:11:41.000</a></span> | <span class="t">Right, so I'm trying to like, I'm trying to, I didn't draw this, the lines on the score but I'm trying to generate this thing. And so there's nothing constraining it in the latent space to be on that same trajectory so it doesn't necessarily pick something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=715" target="_blank">00:11:55.000</a></span> | <span class="t">Okay, so each trajectory at T8, T5, T3, they each try to optimize as much as they can and therefore they arrive at the different, that's the intuition, thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=725" target="_blank">00:12:05.000</a></span> | <span class="t">Yeah, they're always, always like this T equals three is just trying to get this, this like little fuzzy airplane noise back, or something like that, not actually not the fuzzy airplane, sorry, I misspoke.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=738" target="_blank">00:12:18.000</a></span> | <span class="t">Just some noise that produces something like that corresponds to that fuzzy airplane thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=745" target="_blank">00:12:25.000</a></span> | <span class="t">That, does that make sense?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=749" target="_blank">00:12:29.000</a></span> | <span class="t">A little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=750" target="_blank">00:12:30.000</a></span> | <span class="t">Yes, yes it does. Thank you. Okay, great. Okay, so okay so this fancy plot is sort of the alternative that I just alluded to. And we're not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=761" target="_blank">00:12:41.000</a></span> | <span class="t">These, these stochastic differential equations, we're not going to really talk about this and this is like a thing that you don't really need to understand so I just got it from this diagram so you can just kind of ignore the SDE part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=777" target="_blank">00:12:57.000</a></span> | <span class="t">It looks almost the same, it's slightly different, doesn't really matter but it's actually a cool diagram because you can see this, there's these stochastic differential equations that are like sort of modeling this random process by which, you know, sort of, you have, you have noise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=796" target="_blank">00:13:16.000</a></span> | <span class="t">and it has a continuous instead of a discrete.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=802" target="_blank">00:13:22.000</a></span> | <span class="t">It's a continuous instead of a discrete process so like adding noise to like on your left hand side, very very left is the data and these, these two, like normal looking distribution so there's like bimodal normal distribution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=816" target="_blank">00:13:36.000</a></span> | <span class="t">And then, and then what this differential, so this is sort of like heat, heat diffusion right and as time like time is going to the right and as, as the, you know, sort of like heat that is kind of sort of condensed in those two the modes of these two Gaussians</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=838" target="_blank">00:13:58.000</a></span> | <span class="t">like over time it kind of spreads out and, and ends up, you know, sort of like in the middle with this prior here, and that's not exactly what would happen because it's not quite this, it's not the heat equation but like it's a useful intuition for what's happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=853" target="_blank">00:14:13.000</a></span> | <span class="t">here. So that like, there's some differential equation and it's describing this, like sort of diffusion process by which everything ends up in this sort of like literally Gaussian prior for the distribution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=867" target="_blank">00:14:27.000</a></span> | <span class="t">And so this is where we generate our noise. And then we use the backwards process to get back to these, you know, these distributions, these bimodal distribution, and there's like a each one of these squiggly lines is a trajectory from that some random process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=890" target="_blank">00:14:50.000</a></span> | <span class="t">could have taken based on the sort of based on sort of likelihood that is imposed on the field by the, by the diffusion process it in the colored diffusion process in the background.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=907" target="_blank">00:15:07.000</a></span> | <span class="t">Right. So, and then, and then this probability flow ODE is sort of a deterministic version that looks at what is the maximum likelihood path.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=923" target="_blank">00:15:23.000</a></span> | <span class="t">If I started at that trajectory. Right. So in this, so like looking at what's the easiest one to see is this bottom white one. So if you look, what this is saying is I started here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=934" target="_blank">00:15:34.000</a></span> | <span class="t">What is the maximum likelihood path for me to get to somewhere in the, in this middle area. Right, so, so instead of like Sam, so you can imagine if I sampled like a huge number of these SDS.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=949" target="_blank">00:15:49.000</a></span> | <span class="t">And then I took the each one of these columns I took the, you know, sort of the means, then I would get. If I started here I would sort of follow this path right to get to this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=964" target="_blank">00:16:04.000</a></span> | <span class="t">And I'm not speaking super accurately but that's sort of the intuition. So, um, and. Okay, so, and I, this looks quite different from what this previous diagram but it's actually the same kind of space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=979" target="_blank">00:16:19.000</a></span> | <span class="t">So I want to, and that's, so I want to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=982" target="_blank">00:16:22.000</a></span> | <span class="t">So, in, in this diagram you would have like, like, you know, maybe a chunk right here, which is, you know, like I did a, like a discrete Gaussian blurring of my data and then I did another one and another one and another one's is discrete and so what happened,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1001" target="_blank">00:16:41.000</a></span> | <span class="t">this is what happens if you just make the number of those discrete, discrete Gaussian blurrings infinite and infinitely small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1013" target="_blank">00:16:53.000</a></span> | <span class="t">Okay, so and then the other thing, just to look at this is a score function, we don't have to really understand it right now and or not too much ever in this talk but the score function is more or less.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1028" target="_blank">00:17:08.000</a></span> | <span class="t">This is sort of how the, this is the mathematical mechanism by which the, the reverse diffusion can happen, and inside of this score function is our unit model right so our unit is there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1046" target="_blank">00:17:26.000</a></span> | <span class="t">And, and so I'm using that unit to predict what's called the marginal distribution on that probability at for that data, and then that's what helps it to sort of figure out how to do this process in reverse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1063" target="_blank">00:17:43.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1065" target="_blank">00:17:45.000</a></span> | <span class="t">I know this is not super clear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1068" target="_blank">00:17:48.000</a></span> | <span class="t">Hopefully it will become slightly more clear. And then just to be clear, this is like a unit, this is a, I don't think it really matters but this is like the name of the particular unit model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1079" target="_blank">00:17:59.000</a></span> | <span class="t">And then I, this is sort of what I just said it estimates a gradient of the log probability density with respect to data at a given time step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1088" target="_blank">00:18:08.000</a></span> | <span class="t">And, but most importantly, that's where your unit lives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1093" target="_blank">00:18:13.000</a></span> | <span class="t">This, this is just this works in latent space too so this is like all the other stuff that is in that in that first diagram that's all here in the left hand side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1107" target="_blank">00:18:27.000</a></span> | <span class="t">Okay, good. So now let's talk about consistency model so you can see this, this looks a lot like this, but it's slightly different right, same author so not surprising, but, um, so this is sort of the left hand side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1120" target="_blank">00:18:40.000</a></span> | <span class="t">Right. And then we got rid of all the squiggly SD stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1125" target="_blank">00:18:45.000</a></span> | <span class="t">So, uh, so what's happening here and this is this goes back to the discussion about trajectories these are trajectories so you start, you know, in the forward direction you start at one of these green dots and then you follow this trajectory and you end up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1139" target="_blank">00:18:59.000</a></span> | <span class="t">somewhere in this noise distribution here so that like this, like structured data turns into a Gaussian distribution. And what our diff. So we have a, then we have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1156" target="_blank">00:19:16.000</a></span> | <span class="t">particle function, ordinary differential equation I think it's particle it could be probability function, I think it's probability, and it, and it sort of is a, is a differential equation that can map from a given point here, back to a given point here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1173" target="_blank">00:19:33.000</a></span> | <span class="t">So then we can do that because since it's deterministic, then there's exactly one for any one place here there's exactly one place here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1182" target="_blank">00:19:42.000</a></span> | <span class="t">Right. So, and so once it because you have that, what a consistency model does is it says that everything should be on the same trajectory. Right, so I'm going to, if I estimate it, I can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1195" target="_blank">00:19:55.000</a></span> | <span class="t">I'm going to learn how to map from any point on this trajectory to the to this point in the data so including these very left hand things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1207" target="_blank">00:20:07.000</a></span> | <span class="t">And you'll see that it's useful to be able to map to the middle in a minute, but, but the point is that the differential equation solver tries to find the parameters of the differential equation, such that if I know this, then I know this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1225" target="_blank">00:20:25.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1226" target="_blank">00:20:26.000</a></span> | <span class="t">And the link. If you want to learn about that, that's the sort of some, the first link about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1233" target="_blank">00:20:33.000</a></span> | <span class="t">And then, so just to tie it. I want to just tie this back to this is the same information even the same paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1240" target="_blank">00:20:40.000</a></span> | <span class="t">But I just want to tie it back to our, you know, sort of noising and denoising idea is that we're, you know, sort of like mapping this so this is one trajectory in this case it's straight but like this is one of those curvy trajectories from the previous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1255" target="_blank">00:20:55.000</a></span> | <span class="t">diagram, and it's mapping back to this data, this image at x zero this is the data that this particular noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1268" target="_blank">00:21:08.000</a></span> | <span class="t">Best corresponds to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1270" target="_blank">00:21:10.000</a></span> | <span class="t">Right. So, um, and, and, you know, so the idea is just that I'm mapping all the way from any point on that trajectory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1280" target="_blank">00:21:20.000</a></span> | <span class="t">And this is why it's useful to useful to be able to map from any point in the trajectory is that now I can, if I want to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1291" target="_blank">00:21:31.000</a></span> | <span class="t">And most of the time it's two times but if I want to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1297" target="_blank">00:21:37.000</a></span> | <span class="t">If I want to do like refine my image by throwing more compute at the problem what I can do is I can, I can add some this, you know, sort of these these time steps, I can divide my space up into time steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1315" target="_blank">00:21:55.000</a></span> | <span class="t">I can, I can sample noise I can re add it to the trajectory at that timestamp and then I can refine based on that noise and that seems to help the model sort of zone honing on the like just having another opportunity to refine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1338" target="_blank">00:22:18.000</a></span> | <span class="t">I can put it on a slightly different trajectory and help the model to learn from a closer space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1344" target="_blank">00:22:24.000</a></span> | <span class="t">What the original data was so like for example, let's go back here, you know, I might, you know, step one I started t I have this noise I go all the way to x zero, but then I add it back enough noise to get back to this step here, and then I follow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1360" target="_blank">00:22:40.000</a></span> | <span class="t">where that lands man so I will be like slightly off this trajectory. So maybe this is a better model like you think multiple trajectories maybe I end up on a different trajectory and that's not what this diagram is for but I'm end up in a different trajectory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1373" target="_blank">00:22:53.000</a></span> | <span class="t">so that my, my data is slightly different, the data that I'm that that I'm outputting is slightly different. So I want to just any questions in the comments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1386" target="_blank">00:23:06.000</a></span> | <span class="t">I keep just plowing ahead or do people want to come in or ask questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1392" target="_blank">00:23:12.000</a></span> | <span class="t">I'm not seeing any questions in the comments. Okay, yeah, what are some good open source models I don't know if you're a chime in on that RJ.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1400" target="_blank">00:23:20.000</a></span> | <span class="t">Yeah, um, especially if they can generate images with good text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1406" target="_blank">00:23:26.000</a></span> | <span class="t">I, I, well I, I'm actually not the best person to answer that I think that, like the xl three and flux, but those are not this type of model I don't think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1422" target="_blank">00:23:42.000</a></span> | <span class="t">Perfect. That's what Alexander suggested as well. And then you would add your own text Laura's.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1427" target="_blank">00:23:47.000</a></span> | <span class="t">Yeah, exactly flux flux is, is great for text as well as the 3.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1434" target="_blank">00:23:54.000</a></span> | <span class="t">Yeah. Additionally, you can always add some Laura's.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1438" target="_blank">00:23:58.000</a></span> | <span class="t">There's plenty of Laura sensitivity for making better text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1445" target="_blank">00:24:05.000</a></span> | <span class="t">I can do this right now actually I have a copy why open so if anyone wants to test I can just throw and from the text and generate some images quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1458" target="_blank">00:24:18.000</a></span> | <span class="t">Awesome. So, so like, but I think there's like maybe this is actually a good slightly good talking point so these, these types of models are not like these consistency models and there's like related models there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1470" target="_blank">00:24:30.000</a></span> | <span class="t">So, I, with the exception of maybe some of the closed sourced models from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1476" target="_blank">00:24:36.000</a></span> | <span class="t">I think that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1478" target="_blank">00:24:38.000</a></span> | <span class="t">Well, a lot of this. These papers come from open AI so I suspect they're maybe using some of these techniques, maybe. So, but, and I haven't really looked at the sort of big models that are out there to see if any of them are using any of these techniques but like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1495" target="_blank">00:24:55.000</a></span> | <span class="t">these this is pretty cutting edge research so none of this technology that we're discussing today is in any of really in any of the big models that we know and love, with, maybe, maybe with the exception of flux.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1512" target="_blank">00:25:12.000</a></span> | <span class="t">I don't, but that's actually a great question I'm going to look, look into that as soon as this is over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1520" target="_blank">00:25:20.000</a></span> | <span class="t">Okay, so let's, let's keep going in. So this is now so this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1526" target="_blank">00:25:26.000</a></span> | <span class="t">These od solvers, they kind of their discrete time solvers so they they sort of chunk up the time into little chunks and then they.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1536" target="_blank">00:25:36.000</a></span> | <span class="t">And then they solve the od as best they can, given the discretization the quantization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1542" target="_blank">00:25:42.000</a></span> | <span class="t">But that can cause errors. And so that's what this diagram is trying to present is if you have like this, if this delta t here is very big you see it goes like far from x t x minus delta t, then the error that it can have is very big and that can put it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1561" target="_blank">00:26:01.000</a></span> | <span class="t">on a different trajectory, so you get the wrong trajectory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1566" target="_blank">00:26:06.000</a></span> | <span class="t">And then, if the discretization is maybe a bit smaller than the error might be a little bit smaller, and then you'll get a closer but not the same trajectory, and that's sort of the point and then like in continuous time in theory, then because your discretization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1584" target="_blank">00:26:24.000</a></span> | <span class="t">is infinitely small, then you, you, you, it's like, quote unquote, impossible to get on the wrong trajectory, although there are still obviously ways that you can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1597" target="_blank">00:26:37.000</a></span> | <span class="t">But that's the theory anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1600" target="_blank">00:26:40.000</a></span> | <span class="t">So in this, I was a little scratching my head a little bit I didn't see the od solver. Sorry, the continuous models don't use an od solver, they do actually in the paper reference using od solvers in certain steps but they're not essential to the process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1619" target="_blank">00:26:59.000</a></span> | <span class="t">here is, I think the point that they're making.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1623" target="_blank">00:27:03.000</a></span> | <span class="t">And this unbiased estimator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1626" target="_blank">00:27:06.000</a></span> | <span class="t">They don't give any information on how to do this so I think that what they just mean is an empirical estimation of the marginal distribution but they think they left that as an exercise the reader, or somewhere in the appendix that I didn't see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1640" target="_blank">00:27:20.000</a></span> | <span class="t">Okay, so I'm going to get very mathy for a minute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1644" target="_blank">00:27:24.000</a></span> | <span class="t">I know, I like I understand that, like, first of all, even, you know, the math geniuses among us might have trouble following because there's just too little context and unless you really read the paper carefully you're not gonna.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1660" target="_blank">00:27:40.000</a></span> | <span class="t">So, you're not going to be able to follow super well but so I want to just call it a few things. And then there's like these two one and two equations one and two are going to reference a little bit to explain how they accomplish what they did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1674" target="_blank">00:27:54.000</a></span> | <span class="t">And, and also these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1676" target="_blank">00:27:56.000</a></span> | <span class="t">There's this, this is sort of this canonical equation that everybody has been using and when I say everybody I think I mean, mostly the same author in previous papers but also some other people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1688" target="_blank">00:28:08.000</a></span> | <span class="t">And so that like the this, this is sort of like the canonical setup and then there's this these constraints that are on the the C skip and the C out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1698" target="_blank">00:28:18.000</a></span> | <span class="t">And the interesting thing to note, and the important reason those are there is it. So if this is the time variable, the C out and C skip and if time is zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1709" target="_blank">00:28:29.000</a></span> | <span class="t">That means that you're just you have the data right and and see out, you have none of the input from your, from your, from your neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1722" target="_blank">00:28:42.000</a></span> | <span class="t">Right, so this is just saying, at time zero. This is a way to guarantee that at time zero, you're getting back your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1730" target="_blank">00:28:50.000</a></span> | <span class="t">And then the skip and see out they just trade off in some way between each other and as time goes gets later, and you have more than you, you are giving more weight to the, to the neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1748" target="_blank">00:29:08.000</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1749" target="_blank">00:29:09.000</a></span> | <span class="t">And then, so then, and then this is just, I don't think we need to go through this in any detail. This is just the training objective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1757" target="_blank">00:29:17.000</a></span> | <span class="t">And then if you look at this equation two is just that, you know, sort of instantiated with this certain kind of distance function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1771" target="_blank">00:29:31.000</a></span> | <span class="t">So you'll see a distance function appears here, this, you know, L2 loss is being used, which is just squared error loss that's being used.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1785" target="_blank">00:29:45.000</a></span> | <span class="t">And then you, you know, sort of plug everything in, you, you know, you sort of take the limit as t goes to zero, or delta t goes to zero and you get this thing out and there's a proof of it elsewhere.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1798" target="_blank">00:29:58.000</a></span> | <span class="t">And this, this tangent function is kind of the main actor here. So, like, you don't really have to care again, what this is just if you see this thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1812" target="_blank">00:30:12.000</a></span> | <span class="t">Or if you see like this delta maybe then think tangent function, mostly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1819" target="_blank">00:30:19.000</a></span> | <span class="t">Okay, so I know that this is like probably like pretty opaque, it's, I would be surprised if it wasn't unless you read the paper carefully.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1828" target="_blank">00:30:28.000</a></span> | <span class="t">And then, so then they. So, um, you know, again reminding you this, this is great, but it has a problem and then it's unstable and and hard to understand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1841" target="_blank">00:30:41.000</a></span> | <span class="t">So, what they did was they took this is just a repeat of what we saw there's nothing different here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1848" target="_blank">00:30:48.000</a></span> | <span class="t">Just previously, so they took and they, this is like the old way of doing things where you have the, this is for, you know, for these discrete, mostly being used for discrete but also for continuous and they have these, you know, sort of, they did some derivations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1863" target="_blank">00:31:03.000</a></span> | <span class="t">and got these values for C skip and for C out and for C in, and, and then they have all these stability problems, and so they came up with this other idea and we'll motivate this a little bit in a minute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1880" target="_blank">00:31:20.000</a></span> | <span class="t">They use cosine and sine, and this one over sigma d for the, for the C skip C out and C in, and then when you plug that in, then you end up with this instead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1894" target="_blank">00:31:34.000</a></span> | <span class="t">Right. So that nothing, nothing magical happened here I'm just plugging my CF, my F theta, I'm just plugging in these values and I get this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1906" target="_blank">00:31:46.000</a></span> | <span class="t">Okay, so now here's, this is the thing. And this is I, in my opinion, the meat of the paper. So, you have this, you have this part of the, you have this tangent function that I had called out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1921" target="_blank">00:32:01.000</a></span> | <span class="t">And this is like if you plug stuff in again into that tangent function there's nothing magical here I'm just plugging that cosine and sine and everything in there, and you get this big long thing here that's really hard to read.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1935" target="_blank">00:32:15.000</a></span> | <span class="t">And in the paper they talk about. Okay, this thing, if you look at just this thing, like the stability is instant, like, this is not causing instability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1946" target="_blank">00:32:26.000</a></span> | <span class="t">This thing here is not causing stability oh this part, like this sign times this, this expression is causing instability. So, let's look there. Okay, so then they'd say okay look when I like this part is also not causing instability it's this, this part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1963" target="_blank">00:32:43.000</a></span> | <span class="t">So we have the sign with a differential F.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1968" target="_blank">00:32:48.000</a></span> | <span class="t">And then, so I take that, and, and, and so now we're going to address all the sources of instability in these three, or not necessarily these three classes but in these this expression.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1981" target="_blank">00:33:01.000</a></span> | <span class="t">Right, so let's go through piece by piece and decide and figure out what is causing all of the instability you'll notice this is the chain rule.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=1994" target="_blank">00:33:14.000</a></span> | <span class="t">I hope you guys are following I'm trying to keep it very as understandable as possible. So, any questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2004" target="_blank">00:33:24.000</a></span> | <span class="t">No, I was able to follow the last slide. Thank you for breaking it up and reminding us of chain rule. Yeah, I think I'm going to get started getting lost here but you're doing a great job.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2014" target="_blank">00:33:34.000</a></span> | <span class="t">Okay, good. So, this, and then the noise. Um, this, this was just from the previous paper papers again, um, I, they just, you know, sort of give it to you and say go read the paper if you want to know, and they, so they have this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2029" target="_blank">00:33:49.000</a></span> | <span class="t">C noise which you'll recall appears here, right, the C noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2036" target="_blank">00:33:56.000</a></span> | <span class="t">And, and this is basically just a way to a coefficient function that can, like, alter the time, like the rate at which time changes basically, and they are saying this actually causes a lot of this like definitely will cause stability at equals two because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2056" target="_blank">00:34:16.000</a></span> | <span class="t">it's zero and so therefore this goes to infinity. So, definitely can't have that so they just say let's just set it to T, and they don't really motivate this except for this is just makes time asking to cut a constant rate, which makes, I think, intuitive sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2072" target="_blank">00:34:32.000</a></span> | <span class="t">Okay, and then. So now, so that's like this C noise from this page.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2078" target="_blank">00:34:38.000</a></span> | <span class="t">The, this, it appears here it appears here, here's here. Right. And then. Okay, so now what about this embedding thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2088" target="_blank">00:34:48.000</a></span> | <span class="t">So what they say is, this is sort of basically, you know, similar to the fourier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2095" target="_blank">00:34:55.000</a></span> | <span class="t">This is a fourier embedding similar to what you have, you know, in the, in the positional embeddings in transformers, and there's a reason for that because this is using the attention block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2108" target="_blank">00:35:08.000</a></span> | <span class="t">But what, so they point out that, you know, the, the scale that they had set here was 16 that's very high and it causes lots of instability including what right when you get to pi over two, it goes to infinity so that's obviously bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2127" target="_blank">00:35:27.000</a></span> | <span class="t">So they, they played with this and they, I think empirically determined that oh if we just make this really small to this value I don't know where they got point two but it just basically corresponds to the same positional embeddings that you see in the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2142" target="_blank">00:35:42.000</a></span> | <span class="t">in attention is all you need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2148" target="_blank">00:35:48.000</a></span> | <span class="t">Hopefully that's also not so hard I think they were very hand wavy so I don't think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2154" target="_blank">00:35:54.000</a></span> | <span class="t">So what they say is just set s to 0.02. Yeah, that's right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2160" target="_blank">00:36:00.000</a></span> | <span class="t">Man I wish I had the math to understand how they got to the intuition or maybe it's empirical but okay. I think, I think they.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2168" target="_blank">00:36:08.000</a></span> | <span class="t">Yeah, I think that basically what it scales, the coefficients to the same scale that the ones in attention out is all you need are at. I think that's, and I don't I don't think it's, I think it's all algebra to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2183" target="_blank">00:36:23.000</a></span> | <span class="t">If I understood if I recall and understood correctly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2188" target="_blank">00:36:28.000</a></span> | <span class="t">Thank you. Um, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2190" target="_blank">00:36:30.000</a></span> | <span class="t">And then this adaptive double normalization I don't think it's that important, they didn't really talk about this as a whole. This is everything they say about it here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2198" target="_blank">00:36:38.000</a></span> | <span class="t">But they basically they just say okay there's this adaptive normalization we think it works but it doesn't work in our case so we just do it twice, and seems to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2208" target="_blank">00:36:48.000</a></span> | <span class="t">So, I don't think we need to talk about it very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2212" target="_blank">00:36:52.000</a></span> | <span class="t">So you can see like there's a bunch of stuff they're stacking on top of each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2216" target="_blank">00:36:56.000</a></span> | <span class="t">Okay, and then there's this like tangent normalization they tried this and then they also tried just clipping to between one negative one and one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2225" target="_blank">00:37:05.000</a></span> | <span class="t">And they, they, they see like oh yeah like with our, with our models normalization has a lower FID score this is first fair fair shed inception distance it's a measure of quality of or closeness of perceptual closeness of images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2244" target="_blank">00:37:24.000</a></span> | <span class="t">So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2247" target="_blank">00:37:27.000</a></span> | <span class="t">and so you can see with either two steps or one step in our consistency model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2255" target="_blank">00:37:35.000</a></span> | <span class="t">Then we do better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2257" target="_blank">00:37:37.000</a></span> | <span class="t">You know, if we have normalization, and maybe if clipping is clipping might be good enough, because it's obviously cheaper than doing this normalization here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2270" target="_blank">00:37:50.000</a></span> | <span class="t">And then finally, they have this adaptive waiting, basically, I think all you need to understand is they throw this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2280" target="_blank">00:38:00.000</a></span> | <span class="t">weight term, they throw the weight value into the loss function. So this is a loss function for the optimizer when they're, you know, sort of doing the gradient descent, then they, they throw this weight term in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2296" target="_blank">00:38:16.000</a></span> | <span class="t">And that is comes from right somewhere right here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2302" target="_blank">00:38:22.000</a></span> | <span class="t">Right, so this is our gradient. Right. And this weight term isn't here so they just in, you know, when they derive the loss function they just throw in that weight term and that seems to help a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2316" target="_blank">00:38:36.000</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2318" target="_blank">00:38:38.000</a></span> | <span class="t">This yellow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2323" target="_blank">00:38:43.000</a></span> | <span class="t">Oh, no, actually, are they saying.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2327" target="_blank">00:38:47.000</a></span> | <span class="t">No, it looks like it's always it's better. In some cases, but as you go it looks like it's worse, or no, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2336" target="_blank">00:38:56.000</a></span> | <span class="t">If you have. Sorry, if you have. If you do two steps, then it's worse if you do one step it's slightly better so it doesn't look like it matters that much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2346" target="_blank">00:39:06.000</a></span> | <span class="t">And then tangent warm up I don't, again, probably don't need to understand that the sign T, they just put our in front of it and that are just literally increases from zero to one over the first 10k iterations, and they just do this because it's a it's instable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2360" target="_blank">00:39:20.000</a></span> | <span class="t">in the beginning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2362" target="_blank">00:39:22.000</a></span> | <span class="t">No need to discuss a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2365" target="_blank">00:39:25.000</a></span> | <span class="t">Okay, and so, like when you stack all of these things together, then you're able to train much more effectively and continuous time does much better than these discreet this so this n is the number of discrete steps that your model is taking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2385" target="_blank">00:39:45.000</a></span> | <span class="t">And, you know, maybe one interesting thing about this plot is that, you know, sort of the best you can do is at 1024 and then it gets worse. Right, so it goes, so like it's better from here to green and then green to purple gets way better and then it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2401" target="_blank">00:40:01.000</a></span> | <span class="t">gets worse again so like at some point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2405" target="_blank">00:40:05.000</a></span> | <span class="t">So, like it's the issues that they brought up, start to start to matter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2411" target="_blank">00:40:11.000</a></span> | <span class="t">Why is continuous so much better than screen, is it because it's just continuous and therefore it's easy to learn but I thought the continuous unstable as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2420" target="_blank">00:40:20.000</a></span> | <span class="t">No, all of these techniques that we just talked about in the last few slides are making continuous stable. So then they are able to train more effectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2434" target="_blank">00:40:34.000</a></span> | <span class="t">In previous, like in the previous attempts that actually other authors did, and they did people thought I think they found that they had to be very conservative in the, you know, sort of like the way that they train the model in order to avoid all the instabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2452" target="_blank">00:40:52.000</a></span> | <span class="t">And so because of that they were not able to get good results, whereas now they're able to sort of like this intuition that they right here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2461" target="_blank">00:41:01.000</a></span> | <span class="t">They like this quant, it's sort of like, because if I have only a few steps, you know this, the time delta is very big between these and I'm going to have a lot of error in my tangent calculation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2472" target="_blank">00:41:12.000</a></span> | <span class="t">Right, so this, this tangent is that tangent that we talked about. And if there's a error. Like if there's a big quantization here, or like only a few time steps then the ODE solver has to, you know, sort of has only a limited amount of data to work with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2490" target="_blank">00:41:30.000</a></span> | <span class="t">and it ends up making mistakes due to that discretization and so they ends up having big errors and you get on the wrong trajectory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2499" target="_blank">00:41:39.000</a></span> | <span class="t">Makes sense. That makes sense. Yeah, and we also have a question from the chat, what does the FID metric evaluate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2507" target="_blank">00:41:47.000</a></span> | <span class="t">Yeah, it's, that's a great question I had to look it up myself because I've seen it before and I forgot it completely it's.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2513" target="_blank">00:41:53.000</a></span> | <span class="t">Um, so it is just, it is like it is a numerical measure of the difference between two images, but in the reason why it's popular is because it seemed, it was explicitly designed to match the match closely to human perceptual difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2535" target="_blank">00:42:15.000</a></span> | <span class="t">So they, there's a paper that talks about it and one of the things that they talk about is and I think it's what's in the definitely a bibliography but I can dig it if, if, if anyone's interested.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2549" target="_blank">00:42:29.000</a></span> | <span class="t">It basically describes the, the, the previous methods that were being used which were just like, there was one of the divergence divergence measures are not measures divergences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2568" target="_blank">00:42:48.000</a></span> | <span class="t">It didn't match to what people visually what humans actually were visually using to distinguish between images, so that this one was designed to do a better job of that so it's, it's supposed to be like a human perceptual distance metric between the, the, the input, like an input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2593" target="_blank">00:43:13.000</a></span> | <span class="t">input image. So, I think that meaning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2602" target="_blank">00:43:22.000</a></span> | <span class="t">Actually, you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2604" target="_blank">00:43:24.000</a></span> | <span class="t">Yeah, I think there's a, there's like a, and I don't know exactly that's a, that's a great question. I don't know exactly how they do the experiment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2612" target="_blank">00:43:32.000</a></span> | <span class="t">I think that they go do a forward pass with the image, and then they add some noise, and then they do the backwards pass and they see the difference, difference between the images but I'm not 100% sure that is does anyone know this, how this works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2628" target="_blank">00:43:48.000</a></span> | <span class="t">Exactly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2632" target="_blank">00:43:52.000</a></span> | <span class="t">No. Okay, well, so yeah that's actually, that's something that I want to follow up on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2639" target="_blank">00:43:59.000</a></span> | <span class="t">Okay. And then I talked about a tangent warm up continuous versus discrete. Okay, so here's the part that everybody should be a little more comfortable with hopefully is just like we're evaluating models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2652" target="_blank">00:44:12.000</a></span> | <span class="t">The, you know, you have this NFC stands for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2658" target="_blank">00:44:18.000</a></span> | <span class="t">number of function evaluations so this is how many times did I did my sort of core. How many iterations that I have to do to generate my images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2670" target="_blank">00:44:30.000</a></span> | <span class="t">And so, um, and you see that they all their numbers in this section of the paper, they have they they compared to two evaluations in one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2681" target="_blank">00:44:41.000</a></span> | <span class="t">And they do slightly better. Whenever they do too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2686" target="_blank">00:44:46.000</a></span> | <span class="t">So, and then, so there's several things to note about this one thing that they said in the paper it's not here but that, that it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2695" target="_blank">00:44:55.000</a></span> | <span class="t">They it takes about two x to compute to train the this consistency model from as a, as a distillation of whatever they distilled from.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2709" target="_blank">00:45:09.000</a></span> | <span class="t">Approximately twice the compute. So, if you spend a lot of compute to train a model and then you want to distill it with this mechanism you're going to pay about twice as much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2719" target="_blank">00:45:19.000</a></span> | <span class="t">So there could be that could present an operational problem or it might not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2726" target="_blank">00:45:26.000</a></span> | <span class="t">Another thing to know these joint training sections these are basically GANs but like you'll see some of the more common GANs here, but, and I don't know exactly the difference between these guys but this CTM, like was the sort of overall winner for this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2744" target="_blank">00:45:44.000</a></span> | <span class="t">CIFAR data benchmark and then, and then, you know, for a conditional class image net 64 by 64, it's a different one but it's also in this joint training. So the GANs tend to be tend to be winning on these benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2763" target="_blank">00:46:03.000</a></span> | <span class="t">So my belief is that these are the reason why people don't use them is because they're hard to train and they're, they have their very, they have mode seeking behavior meaning it's hard to get any diversity and hard to control them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2776" target="_blank">00:46:16.000</a></span> | <span class="t">But for these benchmarks they do the best.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2780" target="_blank">00:46:20.000</a></span> | <span class="t">And you see it down here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2783" target="_blank">00:46:23.000</a></span> | <span class="t">So sort of their, you know, their consistency model is actually quite close for what it's worth. And then, so this is from distillation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2795" target="_blank">00:46:35.000</a></span> | <span class="t">And then this is if you train from scratch, and they do better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2799" target="_blank">00:46:39.000</a></span> | <span class="t">So that's maybe another interesting thing so the distillation doesn't work quite as well as the training from scratch does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2808" target="_blank">00:46:48.000</a></span> | <span class="t">This is a place where someone might want to like comment or ask questions so I want to pause and make sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2818" target="_blank">00:46:58.000</a></span> | <span class="t">Okay, so, and then, um, so they also compared this variational score distillation which is kind of in the same ballpark, in terms of effectiveness, and they found that they, they have, or VSD has higher precision and lower recall meaning lower diversity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2837" target="_blank">00:47:17.000</a></span> | <span class="t">And like as the guidance scale gets higher it does worse. And, you know, this, because if you'll notice the diffusion teacher model, and, and the, the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2857" target="_blank">00:47:37.000</a></span> | <span class="t">the models that they built are very close to each other and in these cases both for precision and recall so you end up having some very similar FI score as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2871" target="_blank">00:47:51.000</a></span> | <span class="t">And then like another interesting thing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2876" target="_blank">00:47:56.000</a></span> | <span class="t">So, a couple things so there, you know, their model does quite well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2885" target="_blank">00:48:05.000</a></span> | <span class="t">When it's trained and not distilled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2890" target="_blank">00:48:10.000</a></span> | <span class="t">So, or sorry. Let's see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2896" target="_blank">00:48:16.000</a></span> | <span class="t">The distillation doesn't do quite as well as the training and, but neither of them do as well as the diffusion teacher, including the one that was trained from scratch, and that like you'll see also interestingly once.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2912" target="_blank">00:48:32.000</a></span> | <span class="t">So the two step does actually the two step trained model does worse with, you know, sort of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2926" target="_blank">00:48:46.000</a></span> | <span class="t">in the smaller models but better in the bigger models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2931" target="_blank">00:48:51.000</a></span> | <span class="t">Okay, and then this is sort of like their scaling study we're kind of out of time so I won't talk too much but like, yeah, you can see they they did well they have up to 1.5 be model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2945" target="_blank">00:49:05.000</a></span> | <span class="t">Let's see the. Yeah, that's sort of the main takeaway Okay yeah so that's, that's all I have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2953" target="_blank">00:49:13.000</a></span> | <span class="t">I can take any questions if people want to stick around for a few minutes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2964" target="_blank">00:49:24.000</a></span> | <span class="t">I know this is not at all an easy paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2972" target="_blank">00:49:32.000</a></span> | <span class="t">I think it's one of the hardest papers. Yeah, I think the other one was probably PPO or PPO.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2980" target="_blank">00:49:40.000</a></span> | <span class="t">I missed that paper so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2983" target="_blank">00:49:43.000</a></span> | <span class="t">Yeah, I mean to me this, this was challenging for several reasons right like one is just the topic, like diffusion by itself is hard and then you have this like really obscure diffusion that is like even more complicated and you have to understand a little bit about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=2998" target="_blank">00:49:58.000</a></span> | <span class="t">differential equations and whatever. And then on top of that there's just a ton of literature to read in order to read the paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3005" target="_blank">00:50:05.000</a></span> | <span class="t">So all those things like kind of, it's like a triple whammy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3013" target="_blank">00:50:13.000</a></span> | <span class="t">But I must say, I really really enjoyed learning by reading, like because you know I dug into all these papers which I normally don't have time to do but I, you know, because I'm presenting I took the time to really look at all the references and try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3027" target="_blank">00:50:27.000</a></span> | <span class="t">to understand things well enough to hopefully explain them right to other people. And that was super valuable experience and I'm glad I did that on such a hard paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3040" target="_blank">00:50:40.000</a></span> | <span class="t">I feel like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3043" target="_blank">00:50:43.000</a></span> | <span class="t">you guys felt that you got some of the intuition behind this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3051" target="_blank">00:50:51.000</a></span> | <span class="t">I know it's not easy I tried to focus on the intuitions for the paper, and not so much on the math.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3063" target="_blank">00:51:03.000</a></span> | <span class="t">So, let me stop sharing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3068" target="_blank">00:51:08.000</a></span> | <span class="t">Great guys, if there's nothing else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3072" target="_blank">00:51:12.000</a></span> | <span class="t">You know I thoroughly enjoyed doing this I hope, hope somebody new will will.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3082" target="_blank">00:51:22.000</a></span> | <span class="t">Someone who's never presented before will will take take up the mantle for the next session or the next open session will be awesome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3091" target="_blank">00:51:31.000</a></span> | <span class="t">If anyone has any paper that they want to cover so it's great to for you to voice out and say, because we always welcome new, new paper presenters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3100" target="_blank">00:51:40.000</a></span> | <span class="t">Yeah, I think we, I think we had a volunteer for next week but it's on the loom I don't remember which one it was, but people was signing someone up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3109" target="_blank">00:51:49.000</a></span> | <span class="t">Awesome. Yay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3111" target="_blank">00:51:51.000</a></span> | <span class="t">More need more more still needed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3116" target="_blank">00:51:56.000</a></span> | <span class="t">Okay guys, well enjoy your Wednesday then I will.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3121" target="_blank">00:52:01.000</a></span> | <span class="t">I'll see you guys on discord.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3124" target="_blank">00:52:04.000</a></span> | <span class="t">Thank you very much once again for presenting my pleasure. Yeah, you're welcome.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=epwgOz8mZMw&t=3130" target="_blank">00:52:10.000</a></span> | <span class="t">Bye bye.</span></div></div></body></html>