<html><head><title>Multi model multimodal and multi agent innovations in Azure AI: Cedric Vidal</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Multi model multimodal and multi agent innovations in Azure AI: Cedric Vidal</h2><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ"><img src="https://i.ytimg.com/vi_webp/YcOrV-TLNyQ/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./YcOrV-TLNyQ.html">Whisper Transcript</a> | <a href="./transcript_YcOrV-TLNyQ.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">So, I'm CÃ©dric Vidal. I'm a Principal AI Advocate at Microsoft. And today, we're going to do quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=24" target="_blank">00:00:24.000</a></span> | <span class="t">cool stuff. We're going to talk about many things. Multi-models, multi-modality, multi-lingual,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=33" target="_blank">00:00:33.440</a></span> | <span class="t">multi-agents, all of this with Azure AI. So, yeah. And also, one particularity is apart from a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=41" target="_blank">00:00:41.520</a></span> | <span class="t">slides at the beginning, it's only demos. And to be honest, bear with me in case one of them or all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=48" target="_blank">00:00:48.960</a></span> | <span class="t">of them don't work. But it's going to be fun. We'll see how it goes. So, as you know, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=58" target="_blank">00:00:58.560</a></span> | <span class="t">Azure AI is the best AI platform out there. We have a lot of AI services. We can do machine learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=68" target="_blank">00:01:08.480</a></span> | <span class="t">And we also do all of that responsibly with the whole Responsible AI framework. And we encapsulate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=77" target="_blank">00:01:17.360</a></span> | <span class="t">all of this in the Azure AI Studio. And I'm going to do a lot of demos of Azure AI Studio today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=85" target="_blank">00:01:25.760</a></span> | <span class="t">And since now almost a year, a bit more than a year, we've been partnering with OpenAI, of course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=96" target="_blank">00:01:36.160</a></span> | <span class="t">And we have all of the OpenAI models available on Azure platform. But we're going to see that in addition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=104" target="_blank">00:01:44.880</a></span> | <span class="t">to all the OpenAI models that we have and all the modalities that we can get using those,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=109" target="_blank">00:01:49.840</a></span> | <span class="t">we also have many more models available on the platform for text, of course, vision and speech.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=121" target="_blank">00:02:01.760</a></span> | <span class="t">And many organizations trust us today to use AI and build their products.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=128" target="_blank">00:02:08.480</a></span> | <span class="t">So without further ado, so I'm going to jump in the demos very quickly. But before I do,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=138" target="_blank">00:02:18.480</a></span> | <span class="t">so we've had many things announced at Build a couple of months ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=143" target="_blank">00:02:23.440</a></span> | <span class="t">We've had the GA version of Azure AI Studio. We've had the latest model from OpenAI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=150" target="_blank">00:02:30.560</a></span> | <span class="t">GPT for Omni, which supports text, vision and soon speech. We've had the new smaller language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=161" target="_blank">00:02:41.120</a></span> | <span class="t">from Microsoft for my master search called Fi3. Now, we have also announced GPT-4 Turbo Vision,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=168" target="_blank">00:02:48.640</a></span> | <span class="t">daily three and Whisper. We've announced the Assistant API that allows to build agents. And I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=178" target="_blank">00:02:58.880</a></span> | <span class="t">demo it. We've announced fine tuning for GPT-4, the new inference batch API. And also, another very cool thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=190" target="_blank">00:03:10.400</a></span> | <span class="t">I'm going to demo it today. And you had a glimpse of it. I mean, I guess the surprise is kind of out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=196" target="_blank">00:03:16.400</a></span> | <span class="t">But the video translation service that I'm going to demo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=200" target="_blank">00:03:20.000</a></span> | <span class="t">And Azure AI Studio. Oh, yeah. So, let's go straight to the demos now. So, apart from those slides,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=209" target="_blank">00:03:29.680</a></span> | <span class="t">now it's only demos. So, the fun begins. Okay. The first demo. So, we've had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=219" target="_blank">00:03:39.680</a></span> | <span class="t">A year ago, when everything started, you didn't have many choices. It was basically GPT or GPT. The only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=232" target="_blank">00:03:52.240</a></span> | <span class="t">modality available was text. But now things have changed dramatically. Now, we support also multimodal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=240" target="_blank">00:04:00.160</a></span> | <span class="t">vision, mixing text and vision. And this opens a completely new era of use cases. For example, here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=247" target="_blank">00:04:07.840</a></span> | <span class="t">here. And let me zoom. So, I'm going to demo GPT-4.0. And actually, I selected vision here. But what I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=257" target="_blank">00:04:17.280</a></span> | <span class="t">wanted to select was GPT-4.0. And I'm going to demonstrate a use case where -- so, it is kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=265" target="_blank">00:04:25.840</a></span> | <span class="t">small right now. But this is a menu from a restaurant. And I'm going to ask what's began on the menu today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=275" target="_blank">00:04:35.360</a></span> | <span class="t">Okay. So, here, we can see the menu a bit better. So, as you can see, we have winter, chicory salad,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=285" target="_blank">00:04:45.600</a></span> | <span class="t">duck, sea bass, et cetera. And what's very interesting here is that the menu that you just saw was -- the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=296" target="_blank">00:04:56.320</a></span> | <span class="t">the font is funny, but it's printed. So, it's a font from a computer. And GPT-4.0 does a very good job at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=305" target="_blank">00:05:05.360</a></span> | <span class="t">reading what's on the menu. And let me zoom here so that we can see what's -- so, I asked whether there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=313" target="_blank">00:05:13.120</a></span> | <span class="t">were vegan options today on the menu. And what's interesting is that it looks -- it mixes vision. So, it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=320" target="_blank">00:05:20.480</a></span> | <span class="t">extracted all the text from the image. But not only that, but it resounds on it. So, it analyzed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=327" target="_blank">00:05:27.600</a></span> | <span class="t">all the items on the menu today. And for each one of them, looked at which ones were vegan. And as you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=333" target="_blank">00:05:33.760</a></span> | <span class="t">can see here, the cauliflower soup and winter chicory salad. Let me zoom up. Okay. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=346" target="_blank">00:05:46.880</a></span> | <span class="t">okay. Both mentioned vegetarian and vegan versions. So, that's a very good example of how to mix text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=358" target="_blank">00:05:58.880</a></span> | <span class="t">text and rezoning. Something that was not possible before with just OCRs, which becomes available with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=365" target="_blank">00:06:05.840</a></span> | <span class="t">the new generation of multimodal models. Another example, slightly harder, because this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=375" target="_blank">00:06:15.040</a></span> | <span class="t">has handwritten text. So, this menu has not been printed. It has been written by hand on a chalkboard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=387" target="_blank">00:06:27.840</a></span> | <span class="t">So, as you can see -- oh, and it's in French. So, not only does it recognize handwritten sentences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=406" target="_blank">00:06:46.000</a></span> | <span class="t">written on a chalkboard in a picture, but it also translates it and resounds on it. So, that's three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=415" target="_blank">00:06:55.840</a></span> | <span class="t">things that the model is doing all at once. Thanks to multimodality. This is very important to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=422" target="_blank">00:07:02.800</a></span> | <span class="t">understand how it differs from what we were doing before. Because before, we were using image to text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=429" target="_blank">00:07:09.440</a></span> | <span class="t">to extract the text and then reason on it. Now, the model understands natively both pixels and text. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=439" target="_blank">00:07:19.920</a></span> | <span class="t">it's internal representation has the same vectors for the same concepts, visual concepts and textual concepts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=450" target="_blank">00:07:30.160</a></span> | <span class="t">That's a very important thing to understand. And as you can see here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=460" target="_blank">00:07:40.800</a></span> | <span class="t">it displays, it displays the answer. I mean, I asked what's on the menu today. So, it's displaying the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=467" target="_blank">00:07:47.760</a></span> | <span class="t">entries of the menu in French with the English translation, because I asked the question in French.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=475" target="_blank">00:07:55.520</a></span> | <span class="t">And I could also -- oh, yeah. I asked -- okay, that's funny. Because I asked what's good on the menu today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=484" target="_blank">00:08:04.800</a></span> | <span class="t">And so, the choice of what's good would depend on your personal taste preferences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=491" target="_blank">00:08:11.760</a></span> | <span class="t">And the menu offers a variety of traditional French dishes that could cater anyway today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=497" target="_blank">00:08:17.760</a></span> | <span class="t">So, yeah. So, let's move on now to the next demo. So, we looked at, you know, something that you might want to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=507" target="_blank">00:08:27.760</a></span> | <span class="t">on the food at the restaurant when you are in a foreign country and you don't understand what's in the menu.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=512" target="_blank">00:08:32.240</a></span> | <span class="t">And you want to get a better understanding if you have a special diet. So, that's very convenient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=519" target="_blank">00:08:39.600</a></span> | <span class="t">But that technology can also be used for more serious challenges or use cases. So, in this case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=530" target="_blank">00:08:50.320</a></span> | <span class="t">we're going to look -- and that's actually an actual use case from a discussion I had a couple of weeks ago</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=537" target="_blank">00:08:57.600</a></span> | <span class="t">with a customer working in the energy industry. And so, here we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=544" target="_blank">00:09:04.080</a></span> | <span class="t">a picture of electric poles that fell on the ground. And I can ask a very open question. What's going on here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=556" target="_blank">00:09:16.160</a></span> | <span class="t">What's going on here? By the way, you can see how fast the model replies, which is quite something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=566" target="_blank">00:09:26.080</a></span> | <span class="t">So, not only is GPT 4.0 understanding both images and text, but it's also much faster at answering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=577" target="_blank">00:09:37.200</a></span> | <span class="t">So, as you can see here, the image shows several power lines and utility poles that have fallen or are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=582" target="_blank">00:09:42.800</a></span> | <span class="t">leaning indicating damage to the infrastructure. I'm not going to read everything. But what matters here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=588" target="_blank">00:09:48.400</a></span> | <span class="t">is if I was working in the energy transport industry, I might want to observe continuously all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=597" target="_blank">00:09:57.040</a></span> | <span class="t">infrastructure of all the networks, like for a whole country, at the edge to make sure that the network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=606" target="_blank">00:10:06.000</a></span> | <span class="t">is operational. So, I might want to automate looking at all the video cameras of filming the infrastructure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=614" target="_blank">00:10:14.960</a></span> | <span class="t">So, I could ask, is the electricity working here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=628" target="_blank">00:10:28.080</a></span> | <span class="t">It is highly unlikely that the electricity is working in the area shown in the image. Of course, here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=634" target="_blank">00:10:34.240</a></span> | <span class="t">I ask the question in natural language, and the answer is presented to me in natural language too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=640" target="_blank">00:10:40.240</a></span> | <span class="t">But I could also ask for the output to be generated in JSON in a format that could be interpreted by code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=648" target="_blank">00:10:48.800</a></span> | <span class="t">so that I could automate dashboards and monitoring of infrastructure in real time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=655" target="_blank">00:10:55.040</a></span> | <span class="t">Another use case is for the insurance industry. So, here we have a house that we can ask, "What happened?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=673" target="_blank">00:11:13.280</a></span> | <span class="t">The image shows a house that has collapsed and is severely tilted. Natural disasters such as hurricanes, earthquakes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=684" target="_blank">00:11:24.640</a></span> | <span class="t">or landslides. So, yeah, that's also a very interesting use case for the insurance industry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=696" target="_blank">00:11:36.000</a></span> | <span class="t">Next. So, the next one is not going to be a surprise because there was a spoiler. So, we talked about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=704" target="_blank">00:11:44.240</a></span> | <span class="t">multimodal models, but now we're going to talk about another modality, speech. The Azure AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=714" target="_blank">00:11:54.480</a></span> | <span class="t">team, product team, has released an amazing new feature which allows you to translate videos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=724" target="_blank">00:12:04.480</a></span> | <span class="t">So, here, I'm going to play that video. So, disclaimer, that's me on the video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=729" target="_blank">00:12:09.680</a></span> | <span class="t">This is our new video translation service. With this, I can translate videos into other languages in my own voice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=740" target="_blank">00:12:20.640</a></span> | <span class="t">Now, I can speak German as I always wanted. I would like to know how to speak Spanish, but now I can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=747" target="_blank">00:12:27.440</a></span> | <span class="t">speak it without having learned the language. I can even speak in Italian.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=752" target="_blank">00:12:32.320</a></span> | <span class="t">This will make the world more inclusive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=758" target="_blank">00:12:38.240</a></span> | <span class="t">So, what's really impressive about that video is not only the fact that now I can speak German,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=766" target="_blank">00:12:46.480</a></span> | <span class="t">but it took into consideration the intonation of what I was saying. So, when I was whispering,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=776" target="_blank">00:12:56.080</a></span> | <span class="t">it was whispering, too. When I was yelling, it was yelling, too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=779" target="_blank">00:12:59.680</a></span> | <span class="t">So, it takes into account the language and the tone. A disclaimer, I stitched the different videos</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=789" target="_blank">00:13:09.760</a></span> | <span class="t">together myself using post-processing, but apart from that, I didn't do anything. The service did that all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=796" target="_blank">00:13:16.800</a></span> | <span class="t">by itself. Now, yes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=801" target="_blank">00:13:21.520</a></span> | <span class="t">So, as I understand, these are made of models, but did these exist as inventing models as well?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=807" target="_blank">00:13:27.520</a></span> | <span class="t">Okay. I'm going to talk about how many models in a minute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=811" target="_blank">00:13:31.120</a></span> | <span class="t">So, where was I? Model catalog. And thank you. That's a good segue, actually. So, like I was saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=824" target="_blank">00:13:44.400</a></span> | <span class="t">like a year ago, when JGPT was released, basically, you had almost no choice. Now, the amount of models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=833" target="_blank">00:13:53.760</a></span> | <span class="t">available on the Azure AI model catalog is extraordinary. So, here, I'm going to remove</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=842" target="_blank">00:14:02.240</a></span> | <span class="t">that filter here so that we display all of them. So, as you can see here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=848" target="_blank">00:14:08.560</a></span> | <span class="t">we have 1,600 models available in the model catalog right now. And what I like, there is one specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=860" target="_blank">00:14:20.320</a></span> | <span class="t">feature that I really like is deployment options here. You can select serverless API. So, you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=866" target="_blank">00:14:26.960</a></span> | <span class="t">two ways to deploy models on Azure AI at the moment. You can deploy them serverless or you can deploy them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=876" target="_blank">00:14:36.800</a></span> | <span class="t">using your infrastructure. Bring your own infrastructure means basically that you rent for GPUs, that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=884" target="_blank">00:14:44.720</a></span> | <span class="t">pay for GPUs, whether you use the endpoint or not. Serverless means that you pay for the token and that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=892" target="_blank">00:14:52.800</a></span> | <span class="t">infrastructure is managed for you by the vendor. And paying by the token is nothing new. You've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=899" target="_blank">00:14:59.440</a></span> | <span class="t">doing that with OpenAI GPT ever since it was released. But now you can do it for many vendors on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=907" target="_blank">00:15:07.440</a></span> | <span class="t">marketplace. And as you can see here, those are all the vendors and all the models that are available on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=913" target="_blank">00:15:13.040</a></span> | <span class="t">catalog right now. Serverless. So, you pay by the token and you have nothing to manage yourself. Not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=921" target="_blank">00:15:21.120</a></span> | <span class="t">to mention the fact that getting GPUs right now is not the easiest. So, being able to use those models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=927" target="_blank">00:15:27.680</a></span> | <span class="t">serverless is it makes it much easier. And because we have so many models now, it's kind of hard to know which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=937" target="_blank">00:15:37.440</a></span> | <span class="t">one to use. So, now we also have the model benchmarks where we compare not all but we compare many of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=944" target="_blank">00:15:44.640</a></span> | <span class="t">models that are available in the catalog. And you can look at the accuracy as well as a bunch of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=950" target="_blank">00:15:50.880</a></span> | <span class="t">metrics to figure out which model you want to use for your use case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=958" target="_blank">00:15:58.000</a></span> | <span class="t">One. Okay. Let's hope that the Wi-Fi is not dead. Okay. One of those models that I want to focus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=968" target="_blank">00:16:08.080</a></span> | <span class="t">on today because we talked about GPT 4.0, which is a very big model, able to do text and visual analysis. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=978" target="_blank">00:16:18.240</a></span> | <span class="t">Microsoft Research also came up with our own text and visual multimodal model called 53 Vision 128K.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=990" target="_blank">00:16:30.240</a></span> | <span class="t">This model is very, very interesting. It's a family of model. We have a vision version. We have many sizes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=998" target="_blank">00:16:38.560</a></span> | <span class="t">So, that one specifically is very interesting because I'm going to upload one of the use case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1006" target="_blank">00:16:46.880</a></span> | <span class="t">for example, randomly, the same use case as the one I talked about before with GPT 4.0. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1014" target="_blank">00:16:54.480</a></span> | <span class="t">is electricity working here? And so, what's really interesting here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1029" target="_blank">00:17:09.120</a></span> | <span class="t">is that the model, despite being much smaller, and the explanation is a bit simpler, but still,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1043" target="_blank">00:17:23.200</a></span> | <span class="t">53 Vision is able to analyze the image and give a very good answer about the fact that the electricity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1049" target="_blank">00:17:29.840</a></span> | <span class="t">most likely is not working here because of an outage or disruption. So, now you have the possibility in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1059" target="_blank">00:17:39.360</a></span> | <span class="t">addition to GPT 4.0 to use 53 Vision for that. And not only can you use 53 Vision as a service</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1071" target="_blank">00:17:51.920</a></span> | <span class="t">3.8 billion. So, here we have a model size on Azure AI. We also have in the 53 family, a very, very small model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1078" target="_blank">00:17:58.000</a></span> | <span class="t">of 3.8 billion parameters, which weights under roughly 2 gigabytes. And here, if I refresh the window here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1090" target="_blank">00:18:10.400</a></span> | <span class="t">and I hope I didn't make a mistake. No, it's okay. So, model size 2 gigabytes. And here, 53, 3.8 gigabytes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1101" target="_blank">00:18:21.520</a></span> | <span class="t">53, 4.0, is quanticized with 4 bits, is downloading in the browser and running locally on the edge using web GPU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1111" target="_blank">00:18:31.040</a></span> | <span class="t">which is a new HTML5 specification allowing applications and browser to get access to the GPU. And so, here, I can ask,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1121" target="_blank">00:18:41.280</a></span> | <span class="t">what do you know about the Rivian R2? And you know, this is going to be a segue to one of the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1132" target="_blank">00:18:52.080</a></span> | <span class="t">subjects I'm going to be talking about after.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1141" target="_blank">00:19:01.440</a></span> | <span class="t">And so, as you can see, you get an answer generated in the browser, I mean, look at how fast it is for a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1151" target="_blank">00:19:11.200</a></span> | <span class="t">model running locally. So, okay, I have a Mac, which has an Apple Silicon and some kind of GPU support,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1160" target="_blank">00:19:20.160</a></span> | <span class="t">but it's by no mean horsepower machine. It's a MacBook Pro M2, I believe. And as you can see,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1169" target="_blank">00:19:29.200</a></span> | <span class="t">it's running very, very well in the browser. That means that I can disconnect the Wi-Fi. So, I'm not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1175" target="_blank">00:19:35.040</a></span> | <span class="t">going to do it now, but you could disconnect the Wi-Fi and it would still run locally. It's, um, which is also very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1181" target="_blank">00:19:41.600</a></span> | <span class="t">interesting for, um, um, uh, you know, uh, to process, uh, sensitive data. Next thing, chat. So, here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1194" target="_blank">00:19:54.160</a></span> | <span class="t">well, if I ask the question, uh, what are the, uh, different Rivian models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1208" target="_blank">00:20:08.800</a></span> | <span class="t">So, I'm asking GPT-4 Turbo, um, which was last updated in April, 2023. It knows about the Rivian R1T, the R1S.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1218" target="_blank">00:20:18.320</a></span> | <span class="t">Also, uh, Amazon's, um, Rivian truck. And that's all. Now, I can select an index to do RAG,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1233" target="_blank">00:20:33.360</a></span> | <span class="t">retrieval augmented generation where I can ground the, my model into my own documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1241" target="_blank">00:20:41.840</a></span> | <span class="t">And I'm not going to show that now, but what I did, uh, before to prepare the demo, I just took</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1248" target="_blank">00:20:48.480</a></span> | <span class="t">a bunch of Wikipedia pages of Rivian models that I uploaded to the index. Um, and now I am querying. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1256" target="_blank">00:20:56.880</a></span> | <span class="t">if I ask again, the same question, what are the different Rivian models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1272" target="_blank">00:21:12.400</a></span> | <span class="t">Huh? Is it bugging? That's a problem with live demos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1283" target="_blank">00:21:23.040</a></span> | <span class="t">Uh, let me clear. I'm going to copy that. I'm going to copy, clear and rerun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1293" target="_blank">00:21:33.040</a></span> | <span class="t">Okay. I'm going to refresh.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1306" target="_blank">00:21:46.320</a></span> | <span class="t">Okay. I have the index still selected. Now I should be able to, huh? Um, um, is it the model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1315" target="_blank">00:21:55.040</a></span> | <span class="t">Let's try with 3.5 Turbo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1318" target="_blank">00:21:58.080</a></span> | <span class="t">Yeah. So now, uh, so apparently we have a, a bug with the other model, but, uh, with 3.5 Turbo,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1328" target="_blank">00:22:08.880</a></span> | <span class="t">it works. And here you can see that we have the R1T, the R1S, the newly released R3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1334" target="_blank">00:22:14.960</a></span> | <span class="t">and we should have, it doesn't mention the R2, but, um, um, but it does mention the R3. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1343" target="_blank">00:22:23.840</a></span> | <span class="t">so if I ask what about the R2?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1346" target="_blank">00:22:26.640</a></span> | <span class="t">Yeah. So it does know about it. Um, so this is very interesting because it allows us to use an LLM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1358" target="_blank">00:22:38.000</a></span> | <span class="t">on up-to-date, uh, information. Now let's move on to the next demo. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1365" target="_blank">00:22:45.280</a></span> | <span class="t">so I'm going to skip that one, but what I can show here is one thing which is very important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1374" target="_blank">00:22:54.720</a></span> | <span class="t">is evaluation of models. Because when you build a LLM, uh, application, you want to be able to evaluate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1380" target="_blank">00:23:00.400</a></span> | <span class="t">how good they are. And when you make modifications to the system prompt or you change your models on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1385" target="_blank">00:23:05.280</a></span> | <span class="t">your application, you want to make sure that it continues to work as expected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1388" target="_blank">00:23:08.480</a></span> | <span class="t">So inside Azure AI Studio, you have a feature called evaluation, which allows you to run, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1395" target="_blank">00:23:15.840</a></span> | <span class="t">a bunch of metrics. Here I show coherence, groundedness, and relevance. Groundedness is something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1401" target="_blank">00:23:21.440</a></span> | <span class="t">that is very important for RAG applications because you want to make sure that the answer is grounded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1406" target="_blank">00:23:26.640</a></span> | <span class="t">into the documents. So this system allows you to do that moderately, uh, easily. And as you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1414" target="_blank">00:23:34.720</a></span> | <span class="t">here, so I use a very simple dataset that I prepared for the demo. So I have only one entry in my, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1420" target="_blank">00:23:40.960</a></span> | <span class="t">evaluation dataset, but still it shows, um, that for that question, which is what are the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1428" target="_blank">00:23:48.160</a></span> | <span class="t">revision models? The coherence was four. It was well grounded because it's evaluated between one and five.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1434" target="_blank">00:23:54.320</a></span> | <span class="t">Next, something very cool that I absolutely want to show you before we run out of time. So here, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1443" target="_blank">00:24:03.840</a></span> | <span class="t">this is one example of how to build an agent with code interpreter. Last Sunday, and that's real data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1451" target="_blank">00:24:11.920</a></span> | <span class="t">from last Sunday, I went kite surfing, uh, in the bear, in the bay. And I did a pretty good session that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1459" target="_blank">00:24:19.920</a></span> | <span class="t">recording using my watch and I exported the GPX file from, uh, my session from my watch. And now I can ask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1469" target="_blank">00:24:29.440</a></span> | <span class="t">question, which I uploaded the file to code interpreter. And now I can ask question about it. So I can say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1475" target="_blank">00:24:35.920</a></span> | <span class="t">Hey, how long was I on the water?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1481" target="_blank">00:24:41.920</a></span> | <span class="t">And so here the LLM is going to automatically generate path on code and execute it in a sandbox</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1493" target="_blank">00:24:53.600</a></span> | <span class="t">to analyze the file that I uploaded, which is a GPX XML file. So it's not a CSV. Usually when you see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1502" target="_blank">00:25:02.240</a></span> | <span class="t">those demos, they use CSVs, right? But here I'm using an XML file, which is more complicated. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1509" target="_blank">00:25:09.440</a></span> | <span class="t">and you're going to see that it should work. Yeah. 42 minutes. That's roughly how much time I was on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1516" target="_blank">00:25:16.960</a></span> | <span class="t">the water. And now I can ask how many turns, how many tacks did I do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1524" target="_blank">00:25:24.240</a></span> | <span class="t">So attack in, uh, sailing is basically a turn. Um, and here, this is a much harder question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1535" target="_blank">00:25:35.280</a></span> | <span class="t">because asking how many tacks I did requires not only analyzing the GPS coordinates, but also analyzing the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1542" target="_blank">00:25:42.320</a></span> | <span class="t">the, uh, angular differentiation, difference between each point and applying a threshold to decide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1550" target="_blank">00:25:50.080</a></span> | <span class="t">which of the points on the path are actually terms. And as you can see here, it replies with 217.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1559" target="_blank">00:25:59.440</a></span> | <span class="t">And now we can ask, can you draw my session</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1564" target="_blank">00:26:04.240</a></span> | <span class="t">on a map?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1571" target="_blank">00:26:11.920</a></span> | <span class="t">Because I want to see visually what it looks like. Right. It's more fun. Um, so why generally,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1579" target="_blank">00:26:19.040</a></span> | <span class="t">what's very interesting here is that I have no expertise in GPX. Like, I don't know the file format.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1584" target="_blank">00:26:24.480</a></span> | <span class="t">I could, uh, like, if I show you what it looks like, it's pretty, um, uh, you know, technical and, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1591" target="_blank">00:26:31.760</a></span> | <span class="t">it's pretty hard to parse. So here without any explanation of what the file format is, code interpreter figured</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1600" target="_blank">00:26:40.560</a></span> | <span class="t">that I would buy itself. And here, here's the map that it drew. And I'm going to skip,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1613" target="_blank">00:26:53.280</a></span> | <span class="t">I could have asked, Hey, can you please, and I did that to prepare the demo. Can you please add,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1618" target="_blank">00:26:58.320</a></span> | <span class="t">draw red crosses for each one of my turns? And here's the results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1625" target="_blank">00:27:05.200</a></span> | <span class="t">Can you imagine how powerful that is? Like, I didn't code a single line. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1632" target="_blank">00:27:12.080</a></span> | <span class="t">um, and 57. Can I show the last thing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1638" target="_blank">00:27:18.800</a></span> | <span class="t">Uh, well, real quick, um, here's, uh, something pretty cool that I want to show you too. Uh, this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1647" target="_blank">00:27:27.040</a></span> | <span class="t">GitHub work spaces. And here I can go to that repository and I can, so it's a preview, free access.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1659" target="_blank">00:27:39.760</a></span> | <span class="t">And I can ask, can you add a Java GUI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1668" target="_blank">00:27:48.160</a></span> | <span class="t">front end. So this is a demo. Uh, I don't know if you've noticed, but that was Python code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1675" target="_blank">00:27:55.760</a></span> | <span class="t">And I asked, can you generate a Java GUI front end?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1680" target="_blank">00:28:00.000</a></span> | <span class="t">And it's going to automatically using an LLM figure out what is the state of the code repository,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1686" target="_blank">00:28:06.080</a></span> | <span class="t">figure out the, uh, what it contains, what it does not. So it's going to, um, write specifications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1693" target="_blank">00:28:13.680</a></span> | <span class="t">And based on the specification, we can ask to generate a plan and every step of the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1698" target="_blank">00:28:18.720</a></span> | <span class="t">if he makes a mistake, we can ask it to make corrections.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1702" target="_blank">00:28:22.240</a></span> | <span class="t">This is preview. This is not yet available. Uh, but this is incredibly powerful. Uh, and that's upcoming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1712" target="_blank">00:28:32.080</a></span> | <span class="t">And I'm over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1715" target="_blank">00:28:35.680</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1716" target="_blank">00:28:36.520</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YcOrV-TLNyQ&t=1717" target="_blank">00:28:37.360</a></span> | <span class="t">Thank you.</span></div></div></body></html>