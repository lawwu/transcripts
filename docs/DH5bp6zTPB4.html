<html><head><title>Lesson 24: Deep Learning Foundations to Stable Diffusion</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 24: Deep Learning Foundations to Stable Diffusion</h2><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4"><img src="https://i.ytimg.com/vi/DH5bp6zTPB4/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./DH5bp6zTPB4.html">Whisper Transcript</a> | <a href="./transcript_DH5bp6zTPB4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hi, we are here for lesson 24. And once again, it's becoming a bit of a tradition now. We're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6" target="_blank">00:00:06.320</a></span> | <span class="t">joined by Jono and Tanishk, which is always a pleasure. Hi, Jono. Hi, Tanishk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=10" target="_blank">00:00:10.600</a></span> | <span class="t">Hello.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=11" target="_blank">00:00:11.600</a></span> | <span class="t">Another great lesson.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=12" target="_blank">00:00:12.600</a></span> | <span class="t">Yeah, are you guys looking forward to finally actually completing stable diffusion, at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=19" target="_blank">00:00:19.960</a></span> | <span class="t">the unconditional stable diffusion? Well, I should say no, even conditional. So conditional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=24" target="_blank">00:00:24.040</a></span> | <span class="t">stable diffusion, except for the clip bit from scratch. We should be able to finish</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=30" target="_blank">00:00:30.000</a></span> | <span class="t">today. Time permitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=31" target="_blank">00:00:31.000</a></span> | <span class="t">Oh, that's exciting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=32" target="_blank">00:00:32.000</a></span> | <span class="t">That is exciting. All right. Let's do it. Jump in any time. We've got things to talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=41" target="_blank">00:00:41.520</a></span> | <span class="t">about. So we're going to start with a very hopefully named 26 diffusion unit. And what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=52" target="_blank">00:00:52.720</a></span> | <span class="t">we're going to do in 26 diffusion unit is to do unconditional diffusion from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=64" target="_blank">00:01:04.480</a></span> | <span class="t">And there's not really too many new pieces, if I remember correctly. So all the stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=69" target="_blank">00:01:09.880</a></span> | <span class="t">at the start we've already seen. And so when I wrote this, it was before I had noticed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=77" target="_blank">00:01:17.920</a></span> | <span class="t">that the Keras approach was doing less well than the regular cosine schedule approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=82" target="_blank">00:01:22.480</a></span> | <span class="t">So I'm still using Keras Noisify, but this is all the same as from the Keras notebook,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=88" target="_blank">00:01:28.320</a></span> | <span class="t">which was 23.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=91" target="_blank">00:01:31.440</a></span> | <span class="t">Okay, so we can now create a unit that is based on what diffusers has, which is in turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=106" target="_blank">00:01:46.240</a></span> | <span class="t">based on lots of other prior art. I mean, the code's not at all based on it, but the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=112" target="_blank">00:01:52.280</a></span> | <span class="t">basic structure is going to be the same as what you'll get in diffusers. The convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=120" target="_blank">00:02:00.880</a></span> | <span class="t">we're going to use is the same as the final kind of convolution we used for tiny image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=126" target="_blank">00:02:06.080</a></span> | <span class="t">net, which is what's called the preactivation convolution. So the convolution itself happens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=132" target="_blank">00:02:12.460</a></span> | <span class="t">at the end and the normalization and activation happen first. So this is a preact convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=143" target="_blank">00:02:23.720</a></span> | <span class="t">So then I've got a unit res net block. So I kind of wrote this before I actually did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=151" target="_blank">00:02:31.000</a></span> | <span class="t">the preact version of tiny image net. So I suspect this is actually the same, quite possibly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=156" target="_blank">00:02:36.880</a></span> | <span class="t">exactly the same as the tiny image net one. So maybe this is nothing specific about this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=161" target="_blank">00:02:41.200</a></span> | <span class="t">for unit, this is just really a preact conv and a preact res net block. So we've got the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=169" target="_blank">00:02:49.320</a></span> | <span class="t">two comms as per usual and the identity conv. Now there is one difference though to what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=176" target="_blank">00:02:56.240</a></span> | <span class="t">we've seen before for res net blocks, which is that this res net block has no option to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=181" target="_blank">00:03:01.360</a></span> | <span class="t">do downsampling, no option to do a strayed. This is always strayed one, which is our default.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=192" target="_blank">00:03:12.760</a></span> | <span class="t">So the reason for that is that when we get to the thing that strings a bunch of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=198" target="_blank">00:03:18.860</a></span> | <span class="t">together, which will be called down block, this is where you have the option to add downsampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=206" target="_blank">00:03:26.040</a></span> | <span class="t">But if you do add downsampling, we're going to add a strayed to convolution after the res</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=211" target="_blank">00:03:31.040</a></span> | <span class="t">block. And that's because this is how diffusers and stable diffusion does it. I haven't studied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=220" target="_blank">00:03:40.960</a></span> | <span class="t">this closely to Nishkif or Dono if either of you have know like where this idea came</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=226" target="_blank">00:03:46.440</a></span> | <span class="t">from or why. I'd be curious, you know, the difference is that normally we would have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=234" target="_blank">00:03:54.480</a></span> | <span class="t">average pooling here in this connection. But yeah, this different approach is what we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=243" target="_blank">00:04:03.060</a></span> | <span class="t">using.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=244" target="_blank">00:04:04.060</a></span> | <span class="t">A lot of the history of the diffusers unconditional unit is to be compatible with the DDPM weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=252" target="_blank">00:04:12.520</a></span> | <span class="t">that were released and some follow and work from that. And I know like then improved DDPM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=257" target="_blank">00:04:17.560</a></span> | <span class="t">and these others like they all kind of built on that same sort of unit structure, even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=261" target="_blank">00:04:21.120</a></span> | <span class="t">though it's slightly unconventional if you're coming from like a normal computer vision</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=265" target="_blank">00:04:25.720</a></span> | <span class="t">background.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=266" target="_blank">00:04:26.720</a></span> | <span class="t">And do you recall where the DDPM architecture came from? Because like some of the ideas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=271" target="_blank">00:04:31.600</a></span> | <span class="t">came from some of the N units, but I don't know if DDPM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=278" target="_blank">00:04:38.080</a></span> | <span class="t">Yeah, they had something called efficient unit that was inspired by some prior work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=282" target="_blank">00:04:42.760</a></span> | <span class="t">that I can't remember the lineage. Anyway, yeah, I just think the diffusers one has since</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=290" target="_blank">00:04:50.320</a></span> | <span class="t">become you know, like you can add in parameters to control some of this stuff. But yeah, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=296" target="_blank">00:04:56.000</a></span> | <span class="t">we shouldn't assume that this is the optimal approach, I suppose. But yeah, I will dig</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=301" target="_blank">00:05:01.280</a></span> | <span class="t">into the history and try and find out how much like, what ablation studies have been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=305" target="_blank">00:05:05.480</a></span> | <span class="t">done. So for those of you who haven't heard of ablation studies, that's where you'd like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=308" target="_blank">00:05:08.480</a></span> | <span class="t">try, you know, a bunch of different ways of doing things and score which one works better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=313" target="_blank">00:05:13.160</a></span> | <span class="t">and which one works less well and kind of create a table of all of those options. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=319" target="_blank">00:05:19.000</a></span> | <span class="t">so where you can't find ablation studies for something you're interested in, often that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=324" target="_blank">00:05:24.160</a></span> | <span class="t">means that, you know, maybe not many other options were tried because researchers don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=328" target="_blank">00:05:28.720</a></span> | <span class="t">have time to try everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=331" target="_blank">00:05:31.480</a></span> | <span class="t">Okay, now the unit, if we go back to the unit that we used for super resolution, we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=341" target="_blank">00:05:41.640</a></span> | <span class="t">go back to our most basic version. What we did as we went down through the layers in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=351" target="_blank">00:05:51.560</a></span> | <span class="t">the down sampling section, we stored the activations at each point into a list called layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=366" target="_blank">00:06:06.600</a></span> | <span class="t">And then as we went through the up sampling, we added those down sampling layers back into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=373" target="_blank">00:06:13.000</a></span> | <span class="t">the up sampling activations. So that's kind of basic structure of a unit. You don't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=380" target="_blank">00:06:20.440</a></span> | <span class="t">to add, you can also concatenate and actually concatenating is what is, I think it's more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=387" target="_blank">00:06:27.160</a></span> | <span class="t">common nowadays and I think your original unit might have been concatenating. Although</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=391" target="_blank">00:06:31.840</a></span> | <span class="t">for super resolution, just adding seems pretty sensible. So we're going to concatenate. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=397" target="_blank">00:06:37.920</a></span> | <span class="t">what we're going to do is we're going to try to, we're going to kind of exercise our Python</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=402" target="_blank">00:06:42.400</a></span> | <span class="t">muscles a little bit to try to see interesting ways to make some of this a little easier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=407" target="_blank">00:06:47.520</a></span> | <span class="t">to turn different down sampling backbones into units. And you also use that as an opportunity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=415" target="_blank">00:06:55.880</a></span> | <span class="t">to learn a bit more Python. So what we're going to do is we're going to create something called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=423" target="_blank">00:07:03.460</a></span> | <span class="t">a saved res block and a saved convolution. And so our down blocks, so these are our res</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=431" target="_blank">00:07:11.880</a></span> | <span class="t">blocks containing a certain number of res block layers, followed by this optional strive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=438" target="_blank">00:07:18.800</a></span> | <span class="t">to conv. We're going to use saved res blocks and saved cons. And what these are going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=443" target="_blank">00:07:23.080</a></span> | <span class="t">do, it's going to be the same as a normal convolution and the same as a normal res block,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=447" target="_blank">00:07:27.600</a></span> | <span class="t">the same as normal unit res block. But they're going to remember the activations. And the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=455" target="_blank">00:07:35.240</a></span> | <span class="t">reason for that is that later on in the unit, we're going to go through and grab those saved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=463" target="_blank">00:07:43.040</a></span> | <span class="t">activations all at once into a big list. So then yeah, we basically don't have to kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=471" target="_blank">00:07:51.240</a></span> | <span class="t">of think about it. And so to do that, we create a class called a save module. And all saved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=478" target="_blank">00:07:58.400</a></span> | <span class="t">module does is it calls forward to grab the res block or conv results and stores that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=491" target="_blank">00:08:11.400</a></span> | <span class="t">before returning it. Now that's weird because hopefully you know by now that super calls</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=499" target="_blank">00:08:19.120</a></span> | <span class="t">the thing in the parent class, that save module doesn't have a parent class. So this is what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=505" target="_blank">00:08:25.480</a></span> | <span class="t">called a mixin. And it's using something called multiple inheritance. And mixins are as it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=522" target="_blank">00:08:42.800</a></span> | <span class="t">describes here. It's a design pattern, which is to say it's not particularly a part of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=530" target="_blank">00:08:50.800</a></span> | <span class="t">Python per se. It's a design pattern that uses multiple inheritance. Now what multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=535" target="_blank">00:08:55.000</a></span> | <span class="t">inheritance is where you can say, oh, this class called saved res block inherits from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=543" target="_blank">00:09:03.000</a></span> | <span class="t">two things, save module and unit res block. And what that does is it means that all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=551" target="_blank">00:09:11.080</a></span> | <span class="t">the methods in both of these will end up in here. Now that would be simple enough, except</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=558" target="_blank">00:09:18.040</a></span> | <span class="t">we've got a bit of a confusion here, which is that unit res block contains forward and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=563" target="_blank">00:09:23.440</a></span> | <span class="t">saved module contains forward. So it's all very well just combining the methods from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=567" target="_blank">00:09:27.960</a></span> | <span class="t">both of them. But what if they have the same method? And the answer is that the one you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=575" target="_blank">00:09:35.440</a></span> | <span class="t">list first can call, when it calls forward, it's actually calling forward in the later</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=584" target="_blank">00:09:44.040</a></span> | <span class="t">one. And that's why it's a mixin. It's mixing this functionality into this functionality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=591" target="_blank">00:09:51.560</a></span> | <span class="t">So it's a unit res block where we've customized forward. So it calls the existing forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=597" target="_blank">00:09:57.520</a></span> | <span class="t">and also saves it. So you see mixins quite a lot in the Python standard library. For</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=604" target="_blank">00:10:04.560</a></span> | <span class="t">example, the basic HTTP stuff, some of the basic thread stuff with networking uses multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=616" target="_blank">00:10:16.280</a></span> | <span class="t">inheritance using this mixin pattern. So with this approach, then the actual implementation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=622" target="_blank">00:10:22.120</a></span> | <span class="t">of saved res block is nothing at all. So pass means don't do anything. So this is just literally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=629" target="_blank">00:10:29.080</a></span> | <span class="t">just a class which has no implementation of its own other than just to be a mixin of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=636" target="_blank">00:10:36.520</a></span> | <span class="t">two classes. So a saved convolution is an nn.conf2d with the saved module mixed in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=647" target="_blank">00:10:47.800</a></span> | <span class="t">So what's going to happen now is that we can call a saved res block just like a unit res</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=654" target="_blank">00:10:54.280</a></span> | <span class="t">block and a saved conv just like an nn.conf2d. But that object is going to end up with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=661" target="_blank">00:11:01.400</a></span> | <span class="t">activations inside the dot saved attribute. So now a downsampling block is just a sequential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=670" target="_blank">00:11:10.920</a></span> | <span class="t">of saved res blocks. As per usual, the very first one is going to have the number of n</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=682" target="_blank">00:11:22.640</a></span> | <span class="t">channels to start with and it will always have the number of nf, the number of filters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=687" target="_blank">00:11:27.640</a></span> | <span class="t">output, and then after that the inputs will be else equal to nf because the first one's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=692" target="_blank">00:11:32.560</a></span> | <span class="t">changed the number of channels. And we'll do that for however many layers we have. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=698" target="_blank">00:11:38.680</a></span> | <span class="t">then at the end of that process, as we discussed, we will add to that sequential a saved conv</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=705" target="_blank">00:11:45.600</a></span> | <span class="t">with str2 to do the downsampling if requested. So we're going to end up with a single nn.sequential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=711" target="_blank">00:11:51.360</a></span> | <span class="t">for a down block. And then an up block is going to look very similar, but instead of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=721" target="_blank">00:12:01.800</a></span> | <span class="t">using an nn.conf2d with str2, upsampling will be done with a sequence of an upsampling layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=733" target="_blank">00:12:13.400</a></span> | <span class="t">And so literally all that does is it just duplicates every pixel four times into little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=737" target="_blank">00:12:17.360</a></span> | <span class="t">two by two grid. That's what an upsampling layer does, nothing clever. And then follow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=742" target="_blank">00:12:22.360</a></span> | <span class="t">that by a str1 convolution. So that allows it to, you know, adjust some of those pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=751" target="_blank">00:12:31.000</a></span> | <span class="t">as if necessary with a simple three by three conv. So that's pretty similar to a str2 downsampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=760" target="_blank">00:12:40.040</a></span> | <span class="t">This is kind of the rough equivalent for upsampling. There are other ways of doing upsampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=767" target="_blank">00:12:47.120</a></span> | <span class="t">This is just the one that stable diffusion does. So an up block looks a lot like a down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=774" target="_blank">00:12:54.540</a></span> | <span class="t">block, except that now, so as before, we're going to create a bunch of unit res blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=782" target="_blank">00:13:02.360</a></span> | <span class="t">These are not saved res blocks, of course. We want to use the saved results in the upsampling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=786" target="_blank">00:13:06.600</a></span> | <span class="t">path of the unit. So we just use normal res blocks. But what we're going to do now is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=793" target="_blank">00:13:13.960</a></span> | <span class="t">as we go through each res net, we're going to call it not just on our activations, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=800" target="_blank">00:13:20.800</a></span> | <span class="t">we're going to concatenate that with whatever was stored during the downsampling path. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=809" target="_blank">00:13:29.640</a></span> | <span class="t">this is going to be a list of all of the things stored in the downsampling path. It'll be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=814" target="_blank">00:13:34.880</a></span> | <span class="t">passed to the up block. And so .pop will grab the last one off that list and concatenate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=821" target="_blank">00:13:41.120</a></span> | <span class="t">it with the activations and pass that to the res net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=825" target="_blank">00:13:45.480</a></span> | <span class="t">So we need to know how many filters there were, how many activations there were in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=832" target="_blank">00:13:52.760</a></span> | <span class="t">downsampling path. So that's stored here. This is the previous number of filters in the downsampling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=837" target="_blank">00:13:57.920</a></span> | <span class="t">path. And so the res block wanted to add those in in addition to the normal number. So that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=852" target="_blank">00:14:12.120</a></span> | <span class="t">what's going to happen there. And so yeah, do that for each layer as before. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=859" target="_blank">00:14:19.880</a></span> | <span class="t">at the end, add an upsampling layer if it's been requested. So it's a boolean. OK, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=870" target="_blank">00:14:30.760</a></span> | <span class="t">that's the upsampling block. Does that all make sense so far?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=874" target="_blank">00:14:34.520</a></span> | <span class="t">Yeah, it looks good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=878" target="_blank">00:14:38.600</a></span> | <span class="t">OK. OK, so the unit now is going to look a lot like our previous unit. We're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=889" target="_blank">00:14:49.320</a></span> | <span class="t">start out as we tend to with a convolution to now allow us to create a few more channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=897" target="_blank">00:14:57.080</a></span> | <span class="t">And so we're passing to our unit. That's just how many channels are in your image and how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=902" target="_blank">00:15:02.320</a></span> | <span class="t">many channels are in your output image. So for normal full color images, that'll be 3/3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=908" target="_blank">00:15:08.780</a></span> | <span class="t">How many filters are there for each of those res net blocks, up blocks and down blocks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=913" target="_blank">00:15:13.800</a></span> | <span class="t">you've got. And in the downsampling, how many layers are there in each block? So we go from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=921" target="_blank">00:15:21.240</a></span> | <span class="t">the conv will go from in channel. So it'd be 3 to an F0, which this is the number of filters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=926" target="_blank">00:15:26.800</a></span> | <span class="t">in the stable diffusion model. They're pretty big, as you see by default. And so that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=937" target="_blank">00:15:37.160</a></span> | <span class="t">the number of channels we would create, which is like very redundant in that this is a 3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=945" target="_blank">00:15:45.480</a></span> | <span class="t">by 3 conv. So it only contains 3 by 3 by 3 channels equals 27 inputs and 224 outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=953" target="_blank">00:15:53.360</a></span> | <span class="t">So it's not doing computation, useful computation in a sense. It's just giving it more space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=960" target="_blank">00:16:00.220</a></span> | <span class="t">to work with down the line, which I don't think that makes sense, but I haven't played</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=966" target="_blank">00:16:06.360</a></span> | <span class="t">with it enough to be sure. Normally we would do like, you know, like a few res blocks or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=975" target="_blank">00:16:15.200</a></span> | <span class="t">something at this level to more gradually increase it because this feels like a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=978" target="_blank">00:16:18.640</a></span> | <span class="t">of wasted effort. But yeah, I haven't studied that closely enough to be sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=984" target="_blank">00:16:24.360</a></span> | <span class="t">So Jamie, just to tweet, this is the default, I think the default settings for the unconditional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=990" target="_blank">00:16:30.000</a></span> | <span class="t">unit in diffusers. But the stable diffusion unit actually has even more channels. It has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=994" target="_blank">00:16:34.400</a></span> | <span class="t">320, 640, and then 1,280, 1,280. Cool. Thanks for clarifying. And it's, yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1001" target="_blank">00:16:41.800</a></span> | <span class="t">the unconditional one, which is what we're doing right now. That's a great point. Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1007" target="_blank">00:16:47.720</a></span> | <span class="t">So then we, yeah, we go through all of our number of filters and actually the first res</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1014" target="_blank">00:16:54.520</a></span> | <span class="t">block contains 224 to 224. So that's why it's kind of keeping track of this stuff. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1021" target="_blank">00:17:01.480</a></span> | <span class="t">the second res block is 224 to 448 and then 448 to 672 and then 672 to 896. So that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1027" target="_blank">00:17:07.760</a></span> | <span class="t">why we're just going to have to keep track of these things. So yeah, we add, so we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1032" target="_blank">00:17:12.800</a></span> | <span class="t">a sequential for our down blocks and we just add a down block. The very last one doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1038" target="_blank">00:17:18.440</a></span> | <span class="t">have downsampling, which makes sense, right? Because the very last one, there's nothing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1043" target="_blank">00:17:23.560</a></span> | <span class="t">after it, so no point downsampling. Other than that, they all have downsampling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1049" target="_blank">00:17:29.240</a></span> | <span class="t">And then we have one more res block in the middle, which, is that the same as what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1057" target="_blank">00:17:37.000</a></span> | <span class="t">did? Okay. So we didn't have a middle res block in our original unit here. What about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1067" target="_blank">00:17:47.280</a></span> | <span class="t">this one? Do we have any mid blocks? No, so we haven't done. Okay. But I mean, so it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1071" target="_blank">00:17:51.240</a></span> | <span class="t">just another res block that you do after the downsampling. And then we go through the reversed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1077" target="_blank">00:17:57.920</a></span> | <span class="t">list of filters and go through those and adding up blocks. And then one convolution at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1082" target="_blank">00:18:02.960</a></span> | <span class="t">end to turn it from 224 channels to three channels. Okay. And so the forward then is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1094" target="_blank">00:18:14.560</a></span> | <span class="t">going to store in saved all the layers, just like we did back with this unit. But we don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1107" target="_blank">00:18:27.240</a></span> | <span class="t">really have to do it explicitly now. We just call the sequential model. And thanks to our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1112" target="_blank">00:18:32.840</a></span> | <span class="t">automatic saving, each of those now will, we can just go through each of those and grab</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1118" target="_blank">00:18:38.400</a></span> | <span class="t">their dot saved. So that's handy. We then call that mid block, which is just another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1124" target="_blank">00:18:44.080</a></span> | <span class="t">res block. And then same thing. Okay. Now for the ARPS. And what we do is we just passed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1128" target="_blank">00:18:48.360</a></span> | <span class="t">in those saved, right? And just remember, it's going to pop them out each time. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1136" target="_blank">00:18:56.600</a></span> | <span class="t">then the conv at the end. So that's, yeah, that's it. That's our unconditional model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1146" target="_blank">00:19:06.200</a></span> | <span class="t">It's not quite the same as the diffuses unconditional model, because it doesn't have a tension, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1149" target="_blank">00:19:09.800</a></span> | <span class="t">is something we're going to add next. But other than that, this is the same. So let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1157" target="_blank">00:19:17.120</a></span> | <span class="t">for, because we're doing a simpler problem, which is fashion MNIST, we'll use less channels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1161" target="_blank">00:19:21.560</a></span> | <span class="t">than the default. Using two layers per block is standard. One thing to note though, is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1169" target="_blank">00:19:29.280</a></span> | <span class="t">that in the up sampling blocks, it actually is going to be three layers, num layers plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1174" target="_blank">00:19:34.560</a></span> | <span class="t">one. And the reason for that is that the way stable diffusion and diffuses do it is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1181" target="_blank">00:19:41.360</a></span> | <span class="t">even the output of the down sampling is also saved. So if you have num layers equals two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1188" target="_blank">00:19:48.600</a></span> | <span class="t">then there'll be two res blocks saving things here and one conv saving things here. So you'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1194" target="_blank">00:19:54.280</a></span> | <span class="t">have three saved cross connections. So that's why there's an extra plus one here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1202" target="_blank">00:20:02.760</a></span> | <span class="t">Okay. And then we can just train it using mini AI as per usual. Nope, I didn't save</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1213" target="_blank">00:20:13.240</a></span> | <span class="t">it after I last trained it. Sorry about that. So trust me, it trained. Okay. Now that, oh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1222" target="_blank">00:20:22.800</a></span> | <span class="t">okay. No, that is actually missing something else important as well as attention. The other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1226" target="_blank">00:20:26.840</a></span> | <span class="t">thing it's missing is that thing that we discovered is pretty important, which is the time embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1234" target="_blank">00:20:34.600</a></span> | <span class="t">So we already know that sampling doesn't work particularly well with that time embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1238" target="_blank">00:20:38.280</a></span> | <span class="t">So I didn't even bother sampling this. I didn't want to add all this stuff necessary to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1242" target="_blank">00:20:42.240</a></span> | <span class="t">that work a bit better. So let's just go ahead and do time embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1248" target="_blank">00:20:48.520</a></span> | <span class="t">So time embedding, there's a few ways to do it. And the way it's done in stable diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1255" target="_blank">00:20:55.340</a></span> | <span class="t">is what's called sinusoidal embeddings. The basic idea, maybe we'll skip ahead a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1264" target="_blank">00:21:04.680</a></span> | <span class="t">The basic idea is that we're going to create a res block with embeddings where forward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1271" target="_blank">00:21:11.080</a></span> | <span class="t">is not just going to get the activations, but it's also going to get T, which is a vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1279" target="_blank">00:21:19.480</a></span> | <span class="t">that represents the embeddings of each time step. So actually it'll be a matrix because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1285" target="_blank">00:21:25.320</a></span> | <span class="t">it's really in the batch. But for one element of the batch, it's a vector. And it's an embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1289" target="_blank">00:21:29.880</a></span> | <span class="t">in exactly the same way as when we did NLP. Each token had an embedding. And so the word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1296" target="_blank">00:21:36.760</a></span> | <span class="t">"the" would have an embedding and the word "Johnno" would have an embedding and the word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1301" target="_blank">00:21:41.040</a></span> | <span class="t">"Tanishk" would have an embedding, although Tanishk would probably actually be multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1304" target="_blank">00:21:44.800</a></span> | <span class="t">tokens until he's famous enough that he's mentioned in nearly every piece of literature,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1310" target="_blank">00:21:50.320</a></span> | <span class="t">at which point Tanishk will get his own token, I expect. That's how you know when you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1316" target="_blank">00:21:56.480</a></span> | <span class="t">made it. So the time embedding will be the same. T of time step zero will have a particular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1325" target="_blank">00:22:05.600</a></span> | <span class="t">vector, time step one will have a particular vector, and so forth. Well, we're doing Keras.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1332" target="_blank">00:22:12.760</a></span> | <span class="t">So actually they're not time step one, two, three. They're actually sigmas, you know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1338" target="_blank">00:22:18.560</a></span> | <span class="t">So they're continuous. But same idea. A specific value of sigma, which is actually what T is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1346" target="_blank">00:22:26.960</a></span> | <span class="t">going to be, slightly confusingly, will have a specific embedding. Now, we want two values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1357" target="_blank">00:22:37.240</a></span> | <span class="t">of sigma or T, which are very close to each other, should have similar embeddings. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1363" target="_blank">00:22:43.840</a></span> | <span class="t">if they're different to each other, they should have different embeddings. So how do we make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1371" target="_blank">00:22:51.600</a></span> | <span class="t">that happen? You know, and also make sure there's a lot of variety of the embeddings across</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1376" target="_blank">00:22:56.440</a></span> | <span class="t">all the possibilities. So the way we do that is with these sinusoidal time steps. So let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1384" target="_blank">00:23:04.680</a></span> | <span class="t">have a look at how they work. So you first have to decide how big do you want your embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1389" target="_blank">00:23:09.440</a></span> | <span class="t">to be? Just like we do at NLP. Does the word "the," is it represented by eight floats</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1396" target="_blank">00:23:16.440</a></span> | <span class="t">or 16 floats or 400 floats or whatever? Let's just assume it's 16 now. So let's say we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1404" target="_blank">00:23:24.120</a></span> | <span class="t">just looking at a bunch of time steps, which is between negative 10 and 10. And we'll just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1410" target="_blank">00:23:30.400</a></span> | <span class="t">do 100 of them. I mean, we don't actually have negative sigmas or T. So it doesn't exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1416" target="_blank">00:23:36.120</a></span> | <span class="t">make sense. But it doesn't matter. It gives you the idea. And so then we say, OK, what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1423" target="_blank">00:23:43.960</a></span> | <span class="t">the largest time step you could have or the largest sigma that you could have? Interestingly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1430" target="_blank">00:23:50.440</a></span> | <span class="t">every single model I've found, every single model I've found uses 10,000 for this. Even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1437" target="_blank">00:23:57.280</a></span> | <span class="t">though that number actually comes from the NLP transformers literature, and it's based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1441" target="_blank">00:24:01.920</a></span> | <span class="t">on the idea of, like, OK, what's the maximum sequence length we support? You could have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1445" target="_blank">00:24:05.960</a></span> | <span class="t">up to 10,000 things in a document or whatever in a sequence. But we don't actually have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1454" target="_blank">00:24:14.800</a></span> | <span class="t">a sigmas that go up to 10,000. So I'm using the number that's used in real life in stable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1459" target="_blank">00:24:19.200</a></span> | <span class="t">diffusion and all the other models. But interestingly, here purely, as far as I can tell, as a hysterical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1465" target="_blank">00:24:25.280</a></span> | <span class="t">accident, because this is like the maximum sequence length that NLP transformers people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1471" target="_blank">00:24:31.200</a></span> | <span class="t">thought they would need to support. OK, now what we're then going to do is we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1478" target="_blank">00:24:38.640</a></span> | <span class="t">to be then doing e to the power of a bunch of things. And so that's going to be our exponent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1487" target="_blank">00:24:47.720</a></span> | <span class="t">And so our exponent is going to be equal to log of the period, which is about nine, times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1497" target="_blank">00:24:57.820</a></span> | <span class="t">the numbers between 0 and 1, eight of them, because we said we want 16. So you'll see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1504" target="_blank">00:25:04.720</a></span> | <span class="t">why we want eight of them and not 16 in a moment. But basically here are the eight exponents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1511" target="_blank">00:25:11.600</a></span> | <span class="t">we're going to use. So then not surprisingly, we do e to the power of that. OK, so we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1518" target="_blank">00:25:18.880</a></span> | <span class="t">e to the power of that, each of these eight things. And we've also got the actual time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1528" target="_blank">00:25:28.440</a></span> | <span class="t">steps. So imagine these are the actual time steps we have in our batch. So there's a batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1533" target="_blank">00:25:33.320</a></span> | <span class="t">of 100, and they contain this range of sigmas or time steps. So to create our embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1543" target="_blank">00:25:43.200</a></span> | <span class="t">what we do is we do an outer product of the exponent.x and the time steps. This is step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1552" target="_blank">00:25:52.520</a></span> | <span class="t">one. And so this is using a broadcasting trick we've seen before. We add a unit axis and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1561" target="_blank">00:26:01.560</a></span> | <span class="t">an axis 0 here, and add a unit axis 1 here, and add a unit axis and axis 0 here. So if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1573" target="_blank">00:26:13.840</a></span> | <span class="t">we multiply those together, then it's going to broadcast this one across this axis and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1582" target="_blank">00:26:22.520</a></span> | <span class="t">this one across this axis. So we end up with a 100 by 8. So it's basically a Cartesian</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1588" target="_blank">00:26:28.760</a></span> | <span class="t">product or the possible combinations of time step and exponent multiplied together. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1596" target="_blank">00:26:36.080</a></span> | <span class="t">so here's a few of those different exponents for a few different values. OK, so that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1610" target="_blank">00:26:50.800</a></span> | <span class="t">not very interesting yet. We haven't yet reached something where each time step is similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1617" target="_blank">00:26:57.960</a></span> | <span class="t">to each next door time step. You know, over here, you know, these embeddings look very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1624" target="_blank">00:27:04.000</a></span> | <span class="t">different to each other. And over here, they're very similar. So what we then do is we take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1630" target="_blank">00:27:10.720</a></span> | <span class="t">the sine and the cosine of those. So that is 100 by 8. And that is 100 by 8. And that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1643" target="_blank">00:27:23.780</a></span> | <span class="t">gives us 100 by 16. So we concatenate those together. And so that's a little bit hard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1654" target="_blank">00:27:34.920</a></span> | <span class="t">to wrap your head around. So let's take a look. So across the 100 time steps, 100 sigma,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1664" target="_blank">00:27:44.120</a></span> | <span class="t">this one here is the first sine wave. And then this one here is the second sine wave.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1677" target="_blank">00:27:57.240</a></span> | <span class="t">And this one here is the third. And this one here is the fourth and the fifth. So you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1685" target="_blank">00:28:05.200</a></span> | <span class="t">see as you go up to higher numbers, you're basically stretching the sine wave out. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1697" target="_blank">00:28:17.160</a></span> | <span class="t">then once you get up to index 8, you're back up to the same frequency as this blue one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1705" target="_blank">00:28:25.240</a></span> | <span class="t">because now we're starting the cosine rather than sine. And cosine is identical to sine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1710" target="_blank">00:28:30.200</a></span> | <span class="t">It's just shifted across a tiny bit. You can see these two light blue lines are the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1715" target="_blank">00:28:35.080</a></span> | <span class="t">And these two orange lines are the same. They're just shifted across, I shouldn't say, lines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1719" target="_blank">00:28:39.600</a></span> | <span class="t">or curves. So when we concatenate those all together, we can actually draw a picture of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1725" target="_blank">00:28:45.720</a></span> | <span class="t">it. And so this picture is 100 pixels across and 16 pixels top to bottom. And so if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1736" target="_blank">00:28:56.880</a></span> | <span class="t">picked out a particular point, so for example, in the middle here for t equals 0, well sigma</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1743" target="_blank">00:29:03.000</a></span> | <span class="t">equals 0, one column is an embedding. So the bright represents higher numbers and the dark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1751" target="_blank">00:29:11.260</a></span> | <span class="t">represents lower numbers. And so you can see every column looks different, even though</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1757" target="_blank">00:29:17.280</a></span> | <span class="t">the columns next to each other look similar. So that's called a time step embedding. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1766" target="_blank">00:29:26.180</a></span> | <span class="t">this is definitely something you want to experiment with. I've tried to do the plots I thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1774" target="_blank">00:29:34.060</a></span> | <span class="t">are useful to understand this. And Johno and Tanishka also had ideas about plots for these,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1782" target="_blank">00:29:42.320</a></span> | <span class="t">which we've shown. But the only way to really understand them is to experiment. So then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1789" target="_blank">00:29:49.320</a></span> | <span class="t">we can put that all into a function where you just say, OK, well, how many times-- sorry,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1793" target="_blank">00:29:53.680</a></span> | <span class="t">what are the time steps? How many embedding dimensions do you want? What's the maximum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1797" target="_blank">00:29:57.780</a></span> | <span class="t">period? And then all I did was I just copied and pasted the previous cells and merged them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1802" target="_blank">00:30:02.200</a></span> | <span class="t">together. So you can see there's our outer product. And there's our cat of sine and cos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1815" target="_blank">00:30:15.020</a></span> | <span class="t">If you end up with a-- if you have an odd numbered embedding dimension, you have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1818" target="_blank">00:30:18.480</a></span> | <span class="t">pat it to make it even. Don't worry about that. So here's something that now you can pass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1822" target="_blank">00:30:22.800</a></span> | <span class="t">in the number of-- sorry, the actual time steps or sigma's and the number of embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1827" target="_blank">00:30:27.440</a></span> | <span class="t">dimensions. And you will get back something like this. It won't be a nice curve because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1834" target="_blank">00:30:34.480</a></span> | <span class="t">your time steps in a batch won't all be next to each other. It's the same idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1839" target="_blank">00:30:39.600</a></span> | <span class="t">Can I call it something on that little visualization there, which goes back to your comment about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1845" target="_blank">00:30:45.400</a></span> | <span class="t">the max period being super high? So you said, OK, adjacent ones are somewhat similar because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1851" target="_blank">00:30:51.200</a></span> | <span class="t">that's what we want. But there is some change. But if you look at all of this first 100,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1857" target="_blank">00:30:57.000</a></span> | <span class="t">some-- just like the half of the embeddings look like they don't really change at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1861" target="_blank">00:31:01.200</a></span> | <span class="t">And that's because 50 to 100 on a scale of like 0 to 10,000, you want those to be quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1867" target="_blank">00:31:07.240</a></span> | <span class="t">similar because those are still very early in this super long sequence that these are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1870" target="_blank">00:31:10.760</a></span> | <span class="t">designed for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1871" target="_blank">00:31:11.760</a></span> | <span class="t">Yeah. So here, actually, we've got--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1873" target="_blank">00:31:13.560</a></span> | <span class="t">[INTERPOSING VOICES]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1874" target="_blank">00:31:14.560</a></span> | <span class="t">--wasted space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1875" target="_blank">00:31:15.560</a></span> | <span class="t">Yeah. So here we've got a max period of 1,000 instead. And I've changed the figure size so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1880" target="_blank">00:31:20.040</a></span> | <span class="t">you can see it better. And it's using up a bit more of the space. Yeah. Or go to max</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1887" target="_blank">00:31:27.240</a></span> | <span class="t">period of 10. And it's actually now-- this is, yeah, using it much better. Yeah. So based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1896" target="_blank">00:31:36.440</a></span> | <span class="t">on what you're saying, Johnno, I agree. It seems like it would be a lot richer to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1904" target="_blank">00:31:44.280</a></span> | <span class="t">these time step embeddings with a suitable max period. Or maybe you just wouldn't need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1908" target="_blank">00:31:48.640</a></span> | <span class="t">as many embedding dimensions. I guess if you did use something very wasteful like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1913" target="_blank">00:31:53.600</a></span> | <span class="t">but you used lots of embedding dimensions, then it's going to still capture some useful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1918" target="_blank">00:31:58.360</a></span> | <span class="t">ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1921" target="_blank">00:32:01.520</a></span> | <span class="t">Yeah. Thanks, Johnno. So yeah. Yeah. So this is one of these interesting little insights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1930" target="_blank">00:32:10.840</a></span> | <span class="t">about things that are buried deep in code, which I'm not sure anybody probably much looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1935" target="_blank">00:32:15.920</a></span> | <span class="t">at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1940" target="_blank">00:32:20.800</a></span> | <span class="t">OK. So let's do a unit with time step embedding in it. So what do you do once you've got like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1951" target="_blank">00:32:31.440</a></span> | <span class="t">this column of embeddings for each item of the batch? What do you do with it? Well, there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1957" target="_blank">00:32:37.640</a></span> | <span class="t">a few things you can do with it. What stable diffusion does, I think, is correct. I'm not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1964" target="_blank">00:32:44.960</a></span> | <span class="t">promising. I remember all these details right, is that they make their embedding dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1971" target="_blank">00:32:51.560</a></span> | <span class="t">length twice as big as the number of activations. And what they then do is we can use chunk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1984" target="_blank">00:33:04.800</a></span> | <span class="t">to take that and split it into two separate variables. So that's literally just the opposite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1990" target="_blank">00:33:10.720</a></span> | <span class="t">of concatenate. It's just two separate variables. And one of them is added to the activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=1997" target="_blank">00:33:17.700</a></span> | <span class="t">and one of them is multiplied by the activations. So this is a scale and a shift. We don't just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2007" target="_blank">00:33:27.680</a></span> | <span class="t">grab the embeddings as is, though, because each layer might want to do-- each res block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2015" target="_blank">00:33:35.000</a></span> | <span class="t">might want to do different things with them. So we have a embedding projection, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2021" target="_blank">00:33:41.400</a></span> | <span class="t">just a linear layer which allows them to be projected. So it's projected from the number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2025" target="_blank">00:33:45.920</a></span> | <span class="t">of embeddings to 2 times the number of filters so that that torch.chunk works. We also have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2035" target="_blank">00:33:55.200</a></span> | <span class="t">an activation function called silu. This is the activation function that's used in stable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2041" target="_blank">00:34:01.800</a></span> | <span class="t">diffusion. I don't think the details are particularly important. But it looks basically like a rectified</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2055" target="_blank">00:34:15.120</a></span> | <span class="t">linear with a slight curvy bit. Also known as SWISH. Also known as SWISH. And it's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2065" target="_blank">00:34:25.960</a></span> | <span class="t">equal to x times sigmoid x. And yeah, I think it's like activation functions don't make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2077" target="_blank">00:34:37.120</a></span> | <span class="t">a huge difference. But they can make things train a little better or a little faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2084" target="_blank">00:34:44.120</a></span> | <span class="t">And SWISH has been something that's worked pretty well. So a lot of people using SWISH</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2088" target="_blank">00:34:48.880</a></span> | <span class="t">or silu. I always call it SWISH. But I think silu was originally the galley paper which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2097" target="_blank">00:34:57.440</a></span> | <span class="t">had silu was where it originally was kind of invented. And maybe people didn't quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2101" target="_blank">00:35:01.320</a></span> | <span class="t">notice. And then another paper called it SWISH. And everybody called it SWISH. And then people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2105" target="_blank">00:35:05.640</a></span> | <span class="t">were like, wait, that wasn't the original paper. So I guess I should try to call it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2111" target="_blank">00:35:11.080</a></span> | <span class="t">silu. Other than that, it's just a normal res block. So we do our first conv. Then we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2119" target="_blank">00:35:19.200</a></span> | <span class="t">our embedding projection of the activation function of time steps. And so that's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2124" target="_blank">00:35:24.800</a></span> | <span class="t">to be applied to every pixel height and width. So that's why we have to add unit axes on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2134" target="_blank">00:35:34.840</a></span> | <span class="t">the height and width that it's going to cause it to broadcast across those two axes. Do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2139" target="_blank">00:35:39.400</a></span> | <span class="t">our chunk. Do the scale and shift. Then we're ready for the second conv. And then we add</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2144" target="_blank">00:35:44.800</a></span> | <span class="t">it to the input with an additional conv, one stride one conv if necessary as we've done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2152" target="_blank">00:35:52.680</a></span> | <span class="t">before if we have to change the number of channels. OK. Yeah, because I like exercising</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2160" target="_blank">00:36:00.920</a></span> | <span class="t">our Python muscles, I decided to use a second approach now for the down block and the up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2167" target="_blank">00:36:07.680</a></span> | <span class="t">block. I'm not saying which one's better or worse. We're not going to use multiple inheritance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2175" target="_blank">00:36:15.960</a></span> | <span class="t">anymore. But instead, we're going to use-- well, it's not even a decorator. It's a function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2183" target="_blank">00:36:23.200</a></span> | <span class="t">which takes a function. What we're going to do now is we're going to use funf2dd and mbrezblock</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2189" target="_blank">00:36:29.680</a></span> | <span class="t">directly. But we're going to pass them to a function called saved. The function called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2194" target="_blank">00:36:34.120</a></span> | <span class="t">saved is something which is going to take as input a callable, which could be a function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2201" target="_blank">00:36:41.920</a></span> | <span class="t">or a module or whatever. So in this case, it's a module. Takes an mbrezblock or a conv2d.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2209" target="_blank">00:36:49.480</a></span> | <span class="t">And it returns a callable. The callable it returns is identical to the callable that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2216" target="_blank">00:36:56.000</a></span> | <span class="t">passed into it, except that it saves the result, saves the activations, saves the result of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2221" target="_blank">00:37:01.640</a></span> | <span class="t">a function. Where does it save it? It's going to save it into a list in the second argument</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2230" target="_blank">00:37:10.080</a></span> | <span class="t">you pass to it, which is the block. So the save function, you're going to pass it the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2238" target="_blank">00:37:18.280</a></span> | <span class="t">module. We're going to grab the forward from it and store that away to remember what it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2243" target="_blank">00:37:23.080</a></span> | <span class="t">was. And then the function that we want to replace it with, call it underscore f, going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2249" target="_blank">00:37:29.320</a></span> | <span class="t">to take some arguments and some keyword arguments. Well, basically, it's just going to call the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2252" target="_blank">00:37:32.840</a></span> | <span class="t">original modules.forward, passing in the arguments and keyword arguments. And we're then going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2259" target="_blank">00:37:39.880</a></span> | <span class="t">to store the result in something called the saved attribute inside here. And then we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2271" target="_blank">00:37:51.320</a></span> | <span class="t">to return the result. So then we're going to replace the modules forward method with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2277" target="_blank">00:37:57.720</a></span> | <span class="t">this function and return the module. So that module's now been-- yeah, I said callable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2284" target="_blank">00:38:04.760</a></span> | <span class="t">actually. It can't be called. It has to specifically be a module, because with the forward that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2288" target="_blank">00:38:08.600</a></span> | <span class="t">we're changing. This at wraps is just something which automatically-- it's from the Python</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2294" target="_blank">00:38:14.120</a></span> | <span class="t">standard library. So it's going to copy in the documentation and everything from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2298" target="_blank">00:38:18.200</a></span> | <span class="t">original forward so that it all looks like nothing's changed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2306" target="_blank">00:38:26.280</a></span> | <span class="t">Now, where does this dot saved come from? I realized now, actually, we could make this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2310" target="_blank">00:38:30.280</a></span> | <span class="t">easier and automate it. But I forgot, didn't think of this at the time. So we have to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2316" target="_blank">00:38:36.200</a></span> | <span class="t">the saved here in the down block. It actually would have made more sense, I think, here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2322" target="_blank">00:38:42.120</a></span> | <span class="t">for it to have said if the saved attribute doesn't exist, then create it, which would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2327" target="_blank">00:38:47.160</a></span> | <span class="t">look like this. If not has atcher block comma saved block dot saved, because if you do this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2339" target="_blank">00:38:59.800</a></span> | <span class="t">then you wouldn't need this anymore. Anyway, I didn't think of that at the time. So let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2346" target="_blank">00:39:06.680</a></span> | <span class="t">pretend that's not what we do. OK, so now the downsampling conv and the resnets both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2359" target="_blank">00:39:19.880</a></span> | <span class="t">contain saved versions of modules. We don't have to do anything to make that work. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2366" target="_blank">00:39:26.120</a></span> | <span class="t">just have to call them. We can't use sequential anymore, because we have to pass in the time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2371" target="_blank">00:39:31.880</a></span> | <span class="t">step to the resnets as well. It would be easy enough to create your own sequential for things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2379" target="_blank">00:39:39.480</a></span> | <span class="t">with time steps, which passes them along. But that's not what we're doing here. Yeah, maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2388" target="_blank">00:39:48.600</a></span> | <span class="t">it makes sense for sequential to always pass along all the extra arguments. But I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2393" target="_blank">00:39:53.240</a></span> | <span class="t">think that's how they work. Yeah, so our up block is basically exactly the same as before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2401" target="_blank">00:40:01.320</a></span> | <span class="t">except we're now using ember as blocks instead. Just like before, we're going to concatenate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2406" target="_blank">00:40:06.360</a></span> | <span class="t">So that's all the same. OK, so a unit model with time embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2415" target="_blank">00:40:15.720</a></span> | <span class="t">is going to look, if we look at the forward, the thing we're passing into it now is a tuple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2425" target="_blank">00:40:25.160</a></span> | <span class="t">containing the activations and the time steps, or the segments in our case. So split them out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2431" target="_blank">00:40:31.560</a></span> | <span class="t">And what we're going to do is we're going to call that time step embedding function we wrote,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2437" target="_blank">00:40:37.800</a></span> | <span class="t">saying, OK, these are the time steps. And the number of time step embeddings we want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2444" target="_blank">00:40:44.200</a></span> | <span class="t">is equal to however many we asked for. And we're just going to set it equal to the first number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2452" target="_blank">00:40:52.200</a></span> | <span class="t">of filters. That's all that happens there. And then we want to give the model the ability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2461" target="_blank">00:41:01.400</a></span> | <span class="t">then to do whatever it wants with those, to make those work the way it wants to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2464" target="_blank">00:41:04.680</a></span> | <span class="t">And the easiest, smallest way to do that is to create a tiny little MLP. So we create a tiny</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2469" target="_blank">00:41:09.960</a></span> | <span class="t">little MLP, which is going to take the time step embeddings and return the actual embeddings to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2475" target="_blank">00:41:15.480</a></span> | <span class="t">pass into the ResNet box. So tiny little MLP is just a linear layer with-- it's thinking here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2487" target="_blank">00:41:27.160</a></span> | <span class="t">That's interesting. My linear layer by default has an activation function. I'm pretty sure we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2504" target="_blank">00:41:44.600</a></span> | <span class="t">should have act equals none here. It should be a linear layer and then an activation and then a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2510" target="_blank">00:41:50.040</a></span> | <span class="t">linear layer. So I think I've got a bug, which we will need to try rerunning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2515" target="_blank">00:41:55.160</a></span> | <span class="t">OK. It won't be the end of the world. It just means all the negatives will be lost here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2534" target="_blank">00:42:14.280</a></span> | <span class="t">Makes it half-- only half as useful. That's not great. OK. And these are the kind of things like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2543" target="_blank">00:42:23.240</a></span> | <span class="t">you know, as you can see, you've got to be super careful of, like, where do you have activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2548" target="_blank">00:42:28.040</a></span> | <span class="t">functions? Where do you have batch norms? Is it pre-activation? Is it post-activation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2553" target="_blank">00:42:33.480</a></span> | <span class="t">It trains even if you make that mistake. And in this case, it's probably not too much performance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2560" target="_blank">00:42:40.760</a></span> | <span class="t">but often it's like, oh, you've done something where you accidentally zeroed out, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2566" target="_blank">00:42:46.040</a></span> | <span class="t">all except the last few channels of your output block or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2573" target="_blank">00:42:53.000</a></span> | <span class="t">When it work tries anyway, it does its best. It uses what it can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2577" target="_blank">00:42:57.080</a></span> | <span class="t">Yeah, it makes it very difficult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2580" target="_blank">00:43:00.760</a></span> | <span class="t">To make sure you're not giving it those handicaps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2584" target="_blank">00:43:04.040</a></span> | <span class="t">Yeah. It's not like you're making a CRUD app or something and you know that it's not working</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2588" target="_blank">00:43:08.120</a></span> | <span class="t">because it crashes or because, like, it doesn't show the username or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2593" target="_blank">00:43:13.800</a></span> | <span class="t">Instead, you just get, like, slightly less good results. But since you haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2600" target="_blank">00:43:20.200</a></span> | <span class="t">done it correctly in the first place, you don't know it's the less good results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2603" target="_blank">00:43:23.640</a></span> | <span class="t">Yeah, there's not really great ways to do this. It's really nice if you can have an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2608" target="_blank">00:43:28.360</a></span> | <span class="t">existing model to compare to or something like that, which is where Kaggle competitions work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2615" target="_blank">00:43:35.080</a></span> | <span class="t">really well. Actually, if somebody's got a Kaggle result, then you know that's a really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2618" target="_blank">00:43:38.840</a></span> | <span class="t">good baseline and you can check whether yours is as good as theirs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2623" target="_blank">00:43:43.320</a></span> | <span class="t">All right. So, yeah, that's what this MLP is for. So, the down and up blocks are the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2632" target="_blank">00:43:52.920</a></span> | <span class="t">same as before. The convout is the same as before. So, yeah, so we grab our time step embedding. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2637" target="_blank">00:43:57.960</a></span> | <span class="t">that's just that outer product passed through this sinusoidal, the sine and cosine. We then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2643" target="_blank">00:44:03.400</a></span> | <span class="t">pass that through the MLP. And then we call our downsampling, passing in those embeddings each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2659" target="_blank">00:44:19.160</a></span> | <span class="t">time. You know, it's kind of interesting that we pass in the embeddings every time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2663" target="_blank">00:44:23.240</a></span> | <span class="t">in the sense I don't exactly know why we don't just pass them in at the start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2668" target="_blank">00:44:28.280</a></span> | <span class="t">And in fact, in MLP, these kinds of embeddings, I think, are generally just passed into the start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2674" target="_blank">00:44:34.440</a></span> | <span class="t">So, this is kind of a curious difference. I don't know why. It's, you know, if there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2681" target="_blank">00:44:41.800</a></span> | <span class="t">been ablation studies or whatever. Do you guys know, are there like any popular diffusion-y or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2688" target="_blank">00:44:48.760</a></span> | <span class="t">generative models with time embeddings that don't pass them in or is this pretty universal?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2695" target="_blank">00:44:55.240</a></span> | <span class="t">>> Some of the fancier architectures like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2702" target="_blank">00:45:02.200</a></span> | <span class="t">recurrent interface networks and stuff just pass in the conditioning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2706" target="_blank">00:45:06.680</a></span> | <span class="t">I'm actually not sure. Yeah, maybe they do still do it at every stage. I think some of them just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2715" target="_blank">00:45:15.240</a></span> | <span class="t">take in everything all at once up front and then do a stack of transformer blocks or something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2719" target="_blank">00:45:19.800</a></span> | <span class="t">like that. So, I don't know if it's universal, but it definitely seems like all the unit-style ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2724" target="_blank">00:45:24.840</a></span> | <span class="t">have this the time step embedding going in. >> Maybe we should try some ablations to see,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2731" target="_blank">00:45:31.320</a></span> | <span class="t">yeah, if it matters. I mean, I guess it doesn't matter too much either way. But, yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2737" target="_blank">00:45:37.800</a></span> | <span class="t">if you didn't need it at every step, then it would maybe save you a bit of compute, potentially.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2743" target="_blank">00:45:43.480</a></span> | <span class="t">Yeah, so now the upsampling, you're passing in the activations, the time step embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2750" target="_blank">00:45:50.280</a></span> | <span class="t">and that list of saved activations. So, yeah, now we have a non-attention stable diffusion unit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2761" target="_blank">00:46:01.080</a></span> | <span class="t">So, we can train that. And we can sample from it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2771" target="_blank">00:46:11.640</a></span> | <span class="t">using the same -- I just copied and pasted all the stuff from the Keras notebook that we had.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2779" target="_blank">00:46:19.880</a></span> | <span class="t">And there we have it. This is our first diffusion from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2786" target="_blank">00:46:26.440</a></span> | <span class="t">>> So, we wrote every piece of code for this diffusion model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2792" target="_blank">00:46:32.280</a></span> | <span class="t">>> Yeah, I believe so. I mean, obviously, in terms of the optimized kudor implementations of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2798" target="_blank">00:46:38.600</a></span> | <span class="t">stuff, no. But, yeah, we've written our version of everything here, I believe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2805" target="_blank">00:46:45.240</a></span> | <span class="t">>> A big milestone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2806" target="_blank">00:46:46.280</a></span> | <span class="t">>> I think so, yeah. And these FIDS are about the same as the FIDS that we get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2810" target="_blank">00:46:50.360</a></span> | <span class="t">from the stable diffusion one. They're not particularly higher or lower. They bounce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2816" target="_blank">00:46:56.200</a></span> | <span class="t">around a bit, so it's a little hard to compare. Yeah, they're basically the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2819" target="_blank">00:46:59.880</a></span> | <span class="t">Yeah, so that's -- that is an exciting step. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2831" target="_blank">00:47:11.240</a></span> | <span class="t">okay, yeah, that's probably a good time to have a five-minute break.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2836" target="_blank">00:47:16.200</a></span> | <span class="t">Yeah, okay. Let's have a five-minute break.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2840" target="_blank">00:47:20.440</a></span> | <span class="t">Okay. Normally, I would say we're back, but only some of us are back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2849" target="_blank">00:47:29.480</a></span> | <span class="t">Johnno -- Johnno's internet and electricity in same-type way is not the most reliable thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2856" target="_blank">00:47:36.280</a></span> | <span class="t">And he seems to have disappeared, but we expect him to reappear at some point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2859" target="_blank">00:47:39.960</a></span> | <span class="t">So we will kick on Johnno-less and hope that Zimbabwe's infrastructure sorts itself out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2870" target="_blank">00:47:50.360</a></span> | <span class="t">All right. So we're going to talk about attention. We're going to talk about attention for a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2878" target="_blank">00:47:58.760</a></span> | <span class="t">reasons. Reason number one, very pragmatic. We said that we would replicate stable diffusion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2884" target="_blank">00:48:04.120</a></span> | <span class="t">and the stable diffusion unit has tension in it. So we would be lying if we didn't do attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2889" target="_blank">00:48:09.160</a></span> | <span class="t">Okay. Number two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2892" target="_blank">00:48:12.840</a></span> | <span class="t">attention is one of the two basic building blocks of transformers. A transformer layer is attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2902" target="_blank">00:48:22.280</a></span> | <span class="t">attached to a one-layer MLP. We already know how to create a one-layer or one-hidden layer MLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2908" target="_blank">00:48:28.280</a></span> | <span class="t">So once we learn how to do attention, we'll know how to -- we'll know how to create transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2914" target="_blank">00:48:34.760</a></span> | <span class="t">blocks. So those are two good reasons. I'm not including a reason which is our model is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2926" target="_blank">00:48:46.760</a></span> | <span class="t">to look a lot better with attention, because I actually haven't had any success seeing any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2931" target="_blank">00:48:51.480</a></span> | <span class="t">diffusion models I've trained work better with attention. So just to set your expectations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2939" target="_blank">00:48:59.960</a></span> | <span class="t">we are going to get it all working. But regardless of whether I use our implementation of attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2945" target="_blank">00:49:05.960</a></span> | <span class="t">or the diffuser's one, it's not actually making it better. That might be because we need to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2955" target="_blank">00:49:15.560</a></span> | <span class="t">better types of attention than what diffuser's has, or it might be because it's just a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2961" target="_blank">00:49:21.160</a></span> | <span class="t">subtle difference that you only see on bigger images. I'm not sure. That's something we're still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2968" target="_blank">00:49:28.360</a></span> | <span class="t">trying to figure out. This is all pretty new. And not many people have done kind of the diffusion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2974" target="_blank">00:49:34.840</a></span> | <span class="t">the kind of ablation studies necessary to figure these things out. So yeah, so that's just life.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2982" target="_blank">00:49:42.040</a></span> | <span class="t">Anyway, so there's lots of good reasons to know about attention. We'll certainly be using it a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2986" target="_blank">00:49:46.840</a></span> | <span class="t">lot once we do an LP, which we'll be coming to pretty shortly, pretty soon. And it looks like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=2994" target="_blank">00:49:54.360</a></span> | <span class="t">Jono is reappearing as well. So that's good. Okay, so let's talk about attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3003" target="_blank">00:50:03.480</a></span> | <span class="t">The basic idea of attention is that we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3017" target="_blank">00:50:17.320</a></span> | <span class="t">an image, and we're going to be sliding a convolution kernel across that image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3025" target="_blank">00:50:25.880</a></span> | <span class="t">And obviously, we've got channels as well, or filters. And so this also has that. Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3036" target="_blank">00:50:36.760</a></span> | <span class="t">And as we bring it across, we might be, you know, we're trying to figure out like what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3045" target="_blank">00:50:45.640</a></span> | <span class="t">activations do we need to create to eventually, you know, correctly create our outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3051" target="_blank">00:50:51.240</a></span> | <span class="t">But the correct answer as to what's here may depend on something that's way over here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3060" target="_blank">00:51:00.760</a></span> | <span class="t">and/or something that's way over here. So for example, if it's a cute little bunny rabbit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3068" target="_blank">00:51:08.600</a></span> | <span class="t">and this is where its ear is, you know, and there might be two different types of bunny rabbit that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3075" target="_blank">00:51:15.640</a></span> | <span class="t">have different shaped ears, well, it'd be really nice to be able to see over here what its other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3082" target="_blank">00:51:22.040</a></span> | <span class="t">ear looks like, for instance. With just convolutions, that's challenging. It's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3089" target="_blank">00:51:29.240</a></span> | <span class="t">impossible. We talked in part one about the receptive field. And as you get deeper and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3095" target="_blank">00:51:35.640</a></span> | <span class="t">deeper in a convnet, the receptive field gets bigger and bigger. But it's, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3101" target="_blank">00:51:41.960</a></span> | <span class="t">at higher up, it probably can't see the other ear at all. So it can't put it into those kind of more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3106" target="_blank">00:51:46.920</a></span> | <span class="t">texture level layers. And later on, you know, even though this might be in the receptive field here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3114" target="_blank">00:51:54.200</a></span> | <span class="t">most of the weight, you know, the vast majority of the activations it's using is the stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3119" target="_blank">00:51:59.480</a></span> | <span class="t">immediately around it. So what attention does is it lets you take a weighted average of other pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3130" target="_blank">00:52:10.440</a></span> | <span class="t">around the image, regardless of how far away they are. And so in this case, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3138" target="_blank">00:52:18.840</a></span> | <span class="t">we might be interested in bringing in at least a few of the channels of these pixels over here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3148" target="_blank">00:52:28.280</a></span> | <span class="t">The way that attention is done in stable diffusion is pretty hacky and known to be suboptimal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3159" target="_blank">00:52:39.960</a></span> | <span class="t">But it's what we're going to implement because we're implementing stable diffusion and time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3165" target="_blank">00:52:45.400</a></span> | <span class="t">permitting. Maybe we'll look at some other options later. But the kind of attention we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3170" target="_blank">00:52:50.600</a></span> | <span class="t">be doing is 1D attention. And it was a tension that was developed for NLP. And NLP is sequences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3179" target="_blank">00:52:59.400</a></span> | <span class="t">one-dimensional sequences of tokens. So to do attention stable diffusion style,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3184" target="_blank">00:53:04.840</a></span> | <span class="t">we're going to take this image and we're going to flatten out the pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3191" target="_blank">00:53:11.400</a></span> | <span class="t">So we've got all these pixels. We're going to take this row and put it here. And then we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3198" target="_blank">00:53:18.680</a></span> | <span class="t">going to take this row, we're going to put it here. So we're just going to flatten the whole thing out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3203" target="_blank">00:53:23.400</a></span> | <span class="t">into one big vector of all the pixels of row one and then all the pixels of row two and then all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3209" target="_blank">00:53:29.880</a></span> | <span class="t">the pixels of the row three. Or maybe it's column one, column two, column three. I can't remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3212" target="_blank">00:53:32.520</a></span> | <span class="t">this row-wise or column-wise, but it's flattened out anywho. And then it's actually, for each image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3224" target="_blank">00:53:44.120</a></span> | <span class="t">it's actually a matrix, which I'm going to draw it a little bit 3D because we've got the channel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3232" target="_blank">00:53:52.280</a></span> | <span class="t">dimension as well. So this is going to be the number across this way is going to be equal to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3240" target="_blank">00:54:00.520</a></span> | <span class="t">the height times the width. And then the number this way is going to be the number of channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3253" target="_blank">00:54:13.800</a></span> | <span class="t">Okay, so how do we decide, yeah, which, you know, bring in these other pixels? Well, what we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3265" target="_blank">00:54:25.560</a></span> | <span class="t">is we basically create a weighted average of all of these pixels. So maybe these ones get a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3274" target="_blank">00:54:34.680</a></span> | <span class="t">of a negative weight and these ones get a bit of a positive weight and, you know, these get a weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3285" target="_blank">00:54:45.960</a></span> | <span class="t">kind of somewhere in between. And so we're going to have a weighted average. And so basically each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3292" target="_blank">00:54:52.520</a></span> | <span class="t">pixel, so let's say we're doing this pixel here right now, is going to equal its original pixel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3299" target="_blank">00:54:59.400</a></span> | <span class="t">plus, so let's call it x, plus the weighted average. So the sum across, so maybe this is like x, i,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3309" target="_blank">00:55:09.160</a></span> | <span class="t">plus the sum of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3313" target="_blank">00:55:13.240</a></span> | <span class="t">over all the other pixels. So from zero to the height times the width.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3327" target="_blank">00:55:27.320</a></span> | <span class="t">Sum weight times each pixel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3335" target="_blank">00:55:35.800</a></span> | <span class="t">The weights, they're going to sum to one. And so that way the, you know, the pixel value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3352" target="_blank">00:55:52.920</a></span> | <span class="t">scale isn't going to change. Well, that's not actually quite true. It's going to end up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3357" target="_blank">00:55:57.640</a></span> | <span class="t">potentially twice as big, I guess, because it's being added to the original pixel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3361" target="_blank">00:56:01.000</a></span> | <span class="t">So attention itself is not with the x plus, but the way it's done in stable diffusion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3370" target="_blank">00:56:10.120</a></span> | <span class="t">at least, is that the attention is added to the original pixel. So, yeah, now I think about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3377" target="_blank">00:56:17.640</a></span> | <span class="t">I'm not going to need to think about how this is being scaled, anyhow. So the big question is what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3387" target="_blank">00:56:27.640</a></span> | <span class="t">values to use for the weights. And the way that we calculate those is we do a matrix product.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3401" target="_blank">00:56:41.320</a></span> | <span class="t">And so our, for a particular pixel, we've got,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3412" target="_blank">00:56:52.680</a></span> | <span class="t">you know, the number of channels for that one pixel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3422" target="_blank">00:57:02.120</a></span> | <span class="t">And what we do is we can compare that to all of the number of channels for all the other pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3433" target="_blank">00:57:13.080</a></span> | <span class="t">So we've got kind of, this is pixel, let's say x1. And then we've got pixel number x2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3441" target="_blank">00:57:21.560</a></span> | <span class="t">Right, all those channels. We can take the dot product between those two things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3451" target="_blank">00:57:31.960</a></span> | <span class="t">And that will tell us how similar they are. And so one way of doing this would be to say, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3460" target="_blank">00:57:40.200</a></span> | <span class="t">okay, well, let's take that dot product for every pair of pixels. And that's very easy dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3466" target="_blank">00:57:46.600</a></span> | <span class="t">do, because that's just what the matrix product is equal to. So if we've got h by w by c and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3477" target="_blank">00:57:57.960</a></span> | <span class="t">multiply it by its transpose, h by w base, sorry, it said transpose and then totally failed to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3489" target="_blank">00:58:09.400</a></span> | <span class="t">transpose, multiply by its transpose, that will give us an h by w by h by w matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3510" target="_blank">00:58:30.440</a></span> | <span class="t">So each pixel, all the pixels are down here. And for each pixel, as long as these add up to one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3518" target="_blank">00:58:38.920</a></span> | <span class="t">then we've got to wait for each pixel. And it's easy to make these add up to one. We could just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3523" target="_blank">00:58:43.880</a></span> | <span class="t">take this matrix multiplication and take the sigmoid over the last dimension. And that makes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3534" target="_blank">00:58:54.760</a></span> | <span class="t">sorry, not sigmoid. Man, what's wrong with me? Softmax, right? Yep. And take the softmax over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3544" target="_blank">00:59:04.360</a></span> | <span class="t">the last dimension. And that will give me something that adds the sum equals one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3552" target="_blank">00:59:12.200</a></span> | <span class="t">Okay. Now, the thing is, it's not just that we want to find the places where they look the same,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3561" target="_blank">00:59:21.960</a></span> | <span class="t">where the channels are basically the same, but we want to find the places where they're, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3567" target="_blank">00:59:27.160</a></span> | <span class="t">similar in some particular way, you know? And so some particular set of channels are similar in one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3574" target="_blank">00:59:34.200</a></span> | <span class="t">to some different set of channels in another. And so, you know, in this case, we may be looking for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3579" target="_blank">00:59:39.240</a></span> | <span class="t">the pointy-earedness activations, you know, which actually represented by, you know, this, this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3587" target="_blank">00:59:47.640</a></span> | <span class="t">and this, you know, and we want to just find those. So the way we do that is before we do this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3594" target="_blank">00:59:54.360</a></span> | <span class="t">matrix product, we first put our matrix through a projection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3603" target="_blank">01:00:03.000</a></span> | <span class="t">So we just basically put our matrix through a matrix multiplication, this one. So it's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3612" target="_blank">01:00:12.680</a></span> | <span class="t">same matrix, right? But we put it through two different projections. And so that lets it pick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3617" target="_blank">01:00:17.960</a></span> | <span class="t">two different kind of sets of channels to focus on or not focus on before it decides, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3624" target="_blank">01:00:24.280</a></span> | <span class="t">of this pixel, similar to this pixel in the way we care about. And then actually, we don't even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3629" target="_blank">01:00:29.640</a></span> | <span class="t">just multiply it then by the original pixels. We also put that through a different projection as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3636" target="_blank">01:00:36.120</a></span> | <span class="t">well. So there's these different projections. Well, then projection one, projection two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3640" target="_blank">01:00:40.760</a></span> | <span class="t">and projection three. And that gives it the ability to say, like, oh, I want to compare</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3645" target="_blank">01:00:45.720</a></span> | <span class="t">these channels and, you know, these channels to these channels to find similarity. And based on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3651" target="_blank">01:00:51.160</a></span> | <span class="t">similarity, yeah, they want to pick out these channels, right? Both positive and negative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3656" target="_blank">01:00:56.280</a></span> | <span class="t">weight. So that's why there's these three different projections. And so the projections are called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3662" target="_blank">01:01:02.760</a></span> | <span class="t">A, Q, and V. Those are the projections. And so they're all being passed the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3674" target="_blank">01:01:14.440</a></span> | <span class="t">matrix. And because they're all being passed the same matrix, we call this self-attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3681" target="_blank">01:01:21.400</a></span> | <span class="t">Okay, Jono, Tindish, I know this is, I know you guys know this very well, but you also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3687" target="_blank">01:01:27.960</a></span> | <span class="t">know it's really confusing. Did you have anything to add? Change? Anything else?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3693" target="_blank">01:01:33.960</a></span> | <span class="t">Yeah, I like that you introduced this without resorting to the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3699" target="_blank">01:01:39.000</a></span> | <span class="t">let's think of this as queries at all, which I think is, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3704" target="_blank">01:01:44.120</a></span> | <span class="t">Yeah, these are actually short for key, query, and value, even though I personally don't find those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3714" target="_blank">01:01:54.520</a></span> | <span class="t">useful concepts. Yeah. You'll note on the scaling, you said, oh, so we said it so that the weight's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3721" target="_blank">01:02:01.880</a></span> | <span class="t">sum to one. And so then we'd need to worry about like, are we doubling the scale of X? Yeah. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3728" target="_blank">01:02:08.360</a></span> | <span class="t">because of that P3, aka V, that projection that can learn to scale this thing that's added to X</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3739" target="_blank">01:02:19.960</a></span> | <span class="t">appropriately. And so it's not like just doubling the size of X, it's increasing it a little bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3744" target="_blank">01:02:24.200</a></span> | <span class="t">which is why we scatter normalization in between all of these attention layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3748" target="_blank">01:02:28.680</a></span> | <span class="t">But it's not as bad as it might be because we have that V projection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3756" target="_blank">01:02:36.280</a></span> | <span class="t">Yeah, that's a good point. And if this is, if P3, or it's actually the V make projection, is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3766" target="_blank">01:02:46.040</a></span> | <span class="t">initialized such that it would have a mean of zero, then on average it should start out by not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3774" target="_blank">01:02:54.760</a></span> | <span class="t">messing with our scale. OK, so yeah, I guess I find it easier to think in terms of code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3784" target="_blank">01:03:04.440</a></span> | <span class="t">So let's look at the code. You know, there's actually not much code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3787" target="_blank">01:03:07.320</a></span> | <span class="t">I think you've got a bit of background noise too, Jono, maybe. Yes, that's much better. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3795" target="_blank">01:03:15.480</a></span> | <span class="t">So in terms of code, there's, you know, this is one of these things getting everything exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3806" target="_blank">01:03:26.840</a></span> | <span class="t">right. And it's not just right. I wanted to get it identical to the stable diffusion. So we can say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3811" target="_blank">01:03:31.640</a></span> | <span class="t">we've made it identical to stable diffusion. I've actually imported the attention block from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3816" target="_blank">01:03:36.760</a></span> | <span class="t">diffusers so we can compare. And it is so nice when you've got an existing version of something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3821" target="_blank">01:03:41.960</a></span> | <span class="t">to compare to to make sure you're getting the same results. So we're going to start off by saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3830" target="_blank">01:03:50.120</a></span> | <span class="t">let's say we've got a 16 by 16 pixel image. And this is some deeper level of activation. So it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3836" target="_blank">01:03:56.360</a></span> | <span class="t">got 32 channels with a batch size of 64. So NCHW. I'm just going to use random numbers for now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3843" target="_blank">01:04:03.640</a></span> | <span class="t">but this has the, you know, reasonable dimensions for an activation inside a batch size 64</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3849" target="_blank">01:04:09.880</a></span> | <span class="t">CNN or diffusion model or unit, whatever. OK, so the first thing we have to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3855" target="_blank">01:04:15.640</a></span> | <span class="t">is to flatten these out because, as I said, in 1D attention, this is just ignored.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3865" target="_blank">01:04:25.400</a></span> | <span class="t">So it's easy to flatten things out. You just say dot view and you pass in the dimensions of the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3871" target="_blank">01:04:31.560</a></span> | <span class="t">in this case, the three dimensions we want, which is 6432 and everything else. Minus one means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3878" target="_blank">01:04:38.040</a></span> | <span class="t">everything else. So x dot shape colon two. In this case, you know, obviously it'd be easy just to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3883" target="_blank">01:04:43.400</a></span> | <span class="t">type 6432, but I'm trying to create something that I can paste into a function later. So it's general.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3888" target="_blank">01:04:48.840</a></span> | <span class="t">So that's the first two elements, 6432. And then the star just inserts them directly in here. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3894" target="_blank">01:04:54.760</a></span> | <span class="t">6432 minus one. So 16 by 16. Now then, again, because this is all stolen from the NLP world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3904" target="_blank">01:05:04.360</a></span> | <span class="t">in the NLP world, things are, have, they call this sequence. So I'm going to call this sequence by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3912" target="_blank">01:05:12.760</a></span> | <span class="t">which we're in height by width. Sequence comes before channel, which is often called D or dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3919" target="_blank">01:05:19.160</a></span> | <span class="t">So we then transpose those last two dimensions. So we've now got batch by sequence, 16 by 16,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3927" target="_blank">01:05:27.800</a></span> | <span class="t">by channel or dimension. So N, they didn't really call this NSD sequence dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3938" target="_blank">01:05:38.120</a></span> | <span class="t">Okay, so we've got 32 channels. So we now need three different projections that go from 32</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3948" target="_blank">01:05:48.680</a></span> | <span class="t">channels in to 32 channels out. So that's just a linear layer. Okay, and just remember a linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3954" target="_blank">01:05:54.120</a></span> | <span class="t">layer is just a matrix multiply plus a bias. So there's three of them. And so they're all going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3961" target="_blank">01:06:01.560</a></span> | <span class="t">to be randomly initialized at different random numbers. We're going to call them SK, SQ, SV.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3968" target="_blank">01:06:08.040</a></span> | <span class="t">And so we can then, they're just callable. So we can then pass the exact same thing into three,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3973" target="_blank">01:06:13.320</a></span> | <span class="t">all three, because we're doing self-attention to get back our keys, queries, and values,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3978" target="_blank">01:06:18.200</a></span> | <span class="t">or K, Q, and V. I just think of them as K, Q, and V, because they're not really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3982" target="_blank">01:06:22.600</a></span> | <span class="t">keys, queries, and values to me. So then we have to do the matrix multiply by the transpose.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=3990" target="_blank">01:06:30.600</a></span> | <span class="t">And so then for every one of the 64 items in the batch, for every one of the 256 pixels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4000" target="_blank">01:06:40.200</a></span> | <span class="t">there are now 256 weights. So at least there would be if we had done softmax, which we haven't yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4005" target="_blank">01:06:45.720</a></span> | <span class="t">So we can now put that into a self-attention. As Johnno mentioned, we want to make sure that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4012" target="_blank">01:06:52.120</a></span> | <span class="t">we normalize things. So we can proper normalization here. We talked about group norm back when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4017" target="_blank">01:06:57.960</a></span> | <span class="t">talked about batch norm. So group norm is just batch norm, which has been split into a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4024" target="_blank">01:07:04.200</a></span> | <span class="t">sets of channels. Okay, so then we are going to create our K, Q, V. Yep, Johnno?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4038" target="_blank">01:07:18.280</a></span> | <span class="t">I was just going to ask, should those be just bias equals false so that they're only a matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4043" target="_blank">01:07:23.480</a></span> | <span class="t">multiplied to strictly match the traditional implementation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4048" target="_blank">01:07:28.840</a></span> | <span class="t">No, because...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4055" target="_blank">01:07:35.160</a></span> | <span class="t">Okay, they also do it that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4058" target="_blank">01:07:38.520</a></span> | <span class="t">Yeah, they have bias in their attention blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4066" target="_blank">01:07:46.600</a></span> | <span class="t">Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4072" target="_blank">01:07:52.200</a></span> | <span class="t">Okay, so we've got our QK and V, self.q, self.k, self.v being our projections.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4078" target="_blank">01:07:58.200</a></span> | <span class="t">And so to do 2D self-attention, we need to find the NCHW from our shape. We can do a normalization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4089" target="_blank">01:08:09.800</a></span> | <span class="t">We then do our flattening as discussed. We then transpose the last two dimensions. We then create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4097" target="_blank">01:08:17.480</a></span> | <span class="t">our QKV by doing the projections. And we then do the matrix multiply. Now, we've got to be a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4104" target="_blank">01:08:24.360</a></span> | <span class="t">careful now because as a result of that matrix multiply, we've changed the scale by multiplying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4110" target="_blank">01:08:30.520</a></span> | <span class="t">and adding all those things together. So if we then simply divide by the square root of the number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4118" target="_blank">01:08:38.360</a></span> | <span class="t">of filters, it turns out that you can convince yourself of this if you wish to, but that's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4123" target="_blank">01:08:43.000</a></span> | <span class="t">to return it to the original scale. We can now do the softmax across the last dimension, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4132" target="_blank">01:08:52.600</a></span> | <span class="t">multiply each of them by V. So using matrix multiply to do them all in one go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4138" target="_blank">01:08:58.280</a></span> | <span class="t">We didn't mention, but we then do one final projection. Again, just to give it the opportunity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4145" target="_blank">01:09:05.880</a></span> | <span class="t">to map things to some different scale. Shift it also if necessary. Transpose the last two back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4155" target="_blank">01:09:15.880</a></span> | <span class="t">to where they started from, and then reshape it back to where it started from, and then add it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4160" target="_blank">01:09:20.760</a></span> | <span class="t">Remember, I said it's going to be X plus. Add it back to the original. So this is actually kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4165" target="_blank">01:09:25.320</a></span> | <span class="t">self-attention ResNet style, if you like. Diffuses, if I remember correctly, does include the X plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4174" target="_blank">01:09:34.200</a></span> | <span class="t">in theirs, but some implementations, like, for example, PyTorch implementation doesn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4179" target="_blank">01:09:39.560</a></span> | <span class="t">Okay, so that's a self-attention module, and all you need to do is tell it how many channels to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4185" target="_blank">01:09:45.800</a></span> | <span class="t">attention on. And you need to tell it that because that's what we need for our four different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4192" target="_blank">01:09:52.920</a></span> | <span class="t">projections and our group and our scale. I guess, strictly speaking, it doesn't have to be stored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4200" target="_blank">01:10:00.120</a></span> | <span class="t">here. You could calculate it here, but anyway, either way is fine. Okay, so if we create a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4206" target="_blank">01:10:06.440</a></span> | <span class="t">self-attention layer, we can then call it on our little randomly generated numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4214" target="_blank">01:10:14.120</a></span> | <span class="t">And it doesn't change the shape because we transpose it back and reshape it back,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4221" target="_blank">01:10:21.160</a></span> | <span class="t">but we can see that's basically worked. We can see it creates some numbers. How do we know if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4225" target="_blank">01:10:25.160</a></span> | <span class="t">they're right? Well, we could create a diffuser's attention block. That will randomly generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4231" target="_blank">01:10:31.800</a></span> | <span class="t">a QKV projection. Sorry, actually they call something else. They call it a query, key,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4240" target="_blank">01:10:40.040</a></span> | <span class="t">value, projection, attention, and group norm. We call it QKVprogen norm. They're the same things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4246" target="_blank">01:10:46.840</a></span> | <span class="t">And so then we can just zip those tuples together. So that's going to take each pair,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4253" target="_blank">01:10:53.480</a></span> | <span class="t">first pair, second pair, third pair, and copy the weight and the bias from their attention block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4262" target="_blank">01:11:02.680</a></span> | <span class="t">Sorry, from our attention block to the diffuser's attention block. And then we can check that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4270" target="_blank">01:11:10.520</a></span> | <span class="t">give the same value, which you can see they do. So this shows us that our attention block is the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4275" target="_blank">01:11:15.480</a></span> | <span class="t">as the diffuser's attention block, which is nice. Here's a trick which neither diffusers nor PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4287" target="_blank">01:11:27.880</a></span> | <span class="t">use for reasons I don't understand, which is that we don't actually need three separate projections</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4294" target="_blank">01:11:34.200</a></span> | <span class="t">here. We could create one projection from Ni to Ni times three. That's basically doing three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4300" target="_blank">01:11:40.920</a></span> | <span class="t">projections. So we could call this QKV. And so that gives us 64 by 256 by 96 instead of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4309" target="_blank">01:11:49.720</a></span> | <span class="t">64 by 256 by 32, because it's the three sets. And then we can use chunk, which we saw earlier,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4319" target="_blank">01:11:59.560</a></span> | <span class="t">to split that into three separate variables along the last dimension to get us our QKV.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4327" target="_blank">01:12:07.240</a></span> | <span class="t">And we can then do the same thing, Q at Q dot transpose, et cetera. So here's another version</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4332" target="_blank">01:12:12.040</a></span> | <span class="t">of attention where we just have one projection for QKV, and we chunkify it into separate QK and V.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4342" target="_blank">01:12:22.360</a></span> | <span class="t">And this does the same thing. It's just a bit more concise. And it should be faster as well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4350" target="_blank">01:12:30.040</a></span> | <span class="t">at least if you're not using some kind of XLA compiler or ONX or Triton or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4356" target="_blank">01:12:36.680</a></span> | <span class="t">for normal PyTorch. This should be faster because it's doing less back and forth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4360" target="_blank">01:12:40.840</a></span> | <span class="t">between the CPU and the GPU. All right. So that's basic self-attention. This is not what's done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4376" target="_blank">01:12:56.920</a></span> | <span class="t">basically ever, however, because, in fact, the question of which pixels do I care about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4387" target="_blank">01:13:07.720</a></span> | <span class="t">depends on which channels you're referring to. Because the ones which are about, oh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4396" target="_blank">01:13:16.840</a></span> | <span class="t">what color is its ear, as opposed to how pointy is its ear, might depend more on is this bunny</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4406" target="_blank">01:13:26.280</a></span> | <span class="t">in the shade or in the sun. And so maybe you may want to look at its body over here to decide what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4413" target="_blank">01:13:33.640</a></span> | <span class="t">color to make them rather than how pointy to make it. And so, yeah, different channels need to bring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4424" target="_blank">01:13:44.040</a></span> | <span class="t">in information from different parts of the picture depending on which channel we're talking about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4431" target="_blank">01:13:51.080</a></span> | <span class="t">And so the way we do that is with multi-headed attention. And multi-headed attention actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4437" target="_blank">01:13:57.800</a></span> | <span class="t">turns out to be really simple. And conceptually, it's also really simple. What we do is we say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4445" target="_blank">01:14:05.800</a></span> | <span class="t">let's come back to when we look at C here and let's split them into four separate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4460" target="_blank">01:14:20.680</a></span> | <span class="t">vectors. One, two, three, four. Let's split them, right? And let's do the whole dot product thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4476" target="_blank">01:14:36.920</a></span> | <span class="t">on just the first part with the first part. And then do the whole dot product part with the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4486" target="_blank">01:14:46.840</a></span> | <span class="t">part with the second part and so forth, right? So we're just going to do it separately,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4493" target="_blank">01:14:53.800</a></span> | <span class="t">separate matrix multiplies for different groups of channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4498" target="_blank">01:14:58.200</a></span> | <span class="t">And the reason we do that is it then allows, yeah, different parts, different sets of channels to pull</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4511" target="_blank">01:15:11.000</a></span> | <span class="t">in different parts of the image. And so these different groups are called heads. And I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4525" target="_blank">01:15:25.080</a></span> | <span class="t">know why, but they are. Does that seem reasonable? Anything to add to that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4534" target="_blank">01:15:34.040</a></span> | <span class="t">It's maybe worth thinking about why, with just a single head, specifically the softmax starts to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4541" target="_blank">01:15:41.160</a></span> | <span class="t">come into play. Because, you know, we said it's like a weighted sum, just able to bring in information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4546" target="_blank">01:15:46.760</a></span> | <span class="t">from different parts and whatever else. But with softmax, what tends to happen is whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4552" target="_blank">01:15:52.040</a></span> | <span class="t">weight is highest gets scaled up quite dramatically. And so it's like almost like focused on just that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4558" target="_blank">01:15:58.200</a></span> | <span class="t">one thing. And then, yeah, like, as you said, Jeremy, like different channels might want to refer to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4563" target="_blank">01:16:03.160</a></span> | <span class="t">different things. And, you know, just having this one like single weight that's across all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4568" target="_blank">01:16:08.840</a></span> | <span class="t">channels means that that signal is going to be like focused on maybe only one or two things as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4574" target="_blank">01:16:14.040</a></span> | <span class="t">opposed to being able to bring in lots of different kinds of information based on the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4578" target="_blank">01:16:18.040</a></span> | <span class="t">channels. Right. I was going to measure the same thing, actually. That's a good point. So you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4586" target="_blank">01:16:26.600</a></span> | <span class="t">mentioning the second interesting important point about softmax, you know, point one is that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4592" target="_blank">01:16:32.520</a></span> | <span class="t">creates something that adds to one. But point two is that because of its e to the z, it tends to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4598" target="_blank">01:16:38.040</a></span> | <span class="t">highlight one thing very strongly. And yes, so if we had single-headed attention, your point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4605" target="_blank">01:16:45.240</a></span> | <span class="t">guys, I guess, is that you're saying it would end up basically picking nearly all one pixel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4610" target="_blank">01:16:50.840</a></span> | <span class="t">which would not be very interesting. OK, awesome. Oh, I see where everything's got thick. I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4619" target="_blank">01:16:59.720</a></span> | <span class="t">accidentally turned it into a marker. Right. OK, so multi-headed attention. I'll come back to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4632" target="_blank">01:17:12.440</a></span> | <span class="t">the details of how it's implemented in terms of, but I'm just going to mention the basic idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4638" target="_blank">01:17:18.200</a></span> | <span class="t">This is multi-headed attention. And this is identical to before, except I've just stored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4644" target="_blank">01:17:24.680</a></span> | <span class="t">one more thing, which is how many heads do you want. And then the forward is actually nearly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4653" target="_blank">01:17:33.240</a></span> | <span class="t">all the same. So this is identical, identical, identical. This is new. Identical, identical,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4662" target="_blank">01:17:42.840</a></span> | <span class="t">identical, new, identical, identical. So there's just two new lines of code, which might be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4670" target="_blank">01:17:50.280</a></span> | <span class="t">surprising, but that's all we needed to make this work. And they're also pretty wacky, interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4675" target="_blank">01:17:55.560</a></span> | <span class="t">new lines of code to look at. Conceptually, what these two lines of code do is they first,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4682" target="_blank">01:18:02.760</a></span> | <span class="t">they do the projection, right? And then they basically take the number of heads.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4701" target="_blank">01:18:21.320</a></span> | <span class="t">So we're going to do four heads. We've got 32 channels, four heads. So each head is going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4705" target="_blank">01:18:25.800</a></span> | <span class="t">contain eight channels. And they basically grab, they're going to, we're going to keep it as being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4714" target="_blank">01:18:34.520</a></span> | <span class="t">eight channels, not as 32 channels. And we're going to make each batch four times bigger, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4721" target="_blank">01:18:41.800</a></span> | <span class="t">Because the images in a batch don't combine with each other at all. They're totally separate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4730" target="_blank">01:18:50.120</a></span> | <span class="t">So instead of having one image containing 32 channels, we're going to turn that into four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4739" target="_blank">01:18:59.800</a></span> | <span class="t">images containing eight channels. And that's actually all we need, right? Because remember,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4746" target="_blank">01:19:06.040</a></span> | <span class="t">I told you that each group of channels, each head, we want to have nothing to do with each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4753" target="_blank">01:19:13.080</a></span> | <span class="t">So if we literally turn them into different images, then they can't have anything to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4758" target="_blank">01:19:18.680</a></span> | <span class="t">with each other because batches don't react to each other at all. So these rearrange,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4765" target="_blank">01:19:25.400</a></span> | <span class="t">this rearrange, and I'll explain how this works in a moment, but it's basically saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4770" target="_blank">01:19:30.360</a></span> | <span class="t">think of the channel dimension as being of H groups of D and rearrange it. So instead,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4779" target="_blank">01:19:39.640</a></span> | <span class="t">the batch channel is n groups of H and the channels is now just D. So that would be eight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4787" target="_blank">01:19:47.720</a></span> | <span class="t">instead of four by eight. And then we do everything else exactly the same way as usual,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4793" target="_blank">01:19:53.240</a></span> | <span class="t">but now that group, that the channels are split into groups of H, groups of four. And then after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4801" target="_blank">01:20:01.160</a></span> | <span class="t">that, okay, well, we were thinking of the batches as being of size n by H. Let's now think of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4807" target="_blank">01:20:07.080</a></span> | <span class="t">channels as being of size H by D. That's what these rearranges do. So let me explain how these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4814" target="_blank">01:20:14.440</a></span> | <span class="t">work. In the diffusers code, I've, can't remember if I duplicated it or just inspired by it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4822" target="_blank">01:20:22.520</a></span> | <span class="t">They've got things called heads to batch and batch to heads, which do exactly these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4826" target="_blank">01:20:26.520</a></span> | <span class="t">And so for heads to batch, they say, okay, you've got 64 per batch by 256 pixels by 32 channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4839" target="_blank">01:20:39.880</a></span> | <span class="t">Okay, let's reshape it. So you've got 64 images by 256 pixels by four heads by the rest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4854" target="_blank">01:20:54.920</a></span> | <span class="t">So that would be 32 over eight channels. So it's split it out into a separate dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4869" target="_blank">01:21:09.880</a></span> | <span class="t">And then if we transpose these two dimensions, it'll then be n by four. So n by heads by SL by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4878" target="_blank">01:21:18.120</a></span> | <span class="t">minus one. And so then we can reshape. So those first two dimensions get combined into one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4884" target="_blank">01:21:24.280</a></span> | <span class="t">So that's what heads to batch does. And batch to heads does the exact opposite, right? Reshapes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4890" target="_blank">01:21:30.680</a></span> | <span class="t">to bring the batch back to here and then heads by SL by D and then transpose it back again and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4896" target="_blank">01:21:36.680</a></span> | <span class="t">reshape it back again so that the heads gets it. So this is kind of how to do it using just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4904" target="_blank">01:21:44.360</a></span> | <span class="t">traditional PyTorch methods that we've seen before. But I wanted to show you guys this new-ish</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4912" target="_blank">01:21:52.440</a></span> | <span class="t">library called Inops, inspired as it suggests by Einstein summation notation. But it's absolutely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4918" target="_blank">01:21:58.760</a></span> | <span class="t">not Einstein summation notation. It's something different. And the main thing it has is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4922" target="_blank">01:22:02.920</a></span> | <span class="t">thing called rearrange. And rearrange is kind of like a nifty rethinking of Einstein summation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4930" target="_blank">01:22:10.600</a></span> | <span class="t">notation as a tensor rearrangement notation. And so we've got a tensor called t we created earlier,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4941" target="_blank">01:22:21.240</a></span> | <span class="t">64 by 256 by 32. And what Inops rearrange does is you pass it this specification string that says,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4951" target="_blank">01:22:31.880</a></span> | <span class="t">turn this into this. Okay, this says that I have a rank three tensor, three dimensions, three axes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4967" target="_blank">01:22:47.640</a></span> | <span class="t">containing the first dimension is of length n, the second dimension is of length s,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4977" target="_blank">01:22:57.560</a></span> | <span class="t">the third dimension is in parentheses is of length h times d, where h is eight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4984" target="_blank">01:23:04.040</a></span> | <span class="t">Okay, and then I want you to just move things around so that nothing is like broken, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=4994" target="_blank">01:23:14.120</a></span> | <span class="t">so everything's shifted correctly into the right spots so that we now have each batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5003" target="_blank">01:23:23.000</a></span> | <span class="t">is now instead n times eight, n times h. The sequence length is the same,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5010" target="_blank">01:23:30.040</a></span> | <span class="t">and d is now the number of channels. Previously the number of channels was h by d. Now it's d,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5016" target="_blank">01:23:36.360</a></span> | <span class="t">so the number of channels has been reduced by a factor of eight. And you can see it here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5020" target="_blank">01:23:40.600</a></span> | <span class="t">it's turned t from something of 64 by 256 by 32 into something of size 64 times eight by 256</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5031" target="_blank">01:23:51.480</a></span> | <span class="t">by 32 divided by eight. And so this is like really nice because, you know, a, this one line of code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5041" target="_blank">01:24:01.720</a></span> | <span class="t">to me is clearer and easier and I liked writing it better than these lines of code. But whereas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5048" target="_blank">01:24:08.040</a></span> | <span class="t">particularly nice is when I had to go the opposite direction, I literally took this, cut it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5055" target="_blank">01:24:15.800</a></span> | <span class="t">put it here and put the arrow in the middle. Like it's literally backwards, which is really nice,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5062" target="_blank">01:24:22.040</a></span> | <span class="t">right? Because we're just rearranging it in the other order. And so if we rearrange in the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5067" target="_blank">01:24:27.160</a></span> | <span class="t">order, we take our 512 by 256 by 4 thing that we just created and end up with a 64 by 256 by 32</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5074" target="_blank">01:24:34.040</a></span> | <span class="t">thing, which we started with, and we can confirm that the end thing equals, or every element equals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5081" target="_blank">01:24:41.800</a></span> | <span class="t">the first thing. So that shows me that my rearrangement has returned its original correctly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5088" target="_blank">01:24:48.760</a></span> | <span class="t">Yeah, so multi-headed attention, I've already shown you. It's the same thing as before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5094" target="_blank">01:24:54.200</a></span> | <span class="t">but pulling everything out into the batch for each head and then pulling the heads back into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5101" target="_blank">01:25:01.000</a></span> | <span class="t">the channels. So we can do multi-headed attention with 32 channels and four heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5109" target="_blank">01:25:09.640</a></span> | <span class="t">and check that all looks okay. So PyTorch has that all built in. It's called nn.multi_headed_attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5117" target="_blank">01:25:17.720</a></span> | <span class="t">Be very careful. Be more careful than me, in fact, because I keep forgetting that it actually expects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5125" target="_blank">01:25:25.880</a></span> | <span class="t">the batch to be the second dimension. So make sure you write batch first equals true</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5132" target="_blank">01:25:32.760</a></span> | <span class="t">to make batch the first dimension and that way it'll be the same as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5138" target="_blank">01:25:38.040</a></span> | <span class="t">diffusers. I mean, it might not be identical, but the same. It should be almost the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5143" target="_blank">01:25:43.880</a></span> | <span class="t">idea. And to make it self-attention, you've got to pass in three things, right? So the three things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5151" target="_blank">01:25:51.160</a></span> | <span class="t">will all be the same for self-attention. This is the thing that's going to be passed through the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5155" target="_blank">01:25:55.720</a></span> | <span class="t">Q projection, the K projection and the V projection. And you can pass different things to those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5163" target="_blank">01:26:03.640</a></span> | <span class="t">If you pass different things to those, you'll get something called cross-attention rather than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5170" target="_blank">01:26:10.120</a></span> | <span class="t">self-attention, which I'm not sure we're going to talk about until we do it in NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5175" target="_blank">01:26:15.080</a></span> | <span class="t">Just on the rearrange thing, I know that if you've been doing PyTorch and you used to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5184" target="_blank">01:26:24.040</a></span> | <span class="t">like, you really know what transpose and, you know, reshape and whatever do, then it can be a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5189" target="_blank">01:26:29.480</a></span> | <span class="t">little bit weird to see this new notation. But once you get into it, it's really, really nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5193" target="_blank">01:26:33.400</a></span> | <span class="t">And if you look at the self-attention multi-headed implementation there, you've got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5197" target="_blank">01:26:37.000</a></span> | <span class="t">dot view and dot transpose and dot reshape. It's quite fun practice. Like, if you're just saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5203" target="_blank">01:26:43.000</a></span> | <span class="t">oh, this INOPS thing looks really useful, like, take an existing implementation like this and say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5207" target="_blank">01:26:47.880</a></span> | <span class="t">oh, maybe instead of, like, can I do it instead of dot reshape or whatever, can I start replacing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5213" target="_blank">01:26:53.000</a></span> | <span class="t">these individual operations with the equivalent, like, rearrange call? And then checking at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5218" target="_blank">01:26:58.440</a></span> | <span class="t">output to the same, like, that's what helped it, like, click for me was, oh, okay. Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5223" target="_blank">01:27:03.240</a></span> | <span class="t">I can start to express, if it's just transpose, then that's a rearrange with the last two channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5228" target="_blank">01:27:08.840</a></span> | <span class="t">Yeah. I only just started using this. And I've obviously had many years of using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5236" target="_blank">01:27:16.200</a></span> | <span class="t">reshape transpose, et cetera, in Theano, TensorFlow, Keras, PyTorch, APL. And I would say within</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5247" target="_blank">01:27:27.640</a></span> | <span class="t">10 minutes, I was like, oh, I like this much better. You know, like, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5252" target="_blank">01:27:32.040</a></span> | <span class="t">fine for me at least. It didn't take too long to be convinced. It's not part of PyTorch or anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5260" target="_blank">01:27:40.040</a></span> | <span class="t">You've got to pip install it, by the way. And it seems to be becoming super popular now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5267" target="_blank">01:27:47.240</a></span> | <span class="t">at least in the kind of diffusion research crowd. Everybody seems to be using INOPS suddenly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5273" target="_blank">01:27:53.800</a></span> | <span class="t">even though it's been around for a few years. And I actually put in an issue there and asked them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5280" target="_blank">01:28:00.040</a></span> | <span class="t">to add in Einstein summation notation as well, which they've now done. So it's kind of like your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5285" target="_blank">01:28:05.560</a></span> | <span class="t">one place for everything, which is great. And it also works across</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5288" target="_blank">01:28:08.600</a></span> | <span class="t">TensorFlow and other libraries as well, which is nice. Okay. So we can now add that to our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5301" target="_blank">01:28:21.800</a></span> | <span class="t">unit. So this is basically a copy of the previous notebook, except what I've now done is I did this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5308" target="_blank">01:28:28.920</a></span> | <span class="t">at the point where it's like, oh, yeah, it turns out that cosine scheduling is better. So I'm back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5314" target="_blank">01:28:34.520</a></span> | <span class="t">to cosine schedule now. This is copied from the cosine schedule book. And we're still doing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5319" target="_blank">01:28:39.400</a></span> | <span class="t">minus 0.5 thing because we love it. And so this time, I actually decided to export stuff into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5327" target="_blank">01:28:47.960</a></span> | <span class="t">mini-AI.diffusion. So this point, I still think things are working pretty well. And so I renamed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5334" target="_blank">01:28:54.200</a></span> | <span class="t">unit.com to pre-con, since it's a better name. Time step embedding has been exported. Up sample's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5340" target="_blank">01:29:00.440</a></span> | <span class="t">been exported. This is like a pre-act linear version exported. I tried using an n.multihead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5351" target="_blank">01:29:11.160</a></span> | <span class="t">attention, and it didn't work very well for some reason. So I haven't figured out why that is yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5357" target="_blank">01:29:17.720</a></span> | <span class="t">So I'm using, yeah, this self-attention, which we just talked about. Multiheaded self-attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5365" target="_blank">01:29:25.800</a></span> | <span class="t">You know, just the scale, we have to divide the number of channels by the number of heads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5373" target="_blank">01:29:33.640</a></span> | <span class="t">because the effective number of heads is, you know, divided across n heads.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5384" target="_blank">01:29:44.120</a></span> | <span class="t">And instead of specifying n heads, yeah, you specify attention channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5387" target="_blank">01:29:47.480</a></span> | <span class="t">So if you have like 32, n_I is 32, attention channels is 8, then you calculate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5391" target="_blank">01:29:51.640</a></span> | <span class="t">Yeah, that's what diffusers does, I think. It's not what an n.multihead attention does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5396" target="_blank">01:29:56.920</a></span> | <span class="t">And actually, I think n_I divided by n_I divided by attention chance is actually just equal to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5403" target="_blank">01:30:03.720</a></span> | <span class="t">attention chance. So I could have just put that probably. Anyway, never mind. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5414" target="_blank">01:30:14.040</a></span> | <span class="t">So okay, so that's all copied in from the previous one. The only thing that's different here is I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5419" target="_blank">01:30:19.880</a></span> | <span class="t">haven't got the dot view minus one thing here. So this is a 1D self-attention, and then 2D</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5428" target="_blank">01:30:28.600</a></span> | <span class="t">self-attention just adds the dot view before we call forward and then dot reshape it back again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5441" target="_blank">01:30:41.960</a></span> | <span class="t">So yeah, so we've got 1D and 2D self-attention. Okay, so now our MRes block has one extra thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5448" target="_blank">01:30:48.360</a></span> | <span class="t">you can pass in, which is attention channels. And so if you pass in attention channels, we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5454" target="_blank">01:30:54.760</a></span> | <span class="t">to create something called self.attention, which is a self-attention 2D layer with the right number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5460" target="_blank">01:31:00.360</a></span> | <span class="t">of filters and the requested number of channels. And so this is all identical to what we've seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5468" target="_blank">01:31:08.040</a></span> | <span class="t">before, except if we've got attention, then we add it. Oh yeah, and the attention that I did here is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5475" target="_blank">01:31:15.080</a></span> | <span class="t">the non-res-netty version. So we have to do x plus because that's more flexible. You can then choose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5481" target="_blank">01:31:21.880</a></span> | <span class="t">to have it or not have it this way. Okay, so that's an MRes block with attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5488" target="_blank">01:31:28.520</a></span> | <span class="t">And so now our down block, you have to tell it how many attention channels you want,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5495" target="_blank">01:31:35.560</a></span> | <span class="t">because the res blocks need that. The up block, you have to know how many attention channels you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5501" target="_blank">01:31:41.160</a></span> | <span class="t">want, because again the res blocks need that. And so now the unit model, where does the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5507" target="_blank">01:31:47.960</a></span> | <span class="t">go? Okay, we have to say how many attention channels you want. And then you say which index</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5514" target="_blank">01:31:54.920</a></span> | <span class="t">block do you start adding attention? So why don't we, so then what happens is the attention is done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5525" target="_blank">01:32:05.400</a></span> | <span class="t">here. Each res-net has attention. And so as we discussed, you just do the normal res and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5536" target="_blank">01:32:16.440</a></span> | <span class="t">the attention, right? And if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5539" target="_blank">01:32:19.720</a></span> | <span class="t">put that in at the very start, right, let's say you've got a 256 by 256 image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5554" target="_blank">01:32:34.840</a></span> | <span class="t">Then you're going to end up with this matrix here. It's going to be 256 by 256 on one side</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5568" target="_blank">01:32:48.360</a></span> | <span class="t">and 256 by 256 on the other side and contain however many, you know, NF channels. That's huge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5583" target="_blank">01:33:03.640</a></span> | <span class="t">And you have to back prop through it. So you have to store all that to allow back prop to happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5589" target="_blank">01:33:09.240</a></span> | <span class="t">It's going to explode your memory. So what happens is basically nobody puts attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5596" target="_blank">01:33:16.360</a></span> | <span class="t">in the first layers. So that's why I've added a attention start, which is like at which block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5605" target="_blank">01:33:25.640</a></span> | <span class="t">do we start adding attention and it's not zero for the reason we just discussed. Another way you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5614" target="_blank">01:33:34.760</a></span> | <span class="t">could do this is to say like at what grid size should you start adding attention? And so generally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5620" target="_blank">01:33:40.440</a></span> | <span class="t">speaking, people say when you get to 16 by 16, that's a good time to start adding attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5627" target="_blank">01:33:47.400</a></span> | <span class="t">Although stable diffusion adds it at 32 by 32 because remember they're using latents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5634" target="_blank">01:33:54.680</a></span> | <span class="t">which we'll see very shortly I guess in the next lesson. So it starts at 64 by 64 and then they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5640" target="_blank">01:34:00.760</a></span> | <span class="t">add attention at 32 by 32. So we're again, we're replicating stable diffusion here. Stable diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5645" target="_blank">01:34:05.800</a></span> | <span class="t">uses attention start at index one. So we, you know, when we go self.down, dot append, the down block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5653" target="_blank">01:34:13.160</a></span> | <span class="t">has zero attention channels if we're not up to that block yet. And ditto on the up block,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5663" target="_blank">01:34:23.480</a></span> | <span class="t">except we have to count from the end blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5666" target="_blank">01:34:26.040</a></span> | <span class="t">Now I think about it, that should have attention as well, the mid block. So that's missing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5679" target="_blank">01:34:39.480</a></span> | <span class="t">Yeah, so the forward actually doesn't change at all for attention. It's only the in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5690" target="_blank">01:34:50.040</a></span> | <span class="t">Yeah, so we can train that. And so previously, yeah, we got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5695" target="_blank">01:34:55.080</a></span> | <span class="t">without attention, we got to 137. And with attention,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5704" target="_blank">01:35:04.680</a></span> | <span class="t">oh, we can't compare directly because we've changed from Keras to cosine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5713" target="_blank">01:35:13.560</a></span> | <span class="t">We can compare the sampling though. So we're getting, what are we getting? 4, 5, 5, 5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5721" target="_blank">01:35:21.320</a></span> | <span class="t">It's very hard to tell if it's any better or not because,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5727" target="_blank">01:35:27.160</a></span> | <span class="t">well, again, you know, our cosine schedule is better. But yeah, when I've done kind of direct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5734" target="_blank">01:35:34.520</a></span> | <span class="t">like with like, I haven't managed to find any obvious improvements from adding attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5741" target="_blank">01:35:41.560</a></span> | <span class="t">But I mean, it's doing fine, you know, 4 is great. Yeah. All right. So then finally,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5750" target="_blank">01:35:50.440</a></span> | <span class="t">did you guys want to add anything before we go into a conditional model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5753" target="_blank">01:35:53.160</a></span> | <span class="t">I was just going to make a note that, like, I guess, just to clarify,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5758" target="_blank">01:35:58.120</a></span> | <span class="t">with the attention, part of the motivation was certainly to do the sort of spatial mixing and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5764" target="_blank">01:36:04.120</a></span> | <span class="t">kind of like, yeah, to get from different parts of the image and mix it. But then the problem is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5769" target="_blank">01:36:09.800</a></span> | <span class="t">if it's too early, where you do have one of, you know, the more individual pixels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5774" target="_blank">01:36:14.360</a></span> | <span class="t">then the memory is very high. So it seems like you have to get that balance of where you don't,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5781" target="_blank">01:36:21.400</a></span> | <span class="t">you kind of want it to be early. So you can do some of that mixing, but you don't want to be too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5785" target="_blank">01:36:25.080</a></span> | <span class="t">early, where then the memory usage is, is too high. So it seems like there is certainly kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5790" target="_blank">01:36:30.680</a></span> | <span class="t">of the balance of trying to find maybe that right place where to add attention into your network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5796" target="_blank">01:36:36.200</a></span> | <span class="t">So I just thought I was just thinking about that. And maybe that's a point worth noting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5800" target="_blank">01:36:40.680</a></span> | <span class="t">Yeah, for sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5801" target="_blank">01:36:41.560</a></span> | <span class="t">There is a trick, which is like what they do in, for example, vision transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5806" target="_blank">01:36:46.280</a></span> | <span class="t">or the DIT, the diffusion with transformers, which is that if you take like an eight by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5814" target="_blank">01:36:54.920</a></span> | <span class="t">eight patch of the image, and you flatten that all out, or you run that through some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5819" target="_blank">01:36:59.960</a></span> | <span class="t">like convolutional thing to turn it into a one by one by some larger number of channels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5825" target="_blank">01:37:05.000</a></span> | <span class="t">but you can reduce the spatial dimension by increasing the number of channels. And that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5830" target="_blank">01:37:10.760</a></span> | <span class="t">gets you down to like a manageable size where you can then start doing attention as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5834" target="_blank">01:37:14.360</a></span> | <span class="t">So that's another trick is like patching, where you take a patch of the image and you focus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5838" target="_blank">01:37:18.680</a></span> | <span class="t">on that as some number, like some embedding dimension or whatever you like to think of it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5843" target="_blank">01:37:23.560</a></span> | <span class="t">that as a one by one rather than an eight by eight or a 16 by 16. And so that's how,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5849" target="_blank">01:37:29.000</a></span> | <span class="t">like you'll see, you know, 32 by 32 patch models, like some of the smaller clip models or 14 by 14</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5855" target="_blank">01:37:35.800</a></span> | <span class="t">patch for some of the larger like DIT classification models and things like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5860" target="_blank">01:37:40.360</a></span> | <span class="t">So that's another Yeah, I guess that's the yeah, that's mainly used when you have like a full</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5865" target="_blank">01:37:45.800</a></span> | <span class="t">transformer network, I guess. And then this is one where we have that sort of incorporating the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5871" target="_blank">01:37:51.240</a></span> | <span class="t">attention into convolutional network. So there's certainly, I guess, yeah, for different sorts of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5876" target="_blank">01:37:56.840</a></span> | <span class="t">networks, different tricks. But yeah. Yeah. And I haven't decided yet if we're going to look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5886" target="_blank">01:38:06.200</a></span> | <span class="t">the IT or not. Maybe we should based on what you're describing. I was just going to mention,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5891" target="_blank">01:38:11.080</a></span> | <span class="t">though, that since you mentioned transformers, we've actually now got everything we need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5898" target="_blank">01:38:18.600</a></span> | <span class="t">create a transformer. Here's a transformer block with embeddings. A transformer block with embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5905" target="_blank">01:38:25.160</a></span> | <span class="t">is exactly the same embeddings that we've seen before. And then we add attention, as we've seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5911" target="_blank">01:38:31.000</a></span> | <span class="t">before, there's a scale and shift. And then we pass it through an MLP, which is just a linear layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5920" target="_blank">01:38:40.680</a></span> | <span class="t">an activation, a normalize, and a linear layer. For whatever reason, this is, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5926" target="_blank">01:38:46.760</a></span> | <span class="t">GALU, which is just another activation function, is what people always use in transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5934" target="_blank">01:38:54.120</a></span> | <span class="t">For reasons I suspect don't quite make sense in vision, everybody uses layer norm. And again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5938" target="_blank">01:38:58.440</a></span> | <span class="t">I was just trying to replicate an existing paper. But this is just a standard MLP. So if you do,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5943" target="_blank">01:39:03.160</a></span> | <span class="t">so in fact, if we get rid of the embeddings, just to show you a true pure transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5957" target="_blank">01:39:17.960</a></span> | <span class="t">Okay, here's a pure transformer block. So it's just normalize, attention, add, normalize,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5965" target="_blank">01:39:25.240</a></span> | <span class="t">multi-layer perceptron, add. That's all a transformer block is. And then what's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5970" target="_blank">01:39:30.200</a></span> | <span class="t">transformer network? A transformer network is a sequential of transformers. And so in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5975" target="_blank">01:39:35.960</a></span> | <span class="t">diffusion model, I replaced my mid block with a list of sequential transformer blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5986" target="_blank">01:39:46.280</a></span> | <span class="t">So that is a transformer network. And to prove it, this is another version in which I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=5996" target="_blank">01:39:56.280</a></span> | <span class="t">replaced that entire thing with the PyTorch transformers encoder. This is called encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6003" target="_blank">01:40:03.960</a></span> | <span class="t">This is just taken from PyTorch. And so that's the encoder. And I just replaced it with that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6013" target="_blank">01:40:13.000</a></span> | <span class="t">So yeah, we've now built transformers. Now, okay, why aren't we using them right now? And why did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6020" target="_blank">01:40:20.600</a></span> | <span class="t">I just say, I'm not even sure if we're going to do VIT, which is vision transformers. The reason is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6025" target="_blank">01:40:25.240</a></span> | <span class="t">that transformers, you know, they're doing something very interesting, right? Which is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6034" target="_blank">01:40:34.680</a></span> | <span class="t">remember, we're just doing 1D versions here, right? So transformers are taking something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6044" target="_blank">01:40:44.760</a></span> | <span class="t">where we've got a sequence, right? Which in our case is pixels height by width, but we'll just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6050" target="_blank">01:40:50.120</a></span> | <span class="t">call it the sequence. And everything in that sequence has a bunch of channels, right, for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6056" target="_blank">01:40:56.520</a></span> | <span class="t">dimensions, right? I'm not going to draw them all, but you get the idea. And so for each element of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6065" target="_blank">01:41:05.720</a></span> | <span class="t">that sequence, which in our case, it's just some particular pixel, right? And these are just the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6071" target="_blank">01:41:11.480</a></span> | <span class="t">filters, channels, activations, whatever, activations, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6079" target="_blank">01:41:19.080</a></span> | <span class="t">What we're doing is the, we first do attention, which, you know, remember there's a projection for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6086" target="_blank">01:41:26.200</a></span> | <span class="t">each. So like it's mixing the channels a little bit, but just putting that aside, the main thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6090" target="_blank">01:41:30.680</a></span> | <span class="t">it's doing is each row is getting mixed together, you know, into a weighted average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6106" target="_blank">01:41:46.760</a></span> | <span class="t">And then after we do that, we put the whole thing through a multi-layer perceptron. And what the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6113" target="_blank">01:41:53.080</a></span> | <span class="t">multi-layer perceptron does is it entirely looks at each pixel on its own. So let's say this one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6125" target="_blank">01:42:05.480</a></span> | <span class="t">right, and puts that through linear, activation, norm, linear, which we call an MLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6136" target="_blank">01:42:16.840</a></span> | <span class="t">And so a transformer network is a bunch of transformer layers. So it's basically going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6147" target="_blank">01:42:27.800</a></span> | <span class="t">attention, MLP, attention, MLP, attention, et cetera, et cetera, MLP. That's all it's doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6157" target="_blank">01:42:37.160</a></span> | <span class="t">And so in other words, it's mixing together the pixels or sequences, and then it's mixing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6168" target="_blank">01:42:48.920</a></span> | <span class="t">together the channels. Then it's mixing together the sequences and then mixing together the channels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6173" target="_blank">01:42:53.240</a></span> | <span class="t">and it's repeating this over and over. Because of the projections being done in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6180" target="_blank">01:43:00.520</a></span> | <span class="t">attention, it's not just mixing the pixels, but it's kind of, it's largely mixing the pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6187" target="_blank">01:43:07.400</a></span> | <span class="t">And so this combination is very, very, very flexible. And it's flexible enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6199" target="_blank">01:43:19.640</a></span> | <span class="t">that it provably can actually approximate any convolution that you can think of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6206" target="_blank">01:43:26.040</a></span> | <span class="t">given enough layers and enough time and learning the right parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6214" target="_blank">01:43:34.040</a></span> | <span class="t">The problem is that for this to approximate a combination requires a lot of data and a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6225" target="_blank">01:43:45.560</a></span> | <span class="t">layers and a lot of parameters and a lot of compute. So if you try to use this, so this is a transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6234" target="_blank">01:43:54.760</a></span> | <span class="t">network, transformer architecture. If you pass images into this, so pass an image in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6244" target="_blank">01:44:04.280</a></span> | <span class="t">and try to predict, say from ImageNet, the class of the image. So use SGD to try and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6253" target="_blank">01:44:13.640</a></span> | <span class="t">find weights for these attention projections and MLPs. If you do that on ImageNet, you will end up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6261" target="_blank">01:44:21.160</a></span> | <span class="t">with something that does indeed predict the class of each image, but it does it poorly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6265" target="_blank">01:44:25.560</a></span> | <span class="t">Now it doesn't do it poorly because it's not capable of approximating a convolution. It</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6271" target="_blank">01:44:31.240</a></span> | <span class="t">does it poorly because ImageNet, the entire ImageNet as in ImageNet 1k is not big enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6278" target="_blank">01:44:38.200</a></span> | <span class="t">to for a transformer to learn how to do this. However, if you pass it a much bigger data set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6286" target="_blank">01:44:46.360</a></span> | <span class="t">many times larger than ImageNet 1k, then it will learn to approximate this very well. And in fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6294" target="_blank">01:44:54.280</a></span> | <span class="t">it'll figure out a way of doing something like convolutions that are actually better than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6298" target="_blank">01:44:58.920</a></span> | <span class="t">convolutions. And so if you then take that, so that's going to be called a vision transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6306" target="_blank">01:45:06.120</a></span> | <span class="t">or VIT that's been pre-trained on a data set much bigger than ImageNet, and then you fine tune it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6312" target="_blank">01:45:12.600</a></span> | <span class="t">on ImageNet, you will end up with something that is actually better than ResNet. And the reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6321" target="_blank">01:45:21.880</a></span> | <span class="t">it's better than ResNet is because these combinations, right, which together when combined</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6332" target="_blank">01:45:32.920</a></span> | <span class="t">can approximate a convolution, these transformers, you know, convolutions are our best guess as to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6341" target="_blank">01:45:41.080</a></span> | <span class="t">like a good way to kind of represent the calculations we should do on images. But there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6347" target="_blank">01:45:47.480</a></span> | <span class="t">actually much more sophisticated things you could do, you know, if you're a computer and you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6351" target="_blank">01:45:51.960</a></span> | <span class="t">figure these things out better than a human can. And so a VIT actually figures out things that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6356" target="_blank">01:45:56.920</a></span> | <span class="t">even better than convolutions. And so when you fine tune ImageNet using a very, you know, a VIT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6365" target="_blank">01:46:05.080</a></span> | <span class="t">that's been pre-trained on lots of data, then that's why it ends up being better than a ResNet. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6371" target="_blank">01:46:11.560</a></span> | <span class="t">that's why, you know, the things I'm showing you are not the things that contain transformers and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6382" target="_blank">01:46:22.200</a></span> | <span class="t">diffusion because to make that work would require pre-training on a really, really large data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6389" target="_blank">01:46:29.880</a></span> | <span class="t">for a really, really long amount of time. So anyway, so we might only come to transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6398" target="_blank">01:46:38.040</a></span> | <span class="t">well not in a very long time, but when we do them in NLP in vision, maybe we'll cover them briefly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6407" target="_blank">01:46:47.240</a></span> | <span class="t">you know, they're very interesting to use as pre-trained models. The main thing to know about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6412" target="_blank">01:46:52.440</a></span> | <span class="t">them is, yeah, a VIT, you know, which is a really successful and when pre-trained on lots of data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6419" target="_blank">01:46:59.080</a></span> | <span class="t">which they all are nowadays, is a very successful architecture. But like literally the VIT paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6423" target="_blank">01:47:03.960</a></span> | <span class="t">says, oh, we wondered what would happen if we take a totally plain 1D transformer, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6431" target="_blank">01:47:11.000</a></span> | <span class="t">and convert it and make it work on images with as few changes as possible. So everything we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6437" target="_blank">01:47:17.800</a></span> | <span class="t">learned about attention today and MLPs applies directly because they haven't changed anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6445" target="_blank">01:47:25.480</a></span> | <span class="t">And so one of the things you might realize that means is that you can't use a VIT that was trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6454" target="_blank">01:47:34.040</a></span> | <span class="t">on 224 by 224 pixel images on 128 by 128 pixel images because, you know, all of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6461" target="_blank">01:47:41.960</a></span> | <span class="t">self-attention things are the wrong size, you know, and specifically the problem is actually the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6473" target="_blank">01:47:53.560</a></span> | <span class="t">actually it's not really the attention, let me take that back. All of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6482" target="_blank">01:48:02.120</a></span> | <span class="t">position embeddings are the wrong size. And so actually that's something I, sorry,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6486" target="_blank">01:48:06.600</a></span> | <span class="t">I forgot to mention, is that in transformers the first thing you do is you always take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6495" target="_blank">01:48:15.640</a></span> | <span class="t">your, you know, these pixels and you add to them a positional embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6504" target="_blank">01:48:24.840</a></span> | <span class="t">And that's done, I mean, it can be done lots of different ways, but the most popular way is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6510" target="_blank">01:48:30.440</a></span> | <span class="t">identical to what we did for the time step embedding is the sinusoidal embedding. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6516" target="_blank">01:48:36.040</a></span> | <span class="t">that's specific, you know, to how many pixels there are in your image. So yeah, that's an example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6527" target="_blank">01:48:47.320</a></span> | <span class="t">it's one of the things that makes VITs a little tricky. Anyway, hopefully, yeah, you get the idea</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6532" target="_blank">01:48:52.520</a></span> | <span class="t">that we've got all the pieces that we need. Okay, so with that discussion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6548" target="_blank">01:49:08.280</a></span> | <span class="t">I think that's officially taken us over time. So maybe we should do the conditional next time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6560" target="_blank">01:49:20.040</a></span> | <span class="t">Do you know what actually it's tiny? Let's just quickly do it now. You guys got time?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6564" target="_blank">01:49:24.840</a></span> | <span class="t">Yeah. Okay. So let's just, yeah, let's finish by doing a conditional model. So for a conditional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6571" target="_blank">01:49:31.640</a></span> | <span class="t">model, we're going to basically say I want something where I can say draw me the number,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6578" target="_blank">01:49:38.120</a></span> | <span class="t">sorry, draw me a shirt, or draw me some pants, or draw me some sandals. So we're going to pick one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6584" target="_blank">01:49:44.040</a></span> | <span class="t">of the 10 fashion MNIST classes and create an image of a particular class. To do that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6593" target="_blank">01:49:53.960</a></span> | <span class="t">we need to know what class each thing is. Now, we already know what class each thing is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6605" target="_blank">01:50:05.080</a></span> | <span class="t">because it's the Y label, which way back in the beginning of time, we set, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6614" target="_blank">01:50:14.360</a></span> | <span class="t">it's just called the label. So that tells you what category it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6619" target="_blank">01:50:19.240</a></span> | <span class="t">So we're going to change our collation function. So we call noisify as per usual. That gives us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6629" target="_blank">01:50:29.480</a></span> | <span class="t">our noised image, our time step, and our noise. But we're also going to then add to that tuple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6640" target="_blank">01:50:40.600</a></span> | <span class="t">what kind of fashion item is this. And so the first tuple will be noised image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6648" target="_blank">01:50:48.440</a></span> | <span class="t">noise, and label, and then the dependent variable as per usual is the noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6656" target="_blank">01:50:56.280</a></span> | <span class="t">And so what's going to happen now when we call our unit, which is now a conditioned unit model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6660" target="_blank">01:51:00.920</a></span> | <span class="t">is the input is now going to contain not just the activations and the time step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6668" target="_blank">01:51:08.520</a></span> | <span class="t">but it's also going to contain the label. Okay, that label will be a number between zero and nine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6674" target="_blank">01:51:14.120</a></span> | <span class="t">So how do we convert the number between zero and nine into a vector which represents that number?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6681" target="_blank">01:51:21.080</a></span> | <span class="t">Well, we know exactly how to do that in n.embedding. Okay, so we did that lots in part one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6687" target="_blank">01:51:27.320</a></span> | <span class="t">So let's make it exactly, you know, the same size as our time embedding. So n number of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6702" target="_blank">01:51:42.920</a></span> | <span class="t">activations in the embedding. It's going to be the same as our time step embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6710" target="_blank">01:51:50.920</a></span> | <span class="t">And so that's convenient. So now in the forward we do our time step embedding as usual.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6715" target="_blank">01:51:55.240</a></span> | <span class="t">We'll pass the labels into our conditioned embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6720" target="_blank">01:52:00.520</a></span> | <span class="t">The time embedding we will put through the embedding let LPN before, and then we're just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6726" target="_blank">01:52:06.520</a></span> | <span class="t">going to add them together. And that's it, right? So this now represents a combination of the time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6732" target="_blank">01:52:12.680</a></span> | <span class="t">and the fashion item plus. And then everything else is identical in both parts. So all we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6741" target="_blank">01:52:21.400</a></span> | <span class="t">added is this one thing. And then we just literally sum it up. So we've now got a joint</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6748" target="_blank">01:52:28.360</a></span> | <span class="t">embedding representing two things. And then, yeah, and then we train it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6753" target="_blank">01:52:33.320</a></span> | <span class="t">And, you know, interestingly, it looks like the loss, well, it ends up a bit the same,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6761" target="_blank">01:52:41.640</a></span> | <span class="t">but you don't often see 0.031. It is a bit easier for it to do a conditional embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6768" target="_blank">01:52:48.360</a></span> | <span class="t">model because you're telling it what it is. It just makes it a bit easier. So then to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6773" target="_blank">01:52:53.160</a></span> | <span class="t">conditional sampling, you have to pass in what type of thing do you want from these labels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6786" target="_blank">01:53:06.600</a></span> | <span class="t">And so then we create a vector just containing that number repeated over many times there on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6799" target="_blank">01:53:19.080</a></span> | <span class="t">the batch. And we pass it to our model. So our model has now learned how to denoise something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6807" target="_blank">01:53:27.160</a></span> | <span class="t">of type C. And so now if we say like, oh, trust me, this noise contains is a noised image of type C,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6814" target="_blank">01:53:34.600</a></span> | <span class="t">it should hopefully denoise it into something of type C. That's all there is to it. There's no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6821" target="_blank">01:53:41.960</a></span> | <span class="t">magic there. So, yeah, that's all we have to do to change the sampling. So we didn't have to change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6828" target="_blank">01:53:48.760</a></span> | <span class="t">DDIM step at all, right? Literally all we did was we added this one line of code and we added it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6835" target="_blank">01:53:55.960</a></span> | <span class="t">there. So now we can say, okay, let's say class ID zero, which is t-shirt top. So we'll pass that to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6844" target="_blank">01:54:04.280</a></span> | <span class="t">sample. And there we go. Well, everything looks like t-shirts and tops. Yeah, okay. I'm glad we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6856" target="_blank">01:54:16.760</a></span> | <span class="t">didn't leave that till next time because we can now say we have successfully replicated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6865" target="_blank">01:54:25.320</a></span> | <span class="t">everything in stable diffusion, except for being able to create whole sentences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6872" target="_blank">01:54:32.520</a></span> | <span class="t">which is what we do with clip. Getting really close. Yes. Well, except the clip requires</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6879" target="_blank">01:54:39.720</a></span> | <span class="t">all of NLP. So I guess we'll, we might do that next or depending on how research goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6893" target="_blank">01:54:53.160</a></span> | <span class="t">All right. We still need a latent diffusion part. Oh, good point. Latents. Okay. We'll definitely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6900" target="_blank">01:55:00.600</a></span> | <span class="t">do that next time. So let's see. Yeah. So we'll do a VAE and latent diffusion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6908" target="_blank">01:55:08.040</a></span> | <span class="t">which isn't enough for one lesson. So maybe some of the research I'm doing will end up in the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6914" target="_blank">01:55:14.600</a></span> | <span class="t">lesson as well. Yes. Okay. Thanks for the reminder. Although we've already kind of done auto-encoders,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6922" target="_blank">01:55:22.120</a></span> | <span class="t">so VAEs are going to be pretty, pretty easy. Well, thank you, Tanishka and Johnno. Fantastic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6930" target="_blank">01:55:30.280</a></span> | <span class="t">comments, as always. Glad your internet/power reappeared, Johnno. Back up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=DH5bp6zTPB4&t=6942" target="_blank">01:55:42.600</a></span> | <span class="t">All right. Thanks, gang. Cool. Thanks, everybody. That was great.</span></div></div></body></html>