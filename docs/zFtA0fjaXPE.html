<html><head><title>Stanford XCS224U: NLU I NLP Methods and Metrics, Part 4: Datasets I Spring 2023</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford XCS224U: NLU I NLP Methods and Metrics, Part 4: Datasets I Spring 2023</h2><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE"><img src="https://i.ytimg.com/vi/zFtA0fjaXPE/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=24">0:24</a> Water and air for our field<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=67">1:7</a> We ask a lot of our datasets<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=142">2:22</a> Benchmarks saturate faster than ever<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=196">3:16</a> Limitations found more quickly<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=333">5:33</a> Central questions<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=391">6:31</a> Trade-offs<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=536">8:56</a> DynaSent: Prompts increase naturalism<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=632">10:32</a> Adversarial examples or the most common cases?<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=680">11:20</a> Dynamics of adversarial datasets<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=688">11:28</a> Counterpoint from Bowman and Dahl (2021)<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=840">14:0</a> The job to be done<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=914">15:14</a> Major lessons thus far<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1013">16:53</a> Synthetic or naturalistic benchmarks<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1088">18:8</a> Negation as a learning target<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1141">19:1</a> MONLI: A slightly synthetic dataset<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1192">19:52</a> MONLI as challenge dataset<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1241">20:41</a> The value of messy data<br><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1268">21:8</a> Other vital issues for datasets<br><br><div style="text-align: left;"><a href="./zFtA0fjaXPE.html">Whisper Transcript</a> | <a href="./transcript_zFtA0fjaXPE.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Welcome back everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=6" target="_blank">00:00:06.040</a></span> | <span class="t">This is part 4 in our series on methods and metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=8" target="_blank">00:00:08.960</a></span> | <span class="t">We're going to talk about datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=10" target="_blank">00:00:10.820</a></span> | <span class="t">In the previous two screencasts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=12" target="_blank">00:00:12.520</a></span> | <span class="t">we really got in the weeds around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=14" target="_blank">00:00:14.320</a></span> | <span class="t">classifier and generation metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=16" target="_blank">00:00:16.520</a></span> | <span class="t">I want to pop up a level now and talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=18" target="_blank">00:00:18.800</a></span> | <span class="t">conceptually about the role that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=20" target="_blank">00:00:20.920</a></span> | <span class="t">datasets play in our field and how we construct them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=23" target="_blank">00:00:23.940</a></span> | <span class="t">This is really a central topic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=26" target="_blank">00:00:26.280</a></span> | <span class="t">In this context, I'd like to mention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=28" target="_blank">00:00:28.000</a></span> | <span class="t">this quotation from the famous oceanographer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=30" target="_blank">00:00:30.400</a></span> | <span class="t">and explorer Jacques Cousteau.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=32" target="_blank">00:00:32.140</a></span> | <span class="t">Cousteau said, "Water and air,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=33" target="_blank">00:00:33.920</a></span> | <span class="t">the two essential fluids on which all life depends."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=36" target="_blank">00:00:36.940</a></span> | <span class="t">My analogy here is that datasets are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=39" target="_blank">00:00:39.340</a></span> | <span class="t">the resource on which all progress in the field of NLP depends.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=43" target="_blank">00:00:43.480</a></span> | <span class="t">Now, Cousteau's quotation actually continues,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=46" target="_blank">00:00:46.280</a></span> | <span class="t">"Have become global garbage cans, which is worrisome."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=49" target="_blank">00:00:49.640</a></span> | <span class="t">For datasets, I think there are some in the field who would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=52" target="_blank">00:00:52.280</a></span> | <span class="t">make the analogy extend to this worrisome aspect,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=55" target="_blank">00:00:55.100</a></span> | <span class="t">but I feel optimistic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=56" target="_blank">00:00:56.560</a></span> | <span class="t">I feel we've learned a lot about how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=58" target="_blank">00:00:58.400</a></span> | <span class="t">develop datasets effectively and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=60" target="_blank">00:01:00.060</a></span> | <span class="t">have more datasets than ever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=62" target="_blank">00:01:02.000</a></span> | <span class="t">I think things are on a good trajectory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=64" target="_blank">00:01:04.380</a></span> | <span class="t">as long as we're thoughtful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=65" target="_blank">00:01:05.940</a></span> | <span class="t">But it really is important that we get this right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=68" target="_blank">00:01:08.520</a></span> | <span class="t">because we ask so much of our datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=71" target="_blank">00:01:11.320</a></span> | <span class="t">We use them to optimize models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=73" target="_blank">00:01:13.800</a></span> | <span class="t">to evaluate models, to compare models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=77" target="_blank">00:01:17.360</a></span> | <span class="t">to enable new capabilities in models via training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=80" target="_blank">00:01:20.960</a></span> | <span class="t">to measure field-wide progress,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=83" target="_blank">00:01:23.520</a></span> | <span class="t">and for fundamental aspects of scientific inquiry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=86" target="_blank">00:01:26.680</a></span> | <span class="t">This list is pretty much everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=88" target="_blank">00:01:28.680</a></span> | <span class="t">that we do in the field of NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=90" target="_blank">00:01:30.520</a></span> | <span class="t">All of it depends on datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=92" target="_blank">00:01:32.360</a></span> | <span class="t">You can see it's important that we get these datasets right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=95" target="_blank">00:01:35.400</a></span> | <span class="t">After all, if we don't,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=96" target="_blank">00:01:36.820</a></span> | <span class="t">then we've got a very shaky foundation and we might be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=99" target="_blank">00:01:39.200</a></span> | <span class="t">tricking ourselves when we think we're making a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=101" target="_blank">00:01:41.920</a></span> | <span class="t">progress because datasets really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=104" target="_blank">00:01:44.920</a></span> | <span class="t">are in a way the fundamental instrument.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=107" target="_blank">00:01:47.780</a></span> | <span class="t">I like this quotation from Aravind Joshi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=110" target="_blank">00:01:50.120</a></span> | <span class="t">The late great Aravind Joshi had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=112" target="_blank">00:01:52.440</a></span> | <span class="t">the analogy that datasets are like the telescopes of our field.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=116" target="_blank">00:01:56.280</a></span> | <span class="t">When he said this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=117" target="_blank">00:01:57.640</a></span> | <span class="t">this was back in around 2007,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=119" target="_blank">00:01:59.640</a></span> | <span class="t">he was actually expressing a concern.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=121" target="_blank">00:02:01.480</a></span> | <span class="t">He said that NLP-ers were like astronomers who want to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=124" target="_blank">00:02:04.880</a></span> | <span class="t">the stars but refuse to build any telescopes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=128" target="_blank">00:02:08.240</a></span> | <span class="t">Aravind indeed did try to lead the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=131" target="_blank">00:02:11.260</a></span> | <span class="t">toward creating more datasets and valuing dataset contributions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=135" target="_blank">00:02:15.200</a></span> | <span class="t">I think he would be pleased with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=137" target="_blank">00:02:17.160</a></span> | <span class="t">the current state of the field when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=138" target="_blank">00:02:18.640</a></span> | <span class="t">have more datasets than ever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=141" target="_blank">00:02:21.360</a></span> | <span class="t">In that context though, it's worth mentioning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=144" target="_blank">00:02:24.040</a></span> | <span class="t">this plot that I've used a few times in this course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=146" target="_blank">00:02:26.760</a></span> | <span class="t">under the heading of benchmark saturating faster than ever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=150" target="_blank">00:02:30.320</a></span> | <span class="t">Remember along this chart, along the x-axis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=152" target="_blank">00:02:32.520</a></span> | <span class="t">I have time going back to the 90s and the y-axis is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=156" target="_blank">00:02:36.000</a></span> | <span class="t">a normalized measure of distance from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=157" target="_blank">00:02:37.940</a></span> | <span class="t">our so-called human performance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=159" target="_blank">00:02:39.800</a></span> | <span class="t">although we've talked about what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=161" target="_blank">00:02:41.360</a></span> | <span class="t">human performance actually means here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=163" target="_blank">00:02:43.640</a></span> | <span class="t">When some people look at this chart,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=165" target="_blank">00:02:45.460</a></span> | <span class="t">they see a story of progress where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=167" target="_blank">00:02:47.520</a></span> | <span class="t">the benchmarks are indeed saturating faster than ever before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=171" target="_blank">00:02:51.080</a></span> | <span class="t">I think we can't deny that that is evident here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=174" target="_blank">00:02:54.800</a></span> | <span class="t">But the other aspect of this is just the worrisome fact that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=178" target="_blank">00:02:58.360</a></span> | <span class="t">none of the systems that are represented in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=180" target="_blank">00:03:00.520</a></span> | <span class="t">this chart are superhuman in any meaningful sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=183" target="_blank">00:03:03.880</a></span> | <span class="t">The fundamental problem there might be that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=186" target="_blank">00:03:06.320</a></span> | <span class="t">our datasets are simply not up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=188" target="_blank">00:03:08.720</a></span> | <span class="t">to the task of measuring what we want them to measure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=192" target="_blank">00:03:12.320</a></span> | <span class="t">For a alternative perspective on this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=195" target="_blank">00:03:15.660</a></span> | <span class="t">let's talk about the limitations that we find in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=198" target="_blank">00:03:18.400</a></span> | <span class="t">these datasets and we do indeed find them more quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=201" target="_blank">00:03:21.460</a></span> | <span class="t">Again, for this slide along the x-axis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=203" target="_blank">00:03:23.840</a></span> | <span class="t">I have time stretching back into the 90s.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=206" target="_blank">00:03:26.560</a></span> | <span class="t">So far I have one dataset represented,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=208" target="_blank">00:03:28.940</a></span> | <span class="t">the Penn Treebank, which is a collection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=210" target="_blank">00:03:30.840</a></span> | <span class="t">of syntactic parses for sentences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=213" target="_blank">00:03:33.060</a></span> | <span class="t">It drove progress on syntactic parsing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=215" target="_blank">00:03:35.600</a></span> | <span class="t">for decades for maybe too long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=218" target="_blank">00:03:38.280</a></span> | <span class="t">The dots here, the red dots are papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=221" target="_blank">00:03:41.200</a></span> | <span class="t">that are finding errors in the Penn Treebank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=223" target="_blank">00:03:43.840</a></span> | <span class="t">Most of these papers trace to work by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=226" target="_blank">00:03:46.120</a></span> | <span class="t">Detmar Meurer and colleagues and hat tip to them for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=229" target="_blank">00:03:49.360</a></span> | <span class="t">really thinking carefully about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=231" target="_blank">00:03:51.120</a></span> | <span class="t">the quality of the data and trying to improve it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=233" target="_blank">00:03:53.780</a></span> | <span class="t">But one thing that's noteworthy for me is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=236" target="_blank">00:03:56.160</a></span> | <span class="t">despite the very long timeline,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=237" target="_blank">00:03:57.760</a></span> | <span class="t">there are relatively few papers and they're all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=239" target="_blank">00:03:59.800</a></span> | <span class="t">just about errors in the parse trees.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=242" target="_blank">00:04:02.720</a></span> | <span class="t">Let's fast forward to SNLI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=244" target="_blank">00:04:04.780</a></span> | <span class="t">the Stanford Natural Language Inference Benchmark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=247" target="_blank">00:04:07.460</a></span> | <span class="t">This was launched in 2015 and right away,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=250" target="_blank">00:04:10.520</a></span> | <span class="t">you get an outpouring of papers that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=252" target="_blank">00:04:12.660</a></span> | <span class="t">finding limitations in this dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=255" target="_blank">00:04:15.080</a></span> | <span class="t">It's actually rarer to find papers pointing out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=258" target="_blank">00:04:18.060</a></span> | <span class="t">errors in the era of natural language understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=260" target="_blank">00:04:20.400</a></span> | <span class="t">and error is harder to define.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=262" target="_blank">00:04:22.520</a></span> | <span class="t">But we can identify things like artifacts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=265" target="_blank">00:04:25.200</a></span> | <span class="t">those are the orange dots,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=266" target="_blank">00:04:26.620</a></span> | <span class="t">and biases, those are the blue dots,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=268" target="_blank">00:04:28.960</a></span> | <span class="t">as well as gaps in the dataset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=270" target="_blank">00:04:30.680</a></span> | <span class="t">as I've given in that maroon color.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=272" target="_blank">00:04:32.780</a></span> | <span class="t">There are lots of dots here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=274" target="_blank">00:04:34.240</a></span> | <span class="t">compared with the Penn Treebank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=275" target="_blank">00:04:35.960</a></span> | <span class="t">A similar story holds for SQuAD.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=278" target="_blank">00:04:38.040</a></span> | <span class="t">It was launched soon after SNLI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=280" target="_blank">00:04:40.320</a></span> | <span class="t">and again, you get a bunch of papers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=282" target="_blank">00:04:42.380</a></span> | <span class="t">in this case, pointing out artifacts in the dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=285" target="_blank">00:04:45.580</a></span> | <span class="t">Then finally, for another illustration,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=287" target="_blank">00:04:47.540</a></span> | <span class="t">ImageNet is an interesting case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=289" target="_blank">00:04:49.140</a></span> | <span class="t">It was launched in 2009,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=291" target="_blank">00:04:51.020</a></span> | <span class="t">which feels like a previous era of dataset generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=294" target="_blank">00:04:54.500</a></span> | <span class="t">For a while, it got to lead a quiet life as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=297" target="_blank">00:04:57.540</a></span> | <span class="t">a trusted benchmark just like the PTB did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=300" target="_blank">00:05:00.940</a></span> | <span class="t">But then you get an outpouring of papers identifying things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=304" target="_blank">00:05:04.800</a></span> | <span class="t">like biases and errors and artifacts and gaps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=308" target="_blank">00:05:08.900</a></span> | <span class="t">We've entered into this era in which if you are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=311" target="_blank">00:05:11.520</a></span> | <span class="t">successful with your benchmark and you get a lot of users,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=314" target="_blank">00:05:14.640</a></span> | <span class="t">people will also find limitations quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=317" target="_blank">00:05:17.620</a></span> | <span class="t">I think that is a healthy dynamic that we should embrace.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=320" target="_blank">00:05:20.340</a></span> | <span class="t">It's a little bit hard to take as the creator of a dataset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=323" target="_blank">00:05:23.660</a></span> | <span class="t">but ultimately, I think we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=325" target="_blank">00:05:25.380</a></span> | <span class="t">see that this is a marker of progress,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=327" target="_blank">00:05:27.420</a></span> | <span class="t">this skeptical inquiry about these fundamental devices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=333" target="_blank">00:05:33.060</a></span> | <span class="t">To keep things succinct here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=336" target="_blank">00:05:36.040</a></span> | <span class="t">I'm going to identify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=337" target="_blank">00:05:37.140</a></span> | <span class="t">three central questions that I'll address for datasets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=339" target="_blank">00:05:39.980</a></span> | <span class="t">and then I'll list out some more at the end of the screencast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=343" target="_blank">00:05:43.140</a></span> | <span class="t">First question, should we rely on naturalistic data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=347" target="_blank">00:05:47.040</a></span> | <span class="t">like data that you scrape from a website</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=349" target="_blank">00:05:49.220</a></span> | <span class="t">or extract from an existing database,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=351" target="_blank">00:05:51.860</a></span> | <span class="t">or should we turn to crowdsourcing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=354" target="_blank">00:05:54.100</a></span> | <span class="t">It's a commonly debated question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=355" target="_blank">00:05:55.700</a></span> | <span class="t">My answer will be, use both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=358" target="_blank">00:05:58.200</a></span> | <span class="t">Second question, should we use adversarial examples or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=361" target="_blank">00:06:01.740</a></span> | <span class="t">benchmarks that consist only of the most common cases?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=365" target="_blank">00:06:05.060</a></span> | <span class="t">Another thing that's hotly debated,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=366" target="_blank">00:06:06.960</a></span> | <span class="t">and my answer is both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=368" target="_blank">00:06:08.900</a></span> | <span class="t">Third question, should we use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=371" target="_blank">00:06:11.260</a></span> | <span class="t">synthetic benchmarks or naturalistic benchmarks?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=374" target="_blank">00:06:14.260</a></span> | <span class="t">A lot of people in the field think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=375" target="_blank">00:06:15.700</a></span> | <span class="t">synthetic benchmarks are fundamentally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=377" target="_blank">00:06:17.660</a></span> | <span class="t">problematic and that we should use only naturalistic ones,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=381" target="_blank">00:06:21.260</a></span> | <span class="t">but you can probably anticipate my answer at this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=384" target="_blank">00:06:24.300</a></span> | <span class="t">I think both of them have a role to play.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=386" target="_blank">00:06:26.580</a></span> | <span class="t">I'll substantiate all three of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=388" target="_blank">00:06:28.420</a></span> | <span class="t">these both as we move through the screencast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=391" target="_blank">00:06:31.380</a></span> | <span class="t">Let's start with that question of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=394" target="_blank">00:06:34.060</a></span> | <span class="t">naturalistic data versus crowdsourcing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=396" target="_blank">00:06:36.740</a></span> | <span class="t">The reason I answer both is that this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=398" target="_blank">00:06:38.580</a></span> | <span class="t">basically about trade-offs for me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=400" target="_blank">00:06:40.420</a></span> | <span class="t">For naturalistic datasets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=402" target="_blank">00:06:42.160</a></span> | <span class="t">which you could call found or curated,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=404" target="_blank">00:06:44.260</a></span> | <span class="t">like you scrape a website or do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=406" target="_blank">00:06:46.380</a></span> | <span class="t">some work to harvest examples from a website,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=409" target="_blank">00:06:49.160</a></span> | <span class="t">you have abundance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=411" target="_blank">00:06:51.300</a></span> | <span class="t">It's probably inexpensive to gather</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=413" target="_blank">00:06:53.540</a></span> | <span class="t">these examples and they will be genuine in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=415" target="_blank">00:06:55.780</a></span> | <span class="t">some sense because they were presumably not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=417" target="_blank">00:06:57.780</a></span> | <span class="t">created for the sake of your experiment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=419" target="_blank">00:06:59.680</a></span> | <span class="t">but rather for some naturalistic purpose,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=421" target="_blank">00:07:01.900</a></span> | <span class="t">some genuine communicative purpose.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=424" target="_blank">00:07:04.980</a></span> | <span class="t">On the other hand, these are also weaknesses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=427" target="_blank">00:07:07.980</a></span> | <span class="t">The dataset will be uncontrolled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=429" target="_blank">00:07:09.700</a></span> | <span class="t">You're at the mercy of what you observe in the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=432" target="_blank">00:07:12.020</a></span> | <span class="t">It will be limited in terms of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=433" target="_blank">00:07:13.700</a></span> | <span class="t">the kind of information that you can gather.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=436" target="_blank">00:07:16.180</a></span> | <span class="t">It will be maybe intrusive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=438" target="_blank">00:07:18.660</a></span> | <span class="t">It's probably not the case that you got opt-in from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=441" target="_blank">00:07:21.960</a></span> | <span class="t">every single person who contributed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=443" target="_blank">00:07:23.660</a></span> | <span class="t">data point for this dataset that you've created.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=446" target="_blank">00:07:26.500</a></span> | <span class="t">In some sense, you might have a deep concern</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=449" target="_blank">00:07:29.480</a></span> | <span class="t">about the rights of the people who contributed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=452" target="_blank">00:07:32.580</a></span> | <span class="t">Let's contrast this with crowdsourcing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=454" target="_blank">00:07:34.860</a></span> | <span class="t">I've called this lab-grown.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=456" target="_blank">00:07:36.300</a></span> | <span class="t">This is a more artificial thing that you do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=458" target="_blank">00:07:38.460</a></span> | <span class="t">This could be highly controlled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=460" target="_blank">00:07:40.300</a></span> | <span class="t">because you set up the task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=462" target="_blank">00:07:42.300</a></span> | <span class="t">It could be privacy preserving in the sense that you could just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=465" target="_blank">00:07:45.060</a></span> | <span class="t">make sure everyone who contributes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=466" target="_blank">00:07:46.940</a></span> | <span class="t">knows that they're contributing to the dataset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=469" target="_blank">00:07:49.260</a></span> | <span class="t">and you could even offer them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=470" target="_blank">00:07:50.860</a></span> | <span class="t">the opportunity to remove themselves at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=472" target="_blank">00:07:52.860</a></span> | <span class="t">a later date if they decide that that's important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=475" target="_blank">00:07:55.820</a></span> | <span class="t">This will be genuinely expressive because you can have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=478" target="_blank">00:07:58.980</a></span> | <span class="t">crowd workers in principle do even very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=481" target="_blank">00:08:01.420</a></span> | <span class="t">complicated things to get data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=483" target="_blank">00:08:03.260</a></span> | <span class="t">that you wouldn't observe in the wild.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=485" target="_blank">00:08:05.780</a></span> | <span class="t">But then you have the corresponding weaknesses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=488" target="_blank">00:08:08.180</a></span> | <span class="t">This will be scarce.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=489" target="_blank">00:08:09.140</a></span> | <span class="t">You'll never have enough crowdsource</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=490" target="_blank">00:08:10.860</a></span> | <span class="t">data and it will be expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=493" target="_blank">00:08:13.220</a></span> | <span class="t">In addition, it can get very contrived.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=495" target="_blank">00:08:15.820</a></span> | <span class="t">You're having people do things that are very unnatural,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=499" target="_blank">00:08:19.020</a></span> | <span class="t">not things that they would do as a matter of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=501" target="_blank">00:08:21.700</a></span> | <span class="t">with communication, but rather things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=503" target="_blank">00:08:23.320</a></span> | <span class="t">that you set them up to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=505" target="_blank">00:08:25.100</a></span> | <span class="t">The results of this might feel contrived also in the sense that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=508" target="_blank">00:08:28.540</a></span> | <span class="t">you know the crowd workers are trying to please you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=511" target="_blank">00:08:31.940</a></span> | <span class="t">the person who launched the task,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=513" target="_blank">00:08:33.660</a></span> | <span class="t">and that might be a goal that's very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=515" target="_blank">00:08:35.420</a></span> | <span class="t">different from the one that you actually have in mind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=518" target="_blank">00:08:38.740</a></span> | <span class="t">For me, looking at these trade-offs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=521" target="_blank">00:08:41.540</a></span> | <span class="t">the question is how could we balance all these things?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=524" target="_blank">00:08:44.140</a></span> | <span class="t">I do think that we can find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=526" target="_blank">00:08:46.180</a></span> | <span class="t">hybrid models that allow us to be both genuine and expressive,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=530" target="_blank">00:08:50.820</a></span> | <span class="t">and to preserve in general a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=532" target="_blank">00:08:52.700</a></span> | <span class="t">the strengths across these two and minimize the weaknesses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=536" target="_blank">00:08:56.300</a></span> | <span class="t">I've shown you an example of this already.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=538" target="_blank">00:08:58.860</a></span> | <span class="t">For Dynascent round 2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=541" target="_blank">00:09:01.020</a></span> | <span class="t">we had two conditions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=543" target="_blank">00:09:03.060</a></span> | <span class="t">One, where workers just wrote a text from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=545" target="_blank">00:09:05.620</a></span> | <span class="t">scratch to try to fool a top performing model for sentiment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=549" target="_blank">00:09:09.060</a></span> | <span class="t">and another condition where we gave them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=551" target="_blank">00:09:11.260</a></span> | <span class="t">existing sentences that they could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=552" target="_blank">00:09:12.980</a></span> | <span class="t">edit in order to achieve that goal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=555" target="_blank">00:09:15.500</a></span> | <span class="t">Fundamentally, I think the editing condition offers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=559" target="_blank">00:09:19.360</a></span> | <span class="t">much more naturalism while still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=560" target="_blank">00:09:20.940</a></span> | <span class="t">giving us the results that we wanted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=562" target="_blank">00:09:22.980</a></span> | <span class="t">For that prompt condition,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=564" target="_blank">00:09:24.980</a></span> | <span class="t">I would first observe that they did edit the text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=567" target="_blank">00:09:27.820</a></span> | <span class="t">We see a wide range of different edit distances</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=570" target="_blank">00:09:30.380</a></span> | <span class="t">between the original and the thing they produced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=573" target="_blank">00:09:33.100</a></span> | <span class="t">That seems healthy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=574" target="_blank">00:09:34.500</a></span> | <span class="t">Then this is more important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=576" target="_blank">00:09:36.100</a></span> | <span class="t">For example, in terms of length,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=578" target="_blank">00:09:38.500</a></span> | <span class="t">we find that the no prompt examples were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=580" target="_blank">00:09:40.880</a></span> | <span class="t">very short compared to the prompt ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=583" target="_blank">00:09:43.700</a></span> | <span class="t">The prompt ones have lengths that are more like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=586" target="_blank">00:09:46.620</a></span> | <span class="t">just naturally occurring sentences that we would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=589" target="_blank">00:09:49.180</a></span> | <span class="t">harvest in domain from a site like Yelp.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=592" target="_blank">00:09:52.140</a></span> | <span class="t">Here's a similar thing for vocabulary size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=594" target="_blank">00:09:54.880</a></span> | <span class="t">The no prompt condition is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=596" target="_blank">00:09:56.660</a></span> | <span class="t">very limited in terms of its vocabulary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=599" target="_blank">00:09:59.860</a></span> | <span class="t">whereas we get much more diversity for the prompt condition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=603" target="_blank">00:10:03.040</a></span> | <span class="t">approaching the diversity of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=605" target="_blank">00:10:05.020</a></span> | <span class="t">vocabulary for naturally occurring cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=608" target="_blank">00:10:08.300</a></span> | <span class="t">This looks like a clear win for prompting which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=610" target="_blank">00:10:10.860</a></span> | <span class="t">mixes naturalism with things we do in the lab.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=613" target="_blank">00:10:13.980</a></span> | <span class="t">The result was really wonderful examples that would be hard to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=618" target="_blank">00:10:18.620</a></span> | <span class="t">observe that do all sorts of interesting things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=621" target="_blank">00:10:21.580</a></span> | <span class="t">linguistically and also play</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=623" target="_blank">00:10:23.500</a></span> | <span class="t">with non-literal language use and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=626" target="_blank">00:10:26.540</a></span> | <span class="t">I think the hybrid model gave us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=628" target="_blank">00:10:28.460</a></span> | <span class="t">the best of both worlds in some sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=631" target="_blank">00:10:31.740</a></span> | <span class="t">Let's move to our second question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=634" target="_blank">00:10:34.300</a></span> | <span class="t">Should we use adversarial examples or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=636" target="_blank">00:10:36.740</a></span> | <span class="t">just benchmarks that contain the most common cases?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=639" target="_blank">00:10:39.900</a></span> | <span class="t">Remember, my answer is both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=641" target="_blank">00:10:41.680</a></span> | <span class="t">Just as a reminder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=643" target="_blank">00:10:43.100</a></span> | <span class="t">we talked about this in a previous unit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=645" target="_blank">00:10:45.060</a></span> | <span class="t">For standard evaluations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=646" target="_blank">00:10:46.620</a></span> | <span class="t">you create a dataset from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=648" target="_blank">00:10:48.300</a></span> | <span class="t">a single model independent process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=650" target="_blank">00:10:50.520</a></span> | <span class="t">and divide it into trained dev test.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=652" target="_blank">00:10:52.920</a></span> | <span class="t">Whereas for adversarial assessment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=655" target="_blank">00:10:55.400</a></span> | <span class="t">we have a separate test set created in a way that you suspect or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=659" target="_blank">00:10:59.180</a></span> | <span class="t">know will be challenging given</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=661" target="_blank">00:11:01.220</a></span> | <span class="t">your system and the way it was developed initially.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=664" target="_blank">00:11:04.260</a></span> | <span class="t">Then for adversarial datasets in general,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=667" target="_blank">00:11:07.020</a></span> | <span class="t">this would be trained dev test where all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=669" target="_blank">00:11:09.700</a></span> | <span class="t">those elements were guided by attempts by people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=672" target="_blank">00:11:12.340</a></span> | <span class="t">usually to fool a top-performing model or set of models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=677" target="_blank">00:11:17.180</a></span> | <span class="t">These are the comparisons that we're thinking about here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=680" target="_blank">00:11:20.460</a></span> | <span class="t">I mentioned for you before that there are a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=683" target="_blank">00:11:23.000</a></span> | <span class="t">these fully adversarial datasets covering a wide range of domains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=688" target="_blank">00:11:28.180</a></span> | <span class="t">I think that's been fruitful and I think it's a lesson of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=691" target="_blank">00:11:31.400</a></span> | <span class="t">that literature that we're seeing lots of good results,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=693" target="_blank">00:11:33.640</a></span> | <span class="t">especially from adversarial training and testing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=696" target="_blank">00:11:36.700</a></span> | <span class="t">But there is an alternative perspective out there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=699" target="_blank">00:11:39.340</a></span> | <span class="t">and I think the most vocal of that perspective is Bowman and Dahl 2021.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=704" target="_blank">00:11:44.760</a></span> | <span class="t">I'll offer you some quotes and you should definitely check out the paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=708" target="_blank">00:11:48.680</a></span> | <span class="t">They write under the heading of adversarial examples not being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=712" target="_blank">00:11:52.080</a></span> | <span class="t">a panacea that adversarial filtering can systematically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=716" target="_blank">00:11:56.880</a></span> | <span class="t">eliminate coverage of linguistic phenomena or skills that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=720" target="_blank">00:12:00.080</a></span> | <span class="t">necessary for the task but already well-solved by the adversary model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=724" target="_blank">00:12:04.320</a></span> | <span class="t">This mode-seeking as opposed to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=726" target="_blank">00:12:06.720</a></span> | <span class="t">mass covering behavior by adversarial filtering,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=729" target="_blank">00:12:09.560</a></span> | <span class="t">if left unchecked, tends to reduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=731" target="_blank">00:12:11.760</a></span> | <span class="t">dataset diversity and thus make validity harder to achieve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=735" target="_blank">00:12:15.560</a></span> | <span class="t">I actually frankly think that this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=737" target="_blank">00:12:17.640</a></span> | <span class="t">a totally reasonable perspective and the disconnect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=740" target="_blank">00:12:20.240</a></span> | <span class="t">here is the notion of adversarial filtering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=743" target="_blank">00:12:23.560</a></span> | <span class="t">That is certainly not something I would advocate for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=746" target="_blank">00:12:26.480</a></span> | <span class="t">If you think about Dynascent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=748" target="_blank">00:12:28.220</a></span> | <span class="t">our training and Devon test sets all contain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=751" target="_blank">00:12:31.240</a></span> | <span class="t">a mixture of cases that were adversarial and cases that the model actually got right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=756" target="_blank">00:12:36.320</a></span> | <span class="t">more like the mode-seeking behavior that they're talking about here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=759" target="_blank">00:12:39.940</a></span> | <span class="t">I do think you could damage a model by doing adversarial filtering,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=763" target="_blank">00:12:43.480</a></span> | <span class="t">especially for training, because I think you could put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=766" target="_blank">00:12:46.240</a></span> | <span class="t">the model in a very unusual state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=769" target="_blank">00:12:49.440</a></span> | <span class="t">But again, that's not something I was arguing for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=772" target="_blank">00:12:52.600</a></span> | <span class="t">I was arguing for the both perspective,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=775" target="_blank">00:12:55.120</a></span> | <span class="t">have benchmarks that contain both the adversarial cases and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=779" target="_blank">00:12:59.760</a></span> | <span class="t">the truly normal mode-seeking cases that they're mentioning here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=784" target="_blank">00:13:04.400</a></span> | <span class="t">I would not leave this pressure unchecked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=787" target="_blank">00:13:07.320</a></span> | <span class="t">They also write, "This position paper argues that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=790" target="_blank">00:13:10.360</a></span> | <span class="t">concerns about standard benchmarks that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=792" target="_blank">00:13:12.240</a></span> | <span class="t">motivate methods like adversarial filtering are justified,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=795" target="_blank">00:13:15.360</a></span> | <span class="t">but that they can and should be addressed directly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=797" target="_blank">00:13:17.920</a></span> | <span class="t">and that it is possible and reasonable to do so in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=800" target="_blank">00:13:20.240</a></span> | <span class="t">the context of static IID evaluation."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=803" target="_blank">00:13:23.200</a></span> | <span class="t">Again, let's set aside the distracting thing about filtering,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=807" target="_blank">00:13:27.000</a></span> | <span class="t">and focus on what they claim here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=809" target="_blank">00:13:29.000</a></span> | <span class="t">which is that you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=810" target="_blank">00:13:30.520</a></span> | <span class="t">if you have a massive benchmark,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=813" target="_blank">00:13:33.140</a></span> | <span class="t">will simply by virtue of having that massive benchmark,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=816" target="_blank">00:13:36.680</a></span> | <span class="t">cover all of the relevant phenomena.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=819" target="_blank">00:13:39.640</a></span> | <span class="t">I actually just think that that's factually incorrect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=822" target="_blank">00:13:42.360</a></span> | <span class="t">I think it is very difficult given the complexity of language to develop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=826" target="_blank">00:13:46.280</a></span> | <span class="t">a benchmark that is so large that just as a matter of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=829" target="_blank">00:13:49.720</a></span> | <span class="t">you've covered all the hard cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=832" target="_blank">00:13:52.200</a></span> | <span class="t">The role of adversarial training examples could be to help us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=836" target="_blank">00:13:56.200</a></span> | <span class="t">fill in those gaps in a much more efficient way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=839" target="_blank">00:13:59.880</a></span> | <span class="t">Because remember, the job to be done is a complicated one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=844" target="_blank">00:14:04.600</a></span> | <span class="t">Let's focus on the domain of sentiment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=846" target="_blank">00:14:06.760</a></span> | <span class="t">Yes, we need our models to get normal cases like the food was good, correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=852" target="_blank">00:14:12.160</a></span> | <span class="t">But we also need them to deal with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=854" target="_blank">00:14:14.560</a></span> | <span class="t">these complicated shifts in perspective as in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=857" target="_blank">00:14:17.140</a></span> | <span class="t">my sister hated the food but she's massively wrong,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=860" target="_blank">00:14:20.240</a></span> | <span class="t">or the cookies seem dry to my boss but I couldn't disagree more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=864" target="_blank">00:14:24.600</a></span> | <span class="t">We also need them to get things like non-literal language use,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=868" target="_blank">00:14:28.240</a></span> | <span class="t">like breakfast is really good if you're trying to feed it to dogs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=871" target="_blank">00:14:31.280</a></span> | <span class="t">That's some sarcasm or irony.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=873" target="_blank">00:14:33.180</a></span> | <span class="t">As well as really creative things that people do with language like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=876" target="_blank">00:14:36.840</a></span> | <span class="t">worthy of gasps of foodgasms,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=879" target="_blank">00:14:39.240</a></span> | <span class="t">where we get a new use of a suffix here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=881" target="_blank">00:14:41.860</a></span> | <span class="t">We can all immediately intuitive what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=884" target="_blank">00:14:44.040</a></span> | <span class="t">this means it's a positive statement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=886" target="_blank">00:14:46.980</a></span> | <span class="t">But we know models will struggle with this innovative use of language,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=891" target="_blank">00:14:51.160</a></span> | <span class="t">and we need to push them to overcome that hurdle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=894" target="_blank">00:14:54.100</a></span> | <span class="t">If you just do standard data collection,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=896" target="_blank">00:14:56.360</a></span> | <span class="t">you might not see any of these examples or certainly not in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=899" target="_blank">00:14:59.520</a></span> | <span class="t">the density that you need to see them to improve our systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=903" target="_blank">00:15:03.120</a></span> | <span class="t">That's why I would just introduce a measure of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=906" target="_blank">00:15:06.280</a></span> | <span class="t">adversarialness into train, dev, and test.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=909" target="_blank">00:15:09.700</a></span> | <span class="t">But I would not do any of the filtering that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=911" target="_blank">00:15:11.720</a></span> | <span class="t">Bowman and Dahl are worried about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=914" target="_blank">00:15:14.440</a></span> | <span class="t">So for adversarial testing in general,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=917" target="_blank">00:15:17.400</a></span> | <span class="t">here's what I would say are the major lessons we've learned so far.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=920" target="_blank">00:15:20.720</a></span> | <span class="t">Often, our top performing systems like the one from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=923" target="_blank">00:15:23.880</a></span> | <span class="t">that benchmark saturating slide have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=926" target="_blank">00:15:26.320</a></span> | <span class="t">found unsystematic solutions that should worry us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=929" target="_blank">00:15:29.720</a></span> | <span class="t">I also noted in earlier units of this course that progress on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=933" target="_blank">00:15:33.440</a></span> | <span class="t">challenge sets does seem to correlate with meaningful progress in general.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=937" target="_blank">00:15:37.560</a></span> | <span class="t">That's an important insight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=939" target="_blank">00:15:39.520</a></span> | <span class="t">Present-day systems get traction on adversarial cases</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=942" target="_blank">00:15:42.920</a></span> | <span class="t">without degradation on the general cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=945" target="_blank">00:15:45.740</a></span> | <span class="t">It'd be worrisome if training on adversarial examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=948" target="_blank">00:15:48.600</a></span> | <span class="t">even a little bit of them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=950" target="_blank">00:15:50.020</a></span> | <span class="t">caused our systems to perform worse in the general case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=953" target="_blank">00:15:53.360</a></span> | <span class="t">but I think we do not see that happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=956" target="_blank">00:15:56.000</a></span> | <span class="t">Then the final thing I would say is that whatever your view is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=959" target="_blank">00:15:59.500</a></span> | <span class="t">on the role of adversarials in system development,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=962" target="_blank">00:16:02.860</a></span> | <span class="t">if you deploy a system out into the world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=965" target="_blank">00:16:05.700</a></span> | <span class="t">the adversarial examples that people cook up and throw at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=969" target="_blank">00:16:09.240</a></span> | <span class="t">your system will define public perception for your system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=973" target="_blank">00:16:13.440</a></span> | <span class="t">In the interest of self-preservation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=975" target="_blank">00:16:15.960</a></span> | <span class="t">I would encourage you to think about adversarial dynamics for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=979" target="_blank">00:16:19.080</a></span> | <span class="t">evaluation before you do any kind of deployment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=982" target="_blank">00:16:22.780</a></span> | <span class="t">That's why I exhorted you all in an earlier unit for this course to really think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=987" target="_blank">00:16:27.400</a></span> | <span class="t">deeply about evaluation and have diverse teams of people with multiple perspectives on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=993" target="_blank">00:16:33.440</a></span> | <span class="t">your system participate in that internal evaluation to really find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=997" target="_blank">00:16:37.880</a></span> | <span class="t">the cases where your system performs in a problematic way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1001" target="_blank">00:16:41.720</a></span> | <span class="t">You should be your own adversary to the extent that you can to avoid having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1006" target="_blank">00:16:46.240</a></span> | <span class="t">really adversarial problems emerge when your system is used in the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1012" target="_blank">00:16:52.000</a></span> | <span class="t">Final question, synthetic benchmarks or naturalistic benchmarks?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1017" target="_blank">00:16:57.960</a></span> | <span class="t">As I said, there is a prominent perspective in the field</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1020" target="_blank">00:17:00.880</a></span> | <span class="t">that naturalistic benchmarks are the only ones we should be using.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1024" target="_blank">00:17:04.920</a></span> | <span class="t">To me, at a scientific level,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1027" target="_blank">00:17:07.280</a></span> | <span class="t">this is deeply worrisome because what it does is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1030" target="_blank">00:17:10.400</a></span> | <span class="t">introduce two unknowns into almost all the experiments that we run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1034" target="_blank">00:17:14.660</a></span> | <span class="t">The dataset is an unknown in the sense that we don't fully command what its structure is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1039" target="_blank">00:17:19.160</a></span> | <span class="t">like and the model is almost by definition in these contexts an unknown.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1043" target="_blank">00:17:23.260</a></span> | <span class="t">We're trying to explore its properties.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1045" target="_blank">00:17:25.560</a></span> | <span class="t">The situation is like you have this massive dataset that you cannot audit comprehensively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1051" target="_blank">00:17:31.800</a></span> | <span class="t">You might not even fully understand the process that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1054" target="_blank">00:17:34.200</a></span> | <span class="t">created it even if you did crowdsourcing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1056" target="_blank">00:17:36.760</a></span> | <span class="t">Then you have that as the input to a model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1059" target="_blank">00:17:39.560</a></span> | <span class="t">which is also a major unknown,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1061" target="_blank">00:17:41.660</a></span> | <span class="t">and then you get some output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1063" target="_blank">00:17:43.680</a></span> | <span class="t">The question is, what are the causal factors in this output?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1067" target="_blank">00:17:47.460</a></span> | <span class="t">Causal assignment in this case is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1070" target="_blank">00:17:50.240</a></span> | <span class="t">very difficult because of the fact that we have two unknowns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1073" target="_blank">00:17:53.840</a></span> | <span class="t">If we could fix the dataset and call it a known quantity,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1079" target="_blank">00:17:59.040</a></span> | <span class="t">then we could trace aspects of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1081" target="_blank">00:18:01.200</a></span> | <span class="t">the output to properties of the model that we have manipulated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1084" target="_blank">00:18:04.800</a></span> | <span class="t">But with two unknowns in play,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1086" target="_blank">00:18:06.580</a></span> | <span class="t">this will always be uncertain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1088" target="_blank">00:18:08.720</a></span> | <span class="t">I gave you a story about this before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1091" target="_blank">00:18:11.100</a></span> | <span class="t">Let me briefly rehearse it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1092" target="_blank">00:18:12.500</a></span> | <span class="t">This is under the heading of negation as a learning target.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1096" target="_blank">00:18:16.160</a></span> | <span class="t">Remember, we have this idea that we should have systems that know that if A entails B,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1101" target="_blank">00:18:21.060</a></span> | <span class="t">then not B entails not A,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1102" target="_blank">00:18:22.920</a></span> | <span class="t">the entailment reversing property of negation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1106" target="_blank">00:18:26.400</a></span> | <span class="t">We have an observation across a lot of different papers that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1109" target="_blank">00:18:29.860</a></span> | <span class="t">top performing NLI models fail to hit that learning target.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1114" target="_blank">00:18:34.320</a></span> | <span class="t">It's very tempting to conclude here that the model is the problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1119" target="_blank">00:18:39.440</a></span> | <span class="t">Top performing models seem incapable of learning negation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1123" target="_blank">00:18:43.040</a></span> | <span class="t">but we have an observation that our datasets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1126" target="_blank">00:18:46.400</a></span> | <span class="t">the naturalistic benchmarks these models were trained on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1129" target="_blank">00:18:49.500</a></span> | <span class="t">severely under-represent negation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1132" target="_blank">00:18:52.800</a></span> | <span class="t">Now, we don't know whether the issue is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1136" target="_blank">00:18:56.000</a></span> | <span class="t">with the models or with the dataset because we have two unknowns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1141" target="_blank">00:19:01.240</a></span> | <span class="t">In response to that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1142" target="_blank">00:19:02.920</a></span> | <span class="t">we created what I've called here a slightly synthetic benchmark,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1146" target="_blank">00:19:06.460</a></span> | <span class="t">that is monotonicity NLI or MoNLI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1149" target="_blank">00:19:09.640</a></span> | <span class="t">Recall it has two parts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1151" target="_blank">00:19:11.200</a></span> | <span class="t">a positive part where we take existing SNLI hypotheses and use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1156" target="_blank">00:19:16.160</a></span> | <span class="t">WordNet to create new examples that fire off</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1159" target="_blank">00:19:19.700</a></span> | <span class="t">the systematic cases where we get A neutral B and B entailment A.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1164" target="_blank">00:19:24.600</a></span> | <span class="t">That's the positive part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1166" target="_blank">00:19:26.000</a></span> | <span class="t">We did the same thing for negated examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1168" target="_blank">00:19:28.880</a></span> | <span class="t">Now, after the replacement,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1171" target="_blank">00:19:31.380</a></span> | <span class="t">we get the reverse of those patterns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1173" target="_blank">00:19:33.880</a></span> | <span class="t">What this leads us to is a dataset that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1176" target="_blank">00:19:36.920</a></span> | <span class="t">has naturally occurring cases as its basis,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1179" target="_blank">00:19:39.960</a></span> | <span class="t">but a systematic manipulation that leaves us with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1182" target="_blank">00:19:42.920</a></span> | <span class="t">complete guarantees that we have a certain representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1186" target="_blank">00:19:46.960</a></span> | <span class="t">for lexical entailment and negation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1190" target="_blank">00:19:50.200</a></span> | <span class="t">That's why it's slightly synthetic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1192" target="_blank">00:19:52.800</a></span> | <span class="t">Then when we use this as a challenge dataset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1195" target="_blank">00:19:55.160</a></span> | <span class="t">we get a blast of insight, I claim.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1197" target="_blank">00:19:57.480</a></span> | <span class="t">Let's look at the BERT row here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1199" target="_blank">00:19:59.460</a></span> | <span class="t">BERT is performing extremely well on SNLI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1202" target="_blank">00:20:02.760</a></span> | <span class="t">extremely well on the positive part of our synthetic benchmark,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1206" target="_blank">00:20:06.660</a></span> | <span class="t">but essentially hitting zero for the negative part of our benchmark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1211" target="_blank">00:20:11.140</a></span> | <span class="t">It's obviously just ignoring the negations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1213" target="_blank">00:20:13.900</a></span> | <span class="t">What is the issue here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1215" target="_blank">00:20:15.460</a></span> | <span class="t">Is it data or is it the model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1217" target="_blank">00:20:17.920</a></span> | <span class="t">Well, when we do a modest amount of fine-tuning on negative MoNLI examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1222" target="_blank">00:20:22.740</a></span> | <span class="t">we immediately boost performance for the model on that split.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1227" target="_blank">00:20:27.020</a></span> | <span class="t">That shows us definitively that when we show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1230" target="_blank">00:20:30.220</a></span> | <span class="t">a model like BERT relevant negation cases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1233" target="_blank">00:20:33.280</a></span> | <span class="t">it can handle the task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1235" target="_blank">00:20:35.460</a></span> | <span class="t">Now, as a result of having a known dataset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1238" target="_blank">00:20:38.380</a></span> | <span class="t">we have learned something directly about our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1241" target="_blank">00:20:41.140</a></span> | <span class="t">When we turn to naturalistic data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1243" target="_blank">00:20:43.660</a></span> | <span class="t">and I emphasize when there because I do think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1245" target="_blank">00:20:45.940</a></span> | <span class="t">that that's an important component in NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1248" target="_blank">00:20:48.580</a></span> | <span class="t">When we move from synthetic to naturalistic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1251" target="_blank">00:20:51.440</a></span> | <span class="t">we do so knowing that BERT can in principle learn negation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1255" target="_blank">00:20:55.620</a></span> | <span class="t">and that data coverage will be a major factor in its performance there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1260" target="_blank">00:21:00.020</a></span> | <span class="t">Those are crisp analytic lessons that we learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1263" target="_blank">00:21:03.020</a></span> | <span class="t">only because we allowed some synthetic evaluations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1267" target="_blank">00:21:07.260</a></span> | <span class="t">That's it. Those are three major questions for datasets in the field.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1272" target="_blank">00:21:12.020</a></span> | <span class="t">There are many more though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1273" target="_blank">00:21:13.300</a></span> | <span class="t">I address these, but we can also think about issues like data sheets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1278" target="_blank">00:21:18.640</a></span> | <span class="t">that is disclosures for datasets that help us understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1281" target="_blank">00:21:21.740</a></span> | <span class="t">how they can be used responsibly and where their limits lie.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1285" target="_blank">00:21:25.460</a></span> | <span class="t">We should also be thinking much more about how we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1288" target="_blank">00:21:28.220</a></span> | <span class="t">achieve cross-linguistic coverage for our benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1291" target="_blank">00:21:31.060</a></span> | <span class="t">Right now we have still to this day too much focus on English,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1295" target="_blank">00:21:35.140</a></span> | <span class="t">when in fact we want systems and models that are performant the world over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1300" target="_blank">00:21:40.220</a></span> | <span class="t">We could worry about statistical power,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1302" target="_blank">00:21:42.960</a></span> | <span class="t">and of course we should also worry deeply about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1306" target="_blank">00:21:46.020</a></span> | <span class="t">the pernicious social biases that are embedded in our datasets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1309" target="_blank">00:21:49.860</a></span> | <span class="t">and how we will get rid of those in order to create technologies that are more equitable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zFtA0fjaXPE&t=1315" target="_blank">00:21:55.860</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>