<html><head><title>How diffusion models work - explanation and code!</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>How diffusion models work - explanation and code!</h2><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4"><img src="https://i.ytimg.com/vi/I1sPXkm2NH4/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=46">0:46</a> Generative models<br><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=231">3:51</a> Latent space<br><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=455">7:35</a> Forward and reverse process<br><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=540">9:0</a> Mathematical definitions<br><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=780">13:0</a> Training loop<br><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=905">15:5</a> Sampling loop<br><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=996">16:36</a> U-Net<br><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1111">18:31</a> Training code<br><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1168">19:28</a> Sampling code<br><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1234">20:34</a> Full code<br><br><div style="text-align: left;"><a href="./I1sPXkm2NH4.html">Whisper Transcript</a> | <a href="./transcript_I1sPXkm2NH4.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hello guys, welcome to my new video about the diffusion models. In this video I will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=4" target="_blank">00:00:04.880</a></span> | <span class="t">introducing the diffusion model as described in the original paper, the DDPM paper, and I will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=11" target="_blank">00:00:11.520</a></span> | <span class="t">show you the structure of these models, how they work, why they were invented in the first place,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=16" target="_blank">00:00:16.960</a></span> | <span class="t">and also we will go inside some code to see how they are actually implemented. And we will see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=22" target="_blank">00:00:22.640</a></span> | <span class="t">that the code is actually very simple, even if the math and everything there looks very hard,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=27" target="_blank">00:00:27.280</a></span> | <span class="t">and I will also not go very much into the math because I feel like this video is more about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=32" target="_blank">00:00:32.640</a></span> | <span class="t">teaching concepts and how to actually work with these models instead of teaching the math</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=38" target="_blank">00:00:38.160</a></span> | <span class="t">derivations, which you can find also online or in the paper. So let's start by reviewing why we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=43" target="_blank">00:00:43.840</a></span> | <span class="t">needed the DDPM model in the first place. Before we had all these fancy models like the GAN and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=50" target="_blank">00:00:50.480</a></span> | <span class="t">the DDPM etc, we basically had simple models like the autoencoder. And the autoencoder had a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=58" target="_blank">00:00:58.080</a></span> | <span class="t">simple task, that is to compress data. So if we have some data and we run it through the encoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=63" target="_blank">00:01:03.520</a></span> | <span class="t">the encoder will transform the data into some smaller representation of the data. And if this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=69" target="_blank">00:01:09.520</a></span> | <span class="t">data, this code is passed through the decoder, hopefully it will rebuild the original data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=75" target="_blank">00:01:15.600</a></span> | <span class="t">So for example, if we have a picture of a tomato and we run it through the encoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=79" target="_blank">00:01:19.600</a></span> | <span class="t">it will be converted into a vector of numbers that represents that particular picture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=84" target="_blank">00:01:24.800</a></span> | <span class="t">And if we run this vector into the decoder, hopefully it will build up the original image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=89" target="_blank">00:01:29.600</a></span> | <span class="t">And if we run multiple images into an autoencoder, each of them will have an associated code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=95" target="_blank">00:01:35.360</a></span> | <span class="t">different for each image. However, there was a problem with these autoencoders, that is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=101" target="_blank">00:01:41.840</a></span> | <span class="t">the autoencoder did not catch any semantic relationship between the data. So for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=107" target="_blank">00:01:47.520</a></span> | <span class="t">the code associated with the picture of the tomato, or the code associated with the picture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=113" target="_blank">00:01:53.040</a></span> | <span class="t">of the zebra, maybe they were very similar, even if the two images, they have no semantic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=118" target="_blank">00:01:58.480</a></span> | <span class="t">relationship. Because the autoencoder was never told to learn this semantic relationship between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=124" target="_blank">00:02:04.400</a></span> | <span class="t">the data. Its only job was to compress data, and it was pretty good at it. But of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=132" target="_blank">00:02:12.160</a></span> | <span class="t">we wanted to learn some representation. So this code, we wanted to transform into a latent space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=138" target="_blank">00:02:18.480</a></span> | <span class="t">And that's why we introduced the variational autoencoder. In the variational autoencoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=142" target="_blank">00:02:22.480</a></span> | <span class="t">we don't just learn how to compress data, we actually learn a latent space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=146" target="_blank">00:02:26.800</a></span> | <span class="t">which is basically parameters of a multivariate distribution, in such a way that this latent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=155" target="_blank">00:02:35.120</a></span> | <span class="t">space actually catches also some relationship between the data. For example, the code associated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=161" target="_blank">00:02:41.680</a></span> | <span class="t">with the picture of the tomato, and the code associated with the picture of the egg, maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=165" target="_blank">00:02:45.520</a></span> | <span class="t">they are similar to each other, at least more similar compared to the picture of the egg and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=172" target="_blank">00:02:52.480</a></span> | <span class="t">zebra, for example. And the most important property of a latent space is that we can sample from it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=178" target="_blank">00:02:58.320</a></span> | <span class="t">just like we sample from a Gaussian distribution. And if we sample, for example, something from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=183" target="_blank">00:03:03.360</a></span> | <span class="t">this part of the space, hopefully we will get a picture of food. And if we sample,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=188" target="_blank">00:03:08.720</a></span> | <span class="t">for example, here, we hopefully we will get a picture of animals. And if we sample from here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=193" target="_blank">00:03:13.360</a></span> | <span class="t">hopefully we get a picture of a car, etc. So the most important property of these latent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=198" target="_blank">00:03:18.560</a></span> | <span class="t">spaces is that we can sample from it to generate new data. So why is it called a latent space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=205" target="_blank">00:03:25.840</a></span> | <span class="t">this representation? Because basically, we model our data as x, as a variable x, which is conditioned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=212" target="_blank">00:03:32.720</a></span> | <span class="t">on another variable z that we cannot observe, but we want to infer some properties about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=218" target="_blank">00:03:38.720</a></span> | <span class="t">If we model the variable z as a Gaussian, we want to learn its mean and the variance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=225" target="_blank">00:03:45.440</a></span> | <span class="t">Let me give you some more concrete examples on this latent space. I will use the Plato's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=232" target="_blank">00:03:52.480</a></span> | <span class="t">allegory of the cave for that purpose. And in this allegory, we have to imagine that there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=238" target="_blank">00:03:58.160</a></span> | <span class="t">are some people, and these people here, who are born and lived all their life in this small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=244" target="_blank">00:04:04.720</a></span> | <span class="t">section of a cave. And these people cannot leave the cave, they are chained in it. And these people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=251" target="_blank">00:04:11.520</a></span> | <span class="t">observe some objects on these walls, and they believe this is reality. So for them, the horse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=256" target="_blank">00:04:16.400</a></span> | <span class="t">is something black that moves like this, and the bird is something black that moves like this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=261" target="_blank">00:04:21.680</a></span> | <span class="t">etc. However, we know, as external observers, that this is not the real reality. This is actually the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=268" target="_blank">00:04:28.320</a></span> | <span class="t">projections through this fire of these real objects. So for example, these people, they can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=273" target="_blank">00:04:33.440</a></span> | <span class="t">see the real objects, right? So basically, we have to think that our data is the only variable that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=281" target="_blank">00:04:41.440</a></span> | <span class="t">we can observe. And this variable is conditioned on another variable that we cannot observe. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=288" target="_blank">00:04:48.480</a></span> | <span class="t">this variable is hidden. So that's why it's called the latent. Latent means hidden. Now, this was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=296" target="_blank">00:04:56.160</a></span> | <span class="t">true for the variational autoencoder. For diffusion model, we have to go deeper. And I will tell you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=302" target="_blank">00:05:02.800</a></span> | <span class="t">why. Imagine these people here, they believe that they hold the true objects, right? But imagine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=310" target="_blank">00:05:10.240</a></span> | <span class="t">these people themselves, they didn't hold the true objects, but they were themselves prisoners of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=315" target="_blank">00:05:15.680</a></span> | <span class="t">cave, and they were watching some projection of some real objects. So they were just like these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=323" target="_blank">00:05:23.680</a></span> | <span class="t">people. That is, we start from some people who can observe the real object, okay? So this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=331" target="_blank">00:05:31.760</a></span> | <span class="t">real object, and we will say it's time step zero. And these people projected some other people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=338" target="_blank">00:05:38.880</a></span> | <span class="t">inside an inner cave, this real object. So these people here, they think they are seeing the real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=346" target="_blank">00:05:46.800</a></span> | <span class="t">object, but actually, they are watching what is the projection of the real object. So it's more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=352" target="_blank">00:05:52.080</a></span> | <span class="t">noisy, just like through the fire, we projected the shadows, which is a more noisy version of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=358" target="_blank">00:05:58.320</a></span> | <span class="t">the real object, right? And these people themselves, they actually projected to some other people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=363" target="_blank">00:06:03.360</a></span> | <span class="t">inside an inner cave. So it becomes a noisy version of something that was already noisy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=369" target="_blank">00:06:09.040</a></span> | <span class="t">so an even noisier version. And we do it again and again and again for 1000 steps. And the last step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=376" target="_blank">00:06:16.800</a></span> | <span class="t">is called the T, capital T, until it becomes pure noise. This process of noisification is called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=384" target="_blank">00:06:24.160</a></span> | <span class="t">forward process. And then we also want the reverse process, that is, if we have some noise, can we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=390" target="_blank">00:06:30.960</a></span> | <span class="t">infer something about the object that was noisified? So for example, if we are here at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=397" target="_blank">00:06:37.760</a></span> | <span class="t">last time step, can we get some information about the previous time step, which is T capital minus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=404" target="_blank">00:06:44.880</a></span> | <span class="t">one, but in this case is 500. Okay. And these people, of course, they also want to infer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=410" target="_blank">00:06:50.720</a></span> | <span class="t">something about the object that projected the one they are watching, and these people, etc, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=417" target="_blank">00:06:57.280</a></span> | <span class="t">And we do this for 1000 time steps, each step can only watch the previous one. And each noisy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=423" target="_blank">00:07:03.920</a></span> | <span class="t">version comes from a previous noisified version. So this is the forward process. And this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=430" target="_blank">00:07:10.080</a></span> | <span class="t">reverse process in blue. The forward process is quite easy, because we can always add noise to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=435" target="_blank">00:07:15.440</a></span> | <span class="t">something. For example, you can give the picture of the Mona Lisa to a three years old, and he or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=440" target="_blank">00:07:20.800</a></span> | <span class="t">she will add all the noise that you want. However, the reverse process is hard, because we want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=446" target="_blank">00:07:26.960</a></span> | <span class="t">remove noise from something and observe the real object. And because it's hard, we will train a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=453" target="_blank">00:07:33.120</a></span> | <span class="t">neural network to do it. So mathematically, we have some real data that we call it x zero, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=461" target="_blank">00:07:41.280</a></span> | <span class="t">this x zero is conditioned on a latent variable z one, that actually is also conditioned on a z two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=467" target="_blank">00:07:47.440</a></span> | <span class="t">variable, which is itself conditioned on another variable z three, until in this chain of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=474" target="_blank">00:07:54.320</a></span> | <span class="t">conditioning, we have the last variable, which is pure noise. And the process of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=480" target="_blank">00:08:00.640</a></span> | <span class="t">noisification is called the forward process. And the process of denoisification is called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=485" target="_blank">00:08:05.520</a></span> | <span class="t">reverse process. And the forward process, as I said before, it's fixed. So we know how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=491" target="_blank">00:08:11.760</a></span> | <span class="t">go from less noise to more noise. But we don't know how to go from more noise to less noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=498" target="_blank">00:08:18.640</a></span> | <span class="t">That's why we will train a more neural network to do it. Another thing to notice is that with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=505" target="_blank">00:08:25.280</a></span> | <span class="t">zero time step zero, we indicate the original image with time step T capital, we indicate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=510" target="_blank">00:08:30.720</a></span> | <span class="t">pure noise. So higher number means higher noise, less, smaller number means less noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=517" target="_blank">00:08:37.200</a></span> | <span class="t">Now we need to, of course, look at some maths, I will try to avoid any derivation, I will try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=525" target="_blank">00:08:45.280</a></span> | <span class="t">teach the concept behind the math, because this way, you can also read the paper and follow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=531" target="_blank">00:08:51.200</a></span> | <span class="t">through the paper easily. Even if you don't understand each step, you will actually grasp</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=536" target="_blank">00:08:56.640</a></span> | <span class="t">the meaning of all the parts described in the paper. That's why I'm actually quoting the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=543" target="_blank">00:09:03.280</a></span> | <span class="t">itself. We start with the forward process. Now the forward process, as I said before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=548" target="_blank">00:09:08.880</a></span> | <span class="t">this is the original paper, DDPM paper from Ho and the other authors, which was released in 2020.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=556" target="_blank">00:09:16.640</a></span> | <span class="t">And the forward process is called Q. And as you can see, the forward process, which is different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=563" target="_blank">00:09:23.200</a></span> | <span class="t">from the reverse process that we will see later, has no parameter. So it's not Q of theta, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=568" target="_blank">00:09:28.160</a></span> | <span class="t">is like the reverse process is P of theta. But Q has no parameter to learn because it's fixed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=574" target="_blank">00:09:34.160</a></span> | <span class="t">we decide the parameters for it. It's not like the neural network has to learn anything about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=579" target="_blank">00:09:39.200</a></span> | <span class="t">And basically, they describe how to go from a less noisy version, so a less noise, so smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=584" target="_blank">00:09:44.480</a></span> | <span class="t">number, less noise, to a more noisy version, bigger noise, okay. And they model it as steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=591" target="_blank">00:09:51.200</a></span> | <span class="t">of a chain, which is a Markov chain of Gaussian variables, in which we know the mean and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=599" target="_blank">00:09:59.200</a></span> | <span class="t">variance of each one of them. And the mean is this one, so the square root of 1 minus beta t</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=607" target="_blank">00:10:07.200</a></span> | <span class="t">multiplied by the previous version, and also we know the variance. Now this beta, this one for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=614" target="_blank">00:10:14.400</a></span> | <span class="t">each time step is fixed, we decide it. And the sequence of beta is called a schedule.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=619" target="_blank">00:10:19.520</a></span> | <span class="t">And all then we have also the reverse process P. As I said before, this P has a theta here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=628" target="_blank">00:10:28.560</a></span> | <span class="t">because we want to learn the parameters of this reverse process. So this basically means that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=634" target="_blank">00:10:34.000</a></span> | <span class="t">from a more noisy version, if we want to go to a less noisy version, we want to learn this mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=639" target="_blank">00:10:39.920</a></span> | <span class="t">and this covariance matrix, because it's also modeled as a Gaussian variable, and actually as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=645" target="_blank">00:10:45.520</a></span> | <span class="t">a Markov chain of Gaussian variables. Another interesting property of the forward process is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=651" target="_blank">00:10:51.280</a></span> | <span class="t">because it's fixed, we can always go from the original image to the image noisified at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=658" target="_blank">00:10:58.960</a></span> | <span class="t">time step t, whatever t is, without doing all the intermediate step, just with one step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=665" target="_blank">00:11:05.600</a></span> | <span class="t">that is using this formula here. And alpha t is basically 1 minus beta t, so beta t is defined,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=674" target="_blank">00:11:14.320</a></span> | <span class="t">so also alpha t is defined. And alpha t with the hat is the product of all the alphas from 1 to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=682" target="_blank">00:11:22.640</a></span> | <span class="t">t, time step t. And how do we actually learn a neural network to model our reverse process?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=693" target="_blank">00:11:33.120</a></span> | <span class="t">Basically, we do just like what we did for the variational autoencoder. That is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=697" target="_blank">00:11:37.600</a></span> | <span class="t">we model our data. So P of theta of x0 is the latent space that we want to learn. And we know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=705" target="_blank">00:11:45.520</a></span> | <span class="t">that our x0 is conditioned on a chain of latent variables. Here they are called x1, x2, xT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=714" target="_blank">00:11:54.320</a></span> | <span class="t">xT. But basically, they are z1, z2, zT. And basically, we want to learn this latent space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=724" target="_blank">00:12:04.480</a></span> | <span class="t">So what we did is, let me go here, we do what we did for the variational autoencoder. So we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=731" target="_blank">00:12:11.360</a></span> | <span class="t">want to maximize the log likelihood of our data. What we do is, we basically find something that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=737" target="_blank">00:12:17.120</a></span> | <span class="t">is a lower bound for this log likelihood, which is called ELBO. And ELBO is also written here in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=743" target="_blank">00:12:23.840</a></span> | <span class="t">the paper, which is this expression here, which will be further expanded to arrive to the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=750" target="_blank">00:12:30.240</a></span> | <span class="t">function. And what we do with our neural network is that we maximize this ELBO. Because if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=756" target="_blank">00:12:36.000</a></span> | <span class="t">maximize a lower bound, so this one, you also maximize the variable that is bounded. So basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=762" target="_blank">00:12:42.640</a></span> | <span class="t">we maximize the ELBO, or we minimize the negative term of the ELBO. And this is exactly what we did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=768" target="_blank">00:12:48.560</a></span> | <span class="t">for the variational autoencoder. Now, I will not show you the derivation on how to arrive to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=773" target="_blank">00:12:53.040</a></span> | <span class="t">loss. I just told you the concept. So if you want to learn more about it, you can read the paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=777" target="_blank">00:12:57.280</a></span> | <span class="t">There are many tutorials online on how the math of diffusion works. Now let's go to the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=784" target="_blank">00:13:04.720</a></span> | <span class="t">loop. This is from the paper also. And in the paper, they describe the training loop. That is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=789" target="_blank">00:13:09.440</a></span> | <span class="t">we start basically from a picture sampled from our dataset or a batch of pictures sampled from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=797" target="_blank">00:13:17.600</a></span> | <span class="t">our dataset. And for each picture, we choose a time step of noisification. So we generate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=804" target="_blank">00:13:24.320</a></span> | <span class="t">because the time step of noisification can be between one and capital T, we can choose for each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=809" target="_blank">00:13:29.360</a></span> | <span class="t">one of this picture a random time step. And then we sample some noise. Basically, what we do is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=815" target="_blank">00:13:35.360</a></span> | <span class="t">we take this noise, okay, and we add this noise at the time step T to each picture. And our model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=824" target="_blank">00:13:44.320</a></span> | <span class="t">which is this epsilon of theta, because as you remember, the reverse process has the theta</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=830" target="_blank">00:13:50.480</a></span> | <span class="t">parameters, has to predict the noise in this noisified version of the image. So basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=840" target="_blank">00:14:00.080</a></span> | <span class="t">why do we have this formula here? Let's go back to the paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=844" target="_blank">00:14:04.160</a></span> | <span class="t">As you can show, as we saw here, we can always go from the X zero. So from the original image to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=853" target="_blank">00:14:13.440</a></span> | <span class="t">noisified image at time step T. And what we are doing here is exactly the same, we are going from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=860" target="_blank">00:14:20.800</a></span> | <span class="t">the picture X zero, that is here to the noisified version. And why do we do like this? Because of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=870" target="_blank">00:14:30.240</a></span> | <span class="t">the property of the Gaussian variables. And our model will, this is the output of this. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=876" target="_blank">00:14:36.640</a></span> | <span class="t">is the output of our model that given a noisified image and the time step T, at which it was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=883" target="_blank">00:14:43.360</a></span> | <span class="t">noisified, has to predict the noise that was added. So basically, we compare the predicted noise from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=889" target="_blank">00:14:49.520</a></span> | <span class="t">our model with the noise that we added to the image. And that's it, this is the training loop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=895" target="_blank">00:14:55.760</a></span> | <span class="t">So our model has to just predict the noise that we add to an image at the time step T.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=902" target="_blank">00:15:02.160</a></span> | <span class="t">And if we do it, we will learn that latent space. The sampling, that is how do we generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=910" target="_blank">00:15:10.000</a></span> | <span class="t">new samples using our latent space, is also described in the paper. We start with some noise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=917" target="_blank">00:15:17.040</a></span> | <span class="t">and we denoise progressively this initial noise for these time steps until we arrive what is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=925" target="_blank">00:15:25.440</a></span> | <span class="t">X zero. But of course, this X zero does not belong to our dataset, we actually sample something new,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=931" target="_blank">00:15:31.680</a></span> | <span class="t">just like we did for the variational autoencoder. So if you remember previously, let's go back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=942" target="_blank">00:15:42.080</a></span> | <span class="t">here. Our goal with the variational autoencoder, but also with the diffusion model, is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=947" target="_blank">00:15:47.040</a></span> | <span class="t">to sample new stuff. So we want to be able to sample from this space to generate new data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=951" target="_blank">00:15:51.840</a></span> | <span class="t">And also we want our latent space to actually represent features, to capture features from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=958" target="_blank">00:15:58.880</a></span> | <span class="t">our data. So the sampling basically means that we are actually creating, generating new samples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=965" target="_blank">00:16:05.680</a></span> | <span class="t">from our latent space. That's why there is a sampling. And why we do it that way? Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=971" target="_blank">00:16:11.920</a></span> | <span class="t">basically, we start from noise, and we progressively denoise it. So we keep doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=978" target="_blank">00:16:18.240</a></span> | <span class="t">T time step in total. And we do it with this, okay, with this algorithm here. And it's also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=988" target="_blank">00:16:28.480</a></span> | <span class="t">coming from the paper. Now, this still maybe looks a little abstract to you. So let's go inside the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=994" target="_blank">00:16:34.800</a></span> | <span class="t">code. But before that, let's review the model that we use to model our latent space. So the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1003" target="_blank">00:16:43.360</a></span> | <span class="t">that has to predict the reverse process of the diffusion model is the unit. So why did the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1010" target="_blank">00:16:50.800</a></span> | <span class="t">authors choose the unit? Because the unit was introduced in 2015, as image segmentation model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1018" target="_blank">00:16:58.240</a></span> | <span class="t">for medical applications. And this model looks like, if you look at the structure looks like an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1024" target="_blank">00:17:04.480</a></span> | <span class="t">autoencoder. So you start with the original image, it gets compressed until it becomes very small in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1030" target="_blank">00:17:10.400</a></span> | <span class="t">this bottleneck here. And then we up sample to reconstruct the original image. And the authors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1038" target="_blank">00:17:18.240</a></span> | <span class="t">of the DDPM paper also use the unit for the purpose of training the reverse process. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1044" target="_blank">00:17:24.320</a></span> | <span class="t">however, with some modifications, that we will see also in the code. So the modification, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1049" target="_blank">00:17:29.440</a></span> | <span class="t">first modification is that, as you saw in the sampling, and also in the training, there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1054" target="_blank">00:17:34.720</a></span> | <span class="t">two parameters from our model, epsilon theta. The first is the image noisified at the time step t,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1062" target="_blank">00:17:42.560</a></span> | <span class="t">and the second is the time step t itself. So we need to tell our model what is the time step t.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1069" target="_blank">00:17:49.280</a></span> | <span class="t">And how do we do it? Well, basically, at each down sampling and up sampling operation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1076" target="_blank">00:17:56.400</a></span> | <span class="t">we also concat, for example, this one with the positional encoding that from the transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1082" target="_blank">00:18:02.640</a></span> | <span class="t">model. So if you remember from the transformer model, we have a way of encoding the position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1088" target="_blank">00:18:08.080</a></span> | <span class="t">of a token inside of the sentence, which is actually a vector that tells the position.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1092" target="_blank">00:18:12.800</a></span> | <span class="t">And we use the same vector to tell the model what is the position, what is the time step at which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1098" target="_blank">00:18:18.480</a></span> | <span class="t">the image was noisified. The second modification is that we do also attention, self attention. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1105" target="_blank">00:18:25.920</a></span> | <span class="t">at each down sampling, we can do some, we can do the self attention. Let's look at the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1112" target="_blank">00:18:32.880</a></span> | <span class="t">code. Now the training code, as we have already saw the logic of the training code before now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1117" target="_blank">00:18:37.840</a></span> | <span class="t">I will compare it with a Python code. So basically, we start from some samples taken from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1123" target="_blank">00:18:43.120</a></span> | <span class="t">our data set. So a batch of sample. For each sample, we generate a time step t, which is from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1130" target="_blank">00:18:50.320</a></span> | <span class="t">one to t. And we also sample some noise, some random noise, we create the noisified version of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1137" target="_blank">00:18:57.040</a></span> | <span class="t">the image using this noise and the time steps t. And then we pass it through the unit, this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1145" target="_blank">00:19:05.120</a></span> | <span class="t">unit, okay, in which we pass the noisified image and the time steps t. And then we our loss is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1152" target="_blank">00:19:12.000</a></span> | <span class="t">basically predicting the difference between the predicted noise, so e hat, this e, this one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1158" target="_blank">00:19:18.640</a></span> | <span class="t">theta actually not hat. And the epsilon that we used as the initial noise. That's it. This is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1165" target="_blank">00:19:25.760</a></span> | <span class="t">training code. And the sampling code, sampling code is also simple. So basically, we start with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1173" target="_blank">00:19:33.120</a></span> | <span class="t">some random noise. And which is here x. And then we progressively denoise at the this is done for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1183" target="_blank">00:19:43.360</a></span> | <span class="t">only the inner loop. So this code is actually only the inner loop of this for loop here. So basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1188" target="_blank">00:19:48.960</a></span> | <span class="t">we denoise it continuously for these time steps. And this is the same, you can see also the names</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1195" target="_blank">00:19:55.360</a></span> | <span class="t">are same here. And as you can see, the code is not so hard. And it's quite simple. Plus another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1202" target="_blank">00:20:02.720</a></span> | <span class="t">thing I want you to notice is that we use the unit, not because we have to use the unit, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1208" target="_blank">00:20:08.960</a></span> | <span class="t">because the unit works well with this kind of model. So actually, the authors of the DDPM paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1214" target="_blank">00:20:14.800</a></span> | <span class="t">they chose the unit because it actually works well with this kind of model, but we don't have to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1219" target="_blank">00:20:19.360</a></span> | <span class="t">it. So we can use any model, any structure that is good at predicting noise, given the noisified</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1226" target="_blank">00:20:26.800</a></span> | <span class="t">version and the time steps t. It can be as simple as you want, or as complex as you want, but it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1232" target="_blank">00:20:32.080</a></span> | <span class="t">doesn't have to be the unit. The full code is available on my GitHub. And I also want to special</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1239" target="_blank">00:20:39.120</a></span> | <span class="t">thank to two other repositories from which I took the unit model. Now the unit model here was very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1245" target="_blank">00:20:45.120</a></span> | <span class="t">complete with a lot of features, but I removed a lot of them to simplify it as much as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1249" target="_blank">00:20:49.600</a></span> | <span class="t">So that it becomes simple to understand. And the diffusion model I took from here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1254" target="_blank">00:20:54.960</a></span> | <span class="t">The problem with this implementation, however, was that the unit was too simple and actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1260" target="_blank">00:21:00.160</a></span> | <span class="t">not reflecting the unit actually used by the DDPM paper. Thank you guys for watching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I1sPXkm2NH4&t=1266" target="_blank">00:21:06.080</a></span> | <span class="t">and stay tuned for more amazing content on deep learning and machine learning.</span></div></div></body></html>