<html><head><title>o3 and o4-mini - they’re great, but easy to over-hype</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>o3 and o4-mini - they’re great, but easy to over-hype</h2><a href="https://www.youtube.com/watch?v=3aRRYQEb99s"><img src="https://i.ytimg.com/vi/3aRRYQEb99s/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=0">0:0</a> o3 and o4-mini<br><br><div style="text-align: left;"><a href="./3aRRYQEb99s.html">Whisper Transcript</a> | <a href="./transcript_3aRRYQEb99s.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">I have a flight to catch in a few hours, so this is going to be a much speedier version of my normal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=4" target="_blank">00:00:04.460</a></span> | <span class="t">videos, but O4 Mini has been released along with O3 from OpenAI, and it's generating insane hype</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=11" target="_blank">00:00:11.080</a></span> | <span class="t">like this. But is the hype justified? Call me cynical, but they do lean towards giving early</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=16" target="_blank">00:00:16.340</a></span> | <span class="t">access to people that they know are going to massively hype up their new models. Now, don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=21" target="_blank">00:00:21.020</a></span> | <span class="t">get me wrong, they are much better than previous models like O1, they're just not above genius level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=26" target="_blank">00:00:26.540</a></span> | <span class="t">I can prove that in multiple ways, but I'm just going to give you a selection, and yes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=30" target="_blank">00:00:30.580</a></span> | <span class="t">I have read most of the system card and tested the model 20 times already. I should say both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=36" target="_blank">00:00:36.880</a></span> | <span class="t">models because it's O4 Mini and O3. For those completely new to AI, by the way, these are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=42" target="_blank">00:00:42.140</a></span> | <span class="t">now the best models within ChatGPT, which is different, of course, from Google's Gemini 2.5</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=47" target="_blank">00:00:47.660</a></span> | <span class="t">Pro or Anthropix Claude 3.7. Others, like Tyler Cohen, says that O3 is AGI, and honestly, I hear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=54" target="_blank">00:00:54.040</a></span> | <span class="t">people talk about Tyler Cohen. I have no idea who he is, but I don't believe O3 is AGI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=58" target="_blank">00:00:58.340</a></span> | <span class="t">For me, AGI is when a model can perform better than the human average at most tasks that a human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=65" target="_blank">00:01:05.020</a></span> | <span class="t">can do. For knowledge, coding, and mathematics, that is absolutely true, as long as you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=69" target="_blank">00:01:09.520</a></span> | <span class="t">focus on experts, but in general, it's not so much the case. There are many examples I could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=74" target="_blank">00:01:14.040</a></span> | <span class="t">have chosen, but check this one out. Here are five lines, and I asked how many overlaps do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=78" target="_blank">00:01:18.980</a></span> | <span class="t">they have in total. It said there are eight distinct points where the five drawn line</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=84" target="_blank">00:01:24.800</a></span> | <span class="t">segments intersect. Now, I know you guys, and you might pause and say, well, if you extrapolate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=90" target="_blank">00:01:30.000</a></span> | <span class="t">the lines, maybe they intersect eight times. Oh, it's not wrong. Nah, this is exactly what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=95" target="_blank">00:01:35.220</a></span> | <span class="t">O3 meant. Here, for example, is one point of intersection. Anyway, I can't explain my entire</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=99" target="_blank">00:01:39.620</a></span> | <span class="t">theory about AGI here. This is a very brief video, but it is definitely not hallucination</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=104" target="_blank">00:01:44.080</a></span> | <span class="t">free. That is complete BS, and OpenAI know it. It's a great model, a big improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=108" target="_blank">00:01:48.680</a></span> | <span class="t">I think O4 Mini is possibly comparable to Gemini 2.5 Pro on a good day, but it's definitely not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=115" target="_blank">00:01:55.640</a></span> | <span class="t">hallucination free. Both models are trained from the ground up to use tools, and I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=120" target="_blank">00:02:00.080</a></span> | <span class="t">that's an epic way to improve models, and they will get even more useful very fast. In case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=125" target="_blank">00:02:05.280</a></span> | <span class="t">you think I am dehyping O3 too much, it was the first model to get six out of ten on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=130" target="_blank">00:02:10.880</a></span> | <span class="t">first ten public questions of my own benchmark, SimpleBench. I was genuinely impressed with some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=135" target="_blank">00:02:15.980</a></span> | <span class="t">of its answers, and even though I disagree that it would take a fairly old man three to five minutes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=141" target="_blank">00:02:21.580</a></span> | <span class="t">to climb up to the top of a skyscraper, it nevertheless got the question right for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=146" target="_blank">00:02:26.700</a></span> | <span class="t">first time of any OpenAI model. But back to the theme you heard earlier, it can sometimes make some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=152" target="_blank">00:02:32.520</a></span> | <span class="t">pretty basic mistakes, like saying that a glove that falls out of the trunk or boot of a car,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=158" target="_blank">00:02:38.620</a></span> | <span class="t">which is going over a bridge, seems likely to fall into the river, because the trunk area is open and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=164" target="_blank">00:02:44.720</a></span> | <span class="t">the river is directly below. Well, what happened to the bridge? As I hinted at in my previous video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=169" target="_blank">00:02:49.720</a></span> | <span class="t">released just, wait, three, four hours ago, it does sometimes get this question right, because I kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=175" target="_blank">00:02:55.720</a></span> | <span class="t">of indirectly got early access to O3, but more often than not it gets it wrong. I don't know about you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=181" target="_blank">00:03:01.420</a></span> | <span class="t">but if I met someone who was above genius level, I would expect them to at least consider that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=186" target="_blank">00:03:06.520</a></span> | <span class="t">glove might fall out of the car onto the bridge itself. O4 Mini High gets four out of ten on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=192" target="_blank">00:03:12.320</a></span> | <span class="t">public set of questions, which is actually really not bad for a small quick model. Both models, by the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=197" target="_blank">00:03:17.180</a></span> | <span class="t">are coming to the plus tier, which is really making me start to wonder about paying for the pro tier. But anyway,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=203" target="_blank">00:03:23.320</a></span> | <span class="t">here are the prices. These numbers probably don't mean much to you, but the key point of comparison is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=208" target="_blank">00:03:28.520</a></span> | <span class="t">with O3 and Gemini 2.5 Pro. Very roughly speaking, Gemini 2.5 Pro is about three to four times cheaper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=216" target="_blank">00:03:36.380</a></span> | <span class="t">than O3, so bear that in mind when you see the benchmark results in a second. The first benchmark result is on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=222" target="_blank">00:03:42.220</a></span> | <span class="t">the overlap test, and yes, Gemini gets it right. Oh, and by the way, speaking of multi-modality, Gemini 2.5 Pro</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=228" target="_blank">00:03:48.440</a></span> | <span class="t">can handle YouTube videos and just raw videos and O3 can't. I initially got really excited when I saw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=235" target="_blank">00:03:55.160</a></span> | <span class="t">that you could upload videos to O3, but it's just doing an analysis of the metadata. Now, I know O3 is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=241" target="_blank">00:04:01.400</a></span> | <span class="t">trained to use tools natively, and I was particularly impressed with the way that it analyzed my benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=248" target="_blank">00:04:08.120</a></span> | <span class="t">website, created an image, a cover image for it, and did a deep dive analysis, which was pretty much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=253" target="_blank">00:04:13.720</a></span> | <span class="t">accurate. It gave speculation about why the front runners were better, and honestly, some pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=259" target="_blank">00:04:19.320</a></span> | <span class="t">nuanced advice about the benchmark itself and its limitations. Now, some of you may say, what about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=265" target="_blank">00:04:25.480</a></span> | <span class="t">the O3 wow video that I made earlier? And first of all, AI moves very quickly, so even four or five</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=273" target="_blank">00:04:33.080</a></span> | <span class="t">months can change a lot in AI. It's still a wow model, just not as wow in comparison with, say, Gemini 2.5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=280" target="_blank">00:04:40.760</a></span> | <span class="t">or even sometimes Clawed 3.7 thinking. There is another key detail, though, that they slipped into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=285" target="_blank">00:04:45.880</a></span> | <span class="t">the presentation. They said that O3, the one I covered back in December, was, quote, benchmark optimized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=291" target="_blank">00:04:51.400</a></span> | <span class="t">The ones we're getting, as the ARC prize confirmed, are smaller in terms of compute or less thinking time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=298" target="_blank">00:04:58.440</a></span> | <span class="t">than the version that they tested. Now, I am presuming that what they meant by benchmark optimized was that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=303" target="_blank">00:05:03.720</a></span> | <span class="t">they let O3 think for a lot longer, have a lot more inference time compute. In other words, we are not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=309" target="_blank">00:05:09.320</a></span> | <span class="t">quite getting the model that crushed ARC AGI. Some other quick details before we get to the benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=316" target="_blank">00:05:16.520</a></span> | <span class="t">and both models have a 200,000 token context window, think roughly 150,000 words, but they can output up to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=324" target="_blank">00:05:24.200</a></span> | <span class="t">80,000 words, which I think is pretty cool. Their knowledge cutoff, which you can think of as the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=329" target="_blank">00:05:29.560</a></span> | <span class="t">limits of their training data is June 1st, 2024. That compares to January 2025 for Gemini 2.5 Pro.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=337" target="_blank">00:05:37.160</a></span> | <span class="t">It seems, and I haven't had time to check this, that they are still basing it on GPT-4-0,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=342" target="_blank">00:05:42.840</a></span> | <span class="t">hence the lack of an updated training cutoff date. Time for some benchmarks, and don't hate on me for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=348" target="_blank">00:05:48.760</a></span> | <span class="t">literally just getting a screen grab from the YouTube video. For competitive mathematics, O3 and O4 mini do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=355" target="_blank">00:05:55.400</a></span> | <span class="t">extremely well on a data set that couldn't have been in their training data. For reference, on this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=360" target="_blank">00:06:00.840</a></span> | <span class="t">benchmark, Gemini 2.5 Pro gets around 86%. Now, with multiple attempts, Grok 3 gets 93%, but we don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=369" target="_blank">00:06:09.880</a></span> | <span class="t">quite know how many attempts this was for OpenAI. I would presume just first attempt. Either way, as the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=376" target="_blank">00:06:16.280</a></span> | <span class="t">narrator said, when you allow these models to have tools, they are extremely good to the point of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=380" target="_blank">00:06:20.600</a></span> | <span class="t">saturating some of these competitive math benchmarks. Likewise, for competitive code, if you can benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=386" target="_blank">00:06:26.760</a></span> | <span class="t">it, they can crush it. These models, indeed, even other model families, are essentially eval maximizers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=393" target="_blank">00:06:33.000</a></span> | <span class="t">as I touched on in my video from, what, four hours ago. For PhD level science, you can see the results here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=399" target="_blank">00:06:39.480</a></span> | <span class="t">83.3 and 81.4. For reference, Gemini gets 84%, and Claude 3.7 Sonnet gets 84.8%. That's with multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=409" target="_blank">00:06:49.480</a></span> | <span class="t">attempts for Claude, but just a single attempt for Gemini 2.5. So, Gemini 2.5 is better on a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=415" target="_blank">00:06:55.560</a></span> | <span class="t">attempt than either model. Kind of seems a little bit strange to be declaring AGI tonight, but not when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=420" target="_blank">00:07:00.920</a></span> | <span class="t">Gemini 2.5 Pro came out. For me, neither are AGI, but I am not an AGI denialist. I think it is coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=427" target="_blank">00:07:07.400</a></span> | <span class="t">in the next few years. The simplest version of my definition is when I would hire O4, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=434" target="_blank">00:07:14.120</a></span> | <span class="t">over a smart human being. Could they edit an entire video without random glitches or cutting off key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=440" target="_blank">00:07:20.360</a></span> | <span class="t">images? For that matter, could they do my Amazon shopping without putting me 10 grand in debt? I do get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=445" target="_blank">00:07:25.720</a></span> | <span class="t">it. At coming up with quick drafts that seem incredibly intelligent and often are, they are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=451" target="_blank">00:07:31.160</a></span> | <span class="t">incredible, far smarter than me in that sense. I couldn't get any of these scores in any of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=455" target="_blank">00:07:35.880</a></span> | <span class="t">exams. But it is fairly inadvisable to make comparisons to human IQ, because how many super crazy coders</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=462" target="_blank">00:07:42.840</a></span> | <span class="t">or PhDs do you know that could score like this but not count the number of overlaps? Or think of there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=468" target="_blank">00:07:48.360</a></span> | <span class="t">being a bridge beneath the glove that's falling? If it's in their training data, amazing. If it's not,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=475" target="_blank">00:07:55.480</a></span> | <span class="t">on the MMMU, which is a bit like the MMLU in the sense of it spans many different domains,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=480" target="_blank">00:08:00.440</a></span> | <span class="t">but it focuses on questions involving charts and tables and graphs and things like that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=484" target="_blank">00:08:04.440</a></span> | <span class="t">O3 gets 82.9%. That is genuinely better than Gemini 2.5 Pro's 81.7%, so well done to OpenAI on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=492" target="_blank">00:08:12.920</a></span> | <span class="t">Now, on humanity's last exam, which you can think of as a benchmark for really obscure knowledge,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=498" target="_blank">00:08:18.760</a></span> | <span class="t">it was almost slightly disappointing for me, even though the previous record was OpenAI itself with deep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=504" target="_blank">00:08:24.040</a></span> | <span class="t">research. Now, in fairness, again, O3 beats Gemini 2.5 Pro, which got 18% in this benchmark. But given</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=510" target="_blank">00:08:30.840</a></span> | <span class="t">that deep research was powered by an early version, OpenAI said, of O3, I was expecting a little bit more,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=517" target="_blank">00:08:37.160</a></span> | <span class="t">especially with the quote, "new and improved," Sam Altman said, O3, with Python and browsing tools.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=521" target="_blank">00:08:41.960</a></span> | <span class="t">Or even O4 for that matter, I thought they might have injected more knowledge into it. That is kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=525" target="_blank">00:08:45.960</a></span> | <span class="t">harsh because they're just challenging their own record in this benchmark, so well done to them again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=530" target="_blank">00:08:50.920</a></span> | <span class="t">The release notes from OpenAI were fairly interesting, with evaluations by "external experts"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=536" target="_blank">00:08:56.440</a></span> | <span class="t">having O3 making 20% fewer major errors. That's great, but what happened to it being "hallucination-free"?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=543" target="_blank">00:09:03.880</a></span> | <span class="t">If I saw Sam Altman retweet that a new model was "hallucination-free" and I was an average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=548" target="_blank">00:09:08.680</a></span> | <span class="t">white-collar worker, I would be panicking. What's the real truth? It is absolutely not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=552" target="_blank">00:09:12.760</a></span> | <span class="t">hallucination-free, and making fewer major errors is great, but still concedes that it does make major</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=558" target="_blank">00:09:18.840</a></span> | <span class="t">errors, as we've seen already. On one part of Ada's Polyglot coding benchmark, we can see that O3 on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=564" target="_blank">00:09:24.520</a></span> | <span class="t">high settings indeed sets a record. It's more than 10 points higher than Gemini 2.5 Pro. But you may</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=571" target="_blank">00:09:31.160</a></span> | <span class="t">remember that O1 on high settings, as in thinking for a long time using lots of chains of thought,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=576" target="_blank">00:09:36.920</a></span> | <span class="t">cost almost $200. That compares to $6 for Gemini. O3 high, in other words, may eke out Gemini 2.5 Pro,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=584" target="_blank">00:09:44.920</a></span> | <span class="t">and therefore become widely used, but at an extreme cost. Or the TL;DR of all of that is even in those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=591" target="_blank">00:09:51.240</a></span> | <span class="t">domains where O3 has taken the lead, it hasn't taken the cost-effective lead. On Codex CLI, their agent that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=597" target="_blank">00:09:57.640</a></span> | <span class="t">you can run from your terminal, they're clearly taking aim at Claude code, but obviously, given that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=602" target="_blank">00:10:02.360</a></span> | <span class="t">it's only been around two and a half hours, I haven't had time to test it. Of course, that may be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=607" target="_blank">00:10:07.000</a></span> | <span class="t">turbocharged if OpenAI buy Windsurf, the competitor to Cursor itself. Of course, if you check out my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=613" target="_blank">00:10:13.560</a></span> | <span class="t">previous video, Kevin Weil, the chief product officer of OpenAI, said very clearly that competitive coding is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=620" target="_blank">00:10:20.040</a></span> | <span class="t">not always the same as front-end coding, for example, so you'll have to test it yourself. As always, it comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=625" target="_blank">00:10:25.480</a></span> | <span class="t">down to how much high-quality data there is in your domain, and indeed, a diversity of data. As we all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=631" target="_blank">00:10:31.000</a></span> | <span class="t">know, in machine learning, sometimes you can over-train on bits of data, as you can see in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=635" target="_blank">00:10:35.240</a></span> | <span class="t">example. Yes, this was O3, by the way. I bet some of the first comments will be, "What about testing both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=640" target="_blank">00:10:40.600</a></span> | <span class="t">models on SimpleBench, given that the API is out tonight?" Well, given my flight, that will have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=645" target="_blank">00:10:45.400</a></span> | <span class="t">be my colleague, who is hopefully going to do it tonight, and so the results should be on the website</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=650" target="_blank">00:10:50.200</a></span> | <span class="t">tonight, fingers crossed. I suspect it may just take the lead from Gemini 2.5 Pro, albeit costing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=657" target="_blank">00:10:57.240</a></span> | <span class="t">a lot more. But as pretty much all of you know by now, we couldn't test O3 on SimpleBench without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=662" target="_blank">00:11:02.520</a></span> | <span class="t">Weights and Biases, who are the sponsors of today's video. If you want to check out their Weave platform,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=667" target="_blank">00:11:07.240</a></span> | <span class="t">you can do so via the SimpleBench website, or of course, with the link in the description. We should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=672" target="_blank">00:11:12.200</a></span> | <span class="t">be doing some Discord workshops on my Patreon to get you started on Weave. Essentially, it's what we use to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=678" target="_blank">00:11:18.280</a></span> | <span class="t">benchmark these models. It's kind of like being in one of those Mercedes, where you can see like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=682" target="_blank">00:11:22.440</a></span> | <span class="t">thousand options for tweaking things, improving things, and comparing things. And as I mentioned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=687" target="_blank">00:11:27.400</a></span> | <span class="t">before, they have an AI Academy with free courses. Thanks as ever to Weights and Biases for keeping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=693" target="_blank">00:11:33.160</a></span> | <span class="t">SimpleBench going. Now, the system card, which because of the flight for one of the first times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=698" target="_blank">00:11:38.440</a></span> | <span class="t">in video history on AI Explained, I've only read part of. Nevertheless, here are some highlights with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=703" target="_blank">00:11:43.400</a></span> | <span class="t">Meta finding examples of reward hacking. Maxing their score, in other words, not by the model itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=708" target="_blank">00:11:48.760</a></span> | <span class="t">solving the challenge, but tweaking the parameters so it seems like it solved the challenge. A bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=713" target="_blank">00:11:53.640</a></span> | <span class="t">like hacking a game to change your score to win the game, and O3 did this roughly 1% of the time. Also,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=719" target="_blank">00:11:59.320</a></span> | <span class="t">do you remember that paper recently from Meta that I've been discussing with their authors, where the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=723" target="_blank">00:12:03.400</a></span> | <span class="t">length of a task that a model can do is doubling every seven months? Well, there are many caveats to that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=728" target="_blank">00:12:08.200</a></span> | <span class="t">paper, but Meta do say that when they analysed O3, they said they found capabilities exceeding those of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=733" target="_blank">00:12:13.800</a></span> | <span class="t">other public models and surpassing their projections from previous capability scaling trends that we saw.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=738" target="_blank">00:12:18.920</a></span> | <span class="t">In other words, the time horizon of software tasks that they complete with greater than 50%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=743" target="_blank">00:12:23.560</a></span> | <span class="t">reliability may be doubling in less than seven months. Obviously, I'll have to come back to some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=747" target="_blank">00:12:27.960</a></span> | <span class="t">of this stuff in other videos, but here's another highlight. That O3 and O4 Mini are on the cusp</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=754" target="_blank">00:12:34.680</a></span> | <span class="t">of being able to meaningfully help novices create known biological threats. That would cross OpenAI's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=760" target="_blank">00:12:40.360</a></span> | <span class="t">own high-risk threshold, which would mean that they couldn't even release the model. I keep telling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=764" target="_blank">00:12:44.600</a></span> | <span class="t">people this, that because of responsible scaling policies from Anthropic and OpenAI, they are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=769" target="_blank">00:12:49.240</a></span> | <span class="t">promising people that they soon won't even be able to release certain models. That will be reassuring or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=774" target="_blank">00:12:54.760</a></span> | <span class="t">disappointing to you depending on your perspective. Back to dehyping though, because I'm sure tonight you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=779" target="_blank">00:12:59.320</a></span> | <span class="t">going to see plenty of O3 is AGI screaming face thumbnails. Just to drown out that noise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=786" target="_blank">00:13:06.680</a></span> | <span class="t">check out OpenAI research engineer interview performance. Look at that incredible exponential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=792" target="_blank">00:13:12.920</a></span> | <span class="t">you can see from O1 up to O4. Well, kind of not really. Also Paperbench, which is testing whether AIs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=799" target="_blank">00:13:19.960</a></span> | <span class="t">can replicate AI research papers. I bet this particular chart doesn't find itself in many AGI is here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=805" target="_blank">00:13:25.640</a></span> | <span class="t">crazy thumbnails that you see, or videos for that matter, that you see tonight. Look at O1's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=810" target="_blank">00:13:30.360</a></span> | <span class="t">performance, 24%, and O3 without browsing, 18%, O4 Mini, 25%. I do get it, it's not a perfect apples to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=818" target="_blank">00:13:38.520</a></span> | <span class="t">apples, but this is not exactly an exponential. Obligatory caveat, I am expecting progress over the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=823" target="_blank">00:13:43.960</a></span> | <span class="t">course of this year. I'm just saying not every chart backs up the AGI hype. I'll leave you with these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=829" target="_blank">00:13:49.320</a></span> | <span class="t">two more optimistic thoughts on O3. While it may be demanding more and more compute,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=834" target="_blank">00:13:54.360</a></span> | <span class="t">performance does continue to rise and rise. And that's not even to mention letting the models think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=840" target="_blank">00:14:00.120</a></span> | <span class="t">for longer, which is another entire axis we can exploit. As Noam Brown of OpenAI said, there is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=844" target="_blank">00:14:04.920</a></span> | <span class="t">still a lot of room to scale both of these further. So if you ignore the headlines and drown out the hype,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=850" target="_blank">00:14:10.840</a></span> | <span class="t">which is to be honest, good advice for all times in life. O3 represents genuine progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=856" target="_blank">00:14:16.280</a></span> | <span class="t">Well done to OpenAI. If you want to check out more ways that AI is improving,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=3aRRYQEb99s&t=859" target="_blank">00:14:19.800</a></span> | <span class="t">check out my video from around four hours ago. And either way, have a wonderful day.</span></div></div></body></html>