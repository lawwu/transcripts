<html><head><title>Live coding 10</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Live coding 10</h2><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo"><img src="https://i.ytimg.com/vi/zhBRynq9Yvo/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=0">0:0</a> Questions<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=360">6:0</a> Steps for Entering a Standard Image Recognition Competition on Kaggle<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=520">8:40</a> The best models for fine tuning image recognition<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=720">12:0</a> Thomas Capelle script to run experiments<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=840">14:0</a> Github Gist<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=960">16:0</a> Weights and Biases API<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1020">17:0</a> Automating Gist generation<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1230">20:30</a> Summarising and ranking models for fine tuning<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1380">23:0</a> Scatter plot of performance by model family<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1540">25:40</a> Best models for images that don't look like Imagenet<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1980">33:0</a> Pretrained models - Model Zoo, Papers With Code, Huggingface<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2250">37:30</a> Applying learning on Paddy notebook with small models<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2760">46:0</a> Applying learning on large models<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2820">47:0</a> Gradient accumulation to prevent out of memory<br><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3170">52:50</a> Majority vote<br><br><div style="text-align: left;"><a href="./zhBRynq9Yvo.html">Whisper Transcript</a> | <a href="./transcript_zhBRynq9Yvo.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">I've got a question. Yeah, it's to do with, is there a way that machine learning can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=8" target="_blank">00:00:08.800</a></span> | <span class="t">find the sort of conditional probabilistic segments that are say in sort of heterogeneous data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=18" target="_blank">00:00:18.240</a></span> | <span class="t">I am having trouble passing that question. Can you give like an example or something? Yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=25" target="_blank">00:00:25.120</a></span> | <span class="t">okay. All right. Well, I'm waddling with road surface friction with road risk rather. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=33" target="_blank">00:00:33.600</a></span> | <span class="t">quite immediately there's this set of stereotypes in road analysis. And we all know that there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=42" target="_blank">00:00:42.720</a></span> | <span class="t">highways, freeways, urban materials. And they actually go through a series of stages,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=53" target="_blank">00:00:53.040</a></span> | <span class="t">almost like states. And each of the states has got a sort of conditional probabilistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=60" target="_blank">00:01:00.480</a></span> | <span class="t">relationship between the set of predictors and the actual response variable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=66" target="_blank">00:01:06.480</a></span> | <span class="t">the crash response variable. Is there anything that white that in deep learning?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=74" target="_blank">00:01:14.800</a></span> | <span class="t">So how is that different to a normal predictive model? Like, I mean, all predictive models are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=82" target="_blank">00:01:22.480</a></span> | <span class="t">conditional probabilities, right? What's the... Well, I mean, if you take something like XGBoost,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=90" target="_blank">00:01:30.880</a></span> | <span class="t">for example, and you want to predict the risk of a given road, so it'll give you a value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=97" target="_blank">00:01:37.600</a></span> | <span class="t">But then you've got no idea as to what's happening inside of the model. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=102" target="_blank">00:01:42.640</a></span> | <span class="t">we're really interested in that because once you find the distributions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=111" target="_blank">00:01:51.680</a></span> | <span class="t">you can start to do some quality testing on whether they actually follow the domain or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=117" target="_blank">00:01:57.600</a></span> | <span class="t">whether your segmentation process that actually determines your predictions is good or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=124" target="_blank">00:02:04.320</a></span> | <span class="t">And so, in a way, rather than, say, predicting some sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=134" target="_blank">00:02:14.880</a></span> | <span class="t">crash rate or risk or whatever, I'm really looking for those probabilistic distributions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=144" target="_blank">00:02:24.080</a></span> | <span class="t">and learning beneath the surface. So all deep learning models will return a set of probabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=153" target="_blank">00:02:33.520</a></span> | <span class="t">That's what their final layer returns. And then we decode them by taking the argmax</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=160" target="_blank">00:02:40.160</a></span> | <span class="t">across them. But there's nothing to stop you using those probabilities directly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=164" target="_blank">00:02:44.800</a></span> | <span class="t">But I'm probably misunderstanding your question. It's a little abstract for me to understand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=173" target="_blank">00:02:53.520</a></span> | <span class="t">Like, I mean, I know there's lots of things you can do with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=177" target="_blank">00:02:57.120</a></span> | <span class="t">confidence intervals and whatnot, but it really depends a great deal on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=187" target="_blank">00:03:07.520</a></span> | <span class="t">specific details of the application, what you're trying to do and how you're trying to do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=192" target="_blank">00:03:12.320</a></span> | <span class="t">Good question, Daniel. I'm just talking about probability of an incident or risk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=200" target="_blank">00:03:20.560</a></span> | <span class="t">related to the road surface. So you're going to need some sort of tabular data that has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=207" target="_blank">00:03:27.920</a></span> | <span class="t">the occurrences with each road surface that you're trying to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=214" target="_blank">00:03:34.320</a></span> | <span class="t">And why wouldn't XGBoost give you that if you had a predictive model of incidents?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=223" target="_blank">00:03:43.760</a></span> | <span class="t">In my mind, one of the disadvantages of XGBoost is the fact that it only gives you a single set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=233" target="_blank">00:03:53.920</a></span> | <span class="t">of variable effects. Whereas in what we're dealing with, we've got some really high crash roads.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=245" target="_blank">00:04:05.280</a></span> | <span class="t">We've got a different conditional probability relationship between the predictors and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=251" target="_blank">00:04:11.600</a></span> | <span class="t">response compared to, say, the average. XGBoost does an excellent job in making the predictions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=261" target="_blank">00:04:21.120</a></span> | <span class="t">but you've got no idea as to the group of instances that they're actually making the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=269" target="_blank">00:04:29.520</a></span> | <span class="t">prediction or the actual variable effects. Okay, so I think I understand your question now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=278" target="_blank">00:04:38.160</a></span> | <span class="t">and I think the answer is actually it does. And what I suggest you do, if you haven't already,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=284" target="_blank">00:04:44.240</a></span> | <span class="t">is read the chapter of the first AI book on tabular modeling, and it will cover something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=291" target="_blank">00:04:51.440</a></span> | <span class="t">very similar, which is random forests, which is another ensemble of decision trees, and it will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=296" target="_blank">00:04:56.080</a></span> | <span class="t">show you how to get exactly the kind of insights that I think you're looking for. And all of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=305" target="_blank">00:05:05.680</a></span> | <span class="t">techniques there would work equally well for random forests, and they also work equally well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=309" target="_blank">00:05:09.280</a></span> | <span class="t">for deep learning. So maybe after you've done that, you can come back and let us know whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=313" target="_blank">00:05:13.200</a></span> | <span class="t">that helped. Yeah, well, I've sort of played with random forests. It doesn't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=320" target="_blank">00:05:20.400</a></span> | <span class="t">give you what I'm looking for. I strongly suggest you read the chapter before you say that. I will.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=327" target="_blank">00:05:27.360</a></span> | <span class="t">Because I'm pretty sure it will. And if it doesn't, that would be very interesting to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=335" target="_blank">00:05:35.840</a></span> | <span class="t">In fact, I mentioned to you last time, but I'm really looking forward to the tabular data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=342" target="_blank">00:05:42.480</a></span> | <span class="t">Cool. Great. I'll show you guys what I've been working on, which has been fun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=359" target="_blank">00:05:59.760</a></span> | <span class="t">So the first thing I did, you know, after I got off our last call was I basically just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=368" target="_blank">00:06:08.880</a></span> | <span class="t">threw together the kind of like most obvious basic steps one would do for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=383" target="_blank">00:06:23.280</a></span> | <span class="t">a standard image recognition competition, just in order to show people that that can be quite good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=390" target="_blank">00:06:30.800</a></span> | <span class="t">And it was actually a little embarrassing because I didn't mean to do this. When I submitted it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=396" target="_blank">00:06:36.800</a></span> | <span class="t">it turned out I got first on the leaderboard. So now I feel like I'm going to have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=402" target="_blank">00:06:42.320</a></span> | <span class="t">write down exactly what I did because, you know, during an active competition, everybody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=411" target="_blank">00:06:51.440</a></span> | <span class="t">needs to needs to share what they're what they're doing if they share it with anybody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=415" target="_blank">00:06:55.360</a></span> | <span class="t">some publically. So I thought I'd show you what I did here. But I think this is about to go up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=421" target="_blank">00:07:01.920</a></span> | <span class="t">quite a lot, because, you know, what we're doing here is where they're interesting images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=435" target="_blank">00:07:15.760</a></span> | <span class="t">for a couple of reasons. One is that they're kind of like things that you see in ImageNet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=441" target="_blank">00:07:21.200</a></span> | <span class="t">like their pictures of natural objects, their photos. But I don't think ImageNet has any kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=449" target="_blank">00:07:29.600</a></span> | <span class="t">of like categories about diseases, you know, they have categories about like, what's the main</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=456" target="_blank">00:07:36.480</a></span> | <span class="t">object in this? So they might have a category about like, I don't know if they do like some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=460" target="_blank">00:07:40.240</a></span> | <span class="t">different kinds of grass, or some different types of even some different types of, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=468" target="_blank">00:07:48.080</a></span> | <span class="t">fields or something, but I'm pretty sure they don't have anything about different kinds of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=472" target="_blank">00:07:52.320</a></span> | <span class="t">crop disease. So it's a bit different to ImageNet, which is what most of our pre-trained models are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=478" target="_blank">00:07:58.880</a></span> | <span class="t">trained on. But it's not that different. And it's also interesting because nearly all of the images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=485" target="_blank">00:08:05.760</a></span> | <span class="t">are the same shape and size. So we can kind of try to take advantage of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=495" target="_blank">00:08:15.600</a></span> | <span class="t">And, you know, so when we fine-tune a pre-trained model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=499" target="_blank">00:08:19.840</a></span> | <span class="t">there's, so let me pull up this Kaggle notebook I just created.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=506" target="_blank">00:08:26.400</a></span> | <span class="t">So I just published this yesterday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=522" target="_blank">00:08:42.320</a></span> | <span class="t">Kind of look at what are the best vision models for fine-tuning. And so I kind of realized that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=526" target="_blank">00:08:46.640</a></span> | <span class="t">there are two key dimensions that really seem to impact how well a model can be fine-tuned,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=532" target="_blank">00:08:52.320</a></span> | <span class="t">you know, whether it works well or not, or how it's different. So one is what I just talked about,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=537" target="_blank">00:08:57.280</a></span> | <span class="t">which is how similar is your data set to the data set used for the pre-trained model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=545" target="_blank">00:09:05.920</a></span> | <span class="t">If it's really similar, like pets to ImageNet, then like the critical factor is how well does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=554" target="_blank">00:09:14.960</a></span> | <span class="t">the fine-tuning of the model maintain the weights that are pre-trained, you know, because you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=560" target="_blank">00:09:20.720</a></span> | <span class="t">probably not going to be changing very, very much. And you're probably going to be able to take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=564" target="_blank">00:09:24.160</a></span> | <span class="t">advantage of really big, accurate models because they've already learned to do almost the exact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=569" target="_blank">00:09:29.600</a></span> | <span class="t">thing you're trying to do. On the other hand, so that's the pets data set. On the other hand,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=575" target="_blank">00:09:35.840</a></span> | <span class="t">there's a data set called the planet data set, which is images of satellite images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=586" target="_blank">00:09:46.080</a></span> | <span class="t">And these are not really at all like anything that ImageNet ever saw, you know, they're taken</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=592" target="_blank">00:09:52.880</a></span> | <span class="t">from above, they're taken from much further away, there's no single main object. So a lot of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=603" target="_blank">00:10:03.280</a></span> | <span class="t">weights of a pre-trained model are going to be useless for fine-tuning this because they've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=608" target="_blank">00:10:08.560</a></span> | <span class="t">learned specific features like, you know, what does text look like, what do eyeballs look like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=614" target="_blank">00:10:14.800</a></span> | <span class="t">what does fur look like, you know, which none of which are going to be very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=618" target="_blank">00:10:18.880</a></span> | <span class="t">useful. So that's the first dimension. The second dimension is just how big the data set is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=624" target="_blank">00:10:24.560</a></span> | <span class="t">So on a big data set, you've got time, you've got epochs to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=629" target="_blank">00:10:29.600</a></span> | <span class="t">to take advantage of having lots of parameters in the model to learn to use them effectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=640" target="_blank">00:10:40.400</a></span> | <span class="t">And if you don't have much data, then you don't have much ability to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=647" target="_blank">00:10:47.360</a></span> | <span class="t">So you might imagine that deep learning practitioners already know these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=653" target="_blank">00:10:53.200</a></span> | <span class="t">answers of how do we, you know, what's the best models for fine-tuning. But in fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=656" target="_blank">00:10:56.960</a></span> | <span class="t">we don't, as far as I know, nobody's ever done an analysis before of which models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=661" target="_blank">00:11:01.440</a></span> | <span class="t">are the best for fine-tuning. So that's what I did over the weekend.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=664" target="_blank">00:11:04.720</a></span> | <span class="t">And not just over the weekend, but really over the last couple of weeks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=669" target="_blank">00:11:09.200</a></span> | <span class="t">And I did this with Thomas Capelle, who works at Weights of Biases, another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=675" target="_blank">00:11:15.840</a></span> | <span class="t">fast AI community member/alumni. And so what we did was we tried fine-tuning lots of models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=684" target="_blank">00:11:24.160</a></span> | <span class="t">on two data sets, one which has over 10 times less images and where those images are not at all like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=692" target="_blank">00:11:32.480</a></span> | <span class="t">ImageNet, that being the Kaggle Planet sample, and one which is a lot like ImageNet and has a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=699" target="_blank">00:11:39.280</a></span> | <span class="t">lot more images, that being IIT pets. And I kind of figured like if we get some insights from those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=706" target="_blank">00:11:46.400</a></span> | <span class="t">two, perhaps they'll be something that we can leverage more generally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=709" target="_blank">00:11:49.360</a></span> | <span class="t">So Thomas wrote this script, which it's 86 lines, but really there's only like three or four lines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=726" target="_blank">00:12:06.880</a></span> | <span class="t">and they're all be lines you recognize, right? The lines are UntieData, ImageDataLoaders.FromBlah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=734" target="_blank">00:12:14.480</a></span> | <span class="t">and then Vision Learner, DLs, Model, etc. So there's the normal like three or four lines of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=743" target="_blank">00:12:23.920</a></span> | <span class="t">code we see over and over again. And then, you know, the rest of it is basically lets you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=749" target="_blank">00:12:29.440</a></span> | <span class="t">pass into the script different choices about batch size, epochs, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=755" target="_blank">00:12:35.680</a></span> | <span class="t">And that's about it. So this is like how simple the script was that we used. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=767" target="_blank">00:12:47.280</a></span> | <span class="t">partly because Thomas works at Weights and Biases, and partly because Weights and Biases is pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=774" target="_blank">00:12:54.240</a></span> | <span class="t">cool. We used Weights and Biases then to feed in different values for each of those parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=783" target="_blank">00:13:03.360</a></span> | <span class="t">So this is a YAML file that Weights and Biases uses where you can say, okay, try each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=790" target="_blank">00:13:10.320</a></span> | <span class="t">different learning rates, try each of these different models, try, let's see if I can find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=796" target="_blank">00:13:16.480</a></span> | <span class="t">another one, try each of these different resize methods, each of these different pooling methods,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=803" target="_blank">00:13:23.520</a></span> | <span class="t">this distribution of learning rates, you know, whatever, and it goes away and tries them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=810" target="_blank">00:13:30.240</a></span> | <span class="t">And then you can use their Web GUI to look at like the training results. So then you basically say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=817" target="_blank">00:13:37.520</a></span> | <span class="t">okay, start training and it trains each of these models of each of these datasets with each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=822" target="_blank">00:13:42.400</a></span> | <span class="t">pool values and each of these resize methods and a few different selections from this distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=826" target="_blank">00:13:46.320</a></span> | <span class="t">of learning rates and creates a Web GUI that you can dive into. I personally hate Web GUIs. I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=834" target="_blank">00:13:54.240</a></span> | <span class="t">much rather use Python, but they also thankfully have an API. So yeah, so once we ran that script</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=841" target="_blank">00:14:01.360</a></span> | <span class="t">for a few hours, I then checked the results into a GIST. So a GIST is just a place to check</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=859" target="_blank">00:14:19.360</a></span> | <span class="t">text files basically, if you haven't used it before. So I checked my CSV file in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=871" target="_blank">00:14:31.920</a></span> | <span class="t">As you can see, it kind of displays it in a nice way, or you can just click on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=876" target="_blank">00:14:36.640</a></span> | <span class="t">to see the raw data. So I find that quite a nice place just to check things which I'm just going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=884" target="_blank">00:14:44.240</a></span> | <span class="t">share publicly. And so then I can check if there's the URL to the GIST.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=889" target="_blank">00:14:49.120</a></span> | <span class="t">And maybe let me show you how I did that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=902" target="_blank">00:15:02.160</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=922" target="_blank">00:15:22.960</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=938" target="_blank">00:15:38.000</a></span> | <span class="t">So I just kind of like everything to be automated so I can always easily redo it because I always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=951" target="_blank">00:15:51.040</a></span> | <span class="t">assume my first effort is going to be crap, and it always is. And normally my second,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=954" target="_blank">00:15:54.640</a></span> | <span class="t">third efforts are crap as well. So here's my little notebook I put together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=961" target="_blank">00:16:01.600</a></span> | <span class="t">So basically, each time you do one of these sweeps on weights and biases, it generates a new ID. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=969" target="_blank">00:16:09.760</a></span> | <span class="t">so we ended up kind of doing five different ones as we realized we were able to add different models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=974" target="_blank">00:16:14.080</a></span> | <span class="t">and change things a little bit. And so they have this API that you can use. And so they you basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=981" target="_blank">00:16:21.600</a></span> | <span class="t">can go through and say, go through each of the sweep IDs and ask the API for that sweep and grab</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=988" target="_blank">00:16:28.560</a></span> | <span class="t">the runs from it. And then for each one create a dictionary containing a summary and the model name.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=994" target="_blank">00:16:34.800</a></span> | <span class="t">So the details don't matter too much, but you kind of get the idea, hopefully, and then turn that into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=998" target="_blank">00:16:38.640</a></span> | <span class="t">a data frame. And so I kind of end up with this data frame that contains all the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1006" target="_blank">00:16:46.800</a></span> | <span class="t">configuration parameters along with their loss and their speed, their accuracy, GPU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1020" target="_blank">00:17:00.560</a></span> | <span class="t">maximum memory usage, and so forth. So that's basically what I wanted to chuck into a GIST.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1028" target="_blank">00:17:08.160</a></span> | <span class="t">And so specifically, I really wanted this subset of the columns. So these are the columns I wanted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1032" target="_blank">00:17:12.560</a></span> | <span class="t">So I can grab those columns and put them into a CSV. Now, one thing you might not realize is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1039" target="_blank">00:17:19.120</a></span> | <span class="t">I would say for most Python libraries, or at least most well-written ones,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1045" target="_blank">00:17:25.520</a></span> | <span class="t">anyway, you can put a file names. And only when you say to CSV, you put here a file name or a path.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1050" target="_blank">00:17:30.240</a></span> | <span class="t">You could instead put something called a string IO object, which is something that behaves exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1055" target="_blank">00:17:35.440</a></span> | <span class="t">like a file, but it actually just stores it into a string. Because I don't want this stored into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1064" target="_blank">00:17:44.080</a></span> | <span class="t">a file, it's put it into a string. So if you then call .getValue, I actually get the string.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1069" target="_blank">00:17:49.680</a></span> | <span class="t">And so even things like creating the GIST, I want to do that automatically. So there's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1075" target="_blank">00:17:55.120</a></span> | <span class="t">library I'm very fond of. I'm very biased because I made it called ghapi, which is an API for GitHub,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1084" target="_blank">00:18:04.800</a></span> | <span class="t">where we can do things like, say, create GIST. And you give it a description. And here's the text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1090" target="_blank">00:18:10.640</a></span> | <span class="t">which is the contents of the CSV. And the file name, make it public. And then you can get the HTML,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1098" target="_blank">00:18:18.000</a></span> | <span class="t">URL of the GIST. So that's how I used, in this case, a notebook as my kind of, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1106" target="_blank">00:18:26.400</a></span> | <span class="t">interactive REPL, read of our print loop for manipulating this data set, putting it together,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1114" target="_blank">00:18:34.720</a></span> | <span class="t">and then uploading it to GitHub. Jeremy, I had a doubt in this fond of data frame. Here you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1121" target="_blank">00:18:41.600</a></span> | <span class="t">it, like, in your, I just take it to put your GIST and it had in the data set entries with planned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1128" target="_blank">00:18:48.240</a></span> | <span class="t">and that other data set as well, the pet status. So how did you populate it? So what's your question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1135" target="_blank">00:18:55.680</a></span> | <span class="t">How did I populate this data set? Yeah. Just here. So I passed it a list of dictionaries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1145" target="_blank">00:19:05.760</a></span> | <span class="t">The list of dictionaries I created using a list comprehension. Okay. Containing a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1152" target="_blank">00:19:12.240</a></span> | <span class="t">dictionaries. Okay. Got it. And so that's going to make each key. So that means all the dictionaries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1161" target="_blank">00:19:21.200</a></span> | <span class="t">should have, you know, roughly the same keys. Anyone sort of missing are going to end up being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1166" target="_blank">00:19:26.160</a></span> | <span class="t">NA. And then I just fiddled around with it slightly. So, for example, make sure everything had an error</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1173" target="_blank">00:19:33.680</a></span> | <span class="t">rate that was equal to one minus the accuracy. On the planet data set, it's not called accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1178" target="_blank">00:19:38.880</a></span> | <span class="t">So I copied accuracy, multi into accuracy. Yeah, nothing very exciting. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1186" target="_blank">00:19:46.960</a></span> | <span class="t">Jeremy, what's the actual goal of this? Let me show you. So what we've now got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1193" target="_blank">00:19:53.200</a></span> | <span class="t">is a CSV, which I can then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1206" target="_blank">00:20:06.800</a></span> | <span class="t">also very helpful. Okay. A CSV, which I can then use Panda's pivot table functionality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1219" target="_blank">00:20:19.520</a></span> | <span class="t">to group by the data set, the model family and name, and calculate the mean of error rate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1226" target="_blank">00:20:26.560</a></span> | <span class="t">fit, time and GPU memory. And I can then take the pets subset of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1236" target="_blank">00:20:36.560</a></span> | <span class="t">sort by score, where score represents a combination of error and speed and take the top 15.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1245" target="_blank">00:20:45.040</a></span> | <span class="t">And this now shows me the top 15 best models for fine-tuning on pets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1255" target="_blank">00:20:55.840</a></span> | <span class="t">And this is this is gold, in my opinion. I don't think anybody's ever done anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1260" target="_blank">00:21:00.080</a></span> | <span class="t">like this before. There's never been a list of like, here are the best models for fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1264" target="_blank">00:21:04.960</a></span> | <span class="t">Sorry, I have a question. So you fine-tuned different models with pets and then collected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1276" target="_blank">00:21:16.000</a></span> | <span class="t">this information. Is that correct? That's correct. And then based on the information that you collected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1281" target="_blank">00:21:21.920</a></span> | <span class="t">from the fine-tuned of five or whatever number of iterations. We did three runs for each model. Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1288" target="_blank">00:21:28.800</a></span> | <span class="t">And then you collected this information to find out which one is the best behave model for this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1297" target="_blank">00:21:37.280</a></span> | <span class="t">specific case. Correct, correct, correct, correct. Exactly. And best is going to involve two things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1303" target="_blank">00:21:43.680</a></span> | <span class="t">It's going to be which ones have the lowest error rate and which ones are the fastest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1307" target="_blank">00:21:47.440</a></span> | <span class="t">Now, I created this kind of arbitrary scoring function where I multiplied the error rate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1313" target="_blank">00:21:53.200</a></span> | <span class="t">times fit time plus 80. Just because I felt like that particular value of that constant gave me an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1320" target="_blank">00:22:00.800</a></span> | <span class="t">ordering that I was reasonably comfortable with. But you can kind of look through here and see like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1325" target="_blank">00:22:05.440</a></span> | <span class="t">okay, well, VIT base has a much better error rate than conv next tiny. But it's also much slower.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1335" target="_blank">00:22:15.360</a></span> | <span class="t">Like, you can decide for your needs where you want to trade off. So that's what I kind of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1342" target="_blank">00:22:22.160</a></span> | <span class="t">the first thing I did was to create this kind of top 15. And it's interesting looking at the family,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1347" target="_blank">00:22:27.120</a></span> | <span class="t">right? The family is like each of these different architectures, you know, is kind of from, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1352" target="_blank">00:22:32.720</a></span> | <span class="t">from, you know, different sizes of a smaller subset of families, right? So there's conv next tiny,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1359" target="_blank">00:22:39.280</a></span> | <span class="t">conv next base, conv next tiny and 22K and so forth. So you can kind of get a sense of like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1366" target="_blank">00:22:46.080</a></span> | <span class="t">if you want to learn more about architectures, which ones seem most interesting and, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1369" target="_blank">00:22:49.920</a></span> | <span class="t">for fine tuning on pets, it looks like conv next, VIT, SWIN, ResNet are the main ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1378" target="_blank">00:22:58.800</a></span> | <span class="t">So that, you know, the first thing I did, the second thing I then did was to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1384" target="_blank">00:23:04.480</a></span> | <span class="t">take those most interesting families, actually also added this one called ResNetX and created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1394" target="_blank">00:23:14.240</a></span> | <span class="t">a scatterplot of them, colored by family. And so you can kind of see, like, for example, conv next,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1403" target="_blank">00:23:23.680</a></span> | <span class="t">which I'm rather fond of, is this kind of blue line, these blue ones, right? And so you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1413" target="_blank">00:23:33.680</a></span> | <span class="t">that the very best error rate actually was a conv next. So they're pretty good. You can see this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1424" target="_blank">00:23:44.880</a></span> | <span class="t">here, which is ResNetX, seems to be, had some pretty nice values. They're like super fast,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1436" target="_blank">00:23:56.800</a></span> | <span class="t">seems like these tiny SWINs seem to be pretty good. So it kind of gives you a sense of like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1442" target="_blank">00:24:02.480</a></span> | <span class="t">you know, depending on how much time you've got to run or how accurate you want to be,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1445" target="_blank">00:24:05.600</a></span> | <span class="t">what families are likely to most useful. And then the last thing I did for pets was I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1455" target="_blank">00:24:15.600</a></span> | <span class="t">grabbed a subset of the basically the ones which are in the top, basically smaller than the median</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1464" target="_blank">00:24:24.000</a></span> | <span class="t">and faster than the median, because these are the ones I generally care about most of the time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1467" target="_blank">00:24:27.840</a></span> | <span class="t">because most of the time I'm going to be training quick iterations. And then I just ordered those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1474" target="_blank">00:24:34.320</a></span> | <span class="t">by error rate. And so conv next tiny has got the best error rate of those which are in the upper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1482" target="_blank">00:24:42.080</a></span> | <span class="t">half of both speed and accuracy. >> What's GPU memory in this context?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1491" target="_blank">00:24:51.520</a></span> | <span class="t">>> That's the maximum amount of GPU memory that was used. I can't remember what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1497" target="_blank">00:24:57.360</a></span> | <span class="t">the units of measure are, but they don't matter too much because it'll be different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1504" target="_blank">00:25:04.800</a></span> | <span class="t">for your dataset or that matters is the relative usage. And so if you want something,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1513" target="_blank">00:25:13.280</a></span> | <span class="t">you know, if you try to use this and it's actually uses too much GPU memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1518" target="_blank">00:25:18.960</a></span> | <span class="t">you could try ResNet 50D, for example, or, you know, it's interesting that like ResNet 26</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1528" target="_blank">00:25:28.240</a></span> | <span class="t">is really good for memory and speed. Or if you want something really lightweight on memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1536" target="_blank">00:25:36.560</a></span> | <span class="t">RegNet Y004. But the error rates are getting much worse once you get out to here, as you can see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1544" target="_blank">00:25:44.160</a></span> | <span class="t">So then I looked at Planet. And so as I said, Planet's kind of as different a dataset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1551" target="_blank">00:25:51.920</a></span> | <span class="t">as you're going to get in one sense, or it's very different. And so not surprisingly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1560" target="_blank">00:26:00.400</a></span> | <span class="t">its top 15 is also very different. And interestingly, all of the top six are from the same family.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1569" target="_blank">00:26:09.120</a></span> | <span class="t">So this VIT family, these are kind of model called transformers models. And what this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1575" target="_blank">00:26:15.760</a></span> | <span class="t">basically showing is that these models are particularly good at rapidly identifying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1583" target="_blank">00:26:23.360</a></span> | <span class="t">features of data types it hasn't seen before. So, you know, if you were doing something like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1588" target="_blank">00:26:28.880</a></span> | <span class="t">medical imaging or satellite imagery or something like that, these would probably be a good thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1593" target="_blank">00:26:33.920</a></span> | <span class="t">to try. And SWIN, by the way, is kind of another transformers based model, which, as you can see,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1601" target="_blank">00:26:41.680</a></span> | <span class="t">it's actually the most accurate at all, but it's also the smallest. This is SWIN V2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1608" target="_blank">00:26:48.160</a></span> | <span class="t">So I thought that was pretty interesting. And, you know, these VIT models, there are ones with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1619" target="_blank">00:26:59.360</a></span> | <span class="t">pretty good error rates that also have very little memory use and also run very quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1623" target="_blank">00:27:03.760</a></span> | <span class="t">So I did the same thing for Planet. And so perhaps not surprisingly, but interestingly for Planet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1632" target="_blank">00:27:12.960</a></span> | <span class="t">these lines don't necessarily go down, which is to say that the really big models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1639" target="_blank">00:27:19.440</a></span> | <span class="t">the big slow models don't necessarily have better error rates. And that makes sense, right? Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1646" target="_blank">00:27:26.000</a></span> | <span class="t">if they've got heaps of parameters, but they're trying to learn something they've never seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1649" target="_blank">00:27:29.680</a></span> | <span class="t">before on very little data, it's unlikely we're going to be able to take advantage of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1654" target="_blank">00:27:34.160</a></span> | <span class="t">parameters. So when you're doing stuff that doesn't really look much like ImageNet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1661" target="_blank">00:27:41.760</a></span> | <span class="t">you might want to be down more towards this end. So here's the VIT, for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1672" target="_blank">00:27:52.880</a></span> | <span class="t">And here's that really good SWIN model. And there's ConfNEXT Tiny. So then we can do the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1681" target="_blank">00:28:01.600</a></span> | <span class="t">same thing again of like, okay, let's take the top half, both in terms of speed and memory use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1686" target="_blank">00:28:06.640</a></span> | <span class="t">Yeah, ConfNEXT Tiny still looks good. These VIT models is 224. Yeah, this is because you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1696" target="_blank">00:28:16.400</a></span> | <span class="t">only run these models on images of size 224 by 224. You can't use different sizes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1704" target="_blank">00:28:24.160</a></span> | <span class="t">whereas the ConfNEXT models, you can use any size. So it's also interesting to see the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1711" target="_blank">00:28:31.360</a></span> | <span class="t">classic ResNet still. Again, they do pretty well. Yeah, so I'm pretty excited about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1721" target="_blank">00:28:41.760</a></span> | <span class="t">It feels like exactly what we need to kick us on this PADI doctor competition, or indeed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1732" target="_blank">00:28:52.240</a></span> | <span class="t">any kind of computer vision classification task needs this. And I ran this sweep on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1748" target="_blank">00:29:08.240</a></span> | <span class="t">three consumer RTX GPUs in 12 hours or something. Like this is not big institutional resources</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1759" target="_blank">00:29:19.120</a></span> | <span class="t">required. And one of the reasons why is because I didn't try every possible level of everything,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1770" target="_blank">00:29:30.160</a></span> | <span class="t">right? I tried a couple of, you know, so Thomas did a kind of a quick learning rate sweep to kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1780" target="_blank">00:29:40.560</a></span> | <span class="t">of get a sense of the broad range of learning rates that seemed pretty good. And then we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1784" target="_blank">00:29:44.000</a></span> | <span class="t">tried a couple of learning rates and a couple of the best resize methods and a couple of the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1788" target="_blank">00:29:48.640</a></span> | <span class="t">polling types across a few broadly different kinds of models across the two different datasets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1798" target="_blank">00:29:58.880</a></span> | <span class="t">to kind of see if there was any common features. And we found in every single case the same learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1804" target="_blank">00:30:04.160</a></span> | <span class="t">rate, the same resize method and the same polling type was the best. So we didn't need to try every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1809" target="_blank">00:30:09.120</a></span> | <span class="t">possible combination of everything, you know. And this is where like a lot of the stuff you see from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1815" target="_blank">00:30:15.040</a></span> | <span class="t">like Google and stuff, they tend to do hundreds of thousands of experiments, because I guess they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1821" target="_blank">00:30:21.280</a></span> | <span class="t">have no need to do things efficiently, right? Yeah, but you don't have to do it the Google way. You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1830" target="_blank">00:30:30.320</a></span> | <span class="t">can do it the fast AI way. Quick question, Jeremy. Which cards did you use? And another question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1843" target="_blank">00:30:43.520</a></span> | <span class="t">is, which cards did you say? Yeah, the GPU cards. Oh, RTX 3090. Oh, okay. So they were all three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1852" target="_blank">00:30:52.960</a></span> | <span class="t">different. They're all RTX 3090s. Okay. And you reset the index after the query? Why? Oh, just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1864" target="_blank">00:31:04.080</a></span> | <span class="t">because otherwise, it shows the numeric ID here will be the numeric ID from the original dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1871" target="_blank">00:31:11.360</a></span> | <span class="t">And I wanted to be able to quickly kind of say, what's number six? What's number 10? What's number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1874" target="_blank">00:31:14.560</a></span> | <span class="t">three? That's all. So visually. Yeah. Okay. Jeremy, getting back to the earth,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1882" target="_blank">00:31:22.720</a></span> | <span class="t">satellite images, when you say, you know, like the classification, what is it trying to classify?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1889" target="_blank">00:31:29.120</a></span> | <span class="t">In this case, the planet competition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1892" target="_blank">00:31:32.640</a></span> | <span class="t">We have some examples. Basically, they try to classify for each area of the satellite imagery.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1919" target="_blank">00:31:59.680</a></span> | <span class="t">What's it a picture of? Is it forest or farmland or town or whatever?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1926" target="_blank">00:32:06.720</a></span> | <span class="t">And what weather conditions to observe, if I remember correctly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1930" target="_blank">00:32:10.880</a></span> | <span class="t">Question in this image space is, is it just these two major datasets? Or how do you find other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1943" target="_blank">00:32:23.200</a></span> | <span class="t">models that are trained on beside the planet and imagine it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1947" target="_blank">00:32:27.440</a></span> | <span class="t">Oh, you mean beside planet and pets? Sorry. Yep. That's the answer. What was your question? How</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1954" target="_blank">00:32:34.400</a></span> | <span class="t">do you do what with them? How do you find other trained pre-trained models that have been worked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1960" target="_blank">00:32:40.800</a></span> | <span class="t">on different data sets? These all use pre-trained models, pre-trained on ImageNet. These are only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1966" target="_blank">00:32:46.560</a></span> | <span class="t">using pre-trained models, pre-trained on ImageNet. So how do you find pre-trained models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1972" target="_blank">00:32:52.320</a></span> | <span class="t">pre-trained on other things? Mainly, you don't. There aren't many. But, you know, just Google.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1980" target="_blank">00:33:00.160</a></span> | <span class="t">Depends what you're interested in. And academic papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=1987" target="_blank">00:33:07.040</a></span> | <span class="t">There's there is a I don't know how it's doing. It's there was a model. So there is a model zoo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2000" target="_blank">00:33:20.720</a></span> | <span class="t">Which I've never had much success with, to be honest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2005" target="_blank">00:33:25.600</a></span> | <span class="t">So these are a range of pre-trained models that you can download.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2015" target="_blank">00:33:35.920</a></span> | <span class="t">Yeah. But as I say, I haven't found it particularly successful, to be honest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2021" target="_blank">00:33:41.520</a></span> | <span class="t">You could also try papers with papers with code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2025" target="_blank">00:33:45.440</a></span> | <span class="t">And I think these, yeah, they have a link to the paper and the code. That doesn't necessarily mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2039" target="_blank">00:33:59.760</a></span> | <span class="t">they've got a pre-trained model. And then you can just click on the code and see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2048" target="_blank">00:34:08.480</a></span> | <span class="t">And of course, for NLP models, there's the Hugging Face Model Hub, which we've seen before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2062" target="_blank">00:34:22.160</a></span> | <span class="t">And that is an easy answer for NLP. Lots of different pre-trained models are on that hub.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2069" target="_blank">00:34:29.200</a></span> | <span class="t">Jeremy, since you touch on academic papers and papers with code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2076" target="_blank">00:34:36.560</a></span> | <span class="t">first question, will this comparison, do you or Tomau intend to publish it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2082" target="_blank">00:34:42.880</a></span> | <span class="t">If not, if you were to do that, what would you go for, actually? What kind of journal would you look at?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2092" target="_blank">00:34:52.720</a></span> | <span class="t">So I'm not a good person to ask that question because I very rarely publish anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2099" target="_blank">00:34:59.120</a></span> | <span class="t">Which is partly a philosophical thing. I find academia overly exclusive and I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2108" target="_blank">00:35:08.560</a></span> | <span class="t">love PDFs as a publication form. And I don't love the writing style, which is kind of required if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2115" target="_blank">00:35:15.280</a></span> | <span class="t">you're going to get published as being rather difficult to follow. I have published a couple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2126" target="_blank">00:35:26.000</a></span> | <span class="t">of papers, but like only really one significant deep learning one. And that was because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2132" target="_blank">00:35:32.720</a></span> | <span class="t">a guy named Sebastian Ruder was doing his PhD at the time. And he said it'd be really helpful to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2139" target="_blank">00:35:39.600</a></span> | <span class="t">him if we could co-publish something and that he would kind of take the lead on writing the paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2145" target="_blank">00:35:45.920</a></span> | <span class="t">And so that was good because I'm always very happy to help students. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2152" target="_blank">00:35:52.080</a></span> | <span class="t">he did a good job and he was a terrific researcher to work with. The other time I've written a paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2159" target="_blank">00:35:59.680</a></span> | <span class="t">the main time was when I wanted to get that message out about masks. And I felt like it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2165" target="_blank">00:36:05.360</a></span> | <span class="t">probably not going to be taken seriously unless it's in an exclusive academic paper because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2169" target="_blank">00:36:09.520</a></span> | <span class="t">medical people are very inter-exclusive things. So I don't know. I'd say this kind of thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2179" target="_blank">00:36:19.120</a></span> | <span class="t">I suspect would be quite hard to publish because most deep learning academic venues are very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2186" target="_blank">00:36:26.320</a></span> | <span class="t">focused on things with kind of reasonably strong theoretical pieces. And this kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2193" target="_blank">00:36:33.840</a></span> | <span class="t">field of like trying things and seeing what works is experiment-based is certainly a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2206" target="_blank">00:36:46.160</a></span> | <span class="t">very important part of science in other areas. But in the deep learning world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2209" target="_blank">00:36:49.760</a></span> | <span class="t">it hasn't really yet been recognized as a valid source of research, as far as I can tell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2215" target="_blank">00:36:55.840</a></span> | <span class="t">I could concur with all the domains and feel the same quandary to be honest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2221" target="_blank">00:37:01.760</a></span> | <span class="t">Fair enough. What's your domain?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2223" target="_blank">00:37:03.920</a></span> | <span class="t">Hydrology, but more the computational science part of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2234" target="_blank">00:37:14.480</a></span> | <span class="t">Okay. So then what I did was I,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2245" target="_blank">00:37:25.760</a></span> | <span class="t">I mean, this is kind of a bit at the same time, but I went back to Patty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2255" target="_blank">00:37:35.360</a></span> | <span class="t">and I wanted to try out a few of these interesting looking models reasonably quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2266" target="_blank">00:37:46.080</a></span> | <span class="t">So what I did was I kind of took our standard, well, in this case, three lines of code because I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2281" target="_blank">00:38:01.280</a></span> | <span class="t">already untarted earlier, took our three lines of code. So I could basically say train and pass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2289" target="_blank">00:38:09.520</a></span> | <span class="t">in an architecture and pass in some per item pre-processing, in this case resizing everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2299" target="_blank">00:38:19.280</a></span> | <span class="t">to the same square using Squish and some per batch pre-processing, which in this case is the standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2305" target="_blank">00:38:25.280</a></span> | <span class="t">fast AI data augmentation transforms targeting a final size of 224, which is what most models tend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2312" target="_blank">00:38:32.560</a></span> | <span class="t">to be trained at. And so then train a model using those parameters. And then finally, it would use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2322" target="_blank">00:38:42.720</a></span> | <span class="t">test time augmentation. So test time augmentation is where I think we briefly mentioned it last time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2329" target="_blank">00:38:49.920</a></span> | <span class="t">We, in this case, on the validation set, I basically run the fine-tuned model four times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2341" target="_blank">00:39:01.920</a></span> | <span class="t">using random data augmentations each time. And then I run it one more time with no data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2349" target="_blank">00:39:09.360</a></span> | <span class="t">augmentations at all and take an average of all of those five predictions basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2353" target="_blank">00:39:13.760</a></span> | <span class="t">And that gives me some predictions. And then I take an error rate for TTA for the test time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2360" target="_blank">00:39:20.560</a></span> | <span class="t">augmentation. So that basically spits out a number, which is an error rate for PADI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2368" target="_blank">00:39:28.000</a></span> | <span class="t">And I use a fixed random seed when picking out my validation set. So each time I run this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2377" target="_blank">00:39:37.200</a></span> | <span class="t">it's going to be with the same validation set. And so I can compare. So I've got a few different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2382" target="_blank">00:39:42.320</a></span> | <span class="t">conf next small models I've run. First of all, by squishing when I resize and then by cropping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2391" target="_blank">00:39:51.680</a></span> | <span class="t">when I resize. So that was 235. This is also 235. And then instead of resizing to a square,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2404" target="_blank">00:40:04.160</a></span> | <span class="t">I resize to a rectangle. In theory, this wouldn't have been necessary. I thought they were all 480</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2413" target="_blank">00:40:13.120</a></span> | <span class="t">by 640. But when I ran this, I got an error. And then I looked back at the results of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2419" target="_blank">00:40:19.680</a></span> | <span class="t">parallel image sizing thing we ran. And I realized there was actually three or four images that were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2424" target="_blank">00:40:24.880</a></span> | <span class="t">the opposite aspect ratio. So that's why. So the vast majority of the images,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2432" target="_blank">00:40:32.240</a></span> | <span class="t">this resizing does nothing at all. But it's three or four that are the opposite aspect ratio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2437" target="_blank">00:40:37.440</a></span> | <span class="t">And then for the augmentation, yeah, pick a size based on 224</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2445" target="_blank">00:40:45.680</a></span> | <span class="t">of a similar aspect ratio. But what I'm actually aiming for here is something that is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2454" target="_blank">00:40:54.800</a></span> | <span class="t">multiple of 32 on both edges. And the reason for that we'll kind of get into later when we learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2461" target="_blank">00:41:01.840</a></span> | <span class="t">about how convolutional networks really work. But it basically turns out that the kind of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2467" target="_blank">00:41:07.200</a></span> | <span class="t">final patch size in a conf net is 32 by 32 pixels. So you generally want both of your sides. Normally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2474" target="_blank">00:41:14.560</a></span> | <span class="t">you want them to be multiples of 32. So this one got a pretty similar result again, 240. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2483" target="_blank">00:41:23.360</a></span> | <span class="t">I wasn't sure about my contention that they need to be multiples of 32. I thought maybe it's better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2488" target="_blank">00:41:28.320</a></span> | <span class="t">if they like a really crisp resizing by using an exact multiple. So I tried that as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2495" target="_blank">00:41:35.920</a></span> | <span class="t">And that, as I suspected, was a bit worse. Oh, what's this? I've got some which,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2513" target="_blank">00:41:53.520</a></span> | <span class="t">which ones are the right way around? Now I'm confused. I think, let's check.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2521" target="_blank">00:42:01.600</a></span> | <span class="t">Some of these, originally I had my aspect ratio backwards. That's why I've got both. It looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2534" target="_blank">00:42:14.960</a></span> | <span class="t">like I never got around to removing the ones that were unnecessary. Oops, wrong button.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2543" target="_blank">00:42:23.200</a></span> | <span class="t">Copy paste size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2549" target="_blank">00:42:29.120</a></span> | <span class="t">Paste.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2556" target="_blank">00:42:36.080</a></span> | <span class="t">Leave those off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2569" target="_blank">00:42:49.680</a></span> | <span class="t">Method equals add.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2572" target="_blank">00:42:52.640</a></span> | <span class="t">Oops, pad mode. This makes it a bit easier to see what's going on if you do padding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2585" target="_blank">00:43:05.680</a></span> | <span class="t">with black around them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2598" target="_blank">00:43:18.800</a></span> | <span class="t">There we go. Okay, yeah, so you can clearly see this is the one way around,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2608" target="_blank">00:43:28.320</a></span> | <span class="t">right? I've tried to make them wide, but actually they were tall. So the best way around is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2614" target="_blank">00:43:34.640</a></span> | <span class="t">640 by 480. That's more like it. So 640 by 480 is best. So let's get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2628" target="_blank">00:43:48.640</a></span> | <span class="t">rid of the ones that were the wrong way around. Okay, all right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2636" target="_blank">00:43:56.800</a></span> | <span class="t">Yeah, so that was all, you know, various different transforms, pre-processing for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2646" target="_blank">00:44:06.080</a></span> | <span class="t">ConvNEXT Small, and then I did the same thing for one of the VITs, VIT Small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2655" target="_blank">00:44:15.840</a></span> | <span class="t">Now VIT, remember I mentioned it can only work on 224 by 224 images, so these rectangular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2662" target="_blank">00:44:22.880</a></span> | <span class="t">approaches aren't going to be possible. So I've just got the squish and the crop versions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2670" target="_blank">00:44:30.720</a></span> | <span class="t">The crop version doesn't look very good. The squish version must look pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2677" target="_blank">00:44:37.280</a></span> | <span class="t">And I also tried a pad version, which looks pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2695" target="_blank">00:44:55.680</a></span> | <span class="t">And then, yeah, I also tried SWIN, so here's SWIN V2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2703" target="_blank">00:45:03.760</a></span> | <span class="t">And this one is slow and memory intensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2709" target="_blank">00:45:09.840</a></span> | <span class="t">So I had to go down to the 192 pixel version, but actually it seems to work very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2719" target="_blank">00:45:19.920</a></span> | <span class="t">This is the first time we've had one that's better than 0.02, which is interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2732" target="_blank">00:45:32.800</a></span> | <span class="t">This one's also very good. So it's interesting that this slow memory intensive model works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2740" target="_blank">00:45:40.640</a></span> | <span class="t">better even on smaller size, 192 pixel size, which I think is pretty interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2746" target="_blank">00:45:46.480</a></span> | <span class="t">And then there was one more SWIN, which seemed to do pretty well, so I included that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2754" target="_blank">00:45:54.240</a></span> | <span class="t">which I was able to do at 224. That one had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2759" target="_blank">00:45:59.440</a></span> | <span class="t">OK results. So I kind of did that for all these different small models. And as you can see,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2769" target="_blank">00:46:09.440</a></span> | <span class="t">they run pretty quickly, right? 5 or 10 minutes. And so then I picked out the ones that look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2778" target="_blank">00:46:18.560</a></span> | <span class="t">pretty fast, pretty accurate, and created just a copy of that, which are called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2790" target="_blank">00:46:30.880</a></span> | <span class="t">patty large. And this time I just replaced small with large.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2795" target="_blank">00:46:35.360</a></span> | <span class="t">And actually, I've made a mistake. I'm going to have to rerun this because there should not be a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2805" target="_blank">00:46:45.680</a></span> | <span class="t">seed equals 42. I actually want to run this on a different subset each time. And the reason why is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2811" target="_blank">00:46:51.680</a></span> | <span class="t">my plan is to train. So basically what I did was I deleted the ones that were less good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2819" target="_blank">00:46:59.760</a></span> | <span class="t">in patty small. And so now I'm just running the large ones. Now some of these, particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2827" target="_blank">00:47:07.680</a></span> | <span class="t">something like this one, which is 288 by 224, they ran out of memory. They were too big for my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2834" target="_blank">00:47:14.960</a></span> | <span class="t">graphics card. And a lot of people at this point say, oh, I need to go buy a more expensive graphics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2841" target="_blank">00:47:21.040</a></span> | <span class="t">card. But that's not true. You don't. So if you guys remember our training loop, we get the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2854" target="_blank">00:47:34.880</a></span> | <span class="t">gradients. We add the gradients times the learning rate to the weights. And then we zero the gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2864" target="_blank">00:47:44.080</a></span> | <span class="t">What you could do is half the batch size. So for example, from 64 to 32. And then only zero the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2872" target="_blank">00:47:52.880</a></span> | <span class="t">gradients every two iterations. And only do the update every two iterations. So basically you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2881" target="_blank">00:48:01.360</a></span> | <span class="t">calculate in two batches what you used to calculate in one batch. And it will be mathematically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2886" target="_blank">00:48:06.960</a></span> | <span class="t">identical. And that's called gradient accumulation. And so for the ones which ran out of memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2893" target="_blank">00:48:13.440</a></span> | <span class="t">I added this little acume equals true, which is here in my function. And I said, yeah, I said if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2901" target="_blank">00:48:21.200</a></span> | <span class="t">acume equals true, then set the batch size to 32. Because by default it's 64. And add this thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2909" target="_blank">00:48:29.760</a></span> | <span class="t">called a callback. Callbacks are basically things that change the behavior of the training. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2914" target="_blank">00:48:34.960</a></span> | <span class="t">there's a thing called gradient accumulation callback. Which gradient accumulation. And this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2932" target="_blank">00:48:52.880</a></span> | <span class="t">is like just for people that are interested. This is not like massively complex stuff. The entire</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2940" target="_blank">00:49:00.720</a></span> | <span class="t">gradient accumulation callback is that many lines of code. Right? These are not big things. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2947" target="_blank">00:49:07.520</a></span> | <span class="t">like literally all it does is it keeps a count of how many iterations it's been. And it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2957" target="_blank">00:49:17.760</a></span> | <span class="t">adds the, you know, keeps track of the count. And as long as we're not up to the point where we,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2969" target="_blank">00:49:29.360</a></span> | <span class="t">there's the number of accumulations we want, we skip the step and the zero gradient basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2976" target="_blank">00:49:36.320</a></span> | <span class="t">So it's, yeah, things like gradient accumulation, they sound like big complex things. But they,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2984" target="_blank">00:49:44.880</a></span> | <span class="t">yeah, turn out not to be. At least when you have a nice code base like fast AIs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=2996" target="_blank">00:49:56.720</a></span> | <span class="t">Jeremy, can I get a question here? How exactly do the batch size mass animations work?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3004" target="_blank">00:50:04.880</a></span> | <span class="t">So we will get into that in detail in the course. And certainly we get into it in detail in the book.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3015" target="_blank">00:50:15.360</a></span> | <span class="t">But basically all that happens is we randomly shuffle the dataset and we grab, so if the batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3025" target="_blank">00:50:25.120</a></span> | <span class="t">size is 64, we grab the next 64 images. We resize them all to be the same size and we stack them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3034" target="_blank">00:50:34.800</a></span> | <span class="t">on top of each other. So if it's black and white images, for example, we would have 64,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3041" target="_blank">00:50:41.600</a></span> | <span class="t">whatever, 640 by 480 images. And so we would end up with a 640 by, 64 by 640 by 480</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3053" target="_blank">00:50:53.840</a></span> | <span class="t">tensor. And pretty much all the functionality provided by TyTorch will work fine for a mini</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3066" target="_blank">00:51:06.320</a></span> | <span class="t">batch of things, just as it would for a single thing on the whole.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3073" target="_blank">00:51:13.600</a></span> | <span class="t">So in the larger scheme of things, you know, like some huge processes that's trying to characterise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3083" target="_blank">00:51:23.200</a></span> | <span class="t">what role does the batch sort of play? Well, it's just about trying to get the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3091" target="_blank">00:51:31.440</a></span> | <span class="t">most out of your GPU. Your GPU can do 10,000 things at once. So if you just give it one image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3098" target="_blank">00:51:38.240</a></span> | <span class="t">at a time, you can use it. So if you give it 64 things, it can do one, you know, a thing on each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3106" target="_blank">00:51:46.560</a></span> | <span class="t">image and then on each channel in that image, and then you don't have another few other kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3111" target="_blank">00:51:51.120</a></span> | <span class="t">degrees of parallization it can do. And so that's where you start with, you know, we saw that NVIDIA</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3117" target="_blank">00:51:57.360</a></span> | <span class="t">SMI daemon command that shows you the utilisation of your symmetric multiprocessor. Yeah, if you use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3125" target="_blank">00:52:05.280</a></span> | <span class="t">a batch size of one, you'll see that SM will be like 1%, 2% and everything will be useless.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3130" target="_blank">00:52:10.640</a></span> | <span class="t">It's a bit tricky at inference time, you know, in production or whatever, because,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3136" target="_blank">00:52:16.320</a></span> | <span class="t">you know, most of the time you only get one thing to do at a time. And so often inference is done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3142" target="_blank">00:52:22.400</a></span> | <span class="t">on CPU rather than GPU, because we don't get to benefit from batching.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3152" target="_blank">00:52:32.960</a></span> | <span class="t">Or, you know, all people will queue a few of them up and stick the model in the GPU at once. And,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3157" target="_blank">00:52:37.840</a></span> | <span class="t">you know, stuff like that. But yeah, for training, it's pretty easy to take advantage of many batches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3162" target="_blank">00:52:42.560</a></span> | <span class="t">Okay, thank you. No worries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3165" target="_blank">00:52:45.840</a></span> | <span class="t">Jeremy, you've trained so many models. Will you consider using a majority vote or something like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3176" target="_blank">00:52:56.880</a></span> | <span class="t">that? No, I wouldn't, because a majority vote throws away information, it throws away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3184" target="_blank">00:53:04.400</a></span> | <span class="t">the probabilities. So I pretty much always find I get better results by averaging the probabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3192" target="_blank">00:53:12.400</a></span> | <span class="t">So each of them, each of the models after I've trained it, I'm exporting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3198" target="_blank">00:53:18.160</a></span> | <span class="t">to a uniquely named model, which is going to be the name of the architecture, then an underscore,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3205" target="_blank">00:53:25.440</a></span> | <span class="t">and then some description, which is just the thing I pass in. And so that way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3209" target="_blank">00:53:29.840</a></span> | <span class="t">yeah, when I'm done training, I can just have a little loop which opens each of those models up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3216" target="_blank">00:53:36.560</a></span> | <span class="t">grabs the TTA predictions, sticks them into a list. And then at the end, I'll average those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3226" target="_blank">00:53:46.320</a></span> | <span class="t">TTA predictions across the models. And that will be my ensemble prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3233" target="_blank">00:53:53.440</a></span> | <span class="t">So that's my next step. I'm not up to that yet. Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3237" target="_blank">00:53:57.040</a></span> | <span class="t">All right. Well, I think that's it. So that's really more of a like little update on what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3247" target="_blank">00:54:07.120</a></span> | <span class="t">I've been doing over my weekend. But hopefully, yeah, gives you some ideas for things to try.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3257" target="_blank">00:54:17.200</a></span> | <span class="t">And hopefully, you find the Kaggle notebook useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3263" target="_blank">00:54:23.040</a></span> | <span class="t">So Jeremy, so how many hours did you spend in all these explanations? Because you spend a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3274" target="_blank">00:54:34.240</a></span> | <span class="t">experiments here. So, you know, it's like a week or two of work to do the fine tuning experiments,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3283" target="_blank">00:54:43.600</a></span> | <span class="t">but that was like a few hours here and a few hours there. The final sweep was probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3290" target="_blank">00:54:50.480</a></span> | <span class="t">maybe six hours of three GPUs. The patty competition stuff was maybe four hours a day</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3309" target="_blank">00:55:09.440</a></span> | <span class="t">over the last four days since I last saw you guys. And writing the notebook was maybe another four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3316" target="_blank">00:55:16.160</a></span> | <span class="t">hours. Thanks. It helps. No worries. All right. Bye, everybody. Nice to see you all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zhBRynq9Yvo&t=3326" target="_blank">00:55:26.320</a></span> | <span class="t">Bye so much. Thanks, Jeremy. Bye, everyone.</span></div></div></body></html>