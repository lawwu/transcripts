<html><head><title>AGI Inches Closer - 5 Key Quotes: Altman, Huang and 'The Most Interesting Year'</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>AGI Inches Closer - 5 Key Quotes: Altman, Huang and 'The Most Interesting Year'</h2><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y"><img src="https://i.ytimg.com/vi/fPzp_sdCf2Y/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./fPzp_sdCf2Y.html">Whisper Transcript</a> | <a href="./transcript_fPzp_sdCf2Y.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">It has been an interesting few days for the pursuit of Artificial General Intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=5" target="_blank">00:00:05.300</a></span> | <span class="t">So I wanted to give you some of the highlights from GPT 4 point something to recursively improving semiconductor manufacturing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=14" target="_blank">00:00:14.820</a></span> | <span class="t">We got at least five revealing quotes from Jensen Huang, Sam Altman and others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=20" target="_blank">00:00:20.340</a></span> | <span class="t">And the summary is this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=22" target="_blank">00:00:22.260</a></span> | <span class="t">If you thought or know someone who thinks that Artificial Intelligence peaked with chat GPT, you or they are going to have to weather exponential increases in computational power through at least the rest of this decade.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=37" target="_blank">00:00:37.020</a></span> | <span class="t">As Sam Altman just said of 2024, and I agree, this is the most interesting year in human history, except for all future years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=46" target="_blank">00:00:46.140</a></span> | <span class="t">So let's start with Sam Altman, who said that OpenAI's goal is to avoid shocking updates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=52" target="_blank">00:00:52.660</a></span> | <span class="t">Our goal is not to have shock updates to the world, but that's what we're trying to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=56" target="_blank">00:00:56.860</a></span> | <span class="t">That's like our state of the strategy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=58" target="_blank">00:00:58.500</a></span> | <span class="t">And I think we're somehow missing the mark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=60" target="_blank">00:01:00.620</a></span> | <span class="t">So maybe we should think about, you know, releasing GPT 5 in a different way or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=65" target="_blank">00:01:05.020</a></span> | <span class="t">Yeah, 4.71, 4.72.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=68" target="_blank">00:01:08.540</a></span> | <span class="t">And what does he mean by releasing iteratively without shock updates?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=72" target="_blank">00:01:12.500</a></span> | <span class="t">Well, probably something similar to another co-founder of OpenAI, Greg Brockman.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=76" target="_blank">00:01:16.780</a></span> | <span class="t">He said that their plan for safety involved deploying GPT 5 in stages, essentially creating a continuum of incrementally better AIs, such as by deploying subsequent checkpoints of a given training run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=89" target="_blank">00:01:29.780</a></span> | <span class="t">Think of that like saves on the way to completing a video game.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=93" target="_blank">00:01:33.580</a></span> | <span class="t">In short, it's highly likely now that we will be getting something equivalent to GPT 4.5 before we get GPT 5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=100" target="_blank">00:01:40.460</a></span> | <span class="t">As to whether the marketing department comes up with a better name than GPT 4.5, well, let's see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=106" target="_blank">00:01:46.020</a></span> | <span class="t">And on timing, he said this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=108" target="_blank">00:01:48.020</a></span> | <span class="t">Blink twice if it's this year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=110" target="_blank">00:01:50.140</a></span> | <span class="t">I also...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=116" target="_blank">00:01:56.380</a></span> | <span class="t">We will release an amazing new model this year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=120" target="_blank">00:02:00.660</a></span> | <span class="t">I don't know what we'll call it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=122" target="_blank">00:02:02.140</a></span> | <span class="t">We'll release over in the coming months.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=126" target="_blank">00:02:06.060</a></span> | <span class="t">Many different things, I think they'll be very cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=128" target="_blank">00:02:08.540</a></span> | <span class="t">I think before we talk about like a GPT 5 like model called that or not called that or a little bit worse or a little bit better than what you'd expect from a GPT 5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=137" target="_blank">00:02:17.660</a></span> | <span class="t">I know we have a lot of other important things to release.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=140" target="_blank">00:02:20.460</a></span> | <span class="t">And don't forget that not all progress depends on new models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=143" target="_blank">00:02:23.140</a></span> | <span class="t">We can have new systems like Let's Verify or Q* based on existing models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=148" target="_blank">00:02:28.300</a></span> | <span class="t">Sam Altman practically confirmed the existence of Q* in this interview with Lex Friedman from yesterday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=154" target="_blank">00:02:34.180</a></span> | <span class="t">Can you speak to what Q* is?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=156" target="_blank">00:02:36.060</a></span> | <span class="t">We are not ready to talk about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=157" target="_blank">00:02:37.820</a></span> | <span class="t">See, but an answer like that means there's something to talk about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=160" target="_blank">00:02:40.660</a></span> | <span class="t">It's very mysterious, Sam.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=162" target="_blank">00:02:42.980</a></span> | <span class="t">I mean, we work on all kinds of research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=165" target="_blank">00:02:45.820</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=166" target="_blank">00:02:46.820</a></span> | <span class="t">I've done an entire video gathering the best evidence as to what Q* is, so do check that one out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=174" target="_blank">00:02:54.180</a></span> | <span class="t">But if you want the massively condensed TL;DR, it's this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=177" target="_blank">00:02:57.940</a></span> | <span class="t">Models can essentially think or compute for longer on harder questions and generate thousands of example answers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=185" target="_blank">00:03:05.780</a></span> | <span class="t">and have internal systems for checking which answer is best and only showing you that best answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=190" target="_blank">00:03:10.980</a></span> | <span class="t">A system two to complement the base system one thinking, if you will.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=195" target="_blank">00:03:15.020</a></span> | <span class="t">But before we leave that interview, there were two more fascinating quotes, at least from my perspective, that I want to show you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=200" target="_blank">00:03:20.460</a></span> | <span class="t">One involved the possible social response to ever improving AI and the chances of it going theatrically wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=207" target="_blank">00:03:27.300</a></span> | <span class="t">I worry about that for AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=208" target="_blank">00:03:28.460</a></span> | <span class="t">I think some things are going to go theatrically wrong with AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=212" target="_blank">00:03:32.860</a></span> | <span class="t">I don't know what the percent chance is that I eventually get shot, but it's not zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=218" target="_blank">00:03:38.780</a></span> | <span class="t">I'll come back to social responses later in this video, but that was a startling moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=225" target="_blank">00:03:45.500</a></span> | <span class="t">At the moment, at least, thankfully, the power struggle for AGI is only financial.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=231" target="_blank">00:03:51.340</a></span> | <span class="t">Here is Demis Hassabis essentially laughing when an interviewer said that OpenAI was a non-profit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=238" target="_blank">00:03:58.140</a></span> | <span class="t">A lot of AI labs have been grappling with governance and what is the best structure for something like AGI to emerge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=245" target="_blank">00:04:05.820</a></span> | <span class="t">You just mentioned the possibility of some sort of international collective or cooperative that would handle this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=251" target="_blank">00:04:11.340</a></span> | <span class="t">But, you know, across the industry, like OpenAI has set itself up as a non-profit with a for-profit subsidiary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=257" target="_blank">00:04:17.780</a></span> | <span class="t">Anthropic is a public benefit corporation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=260" target="_blank">00:04:20.660</a></span> | <span class="t">So before we get to NVIDIA's GTC, let's linger for a moment on AGI, its definition and recent updates to the timeline to AGI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=270" target="_blank">00:04:30.020</a></span> | <span class="t">Yesterday, Andrej Karpathy, who was until recently at the very top of OpenAI, said this about the definition of AGI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=277" target="_blank">00:04:37.660</a></span> | <span class="t">He thinks of it like the OpenAI charter as being an autonomous system that surpasses humans in most economically valuable tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=285" target="_blank">00:04:45.260</a></span> | <span class="t">And is it me or does that definition not automatically foreshadow economic strife?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=290" target="_blank">00:04:50.020</a></span> | <span class="t">In other words, definitionally, AGI won't have arrived until it can do the work of at least half of all humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=296" target="_blank">00:04:56.460</a></span> | <span class="t">Now, every word matters when we're defining something as consequential as AGI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=301" target="_blank">00:05:01.220</a></span> | <span class="t">And Google DeepMind, led by Demis Hassabis, moderated OpenAI's definition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=305" target="_blank">00:05:05.500</a></span> | <span class="t">They said we'll count it as having achieved AGI if we have systems that are technically capable of performing economically important tasks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=312" target="_blank">00:05:12.900</a></span> | <span class="t">but don't necessarily realize that economic value, as in they might not actually be deployed in the workforce for legal, ethical or social reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=320" target="_blank">00:05:20.940</a></span> | <span class="t">But imagine the economic incentives in that scenario.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=324" target="_blank">00:05:24.420</a></span> | <span class="t">AGI would be here and be capable of realizing trillions of dollars of economic value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=330" target="_blank">00:05:30.020</a></span> | <span class="t">And these companies are supposed to hold back from deploying it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=333" target="_blank">00:05:33.580</a></span> | <span class="t">Would Google allow that? Would Microsoft or would the definition change conveniently?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=338" target="_blank">00:05:38.820</a></span> | <span class="t">But even under that wider definition, when does Demis Hassabis think that AGI will arrive?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=344" target="_blank">00:05:44.460</a></span> | <span class="t">I will say that when we started DeepMind back in 2010, you know, we thought of it as a 20 year project.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=349" target="_blank">00:05:49.660</a></span> | <span class="t">And actually, I think we're on track, which is kind of amazing for 20 year projects, because usually they're always 20 years away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=355" target="_blank">00:05:55.940</a></span> | <span class="t">So that's the joke about, you know, whatever it is, quantum, AI, you know, take your pick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=360" target="_blank">00:06:00.660</a></span> | <span class="t">And but I think we, you know, I think we're on track.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=363" target="_blank">00:06:03.100</a></span> | <span class="t">So I wouldn't be surprised if we had AGI like systems within the next decade.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=367" target="_blank">00:06:07.820</a></span> | <span class="t">Others think that that moment, which again would have colossal economic ramifications, will come before 2030.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=374" target="_blank">00:06:14.100</a></span> | <span class="t">Here's one alignment researcher at OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=377" target="_blank">00:06:17.020</a></span> | <span class="t">He thinks that there's around a two third chance of AGI before 2028.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=382" target="_blank">00:06:22.380</a></span> | <span class="t">And he goes on that he can't talk about all the reasons why he has this timeline,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=386" target="_blank">00:06:26.620</a></span> | <span class="t">but mostly it should be figureoutable from publicly available information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=390" target="_blank">00:06:30.820</a></span> | <span class="t">I'm guessing that's an oblique reference to Q* or Let's Verify.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=394" target="_blank">00:06:34.620</a></span> | <span class="t">He also returns to the economic definition of AGI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=398" target="_blank">00:06:38.220</a></span> | <span class="t">When I say AGI, I mean something which is basically a drop in substitute for a human remote worker circa 2023.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=405" target="_blank">00:06:45.780</a></span> | <span class="t">And not just a mediocre one, a good one, e.g. an OpenAI research engineer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=410" target="_blank">00:06:50.700</a></span> | <span class="t">Notice, though, he's focusing on remote work and even Karpathy limits his comments to digital work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=416" target="_blank">00:06:56.180</a></span> | <span class="t">But as we'll see at the end of this video, even physical tasks might be automated sooner than you think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=421" target="_blank">00:07:01.860</a></span> | <span class="t">Before we leave Daniel Cocotagelo, though, there's one more quote I want to show you of his.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=426" target="_blank">00:07:06.420</a></span> | <span class="t">I think in this one, he's feeling somewhat panicked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=429" target="_blank">00:07:09.060</a></span> | <span class="t">Probably there will be AGI soon, literally any year now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=432" target="_blank">00:07:12.340</a></span> | <span class="t">And probably whoever controls AGI will also be able to use it to get to artificial super intelligence shortly thereafter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=439" target="_blank">00:07:19.860</a></span> | <span class="t">He says maybe in another year, give or take a year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=442" target="_blank">00:07:22.780</a></span> | <span class="t">Now, if you do the maths of that comment, give or take a year means that it could be instantaneous or it could take two years from AGI, according to him.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=451" target="_blank">00:07:31.700</a></span> | <span class="t">At least according to Google DeepMind, an artificial super intelligence would involve outperforming 100% of humans,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=458" target="_blank">00:07:38.500</a></span> | <span class="t">just like in their respective domains, AlphaZero and Stockfish already do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=462" target="_blank">00:07:42.860</a></span> | <span class="t">And in the light of these shortening timelines, some AI researchers are already adapting their behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=468" target="_blank">00:07:48.620</a></span> | <span class="t">One lead researcher at OpenAI said this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=471" target="_blank">00:07:51.180</a></span> | <span class="t">The closer we get to the singularity, that's the moment when progress is so fast humans can't even keep up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=476" target="_blank">00:07:56.140</a></span> | <span class="t">The lower, he said, my risk tolerance gets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=478" target="_blank">00:07:58.540</a></span> | <span class="t">I'd already ruled out skydiving and paragliding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=481" target="_blank">00:08:01.380</a></span> | <span class="t">Last year, I started wearing a helmet consistently while cycling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=485" target="_blank">00:08:05.100</a></span> | <span class="t">And he ended, I think this year might be the year I give up skiing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=488" target="_blank">00:08:08.660</a></span> | <span class="t">In other words, if you think AGI, ASI and the singularity are going to happen in the 2020s, it will be kind of a pity to die before that date, probably.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=497" target="_blank">00:08:17.860</a></span> | <span class="t">But at this point in the video, and I promise you I will get to the GTC straight after this, things are getting kind of heavy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=503" target="_blank">00:08:23.860</a></span> | <span class="t">So I want to bring in a paper I read that's on a lighter note.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=507" target="_blank">00:08:27.860</a></span> | <span class="t">What the paper says, essentially, is that peer reviewers are now starting to use ChatGPT wholesale to do peer review.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=514" target="_blank">00:08:34.940</a></span> | <span class="t">How did they discover this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=516" target="_blank">00:08:36.060</a></span> | <span class="t">Well, mentions of the word commendable, innovative, meticulous, intricate, notable and versatile.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=522" target="_blank">00:08:42.060</a></span> | <span class="t">Now, I think those are words that I use all the time, but maybe not everyone does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=525" target="_blank">00:08:45.540</a></span> | <span class="t">Previously, they were incredibly rare in peer reviews, but they became somewhat common.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=531" target="_blank">00:08:51.180</a></span> | <span class="t">Hmm. Makes you wonder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=532" target="_blank">00:08:52.660</a></span> | <span class="t">They go on that the estimated fraction of large language model generated text is higher in reviews which report lower confidence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=540" target="_blank">00:09:00.100</a></span> | <span class="t">That kind of makes sense, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=541" target="_blank">00:09:01.140</a></span> | <span class="t">If you're not confident, you're going to use an LLM to help you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=543" target="_blank">00:09:03.940</a></span> | <span class="t">But the next bit is funny.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=544" target="_blank">00:09:04.980</a></span> | <span class="t">They were submitted close to the deadline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=547" target="_blank">00:09:07.140</a></span> | <span class="t">So you have these panicked peer reviewers who are like, oh, no, the deadline's coming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=551" target="_blank">00:09:11.020</a></span> | <span class="t">Let's use ChatGPT to do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=552" target="_blank">00:09:12.580</a></span> | <span class="t">And the other correlation was it was more common from reviewers who are less likely to respond to author rebuttals.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=558" target="_blank">00:09:18.900</a></span> | <span class="t">Now, that seems somewhat unfair to me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=561" target="_blank">00:09:21.020</a></span> | <span class="t">You don't even bother to write the peer review yourself and you don't even reply when the author replies to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=566" target="_blank">00:09:26.900</a></span> | <span class="t">These were peer reviews of prominent deep learning conferences, and the rates were 10 and almost 17 percent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=574" target="_blank">00:09:34.340</a></span> | <span class="t">And we're not talking about spell checks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=575" target="_blank">00:09:35.820</a></span> | <span class="t">We're talking about being substantially modified by ChatGPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=579" target="_blank">00:09:39.260</a></span> | <span class="t">Obviously, now is not the time to go through this paper, but I thought it's worth showing you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=582" target="_blank">00:09:42.620</a></span> | <span class="t">I mean, it's one more effect of AGI, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=584" target="_blank">00:09:44.540</a></span> | <span class="t">The whole peer review system might become the AGI review system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=588" target="_blank">00:09:48.900</a></span> | <span class="t">So the conference from around 24 hours ago, obviously way too much to get to in this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=594" target="_blank">00:09:54.140</a></span> | <span class="t">But I'm going to give you the five moments that stood out for me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=596" target="_blank">00:09:56.860</a></span> | <span class="t">First, the obvious one, the announcement of the Blackwell GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=601" target="_blank">00:10:01.100</a></span> | <span class="t">Over the course of the last eight years, we've increased computation by 1000 times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=606" target="_blank">00:10:06.940</a></span> | <span class="t">Eight years, 1000 times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=608" target="_blank">00:10:08.500</a></span> | <span class="t">Remember back in the good old days of Moore's law, 10x every five years, 100 times every 10 years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=614" target="_blank">00:10:14.940</a></span> | <span class="t">100 times every 10 years in the middle of the heydays of the PC revolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=622" target="_blank">00:10:22.860</a></span> | <span class="t">Now, this graph does involve some hype because it's not comparing the same level of precision, FP16 to FP4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=629" target="_blank">00:10:29.260</a></span> | <span class="t">But the point still stands that we are exceeding Moore's law.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=632" target="_blank">00:10:32.780</a></span> | <span class="t">Here's another example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=633" target="_blank">00:10:33.820</a></span> | <span class="t">The Blackwell Superchip system isn't just two times better inference or actually generating tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=639" target="_blank">00:10:39.660</a></span> | <span class="t">It's 30 times more performant than the H100 series.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=644" target="_blank">00:10:44.020</a></span> | <span class="t">In short, there's going to be a lot more generations from generative AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=647" target="_blank">00:10:47.660</a></span> | <span class="t">The cost and energy consumption also drops by a major factor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=651" target="_blank">00:10:51.540</a></span> | <span class="t">And of course, almost every CEO in the world that you can think of lined up to praise and get in the queue for these Blackwell Superchips.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=659" target="_blank">00:10:59.580</a></span> | <span class="t">Next, of course, the model sizes that these systems can serve just keeps getting bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=664" target="_blank">00:11:04.660</a></span> | <span class="t">Remember, GPT-3 was trained at 175 billion parameters, then GPT-4 at around 1.8 trillion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=671" target="_blank">00:11:11.700</a></span> | <span class="t">That's 10 times bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=672" target="_blank">00:11:12.940</a></span> | <span class="t">Well, notice how as we proceed, we're not doubling or 3Xing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=676" target="_blank">00:11:16.860</a></span> | <span class="t">We're talking about another tenfold increase.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=679" target="_blank">00:11:19.420</a></span> | <span class="t">NVIDIA said that their server clusters could deploy a 27 trillion parameter model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=684" target="_blank">00:11:24.260</a></span> | <span class="t">Now, of course, just because NVIDIA can deploy that size of model doesn't mean that the AGI labs will create one that big.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=690" target="_blank">00:11:30.140</a></span> | <span class="t">I think a more reasonable estimate for the next generation of models would be around 10 trillion parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=695" target="_blank">00:11:35.700</a></span> | <span class="t">But the point still stands, we're not doubling each time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=697" target="_blank">00:11:37.860</a></span> | <span class="t">In case you're not familiar, by the way, the number of parameters is like the number of dials in a model that you can tune to better match deep, intricate patterns and patterns within patterns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=707" target="_blank">00:11:47.260</a></span> | <span class="t">Of course, those patterns have to be found within the data that you give it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=710" target="_blank">00:11:50.380</a></span> | <span class="t">So garbage in, garbage out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=711" target="_blank">00:11:51.980</a></span> | <span class="t">But of course, everyone's working on getting higher quality data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=715" target="_blank">00:11:55.260</a></span> | <span class="t">The next interesting moment I think many people might have slept on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=718" target="_blank">00:11:58.420</a></span> | <span class="t">NVIDIA have built a platform that accelerates the compute intensive part of lithography.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=724" target="_blank">00:12:04.260</a></span> | <span class="t">That's the key process in making new and more advanced chips.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=728" target="_blank">00:12:08.580</a></span> | <span class="t">And in this announcement, NVIDIA say that TSMC are already going into production with this platform.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=734" target="_blank">00:12:14.820</a></span> | <span class="t">They're going to be accelerating manufacturing and pushing the limits of physics for the next generation of advanced semiconductor chips.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=741" target="_blank">00:12:21.820</a></span> | <span class="t">Not only that, but these 40 or 60 X improvements also utilize Gen AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=747" target="_blank">00:12:27.100</a></span> | <span class="t">As best I can tell, they're using generative AI to create a mask, which is key in lithography.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=753" target="_blank">00:12:33.180</a></span> | <span class="t">Think of that mask as a template that transfers a pattern onto the chip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=757" target="_blank">00:12:37.700</a></span> | <span class="t">I'm reading the book Chip Wars at the moment, and lithography is absolutely key to the latest chips.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=763" target="_blank">00:12:43.180</a></span> | <span class="t">But the bigger point is this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=764" target="_blank">00:12:44.300</a></span> | <span class="t">They're using Gen AI for ideation suggestions, but then the actual mask is derived by traditional physically rigorous methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=771" target="_blank">00:12:51.700</a></span> | <span class="t">It's that marrying of Gen AI to suggest and traditional systems to check that we'll see again in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=777" target="_blank">00:12:57.580</a></span> | <span class="t">But there is another obvious point here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=779" target="_blank">00:12:59.260</a></span> | <span class="t">This is somewhat recursive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=780" target="_blank">00:13:00.860</a></span> | <span class="t">We have better chips creating better, cheaper, faster generative AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=785" target="_blank">00:13:05.100</a></span> | <span class="t">And now more and more, we're getting generative AI helping in the creation of new and better chips.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=790" target="_blank">00:13:10.820</a></span> | <span class="t">And of course, those new chips might be with us sooner.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=793" target="_blank">00:13:13.740</a></span> | <span class="t">Photo masks that took two weeks can now be processed overnight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=796" target="_blank">00:13:16.980</a></span> | <span class="t">Here's what the CEO of ASML said, which, of course, is the company that's integral to the creation of semiconductors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=803" target="_blank">00:13:23.460</a></span> | <span class="t">This collaboration will bring tremendous benefit to computational lithography and therefore to semiconductor scaling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=810" target="_blank">00:13:30.460</a></span> | <span class="t">If you thought things were already progressing fast, it'll get even faster for the rest of this decade.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=815" target="_blank">00:13:35.940</a></span> | <span class="t">One quick point to make here is that we're actually still lagging the front edge of what's computable by about two years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=822" target="_blank">00:13:42.420</a></span> | <span class="t">Most people, if they're not still using the original chat GPT, are using GPT-4, which finished training two years ago, or Gemini 1 Ultra.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=830" target="_blank">00:13:50.740</a></span> | <span class="t">But I spotted recently from Asabis that Gemini 1 Ultra actually used just the same compute as was rumored for GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=838" target="_blank">00:13:58.420</a></span> | <span class="t">That's 2022 compute levels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=840" target="_blank">00:14:00.860</a></span> | <span class="t">Actually, Gemini 1 used roughly the same amount of compute, maybe slightly more than what was rumored for GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=846" target="_blank">00:14:06.060</a></span> | <span class="t">I don't know exactly what was used, so I think it was in the same ballpark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=849" target="_blank">00:14:09.820</a></span> | <span class="t">In other words, the public hasn't begun to grasp what even 2023 levels of compute could do for training a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=857" target="_blank">00:14:17.780</a></span> | <span class="t">But there was, of course, one more announcement that I simply cannot ignore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=861" target="_blank">00:14:21.700</a></span> | <span class="t">Project Groot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=864" target="_blank">00:14:24.020</a></span> | <span class="t">This is NVIDIA Project Groot, a general purpose foundation model for humanoid robot learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=876" target="_blank">00:14:36.900</a></span> | <span class="t">The Groot model takes multimodal instructions and past interactions as input and produces the next action for the robot to execute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=887" target="_blank">00:14:47.100</a></span> | <span class="t">We developed Isaac Lab, a robot learning application to train Groot on Omniverse Isaac Sim.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=893" target="_blank">00:14:53.420</a></span> | <span class="t">We can train Groot in physically based simulation and transfer zero shot to the real world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=900" target="_blank">00:15:00.980</a></span> | <span class="t">The Groot model will enable a robot to learn from a handful of human demonstrations so it can help with everyday tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=910" target="_blank">00:15:10.660</a></span> | <span class="t">And emulate human movement just by observing us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=915" target="_blank">00:15:15.940</a></span> | <span class="t">This is made possible with NVIDIA's technologies that can understand humans from videos, train models and simulation and ultimately deploy them directly to physical robots.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=926" target="_blank">00:15:26.260</a></span> | <span class="t">As Jensen Huang said, humanoid robots will at first just watch us and learn from imitation data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=931" target="_blank">00:15:31.620</a></span> | <span class="t">But embodied learning does have one advantage over large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=935" target="_blank">00:15:35.300</a></span> | <span class="t">They can use reinforcement learning in simulation, try tasks in simulation, see how they work out and then perform in the real world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=942" target="_blank">00:15:42.900</a></span> | <span class="t">I actually discussed this with two leading figures at NVIDIA, four AI insiders on Patreon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=948" target="_blank">00:15:48.340</a></span> | <span class="t">But let me leave you with this thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=950" target="_blank">00:15:50.020</a></span> | <span class="t">If you think these robot imitations look kind of cute and rubbish at the moment, think about GPT-2 or maybe the first system of BARD that you interacted with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=958" target="_blank">00:15:58.980</a></span> | <span class="t">And now think of GPT-4 or CLAWD-3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=962" target="_blank">00:16:02.340</a></span> | <span class="t">In those cases, they were learning to imitate human text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=965" target="_blank">00:16:05.660</a></span> | <span class="t">In this case, it will be human actions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=967" target="_blank">00:16:07.780</a></span> | <span class="t">But the lesson is the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=968" target="_blank">00:16:08.900</a></span> | <span class="t">These models can improve much faster than you might think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=971" target="_blank">00:16:11.980</a></span> | <span class="t">And don't forget with all of this, as yet another OpenAI employee put it, hope you enjoyed some time to relax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=978" target="_blank">00:16:18.340</a></span> | <span class="t">It'll have been the slowest 12 months of AI progress for quite some time to come.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=983" target="_blank">00:16:23.460</a></span> | <span class="t">Hopefully you'll join me as I cover that progress in the coming months.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=fPzp_sdCf2Y&t=987" target="_blank">00:16:27.140</a></span> | <span class="t">Thank you as always for watching to the end and have a wonderful day.</span></div></div></body></html>