<html><head><title>Judea Pearl: Human-Level AI and the Test of Free Will | AI Podcast Clips</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>Judea Pearl: Human-Level AI and the Test of Free Will | AI Podcast Clips</h2><a href="https://www.youtube.com/watch?v=0rd3TB_dIQo" target="_blank"><img src="https://i.ytimg.com/vi_webp/0rd3TB_dIQo/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Transcript</h3><div class='max-width'><p>I know you're not a futurist, but are you excited? Have you, when you look back at your life, long for the idea of creating a human level intelligence system? - Yeah, I'm driven by that. All my life I'm driven just by one thing. (laughs) But I go slowly, I go from what I know to the next step incrementally. - So without imagining what the end goal looks like, do you imagine what-- - The end goal is gonna be a machine that can answer sophisticated questions, counterfactuals of regret, compassion, responsibility, and free will. - So what is a good test? Is a Turing test a reasonable test? - A test of free will doesn't exist yet. - How would you test free will? - So far we know only one thing. If robots can communicate with reward and punishment among themselves, hitting each other on the wrist and say you shouldn't have done that, playing better soccer because they can do that. - What do you mean because they can do that? - Because they can communicate among themselves. - Because of the communication they can do this? - Because they communicate like us. Reward and punishment, yes, you didn't pass the ball the right time and so forth, therefore you're gonna sit on the bench for the next two. If they start communicating like that, the question is will they play better soccer? As opposed to what? As opposed to what they do now. Without this ability to reason about reward and punishment, responsibility. - And counterfactuals. - So far I can only think about communication. - Communication is not necessarily natural language but just communication. - No, just communication. And that's important to have a quick and effective means of communicating knowledge. If the coach tells you you should have passed the ball, ping, he conveys so much knowledge to you as opposed to what? Go down and change your software. That's the alternative. But the coach doesn't know your software. So how can a coach tell you you should have passed the ball? But our language is very effective. You should have passed the ball. You know your software, you tweak the right module, and next time you don't do it. - Now that's for playing soccer where the rules are well defined. - No, no, no, no, the rules are not well defined. When you should pass the ball-- - It's not well defined. - No, it's very soft, very noisy. - Yeah, the mystery. - You have to do it under pressure. - It's art. But in terms of aligning values between computers and humans, do you think this cause and effect type of thinking is important to align the values? Values, morals, ethics under which the machines make decisions, is the cause effect where the two can come together? - Cause effect is necessary component to build an ethical machine. Cause the machine has to empathize, to understand what's good for you, to build a model of you as a recipient, which should be very much, what is compassion? They imagine that you suffer pain as much as me. - As much as me. - I do have already a model of myself, right? So it's very easy for me to map you to mine. I don't have to rebuild the model. It's much easier to say, oh, you're like me. Okay, therefore I will not hate you. - And the machine has to imagine, it has to try to fake to be human, essentially so you can imagine that you're like me. - And moreover, who is me? That's the first, that's consciousness. They have a model of yourself. Where do you get this model? You look at yourself as if you are a part of the environment. If you build a model of yourself versus the environment, then you can say, I need to have a model of myself. I have abilities, I have desires and so forth. I have a blueprint of myself, though. Not a full detail because I cannot get the whole thing problem, but I have a blueprint. So on that level of a blueprint, I can modify things. I can look at myself in the mirror and say, hmm, if I change this, tweak this model, I'm going to perform differently. That is what we mean by free will. - And consciousness. - And consciousness. (upbeat music) (upbeat music) (upbeat music) (upbeat music) (upbeat music) (upbeat music)</p></div></div></body></html>