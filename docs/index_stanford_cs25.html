<html><head><title>Stanford Cs25 Transcripts</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><h1>Stanford Cs25 Transcripts</h1><table style="width:100%; border-collapse: collapse;"><a href="index.html">back to index</a><tr><th>Date</th><th>Title</th><th>Duration</th><th>Whisper Transcript</th><th>Transcript Only</th></tr><tr style="background-color: #f2f2f2;"><td>2025-05-21</td><td>Stanford CS25: V5 I Large Language Model Reasoning, Denny Zhou of Google Deepmind</td><td>66 min</td><td><a href="./ebnX5Ur1hBk.html">Whisper Transcript</a></td><td><a href="./transcript_ebnX5Ur1hBk.html">Transcript Only</a></td></tr><tr style=""><td>2025-05-13</td><td>Stanford CS25: V5 I The Advent of AGI, Div Garg</td><td>61 min</td><td><a href="./nEHNwdrbfGA.html">Whisper Transcript</a></td><td><a href="./transcript_nEHNwdrbfGA.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2025-04-29</td><td>Stanford CS25: V5 I RL as a Co-Design of Product and Research, Karina Nguyen</td><td>72 min</td><td><a href="./gLwiPrwUDJ8.html">Whisper Transcript</a></td><td><a href="./transcript_gLwiPrwUDJ8.html">Transcript Only</a></td></tr><tr style=""><td>2025-04-18</td><td>Stanford CS25: V5 I Overview of Transformers</td><td>61 min</td><td><a href="./JKbtWimlzAE.html">Whisper Transcript</a></td><td><a href="./transcript_JKbtWimlzAE.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2024-05-23</td><td>Stanford CS25: V4 I Transformers that Transform Well Enough to Support Near-Shallow Architectures</td><td>79 min</td><td><a href="./zL9B3eXq0gY.html">Whisper Transcript</a></td><td><a href="./transcript_zL9B3eXq0gY.html">Transcript Only</a></td></tr><tr style=""><td>2024-06-11</td><td>Stanford CS25: V4 I Hyung Won Chung of OpenAI</td><td>36 min</td><td><a href="./orDKvo8h71o.html">Whisper Transcript</a></td><td><a href="./transcript_orDKvo8h71o.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2024-06-07</td><td>Stanford CS25: V4 I Behind the Scenes of LLM Pre-training: StarCoder Use Case</td><td>61 min</td><td><a href="./jm2hyJLFfN8.html">Whisper Transcript</a></td><td><a href="./transcript_jm2hyJLFfN8.html">Transcript Only</a></td></tr><tr style=""><td>2024-05-30</td><td>Stanford CS25: V4 I From Large Language Models to Large Multimodal Models</td><td>80 min</td><td><a href="./cYfKQ6YG9Qo.html">Whisper Transcript</a></td><td><a href="./transcript_cYfKQ6YG9Qo.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2024-05-10</td><td>Stanford CS25: V4 I Aligning Open Language Models</td><td>76 min</td><td><a href="./AdLgPmcrXwQ.html">Whisper Transcript</a></td><td><a href="./transcript_AdLgPmcrXwQ.html">Transcript Only</a></td></tr><tr style=""><td>2024-05-06</td><td>Stanford CS25: V4 I Jason Wei & Hyung Won Chung of OpenAI</td><td>77 min</td><td><a href="./3gb-ZkVRemQ.html">Whisper Transcript</a></td><td><a href="./transcript_3gb-ZkVRemQ.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2024-04-23</td><td>Stanford CS25: V4 I Overview of Transformers</td><td>77 min</td><td><a href="./fKMB5UlVY1E.html">Whisper Transcript</a></td><td><a href="./transcript_fKMB5UlVY1E.html">Transcript Only</a></td></tr><tr style=""><td>2024-01-25</td><td>Stanford CS25: V3 I Retrieval Augmented Language Models</td><td>79 min</td><td><a href="./mE7IDf2SmJg.html">Whisper Transcript</a></td><td><a href="./transcript_mE7IDf2SmJg.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2023-12-15</td><td>Stanford CS25: V3 I Beyond LLMs: Agents, Emergent Abilities, Intermediate-Guided Reasoning, BabyLM</td><td>60 min</td><td><a href="./ylEk1TE1uBo.html">Whisper Transcript</a></td><td><a href="./transcript_ylEk1TE1uBo.html">Transcript Only</a></td></tr><tr style=""><td>2023-12-15</td><td>Stanford CS25: V3 I No Language Left Behind: Scaling Human-Centered Machine Translation</td><td>52 min</td><td><a href="./ckNMsUuLryM.html">Whisper Transcript</a></td><td><a href="./transcript_ckNMsUuLryM.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2023-12-14</td><td>Stanford CS25: V3 I Recipe for Training Helpful Chatbots</td><td>68 min</td><td><a href="./mcep6W8oB1I.html">Whisper Transcript</a></td><td><a href="./transcript_mcep6W8oB1I.html">Transcript Only</a></td></tr><tr style=""><td>2024-01-17</td><td>Stanford CS25: V3 I How I Learned to Stop Worrying and Love the Transformer</td><td>80 min</td><td><a href="./1GbDTTK3aR4.html">Whisper Transcript</a></td><td><a href="./transcript_1GbDTTK3aR4.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2023-12-09</td><td>Stanford CS25: V3 I Generalist Agents in Open-Ended Worlds</td><td>47 min</td><td><a href="./wwQ1LQA3RCU.html">Whisper Transcript</a></td><td><a href="./transcript_wwQ1LQA3RCU.html">Transcript Only</a></td></tr><tr style=""><td>2023-12-08</td><td>Stanford CS25: V3 I Low-level Embodied Intelligence w/ Foundation Models</td><td>78 min</td><td><a href="./fz8wf9hN20c.html">Whisper Transcript</a></td><td><a href="./transcript_fz8wf9hN20c.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2023-09-01</td><td>Stanford CS25: V2 I Neuroscience-Inspired Artificial Intelligence</td><td>82 min</td><td><a href="./L4DC7e6g2iI.html">Whisper Transcript</a></td><td><a href="./transcript_L4DC7e6g2iI.html">Transcript Only</a></td></tr><tr style=""><td>2023-05-25</td><td>Stanford CS25: V2 I Biomedical Transformers</td><td>68 min</td><td><a href="./nz7_wg5iOlA.html">Whisper Transcript</a></td><td><a href="./transcript_nz7_wg5iOlA.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2023-05-24</td><td>Stanford CS25: V2 I Common Sense Reasoning</td><td>75 min</td><td><a href="./sTQaJyrI-zg.html">Whisper Transcript</a></td><td><a href="./transcript_sTQaJyrI-zg.html">Transcript Only</a></td></tr><tr style=""><td>2023-05-23</td><td>Stanford CS25: V2 I Robotics and Imitation Learning</td><td>76 min</td><td><a href="./ct4tdyyNDY4.html">Whisper Transcript</a></td><td><a href="./transcript_ct4tdyyNDY4.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2023-05-22</td><td>Stanford CS25: V2 I Strategic Games</td><td>53 min</td><td><a href="./phWxl0nkgKk.html">Whisper Transcript</a></td><td><a href="./transcript_phWxl0nkgKk.html">Transcript Only</a></td></tr><tr style=""><td>2023-05-21</td><td>Stanford CS25: V2 I Emergent Abilities and Scaling in LLMs</td><td>67 min</td><td><a href="./tVtOevLrt5U.html">Whisper Transcript</a></td><td><a href="./transcript_tVtOevLrt5U.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2023-05-20</td><td>Stanford CS25: V2 I Language and Human Alignment</td><td>66 min</td><td><a href="./DJ1Yy6Aquug.html">Whisper Transcript</a></td><td><a href="./transcript_DJ1Yy6Aquug.html">Transcript Only</a></td></tr><tr style=""><td>2023-05-19</td><td>Stanford CS25: V2 I Introduction to Transformers w/ Andrej Karpathy</td><td>71 min</td><td><a href="./XfpMkf4rD6E.html">Whisper Transcript</a></td><td><a href="./transcript_XfpMkf4rD6E.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2022-08-11</td><td>Stanford CS25: V2 I Represent part-whole hierarchies in a neural network, Geoff Hinton</td><td>52 min</td><td><a href="./CYaju6aCMoQ.html">Whisper Transcript</a></td><td><a href="./transcript_CYaju6aCMoQ.html">Transcript Only</a></td></tr><tr style=""><td>2022-07-18</td><td>Stanford CS25: V1 I Audio Research: Transformers for Applications in Audio, Speech, Music</td><td>48 min</td><td><a href="./wvE2n8u3drA.html">Whisper Transcript</a></td><td><a href="./transcript_wvE2n8u3drA.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2022-07-17</td><td>Stanford CS25: V1 I Transformer Circuits, Induction Heads, In-Context Learning</td><td>59 min</td><td><a href="./pC4zRb_5noQ.html">Whisper Transcript</a></td><td><a href="./transcript_pC4zRb_5noQ.html">Transcript Only</a></td></tr><tr style=""><td>2022-07-16</td><td>Stanford CS25: V1 I Self Attention and Non-parametric transformers (NPTs)</td><td>65 min</td><td><a href="./zejXBg-2Vpk.html">Whisper Transcript</a></td><td><a href="./transcript_zejXBg-2Vpk.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2022-07-15</td><td>Stanford CS25: V1 I DeepMind's Perceiver and Perceiver IO: new data family architecture</td><td>58 min</td><td><a href="./wTZ3o36lXoQ.html">Whisper Transcript</a></td><td><a href="./transcript_wTZ3o36lXoQ.html">Transcript Only</a></td></tr><tr style=""><td>2022-07-14</td><td>Stanford CS25: V1 I Mixture of Experts (MoE) paradigm and the Switch Transformer</td><td>65 min</td><td><a href="./U8J32Z3qV8s.html">Whisper Transcript</a></td><td><a href="./transcript_U8J32Z3qV8s.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2022-07-13</td><td>Stanford CS25: V1 I Decision Transformer: Reinforcement Learning via Sequence Modeling</td><td>80 min</td><td><a href="./w4Bw8WYL8Ps.html">Whisper Transcript</a></td><td><a href="./transcript_w4Bw8WYL8Ps.html">Transcript Only</a></td></tr><tr style=""><td>2022-07-12</td><td>Stanford CS25: V1 I Transformers in Vision: Tackling problems in Computer Vision</td><td>68 min</td><td><a href="./BP5CM0YxbP8.html">Whisper Transcript</a></td><td><a href="./transcript_BP5CM0YxbP8.html">Transcript Only</a></td></tr><tr style="background-color: #f2f2f2;"><td>2022-07-11</td><td>Stanford CS25: V1 I Transformers in Language: The development of GPT Models, GPT3</td><td>48 min</td><td><a href="./qGkzHFllWDY.html">Whisper Transcript</a></td><td><a href="./transcript_qGkzHFllWDY.html">Transcript Only</a></td></tr><tr style=""><td>2022-07-08</td><td>Stanford CS25: V1 I Transformers United: DL Models that have revolutionized NLP, CV, RL</td><td>22 min</td><td><a href="./P127jhj-8-Y.html">Whisper Transcript</a></td><td><a href="./transcript_P127jhj-8-Y.html">Transcript Only</a></td></tr></table></body></html>