<html><head><title>GPT-5 has Arrived</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>GPT-5 has Arrived</h2><a href="https://www.youtube.com/watch?v=WLdBimUS1IE"><img src="https://i.ytimg.com/vi/WLdBimUS1IE/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./WLdBimUS1IE.html">Whisper Transcript</a> | <a href="./transcript_WLdBimUS1IE.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Well, GPT-5 is here and it's in the free tier. I've tested it a bunch, read the system card in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=7" target="_blank">00:00:07.460</a></span> | <span class="t">full and even sat through that full live stream. Wow. But actually, I think it's pretty huge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=13" target="_blank">00:00:13.540</a></span> | <span class="t">that free users of ChatGPT will get access to GPT-5. In other words, approaching a billion people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=21" target="_blank">00:00:21.340</a></span> | <span class="t">will experience a significantly more intelligent AI model, at least before they hit the limits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=27" target="_blank">00:00:27.660</a></span> | <span class="t">But if you watched the live stream and demo, you may have been underwhelmed. And I don't just mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=33" target="_blank">00:00:33.600</a></span> | <span class="t">the mathematically impossible bar graphs. And there were multiple of those. There were even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=39" target="_blank">00:00:39.500</a></span> | <span class="t">hallucinations in the segment describing how the model hallucinates less. For sure, it would be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=45" target="_blank">00:00:45.500</a></span> | <span class="t">easy to make a video just taking the mic of those mistakes. But the thing is, GPT-5 is actually a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=52" target="_blank">00:00:52.380</a></span> | <span class="t">pretty great model. So here are my first impressions. First, my own logic benchmark,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=57" target="_blank">00:00:57.600</a></span> | <span class="t">or some people call it a trick question benchmark. I can confirm that GPT-5 indeed does crush the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=66" target="_blank">00:01:06.060</a></span> | <span class="t">public questions of SimpleBench. Whoever this was that came out with this viral thread of it getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=72" target="_blank">00:01:12.680</a></span> | <span class="t">nine out of 10 on those public 10 questions from SimpleBench wasn't lying technically. In some of my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=79" target="_blank">00:01:19.600</a></span> | <span class="t">early testing, it got questions right that no other model had gotten right. When I saw this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=85" target="_blank">00:01:25.860</a></span> | <span class="t">I was like, man, I'm gonna have to bring out V2 really early. Everyone's gonna get super hyped.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=90" target="_blank">00:01:30.480</a></span> | <span class="t">This is crazy. However, if you are newer to AI, you might not know that the performance of language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=96" target="_blank">00:01:36.580</a></span> | <span class="t">models is heavily dependent on the training data they're fed. And I suspect some of these 10 public</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=103" target="_blank">00:01:43.640</a></span> | <span class="t">questions have made it into the training data, at least indirectly, not deliberately, I think. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=109" target="_blank">00:01:49.400</a></span> | <span class="t">given that the models are trained on things like Reddit and other forums, it's definitely not impossible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=115" target="_blank">00:01:55.080</a></span> | <span class="t">Given how long I normally take to update the leaderboard, you guys might be quite shocked to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=120" target="_blank">00:02:00.440</a></span> | <span class="t">hear that we're doing the runs tonight. And so far, it's not setting a new record. That surprised even me,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=127" target="_blank">00:02:07.740</a></span> | <span class="t">actually. I was expecting, honestly, 70%. I'll be honest with you guys. So far, in the three runs we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=134" target="_blank">00:02:14.960</a></span> | <span class="t">done, it's getting around 57-58%. So at this point, we can be clear, it's not a new paradigm of AI. And if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=144" target="_blank">00:02:24.280</a></span> | <span class="t">you didn't believe models were AGI now, this model won't convince you that we have AGI. But in fairness</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=150" target="_blank">00:02:30.600</a></span> | <span class="t">to OpenAI, just a couple of hours ago, Sam Altman tweeted that they could release much, much smarter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=156" target="_blank">00:02:36.500</a></span> | <span class="t">models. But the main thing they were pushing for was real-world utility, which I'm going to come to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=161" target="_blank">00:02:41.260</a></span> | <span class="t">and mass accessibility and affordability. Well, they have delivered on that. When it comes to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=166" target="_blank">00:02:46.580</a></span> | <span class="t">affordability, in the API, the prices are incredible. Below clawed force on it. For those who care about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=172" target="_blank">00:02:52.440</a></span> | <span class="t">API, I've got some coding data coming up. But first, hallucinations. The team made a big play about how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=178" target="_blank">00:02:58.680</a></span> | <span class="t">GPT-5 would hallucinate less than previous models. Quite early on in the system card, which is as good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=185" target="_blank">00:03:05.240</a></span> | <span class="t">a research paper as we're going to get, it seems, they say that we find that GPT-5 main has 44% fewer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=193" target="_blank">00:03:13.380</a></span> | <span class="t">responses with at least one major factual error. However, I got suspicious immediately when, on the live</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=200" target="_blank">00:03:20.360</a></span> | <span class="t">stream, I saw a bunch of new benchmarks rather than the ones we already know. I don't blame anyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=206" target="_blank">00:03:26.080</a></span> | <span class="t">watching for not knowing this, but one of the most quoted benchmarks on hallucinations is simple QA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=211" target="_blank">00:03:31.800</a></span> | <span class="t">These are short, factual questions that can be prone to hallucinations. And on that front,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=218" target="_blank">00:03:38.280</a></span> | <span class="t">GPT-5 thinking is just about better than O3, maybe if you squint. Obviously, it makes it hard to compare</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=225" target="_blank">00:03:45.980</a></span> | <span class="t">if we invent a new benchmark for every single model release, but it's probably fair to say it does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=230" target="_blank">00:03:50.860</a></span> | <span class="t">hallucinate a bit less. Again, though, if you don't follow AI too closely, this model, just as all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=236" target="_blank">00:03:56.700</a></span> | <span class="t">others, will still hallucinate with a major incorrect claim around 5% of the time. These are on the questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=243" target="_blank">00:04:03.580</a></span> | <span class="t">by the way, that users are actually using chat GPT for. Okay, now for one domain that OpenAI really did want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=250" target="_blank">00:04:10.700</a></span> | <span class="t">to highlight, which is software engineering and one benchmark in particular, Sweebench Verified. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=256" target="_blank">00:04:16.300</a></span> | <span class="t">time, by the way, you will notice that the graph doesn't have 52% as being higher than 69%. This,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=262" target="_blank">00:04:22.540</a></span> | <span class="t">for me, then, is one of the bigger developments with GPT-5. Because in software engineering, essentially,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=268" target="_blank">00:04:28.380</a></span> | <span class="t">OpenAI lobbed a grenade at Anthropic. They want the Claude family line to die out without heirs. Because Sweebench</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=277" target="_blank">00:04:37.740</a></span> | <span class="t">verified is the singular benchmark that Anthropic cited as proof that their newest model, 4.1 Opus,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=284" target="_blank">00:04:44.700</a></span> | <span class="t">just a few days old, was the frontier model in this domain. If we completely ignore statistical error</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=290" target="_blank">00:04:50.940</a></span> | <span class="t">bars, GPT-5 is now better. Fair warning, if you are not into coding or even vibe coding, this video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=297" target="_blank">00:04:57.580</a></span> | <span class="t">won't spend too long on it. But straight away within cursor, I did notice the difference. I'm not going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=302" target="_blank">00:05:02.940</a></span> | <span class="t">show my code base right now, so let's just leave this other coding benchmark on screen. But testing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=308" target="_blank">00:05:08.540</a></span> | <span class="t">GPT-5 versus 4.0 Sonnet, the best model you get by default from Anthropic on cursor. And GPT-5 was just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=315" target="_blank">00:05:15.020</a></span> | <span class="t">better. Finding bugs that Sonnet assured me were not there. Obviously, we need more time to test,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=320" target="_blank">00:05:20.780</a></span> | <span class="t">and there's always the black horse of Gemini DeepThink, which I think might be the best of all. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=325" target="_blank">00:05:25.580</a></span> | <span class="t">Anthropic get a lot of revenue from vibe coders and professional developers. So, GPT-5's release</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=331" target="_blank">00:05:31.740</a></span> | <span class="t">could be a challenging time for Anthropic. Now, I know it was a very hype-y statement from the live</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=337" target="_blank">00:05:37.180</a></span> | <span class="t">stream, but I do actually get it when one of the presenters said he trusts the model more with coding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=342" target="_blank">00:05:42.060</a></span> | <span class="t">Of course, language models live and die by data, so if GPT-5 lacks it in your domain, it will be jank,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=347" target="_blank">00:05:47.660</a></span> | <span class="t">so do test things out yourself. Beyond coding though, if you are asking a technical question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=352" target="_blank">00:05:52.700</a></span> | <span class="t">that might rely on an image, GPT-5 is looking real good. Take the MMMU, which includes a ton of charts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=360" target="_blank">00:06:00.860</a></span> | <span class="t">and tables. And here, GPT-5 is beating the massively slower and much more inaccessible Gemini DeepThink,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=369" target="_blank">00:06:09.580</a></span> | <span class="t">which is currently reserved for the addicts forking out $250 a month. Yes, I was disappointed that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=375" target="_blank">00:06:15.580</a></span> | <span class="t">context window has been barely widened. Man, we need some fresh air in here. What I mean is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=381" target="_blank">00:06:21.340</a></span> | <span class="t">I love that Gemini 2.5 Pro can analyse one million tokens, or almost a million words, but we are stuck in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=388" target="_blank">00:06:28.380</a></span> | <span class="t">the low hundreds of thousands for GPT-5. Next, you may have noticed on the live stream,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=393" target="_blank">00:06:33.420</a></span> | <span class="t">Sebastian Bubeck, one of the lead authors of that famous Sparks of AGI paper about GPT-4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=400" target="_blank">00:06:40.140</a></span> | <span class="t">and one of the first viewers of this channel, actually, two and a half years ago. He described</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=405" target="_blank">00:06:45.180</a></span> | <span class="t">the "recursive self-improvement" to be had when models can produce better synthetic data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=411" target="_blank">00:06:51.740</a></span> | <span class="t">that is then used to train the next generation of models. I do get that for getting epic scores on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=417" target="_blank">00:06:57.180</a></span> | <span class="t">benchmarks, but if that was all it took, then models like 5.4 and the Openweight OpenAI GPT-OSS model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=426" target="_blank">00:07:06.060</a></span> | <span class="t">would be demigods by now, given how heavily they were trained on synthetic data. True story,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=431" target="_blank">00:07:11.340</a></span> | <span class="t">that recent OpenAI Openweight model flopped so badly on Simplebench that OpenAI reached out to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=436" target="_blank">00:07:16.380</a></span> | <span class="t">me personally to ask about our settings, which were the standard ones, by the way. A bit later on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=441" target="_blank">00:07:21.580</a></span> | <span class="t">I'm going to go to the biggest bit of anti-hype you could find, but a few new people may be watching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=447" target="_blank">00:07:27.660</a></span> | <span class="t">tonight, so let's touch on another highly usable aspect, amazing aspect of GPT-5. If you watched the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=453" target="_blank">00:07:33.420</a></span> | <span class="t">live stream and thought those vibe coding demos were epic, they were, and don't let addicts like us tell</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=459" target="_blank">00:07:39.580</a></span> | <span class="t">you otherwise. Because snake games and chart displays are everywhere in the training data, that's why GPT-5 can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=467" target="_blank">00:07:47.100</a></span> | <span class="t">bang them out with ease. Building a production-ready consumer app is a very different story for now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=473" target="_blank">00:07:53.740</a></span> | <span class="t">So I would say we don't quite have what Sam Olman quoted tonight, software on demand, but we may be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=479" target="_blank">00:07:59.980</a></span> | <span class="t">slowly getting there. More on that in another video coming out soon. Back to the system card, and they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=485" target="_blank">00:08:05.500</a></span> | <span class="t">kept talking about health journeys. And though I had never heard that expression, it didn't strike me that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=491" target="_blank">00:08:11.580</a></span> | <span class="t">they were taking us for a ride. For me, it's genuinely incredible. And it will be super impactful that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=497" target="_blank">00:08:17.820</a></span> | <span class="t">can often get expert-level text-based diagnoses from these models. Notice I say you can often get that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=504" target="_blank">00:08:24.460</a></span> | <span class="t">Though I don't think many people will have noticed this one, that GPT-5 Mini scored higher on health bench</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=511" target="_blank">00:08:31.660</a></span> | <span class="t">consensus than GPT-5 itself. I can imagine some frantic users on the free tier waiting until their GPT-5</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=518" target="_blank">00:08:38.940</a></span> | <span class="t">allowances out to get the quote "better model on health". Now just in case there's any really confused</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=523" target="_blank">00:08:43.980</a></span> | <span class="t">people watching, if you're wondering, there's no new Sora or image generator. There are however new voices,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=530" target="_blank">00:08:50.460</a></span> | <span class="t">and for those who've been chatting on the free tier with models quite a lot, you should notice a step up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=535" target="_blank">00:08:55.820</a></span> | <span class="t">in conversation quality. Although I was disappointed that GPT-5's language skills have not improved from O3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=543" target="_blank">00:09:03.820</a></span> | <span class="t">Translation, I feel, is such an unmitigated good from AI. I was hoping that they had been able to push the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=550" target="_blank">00:09:10.300</a></span> | <span class="t">frontier a bit harder. Some of you will be asking about the semi-mythical GPT-5 Pro, and yes, I'd love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=556" target="_blank">00:09:16.540</a></span> | <span class="t">to test it. I am on the Pro tier, but I'm not yet seeing it in my app as of tonight, so soon hopefully.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=563" target="_blank">00:09:23.740</a></span> | <span class="t">Probably isn't crazily better than the other types of GPT-5, given they barely mentioned it in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=569" target="_blank">00:09:29.260</a></span> | <span class="t">presentation. Now though, for the real anti-hype, because even one of the lead authors of AI 2027,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=576" target="_blank">00:09:36.140</a></span> | <span class="t">which took the world by storm and was read by millions, well, the headlines or videos derived from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=581" target="_blank">00:09:41.660</a></span> | <span class="t">were seen or read by millions, that's Eli Lifland, said that he noticed from the system card no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=588" target="_blank">00:09:48.780</a></span> | <span class="t">improvement on the coding evals that weren't Sweebench. Translated, you know all those videos you've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=594" target="_blank">00:09:54.460</a></span> | <span class="t">seeing on YouTube about AI taking over the world within the next two years? Well, one of the authors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=600" target="_blank">00:10:00.380</a></span> | <span class="t">behind that, who I interviewed on Patreon, has probably updated in the negative in terms of his</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=606" target="_blank">00:10:06.620</a></span> | <span class="t">timelines. We should be seeing a bit more self-improvement by now, if those timelines were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=611" target="_blank">00:10:11.980</a></span> | <span class="t">accurate. It makes sense, right? We would need to see significant improvement from GPT-5 on machine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=617" target="_blank">00:10:17.900</a></span> | <span class="t">learning engineering, for example, machine learning engineering bench, and we don't quite see that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=623" target="_blank">00:10:23.180</a></span> | <span class="t">What about this benchmark from the system card? OpenAI pull requests. Can GPT-5 do some of the more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=628" target="_blank">00:10:28.860</a></span> | <span class="t">mundane tasks that are performed at OpenAI? Well, without diving too much into that benchmark,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=634" target="_blank">00:10:34.220</a></span> | <span class="t">notice the increment. We're not seeing big jumps from O3. What about the ability of models to replicate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=641" target="_blank">00:10:41.020</a></span> | <span class="t">state-of-the-art AI research? This was tested on OpenAI's own paper bench. Again, correct me if I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=647" target="_blank">00:10:47.500</a></span> | <span class="t">wrong, but not a huge step forward. Then there's this benchmark, arguably the most interesting of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=653" target="_blank">00:10:53.420</a></span> | <span class="t">all. I actually think it's a brilliant benchmark, and I remember asking someone at OpenAI about such</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=659" target="_blank">00:10:59.020</a></span> | <span class="t">a benchmark two years ago. Pretty sure that request had no impact, but either way, check this out. Can AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=664" target="_blank">00:11:04.220</a></span> | <span class="t">models overcome any of 20 internal research and engineering bottlenecks encountered for real at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=670" target="_blank">00:11:10.940</a></span> | <span class="t">OpenAI in the past? These were the kind of bottlenecks that led to delays of at least a day, and in some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=675" target="_blank">00:11:15.660</a></span> | <span class="t">cases they said it influenced the outcome of large training runs and launches. Amazing benchmark, and for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=681" target="_blank">00:11:21.820</a></span> | <span class="t">now, slightly underwhelming performance. I say that, but it kind of depends on your perspective, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=687" target="_blank">00:11:27.820</a></span> | <span class="t">solving 2% of those is not bad in my opinion. My only point was that's the same score as O3. Mind you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=695" target="_blank">00:11:35.100</a></span> | <span class="t">I've just noticed something while filming. The green bar looks taller than O3's bar, even though it's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=701" target="_blank">00:11:41.980</a></span> | <span class="t">same 2%. Man, the chart crimes that OpenAI are doing for GPT-5 are unbelievable. I'm just going to spend 20</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=709" target="_blank">00:11:49.340</a></span> | <span class="t">seconds now on safety, because I did see OpenAI's safety paper, and while I haven't finished it, I do love the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=715" target="_blank">00:11:55.340</a></span> | <span class="t">sound of the new approach on refusals. Basically, they've moved to what's called safe completions as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=721" target="_blank">00:12:01.420</a></span> | <span class="t">a new safety paradigm. It makes sense to me, because rather than the model just making a snap judgment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=726" target="_blank">00:12:06.460</a></span> | <span class="t">is the user's intent good or bad, then completely obeying or refusing. Instead, safe completions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=732" target="_blank">00:12:12.620</a></span> | <span class="t">focuses entirely on the safety of the model's output. Translating the pages I have read so far,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=739" target="_blank">00:12:19.420</a></span> | <span class="t">it's basically, we don't really care why you're asking this, this is the only information we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=744" target="_blank">00:12:24.620</a></span> | <span class="t">give you. Perfect segue to the sponsors of today's video, Grace One. Let me know what you think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=750" target="_blank">00:12:30.220</a></span> | <span class="t">but what I find epic is that you can make all models, not just OpenAI's, more secure yourself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=756" target="_blank">00:12:36.940</a></span> | <span class="t">as in you watching. I mean, literally, a few of the viewers of this channel have gone on to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=762" target="_blank">00:12:42.380</a></span> | <span class="t">leaderboards in these paid competitions. If you are not familiar with them, you basically have to find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=768" target="_blank">00:12:48.940</a></span> | <span class="t">jailbreaks for these models, and thereby improve model security. If you're interested, do use my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=774" target="_blank">00:12:54.860</a></span> | <span class="t">personal link in the description. And for me, models being less likely to output bioterror</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=780" target="_blank">00:13:00.140</a></span> | <span class="t">instructions is just a win-win. Now for some last benchmarks before I draw this first impressions video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=786" target="_blank">00:13:06.220</a></span> | <span class="t">to an end. GPT-5 doesn't quite get the record for what I'm calling a pattern recognition benchmark,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=791" target="_blank">00:13:11.820</a></span> | <span class="t">Arc AGI 2. It's beaten by Grok 4, which gets 16% compared to its 10%. GPT-5 is of course much cheaper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=799" target="_blank">00:13:19.580</a></span> | <span class="t">though. Curiously, GPT-5 got a new record on the Google-proof science benchmark,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=805" target="_blank">00:13:25.820</a></span> | <span class="t">called GPQA, getting 88.4%. But they barely mentioned that on the website or the live stream</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=813" target="_blank">00:13:33.820</a></span> | <span class="t">or the system card. In 2024, this was one of the most cited benchmarks for testing model intelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=819" target="_blank">00:13:39.820</a></span> | <span class="t">Seeing the OpenWeights OpenAI models score so highly did make me start to worry about benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=825" target="_blank">00:13:45.340</a></span> | <span class="t">maxing. Same story with humanity's last exam. In other words, if you are new to the channel and thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=831" target="_blank">00:13:51.020</a></span> | <span class="t">a model breaking records in all sorts of benchmarks meant it had to be the smartest, then do please</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=836" target="_blank">00:13:56.460</a></span> | <span class="t">stick around. Now it seems fitting, as I draw the video to an end, that we should discuss the end of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=842" target="_blank">00:14:02.220</a></span> | <span class="t">model selector. Because unless you are on the pro tier, all the other models that you can see here are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=848" target="_blank">00:14:08.460</a></span> | <span class="t">deprecated. That's good news in a way if you like to avoid that mess of models to select from. Not as good news</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=856" target="_blank">00:14:16.700</a></span> | <span class="t">if you liked a particular variant for whatever reason. So there we are, that's my take on GPT-5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=863" target="_blank">00:14:23.420</a></span> | <span class="t">What is yours? For me, I must admit, it's quite a poignant moment in the history of this channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=869" target="_blank">00:14:29.420</a></span> | <span class="t">I've been making videos touching on what GPT-5 might be like for, man, it must be over two years now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=876" target="_blank">00:14:36.940</a></span> | <span class="t">Some of you watching will have been following the channel since then and thank you so much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=881" target="_blank">00:14:41.660</a></span> | <span class="t">Would the Philip of two years ago have been bowled over by the GPT-5 of today? I genuinely don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=888" target="_blank">00:14:48.940</a></span> | <span class="t">Will we all be bowled over by the GPT-6 or 7 of the future? Only time will tell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=WLdBimUS1IE&t=895" target="_blank">00:14:55.340</a></span> | <span class="t">Man, that was kind of a cliche ending, but forgive me and thank you so much for watching. Have a wonderful day.</span></div></div></body></html>