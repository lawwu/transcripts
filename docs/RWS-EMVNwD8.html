<html><head><title>The Phi-4 Reasoning Technical Report — Vibhu Sapra</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>The Phi-4 Reasoning Technical Report — Vibhu Sapra</h2><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8"><img src="https://i.ytimg.com/vi/RWS-EMVNwD8/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./RWS-EMVNwD8.html">Whisper Transcript</a> | <a href="./transcript_RWS-EMVNwD8.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Let me also pull up chat real quick. But for those that don't know, there's the five series</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=10" target="_blank">00:00:10.940</a></span> | <span class="t">of models, right? So this started out way back when, when Microsoft was trying tiny stories,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=17" target="_blank">00:00:17.860</a></span> | <span class="t">tiny stories was like a one mil multiple million parameters. So not even a billion, not even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=23" target="_blank">00:00:23.280</a></span> | <span class="t">tens of millions parameters models. They just wanted to see, can we make a really small one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=28" target="_blank">00:00:28.880</a></span> | <span class="t">million parameter model, like learn text and can it produce any coherent words? Turns out it can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=35" target="_blank">00:00:35.100</a></span> | <span class="t">Then they had like textbooks is all you need. Or, you know, if you train on textbooks, you can do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=39" target="_blank">00:00:39.980</a></span> | <span class="t">some level of words. Then they had this five series. These were really, really small language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=44" target="_blank">00:00:44.800</a></span> | <span class="t">So like up to one B, then we went from super small, like million parameter to billion to now we're at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=51" target="_blank">00:00:51.680</a></span> | <span class="t">five, four, which is a 14 billion parameter model. So they've gotten chunky. I think, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=57" target="_blank">00:00:57.760</a></span> | <span class="t">the sweet spot that they were hitting was kind of that three B range where no one else was really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=63" target="_blank">00:01:03.460</a></span> | <span class="t">doing this, right? Like we had llama, which was seven B, we had Falcon, we had Mistral. These are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=69" target="_blank">00:01:09.140</a></span> | <span class="t">all seven B models. At the time, Quen wasn't really doing anything tiny, tiny. So these were like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=74" target="_blank">00:01:14.740</a></span> | <span class="t">on device, coherent, somewhat decent models. The history of the five models is that they would do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=81" target="_blank">00:01:21.660</a></span> | <span class="t">good on benchmarks. And then people would say, damn, these models suck. And it turns out that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=86" target="_blank">00:01:26.600</a></span> | <span class="t">you know, they were like accused of training on the benchmarks and they were inflating their scores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=93" target="_blank">00:01:33.000</a></span> | <span class="t">So five, three was the, you know, last one that had a pretty big splash. Five, three was like, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=99" target="_blank">00:01:39.040</a></span> | <span class="t">here's a whole section on how we're doing like decontamination of training data. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=104" target="_blank">00:01:44.880</a></span> | <span class="t">they basically said, Hey, we're serious about this. We're not going to train on benchmarks. Here's how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=110" target="_blank">00:01:50.940</a></span> | <span class="t">we like filter all our data. Here's how we train our big foundation models. They were kind of decent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=116" target="_blank">00:01:56.020</a></span> | <span class="t">Some people use them. Then recently we had five, four, this paper came out December, 2024.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=123" target="_blank">00:02:03.580</a></span> | <span class="t">From there, we, as of this week, have got two more papers called five, four reasoning, reasoning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=130" target="_blank">00:02:10.700</a></span> | <span class="t">mini and reasoning plus. So let's do a quick little refresher on five, four, the one that came out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=138" target="_blank">00:02:18.220</a></span> | <span class="t">because this is kind of the foundation model that builds on top that the other two build on. So anyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=144" target="_blank">00:02:24.140</a></span> | <span class="t">has comments, questions, feel free, you know, pop in wherever. I feel like we covered this in one of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=150" target="_blank">00:02:30.780</a></span> | <span class="t">papers, but anyway, we'll go over it again real quick. So five, four now is 14 billion parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=157" target="_blank">00:02:37.200</a></span> | <span class="t">model model, and they do basically a bunch of high quality filtering. They use LLMs to filter a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=164" target="_blank">00:02:44.240</a></span> | <span class="t">of stuff, and then they have a bunch of synthetic data. So they want to show how like distillation can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=171" target="_blank">00:02:51.100</a></span> | <span class="t">do pretty good. So they train on high quality data. They have the same architecture as five, three,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=178" target="_blank">00:02:58.240</a></span> | <span class="t">but you know, now they're focused on reasoning benchmark. So this came out like pre reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=183" target="_blank">00:03:03.360</a></span> | <span class="t">models. But this is the time when we started to realize, oh, shit, reasoning models are pretty,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=189" target="_blank">00:03:09.200</a></span> | <span class="t">reasoning data is pretty high quality, right? So a bunch of the training data here is synthetic data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=195" target="_blank">00:03:15.600</a></span> | <span class="t">They have stuff like multi agent prompting, self revision workflows, instruction reversal. They have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=201" target="_blank">00:03:21.760</a></span> | <span class="t">section on rejection sampling where, you know, you take examples, you have chain of thought, you see what was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=206" target="_blank">00:03:26.960</a></span> | <span class="t">wrong, they have rejection sampling in there, they do DPO, they start to introduce this concept of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=213" target="_blank">00:03:33.200</a></span> | <span class="t">mid training here, I think they're the ones that start to like, you know, really push on it. And then of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=216" target="_blank">00:03:36.720</a></span> | <span class="t">course, in their new thinking models, they have mid training is like their whole mid training is all you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=223" target="_blank">00:03:43.120</a></span> | <span class="t">need, you know, but this one was basically synthetic data, SFT, DPO, we can get pretty good models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=229" target="_blank">00:03:49.920</a></span> | <span class="t">Mid training, mid training is all they need. Here's kind of the benchmarks of how it performed at the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=235" target="_blank">00:03:55.440</a></span> | <span class="t">So, you know, as they always claim, it's kind of 4.0 mini, it's like, similar to the 70b models, it's similar to 4.0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=245" target="_blank">00:04:05.440</a></span> | <span class="t">But you know, this is a little old, it's kind of out of date now, but still good to know what the overall thing is on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=251" target="_blank">00:04:11.440</a></span> | <span class="t">So step zero is this data generation, they have this whole method of seeding data, expanding it out, post training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=259" target="_blank">00:04:19.360</a></span> | <span class="t">stuff like that. And then you know, performance is on par with even 4.05 B, but they've been known to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=268" target="_blank">00:04:28.160</a></span> | <span class="t">not have the best, like track record of how they actually perform on benchmarks. But from what,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=275" target="_blank">00:04:35.920</a></span> | <span class="t">you know, people say for 5.4, this is where things start to turn around, especially because they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=281" target="_blank">00:04:41.440</a></span> | <span class="t">this whole decontamination set. So like they really kick off the paper with addressing overfitting and data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=288" target="_blank">00:04:48.000</a></span> | <span class="t">contamination where, you know, one of their original pitfalls is that they have learned to overfit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=295" target="_blank">00:04:55.040</a></span> | <span class="t">So they improved their data decontamination process. Basically, they have good ways to take out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=304" target="_blank">00:05:04.400</a></span> | <span class="t">stuff from data sets, you know, it's what you would expect, they can use LLMs to filter this out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=308" target="_blank">00:05:08.800</a></span> | <span class="t">they can not train on variants of data set stuff. They have contamination proof benchmarks that they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=316" target="_blank">00:05:16.640</a></span> | <span class="t">doing. Okay, what else have we got here? So purpose of synthetic data, synthetic data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=323" target="_blank">00:05:23.360</a></span> | <span class="t">pretty good, right? It's a form of distillation with SFT, structured, gradual learning, what else?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=329" target="_blank">00:05:29.360</a></span> | <span class="t">Chain of thought data is in there. So synthetic data for pre-training and mid-training. Here's kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=335" target="_blank">00:05:35.200</a></span> | <span class="t">of how they do it. So it begins with high quality seeds from multiple domains. Basically, they start seeding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=341" target="_blank">00:05:41.440</a></span> | <span class="t">data from big domains, right? So they'll do web scrapes, they'll do this seeding filtration process,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=346" target="_blank">00:05:46.640</a></span> | <span class="t">right? So essentially, they'll take big data sets, they'll use an LLM and they'll start filtering it. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=352" target="_blank">00:05:52.480</a></span> | <span class="t">they want to identify what's the highest quality of this data, then they'll generate synthetic examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=358" target="_blank">00:05:58.080</a></span> | <span class="t">and they'll use these examples as more training data. They talk quite a bit about multiple epochs for different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=364" target="_blank">00:06:04.160</a></span> | <span class="t">sub data sets, but yeah, you know, they created 50 types of synthetic data sets. So web and code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=371" target="_blank">00:06:11.840</a></span> | <span class="t">code-based seed, right? For example, so they have a two-stage filtration process. First, identifying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=376" target="_blank">00:06:16.800</a></span> | <span class="t">pages with strong educational content and second, segmenting selected passages into pages into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=382" target="_blank">00:06:22.800</a></span> | <span class="t">passages, scoring each for its factual and reasoning content. Basically, they're trying to filter out what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=387" target="_blank">00:06:27.600</a></span> | <span class="t">is good reasoning data here. In this, for question data sets, you know, discard questions where all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=393" target="_blank">00:06:33.520</a></span> | <span class="t">answered were agreed, you know, where questions are easy or where the answers were kind of inconsistent. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=398" target="_blank">00:06:38.960</a></span> | <span class="t">a lot of data filtration, delete, deduction chains, logical reasoning steps, kind of more efficient,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=406" target="_blank">00:06:46.800</a></span> | <span class="t">rewrite and augment data. So seeds are transformed into synthetic data through multi-step prompting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=413" target="_blank">00:06:53.760</a></span> | <span class="t">workflows. That includes rewriting the most useful content in a passage into exercises,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=418" target="_blank">00:06:58.640</a></span> | <span class="t">discussions, the structured reasoning. So once you have a lot of text, you subset the best part of it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=424" target="_blank">00:07:04.160</a></span> | <span class="t">you know, what are the actual hard questions here? From there, let's rewrite it into exercises,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=429" target="_blank">00:07:09.040</a></span> | <span class="t">let's create discussions around it, let's have structured reasoning to how we got to that example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=433" target="_blank">00:07:13.200</a></span> | <span class="t">That's kind of how they do that. Self-revision, instruction reversal for code. So, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=439" target="_blank">00:07:19.520</a></span> | <span class="t">you have high quality code, let's reverse it. Let's get the path out of it. Let's get the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=444" target="_blank">00:07:24.240</a></span> | <span class="t">you know, generation steps out of it. Filtering web dumps was another one. They have small non-LLM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=451" target="_blank">00:07:31.680</a></span> | <span class="t">classifiers trained on annotations on how to filter out web dumps. They have subsets of non-filtered and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=459" target="_blank">00:07:39.600</a></span> | <span class="t">filtered stuff. You know, they over-index on STEM words. They want to just get that high-level stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=466" target="_blank">00:07:46.240</a></span> | <span class="t">They have multi-modality into this, multi-linguality, sorry. So 176 languages. More extraction, more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=474" target="_blank">00:07:54.240</a></span> | <span class="t">cleaning. Okay. Post-training. Post-training has SFT and DPO. And then we kind of go into their training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=481" target="_blank">00:08:01.840</a></span> | <span class="t">mix. I think like five minutes to cover what they're doing here. But you know, they start off with 4K context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=488" target="_blank">00:08:08.160</a></span> | <span class="t">length. They extend it out to 16K during mid-training. They have a new vocab of a hundred thousand with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=495" target="_blank">00:08:15.120</a></span> | <span class="t">unused tokens. Turns out they just left this note in the paper in December. These unused tokens are what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=501" target="_blank">00:08:21.520</a></span> | <span class="t">the reasoning tokens end up becoming, right? So they add in these think tokens out of the unused tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=506" target="_blank">00:08:26.640</a></span> | <span class="t">and that's how they're able to do it. Previously, they had had a sliding window attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=512" target="_blank">00:08:32.320</a></span> | <span class="t">in 5-3. Now they do full attention over the 4K context. This model trained from scratch is on 10</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=519" target="_blank">00:08:39.520</a></span> | <span class="t">trillion tokens. They kind of give you, you know, here's the regular learning rate, weight decay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=524" target="_blank">00:08:44.480</a></span> | <span class="t">batch size, all that stuff. But pre-trained from scratch, 10 million tokens, a lot of synthetic tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=530" target="_blank">00:08:50.400</a></span> | <span class="t">Then after that, they have a mid-training stage where they do this context length extension from 4K to 16K.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=538" target="_blank">00:08:58.000</a></span> | <span class="t">The interesting thing with all their models, even their reasoning models, like in the reasoning models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=543" target="_blank">00:09:03.440</a></span> | <span class="t">they have four stages of training. So one of the things that they noted was like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=549" target="_blank">00:09:09.920</a></span> | <span class="t">as we do GRPO, we run into like vanishing gradient problems where, you know, at all lengths we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=556" target="_blank">00:09:16.880</a></span> | <span class="t">issues. So at each stage, at each stages of their fixing these problems, how our performance is doing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=563" target="_blank">00:09:23.440</a></span> | <span class="t">How many more points do we get in different benchmarks? Pretty interesting way how they lay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=568" target="_blank">00:09:28.240</a></span> | <span class="t">these out. It's just like really a lot of learning. Okay, so 5-3 was two stages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=576" target="_blank">00:09:36.320</a></span> | <span class="t">Phase one was largely filtered web text. Phase two was basically, you know, small subset of reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=584" target="_blank">00:09:44.000</a></span> | <span class="t">tokens, basically like the high quality code and math. In this case, they show that web data sets had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=591" target="_blank">00:09:51.520</a></span> | <span class="t">small benefits on reasoning heavy benchmarks. Models trained with only synthetic data underperformed on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=597" target="_blank">00:09:57.280</a></span> | <span class="t">knowledge heavy benchmarks as well. So, you know, we need to fix these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=601" target="_blank">00:10:01.840</a></span> | <span class="t">TLDR, here's their data pre-training mixture, where we search over different allocations of tokens coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=609" target="_blank">00:10:09.600</a></span> | <span class="t">from various sources, mainly synthetic, web rewrites, web filtration, divided into reasoning and knowledge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=616" target="_blank">00:10:16.560</a></span> | <span class="t">heavy portions, targeted acquisitions and organic data. So math, books, stuff like that, forums, code data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=624" target="_blank">00:10:24.000</a></span> | <span class="t">And then there's a correlation between 7B and 14B models. Basically, they noticed that the scaling was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=631" target="_blank">00:10:31.520</a></span> | <span class="t">pretty consistent. So they did a lot of their data pre-training mixtures on a 7B model, and then they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=637" target="_blank">00:10:37.200</a></span> | <span class="t">transferred that understanding over to the 14B. Let's go a little bit faster. Here's their subset of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=645" target="_blank">00:10:45.840</a></span> | <span class="t">the final training of their 10B tokens in the pre-training stage. Or I don't know if it's 10B,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=651" target="_blank">00:10:51.520</a></span> | <span class="t">because they're still post-training, you know. So like, let's see, probably 95% of the training is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=656" target="_blank">00:10:56.880</a></span> | <span class="t">here in pre-training. The interesting thing here is, you know, they have a lot of epochs for different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=662" target="_blank">00:11:02.320</a></span> | <span class="t">data. So like synthetic data, even though there's only 290 billion tokens, it's actually 40% of the total</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=669" target="_blank">00:11:09.600</a></span> | <span class="t">pre-training because they go over it with 14 epochs, basically. But yeah, so to keep everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=677" target="_blank">00:11:17.120</a></span> | <span class="t">general, 30% of the training tokens are for web and web rewrites, namely 1.3 trillion tokens of just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=684" target="_blank">00:11:24.080</a></span> | <span class="t">web scraping. Web rewrites are 290 billion tokens, but you know, we do multiple epochs on that. Then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=690" target="_blank">00:11:30.320</a></span> | <span class="t">the remaining tokens are largely from synthetic data, which is 40% of that. 20% of this is pure code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=697" target="_blank">00:11:37.280</a></span> | <span class="t">and then acquired sources are, you know, like the stuff that like the textbooks and things like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=702" target="_blank">00:11:42.720</a></span> | <span class="t">That's most of the pre-training. Then they have their mid-training where they extend context length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=709" target="_blank">00:11:49.680</a></span> | <span class="t">Here is, you know, where they are high quality non-synthetic data sets separate. So they filter out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=718" target="_blank">00:11:58.160</a></span> | <span class="t">in these pre-training sets, which one of these samples have long context, right? So in their pre-training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=725" target="_blank">00:12:05.920</a></span> | <span class="t">what is over 8,000 tokens, what is 16,000? Then they upweight subsets that are long, right? Then they do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=733" target="_blank">00:12:13.440</a></span> | <span class="t">synthetic data sets to have more than 4k. The data set of this long context extension is 30% newly curated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=742" target="_blank">00:12:22.800</a></span> | <span class="t">and 70% of previous stuff from the original pre-training. Then, you know, here's how it performs on different long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=752" target="_blank">00:12:32.640</a></span> | <span class="t">context evals. So recall, rag, re-ranking, summarization. Here's how the models actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=759" target="_blank">00:12:39.120</a></span> | <span class="t">perform. And they show pretty good benchmarks on this, you know? And they kind of explain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=766" target="_blank">00:12:46.000</a></span> | <span class="t">for people that don't understand what are long context benchmarks. Here's kind of the ones that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=770" target="_blank">00:12:50.640</a></span> | <span class="t">exist, right? So recall, this is basically retrieving corresponding value from randomly generated long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=776" target="_blank">00:12:56.240</a></span> | <span class="t">files. Rag, answering questions with QA. You know, this is a subset of these data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=782" target="_blank">00:13:02.800</a></span> | <span class="t">Re-ranking is, you know, you're given 10 documents and a query. You want to re-rank them. QA is question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=789" target="_blank">00:13:09.840</a></span> | <span class="t">answer over long document. Oh, my thing has froze. Okay, never mind. I just decided to break my PDF reader a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=799" target="_blank">00:13:19.680</a></span> | <span class="t">little bit. That's cool. Okay, after that, they have post-training. They do DPO. You know, this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=805" target="_blank">00:13:25.760</a></span> | <span class="t">basically, let's make it a chat-tuned model instead of a base model. Interesting thing to note in the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=812" target="_blank">00:13:32.240</a></span> | <span class="t">this week in the thinking model, one of the approaches that they tried was instead of using the actual 5/4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=818" target="_blank">00:13:38.800</a></span> | <span class="t">model, what if we take the base model and not the instruction-tuned model? And what if we do all of our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=825" target="_blank">00:13:45.360</a></span> | <span class="t">thinking from there? And they're like, actually, it does pretty well, but not good enough. So, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=831" target="_blank">00:13:51.680</a></span> | <span class="t">spoiler, they end up just using their instruction-tuned model. But very open how they do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=836" target="_blank">00:13:56.800</a></span> | <span class="t">So, you know, they use ChatML, you know, user assistant, they have DPO, they have SFT, they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=843" target="_blank">00:14:03.360</a></span> | <span class="t">multilingual data. This is pretty interesting. They only need 8 billion tokens out of their 10 trillion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=848" target="_blank">00:14:08.880</a></span> | <span class="t">during their SFT and post-training, you know. So, DPO is, you know, alignment. SFT is for following</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=856" target="_blank">00:14:16.880</a></span> | <span class="t">that completion. I think that's basically enough for high-level what's going on in 5/4. Performances are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=865" target="_blank">00:14:25.680</a></span> | <span class="t">as you'd expect, you know, it's a 14B. There aren't many 14Bs anymore. They have sections on red teaming,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=872" target="_blank">00:14:32.240</a></span> | <span class="t">weakness. They have a lot of, like, just open research. But yeah, that's kind of where they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=877" target="_blank">00:14:37.200</a></span> | <span class="t">sit, you know. They have 14B models. They do a lot of filtration. They do pre-training. They have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=883" target="_blank">00:14:43.440</a></span> | <span class="t">set of mid-training. They have SFT. They have DPO. It performs pretty good. It's on par with what you'd</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=890" target="_blank">00:14:50.480</a></span> | <span class="t">expect, you know. It came out after Quen 2.5B 14 Instruct, so it's slightly better. Better than 5.3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=897" target="_blank">00:14:57.360</a></span> | <span class="t">of course. When you look at stuff like 4.0 Mini or 4.0, you know, in some cases, it's better. On math</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=904" target="_blank">00:15:04.960</a></span> | <span class="t">and GPQA, they say it's better. Human eval, so coding stuff like this, slightly worse. Simple QA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=910" target="_blank">00:15:10.320</a></span> | <span class="t">One thing that they note, you know, like, in some of the problems with these models is that when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=917" target="_blank">00:15:17.600</a></span> | <span class="t">have factual, like, recollection, they do note that small models just struggle with this, right? Model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=923" target="_blank">00:15:23.520</a></span> | <span class="t">small model can't recognize a bunch of facts, so on QA, it's not the best. Big model will always do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=928" target="_blank">00:15:28.640</a></span> | <span class="t">better. But yeah, that's kind of what 5.4 is at a high level. It's cool, you know. It's, like, not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=936" target="_blank">00:15:36.880</a></span> | <span class="t">better than LAMA 3.370B, but in some areas it is where, you know, they tried to get this reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=944" target="_blank">00:15:44.320</a></span> | <span class="t">data through SFT and SlightDPO with just filtration and a lot of synthetic data. But okay, I will pause</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=951" target="_blank">00:15:51.360</a></span> | <span class="t">here since that's mostly 5.4. From there, we'll go on to the two reasoning data sets. But any questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=959" target="_blank">00:15:59.120</a></span> | <span class="t">any thoughts, questions, comments, concerns? Has anyone used it? Probably not. They get some use now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=966" target="_blank">00:16:06.160</a></span> | <span class="t">they're, like, actually hosted by most people. They're on the, they're there through Azure and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=972" target="_blank">00:16:12.080</a></span> | <span class="t">stuff, of course. But some people have started using them, you know. But anyway, any questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=977" target="_blank">00:16:17.040</a></span> | <span class="t">any thoughts? Okay, chat, someone has said something. It's interesting to me, FI reasoning distilled from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=981" target="_blank">00:16:21.840</a></span> | <span class="t">O3 and FI 4 mini distilled from DeepSeq. Why they use completely different SFT curated data sets,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=987" target="_blank">00:16:27.600</a></span> | <span class="t">also kind of different SFT strategy. Yeah, it's an interesting note that they make. So the papers that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=993" target="_blank">00:16:33.520</a></span> | <span class="t">they released this week, let me actually change my screen share real quick. So this came out in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=999" target="_blank">00:16:39.760</a></span> | <span class="t">December. They have two models, two models that they released, kind of three, actually. So FI 4 mini</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1005" target="_blank">00:16:45.920</a></span> | <span class="t">reasoning, this builds on FI 4 mini. So it's actually a three point something B model. Let me check real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1013" target="_blank">00:16:53.920</a></span> | <span class="t">quick. This is roughly a 3B model. And they show that, you know, there's a whole different set to getting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1023" target="_blank">00:17:03.360</a></span> | <span class="t">sorry, 3.8 B. There's a whole different formula to getting a small, small model to do reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1029" target="_blank">00:17:09.680</a></span> | <span class="t">than there is to getting a large model to do reasoning. So one of the interesting notes that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1035" target="_blank">00:17:15.360</a></span> | <span class="t">someone in chat pointed out is that when they do FI 4 mini reasoning, they do their distillation from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1042" target="_blank">00:17:22.640</a></span> | <span class="t">DeepSeq. But when they do FI 4 large, the one on the 14 B in the plus, they do it from O1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1050" target="_blank">00:17:30.880</a></span> | <span class="t">Sorry, from O3, O3 mini, which is interesting. Who knows why. But there's so many little gems in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1058" target="_blank">00:17:38.720</a></span> | <span class="t">FI 4 mini reasoning paper. Like, for example, they cite a bunch of recent sources of getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1066" target="_blank">00:17:46.320</a></span> | <span class="t">small models to do reasoning. Basically, they start with DeepSeq R1, right? So DeepSeq R1 had distals.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1073" target="_blank">00:17:53.600</a></span> | <span class="t">They had Quen and Llama distals. And they show how they can do better. After that, there was a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1080" target="_blank">00:18:00.880</a></span> | <span class="t">stuff like stuff from OpenHands, stuff from S1. And they make little notes here, right? So like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1088" target="_blank">00:18:08.240</a></span> | <span class="t">there's, there's other things like there's OpenThinker, Bespoke Labs. But one thing that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1093" target="_blank">00:18:13.520</a></span> | <span class="t">noticed was like, if they take the S1 and Limo datasets, S1 was basically, you know, a thousand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1099" target="_blank">00:18:19.280</a></span> | <span class="t">samples of reasoning data trained into Quen 32B, I believe, had a really good reasoning model, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1107" target="_blank">00:18:27.200</a></span> | <span class="t">So a thousand samples is all you need. They show that if they do this SFT on a thousand samples of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1114" target="_blank">00:18:34.160</a></span> | <span class="t">their mini 3.8B model, it actually performs worse. So even though it performed well for S1, S1 is where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1123" target="_blank">00:18:43.440</a></span> | <span class="t">they did it at 32B. They took a base instruct model. They did a thousand reasoning, high, high quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1128" target="_blank">00:18:48.640</a></span> | <span class="t">reasoning samples. They got reasoning. It worked very well. Benchmarks shot up like crazy. S1 paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1133" target="_blank">00:18:53.680</a></span> | <span class="t">was pretty cool, but pretty basic. They show that if we do the exact same thing on 5.4 mini, so we take a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1139" target="_blank">00:18:59.040</a></span> | <span class="t">3.8B model that's competent, good, instruction-tuned, we do a thousand samples of SFT on really good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1146" target="_blank">00:19:06.080</a></span> | <span class="t">reasoning data set, our scores actually go down a lot. So base model had a score of 10, 78, 37.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1153" target="_blank">00:19:13.520</a></span> | <span class="t">It shot down to 3, 47, 26. So TLDR is, you know, that actually doesn't work. And they, I don't remember,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1162" target="_blank">00:19:22.000</a></span> | <span class="t">I was like trying to quote something in this, but they keep saying like, we need to explore a better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1166" target="_blank">00:19:26.240</a></span> | <span class="t">recipe for how to do reasoning tiny models. This paper is basically a blueprint for that. But you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1172" target="_blank">00:19:32.080</a></span> | <span class="t">it is based on DeepSeq. I would assume the reason that they do DeepSeq to answer the question exactly is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1179" target="_blank">00:19:39.760</a></span> | <span class="t">because they're specifically comparing their model to Lama 3.8B, the distil, and the Quen distil. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1189" target="_blank">00:19:49.600</a></span> | <span class="t">they're training on both, they're comparing to both distils and, you know, why not use DeepSeq?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1195" target="_blank">00:19:55.440</a></span> | <span class="t">But anyway, before we move on to that and then the large one, any questions on regular 5.4?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1206" target="_blank">00:20:06.160</a></span> | <span class="t">Okay, we move on. Someone asked about training on synthetic data risk, the effect of hallucinations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1212" target="_blank">00:20:12.960</a></span> | <span class="t">So if you look deeper in there, like synthetic data processing, they have heavy, heavy filtration. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1218" target="_blank">00:20:18.560</a></span> | <span class="t">for some stuff that's questionable, for some stuff that has like good chain of thought, but not the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1226" target="_blank">00:20:26.160</a></span> | <span class="t">right final output, they deal with that. But basically, you know, they have verifiable math output,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1230" target="_blank">00:20:30.640</a></span> | <span class="t">they have verifiable code. They basically have really good pipelines to test whether outputs are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1237" target="_blank">00:20:37.120</a></span> | <span class="t">correct or not. And then this is a lot more shown in the 5.3 paper as well. Is there any justification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1243" target="_blank">00:20:43.680</a></span> | <span class="t">on why they did so many epochs in synthetic data or any rationale behind that? So in 5.4, yeah, basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1249" target="_blank">00:20:49.840</a></span> | <span class="t">they're just saying that all their synthetic data is just higher quality, right? So they start here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1255" target="_blank">00:20:55.440</a></span> | <span class="t">I'm sorry, it's a reasoning paper. Basically, they start with the web scrape is decent, we can filter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1260" target="_blank">00:21:00.400</a></span> | <span class="t">it down and then expand it, and it's all better quality data. And then in 5.3, they show some of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1265" target="_blank">00:21:05.120</a></span> | <span class="t">this too. But the number of epochs is kind of interesting. Specifically, like when they show in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1272" target="_blank">00:21:12.000</a></span> | <span class="t">context length extension, something they talk about in a lot of these, and they also do actually mention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1278" target="_blank">00:21:18.400</a></span> | <span class="t">this in later, like towards the end, I just don't think it's worth covering since these are more so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1283" target="_blank">00:21:23.680</a></span> | <span class="t">reasoning benchmarks. Some of the interesting things that they note is they do like this method of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1289" target="_blank">00:21:29.760</a></span> | <span class="t">packing and unpacking prompts. They also show how they'll repeat long context examples that were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1299" target="_blank">00:21:39.920</a></span> | <span class="t">done in pre-training. So even their method of multiple epochs is like not necessarily reflecting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1308" target="_blank">00:21:48.800</a></span> | <span class="t">the exact number of samples. Although I'm sure it's very minute, in this pre-training, like for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1320" target="_blank">00:22:00.320</a></span> | <span class="t">the web data has 1.3 trillion tokens and is 1.2 epochs. In the mid-training where they do context length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1328" target="_blank">00:22:08.560</a></span> | <span class="t">extension, they once again use the previous samples that had more than 8k context. So they do create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1336" target="_blank">00:22:16.960</a></span> | <span class="t">synthetic, but they also reuse. So like, you know, this is a little skewed, but I don't know, they just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1342" target="_blank">00:22:22.160</a></span> | <span class="t">show that synthetic data is good. The other nice thing about these papers is that they basically cite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1347" target="_blank">00:22:27.040</a></span> | <span class="t">everything. A lot, a lot of citations. But what they show here is like a bunch of synthetic data, model go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1354" target="_blank">00:22:34.400</a></span> | <span class="t">good. As you would expect, the reasoning models kind of follow that same trajectory, right? A lot of synthetic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1361" target="_blank">00:22:41.600</a></span> | <span class="t">data, model can reason, model get good. But let's start with the mini reasoning model. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1366" target="_blank">00:22:46.160</a></span> | <span class="t">5.4 mini reasoning. This is the 3.8 B reasoning model. Okay, so improving small language model reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1377" target="_blank">00:22:57.520</a></span> | <span class="t">remains challenging due to their limited model capability. Also, are we seeing my entire screen?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1382" target="_blank">00:23:02.960</a></span> | <span class="t">Okay, we are making sure we're on the right paper. So they kind of bring up R1 distillation, right? So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1390" target="_blank">00:23:10.400</a></span> | <span class="t">distillation from LLM generated synthetic data can improve reasoning and they show that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1395" target="_blank">00:23:15.200</a></span> | <span class="t">even doing SFT works. So this paper, this work is trying to get a systematic training recipe for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1403" target="_blank">00:23:23.040</a></span> | <span class="t">small language models. They have four steps. Step one is large scale mid training on diverse distilled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1409" target="_blank">00:23:29.200</a></span> | <span class="t">chain of thought data. Step two is SFT on high quality long chain of thought. Step three is rollout DPO to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1416" target="_blank">00:23:36.560</a></span> | <span class="t">leverage carefully curated preference data set. Step four is RL with verifiable reward. So four steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1424" target="_blank">00:23:44.400</a></span> | <span class="t">here's how we do reasoning on tiny model. And at the end, they show that, you know, their compact 3.8 B</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1431" target="_blank">00:23:51.600</a></span> | <span class="t">reasoner can outperform distilled reasoning when 7B and distilled reasoning LLM8B by, you know, a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1439" target="_blank">00:23:59.120</a></span> | <span class="t">bit on math. They're starting to do even more and not overfitting here. So they have sections on like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1446" target="_blank">00:24:06.320</a></span> | <span class="t">calendar planning and they're like, this is something we didn't explicitly train on at all. We filtered out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1451" target="_blank">00:24:11.920</a></span> | <span class="t">data sets in our training, but our models start to generalize. Like they do really good on this task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1457" target="_blank">00:24:17.520</a></span> | <span class="t">And this is something that wasn't trained on at all. Um, basically they validate a carefully designed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1463" target="_blank">00:24:23.440</a></span> | <span class="t">training recipe with large scale, high quality chain of thought data is effective to unlock strong</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1468" target="_blank">00:24:28.240</a></span> | <span class="t">reasoning capabilities, even in reasoning constraints, small models. I don't know what their like team is up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1474" target="_blank">00:24:34.400</a></span> | <span class="t">to with chart colors, but here they go all pink and purple. So, um, here's, you know, AIME 24,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1480" target="_blank">00:24:40.880</a></span> | <span class="t">math 500, GPQA diamond. Um, the original 5.4 is this shade of purple. Um, the R1 distills,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1489" target="_blank">00:24:49.200</a></span> | <span class="t">you know, you can see how they're actually pretty good. So LLM8 and Quinn were pretty good, but hey,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1494" target="_blank">00:24:54.240</a></span> | <span class="t">their tiny model at half the parameters can do even better. They're winning. Um, I thought this was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1499" target="_blank">00:24:59.200</a></span> | <span class="t">interesting, uh, equal contribution for everyone except the first and last two authors. Screw the others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1505" target="_blank">00:25:05.680</a></span> | <span class="t">They, they, they're just listed first, but not equal contribution. Um, those charts are pink.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1510" target="_blank">00:25:10.960</a></span> | <span class="t">These charts are colorful and different, but okay. Back to this. Um, I feel like me sitting here and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1518" target="_blank">00:25:18.720</a></span> | <span class="t">reading through charts is useless. Um, but you know, oh no, my reader is broken. Okay. If interested,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1526" target="_blank">00:25:26.000</a></span> | <span class="t">of how they perform small models, it's interesting how they, they put, uh, 4.0 mini kind of under the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1533" target="_blank">00:25:33.680</a></span> | <span class="t">small model section instead of large models, uh, and 4.0 here, we don't really know how big 4.0 mini is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1542" target="_blank">00:25:42.160</a></span> | <span class="t">but, um, it's there nonetheless. Um, Oh, wrong, wrong chart. My bad. Let me go back to this. Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1552" target="_blank">00:25:52.080</a></span> | <span class="t">Okay. Sorry. Wrong chart. Okay. Um, basically they start off with their intro. They're like, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1557" target="_blank">00:25:57.520</a></span> | <span class="t">chain of thought is a way to do reasoning steps. It's cool. Uh, they say that small language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1563" target="_blank">00:26:03.760</a></span> | <span class="t">struggle with chain of thought. I thought that's kind of interesting. Um, enhancing reasoning capabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1569" target="_blank">00:26:09.600</a></span> | <span class="t">is easier for language models for large language models due to extensive capability. It remains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1575" target="_blank">00:26:15.120</a></span> | <span class="t">challenging for small reasoning models. Um, deep seek R1 shows that non-logit level distillation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1581" target="_blank">00:26:21.440</a></span> | <span class="t">basically just SFT with synthetic data makes a good reasoning performance. Then they cite all the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1588" target="_blank">00:26:28.640</a></span> | <span class="t">stuff. Um, then they show the other people. So, you know, um, bespoke studio, bespoke labs, 7b open thinker,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1596" target="_blank">00:26:36.560</a></span> | <span class="t">7b. Uh, they show that, um, they can do this with SFT. Um, some people suggest GRPO deep scaler does S1 and LIMO,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1608" target="_blank">00:26:48.480</a></span> | <span class="t">um, show that, you know, small samples, even a thousand sets, a thousand samples can do good reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1615" target="_blank">00:26:55.360</a></span> | <span class="t">Okay. Um, rather than focusing on isolated techniques, we explore training paradigms specifically tailored for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1624" target="_blank">00:27:04.400</a></span> | <span class="t">small language models. So, um, they have two stages of distillation followed by rollout-based learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1632" target="_blank">00:27:12.800</a></span> | <span class="t">that reuses wrong LLM-generated samples and concludes with RL with verifiable reward. Initially, we employ</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1639" target="_blank">00:27:19.840</a></span> | <span class="t">a distillation as mid-training mechanism to embed foundation models with reasoning capabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1645" target="_blank">00:27:25.280</a></span> | <span class="t">Then they apply distillation again in fine tuning to further improve generalization. Uh, then there's LLM rollout</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1652" target="_blank">00:27:32.320</a></span> | <span class="t">out sampling for distillation. Incorrect outputs are typically discarded. However, they want to still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1657" target="_blank">00:27:37.680</a></span> | <span class="t">use them. So they have this way of doing this, um, set. They, they take, uh, a sort of RL approach where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1665" target="_blank">00:27:45.760</a></span> | <span class="t">they have it optimized, um, long. So if the answer is incorrect, it should still think a lot for incorrect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1673" target="_blank">00:27:53.840</a></span> | <span class="t">examples. And then they want conciseness on correct examples and stuff. They talk about this later. Then they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1679" target="_blank">00:27:59.840</a></span> | <span class="t">fine tune it with RL for final correctness, um, outcomes, five, four reasoning. Okay. More background, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1687" target="_blank">00:28:07.760</a></span> | <span class="t">optimal distillation strategy for small models still unexplored. They keep repeating this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1693" target="_blank">00:28:13.120</a></span> | <span class="t">um, you know, data diversity. Uh, so they showed that, you know, um, data diversity and quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1702" target="_blank">00:28:22.160</a></span> | <span class="t">is very important. Applying isolated techniques degrades performance. So they tried S1 on 5-4 mini went down,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1710" target="_blank">00:28:30.400</a></span> | <span class="t">which I thought is pretty crazy. Um, their goal is to once again, comprehensive efficient training recipe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1717" target="_blank">00:28:37.680</a></span> | <span class="t">for small language models. So, um, non-reasoning models require a pre, uh, mid training stage to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1724" target="_blank">00:28:44.400</a></span> | <span class="t">absorb a large volume of rate reasoning trajectories before additional techniques are applied. So once</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1729" target="_blank">00:28:49.840</a></span> | <span class="t">again, you know, if small, we need mid training. They love this concept of mid training. So quick questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1735" target="_blank">00:28:55.680</a></span> | <span class="t">to ask is how much mid training do they need? And then what do we do after mid training? Like careful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1740" target="_blank">00:29:00.880</a></span> | <span class="t">distillation, preference learning RL, what should we do next? Uh, once again, systematically address these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1746" target="_blank">00:29:06.880</a></span> | <span class="t">conditions and propose a recipe for building small reasoning models. Mid training is basically after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1752" target="_blank">00:29:12.080</a></span> | <span class="t">pre training and after pre training and before post training. It's mid training. Um, it's like, you know, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1760" target="_blank">00:29:20.960</a></span> | <span class="t">have SFT for post training, but before you do that, when you have base model, is there something that we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1766" target="_blank">00:29:26.400</a></span> | <span class="t">do to do this sort of reasoning or before this specific RL DPO before that last step of most high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1773" target="_blank">00:29:33.440</a></span> | <span class="t">quality stuff? Basically, uh, you know, if you take an instruction model, like five, four mini, and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1779" target="_blank">00:29:39.280</a></span> | <span class="t">just do direct, um, 1000 samples of high quality deep data, like you're cooked, you're not getting, um, reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1788" target="_blank">00:29:48.400</a></span> | <span class="t">The models, the small models cannot pick that up in time. So they're saying mid training is where, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1793" target="_blank">00:29:53.280</a></span> | <span class="t">you need this stage of, let's do some chain of thought, extended synthetic reasoning data. Let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1799" target="_blank">00:29:59.360</a></span> | <span class="t">roll out reasoning, tracing steps. Let's have thinking steps. Let's do a lot of those. Then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1804" target="_blank">00:30:04.320</a></span> | <span class="t">go once again to our core examples. Um, that's kind of what, that's kind of what it is. And yeah, it's like, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1811" target="_blank">00:30:11.360</a></span> | <span class="t">basically train us train on chain of thought before your RL. Okay. Multi-stage, um, continual training for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1819" target="_blank">00:30:19.200</a></span> | <span class="t">reasoning. So, um, multi-stage continual training is good. First we do that. We train curated chain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1825" target="_blank">00:30:25.440</a></span> | <span class="t">of thought reasoning data set. Then we run RL with verifiable rewards. Okay. So can distillation be used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1832" target="_blank">00:30:32.320</a></span> | <span class="t">as mid training? Yes. Uh, we want to use distillation. So we train base models with next token prediction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1839" target="_blank">00:30:39.280</a></span> | <span class="t">on extensive corpus of synthetic chain of thought data. Uh, chain of thought are generated from deep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1846" target="_blank">00:30:46.560</a></span> | <span class="t">seek R1. We apply rejection sampling, only get the correct answer. They talk about this later in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1852" target="_blank">00:30:52.000</a></span> | <span class="t">section four. We pair questions with correct chain of thought, uh, with corresponding correct chain of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1856" target="_blank">00:30:56.640</a></span> | <span class="t">thought answers, train a base model using standard causal language modeling objective. Uh, they have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1863" target="_blank">00:31:03.280</a></span> | <span class="t">packing mode. So basically what they're doing here is not just SFT on reasoning. They're packing in multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1871" target="_blank">00:31:11.120</a></span> | <span class="t">examples into one training set, right? So, um, multiple examples are packed into the same input sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1877" target="_blank">00:31:17.600</a></span> | <span class="t">to increase token efficiency. So we're not specifically trying to learn what is input output. We're not doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1884" target="_blank">00:31:24.800</a></span> | <span class="t">SFT to just do reasoning step answer. We're doing multiple examples. So like they're packing in a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1890" target="_blank">00:31:30.560</a></span> | <span class="t">them. So like you could have seven examples of input chain of thought output, input chain of thought output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1898" target="_blank">00:31:38.000</a></span> | <span class="t">And we're just trying to learn and mid training, you know, here's how we do chain of thought. It's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1902" target="_blank">00:31:42.800</a></span> | <span class="t">just good answer generation. Um, this is like an effective way to use mid training, uh, you know, effective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1910" target="_blank">00:31:50.960</a></span> | <span class="t">way to allow mid training to iteratively use as much chain of thought data as possible until the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1917" target="_blank">00:31:57.360</a></span> | <span class="t">starts to perform well on a validation set. Then we have, uh, distillation for SFT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1923" target="_blank">00:32:03.360</a></span> | <span class="t">Basically after it started to learn how to do this chain of thought, um, you know, we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1930" target="_blank">00:32:10.640</a></span> | <span class="t">fine tuning or just continual training in a non-packing way. And then that's where you teach the model where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1936" target="_blank">00:32:16.880</a></span> | <span class="t">to stop generating text. Okay. After that, uh, rollout preference learning, uh, this is where, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1944" target="_blank">00:32:24.480</a></span> | <span class="t">the previous two stages is trained only on accepted generation. So they've done filtration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1950" target="_blank">00:32:30.080</a></span> | <span class="t">They've taken out all incorrect examples. They're only doing positive chain of thought. Here's question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1956" target="_blank">00:32:36.800</a></span> | <span class="t">Here's chain of thought. Here's answer packet, unpack it. You now know how to think, you now know where to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1962" target="_blank">00:32:42.000</a></span> | <span class="t">stop, but now they want to use rejected rollouts to enhance performance. Basically, um, they, this is how they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1970" target="_blank">00:32:50.000</a></span> | <span class="t">they like ensure that you have, uh, diversity, you have enough thinking, you have, you know, conciseness.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1978" target="_blank">00:32:58.640</a></span> | <span class="t">So basically incorrect responses with minor nuances are compared to their correct answers and they provide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1986" target="_blank">00:33:06.400</a></span> | <span class="t">positive, effective candidates for constructing informative preference pairs. Uh, so you can do preferences of, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1993" target="_blank">00:33:13.040</a></span> | <span class="t">uh, here's the right, uh, thinking approach, but the answer was wrong. And then here's the correct way to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=1998" target="_blank">00:33:18.400</a></span> | <span class="t">do it. Uh, this preference data set is constructed by using correct, um, correct answers as preferred</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2004" target="_blank">00:33:24.640</a></span> | <span class="t">rollouts and incorrect as dispreferred rollout. So now, uh, you know, we have DPO, we're going to do DPO and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2011" target="_blank">00:33:31.280</a></span> | <span class="t">we have, here's chain of thought with correct answer. Here's chain of thought where you kind of messed up a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2015" target="_blank">00:33:35.680</a></span> | <span class="t">little bit. Let's, let's do that. Then we have, um, RL with verifiable reward. So now we've done some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2022" target="_blank">00:33:42.800</a></span> | <span class="t">alignment with DPO. We want it to, you know, we want to have preference towards these pair of examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2029" target="_blank">00:33:49.440</a></span> | <span class="t">but now we want, um, RL on the distilled and preference train model. So, um, in the following,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2036" target="_blank">00:33:56.880</a></span> | <span class="t">we describe RL algorithms that we've implemented. So PPO, PPO is a clip surrogate objective to limit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2044" target="_blank">00:34:04.320</a></span> | <span class="t">the policy update. So it stays close to previous policy. Clipping is doing this, dah, dah, dah, dah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2050" target="_blank">00:34:10.000</a></span> | <span class="t">It has stabilization. Basically this is where they want it to, um, you know, okay, let's see. We have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2058" target="_blank">00:34:18.400</a></span> | <span class="t">PPO and GRPO. We love our GRPO, um, comparing rewards in a batch with multiple responses. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2066" target="_blank">00:34:26.560</a></span> | <span class="t">for each question, we sample a set of responses under the old policy, compute their rewards,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2072" target="_blank">00:34:32.080</a></span> | <span class="t">average out what we want. There's a verifiable reward for the right one. Standard RL stuff at these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2076" target="_blank">00:34:36.960</a></span> | <span class="t">days. Um, what else base, uh, high variance in response lens. So, uh, our pilot study applying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2084" target="_blank">00:34:44.080</a></span> | <span class="t">GRPO to train base model, we observed three issues that affected stability and effectiveness of, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2089" target="_blank">00:34:49.520</a></span> | <span class="t">of model training, high variance in response lens. So although the base model after mid training is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2096" target="_blank">00:34:56.080</a></span> | <span class="t">already able to generate chain of thought responses, we observed substantial variability and response</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2101" target="_blank">00:35:01.520</a></span> | <span class="t">lens within the same GRPO sampling group. So, uh, when you generate multiple outputs for the same example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2109" target="_blank">00:35:09.600</a></span> | <span class="t">uh, there's a lot of variability and how long that is. So for some stuff, positively reward responses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2116" target="_blank">00:35:16.320</a></span> | <span class="t">range from 12,000 to 20,000 tokens, which is, you know, pretty large, uh, optimizing the model for standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2122" target="_blank">00:35:22.880</a></span> | <span class="t">GRPO. Um, it led to instability, right? Okay. Vanishing gradient. This is what you would expect. Um, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2133" target="_blank">00:35:33.680</a></span> | <span class="t">so as they did, um, a bunch of these, as they had so much diversity, so many different, uh, lengths,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2141" target="_blank">00:35:41.520</a></span> | <span class="t">you kind of had identical rewards. So, uh, vanishing gradient problem, zero variance in the returns. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2150" target="_blank">00:35:50.160</a></span> | <span class="t">the model is sensitive to intra-group length discrepancies requiring extended GRPO batch size to 128. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2158" target="_blank">00:35:58.320</a></span> | <span class="t">more batches in GRPO while it worked. Um, we hypothesized that these issues become more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2164" target="_blank">00:36:04.000</a></span> | <span class="t">prominent for small language models where RL stability is likely to be more fragile compared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2168" target="_blank">00:36:08.480</a></span> | <span class="t">to large models. Okay. Uh, moving on quick, since we're short on time, what else? Synthetic data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2176" target="_blank">00:36:16.160</a></span> | <span class="t">synthetic chain of thought data generation. So we can stock large-scale reasoning data set composed of LLM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2182" target="_blank">00:36:22.640</a></span> | <span class="t">generated synthetic, synthetic reasoning capabilities, uh, trajectories. Uh, they use a bunch of pre-made</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2190" target="_blank">00:36:30.080</a></span> | <span class="t">data sets. So basically all these are open data, open data sets and their sizes and whether they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2195" target="_blank">00:36:35.920</a></span> | <span class="t">reasoning or not. Um, for data sets that already had reasoning traces, we directly use their annotation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2203" target="_blank">00:36:43.360</a></span> | <span class="t">So basically, uh, bespoke labs, open R1 math from hugging face and open thoughts from open thoughts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2209" target="_blank">00:36:49.920</a></span> | <span class="t">That's roughly what is that like 350,000 samples. It has reasoning annotations. They use that, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2216" target="_blank">00:36:56.560</a></span> | <span class="t">for the other ones. So all these six or seven different data sets, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2221" target="_blank">00:37:01.360</a></span> | <span class="t">we retain only, sorry, for data sets lacking such trajectories, we retain only math questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2229" target="_blank">00:37:09.520</a></span> | <span class="t">and generate new chain of thought answers using R1, the big R1, 671B. For each question, we sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2236" target="_blank">00:37:16.000</a></span> | <span class="t">approximately eight rollouts. And, um, in total, we collect 10 million rollouts across 1.6 million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2244" target="_blank">00:37:24.880</a></span> | <span class="t">samples. So, uh, they use all these for the other ones. They use big R1. They only use math. They get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2251" target="_blank">00:37:31.280</a></span> | <span class="t">10, uh, eight rollouts per, now they have 10 million samples. All the previous, uh, training steps. So the mid-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2257" target="_blank">00:37:37.280</a></span> | <span class="t">and stuff that's used with this data set, this is not like a new training stage. This is just explaining</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2263" target="_blank">00:37:43.120</a></span> | <span class="t">the previous steps above. Okay. Um, this is kind of interesting as well. For math questions that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2270" target="_blank">00:37:50.320</a></span> | <span class="t">verifiable, we first apply math verification tools to address correctness. Uh, some auto-verification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2276" target="_blank">00:37:56.800</a></span> | <span class="t">fails for complex solutions. And then it says, we additionally employ 40 mini to re-verify rollouts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2283" target="_blank">00:38:03.280</a></span> | <span class="t">incorrectly flagged, initially flagged as incorrect. I thought this was interesting. Like, um, we're in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2289" target="_blank">00:38:09.760</a></span> | <span class="t">like mid 2025, we have O3, we have O1, we have 2.5 flash, we have Sonnet, we have all these big models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2297" target="_blank">00:38:17.360</a></span> | <span class="t">but let's verify our math with 40 mini. Like, let's think about that for a second. We have benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2305" target="_blank">00:38:25.360</a></span> | <span class="t">we have tables, we have everything. But for verifying if our math was flagged as incorrect properly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2311" target="_blank">00:38:31.920</a></span> | <span class="t">let's use 40 mini. Why do we use 40 mini? That's for Microsoft for them to, you know, not tell us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2320" target="_blank">00:38:40.640</a></span> | <span class="t">Uh, could they have used a bigger model? I think so. But anyway, um, they do that. Okay, experiments,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2328" target="_blank">00:38:48.400</a></span> | <span class="t">evaluations, um, you know, we evaluate our model on three, mathematical, uh, possibly they're obsessed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2336" target="_blank">00:38:56.960</a></span> | <span class="t">with token cost, 40 mini validation. I think 40 mini validation is just, you know, it's mini model. Let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2342" target="_blank">00:39:02.800</a></span> | <span class="t">compare it to mini. Um, 40 mini was compared to big, uh, five, four of the 14 B model. And based on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2351" target="_blank">00:39:11.200</a></span> | <span class="t">estimates, you know, people say active parameters of 40 mini are small. So that's fair for token costs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2358" target="_blank">00:39:18.480</a></span> | <span class="t">I mean, I don't know. These are not cheap models to train. You know, this is a 14 B model trained on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2366" target="_blank">00:39:26.640</a></span> | <span class="t">10 trillion tokens. Um, that's a lot of compute. That's in the millions of dollars of compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2372" target="_blank">00:39:32.400</a></span> | <span class="t">One thing I highlighted here that I might've skipped over was how cheap training five, four mini reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2378" target="_blank">00:39:38.320</a></span> | <span class="t">was. Um, like, I'm not going to say it's like deep seek are one cost $5 million, but, um, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2386" target="_blank">00:39:46.720</a></span> | <span class="t">there's obviously a lot of filtration, a lot of time, a lot of synthetic data generation, a lot of inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2392" target="_blank">00:39:52.400</a></span> | <span class="t">that goes into this, but they trained this on, I believe 32 H one hundreds for like two and a half days.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2400" target="_blank">00:40:00.480</a></span> | <span class="t">So like maybe 64 H one hundreds, but, uh, very few nodes were used, you know? So like, this is something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2408" target="_blank">00:40:08.240</a></span> | <span class="t">that someone could do themselves if they really wanted, if someone can actually pull up the five,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2414" target="_blank">00:40:14.240</a></span> | <span class="t">four mini reasoning model on hugging face, it explains the, um, GPUs used to link it, just share it in chat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2421" target="_blank">00:40:21.520</a></span> | <span class="t">And we'll go over it real quick. But, um, that was something I wanted to know, you know, um, training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2426" target="_blank">00:40:26.880</a></span> | <span class="t">this thing, the reasoning model outside of generating that data, which honestly, even in and of itself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2432" target="_blank">00:40:32.960</a></span> | <span class="t">they just used, um, a lot of deep seek or one, and they used open data sets. Like this thing didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2440" target="_blank">00:40:40.320</a></span> | <span class="t">cost that much to train two nodes of H one hundreds for two and a half days. Like that's on the scale of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2446" target="_blank">00:40:46.960</a></span> | <span class="t">tens to hundreds of thousands of dollars. So not that crazy, you know? Um, but yeah, uh, what else, uh, to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2456" target="_blank">00:40:56.240</a></span> | <span class="t">to show their results. Once again, you know, they're very cautious of overfitting on benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2462" target="_blank">00:41:02.080</a></span> | <span class="t">Uh, they, they do three runs and they, they report the averages and they're like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2466" target="_blank">00:41:06.800</a></span> | <span class="t">they have a whole section on how they need to redo on how we need to better evaluate reasoning models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2472" target="_blank">00:41:12.320</a></span> | <span class="t">Uh, they have a section on like reasoning models versus non-reasoning where, where these evals sit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2479" target="_blank">00:41:19.520</a></span> | <span class="t">uh, baselines and stuff. But yeah, they kind of show that, you know, the thing's pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2485" target="_blank">00:41:25.440</a></span> | <span class="t">Training strategies. This is very straightforward, right? So what do they do? Distillation, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2490" target="_blank">00:41:30.880</a></span> | <span class="t">distill, uh, sorry, in the distillation stages, what's the batch size learning rate, how many epochs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2496" target="_blank">00:41:36.960</a></span> | <span class="t">warmup ratio, sequence length, packing, not packing. Um, this is all just, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2502" target="_blank">00:41:42.400</a></span> | <span class="t">if you really care about that, go ahead and read it. We're running short on time, so I will not read it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2507" target="_blank">00:41:47.520</a></span> | <span class="t">for us. Um, on scores, here's kind of where they sit. So once again, like they show all of their stages,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2516" target="_blank">00:41:56.240</a></span> | <span class="t">right? So basic five, four mini sucked at these math and reasoning benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2522" target="_blank">00:42:02.320</a></span> | <span class="t">O1 mini, good. Distills, pretty good. The other people, not so good. Base llama, not good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2528" target="_blank">00:42:08.800</a></span> | <span class="t">Adding distillation mid-training, ooh, a lot of bonuses, a lot of pretty good stuff. Adding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2535" target="_blank">00:42:15.520</a></span> | <span class="t">distillation fine-tuning after, even better. Uh, adding rollout DPO, even better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2541" target="_blank">00:42:21.600</a></span> | <span class="t">RL GURPOL. Wow, we're good. It beats everything. Actually, it doesn't beat everything, but you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2547" target="_blank">00:42:27.280</a></span> | <span class="t">um, pretty good. Beats, uh, R1 Distill Quinn 7B and R1 Distill Llama 8B, which, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2556" target="_blank">00:42:36.320</a></span> | <span class="t">when DeepSeek came out, a lot of people for local inference were using, um, Distill Quinn 7B. Uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2563" target="_blank">00:42:43.840</a></span> | <span class="t">Tyler has linked the hugging face thing. Let's, let's check it out real quick. Um, context length, what model is this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2574" target="_blank">00:42:54.880</a></span> | <span class="t">5-4 mini reasoning. Okay. Model quality, H100, GPU times 128 H100s for two days of training. So, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2584" target="_blank">00:43:04.800</a></span> | <span class="t">not that much. Assuming $2 per hour for H100, 128 times 48 hours is $12,000. Um, math checks out,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2594" target="_blank">00:43:14.080</a></span> | <span class="t">but math doesn't really check out. Um, you can't assume $2 per H100 hour. Cause you know, you're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2600" target="_blank">00:43:20.000</a></span> | <span class="t">this on actual nodes of training, but yeah, you know, per hour on H100, you can say 12K. Now that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2606" target="_blank">00:43:26.800</a></span> | <span class="t">you're doing it on node level, maybe double it up, maybe triple it up. But point being, you know, tens of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2612" target="_blank">00:43:32.400</a></span> | <span class="t">thousands of dollars for this, hundreds of billions of tokens, not trillions of tokens. And this is stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2618" target="_blank">00:43:38.080</a></span> | <span class="t">that like low key could have been done earlier, but, um, yeah, they show it out stage by stage. Thank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2625" target="_blank">00:43:45.120</a></span> | <span class="t">Thank you, Tyler for link and, um, quick math. Um, they show out stage by stage performance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2632" target="_blank">00:43:52.960</a></span> | <span class="t">ablations, um, fun charts, safety. We need safety. Ours stay consistent. Others go down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2642" target="_blank">00:44:02.560</a></span> | <span class="t">What else? Conclusion. Okay. They love their line, uh, small models when trained with deliberate data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2649" target="_blank">00:44:09.440</a></span> | <span class="t">selection and training strategies can match or even exceed capabilities of larger models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2655" target="_blank">00:44:15.360</a></span> | <span class="t">They want to show this work as a blueprint for developing efficient, high performing models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2660" target="_blank">00:44:20.320</a></span> | <span class="t">under resource constraints. Now, one of the very interesting things is, you know, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2666" target="_blank">00:44:26.240</a></span> | <span class="t">some of the other work that's referenced here, like the distillation models, uh, distillation with SFT is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2672" target="_blank">00:44:32.240</a></span> | <span class="t">cool. Deep seek showed it really worked, right? Let me see if this chart actually compares to base</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2677" target="_blank">00:44:37.600</a></span> | <span class="t">Lama. I believe they have it in there at the bottom. So basically for let's change color real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2683" target="_blank">00:44:43.040</a></span> | <span class="t">quick for regular Lama 3.2. Oh, they did 3B. Goddamn. Nevermind. I was trying to compare Lama 8B to 8B.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2692" target="_blank">00:44:52.560</a></span> | <span class="t">Uh, but you know, okay, let's just say for five, four, which is better than 8B on reasoning data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2699" target="_blank">00:44:59.440</a></span> | <span class="t">We did really, really bad. Now, what deep seek showed is with basic SFT on reasoning data, um, you can get pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2708" target="_blank">00:45:08.960</a></span> | <span class="t">good performance. Uh, what they show is if you have a well thought out process to do this specifically for, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2718" target="_blank">00:45:18.560</a></span> | <span class="t">small models, you can do even better than what people were very amazed by in the past. So, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2726" target="_blank">00:45:26.480</a></span> | <span class="t">this thought out way to do this is really good. Um, what else, what else? Uh, so they basically have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2733" target="_blank">00:45:33.040</a></span> | <span class="t">this as a blueprint for small model thinking RL. Um, what was interesting was just, yeah, stuff doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2740" target="_blank">00:45:40.800</a></span> | <span class="t">directly transfer over, you know? So, um, S1, if someone correct me if I'm wrong, I think was done on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2748" target="_blank">00:45:48.160</a></span> | <span class="t">Quen 32B, right? Or one of the large ones where, you know, you take a thousand samples, you have small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2755" target="_blank">00:45:55.600</a></span> | <span class="t">model and now you have really good reasoning. They tried that exact recipe with their small model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2761" target="_blank">00:46:01.760</a></span> | <span class="t">They took five, four mini, they did S1 training and not only did it not improve as much, it actually got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2769" target="_blank">00:46:09.840</a></span> | <span class="t">worse. So, uh, you know, this stuff doesn't translate transfer over at face value for regular, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2777" target="_blank">00:46:17.520</a></span> | <span class="t">foundation model stuff. It does like in the regular five, four 14B, um, they did a lot of their experiments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2785" target="_blank">00:46:25.200</a></span> | <span class="t">on a 7B and then they, they did a lot of their pre-training data experiments on a 7B</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2792" target="_blank">00:46:32.080</a></span> | <span class="t">and then they transferred over to a 14B for actual train run. Where is this? It's somewhere in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2799" target="_blank">00:46:39.360</a></span> | <span class="t">Um, yeah, right here, right here. So we observe a high rank correlation between the performance of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2806" target="_blank">00:46:46.080</a></span> | <span class="t">7B and 14B models on different data mixtures. Given large enough distance between the two data mixtures,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2812" target="_blank">00:46:52.160</a></span> | <span class="t">uh, this allocated us to conduct experiments on 7B scale and transfer findings to 5-4, which is 14B.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2818" target="_blank">00:46:58.080</a></span> | <span class="t">Uh, the key difference between 32B and this one is mid-training? No, so this one is a 14B,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2825" target="_blank">00:47:05.120</a></span> | <span class="t">which also had mid-training. This is basically a mixture of a bunch of stuff, the small reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2830" target="_blank">00:47:10.480</a></span> | <span class="t">Um, there's a whole bunch of sets of this, but here, yeah, basically they have a whole bunch of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2836" target="_blank">00:47:16.880</a></span> | <span class="t">um, let's learn chain of thought, packed, unpacked to know where to stop, then let's do RL.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2842" target="_blank">00:47:22.560</a></span> | <span class="t">That's a better approach for mini reasoning model. Uh, we have questions and discussions, but this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2849" target="_blank">00:47:29.600</a></span> | <span class="t">not the only paper that dropped. I, in fact, was bamboozled an hour ago when I decided to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2854" target="_blank">00:47:34.880</a></span> | <span class="t">read these turns out there's like low key two and a half papers. So we needed to know 5-4 base to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2860" target="_blank">00:47:40.480</a></span> | <span class="t">what they did. Then there's 5-4 mini reasoning, which is their 3.8B. Then there's also just 5-4 reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2866" target="_blank">00:47:46.720</a></span> | <span class="t">5-4 reasoning is not one model. It's actually two models. Um, 5-4 reasoning is where they take the 14B model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2875" target="_blank">00:47:55.040</a></span> | <span class="t">they do, um, they make a reasoning model using O3 mini traces. Uh, and they have another one. They have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2883" target="_blank">00:48:03.120</a></span> | <span class="t">5-4 reasoning plus where they basically do the same thing as before, but now they add RL specifically. And,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2888" target="_blank">00:48:08.720</a></span> | <span class="t">uh, now they're comparing it to the 70B distills. And guess what? It does well. It outperforms the 70Bs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2896" target="_blank">00:48:16.800</a></span> | <span class="t">So same benchmarks, reasoning benchmarks. Um, we show that the benefit of carefully,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2902" target="_blank">00:48:22.080</a></span> | <span class="t">of careful data curation and SFT extends to reasoning models. This can be further amplified</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2907" target="_blank">00:48:27.760</a></span> | <span class="t">with RL. So similar to how there's like, uh, O3 mini, low, high, O1 pro, all that stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2914" target="_blank">00:48:34.640</a></span> | <span class="t">They can also do this. So they have, um, uh, 5-4 reasoning and 5-4 reasoning plus. Could this paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2920" target="_blank">00:48:40.880</a></span> | <span class="t">have basically just launched 5-4 reasoning plus and called it 5-4 reasoning? Yes. They didn't have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2927" target="_blank">00:48:47.440</a></span> | <span class="t">do two. This is very similar to how in the, uh, reasoning mini paper they have, oh, this is the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2935" target="_blank">00:48:55.200</a></span> | <span class="t">this is the big one. One sec. In this reasoning mini paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2941" target="_blank">00:49:01.280</a></span> | <span class="t">in the mini reasoning paper, they show every stage of training and how it performed. Right? Like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2947" target="_blank">00:49:07.360</a></span> | <span class="t">they could have also had 5-4 mini reasoning and then 5-4 mini reasoning plus and do their whole recipe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2955" target="_blank">00:49:15.520</a></span> | <span class="t">Like it's starting to do better as it is. But, um, in this one, they, I guess the point they're trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2961" target="_blank">00:49:21.200</a></span> | <span class="t">to make is that an additional RL stage takes you from 5-4 reasoning to 5-4 reasoning plus. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2970" target="_blank">00:49:30.400</a></span> | <span class="t">yeah. TLDR is, um, they're getting O1 mini O3 level performance, beating R1 70Bs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2977" target="_blank">00:49:37.040</a></span> | <span class="t">Uh, yeah. Okay. I'm going to try to go through this in three minutes. Sorry on bad use of time. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2984" target="_blank">00:49:44.960</a></span> | <span class="t">how they do this. So 14B model, it's 5-4. Uh, they have a 14B model, supervised, fine-tuned. So they do SFT. Then they have reasoning plus, which has a further</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=2999" target="_blank">00:49:59.520</a></span> | <span class="t">round of RL, uh, 1.4 million prompt of high quality answers containing long reasoning traces generated using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3007" target="_blank">00:50:07.040</a></span> | <span class="t">O3 mini. Prompts are filtered to cover a range of difficulty. They want it to be stuff that the regular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3013" target="_blank">00:50:13.200</a></span> | <span class="t">model can't answer. So if 5-4, is there any traction on these? Yeah. Uh, five models have decent traction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3019" target="_blank">00:50:19.680</a></span> | <span class="t">The reasoning one just came out. I don't know about traction on this. Um, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3024" target="_blank">00:50:24.480</a></span> | <span class="t">they basically want to filter out stuff that the regular, um, five model can solve. They only want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3032" target="_blank">00:50:32.960</a></span> | <span class="t">to do stuff that it can't solve. Um, my highlighting got weird. So the data set used in SFT includes stem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3039" target="_blank">00:50:39.120</a></span> | <span class="t">topics, coding, safety focused, uh, tasks. The reasoning plus model is trained using RL on a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3045" target="_blank">00:50:45.840</a></span> | <span class="t">small set of 6,000 high quality math posted, math focused problems with verifiable solutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3051" target="_blank">00:50:51.360</a></span> | <span class="t">Kind of interesting, right? They get so much performance gain from just 6,000 samples of RL.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3056" target="_blank">00:50:56.960</a></span> | <span class="t">Um, they talk into how RL is, um, RL is like, you know, it has high variance, but it also has high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3064" target="_blank">00:51:04.720</a></span> | <span class="t">impact if done correctly, but then it's just math. So, you know, live code bench went down a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3069" target="_blank">00:51:09.440</a></span> | <span class="t">bit. Uh, interesting thing to note. Okay. Basically it's a data, like the whole training pipeline,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3077" target="_blank">00:51:17.680</a></span> | <span class="t">it matches what they've done in previous five models or come models. Uh, they once again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3082" target="_blank">00:51:22.880</a></span> | <span class="t">want to show that good data curation, synthetic data, small models to be good. A small model performs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3089" target="_blank">00:51:29.600</a></span> | <span class="t">better than 01 mini 70 B models. They also outperform Claude's, uh, 3.72 thinking on all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3096" target="_blank">00:51:36.880</a></span> | <span class="t">taxes, um, except GPQA and calendar planning performance on this. Okay. Performance is cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3104" target="_blank">00:51:44.080</a></span> | <span class="t">Um, this was kind of an interesting one. Um, both of them present improvements over the base models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3111" target="_blank">00:51:51.600</a></span> | <span class="t">including math and specific, notably improvement of 50 percentage points here. Surprisingly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3117" target="_blank">00:51:57.520</a></span> | <span class="t">these models also improved by 30, 60 percentage points on, um, algorithmic and planning problems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3125" target="_blank">00:52:05.680</a></span> | <span class="t">like calendar planning, which demonstrate increased generalizability of reasoning skills to domains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3132" target="_blank">00:52:12.640</a></span> | <span class="t">that we did not target directly during SFT or RL. So, uh, on stuff they didn't target and didn't train,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3139" target="_blank">00:52:19.360</a></span> | <span class="t">this shit still generalizes. Uh, very cool. Very cool. Improvement on general benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3144" target="_blank">00:52:24.800</a></span> | <span class="t">Of course it improves. Here's numbers of hell thinking effort versus accuracy trade-off. This was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3150" target="_blank">00:52:30.480</a></span> | <span class="t">interesting. So the reasoning plus model that slapped some RL that does better, it takes approximately</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3156" target="_blank">00:52:36.480</a></span> | <span class="t">1.5 times more, more tokens than the other one. Uh, this difference is less pronounced on other reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3162" target="_blank">00:52:42.560</a></span> | <span class="t">domains. So, um, uses this on average. So some domains like coding, planning, spatial tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3170" target="_blank">00:52:50.880</a></span> | <span class="t">Uh, these are all avenues to improve RL. Okay. Keep going through quick five, four demonstrates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3177" target="_blank">00:52:57.840</a></span> | <span class="t">reasoning responses. They show some examples that the reasoning one did that the other one couldn't. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3183" target="_blank">00:53:03.600</a></span> | <span class="t">this is a word play riddle. This is a question, you know, I have coin tosses. What's the chance I see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3191" target="_blank">00:53:11.440</a></span> | <span class="t">exactly 1.2 heads five, four would give you, you know, an actual math calculation. The reasoning model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3197" target="_blank">00:53:17.840</a></span> | <span class="t">is like, you can't get exactly 0.2. So probability is zero. Um, pretty cool. Pretty cool. More stuff, planning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3205" target="_blank">00:53:25.840</a></span> | <span class="t">games. Crazy. It can do games, data stuff, uh, seed database. We specifically target seeds situated at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3215" target="_blank">00:53:35.040</a></span> | <span class="t">the edge of five four's current ability. Additionally, to maximize the focus of reasoning skills and data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3220" target="_blank">00:53:40.160</a></span> | <span class="t">set, we prioritize prompts that demand complex multi-step reasoning, as opposed to those, uh, testing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3226" target="_blank">00:53:46.880</a></span> | <span class="t">factual knowledge. So they want reasoning stuff. They want teachable things, synthetic seeds. Sorry,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3232" target="_blank">00:53:52.240</a></span> | <span class="t">I'm going quick. We're at like one minute left. So I'm going to go through this quick, quick, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3238" target="_blank">00:53:58.480</a></span> | <span class="t">five, four reasoning, basically SFT on five, four with specific tokens. They have reasoning tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3245" target="_blank">00:54:05.200</a></span> | <span class="t">They use two of those empty tokens that they have. They have think and, um, you know, think tags that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3250" target="_blank">00:54:10.720</a></span> | <span class="t">add in, uh, increased token length. So they, they extend the 32 K synthetically generate examples of long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3258" target="_blank">00:54:18.640</a></span> | <span class="t">chain of thought over this. Our SFT data set is 1.4 million prompt response pairs, um, totaling 8.3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3267" target="_blank">00:54:27.920</a></span> | <span class="t">billion unique token samples. So this many extended out over these domains. Here's training. Here's SFT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3274" target="_blank">00:54:34.800</a></span> | <span class="t">steps. Here's improvement. Uh, during exploration stage, we studied effects of various design choices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3281" target="_blank">00:54:41.760</a></span> | <span class="t">Here's that role of SFT seed hyperparameters, uh, role of system message. Of course, system message is useful. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3290" target="_blank">00:54:50.880</a></span> | <span class="t">um, basically to promote chain of thought, they tell the thing, uh, you're a system, you're a thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3298" target="_blank">00:54:58.400</a></span> | <span class="t">model, have your thinking and think tags, um, partially removing or replacing system messages was cool, but it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3305" target="_blank">00:55:05.760</a></span> | <span class="t">didn't work. Here's the exact thing. You're a large language model by Microsoft. Your role is an assistant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3311" target="_blank">00:55:11.920</a></span> | <span class="t">involved story, uh, exploring questions that, uh, please structure responses in two sections.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3318" target="_blank">00:55:18.240</a></span> | <span class="t">Thought solution using the performed method, think thought section and think then solution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3323" target="_blank">00:55:23.600</a></span> | <span class="t">second in thought detail, your reasoning steps. Each step should include analysis, summarize,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3328" target="_blank">00:55:28.720</a></span> | <span class="t">brainstorm, the solution section should be logical, accurate, concise. Um, now try it with the following</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3335" target="_blank">00:55:35.520</a></span> | <span class="t">guidelines. So that's our system message. It helped optimization base model. So they, they considered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3343" target="_blank">00:55:43.600</a></span> | <span class="t">using the base model before SFT, like we talked about. So the 14 B before that SFT, um, both of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3351" target="_blank">00:55:51.200</a></span> | <span class="t">worked pretty well, but the, you know, the one with SFT and instruction tuning did slightly better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3358" target="_blank">00:55:58.320</a></span> | <span class="t">So they use it. Um, we attribute this to addition of safety focused post training. Wow. Safety is all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3365" target="_blank">00:56:05.200</a></span> | <span class="t">you need. Um, scaling final model is trained on 16 B trillion, 16 B tokens in this. Okay. Uh, real,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3374" target="_blank">00:56:14.160</a></span> | <span class="t">real quick, the plus. So they did 6,000 samples of RL. We applied outcome-based RL to enhance reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3380" target="_blank">00:56:20.240</a></span> | <span class="t">capabilities. Um, um, um, they use, um, 72,000 math problems. Um, 72,000 math problems subset to 64 seeds of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3392" target="_blank">00:56:32.480</a></span> | <span class="t">that. We do small set of 6,400 problems. See, no coding reward function. They want it to, or is it basically, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3402" target="_blank">00:56:42.400</a></span> | <span class="t">incentivize correctness, penalize undesirable behavior, such as reputation and extensive length,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3408" target="_blank">00:56:48.960</a></span> | <span class="t">and encourage proper response formatting. Uh, we encourage the model to generate concise outputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3414" target="_blank">00:56:54.160</a></span> | <span class="t">when it's correct, provoke thinking to think more when it's incorrect. Here's how they do that with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3419" target="_blank">00:56:59.280</a></span> | <span class="t">GERPO, uh, repetition penalty, training details. Uh, oh, this was the one that was, um, bat size of 64 over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3428" target="_blank">00:57:08.960</a></span> | <span class="t">32 H100. So, sorry. The, um, the mini that we talked about was 128 H100s, but this, uh, reasoning plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3439" target="_blank">00:57:19.520</a></span> | <span class="t">was only 32 H100s, 64 batches for that much. It's like a couple hundred hours. They also do context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3446" target="_blank">00:57:26.720</a></span> | <span class="t">length extension here, but I think that's enough. I don't want to go too long over. They have evals.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3451" target="_blank">00:57:31.680</a></span> | <span class="t">Of course they have evals, but I want to, you know, even though we're over time, I want to give it two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3456" target="_blank">00:57:36.240</a></span> | <span class="t">minutes for questions. They have a whole main findings, takeaways, stuff like that. Um, I'm gonna go over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3462" target="_blank">00:57:42.480</a></span> | <span class="t">chat real quick, but if anyone wants to pop in share, please, um, you know, interrupt me now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3467" target="_blank">00:57:47.040</a></span> | <span class="t">Yeah. So they call this SFT instead of, uh, deep seeks use of distill. So distill has like a term</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3480" target="_blank">00:58:00.480</a></span> | <span class="t">of distillation loss, right? Where you kind of compare output logics and you kind of force what did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3485" target="_blank">00:58:05.680</a></span> | <span class="t">big model say? Let's, let's do actual distillation there. They, they do know how this is basically just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3491" target="_blank">00:58:11.520</a></span> | <span class="t">SFT on big model outputs. That's the beginning. What's the difference between five, four reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3496" target="_blank">00:58:16.480</a></span> | <span class="t">and reasoning mini? Oh, five, four reasoning is on their big 14 B model. So five, four 14 B, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3504" target="_blank">00:58:24.560</a></span> | <span class="t">gets trained to do reasoning. It's on par with O one mini O one and seven 70 B distills. The reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3512" target="_blank">00:58:32.240</a></span> | <span class="t">mini model is done on a three B. So reasoning mini, they, they do, um, post training on a 3.8 B and they show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3520" target="_blank">00:58:40.240</a></span> | <span class="t">that they can match distill seven B's and they show that, you know, if you take what distillation was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3527" target="_blank">00:58:47.760</a></span> | <span class="t">done to big models and you directly apply it to a small model, it doesn't work. So they try the S1 data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3533" target="_blank">00:58:53.280</a></span> | <span class="t">set on a small model. It does worse, but they have a blueprint for how to do this for small, small models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3541" target="_blank">00:59:01.200</a></span> | <span class="t">Is there anything interesting in the mini ablation section? Maybe which part they deem most important for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3548" target="_blank">00:59:08.560</a></span> | <span class="t">small models following their, their narrative is mid training or do they imply the combination is the key?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3554" target="_blank">00:59:14.000</a></span> | <span class="t">Um, let's see. Let's see. Let's see. Let's see. Uh, our distillation pipeline serves an effective</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3560" target="_blank">00:59:20.720</a></span> | <span class="t">approach to measure reasoning. I don't think there's much that's reasoning here, much that's super, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3569" target="_blank">00:59:29.520</a></span> | <span class="t">important. Basically they just have like a, you need to do some mid training. They, they pose some open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3577" target="_blank">00:59:37.040</a></span> | <span class="t">questions. Um, yeah, cool. Okay. Thank you everyone. Sorry for last minute, um, paper change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3586" target="_blank">00:59:46.160</a></span> | <span class="t">I low-key read this like an hour and a half ago, but hopefully it was useful. I'm sure some of this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3594" target="_blank">00:59:54.480</a></span> | <span class="t">wrong, but yeah. Uh, next week we should have, uh, Professor Tom who does, uh, by hand illustrations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3605" target="_blank">01:00:05.440</a></span> | <span class="t">talk about the differences in Lama 1, 2, 3, and 4 architecture. I'll share more in Discord. Um, he was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3612" target="_blank">01:00:12.320</a></span> | <span class="t">gonna just do Lama 4, but we pushed it a week so he has time to prep to do a better comparison between,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3618" target="_blank">01:00:18.080</a></span> | <span class="t">you know, what's actually changing between the series. So that should be next. We always need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3622" target="_blank">01:00:22.480</a></span> | <span class="t">volunteers. So if anyone wants to volunteer a paper, uh, let us know and we'll, we'll slot you in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3629" target="_blank">01:00:29.360</a></span> | <span class="t">Someone, so Flo says, I can't wait till GPT 5.4 drops and I can't tell if people are saying 5, 4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3638" target="_blank">01:00:38.960</a></span> | <span class="t">5, 4, like GPT 5.4 or 5, 4, uh, people will be saying GPT 5.4 because no one talks about the five</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3646" target="_blank">01:00:46.400</a></span> | <span class="t">models. These are cool, but really, really not many people talk about them. Uh, not many people use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3652" target="_blank">01:00:52.400</a></span> | <span class="t">them, but it's, it's always nice to have, you know, it's, it's open research. They, they do a lot of work,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3658" target="_blank">01:00:58.320</a></span> | <span class="t">but yeah, nobody, nobody really talks about these. The only people that talk about them are people that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3662" target="_blank">01:01:02.640</a></span> | <span class="t">kind of shit on them for, um, training on benchmarks. If I'm not mistaken, they made</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3670" target="_blank">01:01:10.080</a></span> | <span class="t">one of these multimodal and five, four or five, three with audio had the best transcription word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3680" target="_blank">01:01:20.000</a></span> | <span class="t">error rate. Someone fact checked me on this, but, um, I'll follow up somewhere. I'm pretty sure the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3687" target="_blank">01:01:27.040</a></span> | <span class="t">multilingual version of this had the best word error rate out of any model. Now that's not saying a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3692" target="_blank">01:01:32.240</a></span> | <span class="t">because speech and transcription models are small, like low latency efficient optimized. This is a fat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3698" target="_blank">01:01:38.320</a></span> | <span class="t">model, but yeah, uh, multimodal large models get good. You know, what can you say? Okay. I feel like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3708" target="_blank">01:01:48.000</a></span> | <span class="t">um, that's enough. Thanks guys. Okay, I would end meeting, but Suix is host, so he will end meeting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3733" target="_blank">01:02:13.280</a></span> | <span class="t">So, um, that's a good question. I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3739" target="_blank">01:02:19.360</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3743" target="_blank">01:02:23.520</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3745" target="_blank">01:02:25.440</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3747" target="_blank">01:02:27.360</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3749" target="_blank">01:02:29.520</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3753" target="_blank">01:02:33.520</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3755" target="_blank">01:02:35.520</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3760" target="_blank">01:02:40.000</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3762" target="_blank">01:02:42.480</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3763" target="_blank">01:02:43.600</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3767" target="_blank">01:02:47.800</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3771" target="_blank">01:02:51.800</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3773" target="_blank">01:02:53.920</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3775" target="_blank">01:02:55.840</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3777" target="_blank">01:02:57.840</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3779" target="_blank">01:02:59.840</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3781" target="_blank">01:03:01.840</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3785" target="_blank">01:03:05.840</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3787" target="_blank">01:03:07.840</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3790" target="_blank">01:03:10.560</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3792" target="_blank">01:03:12.320</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3794" target="_blank">01:03:14.240</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3796" target="_blank">01:03:16.160</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3798" target="_blank">01:03:18.080</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3800" target="_blank">01:03:20.000</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3801" target="_blank">01:03:21.840</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3804" target="_blank">01:03:24.080</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3806" target="_blank">01:03:26.080</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3808" target="_blank">01:03:28.320</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3812" target="_blank">01:03:32.480</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3814" target="_blank">01:03:34.480</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3816" target="_blank">01:03:36.880</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3818" target="_blank">01:03:38.640</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3820" target="_blank">01:03:40.640</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3822" target="_blank">01:03:42.640</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3824" target="_blank">01:03:44.640</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3826" target="_blank">01:03:46.640</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3839" target="_blank">01:03:59.200</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3843" target="_blank">01:04:03.200</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3845" target="_blank">01:04:05.200</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3847" target="_blank">01:04:07.440</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3851" target="_blank">01:04:11.600</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3855" target="_blank">01:04:15.600</a></span> | <span class="t">What are you going to ask you to answer your question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3856" target="_blank">01:04:16.800</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3859" target="_blank">01:04:19.440</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3862" target="_blank">01:04:22.400</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3865" target="_blank">01:04:25.840</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=RWS-EMVNwD8&t=3868" target="_blank">01:04:28.960</a></span> | <span class="t">I'm going to ask you to answer your question. I'm going to ask you to answer your question.</span></div></div></body></html>