<html><head><title>GUI-based Few Shot Classification Model Trainer | Demo</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>GUI-based Few Shot Classification Model Trainer | Demo</h2><a href="https://www.youtube.com/watch?v=pfwBut7E60Q"><img src="https://i.ytimg.com/vi/pfwBut7E60Q/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=74">1:14</a> Classification<br><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=169">2:49</a> Better Classifier Training<br><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=393">6:33</a> Classification as Vector Search<br><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=527">8:47</a> How Fine-tuning Works<br><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=650">10:50</a> Identifying Important Samples<br><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=759">12:39</a> CODE IMPLEMENTATION<br><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=793">13:13</a> Indexing<br><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1139">18:59</a> Fine-tuning the Classifier<br><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1657">27:37</a> Classifier Predictions<br><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1843">30:43</a> Closing Notes<br><br><div style="text-align: left;"><a href="./pfwBut7E60Q.html">Whisper Transcript</a> | <a href="./transcript_pfwBut7E60Q.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Today we're going to talk about a more effective way of training classification models. Nowadays</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=6" target="_blank">00:00:06.400</a></span> | <span class="t">pre-trained models dominate the field of machine learning. There are very few ML projects that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=13" target="_blank">00:00:13.040</a></span> | <span class="t">start with us actually training a model from scratch. Instead we usually start by looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=19" target="_blank">00:00:19.920</a></span> | <span class="t">for an off-the-shelf pre-trained model. Whether that pre-trained model is from an online platform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=26" target="_blank">00:00:26.960</a></span> | <span class="t">like PyTorch Hub or HuggingFace Hub or from our own internal already trained in-house models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=34" target="_blank">00:00:34.960</a></span> | <span class="t">The ecosystem of these pre-trained models whether external or internal has allowed us to push the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=42" target="_blank">00:00:42.480</a></span> | <span class="t">limits of what is possible in machine learning. This doesn't mean however that everything is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=48" target="_blank">00:00:48.320</a></span> | <span class="t">super easy and everything works all the time. There are always going to be some challenges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=54" target="_blank">00:00:54.640</a></span> | <span class="t">Fortunately we're able to tackle a lot of these problems that are actually shared across a huge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=60" target="_blank">00:01:00.960</a></span> | <span class="t">number of pre-trained models because they tend to have similar points of failure. One of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=67" target="_blank">00:01:07.120</a></span> | <span class="t">is the excessive compute and data needed to actually fine-tune one of these models. Now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=74" target="_blank">00:01:14.720</a></span> | <span class="t">focusing on classification a very typical scenario that we have is that we have some model some big</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=82" target="_blank">00:01:22.640</a></span> | <span class="t">model like BERT or T5 and what we want to do is fine-tune this model for classification. Now one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=90" target="_blank">00:01:30.400</a></span> | <span class="t">way we can do that is we add a simple linear layer onto the end of it and then we fine-tune that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=97" target="_blank">00:01:37.040</a></span> | <span class="t">linear layer. Now what I want us to focus on here is the model that comes before doesn't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=103" target="_blank">00:01:43.200</a></span> | <span class="t">matter. We only really care about this linear layer. We can actually fine-tune that for a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=108" target="_blank">00:01:48.400</a></span> | <span class="t">of different use cases without even touching the model weights of the big pre-trained model that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=114" target="_blank">00:01:54.160</a></span> | <span class="t">comes before it. It's a classification layer that is actually producing the final prediction and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=120" target="_blank">00:02:00.480</a></span> | <span class="t">because of this that classification layer can become the single point of failure in producing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=127" target="_blank">00:02:07.040</a></span> | <span class="t">our predictions. So we focus on fine-tuning that classification layer and a common approach to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=132" target="_blank">00:02:12.800</a></span> | <span class="t">doing this might look a little bit like this. First we have to collect a data set that focuses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=139" target="_blank">00:02:19.120</a></span> | <span class="t">on enabling this model to adapt to a new domain or just dealing with data drift. Then we have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=147" target="_blank">00:02:27.280</a></span> | <span class="t">slog through the data set and if it's going to work well it's usually a large data set labeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=153" target="_blank">00:02:33.440</a></span> | <span class="t">the records as per their classification and then once all records have been labeled we have to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=160" target="_blank">00:02:40.000</a></span> | <span class="t">fine-tune the classifier. This approach works but it really is not efficient. There's actually a much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=167" target="_blank">00:02:47.760</a></span> | <span class="t">better way of doing this. What we need to do is focus our fine-tuning efforts on the essential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=174" target="_blank">00:02:54.720</a></span> | <span class="t">records that actually matter. Otherwise we're wasting time, our own time, and compute on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=181" target="_blank">00:03:01.680</a></span> | <span class="t">annotating and fine-tuning across the entire data set when the vast majority of the data in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=188" target="_blank">00:03:08.160</a></span> | <span class="t">data set probably doesn't matter. So now the question is how do we decide which samples are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=195" target="_blank">00:03:15.440</a></span> | <span class="t">actually essential and which are not? Well that's where we can use vector search. We can use vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=201" target="_blank">00:03:21.520</a></span> | <span class="t">search to search through our data set before we even annotate everything and identify the records</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=209" target="_blank">00:03:29.680</a></span> | <span class="t">that are going to make the biggest impact on our model performance. Meaning we save our time and a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=215" target="_blank">00:03:35.600</a></span> | <span class="t">lot of compute by just skipping the non-essential records. Some of you may be thinking what does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=221" target="_blank">00:03:41.440</a></span> | <span class="t">vector search have to do with training a classification model? Well it's actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=227" target="_blank">00:03:47.440</a></span> | <span class="t">super important. Many state-of-the-art models are available as pre-trained models. Those are models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=235" target="_blank">00:03:55.280</a></span> | <span class="t">like BERT, T5, EpsilonNet, OpenAI's CLIP. These models use an insane number of parameters and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=246" target="_blank">00:04:06.400</a></span> | <span class="t">perform a lot of complex operations. Yet when applied to classification we're actually relying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=254" target="_blank">00:04:14.880</a></span> | <span class="t">on the final layers that are added onto the end of these huge models. So we might have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=262" target="_blank">00:04:22.640</a></span> | <span class="t">some simple feed forward layers or just a linear classification layer. Now the reason for this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=269" target="_blank">00:04:29.440</a></span> | <span class="t">that these models they're not being trained to produce class predictions. We can think of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=278" target="_blank">00:04:38.000</a></span> | <span class="t">as actually being trained to make vector embeddings. So we pre-train these big models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=284" target="_blank">00:04:44.400</a></span> | <span class="t">and the idea is that after pre-training these models will produce these very information rich</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=293" target="_blank">00:04:53.440</a></span> | <span class="t">vector embeddings. And then what we do for different tasks is that we add an extra task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=301" target="_blank">00:05:01.760</a></span> | <span class="t">specific head onto the end of that. And that task specific head is taking that vector embedding or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=308" target="_blank">00:05:08.160</a></span> | <span class="t">vector embeddings from the model and running them through a smaller network. Like I said it can just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=315" target="_blank">00:05:15.920</a></span> | <span class="t">be a linear layer and outputting something else. Outputting those predictions. So the power of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=322" target="_blank">00:05:22.560</a></span> | <span class="t">these models is not that they can do classification, question answering, all these different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=329" target="_blank">00:05:29.840</a></span> | <span class="t">things. The power of these models is that they produce these very information rich vectors that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=335" target="_blank">00:05:35.600</a></span> | <span class="t">then smaller simpler models can use to do these tasks of question answering, classification and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=342" target="_blank">00:05:42.320</a></span> | <span class="t">on. These vectors that these models are producing are simply full of useful information that have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=350" target="_blank">00:05:50.160</a></span> | <span class="t">been encoded into a vector space. Okay so you can imagine in this vector space, imagine a 2D space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=357" target="_blank">00:05:57.280</a></span> | <span class="t">we have vector A here, vector B here. Those two are very close to each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=364" target="_blank">00:06:04.240</a></span> | <span class="t">and therefore they share some sort of similar meaning. Whereas vector C over here is very far</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=370" target="_blank">00:06:10.640</a></span> | <span class="t">away from from A and B. Therefore it shares less meaning with A and B. Now the result of this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=378" target="_blank">00:06:18.640</a></span> | <span class="t">that these models are essentially creating a map of information. Using this map they're able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=384" target="_blank">00:06:24.560</a></span> | <span class="t">consume data like images or tech and output these useful information rich representations with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=392" target="_blank">00:06:32.080</a></span> | <span class="t">vectors. So our task in classification now is not to consume data and try and abstract</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=402" target="_blank">00:06:42.880</a></span> | <span class="t">different meaning from that and classify that abstraction of meaning. In reality the abstraction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=410" target="_blank">00:06:50.080</a></span> | <span class="t">of meaning is already handled by the big models. Instead our task with classification is to teach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=417" target="_blank">00:06:57.920</a></span> | <span class="t">a smaller model to identify the different regions within that map or the vector space. Now a typical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=426" target="_blank">00:07:06.000</a></span> | <span class="t">architecture that we will see for classification is a pre-trained model followed by a linear layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=432" target="_blank">00:07:12.400</a></span> | <span class="t">Now we can think of the internal weights of this classifier as actually being a vector within the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=440" target="_blank">00:07:20.640</a></span> | <span class="t">wider vector space. And Ido Liberty, the founder and CEO of Pinecone and past head of Amazon AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=449" target="_blank">00:07:29.760</a></span> | <span class="t">Labs explained to me that we can actually use this fact and couple it with vector search in order to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=457" target="_blank">00:07:37.360</a></span> | <span class="t">massively optimize the learning process for our classifier. So what we need to do is really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=465" target="_blank">00:07:45.600</a></span> | <span class="t">imagine this problem as being within a vector space or a map. We have the internal model weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=471" target="_blank">00:07:51.600</a></span> | <span class="t">w and we have all these vectors that as of yet are unannotated and we haven't fine-tuned on them yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=478" target="_blank">00:07:58.560</a></span> | <span class="t">We want to calculate the dot products between w and x. If they share a positive direction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=484" target="_blank">00:08:04.560</a></span> | <span class="t">they will have a positive value and they produce a negative score if the directions are opposite.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=491" target="_blank">00:08:11.440</a></span> | <span class="t">Now there is just one problem with dot product here. It considers both direction and magnitude</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=496" target="_blank">00:08:16.720</a></span> | <span class="t">which means that if we have a vector x that has a larger magnitude than another vector x even if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=504" target="_blank">00:08:24.800</a></span> | <span class="t">that other vector is actually the same vector as our model weights or very similar it can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=511" target="_blank">00:08:31.520</a></span> | <span class="t">output a larger dot product score. So what we need to do is normalize all these vectors that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=517" target="_blank">00:08:37.440</a></span> | <span class="t">we're comparing. This simply removes the magnitude problem and makes it that we are comparing only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=524" target="_blank">00:08:44.960</a></span> | <span class="t">the direction of the vectors. Now when we fine-tune the linear classifier with these vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=532" target="_blank">00:08:52.800</a></span> | <span class="t">it's going to learn to align itself with vectors that we label as positives and move away from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=540" target="_blank">00:09:00.800</a></span> | <span class="t">vectors we label as negatives. Now this will work really well but there are still some improvements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=548" target="_blank">00:09:08.160</a></span> | <span class="t">that we could add in here. First imagine we return only irrelevant samples in a single training batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=556" target="_blank">00:09:16.240</a></span> | <span class="t">They will all be marked as negative one and the classifier knows to move away from these values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=561" target="_blank">00:09:21.280</a></span> | <span class="t">but it doesn't know in which direction. Okay and especially in a high dimensional space there are a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=565" target="_blank">00:09:25.840</a></span> | <span class="t">lot of directions that the classifier can move in. So this is problematic because it means that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=571" target="_blank">00:09:31.360</a></span> | <span class="t">classifier is just going to be moving at random away from those negative vectors. Another problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=577" target="_blank">00:09:37.280</a></span> | <span class="t">is that many labels be more or less relevant. So imagine we had the query dogs in the snow and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=585" target="_blank">00:09:45.280</a></span> | <span class="t">we had two pieces of text a dog and a dog in the snow. Both of those are relevant depending on what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=593" target="_blank">00:09:53.840</a></span> | <span class="t">you're looking at but a dog in the snow is more relevant. These two pieces of text are not equally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=601" target="_blank">00:10:01.600</a></span> | <span class="t">relevant but at the moment all we can do is label one as negative one as positive or both as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=609" target="_blank">00:10:09.520</a></span> | <span class="t">positives and that's not really ideal because it doesn't really show the full picture of both of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=616" target="_blank">00:10:16.720</a></span> | <span class="t">these are relevant just one is more than the other. So what we need is almost like a gradient of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=621" target="_blank">00:10:21.920</a></span> | <span class="t">relevance. We need a continuous range from negative e.g. minus one to positive e.g. plus one. Even if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=629" target="_blank">00:10:29.680</a></span> | <span class="t">we just have a range from negative one to negative 0.8 there's still a direction that the model can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=637" target="_blank">00:10:37.440</a></span> | <span class="t">figure out from that range of values. So all of this together just allows our linear classifier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=644" target="_blank">00:10:44.720</a></span> | <span class="t">to learn where to place itself within the vector space produced by the model layers preceding it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=650" target="_blank">00:10:50.560</a></span> | <span class="t">Now that describes a fine-tuning process but we can't do this across our entire data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=657" target="_blank">00:10:57.520</a></span> | <span class="t">If we have like a big data set which we probably do it would take too much time annotating everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=663" target="_blank">00:11:03.920</a></span> | <span class="t">and it would be a waste of our time as well. To do this efficiently what we must do is capitalize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=670" target="_blank">00:11:10.480</a></span> | <span class="t">on the idea of identifying relevant versus irrelevant vectors within a proximity of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=677" target="_blank">00:11:17.040</a></span> | <span class="t">model's learned weights w. So we focus our efforts on the specific area that is actually going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=684" target="_blank">00:11:24.560</a></span> | <span class="t">helpful. For an already trained classifier those are going to be the false positives and false</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=689" target="_blank">00:11:29.360</a></span> | <span class="t">negatives predicted by the classifier. However we also usually don't have a list of false negatives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=697" target="_blank">00:11:37.680</a></span> | <span class="t">and false positives but we do know that the solvable errors will be present near the classifier's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=704" target="_blank">00:11:44.560</a></span> | <span class="t">decision boundary e.g. the line that separates the positive predictions from negative predictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=710" target="_blank">00:11:50.640</a></span> | <span class="t">So we use vector search in order to actually pull in the high proximity samples that are most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=718" target="_blank">00:11:58.000</a></span> | <span class="t">similar to the model weights w. We then label those vectors and use them for training our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=725" target="_blank">00:12:05.200</a></span> | <span class="t">The model optimizes those internal weights w. We extract them again and then we perform a vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=731" target="_blank">00:12:11.200</a></span> | <span class="t">search with them again and we just keep repeating this process over and over again until the linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=736" target="_blank">00:12:16.960</a></span> | <span class="t">classifier has been optimized and is producing the correct predictions that we need. So by focusing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=744" target="_blank">00:12:24.000</a></span> | <span class="t">annotation and training on these essential samples we avoid wasting time and compute on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=750" target="_blank">00:12:30.560</a></span> | <span class="t">those vectors that don't make as much of a difference. Okay so all of that is the general</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=756" target="_blank">00:12:36.640</a></span> | <span class="t">idea behind this process. Now let's have a look at how we can put all that together and fine-tune a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=763" target="_blank">00:12:43.200</a></span> | <span class="t">classifier with vector search. Now we will see that there are two parts to the training process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=769" target="_blank">00:12:49.200</a></span> | <span class="t">First we need to index our data so that is where we embed everything using the preceding model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=775" target="_blank">00:12:55.680</a></span> | <span class="t">layers e.g. BERT or CLIP or so on and then store those in a vector database and then step two is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=781" target="_blank">00:13:01.920</a></span> | <span class="t">that we actually fine-tune the classifier. So query with model weights w, return the most similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=788" target="_blank">00:13:08.240</a></span> | <span class="t">records, annotate them and then use them to fine-tune the classifier. So let's go ahead and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=794" target="_blank">00:13:14.800</a></span> | <span class="t">start with indexing. Given a data set of images or other formats we first need to process everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=802" target="_blank">00:13:22.240</a></span> | <span class="t">through the big model preceding our linear classifier to create the vector embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=808" target="_blank">00:13:28.320</a></span> | <span class="t">For our example we're going to use a model called CLIP that's capable of understanding both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=812" target="_blank">00:13:32.960</a></span> | <span class="t">text and images and it has been trained on text image pairs and has learned how to encode them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=821" target="_blank">00:13:41.120</a></span> | <span class="t">into as similar vector space as possible. So what we're going to need to start with before indexing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=827" target="_blank">00:13:47.200</a></span> | <span class="t">anything is initializing a data set that we can then encode with CLIP. So we're going to use this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=834" target="_blank">00:13:54.160</a></span> | <span class="t">data set from Hugging Face datasets hub. So we can pip install everything we're going to need for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=840" target="_blank">00:14:00.000</a></span> | <span class="t">this here. We're taking the train split and that contains 9.5 000 images. Some of those are radios</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=848" target="_blank">00:14:08.560</a></span> | <span class="t">like you can see here, there's pictures of dogs, trucks and a few other things. And we can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=856" target="_blank">00:14:16.000</a></span> | <span class="t">an array of one of those images right there. Now it's not so important for what we're doing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=862" target="_blank">00:14:22.640</a></span> | <span class="t">What we do want to do is actually initialize both the model and the pre-processing steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=870" target="_blank">00:14:30.160</a></span> | <span class="t">before the data is being fed into the model. So we do that here. So initialize the model CLIP</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=875" target="_blank">00:14:35.600</a></span> | <span class="t">using this model ID here. Okay so this is one version the CLIP model. And then the pre-processor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=883" target="_blank">00:14:43.920</a></span> | <span class="t">will just take images and process them so that CLIP can read them. Okay as all we're doing here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=890" target="_blank">00:14:50.160</a></span> | <span class="t">we're going to go through all of these steps. This is the pre-processing and from that we get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=897" target="_blank">00:14:57.040</a></span> | <span class="t">the image features. Those image features are a vector representation of the image. So in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=905" target="_blank">00:15:05.680</a></span> | <span class="t">case we've done the Sony radio image and that gives us a 512 dimensional vector embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=915" target="_blank">00:15:15.840</a></span> | <span class="t">The embeddings from CLIP are not normalized. Okay so we're going to be using dot product both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=922" target="_blank">00:15:22.000</a></span> | <span class="t">within the model and during our vector search. So we should really normalize these. So we do that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=928" target="_blank">00:15:28.720</a></span> | <span class="t">here and then we see that these values are all between the values of negative one to two plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=936" target="_blank">00:15:36.880</a></span> | <span class="t">one. Now that's how we embed or create a vector embedding for a single item. But we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=943" target="_blank">00:15:43.680</a></span> | <span class="t">want to do for loads of items and we're also going to want to index them and store them inside a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=948" target="_blank">00:15:48.160</a></span> | <span class="t">vector database. So we're going to use Pinecone for this. You may need to sign up for a free API</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=954" target="_blank">00:15:54.560</a></span> | <span class="t">key if you haven't already. And what we do is initialize our connection to Pinecone here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=960" target="_blank">00:16:00.720</a></span> | <span class="t">You just put your API key here. It's all free. And then we create an index. Now it's important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=967" target="_blank">00:16:07.040</a></span> | <span class="t">that we have a few things here. So the index name that doesn't actually matter. Okay you can put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=971" target="_blank">00:16:11.600</a></span> | <span class="t">whatever you want. But what you do need is the correct dimensionality. So that is the 512 that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=978" target="_blank">00:16:18.800</a></span> | <span class="t">you saw up here. That is what we put in here. We do need to make sure that we're using dot product</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=986" target="_blank">00:16:26.080</a></span> | <span class="t">similarity. And we're going to also include this metadata config. So basically when once we see an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=993" target="_blank">00:16:33.120</a></span> | <span class="t">image and we label it we're going to tell Pinecone we don't want to return that image again. Okay so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=998" target="_blank">00:16:38.560</a></span> | <span class="t">that we can go through and not over optimize on like 10 images. And then we connect to the index</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1006" target="_blank">00:16:46.880</a></span> | <span class="t">after we have created it there. Now to add that single feature embedding that we just created,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1015" target="_blank">00:16:55.120</a></span> | <span class="t">that image embedding we just created, we would do this. Okay so we have an ID and then we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1020" target="_blank">00:17:00.800</a></span> | <span class="t">convert the embedding into a list format and we just upsert. So with that we have one embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1029" target="_blank">00:17:09.680</a></span> | <span class="t">within our vector index. But of course we want to have our full data set in there so we can search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1036" target="_blank">00:17:16.000</a></span> | <span class="t">for it and add data and so on. So to do that we're going to use this loop here. I'm not going to go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1043" target="_blank">00:17:23.440</a></span> | <span class="t">through because it's literally what we've just done. Okay the only thing I think I've added here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1047" target="_blank">00:17:27.760</a></span> | <span class="t">is this which is checking for grayscale versus RGB images. But the rest of this is exactly the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1056" target="_blank">00:17:36.880</a></span> | <span class="t">Okay we're just going we're doing it all at a larger scale and we're also adding in the metadata</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1062" target="_blank">00:17:42.240</a></span> | <span class="t">here. Okay so that's seen. We're setting it to zero for all the images to start with and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1066" target="_blank">00:17:46.640</a></span> | <span class="t">we'll set it to one once we've seen a set of images. Mark them as you know positive or negative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1073" target="_blank">00:17:53.600</a></span> | <span class="t">and train with them. Then we set that seen value to one so we don't return it again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1078" target="_blank">00:17:58.240</a></span> | <span class="t">Okay so we have this this radio. Let's have a quick look at how we might query.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1085" target="_blank">00:18:05.840</a></span> | <span class="t">So we create our query vector xq here which is just we're doing the same thing again as what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1093" target="_blank">00:18:13.840</a></span> | <span class="t">we did before. Normalizing it and then we query with it. Okay and that returns these items here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1100" target="_blank">00:18:20.880</a></span> | <span class="t">from Pinecone. Let's have a look at what they look like. So the first one is obviously that radio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1105" target="_blank">00:18:25.600</a></span> | <span class="t">That radio is the most similar of the vector. So naturally that would be the first thing that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1110" target="_blank">00:18:30.000</a></span> | <span class="t">gets returned. Okay next one we have a car radio. We have another Sony radio. I think it's even the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1116" target="_blank">00:18:36.640</a></span> | <span class="t">same model. And another Sony radio which is also the same model. It seems so. And then just another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1125" target="_blank">00:18:45.600</a></span> | <span class="t">radio. It's very similar. So clearly those embeddings are pretty good from Clip. But now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1131" target="_blank">00:18:51.360</a></span> | <span class="t">what we want to do is fine-tune a linear classifier on top of that to classify these different images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1138" target="_blank">00:18:58.960</a></span> | <span class="t">Okay so to do that I'm going to start from scratch. So this is a new notebook. You can find all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1144" target="_blank">00:19:04.400</a></span> | <span class="t">links to these notebooks by the way in the video description or if you're watching this on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1149" target="_blank">00:19:09.360</a></span> | <span class="t">article down at the bottom of the article in the resources section. So here initialize the connection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1155" target="_blank">00:19:15.600</a></span> | <span class="t">to the index again. You don't need to do this if you just ran through the last bit of code. You can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1159" target="_blank">00:19:19.600</a></span> | <span class="t">just keep that as it is and maintain your connection to the index. Again we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1166" target="_blank">00:19:26.240</a></span> | <span class="t">load the data set and again you don't need to do that if you've already done it. Initialize the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1173" target="_blank">00:19:33.760</a></span> | <span class="t">model. So Clip and the processor. So there's one thing different here and you can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1180" target="_blank">00:19:40.480</a></span> | <span class="t">tokenize using the other preprocessor. But for the sake of covering everything I'm just showing you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1186" target="_blank">00:19:46.080</a></span> | <span class="t">how to do with the Clip tokenizer fast here as well. So here we're initializing just the tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1192" target="_blank">00:19:52.160</a></span> | <span class="t">side of the Clip preprocessor. And we're setting up this prompt. So dogs in the snow. We tokenize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1198" target="_blank">00:19:58.960</a></span> | <span class="t">them to get a set of token IDs and then we use the model get text features method in order to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1206" target="_blank">00:20:06.720</a></span> | <span class="t">get a vector embedding of that text, of that dogs in the snow prompt. Okay and we come down here. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1215" target="_blank">00:20:15.280</a></span> | <span class="t">create the query vector from that and we're just going to retrieve top 10 most similar records and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1222" target="_blank">00:20:22.400</a></span> | <span class="t">store them in in XC. So it's just like the contents. So there's a few things in XC here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1229" target="_blank">00:20:29.360</a></span> | <span class="t">We actually don't need all of this. So what we want is the IDs and then the values as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1237" target="_blank">00:20:37.920</a></span> | <span class="t">So first we get the IDs then we get the values. Okay and we can see why it's returned. So dogs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1245" target="_blank">00:20:45.840</a></span> | <span class="t">in the snow. Right this one is not a dog in the snow but you can kind of see where it's a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1249" target="_blank">00:20:49.360</a></span> | <span class="t">confused. The sand in the background does look kind of white and snowy. But then the rest of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1255" target="_blank">00:20:55.760</a></span> | <span class="t">these yeah they're dogs in the snow other than this one. So it's returning the right thing here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1263" target="_blank">00:21:03.440</a></span> | <span class="t">but let's say we don't want dogs in the snow. Okay let's say we want to adjust this to something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1269" target="_blank">00:21:09.680</a></span> | <span class="t">slightly different. Like for example dogs at dog shows and we'll go through this. So this code here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1277" target="_blank">00:21:17.040</a></span> | <span class="t">not really that important. All this is is a little interface that I built within Jupiter so that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1283" target="_blank">00:21:23.760</a></span> | <span class="t">can sort of quickly go through and label the images. So I would run this. Okay I'm not going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1293" target="_blank">00:21:33.040</a></span> | <span class="t">to run it again. So I'll just run this here and basically what it's going to do is it's going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1298" target="_blank">00:21:38.240</a></span> | <span class="t">show an image. So example this one here it's going to show the image and say okay what you rate this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1303" target="_blank">00:21:43.360</a></span> | <span class="t">from negative one to one. And you just go through you say you know what you what you would rate it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1309" target="_blank">00:21:49.280</a></span> | <span class="t">And then that will give you or that will basically produce a dictionary that maps these ideas to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1316" target="_blank">00:21:56.240</a></span> | <span class="t">score that you gave it. So you can see all the scores I gave last time I ran this. And you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1322" target="_blank">00:22:02.640</a></span> | <span class="t">just double check that the ideas and scores are aligned here. Yes they are so you don't need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1327" target="_blank">00:22:07.840</a></span> | <span class="t">worry so much about that. And all we do is we need to get the values which are going to be the inputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1334" target="_blank">00:22:14.320</a></span> | <span class="t">of training data for the linear classifier. And then we get the labels okay so the scores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1338" target="_blank">00:22:18.880</a></span> | <span class="t">So we go through and what we're going to do here is just initialize a PyTorch linear classifier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1347" target="_blank">00:22:27.200</a></span> | <span class="t">layer. And what I do first is so in most cases I imagine that we're going to have a linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1355" target="_blank">00:22:35.520</a></span> | <span class="t">classifier already trained. So I'm just emulating that here. So I'm getting the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1360" target="_blank">00:22:40.080</a></span> | <span class="t">query vector reshaping that and I'm inserting it as the first set of model weights w. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1369" target="_blank">00:22:49.520</a></span> | <span class="t">what we're going to do is we're going to initialize the loss. We're going to use bc with logics loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1374" target="_blank">00:22:54.320</a></span> | <span class="t">And we're going to use stochastic gradient descent. Now this learning rate you'll probably find that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1379" target="_blank">00:22:59.680</a></span> | <span class="t">quite high. And it is high. We're just kind of putting it high so that we can see a lot of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1386" target="_blank">00:23:06.160</a></span> | <span class="t">quick movement through the data set. If you're actually implementing something like this you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1389" target="_blank">00:23:09.920</a></span> | <span class="t">might want to use a lower learning rate. So with that we just create this function fit here which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1399" target="_blank">00:23:19.120</a></span> | <span class="t">is basically just a training loop. And we can set the number of iterations per training loop. Again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1404" target="_blank">00:23:24.320</a></span> | <span class="t">you might want to lower this if you don't want to move so quickly through the vector space and keep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1408" target="_blank">00:23:28.320</a></span> | <span class="t">things a bit more stable. And yeah we'll just call fit. From that the model weight will actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1417" target="_blank">00:23:37.440</a></span> | <span class="t">be optimized and it will change. And that will represent the next query that we're going to pass</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1424" target="_blank">00:23:44.320</a></span> | <span class="t">into our vector database. So we convert into a flat list so that Pinecone can we can query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1430" target="_blank">00:23:50.560</a></span> | <span class="t">in Pinecone with it. And so that we're not returning the same records that we just went</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1437" target="_blank">00:23:57.280</a></span> | <span class="t">through. We update the metadata attached to each one of the vectors that we've just seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1442" target="_blank">00:24:02.800</a></span> | <span class="t">to be set to equal scene equals one. And then the reason we do that is because we add a filter now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1453" target="_blank">00:24:13.200</a></span> | <span class="t">to the next query where we set scene equal to zero. Okay and then we return the next set of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1459" target="_blank">00:24:19.120</a></span> | <span class="t">queries and we can see here we have some other images. And basically what I'm doing here is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1463" target="_blank">00:24:23.680</a></span> | <span class="t">trying to optimize for dogs and fields. And then from dogs and fields we're going to try and move</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1469" target="_blank">00:24:29.440</a></span> | <span class="t">to dogs at dog shows. Okay and we'll just go through this bit quickly now. So this is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1475" target="_blank">00:24:35.120</a></span> | <span class="t">tuning. So I'm putting all the what we just did into a single function just to make things a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1479" target="_blank">00:24:39.760</a></span> | <span class="t">simpler. And yeah we'll go through. Okay so you can see how things are kind of changing more towards</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1486" target="_blank">00:24:46.160</a></span> | <span class="t">dogs and fields here. And then here it goes a bit crazy because basically I'm putting a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1493" target="_blank">00:24:53.040</a></span> | <span class="t">dogs as negative. So now it's thinking or maybe I don't actually want to see any dogs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1497" target="_blank">00:24:57.120</a></span> | <span class="t">And that makes it push away from that. But obviously I don't want that to happen. So I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1504" target="_blank">00:25:04.480</a></span> | <span class="t">set everything negative here other than I think this image that has a field or maybe this image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1510" target="_blank">00:25:10.000</a></span> | <span class="t">that has a field and also this image of a dog. And then we go towards dogs again. Focus on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1517" target="_blank">00:25:17.360</a></span> | <span class="t">Push towards dogs. And then here you can see the first in the middle right here. There's the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1523" target="_blank">00:25:23.360</a></span> | <span class="t">image of dogs at a dog show. Actually I think this is also a dog show here. So that would technically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1528" target="_blank">00:25:28.240</a></span> | <span class="t">be the first one. But this is what I'm looking for. More like this sort of image. So we focus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1534" target="_blank">00:25:34.160</a></span> | <span class="t">on that and we push for that a little more. Next one we see oh okay we have a few more dog shows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1539" target="_blank">00:25:39.600</a></span> | <span class="t">here. So here and here. And we keep pushing for that. And you can see as we go through each step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1545" target="_blank">00:25:45.920</a></span> | <span class="t">there's more of these dogs in dog shows. Because that's what I'm labeling as being more relevant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1551" target="_blank">00:25:51.280</a></span> | <span class="t">Okay and now we're really getting into that sort of space. Keep going and now we're at the point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1559" target="_blank">00:25:59.520</a></span> | <span class="t">where pretty much everything when we're returning is a dog show. So this is the final bit. So now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1566" target="_blank">00:26:06.560</a></span> | <span class="t">that we've done that we want to set all of the scene labels in our vector database back to not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1573" target="_blank">00:26:13.760</a></span> | <span class="t">scene. Okay because we want to search again. We can either search without the filter just to check</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1579" target="_blank">00:26:19.600</a></span> | <span class="t">that it has trained the classifier. Or we just reset all of those scene labels. If you wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1587" target="_blank">00:26:27.280</a></span> | <span class="t">to go through data again and focus more on those that's where you might want to reset all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1592" target="_blank">00:26:32.720</a></span> | <span class="t">labels back to zero. So to do that all I'm going to do is go through a while loop. And we keep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1599" target="_blank">00:26:39.440</a></span> | <span class="t">going through and we search for everything where the filter is equal to scene. We get those ideas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1604" target="_blank">00:26:44.880</a></span> | <span class="t">and then we mark them as not seen. Once we don't return any more items that means we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1610" target="_blank">00:26:50.480</a></span> | <span class="t">set everything to not seen because we're not returning anything else. We've seen equal to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1616" target="_blank">00:26:56.240</a></span> | <span class="t">true. So at that point we break. So after that if we search again we get a completely unfiltered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1625" target="_blank">00:27:05.120</a></span> | <span class="t">view of the search results. And here we go. Okay so we can see loads of dogs at dog shows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1633" target="_blank">00:27:13.680</a></span> | <span class="t">Now there's one here that isn't a dog at a dog show. I think the rest of them are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1638" target="_blank">00:27:18.960</a></span> | <span class="t">So with that we've actually fine-tuned our classifier. So now that we've finished</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1645" target="_blank">00:27:25.520</a></span> | <span class="t">optimizing those model weights we can save them to file. Okay so we do this. And with that let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1651" target="_blank">00:27:31.920</a></span> | <span class="t">have a look at how the model performs on actually classifying images. So again move to another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1659" target="_blank">00:27:39.600</a></span> | <span class="t">notebook. This is number 02 classifier tests. And here we're just going to test the classifier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1666" target="_blank">00:27:46.960</a></span> | <span class="t">on a set of images that it has not seen before. So again we initialize everything. Again if you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1675" target="_blank">00:27:55.040</a></span> | <span class="t">already loaded everything and you're in the same notebook you don't need to do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1680" target="_blank">00:28:00.240</a></span> | <span class="t">So we need to load the validation split from ImageNet. So you can see here this before was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1688" target="_blank">00:28:08.480</a></span> | <span class="t">train. Now it's validation. So you will need to rerun this bit. And we have about 4,000 images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1695" target="_blank">00:28:15.040</a></span> | <span class="t">there. Now let's start by checking the predictions for some specific images. Okay so this one is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1703" target="_blank">00:28:23.120</a></span> | <span class="t">dog at a dog show. So we pre-process that. We get the image features from clip. And then we make a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1712" target="_blank">00:28:32.240</a></span> | <span class="t">prediction. So the classifier and then we put in those the vector output by clip. And we can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1719" target="_blank">00:28:39.040</a></span> | <span class="t">there's a pretty positive value there. So positive remember is a true value. Negative is a not true</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1728" target="_blank">00:28:48.880</a></span> | <span class="t">prediction. Okay cool. So that's correct. It's predicted that that is a dog show.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1735" target="_blank">00:28:55.840</a></span> | <span class="t">Now let's have a look at this. Okay this is not a dog show. So we should see that it will predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1740" target="_blank">00:29:00.640</a></span> | <span class="t">a negative value. So let's go through and yeah we get a pretty negative value there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1745" target="_blank">00:29:05.840</a></span> | <span class="t">So we can label the full data set and we'll find a cutoff point between what is viewed as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1751" target="_blank">00:29:11.760</a></span> | <span class="t">relevant and what is irrelevant. So basically anything that's positive. So we do that here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1757" target="_blank">00:29:17.520</a></span> | <span class="t">I'm not going to go through it but it's essentially the same thing as what we just said. I'm just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1761" target="_blank">00:29:21.520</a></span> | <span class="t">making a list of these predictions. Okay I'm going to add a column to the ImageNet data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1768" target="_blank">00:29:28.640</a></span> | <span class="t">called predictions. So we now have these three. And let's have a look. So filter out any results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1775" target="_blank">00:29:35.440</a></span> | <span class="t">where the prediction is not positive. So we get 23 results. And let's have a look at what those are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1782" target="_blank">00:29:42.560</a></span> | <span class="t">So those 23 positive results. All of them, I think almost all of them, are dog shows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1792" target="_blank">00:29:52.560</a></span> | <span class="t">And we keep going through. So each one of these as we go through has been scored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1798" target="_blank">00:29:58.320</a></span> | <span class="t">less highly but all these are still scored very highly. Okay I'm going through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1808" target="_blank">00:30:08.080</a></span> | <span class="t">And then we go through and then yeah we get this, I don't know, emoji chainsaw thing which is right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1815" target="_blank">00:30:15.680</a></span> | <span class="t">at the bottom of these positively labeled things. It's kind of random. I don't know why it's in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1820" target="_blank">00:30:20.960</a></span> | <span class="t">there. Yeah so other than literally these two images right at the end, everything else is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1828" target="_blank">00:30:28.000</a></span> | <span class="t">true positive. So it's predicted everything correctly other than these two. This one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1833" target="_blank">00:30:33.600</a></span> | <span class="t">no idea why. This one, I kind of understand, you know, dogs in a field. So generally speaking these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1840" target="_blank">00:30:40.320</a></span> | <span class="t">are I think very good results. And we got these from fine-tuning our classifier on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1846" target="_blank">00:30:46.960</a></span> | <span class="t">not really that many images. I think there was maybe 50 images there. So really good results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1853" target="_blank">00:30:53.920</a></span> | <span class="t">on a very small amount of data. And that's because we're using vector search to focus our annotation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1860" target="_blank">00:31:00.720</a></span> | <span class="t">and training on what is the most important part of the data set. Now doing this for an image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1867" target="_blank">00:31:07.360</a></span> | <span class="t">classifier is just one example. We can do this with text. We can do this in recommendation engines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1873" target="_blank">00:31:13.600</a></span> | <span class="t">or even anomaly detection. There's like a huge number of use cases with this. Basically whenever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1879" target="_blank">00:31:19.920</a></span> | <span class="t">you need to classify something and you want to do that efficiently, you can use this as long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1886" target="_blank">00:31:26.640</a></span> | <span class="t">as you're using something like a linear classifier. So for me, I think that was a really cool method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1895" target="_blank">00:31:35.920</a></span> | <span class="t">for efficiently training classification models. Thank you a lot to Edo for actually sharing with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1902" target="_blank">00:31:42.480</a></span> | <span class="t">this and explaining and walking me through everything. I think, yeah, this is a really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1908" target="_blank">00:31:48.080</a></span> | <span class="t">useful method and I hope you will find it useful as well. So thank you very much for watching and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1914" target="_blank">00:31:54.960</a></span> | <span class="t">I will see you again in the next one. Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=pfwBut7E60Q&t=1921" target="_blank">00:32:01.200</a></span> | <span class="t">[MUSIC]</span></div></div></body></html>