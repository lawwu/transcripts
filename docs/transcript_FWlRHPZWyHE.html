<html><head><title>[Workshop] AI Pipelines and Agents in Pure TypeScript with Mastra.ai — Nick Nisi, Zack Proser</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>[Workshop] AI Pipelines and Agents in Pure TypeScript with Mastra.ai — Nick Nisi, Zack Proser</h2><a href="https://www.youtube.com/watch?v=FWlRHPZWyHE" target="_blank"><img src="https://i.ytimg.com/vi_webp/FWlRHPZWyHE/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Transcript</h3><div class='max-width'><p>. All right, should we get you on? Let's do it. All right, welcome everyone. This is AI Pipelines and Agents in Pure TypeScript with Master.ai. Today's mission, do you want to talk? Sure. So what we're going to do today is we're going to build an AI-powered Neme generator. And yes, that's humorous, sounds like a toy, but the patterns that we're going to use here, both with the master framework and in terms of using TypeScript to build a production agent, are the same patterns that we've used and that you can use to deploy to production with AI applications.</p><p>So the rough format that we're going to follow here is we're going to do a 20-minute intros and concept just to make sure everyone's level set. Feel free to stop us, ask questions, and then the majority of the time this workshop is going to be spent coding together collaboratively.</p><p>And then we'll have about 10 minutes wrap up in QA and a little fun demo for you at the end to get some swag. Yep. And yeah, so this is a true workshop format. We'll be building together. If you have questions, reach out to us. We're happy to help.</p><p>And just so you can get kind of a head start on it, if you go to workshop AI agents with Mastra, the Slack channel, in the AI engineer Slack, all the materials are in the pinned link there. And we can have discussions there as well continuing. So we work at a company called WorkOS.</p><p>We build developer tools and make enterprise features happy. No, enterprise developers happy with easy-to-use tools like SSO and SAML, directory sync, audit logs, fine-grained auth. And we're really getting into AI and securing your AI. Things like securing your MCP, attaching identity to those agents so that they can act on your behalf and know who you are.</p><p>Yep. Another good way to think about WorkOS is if you, like, let's say Nick and I built the ultimate app this weekend, we're ready to go sell it, and then the first time we demo it to somebody, they say, "Can you give us a single sign-on for our 2,000 users over here in a different path over here?" So then we would go and buy WorkOS or use WorkOS, drop the JavaScript in, and we would have those features ready to sell.</p><p>So my name's Nick Nisi. I'm developer experience at WorkOS. I'm also a host on the dysfunctional.fm podcast, formerly JS Party. Any JS Party listeners ever? Thanks. I also do conference MCing and speaking. I'll be at SquiggleConf MCing that, which is a DevTools-focused conference in Boston later this year. I'm also a TypeScript enthusiast, as you'll see.</p><p>I'm a Vim user, by the way, and I'm Nick Nisi everywhere. Hey, everyone. I'm Zach. Really excited to be here with you all. I've mostly been an application and infrastructure developer my career, but for the last two years, I've really been focused on Gen AI, MLOps, and then retrieval augmented generation pipelines, or RAG pipelines.</p><p>So, yeah, really excited to be here building with you today. Okay, so what is Mastra? I'll just embarrass two folks quickly and just point out that we have some core Mastra team members here, so this is very exciting, so you'll not only be able to get some assistance from us hopefully, but also from the Mastra core team for any questions that go over our heads.</p><p>Mastra is a framework, and so it's a framework for building production AI applications in an agentic manner. And these are the components that we're all going to learn and get hands-on with today in this workshop and understand very well by the time we leave here. So we're going to build workflows, which think of them as composable and typed pipelines, which are very exciting.</p><p>Tools that you can optionally use and give to agents. Agents are like the interfaces that we're chatting with. They're the ideal interface for humans to work with. And then the Mastra framework does some incredibly cool things out of the box with batteries included that we'll see. So not just a playground that makes it super easy to debug everything, but built-in persistence, memory, observability, and even evaluation so that you can determine over time how healthy your pipeline is, which is critical for successfully deploying an AI application in production.</p><p>And we'll be focusing on pieces of this. We don't have time in two hours to go over everything, but there's a lot of really cool tools in there. So we're going to be focusing on some core concepts for the example app that we're building, and we'll kind of understand some of those building blocks as we get going.</p><p>Cool. So let's start off. What are workflows? Workflows are composable pipelines. So the way that I think about this is I map it in my head mentally to if a coworker says, I just keep on having to go scrape the site and download people that look interesting and look up their info and then take an image and then write an email.</p><p>You know, that sounds to me like a workflow, right? It's a pipeline of discrete steps. You want them to happen in a certain order. And as we can begin to see with this example code on the screen, you can even have control over transforms that happen in the middle of your pipeline.</p><p>So the idea is you're chaining multiple steps together to get some work done. You can pass data between steps. And then very importantly, because as we know, LLMs are incredibly powerful, but they're non deterministic. And so how do we rely on their output? How do we coerce their output into something that we can actually build against dependably?</p><p>That's where we're going to validate inputs with Zod. But we're also going to learn how Zod can even coerce at runtime and then handle errors gracefully. But really, the key idea here is that workflows are a discrete set of steps to get a task done. And the API is very similar.</p><p>It reminds me of like RxJS, like very similar. You're starting with one thing and then doing something and then mapping to something else and then doing something else and running through all of that to give a little bit of determinism to the call of all of these tools as they're being called by your agent or some other tool.</p><p>And speaking of tools, tools are just functions that agents can call. They can give you things like file system access, API calls, database queries, custom business logic. If you've used MCP, MCP calls tools. And so that's like a really cool thing. It gives the LLM the ability to act on your behalf or to read in data that it doesn't just inherently know from its latent space so that it can do more things and be more powerful for you.</p><p>Yep. Absolutely. I'll just say that, you know, we think of like AI systems getting better the more data and context they have access to. And one of the things that MCP is really excellent at doing is giving, granting context to Claude to OpenAI that it normally wouldn't have and that's not in its training data.</p><p>And one note for today's workshop, we did build everything using tools, but then we switched as we brought in an agent to call and we had the agent call a workflow rather than the tools independently. So we wanted to touch on them there. There's something powerful that you should look into on your own and figure out your use case for them.</p><p>But we didn't really use them in the final version of this workshop. And then finally, what are agents? So we've all probably seen and used the chatbot type demos, but, you know, the way that we're thinking of agents these days is really that they're kind of an ideal human interface.</p><p>So if I set up a workflow that's a deterministic set of steps to get some discrete task done for my colleague, let's say that my colleague is in a hurry or they're busy or they're doing this while they're on the phone or they're not technical, then a chatbot can be an ideal interface for that human colleague.</p><p>Right. Because they can describe their problem or their issue, what they need with natural language, and then the system can be smart enough to actually do what they want. And so this is the core. This is a very core kind of pattern that we're seeing in a lot of AI applications.</p><p>And so we're actually going to build this and understand this here. So after we create our workflow, we'll create an agent and we'll grant that agent the ability to call the workflow. Yeah. And agents was something that when I first heard of them, like, like in a lot of these things, like the naming adds more confusion than is really necessary.</p><p>And we spent like an hour on the phone call and I kept being like, but what is an agent? What how is that anything beyond just a simple prompt? And it's really like the marriage of that prompt plus the workflows or the tools that it can use to do things in a specialized way.</p><p>Yeah. The other way I think of it is like if, you know, in the past, maybe five, ten years ago, you might have written deterministic, more deterministic software with agents. You're expecting that the system overall can kind of interpolate or can understand, introspect, what's the state and then make a decision in like a graph sense of we need to actually go here.</p><p>So that's the other piece that you'll hear when you're discussing agentic systems. Yeah. Cool. Another thing, MCP or model context protocol, I told you I'd show you how to spell it. This is a way for you to it's an open standard for a way to bring like universal plugins or these tools to AI agents so that they can be called.</p><p>This was really developed by Anthropic and you can use it easily in Cloud Code, among other places like Cursor, Windsurf, I think. And even OpenAI is is adopting these tools as well. So it's really a nice, easy to use API that these tools know how to use and call.</p><p>And to also make it concrete, like you say you work on the DX team at WorkWest, you have constantly crushing a ton of bugs and all various SDKs and you use Cloud Desktop, right? And so like what changed the day that you enabled the GitHub MCP server for Cloud Desktop?</p><p>Yeah. The GitHub MCP server was the one that really like made me understand what MCP is doing because I was like, why do I want to do this? How is this different than just like having access to GitHub and, you know, calling all of that? But it's really an easy way for me to have a conversation with Cloud and for it to bring in the context that it needs based on the tool, the issue that I'm working on.</p><p>For example, if you have an issue on a GitHub repo, I can just say, hey, can you check out that issue and tell me, you know, here's my example app. Tell me how I might reproduce this and it can like go figure that out, pull in the comments, understand what's going on, link out to other repos or other examples from there.</p><p>And then look at my example repo and tell me how to to make that change. Speaking of MCPs, we built a fun little demo called mcp.shop. You can go there now and you can use MCP to order a shirt. And it's the only way that you can order this shirt.</p><p>And for the low, low price of zero dollars, you can hit an MCP shirt. The point is, you just have to use the MCP. So it's just a fun demo to to try out MCP, play with it. You can add it. It has instructions for adding it into Cloud or into any of the MCP servers.</p><p>Sorry, MCP clients that support it. Yep. Also mentioned that recently. So MCP is, you know, one of the protocols that's really hot right now in the space and a lot of folks are taking notice. We recently had an MCP night and it was at the Exploratorium. It was a ton of fun.</p><p>We blew out like the capacity of the event and we had people like wind up around the block, which we didn't expect. We're almost certainly going to do something like this again soon. So be sure to follow us if you want to hear about it. And yeah, we'd love to see you there in the future.</p><p>Yeah. All right. What we're going to actually build today, though, to to get into it is the AI meme generator. So we're going to if you imagine the input to this is going to be you venting any random frustration, workplace frustration, frustration with your colleagues or boss into the pipeline and the workflow will process your frustration.</p><p>It's going to find the best base meme that already exists that would be ideal or might be humorous. It's going to think about how to actually edit and create new captions and it's going to publish a new meme at a stable URL that's available for you. And again, I just mentioned like this is a toy.</p><p>We've got two hours. It's a quick demonstration. But the patterns that you see here and the master framework are definitely, you know, AI production ready. We'll use open AI just for the understanding and image flip is the only other API involved here, which you can get free username and keys for that.</p><p>And there's information in the workshop MD file for that. Yeah. And it's a really fun demo just to kind of showcase some of the tooling that you can do with master and how easy it is to really get all of this going, but also not just to get your tools going, but to test them very easily along the way.</p><p>So we can start with just like a single step and a workflow and test that without an agent. And then we can test the agent independent too. And we can do all of this and not have to have like a full picture to understand how it's going to work, but kind of iterate along the way.</p><p>And the tooling that master provides is just super nice. That's why we love it. We're also huge fans of TypeScript, which makes it awesome as well. And so, yeah, it's just nice and easy. Yep, absolutely. Okay, this is the way that we've structured this workshop. And so, you know, we weren't really sure the level that everyone's coming in at.</p><p>And some folks are experts and some folks are just getting started. So it's self-paced learning and you can go at the speed that you want to go. If you want to go and fly all the way through it, you're free to do that. Workshop MD in that repo is the entirety of this course.</p><p>And so you can kind of follow along that way. And then we also created Git branch checkpoints for you. So in case, for example, you're to fall behind and you get stuck on something and then we get to phase two, you can also skip to phase two and stay, stay with everybody just by, you know, checking out the right branch.</p><p>If you get stuck at any point, we're here to help. So please raise your hand. We'll come around. Come to the mics. Yeah, if you have questions that other folks likely have or might benefit from in the future, please be sure to come up to a mic and we'll make sure that your question is heard.</p><p>And then, you know, the other way we're thinking about this workshop is, again, anyone can read online. We can all talk online anytime, but we're actually here in person today. So, you know, please shout out questions and raise your hand and ask us things you want to know. We feel that understanding is more important than completing stuff here and it's OK to explore.</p><p>So, yeah, we're all very new to this. This is all very new stuff, very new tools. And it's very cool. It's also changing every single week. So it's it's fun, like snapshot in time to play with this stuff. And if you have, like I said, you don't have to finish it.</p><p>We do have the whole workshop.md that you can follow step by step all the way through to the end. And then those those branches to to get us there. And if you just look at the main branch, that's the completed version. But it's more fun to build along the way.</p><p>So with that, let's get started. Like I said, everything is in the Workshop AI Agents with Mastra channel on Slack. So if you're in there, you can go grab it. There's also the get clone command right there to grab the repo. And we can get started with that. Just go to the step slash step zero branch.</p><p>That has everything kind of as a baseline to start from. And then you can npm install from there and get going with the workshop workshop.md. So here, I think we can stop and you can get started. We'll give you some time to build. But if there are any questions, please come to the mics and we'd be happy to continue the chat.</p><p>I had a quick question. Yeah. So the before you showed the example of an agent and workflows, that's kind of different from what I'm used to seeing in these like agent SDKs where they usually have tools. So is the workflow kind of like a tool that I can use or?</p><p>Yeah. I mean, I feel like correct me if I'm wrong here. I feel to some degree that like the create tool and create step APIs are somewhat similar. And in my mind, at least right now, it's sort of like an organizational preference. Like if I have a simple use case and there might be three different tools and I want the agent to decide the right time to call those tools, I might create three separate mostly essentially functions, name them tools, grant them to the agent, and then start chatting with the agent and ask for things and let the LLM determine at runtime which which one's to call.</p><p>The difference is with the workflow is I'm saying, I always want you to proceed in exactly this sequence with these steps and these transforms. And then you can also in master at least you can optionally grant an agent the ability to call that workflow. So, and then also in my conversation recently with Sam, that's kind of like, you know, these are, these are various tools that you can build up and kind of assemble into the exact paradigm that you need.</p><p>Can you do both tools and workflows? I think so. Yeah, you can grant because it's basically like you, you're passing like this giant, JSON object to the agent saying you can call these tools and you can call these workflows. And then the tricky part is like if you give something 100 tools and then ask an LLM like you've got 100 tools, let's like go to Disneyland.</p><p>I don't know exactly what we're going to get out of that. But that's where like the determinism of a pipeline can be of a workflow can be beneficial. Cool. Thanks. Thanks. Great question. Anybody want to raise any, there's no shame here. Anyone having difficulties getting started? Need help with that?</p><p>Permission issues, should we expect that? No, not at all. What's the permission issue? I'll come by. Yeah, the repo should be fully public. So should be able to clone that. Well, Zach's doing that. I will also bring up the master docs because these are, oops, these are wonderful. They're really easy to go through.</p><p>But also as Zach and I were working, we discovered something that was actually really awesome. And that is the MCP docs server. Once I installed this, things like my tooling got a lot smarter and knew how to work with Mastra. And it made things way easier. So if you get stuck or if not, and you want to see MCP in action, I would recommend installing the master tools for your IDE.</p><p>I installed it into cloud code and into cloud desktop and played with it in both. And it immediately knew a lot more. Okay. Gotcha. Can you clone with HTTPS? Can you clone not over SSH? Try the HTTPS. So if you go back to the repo, look at the GitHub repo, like in the browser.</p><p>It should have a different option. Oh, you followed that. So go to github.com, work OS, and then the master agent. You have to change that from a colon to a forward slash thing. So like grab this whole, grab everything after the ampersand. And then go up here, and so make, but you got to change the URL.</p><p>So do HTTPS. And then GitHub, oh, yep. And then choose. Yep, hit that. Sorry, I'm having trouble. Oh, you know what? Oh, that's why. Okay, thank you. It's searched for that URL instead of going directly. So make that, if you can, and then change this whole into a forward slash and then get rid of that final git.</p><p>That should go. Okay, now this is up there. And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option.</p><p>And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option.</p><p>And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option.</p><p>And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option.</p><p>And then the local should have that option. And then the local should have that option. And then the local should have that option. And then the local should have that option. Anybody else? Any setup issues or everyone good? I'll post the HTTPS clone command in the Slack as well.</p><p>Yeah. In case anyone's having trouble with SSH clone, because you're on a work laptop, we'll put in the instructions for HTTPS too. All right, we're going to do about five more minutes set up. Feel free to raise your hand if you have an issue. Yeah. Oh, sorry. What's that?</p><p>Oh, the Wi-Fi is bad. Yeah, the comment is the Wi-Fi is bad. I wish we could do something about that. Sorry. Classic conference Wi-Fi. For cloud code, yeah. If you open cloud code, you just need that. You still need that like JSON object, I think. I mean, that's what I use for my fancy clients.</p><p>But it should off. Yeah. Yeah. That's what I use for my fancy. That's what I use for my fancy. Yeah. That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy.</p><p>Yeah. That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy.</p><p>That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy. That's what I use for my fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy. That's what I use for fancy.</p><p>That's what I use for fancy. I'm going to do about two and a half minutes until we move on. Anybody have any issues? Everyone good? Slow internet still? Okay. Yeah. We can get more time. We got... We'll do a queuing system. Everyone turn off their Wi-Fi. One person download packages.</p><p>Move to the right... Put it on a flash drive and then we'll pass it around. Yeah. That would be a sneaker net. The repo is 77% closed. Nice. Yeah, let's get in there. This guy clones. We will... We can get more time. Excellent. These are great numbers. The end goal of this first step is really just seeing the playground.</p><p>And we'll kind of show that here in a minute. there's not going to be any tools or agents or anything yet and we'll build those out. But it's just seeing kind of what Mastra gives you right out of the box so that you have everything you need to get going fast.</p><p>Absolutely. Let's go to 60. Question. Yes. Why Mastra compared to all the other frameworks? I can tell you why I'm excited about it. Tell me about it. The first couple of things I heard were pure type script, right? And I'm already kind of bought into that with... I like compilers finding my errors before I ship them.</p><p>Then there's the Vercel AI SDK that I think that the team wisely chose to build upon. My experience with that has been excellent. It's kind of mind bending to kind of wrap my head around. But the idea that I can multiplex between any LLM provider, I mean, when GPT 4.0 came out, I shipped a two character change in a PR and my entire pipeline got way smarter.</p><p>And that was the day where I was like, "This is good. This is good." So the first couple of things I heard were pure type script. Right? And I'm already kind of bought into that with... I like compilers finding my errors before I ship them. Then there's the Vercel AI SDK that I think that the team wisely chose to build upon.</p><p>My experience with that has been excellent. It's kind of mind bending to kind of wrap my head around. And that was the day where I was like, "This SDK." Then I found out that the master came out and it was like Vercel AI SDK and pure type script. And I can tell you that there's a ton of stuff that they put in there, like including evals that are just baked in.</p><p>So that's one of OpenAI's own recommendations about the right way to deploy agents at enterprise and that scale is to start with a evaluated pipeline. And I can tell you from working in like vector database companies too, that that's... People that are actually in prod are using evaluations to determine the health of their pipeline and the health of each individual generation.</p><p>And master has those baked in. So it's like import and then like also evaluate my pipeline. And then finally, so it's like because of that, then it's on the Vercel AI SDK. Then being able to deploy it quickly and then have a good experience that way too. And honestly, what we'll see just in the local playground was pretty great.</p><p>Yeah. Very complete in my, in my experience. Like every, everything has issues, but that was the experience I've had with it so far. And real quick, I think that for me, like TypeScript moving fast with that. I still don't have to figure out what PIP is. So it's prolonging that.</p><p>It's prolonging that. Yeah. But also like we had, how many of you have had these like come to AI moments within your company? Like a big, Hey, we're going to have everybody, we're going to work hard with AI. We're all doing AI now, whether you like it or not.</p><p>That Shopify post came out and then like, we had it. My wife's company's had it. Like everybody that I've talked to, like, Oh, we're going to have this meeting where we're going to do everything with AI. We're going to see how way I can, you know, solve every problem in every domain.</p><p>And, um, after we had that, we did like an open workshop thing. And we had, uh, like immediately we showed Mastra and then we had like 10 people just like start going off with 10 individual demos. And it was just faster. And cause they successfully built the exact workflow that they were looking to build.</p><p>And so then for me, the reason I'm the most excited about that piece of it is that I think it's an ideal platform for internal tooling. I think all of us are rapidly experimenting with this stuff. And you know, do I want to live in a world where Nick's writing bespoke LLM scripts while I'm sleeping and I wake up and I'm like, what is this spaghetti mess?</p><p>And he has to do the same with my, you know, crap or are we all using that? Or are we all using like, you know, an actual framework that we can agree on certain primitives. It makes us faster use. There's, there's even forethought I can see, um, in the way it's been organized so that once you've defined an agent, a different project can reach in and call that agent via code or API.</p><p>So, um, all those reasons, I'm kind of excited to use it as sort of a unifying internal tools platform, but we'll see. Uh, yes. Yes, sir. Yeah. Just a quick question on steps. This might be a little premature, but, um, step one, number five, where you, so you create a workflow, you pass a discrete array of steps, um, which of which there's only one, which makes sense to me.</p><p>And I would think you would just, I guess I'm asking the design decision behind then needing to just also explicitly do test workflow dot then, and then invoke the step. Yeah. Is that not implicit in the array of steps? That's a good question. Does that make sense? The ergonomics around, are you asking about the ergonomics around the commit method itself?</p><p>Like why actually define the commit? Correct. I explicitly say here's workflow. What is going on? What's the, what's the, gentlemen, what's the decision behind that? I'm just kidding. I'm sorry. I actually don't know. Um, I've looked at it recently and I actually checked that API today because I was curious of the same thing.</p><p>I was like, oh, does it return? I actually argued with Nick because he correctly said, no, commit finalizes your pipeline, returns it. And I argued with him incorrectly. Gotcha. So I'm not certain. Yeah. What's the, what's the final idea behind commit? Uh, that, and then, I mean, so, for sort of the local dot is kind of like a .</p><p>It's synchronized. Okay. Got it. It's the final step that's like actually creates the whole object and adds the steps and returns the final. Okay. Gotcha. But why, sorry, I don't mean to berate this, but like why the dot then and then the name of the step? Um, is that, is that step not already in the workflow steps already there?</p><p>Um, so you should be able to, um, so there's sort of two ways of defining steps. Can you, I'm sorry, would you mind coming to the mic? Just so we, sorry. I apologize. No, no, no, no, no. Um, uh, so there's, uh, there's two ways of, uh, coming to, of defining, um, steps.</p><p>You can either give it a step array, um, which as you might expect is kind of, um, the most, a lot of times we just have these linear pipelines of steps. And so you just give it a step array and it will execute things in a linear pipeline. Um, or if you want to add sort of like branching and conditionals and a lot of that kind of thing.</p><p>Um, we have this like fluent syntax where you can do dot then, and then you can do dot if dot branch, dot do while and like loop and, and do conditionals and, and all the fun, complex stuff, you know, but a lot of times you're just, you're running through the pipeline.</p><p>So it's tough. You also just do test workflow document and that it would run. Yeah. Yeah. Yeah. For what it's worth, I have also recently had the experience where I had built two different Gen AI apps, like experimentally internally and realized that I had implemented a pipeline concept in both of them.</p><p>And that was another reason why I was like, okay, I'm excited now about a single framework with one pipeline. We're learning. Yeah. Okay. We've mostly got packages installed or anybody getting into a hundred. Nice. Nice. Okay. Excellent. And you're selling access for $5, right? Okay. All right. We'll kind of show what's, what's happening.</p><p>Um, feel free to keep working on it. It's not, uh, you'll be able to catch up quickly or you can skip to the next step, which I'll show here. Um, whoops. All right. So I'm going to just, um, switch over to steps slash step, uh, one, which is the end of step zero.</p><p>That's where it would bring you to. Um, and so, I don't know what's happening. Okay. Nope. I'm not on. Uh, there we go. I didn't know how to spell switch apparently. Um, okay. So once you have it all installed, then, uh, you really should just have kind of a master index.</p><p>It also has memory, um, set up for you automatically. Uh, but this just creates the master instance. Um, currently we have nothing enabled, no agents, no workflows, uh, no tools, and that's okay. And when we, oops, when we run NPM dev, uh, we will get this URL localhost 4,011.</p><p>And if we go there, this, nope, this is the, the end of step one, which is maybe, there we go. Uh, you look here, you have agents, networks, tools, MCP servers, workflows, and then this runtime context. And currently we have nothing in there. Um, and that's currently by design because we've done nothing.</p><p>We've just gotten the project set up, but now we have all of these tools to help us with building along the way. And so, um, once you get this set up, uh, you should be able to switch over to step one, or just continue on in your branch. I think it might actually be the same because it's just NPM installing.</p><p>Um, and then you should be able to continue on in the, uh, the steps. Uh, this is, I'll just say that this is one of my favorite things though about master, like the local playground. And if you look in the console, you'll see that there is also a couple other things spun up.</p><p>There's the API endpoint. There's also a, uh, swagger spec that you get automatically. And so like the amount of thought that's been put into this, and then you could see how once everyone's comfortable with it, you could, you know, very rapidly deploy applications in a standardized way that other tools can consume, uh, reliably.</p><p>So that's, um, another exciting feature of it. And again, this is like without us having built anything yet. So the goals that we're going to do in step one now, uh, is just create our first workflow. And this is just a very basic workflow. We'll end up throwing it away.</p><p>Uh, but it's going to be one workflow with a single step and it's not going to do anything else, but we'll see kind of the power of it. Uh, and then we'll build upon that in the next step to add additional steps. So we're using steps a lot. Um, and then we will, we'll, uh, be able to put that together into a full workflow in the next step.</p><p>But we will more importantly, we'll be able to see it in the master playground and start really seeing the power of that. Yep. Testing. As always, any questions, uh, feel free to shout them out. If anyone gets stuck, just raise your hand. Yep. We'll run past. We really tried to give ample time for this.</p><p>Not, uh, not including wifi issues. Um, and so, um, yeah, if you have questions, we'd love to, to chat or just ideas of this stuff. Cause I think there's a lot of really cool powers, uh, that you can do with this. Sure. Do you want to hop up to the, thanks.</p><p>Uh, I'm just kind of curious since you're obviously using Vim and kind of deep in the hole. Yeah. Have you played around with any of like the AI integrations into Neo Vim? Kind of like how, what's your current workflow? Yeah, but nobody would ask. Um, yeah, I'm a big fan of Vim.</p><p>I haven't used cursor yet at all because it's not Vim. Um, it's Vim mode. It's not great. Um, but I have played with the tools there. There's one, I'm forgetting a goose. I think that in Vim, I haven't played with that one yet, but it's on my list to play with.</p><p>Uh, the one that I have played with is Avante, uh, which I think I have still set up. Uh, yeah. So it gives you kind of that like chat like interface here. So I can just start having, uh, a chat with this code. Uh, I don't know. There's also, was it Neo AI use that for Neo Vim?</p><p>Even a year and a half ago, you could do that before, before most of the tools allowed you to chat in IDE. Yeah. Yeah. That's always gonna be the benefit of open source is it lands first, right? Yep. Um, but I honestly, like I didn't like the ergonomics of playing with this and like switching buffers and things like that.</p><p>And I honestly felt that, uh, for me, uh, a better workflow was just not using this at all. Uh, I'm also a big team X user. So, um, you know, I will have like Vim open and then I'll just open a split. And Claude, Claude code, um, gives me that kind of the same thing.</p><p>And it's often like its own team X split. So I can work in Vim as I normally would without like weird buffer things. And then it's just off doing things and I can, uh, you know, whoops, use, um, use T mux to like full screen Vim when I need it.</p><p>Claude's out of the way. And then when I want it, I just bring it back in and go. And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go.</p><p>And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go.</p><p>And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go.</p><p>And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go.</p><p>And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go.</p><p>And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go. And then when I want it, I want it to go. I would also be interested in hearing how all of you are using these AI tools.</p><p>Just for, like, not just what you're building, but how you're interacting with them day to day. Because they're changing our workflows. And I feel like everybody's, like, in their own bubble doing their own thing. And then we, like, we have this opportunity to come together and learn, like, amazing new tips and tricks.</p><p>Yeah. I'm all for that. I don't know that I'm all for everybody getting on the same, you know, plus. Yeah. I think it should depend on, on, you know, product or, you know, service or whatever. But I'm, I'm afeard of, of, you know, somebody coming down from on high with, like, this is the golden framework.</p><p>Everybody uses this. Yeah. I mean, we've been through that for decades. Yeah. For sure. Absolutely. That's my personal. Like to mix and match and let everyone kind of choose their own lane. That's exactly. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. To summarize for the video, mixing and matching tools is good.</p><p>And I think that that's really what is, like, powering this right now, especially among, like, us hackers, right? Like there's all these cool new things. It's a whole new world of figuring out what to do, how to do it. And you're not just being prescribed. Oh, just, you know, go use random.</p><p>I don't want to shame any specific editor, but. Anybody specifically. Yeah. Yeah. But I mean, the leaders come forward. Yeah. For sure. You have those choices, you know. For sure. Absolutely. In the meantime, I'm going to play around. Yeah. Yeah. It's all about experimentation, I think. Yeah. Yeah. There's all sorts of experimentation, all sorts of fun.</p><p>I think it's going to help for sure. Also, I do worry that it's like, you know, the first hit is free and then we're all like, Yeah. Oh, no. Yeah. Becoming dependent on it now. Yes, sir. Question for you guys. Do you have a framework specific, like, set of rules, like, that would integrate?</p><p>Not that everyone has to use cursor, but just like, all of a sudden, like, at my company, we've started to essentially say, hey, here's the top 10 tools that we use. And here's cursor rules to do all of those the same kind of way. And it's not so much trying to, like, box people in, but it's more trying to say, give them, like, in Mario Kart, it's like, you get the three booster packs.</p><p>It's like, how can we give people booster packs from the beginning? Yeah. We were talking about this earlier, actually, with Nick Taylor. we were talking about, like, cursor rules growing and evolving kind of like tests. And then it's like this thing that evolves with your code base to prevent you from doing bad things.</p><p>I don't know what that means, though, because I've never used cursor. It's not exactly the question you asked, but I will just say that that's also, like, when you run, you know, NPX install mastra, it asks you, are you going to use cursor, are you going to use windsurf?</p><p>Because if so, I know I can inject the MCP server for our docs. And then the experience that I had after accepting that, I saw, it's like, oh, it enabled that. I checked in my MCP in cursor. And then that session where I coded, there were zero hallucinations. And so that means that every time I asked for a feature, it was one-shotted correctly.</p><p>Furthermore, because it was in TypeScript, I could quickly lint it and compile it and know it was good. And so that's almost like, we were almost starting to, Nick and I were starting to suspect that MCP might be more powerful. Because the other problem is the cursor rules are specific to cursor, right?</p><p>So what if, like, half your team's on windsurf, half's on cursor. You know, we've got tons of licenses for cursor internally. So it's kind of like, but it's not prescriptive. I think the MCP docs server so far is more powerful of a pattern because it is, it's almost like the, the guarantee that the end user dev is going to get your latest docs is not going to get a hallucination.</p><p>And I really wonder if that's like, like, there's so much excitement around that. We saw that at MCP night a couple of weeks ago, like there's so much excitement around that. And I'm just starting to wonder, is it really just because it's like a standard emerging? Um, and that's the reason because it's, it's very simple.</p><p>Uh, but it's, it's enabling all of these tools across, you know, it's not just an anthropic thing anymore. Yeah. Uh, which makes it super powerful. Absolutely. Totally agree. Yes, sir. Yeah. I'm not sure if this is a better question for y'all or for the master team, but I saw that master has experimental support for ingest, which is a durable execution backend, but that it's labeled as experimental.</p><p>And I was curious, like how experimental that is because I'm really excited about durable execution for agents. You know, if you've read the 12 factor agents manifesto, it's really good. Oh, no, I haven't. Where's that? Who published it? Uh, it's on GitHub, uh, Dex from human layer. Um, originally did a lot of the work on that.</p><p>Um, but yeah, I just was curious about jamming on that. Awesome. Great question. Thank you. Unfortunately, we have the folks in the room for that. Okay. Yeah. Well, I'll show Dex who shouted him out. He'll be happy to hear that. Um, uh, so the, we shipped in, uh, sort of a, what we call workflows V next about three, four weeks ago.</p><p>Now, um, the idea being that basically it allows you to have the same syntax, but switch out the, the workflow, um, engine. So the first, um, the, the first, uh, integration that we shipped, we, we sort of initially had, we initially built our workflow engine using X state as a backend, because it kind of makes sense.</p><p>Um, and then we kind of, we, we need to make a couple of syntax changes. And then we also kind of realized that, uh, people started asking us, Hey, like, I love the syntax, but I'd love to have this work with, and I love the visualization in the dev server, but I would love to have this work with ingest or temporal, um, or Cloudflare work workflows or dot, dot, dot, dot, dot.</p><p>Um, and so we're like, yeah, that's a really good idea. So then we shipped workflow V next. That was like, again, three, four weeks ago. And then now we're just starting to, you know, do the list of integration. And so injustice first, um, it's, you should use it. Like it's experimental cause we shipped it like a week ago, but I would be surprised if the API changed after a week from now.</p><p>I actually have a question. Um, just curious what, how does the team think about, uh, deployments going forward? Like are you targeting specific platforms first? Are you going serverless first? Like, are you thinking about trying to go everywhere? Like what's top of mind for you there? Uh, so by default, um, by, by default like master will bundle into a Hono server.</p><p>Put the Hono server in a Docker container and put it on EC2 or digital ocean or wherever you want to put, uh, put it. We also have adapters for Cloudflare, Netlify, Vercel, we also have our own monstrad cloud. So those are kind of the two, Hono is not a, you know, if you're only using Hono, great, but also you can put it in Express or whatever, you can put it in the backend of a Next.js operator app, you know, in general, I think like, you can't really, I mean, you can call it open source and it cannot work everywhere, but like these days you should actually make it work everywhere.</p><p>So that's just our philosophy on things. Yeah. Awesome. Thanks. Yes, sir. Certainly. Yes. Hey. And then what's the full error? What are your MCP shirts? Oh, nice. Yeah, what are your MCP shirts? a fun demo. Thank you. I have a question. I was just reading. I was wondering, is there anything inbuilt into the framework that ensures that the output of each step matches the schema kind of by default?</p><p>Because what if like you specific, like, you know, let's say in the prompt, you kind of forgot what your schema was and you like, how does it reconcile that as well? Yeah. Great question. So I think the answer to that is essentially the Zod schema, right? And the way that I look at that is like, LLMs are non-deterministic.</p><p>That's part of why we love them. But then it's at the point where they're so useful. We're trying to get specific JSON out of them while coding too, right? And the Zod package and like validation library is now ubiquitous in AI engineering, at least in JavaScript. You see it literally everywhere.</p><p>So it's doing the work under the hood. My understanding is that the open AI team couldn't get to a certain level of accuracy without adding on top of training the Zod runtime validation, which can also do coercion into the right types. So that's kind of doing the heavy lifting there.</p><p>I don't think there's anything framework specific that's doing structure generation, but correct me if I'm wrong, but you can define like the transform steps between the workflow. Yeah. There's actually, we actually just did a blog post on this, but it's funny that the models don't always actually respect the schemas that you give them, especially there's some, you know, yellow, okay, Z dot string, like they'll respect that.</p><p>But if you know Z dot string dot, you know, length, you know, four or whatever, like they're not necessarily going to respect that like level of, of nuance. So we actually added, we added sort of four, four, this is especially challenging. This is mostly worked, works reasonably well structure generation is more challenging with tool calling for reasons that are not quite clear to us, but we're clear when we ran 16, you know, with the 30 schemas across 16 models, so we added like a tool compatibility structured layer that reduced, that like reduced the error rate a lot.</p><p>So in addition, on top of the side, like there's also master side, like optimizations to ensure structure generation. Yeah. The, the longer version of this is in a blog post we published over the last week. If you're, if you want to dive into the details. And I don't know if it's related to this, but one thing that we were running into constantly while we were developing this was we were like, as you'll see, we were accidentally sending, sending like a base 64 encoded image, which was huge and failing and it would retry a lot.</p><p>So I assume that there's some retry logic built into it too. If like it wasn't getting back what was expected from the schema. Um, is it built into the, the schema validation piece? I mean, I would assume probably what was happening was that the agents has like a max steps.</p><p>Yeah. It was running until in a loop until hit max steps in it, but it, I guess what I'm asking is if you, if you said, I want a string that's length four and I gave back a length five, would it automatic would master automatically retry? There are cases in which it would, it would retry.</p><p>I don't know if that particular case is one of them. Okay. Yeah. Does that, yeah, that does answer my question and to kind of, to add to that with, if you were to specify a certain things into the schema that aren't inherently like supported, for example, the, the length would that, um, would that be kind of like, would that error just be displayed in compile time at all?</p><p>Uh, let's try it. I don't know. I would expect it's odd to coerce it actually at runtime, um, but I'm not sure. Usually the model will fail silently and just give you a output that doesn't conform to the, um, to the, um, to the, uh, to the schema and we kind of made a decision.</p><p>Should we error or not? And we're like, makes sense. You, maybe you should decide if you want to error. Yeah. All right. Thank you. Thank you. Thank you. Great question. Uh, so just talking about deployment again, I, I noticed the server was the point is there's no like AWS Lambda or anything.</p><p>It's all through Netlify or or. Yeah. Um, there's also a AWS Lambda, um, the player that the community had. Okay. If you, if you Google, you'll probably find that you have issue. Okay. And how does the, the serverless deploy work? Does each step kind of map onto its own Lambda function or how's that?</p><p>Yeah. I mean, we just sort of pack it, bundle it in a, in a, in a, in the, a platform specific way that works for those platforms. So like Cloudflare has like a 300 meg, um, uh, bundle size limit and so we need to do some specific things to get down under that.</p><p>I guess I'm just being in terms of the runtime model that each step kind of maps logically to a function or are you putting multiple steps inside a single function? I did not work on that part of that, so I would have scored. I'm assuming they're all bundled into one, but yeah, I mean, I think they're all bundled into one, but yeah, really.</p><p>Okay. Yeah. That would just be weird for long running stuff. Cause there's. Yeah. Yeah. That's yeah. We, we all, we bundle it all into one, I'm pretty sure. Okay. Thanks. Cool. How are folks doing on step, uh, step one. Good. Good. Awesome. Okay. All right. We've got functioning wifi.</p><p>Excellent. So we can kind of show that I'll go to, um, step two. Did I spell that right? Yep. Uh, which is the end of step one. Um, and so now like looking at the code, uh, we've got, if I update this, we've now got our test workflow in our master object.</p><p>Um, and then we've got a workflows directory with the test workflow and the schema for it. And it's just going to have you, um, basically extract from the user input, uh, the type of frustration that you're experiencing. And the really cool thing now is like without building anything else, uh, we can go to our master playground, refresh it and go to workflows.</p><p>And then we've got our test workflow right there and you can see the graph here. Isn't very impressive with just one step in the workflow, but it's there. And we can see that it would accept a raw user input about work frustration. So does anyone have a work frustration?</p><p>Use your name, your boss, my name, please. Please state the company you work for and your boss's name. We won't tell them. Um, conference wifi sucks. Not really. This is a great job, AI engineer. Um, in general sometimes though. So we can see just by calling that it turned green in the, in the graph and you can see that we click on it and we can see that that's the input that we gave.</p><p>It ran the step and it gave us back this output, this, uh, Jason object. Uh, and we can see with the text conference wifi sucks. The overall mood is frustrated. I think that's accurate. Uh, and the analyzed frustration is technology. Or so we're frustrated about technology in this room.</p><p>So in the next step, where did I go? Oh yeah. Uh, in the next step, um, we're going to create our frustration schema with Zod, uh, build our first workflow step. workflow step. No, that's what we just did. I have my slides backwards. In this one, we're going to, uh, create all of the workflow steps.</p><p>Uh, we're going to chain them together with data mapping. Uh, and then we're going to successfully generate a meme. Uh, and we'll understand the composition of that workflow as we go. Uh, it still won't be like the perfect end result, but it will give us the full workflow where we can like kind of plug it in, in that, uh, workflows tool and see it go through all of the steps from our user input to an actual meme that's, uh, uploaded to image flip.</p><p>So you can skip to step two, uh, or continue on in your branch and, uh, continue from there. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Yep. Sorry. Yep. And so what is this? Is this something, an object that I would then pass to another person?</p><p>Precisely. Precisely. And it's just right now, we're just in the early stages of showing exactly that and that you could have structured this object however you want. But in our case, but in our case, because of the pipeline that we're building, this is the data that we found valuable.</p><p>And so we formed it this way and then we're going to pass it further into the pipeline to do more work based on that. And so the output is, you can change it. Totally. It's your arbitrary schema. If I want markdown, if I want JSON, if I want whatever.</p><p>Yep. Yep, absolutely. And that's part of what Zot will help you do too. Because you can define like, maybe you have some giant object and this may fields and this is a string and this is an array of strings and all that. But it's really for you to compose together the exact structure that you need.</p><p>You would have to know what the next stage is. Yeah. Yeah. So there's a little bit of a forethought. Absolutely. A forethought or the third time you've written that app. You've had enough, you've had two shitty first drafts and you're ready for the third. Sometimes I do it that way.</p><p>But yeah, sometimes I'll plan it out and be like, what's the logical breakdown for these steps? Yeah. Yeah. Yep. The main point of this one is to just determine like the level of frustration and what you're frustrated about so that it can be fed in in the next step to image flips API to get back an image template that, or a mean template that would accurately fit that.</p><p>And then we kind of shoehorn it in from there. But again, the like, I guess the mental mapping that we're all trying to do here too. It's like to think about how do we take this home, then like turn it into something that actually solves a problem or automate something at work.</p><p>So we get promoted before the machines come for us. You know, that's the general, pretty much. Yeah, I think so. And just so we're level setting, this is like the memes that you've seen. Image flip is a, they have an API for not only finding great memes, but also just having blank templates.</p><p>So they, they can give us back information about this, the rock meme, the rock in a taxi meme or whatever, and those boxes are blank. And then you can post to their API with whatever you want it to say in each of those. And it'll tell, tell you like, Oh, I have three boxes.</p><p>And then you just post in there. And that's what we're eventually going to be doing in one of these steps. But that's, that's a perfect real world example. It's like knowing those box slots is critical to the rest of the pipeline. If any other step in the pipeline didn't know the box slots correctly, right?</p><p>Like that'd be a problem. So you can define that in your schema and make sure that it's there and like that's part of it. Yeah, yeah. So, thank you. putting this workflow together too, is probably the biggest of the steps. Yep. Once we have this, we'll, we'll create an agent in the next one.</p><p>And that's pretty straightforward, as you'll see. And so there's, there's time built in also to, to play with this experiment, tweak things like the, like the prompt temperature, temperature, things like that. Well, we'll look at that in the playground. That's the cool thing is like, once we get the agent and start chatting with it, you know, like there's just a, iterating locally is so much faster, right?</p><p>And that's really what the playground's about. So you can even tweak the prompt on a per request basis. You can change temperature model, whatever. certainly. Yep. Certainly. Yep. And, and, and, and, and, and, and, and, and, and. Certainly. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.</p><p>Thank you. Does it sound like the credentials are being... Yeah, so in general, if you get an error at the generate meme step and you don't get a clear error message and you have not created an image flip username and password, that's likely the problem. And then if you sign in with Google, which is the same thing I did, that's fine.</p><p>And then you just have to go into image flip settings after and set a password because you're OAuth-ing in so you didn't get to set a password, so the complexity is in the UI of image flip. Just... Thank you. Yes, absolutely. Let me know if you have another issue.</p><p>Yes. So in our testing, there's a public key that floats around. So there is an anonymous key that's public, like git guardian will flag. Others consider it a secret, but apparently it's not, and people are using it. And the reason that we finally asked people to make their username and password is that it gets you a significantly higher rate limit.</p><p>Yeah. And so you're less likely to run into this issue in the workshop, at least. But the error is it? Yeah, the error. The error. What's the specific error you're getting? Is it opaque? Actually, now I'm getting just like 20, but I don't know if it's just like you cannot run the restrictions.</p><p>Oh, if you like... Are you on the... Which branch are you? Okay. I think we're on two. We're on two? Mm-hmm. Yeah, I think. So try doing git switch and yeah. I'm gonna just stash all that stuff first. Yeah. You have no idea the struggles of trying to do a workshop with, when API keys are involved.</p><p>We originally had a step that it would not, it would take an inspiration from an image flip. All right. And then generate a new meme. Okay. So it was a completely unique meme. Yeah. But in order to do that, you would have to go in and verify your OpenAI account, which means like you would have to scan your passport to be able to do it.</p><p>We thought that might be a little much to ask in this workshop. We thought that might be a little much to ask in this workshop. We thought that might be a little bit more. We thought that might be a little bit more. We thought that might be a little bit more.</p><p>We thought that might be a little bit more. We thought that might be a little bit more. We thought that might be a little bit more. We thought that might be a little bit more. We thought that might be a little bit more. We thought that might be a little bit more.</p><p>We thought that might be a little bit more. Can you guys say more about like how you're, I guess, like interacting with these workflows and agents like in the cases you've seen? You said something about Vercel, like are you deploying them and then contact them through like an API call or like, are they actually embedded into your application?</p><p>Yeah. What I'm primarily doing right now is you still using the Verceli ISDK. So everything I've got, like at least at work that's deployed already, that's mostly Verceli ISDK. And then we're building a ton of like internal tooling with master that started like two, three weeks ago. And most of our stuff goes to Vercel just because we already have that and it's pretty fast.</p><p>And then most of the things I've built so far are web applications that might have a pipeline. So there's a UI and there's still a user kind of requesting generations and asking for things. What I think would be super cool and powerful though is like the workflows expose like an API endpoint to just start them and hit them from anything.</p><p>And so I think that's also like a pretty powerful pattern. I've not really used it really fully right now in Prod yet, but that's something I would think about for sure. Like cron jobs almost. Workflows that need to run like every night, you know, maybe have a cron that fires that or something.</p><p>All right. Cool. Thanks. All right. We've got about five minutes and then we're going to move to the next step. So if anyone's stuck on anything or has questions, don't be shy. Speaker 2: Does anybody have the memes generating right now through the workflow? All right. One, two, three, four, five, six, seven, eight, nine, 10, one, 12.</p><p>That's amazing. Post some of your favorites in the Slack. Yeah. There's no filters left on them. So if you like what happened, we did it. And if you are offended, it's not our fault. When you're dealing with memes like this, it really brings out the non-determinism of this. If it generates offensive ones, we tried to curb that.</p><p>But also these AIs are not great sometimes. Speaker 2: If people who didn't want to raise their hands, I'll just go around and give you guys books. Speaker 2: If you want a free signed, are we talking autographs here, Sam? We're talking autographed copies. So the first edition or second edition?</p><p>Speaker 2: First edition. Speaker 2: Autographed first edition from the CEO of Master Yourself. If you got a meme working and you want, or you just want a book, raise your hand. Excellent. that's pretty offensive this gentleman was like a book as well yeah i'm building agents and typescript got it cheers oh these are all this is amazing yeah i got some pretty racy ones by saying why did they put a systems engineer on an open floor plan with the sales folks that are screaming all day that's a fun prompt i love this that's awesome yes sir so i come from a data engineering background and there's something called daggs and airflow which are for whatever reason culturally they've caught on um as you guys have designed workflows have you thought of daggs are they similar dissimilar are you talking about directed acyclic graphs yeah control what does the control flow look like for workflows so far stuff that i i've seen you know supported by the semantics of like a master pipeline honestly um to be perfectly frank the place that my mind goes with that is just graph rag like a graph plus retrieval augmented generation so like some vector database plus a graph knowledge graph to like do traversal um to also answer like structured questions about entities in addition to like semantic search capabilities um that's honestly what i've built mostly or i've seen people kind of like uh like positing is going to be a next gen architecture but so far what i've needed has just been pretty simple pipelines basically run these steps branch over here if this happens um you know i see the dag is like that's like terraform in my mind from from devops like land of like it must proceed this way and the entire thing fails if if like node 3 uh is unhealthy kind of yeah that's a great question we were actually nick asked if we could trigger a specific step i'm not sure but the other thing i'll say is that in those cases that's the other reason i love the pipelines and also even just the concept of steps and agents because i can do a specific model for each one so like extracting frustrations is like that's pretty simple and should be fast and cheap so it's like do 4.0 or even something simpler or maybe even get away with like a 7 billion parameter model that's deployed on like cloudflare workers right and then which it's like essentially free um that's like and that question by the way this is like the uh like how do you right size ai application workloads like that is top of mind for everybody now everyone's asking that questions like how do i get the infra to be what's correct for the workload i have i think everyone's trying to figure that out and another thing like you can explore different ways of doing this uh when we first started with this we had all of these steps as tools and then kind of let the ai decide when it should call them um so that could be another approach depending on if it can intelligently skip steps um it might be able to do that um there was a question is this is in our chat right is it okay so there's a question is is there a way to implement or configure caching with master i think the answer is yes yeah for sure yeah this so i did i did i did the uh image uh-huh the same here show me the your dot n file you would okay yeah right that looks great to me assuming those are your actual credits yeah and the other other thing is did you uh did you restart in family i i saved it and then i oh so restarted now because i bet you did you update them while that was wrong so if you restart it it should um pick up the new dot n and let's see if it's the same or not uh yeah i thought it was because it's two words instead of one and i still have a is there an extra space anywhere and because i had that issue even after i had the correct values like there has to be oh it'll take a few weeks probably oh is it not going through oh it'll take a few weeks probably oh is it not going through did it try and execute the tool uh what uh different key what um i don't think uh clandry is right no no no no it's this is it should it should be relatively fast second time trying it's just waiting for approval ah okay uh good to know let's try that uh we should um so i can show this now uh so if you go if you have it installed which i do um down in here i have mcp shop set up this is claude by the way uh hey bro i here i can get a shirt let's see if it works pondering t-shirt potential that was awesome ah i can't provide physical shirts or merchandise that's interesting i thought you should be connected nope that's the problem there we go try that again hey bro here i can get a sweet mcp shirt now that we're maybe connected yeah cool so it pops up we'll allow that you can definitely get an mcp shirt there's one available right now here's what you can get minimal design i don't know that it says context is everything but it might yeah i don't think it says that yeah oh oh oh yeah okay it does context is everything yep cool so it just needs for me my company name my mailing address and my t-shirt size so i'll say we'll say excel um one infinite loop and company name uh work os oh it needs my city state and zip code i don't i don't know what that is for apple um so i'll just i'm i live in omaha oh and look at that it's going to buy my shirt and it's ordered we will we will actually send you a shirt so be sure to yeah be sure to submit it while you're here you can also ask things like um can you tell me about my order uh it's deployed on is this you put it on cloudflare yeah yeah i have a version deployed on cloudflare um this one i think is it might be the original mcp shop yeah probably in versell i think it's yeah it's deployed to versell um for this specific instance of it i i have a talk on thursday where i'm also i have the same thing deployed to cloudflare so um we'll go into the code and i can send out the repo for that but um yes that one just saves it saves the info to a kv store uh and then that's that's what's used to order the shirts uh you can deploy mcp servers to cloudflare now using work os as the auth layer yeah so if you check that we have a blog post and a couple of tutorials yeah yeah that's the thing it's using work os to do that off you didn't see it because i'm already often but when i hit connect it opened up and it was do completing that offload to get me a token so that i could do that here and you can see that in here it's got like my order information um i don't know do you know my name and email which is totally not something i've said yet but but also to tie it again uh back together right because again like toy it's fun got a t-shirt but imagine this as an e-commerce workflow right this is what people are building like this is what everyone's trying to figure out how to do correctly what i actually want to do is just go i'm in a hurry i want to get on the page and say it needs to be a product exactly like this does it support that okay fine go not 40 less than that right that's what everyone wants to do um and so that's what this interface is yeah pretty soon you'll be social engineering your way through llns to get a free shirt when it's not free yep i can't wait for the future uh cool yeah let's let's uh look at the workflow so i switched over to the step three branch which is the end of step two uh where you should be at and you've got a new meme generation workflow uh and it's got you know a bunch of schemas set up for the input and output schemas uh and all of the steps set up to run each of these and you know that's the code for it let's go look at the the actual get out of here um the tools in master so i'll refresh this and go back to work no workflows there we go now we have our meme generation workflow and it's got four steps and so this is a little bit better a little little more detailed in what what it's doing um it's got not including these mappings it's got our extract functions find base meme generate captions generate meme oh come on uh and then a final mapping um and so i don't know someone give me a work frustration somebody ate my sandwich out of the fridge when no one in the workshop is someone was too busy preparing a workshop to review my pr nick nick no never and won't review my pr that's a made up one um so yeah it can run you can see it running um and then we can go we see all of the steps are now green and so we can see the input and debug the input and output on each of the steps so there's the input that we got and it gave out a a frustration a communication frustration and oh i am all sorts of messing this up but we can have it find the base meme and then generate the captions for it find out what that is so when the meeting could have been an email but everyone is just smiling like it's fine that's relatable um but then down in the generate meme one that's going to receive the captions it's going to receive apparently a meme called disaster girl and did i mention that these are non-deterministic and i don't know what it's going to generate ah the meeting could have been an email but everyone is just smiling like it's fine this is fine yeah um yeah so this is fun right we can see the workflows the inputs and outputs of it and we can debug those steps along the way we can see exactly what is what we're starting with and how it progresses through each of the steps uh to give us a full workflow which is awesome um we haven't even had to do a deployment yet and we can just iterate locally change the prompts change the schemas until you get it exactly the way you want and then you haven't wasted time going back and forth you've like iterated rapidly yeah and so really easy debugging that's why we love this tool like it's it's just really fun and easy to do so in the final step um the the final main step we have uh we're going to like take that workflow now and call it with an agent so this is a pretty straightforward step we're just going to create an agent give it a prompt to work with and give it the the knowledge of the this workflow that it can run and then it'll run it for us so instead of having to use that interface we can use a chat interface uh that we're more familiar with and go from there and so and again to tie it back to actually taking this home and doing something useful with it like we've gotten to the point where we've described the workflow of steps that completes a discrete task and maybe that's something that our co-worker needs and then again maybe they are technical maybe they're not maybe they're just in a hurry so by building them an agent and saying use this workflow and you have the ability to call this workflow that becomes an ideal interface to give to our colleagues to start using this and then something that they used to have to do piecemeally they're just now firing off a chat request and it's done for them automatically yeah so with this you'll learn what agents are how you give them instructions the memory systems for them the workflow integration through master and then how you can test them in the and then how you can test them in the playground wow these are awesome so these are new community memes pouring in in real time we finally catch up on slack messages but there's already 20 more waiting nice yeah that's a great idea yeah there's some great um feedback on the framework guys in the in the slack channel there's like some ux requests as well you see that's great too real you can also play with the uh prompt uh the prompts a little bit to tweak it about what it's how it's like analyzing the frustration the level of frustration the type of meme things like that it's really fun to get a vibe for it yeah indeed all right all right is everyone more or less have uh what they need is anyone still stuck on anything last minute questions or pickups i'll make a t-shirt with that that's amazing i'll make a t-shirt with that that's amazing i'll make a t-shirt with that that's amazing i'll make a t-shirt with that so so so so uh just a i guess a comment from us and i guess from the team as well like honestly like thanks everybody for coming and building these we didn't even know this workshop was happening until last week it was but um i mean previously like so like most of us at monster were previously building gatsby like i was the co-founder and so we've been doing open source javascript stuff for a while but it's like it's like pretty humbling when you show up for a conference and actually someone else is giving a workshop about how to use the thing that you built um and i think i speak for all of us so like thanks everybody and on the same side we didn't know that you were going to be here until i think like yesterday but we got very excited because it's like hey you got a question about commit let's go i'm just personally curious how many folks have or like already have agents deployed at work in prod that they're using for things a couple how many folks are trying to get them in into prod right now i'd be curious to know what you're using them for yeah i'd also be curious if anyone wants to share either in the slack or just call it out or come up to mike like what are the top use cases that you're thinking of for agents or struggling with i'd be curious to know too it's such a fun time because there's like you have to get your head around what it's doing and then get your head around what it can do and it just it starts to feel like the possibilities are endless and just super fun yep that's awesome yeah that's awesome so like you've got um so you want to be able to chat with your infrastructure and like ask questions like either an incident like show up to the incident and even already have like initial guesses maybe yeah that's awesome cool any other use cases i think that we're finding um we're mostly able to just knock out a ton of like low-hanging fruit that folks are doing manually right now that's you know especially with tools like this like you you know create a simple agent or even just a pipeline with a few steps and a couple api calls and that can like free up hours of somebody's week i think that's the part that i'm most excited about right now yeah it's like all the little paper cuts you can just so quickly iterate on them and get things going and not just with these tools but just like vibe coding in general like you can you know be like i'm going to spend an hour just seeing where i'm just seeing where i can get to and yeah it's amazing incredible how quickly you can get there always review the code though please what's that always review the code please yeah please review the code use tools like git guardian before you commit yeah yeah we had our our ai moment a couple weeks ago at our last onsite and we had like a couple hours just to spend doing something with ai and there was really no prescription to it it was just explore and play and if you can solve a problem great if not you learned something along the way and uh the thing that i worked on was like me as the maintainer of several sdks across several languages uh a pain point i saw was like people adding in you know very simple prs to one repo that's like the node repo the node sdk and then doing the same thing it's like adding a new field to the node sdk and then adding the same field to the ruby go php kotlin like all of the sdks i was like i wonder if we could do something to alleviate that and make it easier and after two hours of pure vibe coding with clod i had a github action that when you label the first pr that you do you just add a label to it it will go and generate the prs for every other repo and you know every other automatic pr every other sdk yeah that's awesome were you using like a software engineering like dagger or something to essentially make the changes making it oh that's a great question making the changes is one thing and yeah that's something that yeah i think dagger would make a lot of sense but what were you doing with that i wasn't i wasn't doing any of that um i vibe coded it and i actually don't know what the code does and he had that i didn't review it a 4 300 line uh github action that's working great now how much more about that but to be clear we didn't ship it uh it's it's an experiment maybe maybe we will for sure um but the week after that i think um clod had come out with like b the ability to run clod code as a uh like via an api so that you could like spin it up run it give it the instructions on what to do and then let it figure out how to do it because like most of the code that it generated was just handling how it was going to do the diffs and for several hours of that it was just like it made the changes i wanted and then deleted the rest of the files and that wasn't great um we're also for what's worth finding uh incredible utility with tools like v0 dev so if you're already in the versell ecosystem or have used next js there's now they're they were originally conceived of as like rapid prototyping tools that may be for designers or maybe for developers but like an example is that somebody on our marketing and sales team is trying to figure out who would be interesting engineers are already doing work with mcp to contact about conferences like this and their workflow is completely manual and they're you know talking to me about it on on a call and four minutes after they started telling me about it i had it working like in v0 dev and hand it to them and had a completely separate you know tool that's available on a url that they can just paste in whatever they need essentially and get like the analysis done um and so that was very eye-opening for me because it's in some cases now it's faster to create the tool that your colleague needs than it is to continue talking about the tool that your colleague needs and even ticketing it or saying next tuesday we should try and like sometimes you can literally sit down in v0 dev with like a paragraph very descript prompt and get what do you need that's pretty good yes no not in my experience not yet yeah totally i think that's a fascinating question yeah the question is like when um folks in other roles that are not traditionally technical see how quickly you can scaffold the stuff are they all clamoring for the keyboard that's not been my experience yet there i think that's also like part of what the trepidation and anxiety is around is like well now everyone can do it but then i also comfort myself and say that i define a pleasurable evening as like sitting down for 12 hours on one of these machines and going back and forth to try and get it to go the way i want and that's not most people's description of a fun time so like even when the tools are better i i still think you kind of have to find this enjoyable you know what i mean i don't i don't i i i think it might change to some degree like when like most generation becomes one shot able and you say i want this app and it's of like this complexity and most people can get something working immediately if that's correct i think that'll take a lot of low-hanging fruit out but but they would do what they would do what lawyer like legal questions and data and just these fees and then they would really uh almost like a blind amount start telling plot codes go to xyz and tell me what the results yeah i think it's super fascinating and anecdotally um it's mostly been lawyers when i've been at meetups sort of come up and asked the most like salient questions about gen ai and they'll say like i'm not a coder but like this we're trying to do also semantic search and all like the information compression that's available with a lot of the gen ai tools like i think uniquely speaks to their use case too there's this gigantic corpus of case law and you need to know exactly this right now right yeah it's but it is um it's an intense time i think for that reason yeah culturally right okay uh um uh in this uh session or in general sorry right now uh no yeah but uh i have a i have a yeah yeah for the most part i have a tutorial for you that does that if you want it thanks thanks for coming appreciate it yeah all right so we can show the agent piece of it now um so i switched over to the step four branch which is the end of step three uh where we should have the created uh agent now that can run and actually have a conversation with the tooling which makes it really a lot easier to work with but we still have the power of being able to use the workflow tool to see what's going on and debug the steps along the way but now if we go to the agents tab in mastro we've got a meme generator and this gives us a very sim a very familiar look and feel gives us a chat window but it gives us more than that in the uh the sidebar here we've got an overview we can see the instructions that are given to the agent so it's a helpful ui agent or ai agent that's going to help us do that it's got some critical steps in there it's got the workflow that it should follow and telling it what it has access to we also can see the model settings and we can adjust this as we go so we can add more or less temperature uh top p we can change all of these on the fly and test it to really hone in on like what works best for whatever we're trying to build so i'll ask one more time work frustration he's got the gnarliest work for us who's the most frustrated at work right now raise your hand and again you must state your company and your immediate superior's name i always get asked to go to large meetings for four hours and then i don't speak at all this bothers you too i see okay yes meeting fatigue um so now we can just ask the chat and see the output and it's much cleaner it'll actually give us the image in line too which makes it really nice and easy to work with that pointless meeting i was dragged into but if you scroll up a little bit too the other thing uh to see here is like so the user asked a question and you saw that the workflow got run um but now there's also additionally like the agent is still chatting and it's in a familiar way that you already if it are familiar with if you use gpt but then again just a reminder that this is kind of the ideal interface for folks that might be your clients your customers your colleagues yeah and we can see like in line what happened you know the tool arguments that were passed in the total result we can see what tools were called uh and how in this case it was the workflow and here's all of the information and then the end result that we can actually play with yeah so this could be you know chatbot that someone is requesting a report from an analysis a sql query a new code a review of code review of a design like a new image you can kind of put whatever you want behind the same interface not really not really it's non-deterministic guys uh there's there's no hr for this conference i was told that in advance so uh kind of to wrap that up uh what we built was a multi-step workflow that we could give to a conversational agent who knows how to execute it knows what to pass into it and what it's going to get back and then it can do without what it will it gave us you know human feedback uh it wasn't just spitting out jason in the end it was giving us an actual response and then showing us the image inline and giving us a clickable link so that we could go share that image to whoever we wanted to um and we were able to create some awesome memes i highly recommend you deploy this and use it because it's cathartic to really vent to it and if you're deploying it your data's safe probably i don't know so some key takeaways uh from this uh we learned about the workflows agents we are uh type safety um catching errors in that uh and the structured generation to ensure a reliable output uh and some of the benefits of mastro yep um also just say that we didn't show this here but one of the examples that's on master site you can go check out is like a 37 line of code uh pipeline that does retrieval augmented generation and if you've worked if you've built those pipelines before like two years ago you know you had to glue together at least three or four libraries it was a super crappy experience so it's just really nice to have a single place you can go and define that pipeline at a high level so yeah excited to experiment more with that as well there's a ton here that you can do that we did not even scratch the surface of or point to yet yeah for sure coming up with uh what to do in two hours it's uh not a lot of time and there's a lot a lot more that we could dig into and we highly encourage you to so this was meant as a a primer uh you know have like an example yeah yeah uh now experiment with it add things add tools um deploy it with mcp like figure out your co-workers yeah yeah ask them to use it see what happens so yeah explore the tool creation uh add a vector database implement rag uh all of those and just a final reminder mcp.shop um go order a t-shirt check it out uh it's really cool so thank you with that um we've got 15 minutes left we wanted to save that for questions any additional follow-up any just general casual conversation about these tools uh the fascinating world of ai anything vote on memes that regenerated and see who is the ultimate winner in the slack channel so i'm giving a talk on agents and workflows tomorrow and i really liked your agents and workflow side can you bring them up again what i didn't hear what you said yeah i didn't hear it sorry oh sorry i'm giving a talk on agents and workflows tomorrow agents and workflow sides were really good can you bring them up again sure i can share them too they're open source because they're in our repo and they're on markdown there's a couple tools that nick nick likes uh yeah this was sly dot sly dev or sly dot dev yeah it was something that we switched to relatively 20 minutes not that long ago 20 minutes before this talk pretty much yeah uh questions for us or the master team uh do make sure that you if you want a shirt buy a shirt because we will actually send you a shirt we might not send it this week but uh we're tracking all the orders and we're going to honor all of them so it's a limited edition mcp dot shop shirt that will never be seen again yeah if you want an official master book um autographed copies are thirty dollars right and otherwise cool um yeah yeah question where's the memory and execution step the memory and execution step um yeah so you you can configure you know we configured sqlite for this demo and that's what's powering like the ability as you create additional chats you'll see the previous chats on the left rail but there's a ton of different storage drivers like there's the postgres and everything else right so you can basically choose what you need to and then once you configure the memory you pass it into either the workflow or agent um and then that's by by way of doing that you're telling it can use it essentially is that your question the demo one doesn't have memory the demo one does have memories using sqlite and it's solid uh it says check the execution step where do i find that uh check execution step where are you let me oh i'll come over great talks oh thank you thank you thanks so much for coming i appreciate it and uh yeah we'll be around uh all week uh at the conference so reach out uh we'd love to chat more talking about just uh like that graph this is amazing thank you</p></div></div></body></html>