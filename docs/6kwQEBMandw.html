<html><head><title>Lesson 3: Practical Deep Learning for Coders</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 3: Practical Deep Learning for Coders</h2><a href="https://www.youtube.com/watch?v=6kwQEBMandw"><img src="https://i.ytimg.com/vi_webp/6kwQEBMandw/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./6kwQEBMandw.html">Whisper Transcript</a> | <a href="./transcript_6kwQEBMandw.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Let's start actually on the Wiki on the Lesson 3 section of the Wiki because Rachel added</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=13" target="_blank">00:00:13.200</a></span> | <span class="t">something which I think is super helpful to the Wiki this week, which is in this section</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=18" target="_blank">00:00:18.180</a></span> | <span class="t">about the assignments, you'll see where it talks about going through the notebooks as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=22" target="_blank">00:00:22.640</a></span> | <span class="t">a section called "How to Use the Provided Notebooks" and I think the feedback I get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=28" target="_blank">00:00:28.320</a></span> | <span class="t">is each time I talk about the kind of teaching approach in this class, people get a lot out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=33" target="_blank">00:00:33.680</a></span> | <span class="t">of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=34" target="_blank">00:00:34.680</a></span> | <span class="t">So I thought I wanted to keep talking a little bit about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=39" target="_blank">00:00:39.240</a></span> | <span class="t">As we've discussed before, in the two hours that we spend together each week, that's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=43" target="_blank">00:00:43.960</a></span> | <span class="t">nearly enough time for me to teach you Deep Learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=46" target="_blank">00:00:46.800</a></span> | <span class="t">I can show you what kinds of things you need to learn about and I can show you where to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=51" target="_blank">00:00:51.080</a></span> | <span class="t">look and try to give you a sense of some of the key topics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=55" target="_blank">00:00:55.000</a></span> | <span class="t">But then the idea is that you're going to learn about deep learning during the week</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=58" target="_blank">00:00:58.160</a></span> | <span class="t">by doing a whole lot of experimenting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=60" target="_blank">00:01:00.600</a></span> | <span class="t">And one of the places that you can do that experimenting is with the help of the notebooks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=65" target="_blank">00:01:05.720</a></span> | <span class="t">that we provide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=68" target="_blank">00:01:08.420</a></span> | <span class="t">Having said that, if you do that by loading up a notebook and hitting Shift + Enter a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=72" target="_blank">00:01:12.480</a></span> | <span class="t">bunch of times to go through each cell until you get an error message and then you go,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=76" target="_blank">00:01:16.680</a></span> | <span class="t">"Oh shit, I got an error message," you're not going to learn anything about deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=83" target="_blank">00:01:23.700</a></span> | <span class="t">I was almost tempted to not put the notebooks online until a week after each class because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=90" target="_blank">00:01:30.960</a></span> | <span class="t">it's just so much better when you can build it yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=95" target="_blank">00:01:35.520</a></span> | <span class="t">But the notebooks are very useful if you use them really rigorously and thoughtfully which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=100" target="_blank">00:01:40.120</a></span> | <span class="t">is as Rachel described here, read through it and then put it aside, minimize it or close</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=107" target="_blank">00:01:47.400</a></span> | <span class="t">it or whatever, and now try and replicate what you just read from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=113" target="_blank">00:01:53.920</a></span> | <span class="t">And anytime you get stuck, you can go back and open back up the notebook, find the solution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=119" target="_blank">00:01:59.840</a></span> | <span class="t">to your problem, but don't copy and paste it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=123" target="_blank">00:02:03.580</a></span> | <span class="t">Put the notebook aside again, go and read the documentation about what it turns out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=128" target="_blank">00:02:08.440</a></span> | <span class="t">the solution was, try and understand why is this a solution, and type in that solution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=133" target="_blank">00:02:13.800</a></span> | <span class="t">yourself from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=136" target="_blank">00:02:16.360</a></span> | <span class="t">And so if you can do that, it means you really understand now the solution to this thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=140" target="_blank">00:02:20.800</a></span> | <span class="t">you're previously stuck on and you've now learned something you didn't know before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=145" target="_blank">00:02:25.240</a></span> | <span class="t">You might still be stuck, and that's fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=147" target="_blank">00:02:27.680</a></span> | <span class="t">So if you're still stuck, you can refer back to the notebook again, still don't copy and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=152" target="_blank">00:02:32.040</a></span> | <span class="t">paste the code, but whilst having both open on the screen at the same time, type in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=157" target="_blank">00:02:37.560</a></span> | <span class="t">code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=158" target="_blank">00:02:38.560</a></span> | <span class="t">Now that might seem pretty weird.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=159" target="_blank">00:02:39.560</a></span> | <span class="t">Why would you type in code you can copy and paste, but just the very kinesthetic process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=163" target="_blank">00:02:43.800</a></span> | <span class="t">of typing it in forces you to think about where are the parentheses, where are the dots, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=168" target="_blank">00:02:48.680</a></span> | <span class="t">what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=169" target="_blank">00:02:49.920</a></span> | <span class="t">And then once you've done that, you can try changing the inputs to that function and see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=175" target="_blank">00:02:55.040</a></span> | <span class="t">what happens and see how it affects the outputs and really experiment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=179" target="_blank">00:02:59.320</a></span> | <span class="t">So it's through this process of trying to come up and think about what step do I take next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=186" target="_blank">00:03:06.140</a></span> | <span class="t">That means that you're thinking about the concepts you've learned.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=189" target="_blank">00:03:09.000</a></span> | <span class="t">And then how do you do that step means that you're having to recall how the actual libraries</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=194" target="_blank">00:03:14.080</a></span> | <span class="t">are working.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=195" target="_blank">00:03:15.560</a></span> | <span class="t">And then most importantly, through experimenting with the inputs and outputs, you get this really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=200" target="_blank">00:03:20.000</a></span> | <span class="t">intuitive understanding of what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=202" target="_blank">00:03:22.400</a></span> | <span class="t">So one of the questions I was thrilled to see over the weekend, which is exactly the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=212" target="_blank">00:03:32.080</a></span> | <span class="t">kind of thing I think is super helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=217" target="_blank">00:03:37.600</a></span> | <span class="t">How do I pronounce your name?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=219" target="_blank">00:03:39.600</a></span> | <span class="t">I'm trying to understand Correlate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=227" target="_blank">00:03:47.060</a></span> | <span class="t">So I sent it two vectors with two things each and was happy with Resolve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=233" target="_blank">00:03:53.080</a></span> | <span class="t">And then I sent it two vectors with three things in, and I don't get it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=237" target="_blank">00:03:57.560</a></span> | <span class="t">And so that's great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=238" target="_blank">00:03:58.560</a></span> | <span class="t">This is like taking it down to make sure I really understand this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=242" target="_blank">00:04:02.720</a></span> | <span class="t">And so I typed something in and the output was not what I expected, what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=248" target="_blank">00:04:08.440</a></span> | <span class="t">And so then I tried it by creating a little spreadsheet and showed here are the three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=252" target="_blank">00:04:12.920</a></span> | <span class="t">numbers and here's how it was calculated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=255" target="_blank">00:04:15.760</a></span> | <span class="t">And then it's like, "Okay, I kind of get that, not fully," and then I finally described it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=261" target="_blank">00:04:21.560</a></span> | <span class="t">Did that make sense in the end?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=263" target="_blank">00:04:23.240</a></span> | <span class="t">So you now understand correlation and convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=265" target="_blank">00:04:25.960</a></span> | <span class="t">You know you do because you put it in there, you figure out what the answer ought to be,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=270" target="_blank">00:04:30.600</a></span> | <span class="t">and eventually the answer is what you thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=272" target="_blank">00:04:32.520</a></span> | <span class="t">So this is exactly the kind of experimentation I find a lot of people try to jump straight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=283" target="_blank">00:04:43.320</a></span> | <span class="t">to full-scale image recognition before they've got to the kind of 1+1 stage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=291" target="_blank">00:04:51.000</a></span> | <span class="t">And so you'll see I do a lot of stuff in Excel, and this is why.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=295" target="_blank">00:04:55.480</a></span> | <span class="t">In Excel or with simple little things in Python, I think that's where you get the most experimental</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=300" target="_blank">00:05:00.560</a></span> | <span class="t">benefit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=302" target="_blank">00:05:02.640</a></span> | <span class="t">So that's what we're talking about when we talk about experiments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=310" target="_blank">00:05:10.280</a></span> | <span class="t">I want to show you something pretty interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=312" target="_blank">00:05:12.960</a></span> | <span class="t">And remember last week we looked at this paper from Matt Zyla where we saw what the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=323" target="_blank">00:05:23.040</a></span> | <span class="t">layers of a convolutional neural network look like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=333" target="_blank">00:05:33.880</a></span> | <span class="t">One of the steps in the how to use the provided notebooks is if you don't know why a step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=357" target="_blank">00:05:57.280</a></span> | <span class="t">is being done or how it works or what you observe, please ask.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=366" target="_blank">00:06:06.440</a></span> | <span class="t">Any time you're stuck for half an hour, please ask.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=372" target="_blank">00:06:12.000</a></span> | <span class="t">So far, I believe that there has been a 100% success rate in answering questions on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=378" target="_blank">00:06:18.840</a></span> | <span class="t">forums.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=379" target="_blank">00:06:19.840</a></span> | <span class="t">So when people ask, they get an answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=383" target="_blank">00:06:23.120</a></span> | <span class="t">So part of the homework this week in the assignments is ask a question on the forum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=391" target="_blank">00:06:31.080</a></span> | <span class="t">Question about setting up AWS, don't be embarrassed if you still have questions there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=402" target="_blank">00:06:42.240</a></span> | <span class="t">No, absolutely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=403" target="_blank">00:06:43.240</a></span> | <span class="t">I know a lot of people are still working through cats and dogs, or cats and dogs, or redux.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=410" target="_blank">00:06:50.020</a></span> | <span class="t">And that makes perfect sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=411" target="_blank">00:06:51.360</a></span> | <span class="t">The people here have different backgrounds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=413" target="_blank">00:06:53.180</a></span> | <span class="t">There are plenty of people here who have never used Python before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=417" target="_blank">00:06:57.400</a></span> | <span class="t">Python was not a prerequisite.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=419" target="_blank">00:06:59.260</a></span> | <span class="t">The goal is that for those of you that don't know Python, that we give you the resources</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=424" target="_blank">00:07:04.180</a></span> | <span class="t">to learn it and learn it well enough to be effective in doing deep learning in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=429" target="_blank">00:07:09.920</a></span> | <span class="t">But that does mean that you guys are going to have to ask more questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=435" target="_blank">00:07:15.500</a></span> | <span class="t">There are no dumb questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=437" target="_blank">00:07:17.680</a></span> | <span class="t">So if you see somebody asking on the forum about how do I analyze functional brain MRIs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=444" target="_blank">00:07:24.840</a></span> | <span class="t">with 3D convolutional neural networks, that's fine, that's where they are at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=449" target="_blank">00:07:29.120</a></span> | <span class="t">That's okay if you then ask, What does this Python function do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=453" target="_blank">00:07:33.520</a></span> | <span class="t">Or vice versa.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=454" target="_blank">00:07:34.520</a></span> | <span class="t">If you see somebody ask, What does this Python function do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=456" target="_blank">00:07:36.960</a></span> | <span class="t">And you want to talk about 3D brain MRIs, do that too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=460" target="_blank">00:07:40.560</a></span> | <span class="t">The nice thing about the forum is that as you can see, it really is buzzing now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=468" target="_blank">00:07:48.040</a></span> | <span class="t">The nice thing is that the different threads allow people to dig into the stuff that interests</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=473" target="_blank">00:07:53.360</a></span> | <span class="t">them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=474" target="_blank">00:07:54.360</a></span> | <span class="t">And I'll tell you from personal experience, the thing that I learn the most from is answering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=480" target="_blank">00:08:00.920</a></span> | <span class="t">the simplest questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=483" target="_blank">00:08:03.060</a></span> | <span class="t">So actually answering that question about a 1D convolution, I found very interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=488" target="_blank">00:08:08.080</a></span> | <span class="t">I actually didn't realize that the reflect parameter was the default parameter and I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=492" target="_blank">00:08:12.560</a></span> | <span class="t">didn't quite understand how it worked, so answering that question I found very interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=497" target="_blank">00:08:17.600</a></span> | <span class="t">And even sometimes if you know the answer, figuring out how to express it teaches you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=502" target="_blank">00:08:22.480</a></span> | <span class="t">a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=503" target="_blank">00:08:23.280</a></span> | <span class="t">So asking questions of any level is always helpful to you and to the rest of the community.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=512" target="_blank">00:08:32.160</a></span> | <span class="t">So please, if everybody only does one part of the assignments this week, do that one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=518" target="_blank">00:08:38.840</a></span> | <span class="t">Which is to ask a question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=520" target="_blank">00:08:40.280</a></span> | <span class="t">And here are some ideas about questions you could ask if you're not sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=526" target="_blank">00:08:46.240</a></span> | <span class="t">Thank you Rachel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=529" target="_blank">00:08:49.360</a></span> | <span class="t">So I was saying last week we kind of looked later in the class at this amazing visualization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=536" target="_blank">00:08:56.360</a></span> | <span class="t">of what goes on in a convolutional neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=540" target="_blank">00:09:00.440</a></span> | <span class="t">I want to show you something even cooler, which is the same thing in video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=547" target="_blank">00:09:07.800</a></span> | <span class="t">This is by an amazing guy called Jason Nusinski, his supervisor, Todd Lipson, and some other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=553" target="_blank">00:09:13.200</a></span> | <span class="t">guys.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=555" target="_blank">00:09:15.080</a></span> | <span class="t">And it's doing the same thing but in video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=558" target="_blank">00:09:18.760</a></span> | <span class="t">And so I'm going to show you what's going on here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=563" target="_blank">00:09:23.800</a></span> | <span class="t">And you can download this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=564" target="_blank">00:09:24.800</a></span> | <span class="t">It's called the Deep Visualization Toolbox.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=566" target="_blank">00:09:26.400</a></span> | <span class="t">So if you go to Google and search for the Deep Visualization Toolbox, you can do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=572" target="_blank">00:09:32.180</a></span> | <span class="t">You can grab pictures, you can click on any one of the layers of a convolutional neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=577" target="_blank">00:09:37.640</a></span> | <span class="t">network, and it will visualize every one of the outputs of the filters in that convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=586" target="_blank">00:09:46.920</a></span> | <span class="t">layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=587" target="_blank">00:09:47.920</a></span> | <span class="t">So you can see here with this dog, it looks like there's a filter here which is kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=591" target="_blank">00:09:51.480</a></span> | <span class="t">finding edges.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=592" target="_blank">00:09:52.480</a></span> | <span class="t">And you can even give it a video stream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=595" target="_blank">00:09:55.000</a></span> | <span class="t">So if you give it a video stream of your own webcam, you can see the video stream popping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=599" target="_blank">00:09:59.460</a></span> | <span class="t">up here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=602" target="_blank">00:10:02.920</a></span> | <span class="t">So this is a great tool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=604" target="_blank">00:10:04.200</a></span> | <span class="t">And looking at this tool now, I hope it will give us a better intuition about what's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=607" target="_blank">00:10:07.440</a></span> | <span class="t">on in a convolutional neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=609" target="_blank">00:10:09.300</a></span> | <span class="t">Look at this one here he selected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=610" target="_blank">00:10:10.920</a></span> | <span class="t">There's clearly an edge detector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=612" target="_blank">00:10:12.680</a></span> | <span class="t">As he slides a piece of paper over it, you get this very strong edge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=618" target="_blank">00:10:18.280</a></span> | <span class="t">And clearly it's specifically a horizontal edge detector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=621" target="_blank">00:10:21.360</a></span> | <span class="t">And here is actually a visualization of the pixels of the filter itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=624" target="_blank">00:10:24.920</a></span> | <span class="t">And it's exactly what you would expect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=626" target="_blank">00:10:26.480</a></span> | <span class="t">Remember from our initial lesson 0, an edge detector has black on one side and white on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=630" target="_blank">00:10:30.520</a></span> | <span class="t">the other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=632" target="_blank">00:10:32.200</a></span> | <span class="t">So you can scroll through all the different layers of this neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=638" target="_blank">00:10:38.360</a></span> | <span class="t">And different layers do different things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=640" target="_blank">00:10:40.280</a></span> | <span class="t">And the deeper the layer, the larger the area it covers, and therefore the smaller the actual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=647" target="_blank">00:10:47.280</a></span> | <span class="t">filter is, and the more complex the objects that it can recognize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=652" target="_blank">00:10:52.160</a></span> | <span class="t">So here's an interesting example of a layer 5 thing which it looks like it's a face detector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=658" target="_blank">00:10:58.440</a></span> | <span class="t">So you can see that as he moves his face around, this is moving around as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=663" target="_blank">00:11:03.780</a></span> | <span class="t">So one of the cool things you can do with this is you can say show me all the images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=667" target="_blank">00:11:07.640</a></span> | <span class="t">from ImageNet that match this filter as much as possible, and you can see that it's showing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=672" target="_blank">00:11:12.760</a></span> | <span class="t">us faces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=673" target="_blank">00:11:13.760</a></span> | <span class="t">This is a really cool way to understand what your neural network is doing, or what ImageNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=682" target="_blank">00:11:22.480</a></span> | <span class="t">is doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=683" target="_blank">00:11:23.480</a></span> | <span class="t">You can see other guys come along and here we are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=686" target="_blank">00:11:26.040</a></span> | <span class="t">And so here you can see the actual result in real time of the filter deconvolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=691" target="_blank">00:11:31.280</a></span> | <span class="t">and here's the actual recognition that it's doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=694" target="_blank">00:11:34.200</a></span> | <span class="t">So clearly it's a face detector which also detects cat faces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=699" target="_blank">00:11:39.520</a></span> | <span class="t">So the interesting thing about these types of neural net filters is that they're often</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=704" target="_blank">00:11:44.300</a></span> | <span class="t">pretty subtle as to how they work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=706" target="_blank">00:11:46.720</a></span> | <span class="t">They're not looking for just some fixed set of pixels, but they really understand concepts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=712" target="_blank">00:11:52.480</a></span> | <span class="t">So here's a really interesting example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=715" target="_blank">00:11:55.400</a></span> | <span class="t">Here's one of the filters in the 5th layer which seems to be like an armpit detector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=721" target="_blank">00:12:01.340</a></span> | <span class="t">So why would you have an armpit detector?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=723" target="_blank">00:12:03.680</a></span> | <span class="t">Well interestingly, what he shows here is that actually it's not an armpit detector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=727" target="_blank">00:12:07.600</a></span> | <span class="t">Because look what happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=729" target="_blank">00:12:09.240</a></span> | <span class="t">If he smooths out his fabric, this disappears.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=732" target="_blank">00:12:12.920</a></span> | <span class="t">So what this actually is, is a texture detector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=736" target="_blank">00:12:16.200</a></span> | <span class="t">It's something that detects some kind of regular texture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=743" target="_blank">00:12:23.520</a></span> | <span class="t">Here's an interesting example of one which clearly is a text detector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=747" target="_blank">00:12:27.600</a></span> | <span class="t">Now interestingly, ImageNet did not have a category called text, one of the thousand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=752" target="_blank">00:12:32.880</a></span> | <span class="t">categories is not text, but one of the thousand categories is bookshelf.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=757" target="_blank">00:12:37.800</a></span> | <span class="t">And so you can't find a bookshelf if you don't know how to find a book, and you can't find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=761" target="_blank">00:12:41.840</a></span> | <span class="t">a book if you don't know how to recognize its spine, and the way to recognize its spine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=765" target="_blank">00:12:45.560</a></span> | <span class="t">is by finding text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=767" target="_blank">00:12:47.480</a></span> | <span class="t">So this is the cool thing about these neural networks is that you don't have to tell them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=772" target="_blank">00:12:52.320</a></span> | <span class="t">what to find.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=773" target="_blank">00:12:53.860</a></span> | <span class="t">They decide what they want to find in order to solve your problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=779" target="_blank">00:12:59.520</a></span> | <span class="t">So I wanted to start at this end of "Oh my God, deep learning is really cool" and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=786" target="_blank">00:13:06.480</a></span> | <span class="t">jump back to the other end of "Oh my God, deep learning is really simple."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=791" target="_blank">00:13:11.960</a></span> | <span class="t">So everything we just saw works because of the things that we've learned about so far,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=798" target="_blank">00:13:18.080</a></span> | <span class="t">and I've got a section here called CNN Review in lesson 3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=801" target="_blank">00:13:21.920</a></span> | <span class="t">And Rachel and I have started to add some of our favorite readings about each of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=807" target="_blank">00:13:27.280</a></span> | <span class="t">pieces, but everything you just saw in that video consists of the following pieces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=813" target="_blank">00:13:33.280</a></span> | <span class="t">Matrix products, convolutions just like we saw in Excel and Python, activations such</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=822" target="_blank">00:13:42.260</a></span> | <span class="t">as ReLuse and Softmax, Stochastic Gradient Descent which is based on backpropagation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=830" target="_blank">00:13:50.120</a></span> | <span class="t">- we'll learn more about that today - and that's basically it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=834" target="_blank">00:13:54.700</a></span> | <span class="t">One of the, I think, challenging things is even if you feel comfortable with each of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=839" target="_blank">00:13:59.080</a></span> | <span class="t">these 1, 2, 3, 4, 5 pieces that are convolutional neural networks, is really understanding how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=846" target="_blank">00:14:06.960</a></span> | <span class="t">will those pieces fit together to actually do deep learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=850" target="_blank">00:14:10.920</a></span> | <span class="t">So we've got two really good resources here on putting it all together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=855" target="_blank">00:14:15.040</a></span> | <span class="t">So I'm going to go through each of these six things today as revision, but what I suggest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=862" target="_blank">00:14:22.400</a></span> | <span class="t">you do if there's any piece where you feel like I'm not quite confident, I really know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=867" target="_blank">00:14:27.480</a></span> | <span class="t">what a convolution is or I really know what an activation function is, see if this information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=872" target="_blank">00:14:32.440</a></span> | <span class="t">is helpful and maybe ask a question on the forum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=878" target="_blank">00:14:38.860</a></span> | <span class="t">So let's go through each of these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=880" target="_blank">00:14:40.840</a></span> | <span class="t">I think a particularly good place to start maybe is with convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=887" target="_blank">00:14:47.120</a></span> | <span class="t">And a good reason to start with convolutions is because we haven't really looked at them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=890" target="_blank">00:14:50.980</a></span> | <span class="t">since Lesson 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=893" target="_blank">00:14:53.480</a></span> | <span class="t">And that was quite a while ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=894" target="_blank">00:14:54.800</a></span> | <span class="t">So let's remind ourselves about Lesson 0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=900" target="_blank">00:15:00.720</a></span> | <span class="t">So in Lesson 0, we learned about what a convolution is and we learned about what a convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=905" target="_blank">00:15:05.500</a></span> | <span class="t">is by actually running a convolution against an image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=910" target="_blank">00:15:10.440</a></span> | <span class="t">So we used the MNIST dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=912" target="_blank">00:15:12.760</a></span> | <span class="t">The MNIST dataset, remember, consists of 55,000 28x28 grayscale images of handwritten digits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=924" target="_blank">00:15:24.200</a></span> | <span class="t">So each one of these has some known label, and so here's five examples with a known label.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=933" target="_blank">00:15:33.620</a></span> | <span class="t">So in order to understand what a convolution is, we tried creating a simple little 3x3 matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=941" target="_blank">00:15:41.380</a></span> | <span class="t">And so the 3x3 matrix we started with had negative 1s at the top, 1s in the middle, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=947" target="_blank">00:15:47.080</a></span> | <span class="t">0s at the bottom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=948" target="_blank">00:15:48.560</a></span> | <span class="t">So we could kind of visualize that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=952" target="_blank">00:15:52.240</a></span> | <span class="t">So what would happen if we took this 3x3 matrix and we slid it over every 3x3 part of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=961" target="_blank">00:16:01.420</a></span> | <span class="t">image and we multiplied negative 1 by the first pixel, negative 1 by the second pixel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=967" target="_blank">00:16:07.560</a></span> | <span class="t">and then move to the next row and multiply by 1, 1, 1, 0, 0, 0, and add them all together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=976" target="_blank">00:16:16.140</a></span> | <span class="t">And so we could do that for every 3x3 area.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=981" target="_blank">00:16:21.120</a></span> | <span class="t">That's what a convolution does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=983" target="_blank">00:16:23.920</a></span> | <span class="t">So you might remember from Lesson 0, we looked at a little area to actually see what this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=989" target="_blank">00:16:29.840</a></span> | <span class="t">looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=991" target="_blank">00:16:31.120</a></span> | <span class="t">So we could zoom in, so here's a little small little bit of the 7.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1003" target="_blank">00:16:43.440</a></span> | <span class="t">And so one thing I think is helpful is just to look at what is that little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1011" target="_blank">00:16:51.280</a></span> | <span class="t">Let's make it a bit smaller so it fits on our screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1017" target="_blank">00:16:57.280</a></span> | <span class="t">So you can see that an image just is a bunch of numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1023" target="_blank">00:17:03.240</a></span> | <span class="t">And the blacks are zeros and the things in between bigger and bigger numbers until eventually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1028" target="_blank">00:17:08.440</a></span> | <span class="t">the whites are very close to 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1031" target="_blank">00:17:11.100</a></span> | <span class="t">So what would happen if we took this little 3x3 area?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1033" target="_blank">00:17:13.960</a></span> | <span class="t">0, 0, 0, 0, 0.35, 0.5, 0.9, 0.9, 0.9, and we multiplied each of those 9 things by each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1045" target="_blank">00:17:25.400</a></span> | <span class="t">of these 9 things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1047" target="_blank">00:17:27.720</a></span> | <span class="t">So clearly anywhere where the first row is zeros and the second row is ones, this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1058" target="_blank">00:17:38.000</a></span> | <span class="t">going to be very high when we multiply it all together and add the 9 things up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1062" target="_blank">00:17:42.720</a></span> | <span class="t">And so given that white means high, you can see then that when we do this convolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1073" target="_blank">00:17:53.680</a></span> | <span class="t">we end up with something where the top edges become bright because we went -1, -1, -1 times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1082" target="_blank">00:18:02.840</a></span> | <span class="t">1, 1, 1 times 0, 0, 0 and added them all together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1087" target="_blank">00:18:07.040</a></span> | <span class="t">So one of the things we looked at in lesson 0 and we have a link to here is this cool</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1091" target="_blank">00:18:11.840</a></span> | <span class="t">little image kernel explained visually site where you can actually create any 3x3 matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1101" target="_blank">00:18:21.600</a></span> | <span class="t">yourself and go through any 3x3 part of this picture and see the actual arithmetic and see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1112" target="_blank">00:18:32.400</a></span> | <span class="t">the result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1114" target="_blank">00:18:34.480</a></span> | <span class="t">So if you're not comfortable with convolutions, this would be a great place to go next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1125" target="_blank">00:18:45.520</a></span> | <span class="t">That's an excellent question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1127" target="_blank">00:18:47.160</a></span> | <span class="t">How did you decide on the values of the top matrix?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1132" target="_blank">00:18:52.240</a></span> | <span class="t">So in order to demonstrate an edge filter, I picked values based on some well-known edge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1141" target="_blank">00:19:01.260</a></span> | <span class="t">filter matrices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1142" target="_blank">00:19:02.260</a></span> | <span class="t">So you can see here's a bunch of different matrices that this guy has.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1146" target="_blank">00:19:06.040</a></span> | <span class="t">So for example, top_sobel, I could select, and you can see that does a top_edge filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1152" target="_blank">00:19:12.180</a></span> | <span class="t">Or I could say emboss, and you can see it creates this embossing sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1159" target="_blank">00:19:19.760</a></span> | <span class="t">Here's a better example because it's nice and big here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1165" target="_blank">00:19:25.520</a></span> | <span class="t">So these types of filters have been created over many decades, and there's lots and lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1170" target="_blank">00:19:30.880</a></span> | <span class="t">of filters designed to do interesting things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1174" target="_blank">00:19:34.800</a></span> | <span class="t">So I just picked a simple filter which I knew from experience and from common sense would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1191" target="_blank">00:19:51.040</a></span> | <span class="t">create a top edge filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1193" target="_blank">00:19:53.320</a></span> | <span class="t">And so by the same kind of idea, if I rotate that by 90 degrees, that's going to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1202" target="_blank">00:20:02.200</a></span> | <span class="t">a left-hand edge filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1205" target="_blank">00:20:05.040</a></span> | <span class="t">So if I create the four different types of filter here, and I could also create four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1209" target="_blank">00:20:09.980</a></span> | <span class="t">different diagonal filters like these, that would allow me to create top edge, left edge,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1216" target="_blank">00:20:16.840</a></span> | <span class="t">bottom edge, right edge, and then each diagonal edge filter here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1221" target="_blank">00:20:21.560</a></span> | <span class="t">So I created these filters just by hand through a combination of common sense and having read</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1229" target="_blank">00:20:29.440</a></span> | <span class="t">about filters because people spend time designing filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1235" target="_blank">00:20:35.040</a></span> | <span class="t">The more interesting question then really is what would be the optimal way to design</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1241" target="_blank">00:20:41.200</a></span> | <span class="t">filters?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1242" target="_blank">00:20:42.460</a></span> | <span class="t">Because it's definitely not the case that these eight filters are the best way of figuring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1248" target="_blank">00:20:48.800</a></span> | <span class="t">out what's a 7 and what's an 8 and what's a 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1253" target="_blank">00:20:53.160</a></span> | <span class="t">So this is what deep learning does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1256" target="_blank">00:20:56.040</a></span> | <span class="t">What deep learning does is it says let's start with random filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1261" target="_blank">00:21:01.320</a></span> | <span class="t">So let's not design them, but we'll start with totally random numbers for each of our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1265" target="_blank">00:21:05.520</a></span> | <span class="t">filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1266" target="_blank">00:21:06.520</a></span> | <span class="t">So we might start with eight random filters, each of 3x3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1272" target="_blank">00:21:12.200</a></span> | <span class="t">And we then use stochastic gradient descent to find out what are the optimal values of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1279" target="_blank">00:21:19.320</a></span> | <span class="t">each of those sets of 9 numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1283" target="_blank">00:21:23.300</a></span> | <span class="t">And that's what happens in order to create that cool video we just saw, and that cool</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1288" target="_blank">00:21:28.640</a></span> | <span class="t">paper that we saw.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1289" target="_blank">00:21:29.800</a></span> | <span class="t">That's how those different kinds of edge detectors and gradient detectors and so forth were created.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1294" target="_blank">00:21:34.880</a></span> | <span class="t">When you use stochastic gradient descent to optimize these kinds of values when they start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1299" target="_blank">00:21:39.980</a></span> | <span class="t">out random, it figures out that the best way to recognize images is by creating these kinds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1306" target="_blank">00:21:46.600</a></span> | <span class="t">of different detectors, different filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1312" target="_blank">00:21:52.600</a></span> | <span class="t">Where it gets interesting is when you start building convolutions on top of convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1319" target="_blank">00:21:59.640</a></span> | <span class="t">So we saw last week that we can create a bunch of inputs, so if I don't, please remind me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1343" target="_blank">00:22:23.480</a></span> | <span class="t">So we saw last week how if you've got three inputs, you can create a bunch of weight matrices,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1350" target="_blank">00:22:30.780</a></span> | <span class="t">so we can create one weight matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1355" target="_blank">00:22:35.960</a></span> | <span class="t">So if we've got three inputs, we saw last week how you could create a random matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1361" target="_blank">00:22:41.280</a></span> | <span class="t">and then do a matrix multiply of the inputs times a random matrix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1369" target="_blank">00:22:49.180</a></span> | <span class="t">We could then put it through an activation function such as max(0,x) and we could then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1378" target="_blank">00:22:58.600</a></span> | <span class="t">take that and multiply it by another weight matrix to create another output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1385" target="_blank">00:23:05.260</a></span> | <span class="t">And then we could put that through max(0,x) and we can keep doing that to create arbitrarily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1392" target="_blank">00:23:12.240</a></span> | <span class="t">complex functions. And we looked at this really great neural networks and deep learning chapter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1402" target="_blank">00:23:22.600</a></span> | <span class="t">where we saw visually how that kind of bunch of matrix products followed by activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1408" target="_blank">00:23:28.960</a></span> | <span class="t">functions can approximate any given function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1416" target="_blank">00:23:36.280</a></span> | <span class="t">So where it gets interesting then is instead of just having a bunch of weight matrices and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1422" target="_blank">00:23:42.880</a></span> | <span class="t">matrix products, what if sometimes we had convolutions and activations? Because a convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1431" target="_blank">00:23:51.120</a></span> | <span class="t">is just a subset of a matrix product, so if you think about it, a matrix product says</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1436" target="_blank">00:23:56.200</a></span> | <span class="t">here's 10 activations and then a weight matrix going down to 10 activations. The weight matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1443" target="_blank">00:24:03.120</a></span> | <span class="t">goes from every single element of the first layer to every single element of the next layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1448" target="_blank">00:24:08.280</a></span> | <span class="t">So if this goes from 10 to 10, there are 100 weights. Whereas a convolution is just creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1454" target="_blank">00:24:14.400</a></span> | <span class="t">a subset of those weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1457" target="_blank">00:24:17.400</a></span> | <span class="t">So I'll let you think about this during the week because it's a really interesting insight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1460" target="_blank">00:24:20.480</a></span> | <span class="t">to think about that a convolution is identical to a fully connected layer, but it's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1467" target="_blank">00:24:27.360</a></span> | <span class="t">a subset of the weights. And so therefore everything we learned about stacking linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1475" target="_blank">00:24:35.680</a></span> | <span class="t">and nonlinear layers together applies also to convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1480" target="_blank">00:24:40.960</a></span> | <span class="t">But we also know that convolutions are particularly well-suited to identifying interesting features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1487" target="_blank">00:24:47.240</a></span> | <span class="t">of images. So by using convolutions, it allows us to more conveniently and quickly find powerful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1497" target="_blank">00:24:57.920</a></span> | <span class="t">deep learning networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1500" target="_blank">00:25:00.440</a></span> | <span class="t">So the spreadsheet will be available for download tomorrow. We're trying to get to the point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1518" target="_blank">00:25:18.200</a></span> | <span class="t">that we can actually get the derivatives to work in the spreadsheet and we're still slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1521" target="_blank">00:25:21.280</a></span> | <span class="t">stuck with some of the details, but we'll make something available tomorrow. Are the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1528" target="_blank">00:25:28.240</a></span> | <span class="t">filters the layers? Yes they are. So this is something where spending a lot of time looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1537" target="_blank">00:25:37.880</a></span> | <span class="t">at simple little convolution examples is really helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1544" target="_blank">00:25:44.240</a></span> | <span class="t">Because for a fully connected layer, it's pretty easy. You can see if I have 3 inputs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1549" target="_blank">00:25:49.040</a></span> | <span class="t">then my matrix product will have to have 3 rows, otherwise they won't match. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1554" target="_blank">00:25:54.840</a></span> | <span class="t">I can create as many columns as I like. And the number of columns I create tells me how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1559" target="_blank">00:25:59.500</a></span> | <span class="t">many activations I create because that's what matrix products do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1564" target="_blank">00:26:04.640</a></span> | <span class="t">So it's very easy to see how with what Keras calls dense layers, I can decide how big I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1571" target="_blank">00:26:11.040</a></span> | <span class="t">want each activation layer to be. If you think about it, you can do exactly the same thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1578" target="_blank">00:26:18.560</a></span> | <span class="t">with convolutions. You can decide how many sets of 3x3 matrices you want to create at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1587" target="_blank">00:26:27.320</a></span> | <span class="t">random, and each one will generate a different output when applied to the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1594" target="_blank">00:26:34.160</a></span> | <span class="t">So the way that VGG works, for example, so the VGG network, which we learned about in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1608" target="_blank">00:26:48.840</a></span> | <span class="t">Lesson 1, contains a bunch of layers. It contains a bunch of convolutional layers, followed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1621" target="_blank">00:27:01.200</a></span> | <span class="t">by a flatten. And all flatten does is just a Keras thing that says don't think of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1627" target="_blank">00:27:07.280</a></span> | <span class="t">layers anymore as being x by y by channel matrices, think of them as being a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1635" target="_blank">00:27:15.480</a></span> | <span class="t">vector. So it just concatenates all the dimensions together, and then it contains a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1640" target="_blank">00:27:20.720</a></span> | <span class="t">fully connected blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1642" target="_blank">00:27:22.600</a></span> | <span class="t">And so each of the convolutional blocks is -- you can kind of ignore the zero padding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1649" target="_blank">00:27:29.800</a></span> | <span class="t">that just adds zeros around the outside so that your convolutions end up with the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1654" target="_blank">00:27:34.520</a></span> | <span class="t">number of outputs as inputs. It contains a 2D convolution, followed by, and we'll review</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1660" target="_blank">00:27:40.720</a></span> | <span class="t">this in a moment, a max pooling layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1664" target="_blank">00:27:44.840</a></span> | <span class="t">You can see that it starts off with 2 convolutional layers with 64 filters, and then 2 convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1672" target="_blank">00:27:52.360</a></span> | <span class="t">layers with 128 filters, and then 3 convolutional layers with 256 filters. And so you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1676" target="_blank">00:27:56.960</a></span> | <span class="t">what it's doing is it's gradually creating more and more filters in each layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1688" target="_blank">00:28:08.040</a></span> | <span class="t">These definitions of block are specific to VGG, so I just created -- this is just me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1692" target="_blank">00:28:12.960</a></span> | <span class="t">refactoring the model so there wasn't lots and lots of lines of code. So I just didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1697" target="_blank">00:28:17.080</a></span> | <span class="t">want to retype lots of code, so I kind of found that these lines of code were being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1701" target="_blank">00:28:21.480</a></span> | <span class="t">repeated so I turned it into a function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1704" target="_blank">00:28:24.660</a></span> | <span class="t">So why would we be having the number of filters being increasing? Well, the best way to understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1711" target="_blank">00:28:31.560</a></span> | <span class="t">a model is to use the summary command. So let's go back to lesson 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1731" target="_blank">00:28:51.000</a></span> | <span class="t">So let's go right back to our first thing we learned, which was the 7 lines of code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1736" target="_blank">00:28:56.560</a></span> | <span class="t">that you can run in order to create and train a network. I won't wait for it to actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1747" target="_blank">00:29:07.520</a></span> | <span class="t">finish training, but what I do want to do now is go vgg.model.summary. So anytime you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1758" target="_blank">00:29:18.560</a></span> | <span class="t">creating models, it's a really good idea to use the summary command to look inside them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1761" target="_blank">00:29:21.960</a></span> | <span class="t">and it tells you all about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1765" target="_blank">00:29:25.680</a></span> | <span class="t">So here we can see that the input to our model has 3 channels, red, green and blue, and they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1772" target="_blank">00:29:32.840</a></span> | <span class="t">are 224x224 images. After I do my first 2D convolution, I now have 64 channels of 224x224.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1787" target="_blank">00:29:47.320</a></span> | <span class="t">So I've replaced my 3 channels with 64, just like here I've got 8 different filters, here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1798" target="_blank">00:29:58.160</a></span> | <span class="t">I've got 64 different filters because that's what I asked for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1807" target="_blank">00:30:07.360</a></span> | <span class="t">So again we have a second convolution set with 224x224 of 64, and then we do max pooling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1817" target="_blank">00:30:17.800</a></span> | <span class="t">So max pooling, remember from lesson 0, was this thing where we simplified things. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1825" target="_blank">00:30:25.440</a></span> | <span class="t">we started out with these 28x28 images and we said let's take each 7x7 block and replace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1833" target="_blank">00:30:33.620</a></span> | <span class="t">that entire 7x7 block with a single pixel which contains the maximum pixel value. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1840" target="_blank">00:30:40.880</a></span> | <span class="t">here is this 7x7 block which is basically all gray, so we end up with a very low number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1848" target="_blank">00:30:48.060</a></span> | <span class="t">here. And so instead of being 28x28, it becomes 4x4 because we are replacing every 7x7 block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1858" target="_blank">00:30:58.760</a></span> | <span class="t">with a single pixel. That's all max pooling does. So the reason we have max pooling is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1866" target="_blank">00:31:06.080</a></span> | <span class="t">it allows us to gradually simplify our image so that we get larger and larger areas and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1873" target="_blank">00:31:13.720</a></span> | <span class="t">smaller and smaller images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1876" target="_blank">00:31:16.440</a></span> | <span class="t">So if we look at VGG, after our max pooling layer, we now longer have 224x224, we now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1882" target="_blank">00:31:22.880</a></span> | <span class="t">have 112x112. Later on we do another max pooling, we end up with 56x56. Later on we do another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1894" target="_blank">00:31:34.520</a></span> | <span class="t">max pooling and we end up with 28x28. So each time we do a max pooling we're reducing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1904" target="_blank">00:31:44.880</a></span> | <span class="t">resolution of our image. As we're reducing the resolution, we need to high cut the number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1916" target="_blank">00:31:56.240</a></span> | <span class="t">of filters otherwise we're losing information. So that's really why each time we have a max</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1924" target="_blank">00:32:04.000</a></span> | <span class="t">pooling, we then double the number of filters because that means that every layer we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1929" target="_blank">00:32:09.200</a></span> | <span class="t">keeping the same amount of information content.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1932" target="_blank">00:32:12.320</a></span> | <span class="t">So it starts out with a very, very important insight, which is a very important insight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1961" target="_blank">00:32:41.760</a></span> | <span class="t">which is a convolution is position invariant. So in other words, this thing we created which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1967" target="_blank">00:32:47.960</a></span> | <span class="t">is a top edge detector, we can apply that to any part of the image and get top edges from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1984" target="_blank">00:33:04.580</a></span> | <span class="t">every part of the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1986" target="_blank">00:33:06.280</a></span> | <span class="t">And earlier on when we looked at that Jason Nusinski video, it showed that there was a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1990" target="_blank">00:33:10.600</a></span> | <span class="t">face detector which could find a face in any part of the image. So this is fundamental to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=1996" target="_blank">00:33:16.680</a></span> | <span class="t">how a convolution works. A convolution is a position invariant. It finds a pattern regardless</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2002" target="_blank">00:33:22.680</a></span> | <span class="t">of where abouts an image is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2005" target="_blank">00:33:25.280</a></span> | <span class="t">Now that is a very powerful idea because when we want to say find a face, we want to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2012" target="_blank">00:33:32.120</a></span> | <span class="t">able to find eyes. And we want to be able to find eyes regardless of whether the face</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2017" target="_blank">00:33:37.080</a></span> | <span class="t">is in the top left or the bottom right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2020" target="_blank">00:33:40.600</a></span> | <span class="t">So position invariance is important, but also we need to be able to identify position to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2027" target="_blank">00:33:47.000</a></span> | <span class="t">some extent because if there's four eyes in the picture, or if there's an eye in the top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2032" target="_blank">00:33:52.680</a></span> | <span class="t">corner and the bottom corner, then something weird is going on, or if the eyes and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2037" target="_blank">00:33:57.080</a></span> | <span class="t">nose aren't in the right positions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2039" target="_blank">00:33:59.800</a></span> | <span class="t">So how does a convolutional neural network both have this location invariant filter but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2047" target="_blank">00:34:07.960</a></span> | <span class="t">also handle location? And the trick is that every one of the 3x3 filters cares deeply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2056" target="_blank">00:34:16.640</a></span> | <span class="t">about where each of these 3x3 things is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2060" target="_blank">00:34:20.280</a></span> | <span class="t">And so as we go down through the layers of our model from 224 to 112 to 56 to 28 to 14</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2071" target="_blank">00:34:31.080</a></span> | <span class="t">to 7, at each one of these stages (think about this stage which goes from 14x14 to 7x7),</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2080" target="_blank">00:34:40.320</a></span> | <span class="t">these filters are now looking at large parts of the image. So it's now at a point where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2084" target="_blank">00:34:44.280</a></span> | <span class="t">it can actually say there needs to be an eye here and an eye here and a nose here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2092" target="_blank">00:34:52.160</a></span> | <span class="t">So this is one of the cool things about convolutional neural networks. They can find features everywhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2097" target="_blank">00:34:57.640</a></span> | <span class="t">but they can also build things which care about how features relate to each other positionally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2102" target="_blank">00:35:02.920</a></span> | <span class="t">So you get to do both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2129" target="_blank">00:35:29.220</a></span> | <span class="t">So do we need zero padding? Zero padding is literally something that sticks zeros around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2135" target="_blank">00:35:35.120</a></span> | <span class="t">the outside of an image. If you think about what a convolution does, it's taking a 3x3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2141" target="_blank">00:35:41.640</a></span> | <span class="t">and moving it over an image. If you do that, when you get to the edge, what do you do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2148" target="_blank">00:35:48.960</a></span> | <span class="t">Because at the very edge, you can't move your 3x3 any further. Which means if you only do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2155" target="_blank">00:35:55.140</a></span> | <span class="t">what's called a valid convolution, which means you always make sure your 3x3 filter fits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2159" target="_blank">00:35:59.960</a></span> | <span class="t">entirely within your image, you end up losing 2 pixels from the sides and 2 pixels from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2166" target="_blank">00:36:06.720</a></span> | <span class="t">the top each time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2169" target="_blank">00:36:09.320</a></span> | <span class="t">There's actually nothing wrong with that, but it's a little inelegant. It's kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2175" target="_blank">00:36:15.120</a></span> | <span class="t">nice to be able to half the size each time and be able to see exactly what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2179" target="_blank">00:36:19.520</a></span> | <span class="t">So people tend to often like doing what's called same convolutions. So if you add a black border</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2185" target="_blank">00:36:25.620</a></span> | <span class="t">around the outside, then the result of your convolution is exactly the same size as your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2190" target="_blank">00:36:30.920</a></span> | <span class="t">input. That is literally the only reason to do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2194" target="_blank">00:36:34.740</a></span> | <span class="t">In fact, this is a rather inelegant way of going zero padding and then convolution. In</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2199" target="_blank">00:36:39.520</a></span> | <span class="t">fact, there's a parameter to nearly every library's convolution function where you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2204" target="_blank">00:36:44.200</a></span> | <span class="t">say "I want valid" or "full" or "half" which basically means do you add no black pixels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2212" target="_blank">00:36:52.560</a></span> | <span class="t">one black pixels or two black pixels, assuming it's 3x3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2217" target="_blank">00:36:57.240</a></span> | <span class="t">So I don't quite know why this one does it this way. It's really doing two functions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2221" target="_blank">00:37:01.660</a></span> | <span class="t">where one would have done, but it does the job. So there's no right answer to that question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2232" target="_blank">00:37:12.840</a></span> | <span class="t">All neural networks work fine for cartoons. The question was do they work for cartoons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2239" target="_blank">00:37:19.080</a></span> | <span class="t">However, fine-tuning, which has been fundamental to everything we've learned so far, it's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2247" target="_blank">00:37:27.240</a></span> | <span class="t">to be difficult to fine-tune from an ImageNet model to a cartoon. Because an ImageNet model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2253" target="_blank">00:37:33.800</a></span> | <span class="t">was built on all those pictures of corn we looked at and all those pictures of dogs we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2257" target="_blank">00:37:37.560</a></span> | <span class="t">looked at. So an ImageNet model has learned to find the kinds of features that are in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2263" target="_blank">00:37:43.480</a></span> | <span class="t">photos of objects out there in the world. And those are very different kinds of photos to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2268" target="_blank">00:37:48.640</a></span> | <span class="t">what you see in a cartoon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2271" target="_blank">00:37:51.400</a></span> | <span class="t">So if you want to be able to build a cartoon neural network, you'll need to either find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2278" target="_blank">00:37:58.100</a></span> | <span class="t">somebody else who has already trained a neural network on cartoons and fine-tune that, or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2283" target="_blank">00:38:03.600</a></span> | <span class="t">you're going to have to create a really big corpus of cartoons and create your own ImageNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2289" target="_blank">00:38:09.400</a></span> | <span class="t">equivalent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2304" target="_blank">00:38:24.400</a></span> | <span class="t">So why doesn't an ImageNet network translate to cartoons given that an eye is a circle?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2312" target="_blank">00:38:32.200</a></span> | <span class="t">Because the nuance level of a CNN is very high. It doesn't think of an eye as being just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2320" target="_blank">00:38:40.160</a></span> | <span class="t">a circle. It knows that an eye very specifically has particular gradients and particular shapes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2325" target="_blank">00:38:45.800</a></span> | <span class="t">and particular ways that the light reflects off it and so forth. So when it sees a round</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2331" target="_blank">00:38:51.880</a></span> | <span class="t">blob there, it has no ability to abstract that out and say I guess they mean an eye. One</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2341" target="_blank">00:39:01.440</a></span> | <span class="t">of the big shortcomings of CNNs is that they can only learn to recognize things that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2346" target="_blank">00:39:06.920</a></span> | <span class="t">specifically give them to recognize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2350" target="_blank">00:39:10.280</a></span> | <span class="t">If you feed a neural net with a wide range of photos and drawings, maybe it would learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2358" target="_blank">00:39:18.640</a></span> | <span class="t">about that kind of abstraction. To my knowledge, that's never been done. It would be a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2363" target="_blank">00:39:23.680</a></span> | <span class="t">interesting question. It must be possible. I'm just not sure how many examples you would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2368" target="_blank">00:39:28.880</a></span> | <span class="t">need and what kind of architecture you would need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2371" target="_blank">00:39:31.960</a></span> | <span class="t">In this particular example, I used correlate, not convolution. One of the things we briefly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2389" target="_blank">00:39:49.720</a></span> | <span class="t">mentioned in lesson 1 is that convolve and correlate are exactly the same thing, except</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2399" target="_blank">00:39:59.680</a></span> | <span class="t">convolve is equal to correlate of an image with a filter that has been rotated by 90</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2406" target="_blank">00:40:06.560</a></span> | <span class="t">degrees. So you can see convolve images with rotated 90 degrees filter looks exactly the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2414" target="_blank">00:40:14.200</a></span> | <span class="t">same and numpy.all_close is true. So convolve and correlate are identical except that correlate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2424" target="_blank">00:40:24.760</a></span> | <span class="t">is more intuitive. In each one it goes rows and then columns, where else with convolve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2433" target="_blank">00:40:33.160</a></span> | <span class="t">one goes along rows and the other one goes down columns. So I tend to prefer to think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2438" target="_blank">00:40:38.280</a></span> | <span class="t">about correlate because it's just more intuitive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2442" target="_blank">00:40:42.680</a></span> | <span class="t">Convolve originally came really from physics, I think, and it's also a basic math operation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2449" target="_blank">00:40:49.720</a></span> | <span class="t">There are various reasons that people sometimes find it more intuitive to think about convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2454" target="_blank">00:40:54.600</a></span> | <span class="t">but in terms of everything that they can do in a neural net, it doesn't matter which one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2460" target="_blank">00:41:00.360</a></span> | <span class="t">you're using. In fact, many libraries let you set a parameter to true or false to decide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2466" target="_blank">00:41:06.120</a></span> | <span class="t">whether or not internally it uses convolution or correlation. And of course the results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2470" target="_blank">00:41:10.320</a></span> | <span class="t">are going to be identical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2472" target="_blank">00:41:12.080</a></span> | <span class="t">So let's go back to our CNN review. Our network architecture is a bunch of matrix products</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2487" target="_blank">00:41:27.720</a></span> | <span class="t">or in more generally linear layers, and remember a convolution is just a subset of a matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2494" target="_blank">00:41:34.040</a></span> | <span class="t">product so it's also a linear layer, a bunch of matrix products or convolutions stacked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2499" target="_blank">00:41:39.120</a></span> | <span class="t">with alternating nonlinear activation functions. And specifically we looked at the activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2506" target="_blank">00:41:46.360</a></span> | <span class="t">function which was the rectified linear unit, which is just max of 0, x. So that's an incredibly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2515" target="_blank">00:41:55.160</a></span> | <span class="t">simple activation function, but it's by far the most common, it works really well, for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2521" target="_blank">00:42:01.240</a></span> | <span class="t">the internal parts of a neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2524" target="_blank">00:42:04.760</a></span> | <span class="t">I want to introduce one more activation function today, and you can read more about it in Lesson</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2530" target="_blank">00:42:10.960</a></span> | <span class="t">2. Let's go down here where it says About Activation Functions. And you can see I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2546" target="_blank">00:42:26.680</a></span> | <span class="t">got all the details of these activation functions here. I want to talk about one core.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2554" target="_blank">00:42:34.720</a></span> | <span class="t">It's called the Softmax function, and Softmax is defined as follows, e^xi divided by sum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2562" target="_blank">00:42:42.880</a></span> | <span class="t">of e^xi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2566" target="_blank">00:42:46.460</a></span> | <span class="t">What is this all about? Softmax is used not for the middle layers of a deep learning network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2572" target="_blank">00:42:52.920</a></span> | <span class="t">but for the last layer. The last layer of a neural network, if you think about what it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2577" target="_blank">00:42:57.360</a></span> | <span class="t">trying to do for classification, it's trying to match to a one-hot encoded output. Remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2583" target="_blank">00:43:03.760</a></span> | <span class="t">a one-hot encoded output is a vector with all zeros and just a 1 in one spot. The spot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2590" target="_blank">00:43:10.320</a></span> | <span class="t">is like we had for cats and dogs two spots, the first one was a 1 if it was a cat, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2596" target="_blank">00:43:16.400</a></span> | <span class="t">second one was a 1 if it was a dog.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2599" target="_blank">00:43:19.440</a></span> | <span class="t">So in general, if we're doing classification, we want our output to have one high number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2606" target="_blank">00:43:26.600</a></span> | <span class="t">and all the other ones be low. That's going to be easier to create this one-hot encoded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2611" target="_blank">00:43:31.680</a></span> | <span class="t">output. Furthermore, we would like to be able to interpret these as probabilities, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2616" target="_blank">00:43:36.440</a></span> | <span class="t">means all of the outputs have to add to 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2619" target="_blank">00:43:39.000</a></span> | <span class="t">So we've got these two requirements here. Our final layer's activations should add to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2622" target="_blank">00:43:42.480</a></span> | <span class="t">one, and one of them should be higher than all the rest. This particular function does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2630" target="_blank">00:43:50.120</a></span> | <span class="t">exactly that, and we will look at that by looking at a spreadsheet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2635" target="_blank">00:43:55.980</a></span> | <span class="t">So here is an example of what an output layer might contain. Here is e^of each of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2645" target="_blank">00:44:05.720</a></span> | <span class="t">things to the left. Here is the sum of e^of those things. And then here is the thing to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2655" target="_blank">00:44:15.080</a></span> | <span class="t">the left divided by the sum of them, in other words, softmax. And you can see that we start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2663" target="_blank">00:44:23.680</a></span> | <span class="t">with a bunch of numbers that are all of a similar kind of scale. And we end up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2668" target="_blank">00:44:28.160</a></span> | <span class="t">a bunch of numbers that sum to 1, and one of them is much higher than the others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2674" target="_blank">00:44:34.280</a></span> | <span class="t">So in general, when we design neural networks, we want to come up with architectures, by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2683" target="_blank">00:44:43.480</a></span> | <span class="t">which I mean convolutions, fully connected layers, activation functions, we want to come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2691" target="_blank">00:44:51.480</a></span> | <span class="t">up with architectures where replicating the outcome we want is as convenient as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2700" target="_blank">00:45:00.380</a></span> | <span class="t">So in this case, our activation function for the last layer makes it pretty convenient,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2705" target="_blank">00:45:05.720</a></span> | <span class="t">pretty easy to come up with something that looks a lot like a 1-watt encoded output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2711" target="_blank">00:45:11.280</a></span> | <span class="t">So the easier it is for our neural net to create the thing we want, the faster it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2716" target="_blank">00:45:16.260</a></span> | <span class="t">going to get there, and the more likely it is to get there in a way that's quite accurate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2721" target="_blank">00:45:21.200</a></span> | <span class="t">So we've learned that any big enough, deep enough neural network, because of the Universal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2729" target="_blank">00:45:29.480</a></span> | <span class="t">Approximation Theorem, can approximate any function at all. And we know that Stochastic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2735" target="_blank">00:45:35.600</a></span> | <span class="t">Gradient Descent can find the parameters for any of these, which kind of leaves you thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2739" target="_blank">00:45:39.920</a></span> | <span class="t">why do we need 7 weeks of neural network training? Any architecture ought to work. And indeed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2747" target="_blank">00:45:47.520</a></span> | <span class="t">that's true. If you have long enough, any architecture will work. Any architecture can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2753" target="_blank">00:45:53.040</a></span> | <span class="t">translate Hungarian to English, any architecture can recognize cats versus dogs, any architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2758" target="_blank">00:45:58.640</a></span> | <span class="t">can analyze Hillary Clinton's emails, as long as it's big enough. However, some of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2764" target="_blank">00:46:04.480</a></span> | <span class="t">do it much faster than others. They train much faster than others. A bad architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2771" target="_blank">00:46:11.560</a></span> | <span class="t">could take so long to train that it doesn't train in the amount of years you have left</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2776" target="_blank">00:46:16.040</a></span> | <span class="t">in your lifetime. And that's why we care about things like convolutional neural networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2781" target="_blank">00:46:21.400</a></span> | <span class="t">instead of just fully connected layers all the way through. That's why we care about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2786" target="_blank">00:46:26.340</a></span> | <span class="t">having a softmax at the last layer rather than just a linear last layer. So we try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2790" target="_blank">00:46:30.760</a></span> | <span class="t">make it as convenient as possible for our network to create the thing that we want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2794" target="_blank">00:46:34.800</a></span> | <span class="t">create. Yes, Rachel? [audience question]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2817" target="_blank">00:46:57.800</a></span> | <span class="t">So the first one was? Softmax, just like the other one, is about how Keras internally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2829" target="_blank">00:47:09.800</a></span> | <span class="t">handles these matrices of data. Any more information about that one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2835" target="_blank">00:47:15.800</a></span> | <span class="t">Honestly, I don't do theoretical justifications, I do intuitive justifications. There is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2855" target="_blank">00:47:35.760</a></span> | <span class="t">great book for theoretical justifications and it's available for free. If you just google</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2860" target="_blank">00:47:40.840</a></span> | <span class="t">for Deep Learning Book, or indeed go to deeplearningbook.org, it actually does have a fantastic theoretical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2868" target="_blank">00:47:48.000</a></span> | <span class="t">justification of why we use softmax. The short version basically is as follows. Softmax contains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2876" target="_blank">00:47:56.400</a></span> | <span class="t">an eta in it, our log-loss layer contains a log in it, the two nicely mesh up against</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2885" target="_blank">00:48:05.800</a></span> | <span class="t">each other and in fact the derivative of the two together is just a - b. So that's kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2892" target="_blank">00:48:12.560</a></span> | <span class="t">of the short version, but I will refer you to the Deep Learning Book for more information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2896" target="_blank">00:48:16.480</a></span> | <span class="t">about the theoretical justification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2898" target="_blank">00:48:18.680</a></span> | <span class="t">The intuitive justification is that because we have an eta here, it makes a big number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2904" target="_blank">00:48:24.320</a></span> | <span class="t">really really big, and therefore once we take one divided by the sum of the others, we end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2909" target="_blank">00:48:29.960</a></span> | <span class="t">up with one number that tends to be bigger than all the rest, and that is very close</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2913" target="_blank">00:48:33.840</a></span> | <span class="t">to the one-hot encoded output that we're trying to match.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2919" target="_blank">00:48:39.960</a></span> | <span class="t">Could a network learn identical filters? A network absolutely could learn identical filters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2929" target="_blank">00:48:49.840</a></span> | <span class="t">but it won't. The reason it won't is because it's not optimal to. Stochastic gradient descent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2936" target="_blank">00:48:56.200</a></span> | <span class="t">is an optimization procedure. It will come up with, if you train it for long enough,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2941" target="_blank">00:49:01.640</a></span> | <span class="t">with an appropriate learning rate, the optimal set of filters. Having the same filter twice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2947" target="_blank">00:49:07.080</a></span> | <span class="t">is never optimal, that's redundant. So as long as you start off with random weights, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2955" target="_blank">00:49:15.880</a></span> | <span class="t">it can learn to find the optimal set of filters, which will not include duplicate filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2964" target="_blank">00:49:24.600</a></span> | <span class="t">These are all fantastic questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2974" target="_blank">00:49:34.200</a></span> | <span class="t">In this review, we've done our different layers, and then these different layers get optimized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2983" target="_blank">00:49:43.360</a></span> | <span class="t">with SGD. Last week we learned about SGD by using this extremely simple example where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=2992" target="_blank">00:49:52.960</a></span> | <span class="t">we said let's define a function which is a line, ax + b. Let's create some data that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3001" target="_blank">00:50:01.960</a></span> | <span class="t">matches a line, x's and y's. Let's define a loss function, which is the sum of squared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3010" target="_blank">00:50:10.480</a></span> | <span class="t">errors. We now no longer know what a and b are, so let's start with some guess. Obviously</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3018" target="_blank">00:50:18.960</a></span> | <span class="t">the loss is pretty high, and let's now try and come up with a procedure where each step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3026" target="_blank">00:50:26.760</a></span> | <span class="t">makes the loss a little bit better by making a and b a little bit better. The way we did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3032" target="_blank">00:50:32.520</a></span> | <span class="t">that was very simple. We calculated the derivative of the loss with respect to each of a and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3039" target="_blank">00:50:39.840</a></span> | <span class="t">b, and that means that the derivative of the loss with respect to b is, if I increase b</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3046" target="_blank">00:50:46.480</a></span> | <span class="t">by a bit, how does the loss change? And the derivative of the loss with respect to a means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3052" target="_blank">00:50:52.440</a></span> | <span class="t">as I change a a bit, how does the loss change? If I know those two things, then I know that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3058" target="_blank">00:50:58.240</a></span> | <span class="t">I should subtract the derivative times some learning rate, which is 0.01, and as long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3066" target="_blank">00:51:06.440</a></span> | <span class="t">as our learning rate is low enough, we know that this is going to make our a guess a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3071" target="_blank">00:51:11.600</a></span> | <span class="t">bit better. And we do the same for our b guess, it gets a little bit better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3077" target="_blank">00:51:17.280</a></span> | <span class="t">And so we learned that that is the entirety of SGD. We run that again and again and again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3083" target="_blank">00:51:23.160</a></span> | <span class="t">and indeed we set up something that would run it again and again and again in an animation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3087" target="_blank">00:51:27.600</a></span> | <span class="t">loop and we saw that indeed it does optimize our line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3093" target="_blank">00:51:33.920</a></span> | <span class="t">The tricky thing for me with deep learning is jumping from this kind of easy to visualize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3100" target="_blank">00:51:40.480</a></span> | <span class="t">intuition. If I run this little derivative on these two things a bunch of times, it optimizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3107" target="_blank">00:51:47.960</a></span> | <span class="t">this line, I can then create a set of layers with hundreds of millions of parameters that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3120" target="_blank">00:52:00.480</a></span> | <span class="t">in theory can match any possible function and it's going to do exactly the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3127" target="_blank">00:52:07.000</a></span> | <span class="t">So this is where our intuition breaks down, which is that this incredibly simple thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3131" target="_blank">00:52:11.560</a></span> | <span class="t">called SGD is capable of creating these incredibly sophisticated deep learning models. We really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3139" target="_blank">00:52:19.680</a></span> | <span class="t">have to just respect our understanding of the basics of what's going on. We know it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3144" target="_blank">00:52:24.800</a></span> | <span class="t">going to work, and we can see that it does work. But even when you've trained dozens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3151" target="_blank">00:52:31.520</a></span> | <span class="t">of deep learning models, it's still surprising that it does work. It's always a bit shocking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3156" target="_blank">00:52:36.800</a></span> | <span class="t">when you start without any ability to analyze some problem. You start with some random weights,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3163" target="_blank">00:52:43.440</a></span> | <span class="t">you start with a general architecture, you throw some data in with SGD, and you end up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3167" target="_blank">00:52:47.240</a></span> | <span class="t">with something that works. Hopefully now it makes sense, you can see why that happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3173" target="_blank">00:52:53.760</a></span> | <span class="t">But it takes doing it a few times to really intuitively understand, okay, it really does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3180" target="_blank">00:53:00.280</a></span> | <span class="t">work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3181" target="_blank">00:53:01.280</a></span> | <span class="t">So one question about Softmax, could you use it for multi-class, multi-label classification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3188" target="_blank">00:53:08.920</a></span> | <span class="t">for the multiple correct answers?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3190" target="_blank">00:53:10.840</a></span> | <span class="t">And you use Softmax for multi-class classification, and the answer is absolutely yes. In fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3195" target="_blank">00:53:15.400</a></span> | <span class="t">the example I showed here was such an example. So imagine that these outputs were for cat,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3203" target="_blank">00:53:23.320</a></span> | <span class="t">dog, plane, fish, and building. So these might be what these 5 things represent. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3214" target="_blank">00:53:34.040</a></span> | <span class="t">is exactly showing a Softmax for a multi-class output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3221" target="_blank">00:53:41.160</a></span> | <span class="t">You just have to make sure that your neural net has as many outputs as you want. And to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3227" target="_blank">00:53:47.520</a></span> | <span class="t">do that, you just need to make sure that the last weight layer in your neural net has as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3234" target="_blank">00:53:54.740</a></span> | <span class="t">many columns as you want. The number of columns in your final weight matrix tells you how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3239" target="_blank">00:53:59.880</a></span> | <span class="t">many outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3240" target="_blank">00:54:00.880</a></span> | <span class="t">[IENCE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3241" target="_blank">00:54:01.880</a></span> | <span class="t">Okay, that is not multi-class classification. So if you want to create something that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3251" target="_blank">00:54:11.200</a></span> | <span class="t">going to find more than one thing, then no. Softmax would not be the best way to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3257" target="_blank">00:54:17.400</a></span> | <span class="t">I'm not sure if we're going to cover that in this set of classes. If we don't, we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3263" target="_blank">00:54:23.720</a></span> | <span class="t">be doing it next year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3264" target="_blank">00:54:24.720</a></span> | <span class="t">[AUDIENCE]</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3265" target="_blank">00:54:25.720</a></span> | <span class="t">Let's go back to the question about 3x3 filters, and more generally, how do we pick an architecture?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3289" target="_blank">00:54:49.200</a></span> | <span class="t">So the question of the VGG authors used 3x3 filters. The 2012 ImageNet winners used a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3300" target="_blank">00:55:00.440</a></span> | <span class="t">combination of 7x7 and 11x11 filters. What has happened over the last few years since</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3309" target="_blank">00:55:09.000</a></span> | <span class="t">then if people have realized that 3x3 filters are just better? The original insight for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3317" target="_blank">00:55:17.560</a></span> | <span class="t">this was actually that Matt Zeiler visualization paper I showed you. It's real worth reading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3323" target="_blank">00:55:23.200</a></span> | <span class="t">that paper because he really shows that by looking at lots of pictures of all the stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3327" target="_blank">00:55:27.600</a></span> | <span class="t">going on inside of CNN, it clearly works better when you have smaller filters and more layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3334" target="_blank">00:55:34.360</a></span> | <span class="t">I'm not going to go into the theoretical justification as to why, for the sake of applying CNNs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3339" target="_blank">00:55:39.760</a></span> | <span class="t">all you need to know is that there's really no reason to use anything but 3x3 filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3345" target="_blank">00:55:45.880</a></span> | <span class="t">So that's a nice simple rule of thumb which always works, 3x3 filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3353" target="_blank">00:55:53.000</a></span> | <span class="t">How many layers of 3x3 filters? This is where there is not any standard agreed-upon technique.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3365" target="_blank">00:56:05.100</a></span> | <span class="t">Weeding lots of papers, looking at lots of Kaggle winners, you will over time get a sense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3369" target="_blank">00:56:09.600</a></span> | <span class="t">of for a problem of this level of complexity, you need this many filters. There have been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3376" target="_blank">00:56:16.640</a></span> | <span class="t">various people that have tried to simplify this, but we're really still at a point where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3382" target="_blank">00:56:22.960</a></span> | <span class="t">the answer is try a few different architectures and see what works. The same applies to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3387" target="_blank">00:56:27.840</a></span> | <span class="t">question of how many filters per layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3391" target="_blank">00:56:31.600</a></span> | <span class="t">So in general, this idea of having 3x3 filters with max pooling and doubling the number of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3397" target="_blank">00:56:37.800</a></span> | <span class="t">filters each time you do max pooling is a pretty good rule of thumb. How many do you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3403" target="_blank">00:56:43.080</a></span> | <span class="t">start with? You've kind of got to experiment. Actually, we're going to see today an example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3410" target="_blank">00:56:50.400</a></span> | <span class="t">of how that works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3412" target="_blank">00:56:52.440</a></span> | <span class="t">If you had a much larger image, would you still want 3x3 filters?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3419" target="_blank">00:56:59.960</a></span> | <span class="t">If you had a much larger image, what would you do? For example, on Kaggle, there's a diabetic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3424" target="_blank">00:57:04.800</a></span> | <span class="t">retinopathy competition that has some pictures of eyeballs that are quite a high resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3429" target="_blank">00:57:09.320</a></span> | <span class="t">I think they're a couple of thousand by a couple of thousand. The question of how to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3434" target="_blank">00:57:14.160</a></span> | <span class="t">deal with large images is as yet unsolved in the literature. So if you actually look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3440" target="_blank">00:57:20.520</a></span> | <span class="t">at the winners of that Kaggle competition, all of the winners resampled that image down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3446" target="_blank">00:57:26.000</a></span> | <span class="t">to 512x512. So I find that quite depressing. It's clearly not the right approach. I'm pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3454" target="_blank">00:57:34.360</a></span> | <span class="t">sure I know what the right approach is. I'm pretty sure the right approach is to do what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3458" target="_blank">00:57:38.200</a></span> | <span class="t">the eye does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3459" target="_blank">00:57:39.200</a></span> | <span class="t">The eye does something called foveation, which means that when I look directly at something,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3464" target="_blank">00:57:44.200</a></span> | <span class="t">the thing in the middle is very high-res and very clear, and the stuff on the outside is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3468" target="_blank">00:57:48.440</a></span> | <span class="t">not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3472" target="_blank">00:57:52.320</a></span> | <span class="t">I think a lot of people are generally in agreement with the idea that if we could come up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3476" target="_blank">00:57:56.240</a></span> | <span class="t">an architecture which has this concept of foveation, and then secondly, we need something,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3482" target="_blank">00:58:02.640</a></span> | <span class="t">and there are some good techniques to this already called attentional models. An attentional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3486" target="_blank">00:58:06.600</a></span> | <span class="t">model is something that says, "Okay, the thing I'm looking for is not in the middle of my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3490" target="_blank">00:58:10.440</a></span> | <span class="t">view, but my low-res peripheral vision thinks it might be over there. Let's focus my attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3498" target="_blank">00:58:18.800</a></span> | <span class="t">over there."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3499" target="_blank">00:58:19.800</a></span> | <span class="t">And we're going to start looking at recurrent neural networks next week, and we can use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3505" target="_blank">00:58:25.200</a></span> | <span class="t">recurrent neural networks to build attentional models that allow us to search through a big</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3509" target="_blank">00:58:29.720</a></span> | <span class="t">image to find areas of interest. That is a very active area of research, but as yet is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3516" target="_blank">00:58:36.760</a></span> | <span class="t">not really finalized. By the time this turns into a MOOC and a video, I wouldn't be surprised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3524" target="_blank">00:58:44.360</a></span> | <span class="t">if that has been much better solved. It's moving very quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3528" target="_blank">00:58:48.000</a></span> | <span class="t">The Matt Zyler paper showed larger filters because he was showing what AlexNet, the 2012</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3541" target="_blank">00:59:01.360</a></span> | <span class="t">winner, looked like. Later on in the paper, he said based on what it looks like, here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3547" target="_blank">00:59:07.080</a></span> | <span class="t">are some suggestions about how to build better models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3552" target="_blank">00:59:12.640</a></span> | <span class="t">So let us now finalize our review by looking at fine-tuning. So we learned how to do fine-tuning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3568" target="_blank">00:59:28.840</a></span> | <span class="t">using the little VGG class that I built, which is one line of code, vgg.fine-tuned. We also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3577" target="_blank">00:59:37.520</a></span> | <span class="t">learned how to take 1000 predictions of all the 1000 ImageNet categories and turn them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3585" target="_blank">00:59:45.680</a></span> | <span class="t">into two predictions, which is just a cat or a dog, by building a simple linear model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3593" target="_blank">00:59:53.080</a></span> | <span class="t">that took as input the 1000 ImageNet category predictions as input, and took the true cat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3614" target="_blank">01:00:14.240</a></span> | <span class="t">and dog labels as output, and we just created a linear model of that. So here is that linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3630" target="_blank">01:00:30.880</a></span> | <span class="t">model. It's got 1000 inputs and 2 outputs. So we trained that linear model, it took less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3641" target="_blank">01:00:41.240</a></span> | <span class="t">than a second to train, and we got 97.7% accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3646" target="_blank">01:00:46.780</a></span> | <span class="t">So this was actually pretty effective. So why was it pretty effective to take 1000 predictions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3655" target="_blank">01:00:55.360</a></span> | <span class="t">of is it a cat, is it a fish, is it a bird, is it a poodle, is it a pug, is it a plane,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3661" target="_blank">01:01:01.800</a></span> | <span class="t">and turn it into a cat or is it a dog. The reason that worked so well is because the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3667" target="_blank">01:01:07.600</a></span> | <span class="t">original architecture, the ImageNet architecture, was already trained to do something very similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3675" target="_blank">01:01:15.960</a></span> | <span class="t">to what we wanted our model to do. We wanted our model to separate cats from dogs, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3681" target="_blank">01:01:21.080</a></span> | <span class="t">the ImageNet model already separated lots of different cats from different dogs from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3686" target="_blank">01:01:26.040</a></span> | <span class="t">lots of other things as well. So the thing we were trying to do was really just a subset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3690" target="_blank">01:01:30.840</a></span> | <span class="t">of what ImageNet already does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3693" target="_blank">01:01:33.920</a></span> | <span class="t">So that was why starting with 1000 predictions and building the simple linear model worked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3699" target="_blank">01:01:39.440</a></span> | <span class="t">so well. This week, you're going to be looking at the State Farm competition. And in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3705" target="_blank">01:01:45.440</a></span> | <span class="t">State Farm competition, you're going to be looking at pictures like this one, and this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3714" target="_blank">01:01:54.840</a></span> | <span class="t">one, and this one. And your job will not be to decide whether or not it's a person or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3723" target="_blank">01:02:03.560</a></span> | <span class="t">a dog or a cat. Your job will be to decide is this person driving in a distracted way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3728" target="_blank">01:02:08.880</a></span> | <span class="t">or not. That is not something that the original ImageNet categories included. And therefore</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3736" target="_blank">01:02:16.360</a></span> | <span class="t">this same technique is not going to work this week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3741" target="_blank">01:02:21.280</a></span> | <span class="t">So what do you do if you need to go further? What do you do if you need to predict something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3747" target="_blank">01:02:27.520</a></span> | <span class="t">which is very different to what the original model did? The answer is to throw away some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3754" target="_blank">01:02:34.280</a></span> | <span class="t">of the later layers in the model and retrain them from scratch. And that's called fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3762" target="_blank">01:02:42.320</a></span> | <span class="t">And so that is pretty simple to do. So if we just want to fine-tune the last layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3770" target="_blank">01:02:50.000</a></span> | <span class="t">we can just go model.pop, that removes the last layer. We can then say make all of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3776" target="_blank">01:02:56.040</a></span> | <span class="t">other layers non-trainable, so that means it won't update those weights, and then add</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3781" target="_blank">01:03:01.760</a></span> | <span class="t">a new fully connected layer, dense layer to the end with just our dog and cat, our two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3787" target="_blank">01:03:07.480</a></span> | <span class="t">activations, and then go ahead and fit that model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3794" target="_blank">01:03:14.320</a></span> | <span class="t">So that is the simplest kind of fine-tuning. Remove the last layer, but previously that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3799" target="_blank">01:03:19.680</a></span> | <span class="t">last layer was going to try and predict 1000 possible categories, and replace it with a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3804" target="_blank">01:03:24.360</a></span> | <span class="t">new last layer which we train. In this case, I've only run it for a two-week box, so I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3811" target="_blank">01:03:31.120</a></span> | <span class="t">not getting a great result. But if we ran it for a few more, we would get a bit better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3814" target="_blank">01:03:34.260</a></span> | <span class="t">than the 97.7 we had last time. When we look at State Farm, it's going to be critical to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3820" target="_blank">01:03:40.040</a></span> | <span class="t">do something like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3823" target="_blank">01:03:43.480</a></span> | <span class="t">So how many layers would you remove? Because you don't just have to remove one. In fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3828" target="_blank">01:03:48.320</a></span> | <span class="t">if you go back through your lesson 2 notebook, you'll see after this, I've got a section</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3835" target="_blank">01:03:55.560</a></span> | <span class="t">called Retraining More Layers. In it, we see that we can take any model and we can say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3852" target="_blank">01:04:12.120</a></span> | <span class="t">okay, let's grab all the layers up to the nth layer. So in this case, we set all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3858" target="_blank">01:04:18.840</a></span> | <span class="t">layers up to, sorry, after the first fully connected layer and set them all to trainable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3867" target="_blank">01:04:27.280</a></span> | <span class="t">And then what would happen if we tried running that model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3871" target="_blank">01:04:31.120</a></span> | <span class="t">So with Keras, we can tell Keras which layers we want to freeze and leave them at their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3878" target="_blank">01:04:38.280</a></span> | <span class="t">ImageNet-decided weights, and which layers do we want to retrain based on the things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3885" target="_blank">01:04:45.520</a></span> | <span class="t">that we're interested in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3886" target="_blank">01:04:46.840</a></span> | <span class="t">And so in general, the more different your problem is to the original ImageNet 1000 categories,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3893" target="_blank">01:04:53.320</a></span> | <span class="t">the more layers you're going to have to retrain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3896" target="_blank">01:04:56.560</a></span> | <span class="t">So how do you decide how far to go back in the layers? Two ways. Way number 1, intuition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3919" target="_blank">01:05:19.160</a></span> | <span class="t">So have a look at something like those mat-zylar visualizations to get a sense of at what semantic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3924" target="_blank">01:05:24.840</a></span> | <span class="t">level each of those layers is operating at. And go back to the point where you feel like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3931" target="_blank">01:05:31.720</a></span> | <span class="t">that level of meaning is going to be relevant to your model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3937" target="_blank">01:05:37.920</a></span> | <span class="t">Method number 2, experiment. It doesn't take that long to train another model starting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3943" target="_blank">01:05:43.880</a></span> | <span class="t">at a different point. I generally do a bit of both. When I know dogs and cats are subsets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3952" target="_blank">01:05:52.920</a></span> | <span class="t">of the ImageNet categories, I'm not going to bother generally training more than one replacement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3960" target="_blank">01:06:00.080</a></span> | <span class="t">layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3961" target="_blank">01:06:01.080</a></span> | <span class="t">For State Farm, I really had no idea. I was pretty sure I wouldn't have to retrain any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3967" target="_blank">01:06:07.280</a></span> | <span class="t">of the convolutional layers because the convolutional layers are all about spatial relationships.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3974" target="_blank">01:06:14.160</a></span> | <span class="t">And therefore a convolutional layer is all about recognizing how things in space relate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3977" target="_blank">01:06:17.960</a></span> | <span class="t">to each other. I was pretty confident that figuring out whether somebody is looking at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3983" target="_blank">01:06:23.440</a></span> | <span class="t">a mobile phone or playing with their radio is not going to use different spatial features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3989" target="_blank">01:06:29.740</a></span> | <span class="t">So for State Farm, I've really only looked at retraining the dense layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=3995" target="_blank">01:06:35.280</a></span> | <span class="t">And in VGG, there are actually only three dense layers. There are actually only three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4004" target="_blank">01:06:44.900</a></span> | <span class="t">dense layers, the two intermediate layers and the output layer, so I just trained all three.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4013" target="_blank">01:06:53.840</a></span> | <span class="t">Generally speaking, the answer to this is try a few things and see what works the best.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4024" target="_blank">01:07:04.720</a></span> | <span class="t">When we retrain the layers, we do not set the weights randomly. We start the weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4029" target="_blank">01:07:09.560</a></span> | <span class="t">at their optimal ImageNet levels. That means that if you retrain more layers than you really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4038" target="_blank">01:07:18.880</a></span> | <span class="t">need to, it's not a big problem because the weights are already at the right point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4044" target="_blank">01:07:24.640</a></span> | <span class="t">If you randomized the weights of the layers that you're retraining, that would actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4051" target="_blank">01:07:31.160</a></span> | <span class="t">kill the earlier layers as well if you made them trainable. There's no point really setting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4058" target="_blank">01:07:38.840</a></span> | <span class="t">them to random most of the time. We'll be learning a bit more about that after the break.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4065" target="_blank">01:07:45.360</a></span> | <span class="t">So far, we have not reset the weights. When we say layer.trainable = true, we're just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4072" target="_blank">01:07:52.880</a></span> | <span class="t">telling Keras that when you say fit, I want you to actually use SGD to update the weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4078" target="_blank">01:07:58.720</a></span> | <span class="t">in that layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4090" target="_blank">01:08:10.480</a></span> | <span class="t">When we come back, we're going to be talking about how to go beyond these basic five pieces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4097" target="_blank">01:08:17.960</a></span> | <span class="t">to create models which are more accurate. Specifically, we're going to look at avoiding underfitting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4105" target="_blank">01:08:25.360</a></span> | <span class="t">and avoiding overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4108" target="_blank">01:08:28.480</a></span> | <span class="t">Next week, we're going to be doing half a class on review of convolutional neural networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4115" target="_blank">01:08:35.080</a></span> | <span class="t">and half a class of an introduction to recurrent neural networks which we'll be using for language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4120" target="_blank">01:08:40.680</a></span> | <span class="t">So hopefully by the end of this class, you'll be feeling ready to really dig deep into CNNs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4128" target="_blank">01:08:48.760</a></span> | <span class="t">during the week. This is really the right time this week to make sure that you're asking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4133" target="_blank">01:08:53.120</a></span> | <span class="t">questions you have about CNNs because next week we'll be wrapping up this topic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4139" target="_blank">01:08:59.560</a></span> | <span class="t">Let's come back at 5 past 8.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4147" target="_blank">01:09:07.000</a></span> | <span class="t">So we have a lot to cover in our next 55 minutes. I think this approach of doing the new material</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4154" target="_blank">01:09:14.440</a></span> | <span class="t">quickly and then you can review it in the lesson notebook on the video by experimenting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4159" target="_blank">01:09:19.920</a></span> | <span class="t">during the week and then reviewing the next week is fine. I think that's a good approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4164" target="_blank">01:09:24.760</a></span> | <span class="t">But I just want to make you aware that the new material of the next 55 minutes will move</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4169" target="_blank">01:09:29.560</a></span> | <span class="t">pretty quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4172" target="_blank">01:09:32.200</a></span> | <span class="t">So don't worry too much if not everything sinks in straight away. If you have any questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4177" target="_blank">01:09:37.640</a></span> | <span class="t">of course, please do ask. But also, recognize that it's really going to sink in as you study</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4185" target="_blank">01:09:45.400</a></span> | <span class="t">it and play with it during the week, and then next week we're going to review all of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4189" target="_blank">01:09:49.520</a></span> | <span class="t">So if it's still not making sense, and of course you've asked your questions on the forum,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4193" target="_blank">01:09:53.320</a></span> | <span class="t">it's still not making sense, we'll be reviewing it next week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4196" target="_blank">01:09:56.640</a></span> | <span class="t">So if you don't retrain a layer, does that mean the layer remembers what gets saved?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4221" target="_blank">01:10:21.480</a></span> | <span class="t">So yes, if you don't retrain a layer, then when you save the weights, it's going to contain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4225" target="_blank">01:10:25.720</a></span> | <span class="t">the weights that it originally had. That's a really important question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4231" target="_blank">01:10:31.720</a></span> | <span class="t">Why would we want to start out by overfitting? We're going to talk about that next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4238" target="_blank">01:10:38.320</a></span> | <span class="t">The last conflayer in VGG is a 7x7 output. There are 49 boxes and each one has 512 different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4245" target="_blank">01:10:45.440</a></span> | <span class="t">things. That's kind of right, but it's not that it recognizes 512 different things. When</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4251" target="_blank">01:10:51.160</a></span> | <span class="t">you have a convolution on a convolution on a convolution on a convolution on a convolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4255" target="_blank">01:10:55.280</a></span> | <span class="t">you have a very rich function with hundreds of thousands of parameters. So it's not that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4262" target="_blank">01:11:02.120</a></span> | <span class="t">it's recognizing 512 things, it's that there are 512 rich complex functions. And so those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4271" target="_blank">01:11:11.200</a></span> | <span class="t">rich complex functions can recognize rich complex concepts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4278" target="_blank">01:11:18.100</a></span> | <span class="t">So for example, we saw in the video that even in layer 6 there's a face detector which can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4285" target="_blank">01:11:25.560</a></span> | <span class="t">recognize cat faces as well as human faces. So the later on we get in these neural networks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4293" target="_blank">01:11:33.520</a></span> | <span class="t">the harder it is to even say what it is that's being found because they get more and more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4299" target="_blank">01:11:39.080</a></span> | <span class="t">sophisticated and complex. So what those 512 things do in the last layer of VGG, I'm not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4309" target="_blank">01:11:49.080</a></span> | <span class="t">sure that anybody's really got to a point that they could tell you that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4313" target="_blank">01:11:53.480</a></span> | <span class="t">I'm going to move on. The next section is all about making our model better. So at this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4342" target="_blank">01:12:22.120</a></span> | <span class="t">point, we have a model with an accuracy of 97.7%. So how do we make it better?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4351" target="_blank">01:12:31.760</a></span> | <span class="t">Now because we have started with an existing model, a VGG model, there are two reasons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4366" target="_blank">01:12:46.160</a></span> | <span class="t">that you could be less good than you want to be. Either you're underfitting or you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4371" target="_blank">01:12:51.960</a></span> | <span class="t">overfitting. Underfitting means that, for example, you're using a linear model to try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4379" target="_blank">01:12:59.060</a></span> | <span class="t">to do image recognition. You're using a model that is not complex and powerful enough for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4385" target="_blank">01:13:05.640</a></span> | <span class="t">the thing you're doing or it doesn't have enough parameters for the thing you're doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4390" target="_blank">01:13:10.240</a></span> | <span class="t">That's what underfitting is. Overfitting means that you're using a model with too many parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4397" target="_blank">01:13:17.760</a></span> | <span class="t">that you've trained for too long without using any of the techniques or without correctly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4402" target="_blank">01:13:22.440</a></span> | <span class="t">using the techniques you're about to learn about, such that you've ended up learning what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4406" target="_blank">01:13:26.800</a></span> | <span class="t">your specific training pictures look like rather than what the general patterns in them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4413" target="_blank">01:13:33.840</a></span> | <span class="t">look like. You will recognize overfitting if your training set has a much higher accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4423" target="_blank">01:13:43.560</a></span> | <span class="t">than your test set or your validation set. So that means you've learned how to recognize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4429" target="_blank">01:13:49.520</a></span> | <span class="t">the contents of your training set too well. And so then when you look at your validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4435" target="_blank">01:13:55.200</a></span> | <span class="t">set you get a less good result. So that's overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4440" target="_blank">01:14:00.120</a></span> | <span class="t">I'm not going to go into detail on this because any of you who have done any machine learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4443" target="_blank">01:14:03.560</a></span> | <span class="t">have seen this before, so any of you who haven't, please look up overfitting on the internet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4450" target="_blank">01:14:10.920</a></span> | <span class="t">learn about it, ask questions about it. It is perhaps the most important single concept</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4455" target="_blank">01:14:15.760</a></span> | <span class="t">in machine learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4457" target="_blank">01:14:17.960</a></span> | <span class="t">So it's not that we're not covering it because it's not interesting, it's just that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4460" target="_blank">01:14:20.800</a></span> | <span class="t">not covering it because I know a lot of you are already familiar with it. Underfitting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4466" target="_blank">01:14:26.840</a></span> | <span class="t">we can see in the same way, but it's the opposite. If our training error is much lower than our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4476" target="_blank">01:14:36.640</a></span> | <span class="t">validation error, then we're underfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4481" target="_blank">01:14:41.240</a></span> | <span class="t">So I'm going to look at this now because in fact you might have noticed that in all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4485" target="_blank">01:14:45.240</a></span> | <span class="t">our models so far, our training error has been lower than our validation error, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4492" target="_blank">01:14:52.800</a></span> | <span class="t">means we are underfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4496" target="_blank">01:14:56.360</a></span> | <span class="t">So how is this possible? And the answer to how this is possible is because the VGG network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4503" target="_blank">01:15:03.240</a></span> | <span class="t">includes something called dropout, and specifically dropout with a p of 0.5. What does dropout</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4510" target="_blank">01:15:10.880</a></span> | <span class="t">mean with a p of 0.5? It means that at this layer, which happens at the end of every fully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4516" target="_blank">01:15:16.700</a></span> | <span class="t">connected block, it deletes 0.5, so 50% of, the activations at random. It sets them to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4527" target="_blank">01:15:27.640</a></span> | <span class="t">0. That's what a dropout layer does. It sets to 0.5, half of the activations at random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4536" target="_blank">01:15:36.680</a></span> | <span class="t">Why would it do that? Because when you randomly throw away bits of the network, it means that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4543" target="_blank">01:15:43.120</a></span> | <span class="t">the network can't learn to overfit. It can't learn to build a network that just learns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4548" target="_blank">01:15:48.880</a></span> | <span class="t">about your images, because as soon as it does, you throw away half of it and suddenly it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4553" target="_blank">01:15:53.640</a></span> | <span class="t">not working anymore. So dropout is a fairly recent development, I think it's about three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4558" target="_blank">01:15:58.960</a></span> | <span class="t">years old, and it's perhaps the most important development of the last few years. Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4566" target="_blank">01:16:06.040</a></span> | <span class="t">it's the thing that now means we can train big complex models for long periods of time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4571" target="_blank">01:16:11.920</a></span> | <span class="t">without overfitting. Incredibly important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4575" target="_blank">01:16:15.920</a></span> | <span class="t">But in this case, it seems that we are using too much dropout. So the VGG network, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4584" target="_blank">01:16:24.200</a></span> | <span class="t">used a dropout of 0.5, they decided they needed that much in order to avoid overfitting ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4590" target="_blank">01:16:30.840</a></span> | <span class="t">But it seems for our cats and dogs, it's underfitting. So what do we do? The answer is, let's try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4599" target="_blank">01:16:39.360</a></span> | <span class="t">removing dropout. So how do we remove dropout? And this is where it gets fun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4606" target="_blank">01:16:46.960</a></span> | <span class="t">We can start with our VGG fine-tuned model. And I've actually created a little function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4612" target="_blank">01:16:52.400</a></span> | <span class="t">called VGG fine-tuned, which creates a VGG fine-tuned model with two outputs. It looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4622" target="_blank">01:17:02.060</a></span> | <span class="t">exactly like you would expect it to look. It creates a VGG model, it fine-tunes it, it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4634" target="_blank">01:17:14.320</a></span> | <span class="t">returns it. What does fine-tune do? It does exactly what we've learnt. It pops off the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4644" target="_blank">01:17:24.480</a></span> | <span class="t">last layer, sets all the rest of the layers to non-trainable, and adds a new dense layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4650" target="_blank">01:17:30.600</a></span> | <span class="t">So I just create a little thing that does all that. Every time I start writing the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4655" target="_blank">01:17:35.680</a></span> | <span class="t">code more than once, I stick it into a function and use it again in the future. It's good practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4662" target="_blank">01:17:42.360</a></span> | <span class="t">I then load the weights that I just saved in my last model, so I don't have to retrain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4668" target="_blank">01:17:48.520</a></span> | <span class="t">it. So saving and loading weights is a really helpful way of avoiding not refitting things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4674" target="_blank">01:17:54.180</a></span> | <span class="t">So already I now have a model that fits cats and dogs with 97.7% accuracy and underfits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4685" target="_blank">01:18:05.460</a></span> | <span class="t">We can grab all of the layers of the model and we can then enumerate through them and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4691" target="_blank">01:18:11.920</a></span> | <span class="t">find the last one which is a convolution. So let's remind ourselves, model.summary. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4705" target="_blank">01:18:25.360</a></span> | <span class="t">that's going to enumerate through all the layers and find the last one that is a convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4713" target="_blank">01:18:33.480</a></span> | <span class="t">So at this point, we now have the index of the last convolutional layer. It turns out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4721" target="_blank">01:18:41.600</a></span> | <span class="t">to be 30. So we can now grab that last convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4726" target="_blank">01:18:46.960</a></span> | <span class="t">And so what we want to try doing is removing dropout from all the rest of the layers. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4733" target="_blank">01:18:53.160</a></span> | <span class="t">after the convolutional layer are the dense layers. So after the convolutional layers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4745" target="_blank">01:19:05.400</a></span> | <span class="t">the last convolutional layer, after that we have the dense layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4750" target="_blank">01:19:10.560</a></span> | <span class="t">So this is a really important concept in the Keras library of playing around with layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4765" target="_blank">01:19:25.560</a></span> | <span class="t">And so spend some time looking at this code and really look at the inputs and the outputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4770" target="_blank">01:19:30.680</a></span> | <span class="t">and get a sense of it. So you can see here, here are all the layers up to the last convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4778" target="_blank">01:19:38.240</a></span> | <span class="t">layer. Here are all of the layers from the last convolutional layer. So all the fully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4784" target="_blank">01:19:44.120</a></span> | <span class="t">connected layers and all the convolutional layers. I can create a whole new model that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4788" target="_blank">01:19:48.880</a></span> | <span class="t">contains just the convolutional layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4793" target="_blank">01:19:53.360</a></span> | <span class="t">Why would I do that? Because if I'm going to remove dropout, then clearly I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4800" target="_blank">01:20:00.180</a></span> | <span class="t">to want to fine-tune all of the layers that involve dropout. That is, all of the dense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4805" target="_blank">01:20:05.560</a></span> | <span class="t">layers. I don't need to fine-tune any convolutional layers because none of the convolutional layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4811" target="_blank">01:20:11.180</a></span> | <span class="t">have dropout. I'm going to save myself some time. I'm going to pre-calculate the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4824" target="_blank">01:20:24.120</a></span> | <span class="t">of the last convolutional layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4826" target="_blank">01:20:26.980</a></span> | <span class="t">So you see this model I've built here, this model that contains all the convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4832" target="_blank">01:20:32.800</a></span> | <span class="t">layers. If I pre-calculate the output of that, then that's the input to the dense layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4840" target="_blank">01:20:40.780</a></span> | <span class="t">that I want to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4843" target="_blank">01:20:43.040</a></span> | <span class="t">So you can see what I do here is I say conv_model.predict with my validation batches, conv_model.predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4852" target="_blank">01:20:52.720</a></span> | <span class="t">with my batches, and that now gives me the output of the convolutional layer for my training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4859" target="_blank">01:20:59.800</a></span> | <span class="t">and the output of it for my validation. And because that's something I don't want to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4864" target="_blank">01:21:04.480</a></span> | <span class="t">to do it again and again, I save it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4868" target="_blank">01:21:08.640</a></span> | <span class="t">So here I'm just going to go load_array and that's going to load from the disk the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4877" target="_blank">01:21:17.640</a></span> | <span class="t">of that. And so I'm going to say train_features.shape, and this is always the first thing that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4882" target="_blank">01:21:22.520</a></span> | <span class="t">want to do when you've built something, is look at its shape. And indeed, it's what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4887" target="_blank">01:21:27.400</a></span> | <span class="t">would expect. It is 23,000 images, each one is 14x14, because I didn't include the final</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4894" target="_blank">01:21:34.720</a></span> | <span class="t">Max Pauling layer, with 512 filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4899" target="_blank">01:21:39.760</a></span> | <span class="t">And so indeed, if we go model.summary, we should find that the last convolutional layer, here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4910" target="_blank">01:21:50.580</a></span> | <span class="t">it is, 512 filters, 14x14 dimension. So we have basically built a model that is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4920" target="_blank">01:22:00.600</a></span> | <span class="t">a subset of VGG containing all of these earlier layers. We've run it through our test set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4927" target="_blank">01:22:07.480</a></span> | <span class="t">and our validation set, and we've got the outputs. So that's the stuff that we want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4932" target="_blank">01:22:12.720</a></span> | <span class="t">to fix, and so we don't want to recalculate that every time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4937" target="_blank">01:22:17.920</a></span> | <span class="t">So now we create a new model which is exactly the same as the dense part of VGG, but we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4944" target="_blank">01:22:24.840</a></span> | <span class="t">replace the dropout P with 0. So here's something pretty interesting, and I'm going to let you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4952" target="_blank">01:22:32.160</a></span> | <span class="t">guys think about this during the week. How do you take the previous weights from VGG</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4961" target="_blank">01:22:41.520</a></span> | <span class="t">and put them into this model where dropout is 0? So if you think about it, before we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4966" target="_blank">01:22:46.480</a></span> | <span class="t">had dropout of 0.5, so half the activations were being deleted at random. So since half</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4972" target="_blank">01:22:52.440</a></span> | <span class="t">the activations are being deleted at random, now that I've removed dropout, I effectively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4977" target="_blank">01:22:57.400</a></span> | <span class="t">have twice as many weights being active. Since I have twice as many weights being active,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4982" target="_blank">01:23:02.840</a></span> | <span class="t">I need to take my imageNet weights and divide them by 2. So by taking my imageNet weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4990" target="_blank">01:23:10.360</a></span> | <span class="t">and copying them across, so I take my previous weights and copy them across to my new model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=4995" target="_blank">01:23:15.360</a></span> | <span class="t">each time divide them by 2, that means that this new model is going to be exactly as accurate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5000" target="_blank">01:23:20.960</a></span> | <span class="t">as my old model before I start training, but it has no dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5006" target="_blank">01:23:26.520</a></span> | <span class="t">Is it wasteful to have in the cats and dogs model filters that are being learnt to find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5025" target="_blank">01:23:45.720</a></span> | <span class="t">things like bookshelves? Potentially it is, but it's okay to be wasteful. The only place</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5034" target="_blank">01:23:54.040</a></span> | <span class="t">that it's a problem is if we are overfitting. And if we're overfitting, then we can easily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5039" target="_blank">01:23:59.320</a></span> | <span class="t">fix that by adding more dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5043" target="_blank">01:24:03.440</a></span> | <span class="t">So let's try this. We now have a model which takes the output of the convolutional layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5050" target="_blank">01:24:10.000</a></span> | <span class="t">as input, gives us our cats vs. dogs as output, and has no dropout. So now we can just go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5058" target="_blank">01:24:18.200</a></span> | <span class="t">ahead and fit it. So notice that the input to this is my 512 x 14 x 14 inputs. My outputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5068" target="_blank">01:24:28.720</a></span> | <span class="t">are my cats and dogs as usual, and train it for a few epochs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5073" target="_blank">01:24:33.760</a></span> | <span class="t">And here's something really interesting. Dense layers take very little time to compute. A</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5081" target="_blank">01:24:41.800</a></span> | <span class="t">convolutional layer takes a long time to compute. Think about it, you're computing 512 x 3 x</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5088" target="_blank">01:24:48.160</a></span> | <span class="t">3 x 512 filters. For each of 14 x 14 spots, that is a lot of computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5098" target="_blank">01:24:58.760</a></span> | <span class="t">So in a deep learning network, your convolutional layers is where all of your computation is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5104" target="_blank">01:25:04.120</a></span> | <span class="t">being taken up. So look, when I train just my dense layers, it's only taking 17 seconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5109" target="_blank">01:25:09.440</a></span> | <span class="t">Super fast. On the other hand, the dense layers is where all of your memory is taken up. Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5115" target="_blank">01:25:15.160</a></span> | <span class="t">between this 4096 layer and this 4096 layer, there are 4000 x 4000 = 16 million weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5124" target="_blank">01:25:24.160</a></span> | <span class="t">And between the previous layer, which was 512 x 7 x 7 after Max Pauling, that's 25,088.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5131" target="_blank">01:25:31.880</a></span> | <span class="t">There are 25,088 x 4096 weights. So this is a really important rule of thumb. Your dense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5139" target="_blank">01:25:39.600</a></span> | <span class="t">layers is where your memory is taken up. Your convolutional layers is where your computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5144" target="_blank">01:25:44.120</a></span> | <span class="t">time is taking up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5146" target="_blank">01:25:46.200</a></span> | <span class="t">So it took me a minute or so to run 8 epochs. That's pretty fast. And holy shit, look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5152" target="_blank">01:25:52.560</a></span> | <span class="t">that! 98.5%. So you can see now, I am overfitting. But even though I'm overfitting, I am doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5164" target="_blank">01:26:04.640</a></span> | <span class="t">pretty damn well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5166" target="_blank">01:26:06.680</a></span> | <span class="t">So overfitting is only bad if you're doing it so much that your accuracy is bad. So in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5174" target="_blank">01:26:14.920</a></span> | <span class="t">this case, it looks like actually this amount of overfitting is pretty good. So for cats</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5180" target="_blank">01:26:20.480</a></span> | <span class="t">and dogs, this is about as good as I've gotten. And in fact, if I'd stopped it a little earlier,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5186" target="_blank">01:26:26.960</a></span> | <span class="t">you can see it was really good. In fact, the winner was 98.8, and here I've got 98.75.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5194" target="_blank">01:26:34.680</a></span> | <span class="t">And there are some tricks I'll show you later that always give you an extra 50% accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5199" target="_blank">01:26:39.520</a></span> | <span class="t">So this would definitely have won cats and dogs if we had used this model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5203" target="_blank">01:26:43.280</a></span> | <span class="t">Question - Can you perform dropout on a convolutional layer?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5208" target="_blank">01:26:48.040</a></span> | <span class="t">You can absolutely perform dropout on a convolutional layer. And indeed, nowadays people normally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5212" target="_blank">01:26:52.920</a></span> | <span class="t">do. I don't quite remember the VGG days. I guess that was 2 years ago. Maybe people in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5218" target="_blank">01:26:58.240</a></span> | <span class="t">those days didn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5219" target="_blank">01:26:59.440</a></span> | <span class="t">Nowadays, the general approach would be you would have dropout of 0.1 before your first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5224" target="_blank">01:27:04.760</a></span> | <span class="t">layer, dropout of 0.2 before this one, 0.3, 0.4, and then finally dropout of 0.5 before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5230" target="_blank">01:27:10.040</a></span> | <span class="t">your fully connected layers. It's kind of the standard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5233" target="_blank">01:27:13.800</a></span> | <span class="t">If you then find that you're underfitting or overfitting, you can modify all of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5238" target="_blank">01:27:18.080</a></span> | <span class="t">probabilities by the same amount. If you dropout in an early layer, you're losing that information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5247" target="_blank">01:27:27.840</a></span> | <span class="t">for all of the future layers, so you don't want to drop out too much in the early layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5252" target="_blank">01:27:32.520</a></span> | <span class="t">You can feel better dropping out more in the later layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5257" target="_blank">01:27:37.240</a></span> | <span class="t">This is how you manually tune with your overfitting or underfitting. Another way to do it would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5277" target="_blank">01:27:57.400</a></span> | <span class="t">be to modify the architecture to have less or more filters. But that's actually pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5283" target="_blank">01:28:03.480</a></span> | <span class="t">difficult to do. So it's the point that we didn't need dropout anyway. Perhaps it was.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5290" target="_blank">01:28:10.760</a></span> | <span class="t">But VGG comes with dropout. So when you're fine-tuning, you start with what you start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5296" target="_blank">01:28:16.040</a></span> | <span class="t">with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5299" target="_blank">01:28:19.920</a></span> | <span class="t">We are overfitting here, so my hypothesis is that we maybe should try a little less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5304" target="_blank">01:28:24.400</a></span> | <span class="t">dropout. But before we do, I'm going to show you some better tricks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5310" target="_blank">01:28:30.280</a></span> | <span class="t">The first trick I'm going to show you is a trick that lets you avoid overfitting without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5315" target="_blank">01:28:35.240</a></span> | <span class="t">deleting information. Dropout deletes information, so we don't want to do it unless we have to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5320" target="_blank">01:28:40.600</a></span> | <span class="t">So instead of dropout, here is a list. You guys should refer to this every time you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5327" target="_blank">01:28:47.000</a></span> | <span class="t">building a model that is overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5329" target="_blank">01:28:49.760</a></span> | <span class="t">5 steps. Step 1, add more data. This is a Kaggle competition, so we can't do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5337" target="_blank">01:28:57.720</a></span> | <span class="t">Step 2, use data augmentation, which we're about to learn.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5342" target="_blank">01:29:02.040</a></span> | <span class="t">Step 3, use more generalizable architectures. We're going to learn that after this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5347" target="_blank">01:29:07.480</a></span> | <span class="t">Step 4, add regularization. That generally means dropout. There's another type of regularization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5353" target="_blank">01:29:13.560</a></span> | <span class="t">which is where you basically add up all of your weights, the value of all of your weights,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5362" target="_blank">01:29:22.360</a></span> | <span class="t">and then multiply it by some small number, and you add that to the loss function. Basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5366" target="_blank">01:29:26.960</a></span> | <span class="t">you say having higher weights is bad. That's called either L2 regularization, if you take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5374" target="_blank">01:29:34.320</a></span> | <span class="t">the square of your weights and add them up, or L1 regularization if you take the absolute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5378" target="_blank">01:29:38.300</a></span> | <span class="t">value of your weights and add them up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5380" target="_blank">01:29:40.600</a></span> | <span class="t">Tera supports that as well. Also popular. I don't think anybody has a great sense of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5389" target="_blank">01:29:49.760</a></span> | <span class="t">when do you use L1 and L2 regularization and when do you use dropout. I use dropout pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5396" target="_blank">01:29:56.040</a></span> | <span class="t">much all the time, and I don't particularly see why you would need both, but I just wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5400" target="_blank">01:30:00.460</a></span> | <span class="t">to let you know that that other type of regularization exists.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5405" target="_blank">01:30:05.520</a></span> | <span class="t">And then lastly, if you really have to reduce architecture complexity, so remove some filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5410" target="_blank">01:30:10.560</a></span> | <span class="t">But that's pretty hard to do if you're fine-tuning, because how do you know which filters to remove?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5416" target="_blank">01:30:16.520</a></span> | <span class="t">So really, the first four. Now that we have dropout, the first four are what we do in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5422" target="_blank">01:30:22.440</a></span> | <span class="t">practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5423" target="_blank">01:30:23.440</a></span> | <span class="t">Like in Random Forests, where we randomly select subsets of variables at each point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5441" target="_blank">01:30:41.160</a></span> | <span class="t">that's kind of what dropout is doing. Dropout is randomly throwing away half the activations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5446" target="_blank">01:30:46.120</a></span> | <span class="t">so dropout and random forests both effectively create large ensembles. It's actually a fantastic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5457" target="_blank">01:30:57.320</a></span> | <span class="t">kind of analogy between random forests.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5459" target="_blank">01:30:59.560</a></span> | <span class="t">So just like when we went from decision trees to random forests, it was this huge step which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5465" target="_blank">01:31:05.640</a></span> | <span class="t">was basically create lots of decision trees with some random differences. Dropout is effectively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5470" target="_blank">01:31:10.440</a></span> | <span class="t">creating lots of, automatically, lots of neural networks with different subsets of features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5475" target="_blank">01:31:15.920</a></span> | <span class="t">that have been randomly selected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5479" target="_blank">01:31:19.840</a></span> | <span class="t">Data augmentation is very simple. Data augmentation is something which takes a cat and turns it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5487" target="_blank">01:31:27.160</a></span> | <span class="t">into lots of cats. That's it. Actually, it does it for dogs as well. You can rotate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5498" target="_blank">01:31:38.160</a></span> | <span class="t">you can flip, you can move up and down, left and right, zoom in and out. And in Keras,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5504" target="_blank">01:31:44.920</a></span> | <span class="t">you do it by, rather than, what we've always said before was image data generator, open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5509" target="_blank">01:31:49.920</a></span> | <span class="t">parenthesis, closed parenthesis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5512" target="_blank">01:31:52.360</a></span> | <span class="t">Now we say all these other things. Flip it horizontally at random, zoom in a bit at random,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5518" target="_blank">01:31:58.600</a></span> | <span class="t">share at random, rotate at random, move it left and right at random, and move it up and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5522" target="_blank">01:32:02.480</a></span> | <span class="t">down at random. So once you've done that, then when you create your batches, rather than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5532" target="_blank">01:32:12.640</a></span> | <span class="t">doing it the way we did it before, you simply add that to your batches. So we said, Ok, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5542" target="_blank">01:32:22.160</a></span> | <span class="t">is our data generator, and so when we create our batches, use that data generator, the augmenting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5548" target="_blank">01:32:28.360</a></span> | <span class="t">data generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5550" target="_blank">01:32:30.780</a></span> | <span class="t">Very important to notice, the validation set does not include that. Because the validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5556" target="_blank">01:32:36.120</a></span> | <span class="t">set is the validation set. That's the thing we want to check against, so we shouldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5559" target="_blank">01:32:39.400</a></span> | <span class="t">be fiddling with that at all. The validation set has no data augmentation and no shuffling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5564" target="_blank">01:32:44.400</a></span> | <span class="t">It's constant and fixed. The training set, on the other hand, we want to move it around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5569" target="_blank">01:32:49.460</a></span> | <span class="t">as much as we can. So shuffle its order and add all these different types of augmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5575" target="_blank">01:32:55.680</a></span> | <span class="t">How much augmentation to use? This is one of the things that Rachel and I would love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5579" target="_blank">01:32:59.880</a></span> | <span class="t">to automate. For now, two methods, use your intuition. The best way to use your intuition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5586" target="_blank">01:33:06.540</a></span> | <span class="t">is to take one of your images, add some augmentation, and check whether they still look like cats.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5595" target="_blank">01:33:15.020</a></span> | <span class="t">So if it's so warped that you're like, "Ok, nobody takes a photo of a cat like that,"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5599" target="_blank">01:33:19.860</a></span> | <span class="t">you've done it wrong. So this is kind of like a small amount of data augmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5605" target="_blank">01:33:25.560</a></span> | <span class="t">Method 2, experiment. Try a range of different augmentations and see which one gives you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5609" target="_blank">01:33:29.600</a></span> | <span class="t">the best results. If we add some augmentation, everything else is exactly the same, except</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5618" target="_blank">01:33:38.520</a></span> | <span class="t">we can't pre-compute anything anymore. So earlier on, we pre-computed the output of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5623" target="_blank">01:33:43.520</a></span> | <span class="t">the last convolutional layer. We can't do that now, because every time this cat approaches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5629" target="_blank">01:33:49.040</a></span> | <span class="t">our neural network, it's a little bit different. It's rotated a bit, it's flipped, it's moved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5633" target="_blank">01:33:53.920</a></span> | <span class="t">around or it's zoomed in and out. So unfortunately, when we use data augmentation, we can't pre-compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5640" target="_blank">01:34:00.440</a></span> | <span class="t">anything and so things take longer. Everything else is the same though. So we grab our fully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5645" target="_blank">01:34:05.800</a></span> | <span class="t">connected model, we add it to the end of our convolutional model, and this is the one with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5650" target="_blank">01:34:10.760</a></span> | <span class="t">our dropout, compile it, fit it, and now rather than taking 9 seconds per epoch, it takes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5658" target="_blank">01:34:18.600</a></span> | <span class="t">273 seconds per epoch because it has to calculate through all the convolutional layers because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5665" target="_blank">01:34:25.000</a></span> | <span class="t">of the data augmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5669" target="_blank">01:34:29.680</a></span> | <span class="t">So in terms of results here, we have not managed to get back up to that 98.7 accuracy. I probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5680" target="_blank">01:34:40.280</a></span> | <span class="t">have, I've run a few more. So if I keep running them, again, I start overfitting. So it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5691" target="_blank">01:34:51.160</a></span> | <span class="t">a little hard to tell because my validation accuracy is moving around quite a lot because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5695" target="_blank">01:34:55.920</a></span> | <span class="t">my validation sets a little bit on the small side. It's a little bit hard to tell whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5700" target="_blank">01:35:00.520</a></span> | <span class="t">this data augmentation is helping or hindering. I suspect what we're finding here is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5707" target="_blank">01:35:07.840</a></span> | <span class="t">maybe we're doing too much data augmentation, so if I went back and reduced my different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5717" target="_blank">01:35:17.440</a></span> | <span class="t">ranges by say half, I might get a better result than this. But really, this is something to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5724" target="_blank">01:35:24.720</a></span> | <span class="t">experiment with and I had better things to do than experiment with this. But you get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5727" target="_blank">01:35:27.960</a></span> | <span class="t">the idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5730" target="_blank">01:35:30.640</a></span> | <span class="t">Data augmentation is something you should always do. There's never a reason not to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5737" target="_blank">01:35:37.340</a></span> | <span class="t">data augmentation. The question is just what kind and how much. So for example, what kind?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5743" target="_blank">01:35:43.120</a></span> | <span class="t">Should you flip x, y? So clearly, for dogs and cats, no. You pretty much never see a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5750" target="_blank">01:35:50.180</a></span> | <span class="t">picture of an upside down dog. So would you do vertical flipping in this particular problem?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5757" target="_blank">01:35:57.520</a></span> | <span class="t">No you wouldn't. Would you do rotations? Yeah, you very often see cats and dogs that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5763" target="_blank">01:36:03.040</a></span> | <span class="t">kind of on their hind legs or the photos taken a little bit uneven or whatever. You certainly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5766" target="_blank">01:36:06.820</a></span> | <span class="t">would have zooming because sometimes you're close to the dog, sometimes further away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5770" target="_blank">01:36:10.260</a></span> | <span class="t">So use your intuition to think about what kind of augmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5774" target="_blank">01:36:14.480</a></span> | <span class="t">Yes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5775" target="_blank">01:36:15.480</a></span> | <span class="t">What about data augmentation? Data augmentation for color? That's an excellent point. So something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5782" target="_blank">01:36:22.680</a></span> | <span class="t">I didn't add to this, but I probably should have, is that there is a channel augmentation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5790" target="_blank">01:36:30.000</a></span> | <span class="t">parameter for the data generator in Keras. And that will slightly change the colors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5795" target="_blank">01:36:35.380</a></span> | <span class="t">That's a great idea for natural images like these because you have different white balance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5800" target="_blank">01:36:40.420</a></span> | <span class="t">you have different lighting and so forth. And indeed I think that would be a great idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5805" target="_blank">01:36:45.440</a></span> | <span class="t">So I hope during the week people will take this notebook and somebody will tell me what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5811" target="_blank">01:36:51.460</a></span> | <span class="t">is the best result they've got. And hopefully I bet that that data augmentation will include</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5818" target="_blank">01:36:58.460</a></span> | <span class="t">some fiddling around with the colors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5821" target="_blank">01:37:01.500</a></span> | <span class="t">Question on the same light screen. If you change all the images to more of long images? Would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5835" target="_blank">01:37:15.380</a></span> | <span class="t">that be equal to black and white?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5836" target="_blank">01:37:16.380</a></span> | <span class="t">We're changing it to black and white. No it wouldn't, because the Kaggle competition test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5839" target="_blank">01:37:19.980</a></span> | <span class="t">set is in color. So if you're throwing away color, you're throwing away information. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5845" target="_blank">01:37:25.260</a></span> | <span class="t">figuring out whether something is -- but the Kaggle competition is saying is this a cat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5852" target="_blank">01:37:32.260</a></span> | <span class="t">or is this a dog? And part of seeing whether something is a cat or a dog is looking at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5855" target="_blank">01:37:35.860</a></span> | <span class="t">what color it is. So if you're throwing away the color, you're making that harder. So yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5859" target="_blank">01:37:39.780</a></span> | <span class="t">you could run it on the test set and get answers, but they're going to be less accurate because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5864" target="_blank">01:37:44.380</a></span> | <span class="t">you've thrown away information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5866" target="_blank">01:37:46.380</a></span> | <span class="t">Question on the same light screen. How is it working since you've removed the flattened</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5877" target="_blank">01:37:57.100</a></span> | <span class="t">layer between the comp block and the dense layers?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5878" target="_blank">01:37:58.100</a></span> | <span class="t">Okay, so what happened to the flattened layer? And the answer is that it was there. Where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5882" target="_blank">01:38:02.180</a></span> | <span class="t">was it? Oh gosh. I forgot to add it back to this one. So I actually changed my mind about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5891" target="_blank">01:38:11.900</a></span> | <span class="t">whether to include the flattened layer and where to put it and where to put max pooling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5895" target="_blank">01:38:15.620</a></span> | <span class="t">It will come back later. So this is a slightly old version. Thank you for picking it up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5899" target="_blank">01:38:19.780</a></span> | <span class="t">Could you do a form of dropout on the raw images by randomly blanking out pieces of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5906" target="_blank">01:38:26.260</a></span> | <span class="t">the images?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5907" target="_blank">01:38:27.260</a></span> | <span class="t">Yeah, so can you do dropout on the raw images? The simple answer is yes, you could. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5912" target="_blank">01:38:32.660</a></span> | <span class="t">no reason I can't put a dropout layer right here. And that's going to drop out raw pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5918" target="_blank">01:38:38.340</a></span> | <span class="t">It turns out that's not a good idea. Throwing away input information is very different to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5924" target="_blank">01:38:44.540</a></span> | <span class="t">throwing away modeled information. Throwing away modeled information is letting you effectively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5929" target="_blank">01:38:49.780</a></span> | <span class="t">avoid overfitting the model. But you don't want to avoid overfitting the data. So you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5935" target="_blank">01:38:55.220</a></span> | <span class="t">probably don't want to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5938" target="_blank">01:38:58.900</a></span> | <span class="t">Question on the same light screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5948" target="_blank">01:39:08.140</a></span> | <span class="t">To clarify, the augmentation is at random. I just showed you 8 examples of the augmentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5954" target="_blank">01:39:14.300</a></span> | <span class="t">So what the augmentation does is it says at random, rotate by up to 20 degrees, move by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5960" target="_blank">01:39:20.740</a></span> | <span class="t">up to 10% in each direction, sheer by up to 5%, zoom by up to 10%, and flip at random</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5966" target="_blank">01:39:26.140</a></span> | <span class="t">half the time. So then I just said, OK, here are 8 cats. But what happens is every single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5971" target="_blank">01:39:31.660</a></span> | <span class="t">time an image goes into the batch, it gets randomized. So effectively, it's an infinite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5978" target="_blank">01:39:38.420</a></span> | <span class="t">number of augmented images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5980" target="_blank">01:39:40.940</a></span> | <span class="t">That doesn't have anything to do with data augmentation, so maybe we'll discuss that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5994" target="_blank">01:39:54.140</a></span> | <span class="t">on a forum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=5996" target="_blank">01:39:56.900</a></span> | <span class="t">The final concept to learn about today is batch normalization. Batch normalization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6003" target="_blank">01:40:03.140</a></span> | <span class="t">like data augmentation, is something you should always do. Why didn't VGG do it? Because it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6009" target="_blank">01:40:09.020</a></span> | <span class="t">didn't exist then. Batch norm is about a year old, maybe 18 months. Here's the basic idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6016" target="_blank">01:40:16.620</a></span> | <span class="t">When anybody who's done any machine learning probably knows that one of the first things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6023" target="_blank">01:40:23.900</a></span> | <span class="t">you want to do is take your input data, subtract its mean, and divide by its standard deviation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6031" target="_blank">01:40:31.380</a></span> | <span class="t">Why is that? Imagine that we had 40, minus 30, and 1. You can see that the outputs are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6044" target="_blank">01:40:44.980</a></span> | <span class="t">all over the place. The intermediate values, some are really big, some are really small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6051" target="_blank">01:40:51.120</a></span> | <span class="t">So if we change a weight which impacted x_1, it's going to change the loss function by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6057" target="_blank">01:40:57.780</a></span> | <span class="t">a lot, whereas if we change a weight which impacts x_3, it'll change the loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6062" target="_blank">01:41:02.940</a></span> | <span class="t">by very little.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6064" target="_blank">01:41:04.260</a></span> | <span class="t">So the different weights have very different gradients, very different amounts that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6070" target="_blank">01:41:10.620</a></span> | <span class="t">going to affect the outcome. Furthermore, as you go further down through the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6076" target="_blank">01:41:16.660</a></span> | <span class="t">that's going to multiply. Particularly when we're using something like softmax, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6079" target="_blank">01:41:19.980</a></span> | <span class="t">has an 'e' to the power of in it, you end up with these crazy big numbers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6084" target="_blank">01:41:24.700</a></span> | <span class="t">So when you have inputs that are of very different scales, it makes the whole model very fragile,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6092" target="_blank">01:41:32.300</a></span> | <span class="t">which means it is harder to learn the best set of weights and you have to use smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6096" target="_blank">01:41:36.820</a></span> | <span class="t">learning weights. This is not just true of deep learning, it's true of pretty much every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6103" target="_blank">01:41:43.020</a></span> | <span class="t">kind of machine learning model, which is why everybody who's been through the MSAM program</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6107" target="_blank">01:41:47.220</a></span> | <span class="t">here hopefully you guys all learn to normalize your inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6111" target="_blank">01:41:51.180</a></span> | <span class="t">So if you haven't done any machine learning before, no problem, just take my word for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6115" target="_blank">01:41:55.540</a></span> | <span class="t">it, you always want to normalize your inputs. It's so common that pretty much all of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6122" target="_blank">01:42:02.900</a></span> | <span class="t">deep learning libraries will normalize your inputs for you with a single parameter. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6128" target="_blank">01:42:08.660</a></span> | <span class="t">indeed we're doing it in hours because images, like pixel values only range from 0 to 255,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6139" target="_blank">01:42:19.260</a></span> | <span class="t">you don't generally worry about dividing by the standard deviation with images, but you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6144" target="_blank">01:42:24.120</a></span> | <span class="t">do generally worry about subtracting the mean. So you'll see that the first thing that our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6150" target="_blank">01:42:30.700</a></span> | <span class="t">model does is this thing called pre-process, which subtracts the mean. And the mean was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6157" target="_blank">01:42:37.420</a></span> | <span class="t">something which basically you can look it up on the internet and find out what the mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6161" target="_blank">01:42:41.260</a></span> | <span class="t">of the ImageNet data is. So these three fixed values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6166" target="_blank">01:42:46.300</a></span> | <span class="t">Now what's that got to do with batch norm? Well, imagine that somewhere along the line</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6172" target="_blank">01:42:52.140</a></span> | <span class="t">in our training, we ended up with one really big weight. Then suddenly one of our layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6179" target="_blank">01:42:59.700</a></span> | <span class="t">is going to have one really big number. And now we're going to have exactly the same problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6183" target="_blank">01:43:03.920</a></span> | <span class="t">as we had before, which is the whole model becomes very un-resilient, becomes very fragile,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6190" target="_blank">01:43:10.460</a></span> | <span class="t">becomes very hard to train, going to be all over the place. Some numbers could even get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6197" target="_blank">01:43:17.100</a></span> | <span class="t">slightly out of control.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6203" target="_blank">01:43:23.860</a></span> | <span class="t">So what do we do? Really what we want to do is to normalize not just our inputs but our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6214" target="_blank">01:43:34.420</a></span> | <span class="t">activations as well. So you may think, OK, no problem, let's just subtract the mean and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6220" target="_blank">01:43:40.020</a></span> | <span class="t">divide by the standard deviation for each of our activation layers. Unfortunately that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6225" target="_blank">01:43:45.300</a></span> | <span class="t">doesn't work. SGD is very bloody-minded. If it wants to increase one of the weights higher</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6231" target="_blank">01:43:51.420</a></span> | <span class="t">and you try to undo it by subtracting the mean and dividing by the standard deviation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6235" target="_blank">01:43:55.380</a></span> | <span class="t">the next iteration is going to try to make it higher again. So if SGD decides that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6240" target="_blank">01:44:00.860</a></span> | <span class="t">wants to make your weights of very different scales, it will do so. So just normalizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6247" target="_blank">01:44:07.020</a></span> | <span class="t">the activation layers doesn't work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6250" target="_blank">01:44:10.220</a></span> | <span class="t">So batch norm is a really neat trick for avoiding that problem. Before I tell you the trick,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6256" target="_blank">01:44:16.580</a></span> | <span class="t">I will just tell you why you want to use it. Because A) it's about 10 times faster than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6262" target="_blank">01:44:22.800</a></span> | <span class="t">not using it, particularly because it often lets you use a 10 times higher learning rate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6268" target="_blank">01:44:28.420</a></span> | <span class="t">and B) because it reduces overfitting without removing any information from the model. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6273" target="_blank">01:44:33.620</a></span> | <span class="t">these are the two things you want, less overfitting and faster models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6279" target="_blank">01:44:39.860</a></span> | <span class="t">I'm not going to go into detail on how it works. You can read about this during the week if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6282" target="_blank">01:44:42.980</a></span> | <span class="t">you're interested. But a brief outline. First step, it normalizes the intermediate layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6288" target="_blank">01:44:48.980</a></span> | <span class="t">just the same way as input layers can be normalized. The thing I just told you wouldn't work, well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6294" target="_blank">01:44:54.020</a></span> | <span class="t">it does it, but it does something else critical, which is it adds two more trainable parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6300" target="_blank">01:45:00.340</a></span> | <span class="t">One trainable parameter multiplies by all the activations, and the other one is added</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6304" target="_blank">01:45:04.580</a></span> | <span class="t">to all the activations. So effectively that is able to undo that normalization. Both of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6312" target="_blank">01:45:12.060</a></span> | <span class="t">those two things are then incorporated into the calculation of the gradient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6316" target="_blank">01:45:16.800</a></span> | <span class="t">So the model now knows that it can rescale all of the weights if it wants to without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6324" target="_blank">01:45:24.880</a></span> | <span class="t">moving one of the weights way off into the distance. And so it turns out that this does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6330" target="_blank">01:45:30.720</a></span> | <span class="t">actually effectively control the weights in a really effective way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6334" target="_blank">01:45:34.580</a></span> | <span class="t">So that's what batch normalization is. The good news is, for you to use it, you just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6338" target="_blank">01:45:38.820</a></span> | <span class="t">type batch normalization. In fact, you can put it after dense layers, you can put it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6347" target="_blank">01:45:47.860</a></span> | <span class="t">after convolutional layers, you should put it after all of your layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6352" target="_blank">01:45:52.300</a></span> | <span class="t">Here's the bad news, VGG didn't train originally with batch normalization, and adding batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6359" target="_blank">01:45:59.300</a></span> | <span class="t">normalization changes all of the weights. I think that there is a way to calculate a new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6365" target="_blank">01:46:05.820</a></span> | <span class="t">set of weights with batch normalization, I haven't gone through that process yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6372" target="_blank">01:46:12.020</a></span> | <span class="t">So what I did today was I actually grabbed the entirety of ImageNet and I trained this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6380" target="_blank">01:46:20.900</a></span> | <span class="t">model on all of ImageNet. And that then gave me a model which was basically VGG plus batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6388" target="_blank">01:46:28.940</a></span> | <span class="t">normalization. And so that is the model here that I'm loading. So this is the ImageNet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6396" target="_blank">01:46:36.380</a></span> | <span class="t">whatever it is, large visual recognition competition 2012 dataset. And so I trained this set of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6402" target="_blank">01:46:42.140</a></span> | <span class="t">weights on the entirety of ImageNet so that I created basically a VGG plus batch norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6407" target="_blank">01:46:47.540</a></span> | <span class="t">And so then I fine-tuned the VGG plus batch norm model by popping off the end and adding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6416" target="_blank">01:46:56.960</a></span> | <span class="t">a new dense layer. And then I trained it, and these only took 6 seconds because I pre-calculated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6426" target="_blank">01:47:06.440</a></span> | <span class="t">the inputs to this. Then I added data augmentation and I started training that. And then I ran</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6440" target="_blank">01:47:20.420</a></span> | <span class="t">out of time because it was class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6442" target="_blank">01:47:22.380</a></span> | <span class="t">So I think this was on the right track. I think if I had another hour or so, you guys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6449" target="_blank">01:47:29.100</a></span> | <span class="t">can play with this during the week. Because this is now like all the pieces together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6454" target="_blank">01:47:34.780</a></span> | <span class="t">It's batch norm and data augmentation and as much dropout as you want. So you'll see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6463" target="_blank">01:47:43.300</a></span> | <span class="t">what I've got here is I have dropout layers with an arbitrary amount of dropout. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6470" target="_blank">01:47:50.820</a></span> | <span class="t">in this, the way I set it up, you can go ahead and say create batch norm layers with whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6476" target="_blank">01:47:56.140</a></span> | <span class="t">amount of dropout you want. And then later on you can say I want you to change the weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6482" target="_blank">01:48:02.020</a></span> | <span class="t">to use this new amount of dropout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6484" target="_blank">01:48:04.180</a></span> | <span class="t">So this is kind of like the ultimate ImageNet fine-tuning experience. And I haven't seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6491" target="_blank">01:48:11.820</a></span> | <span class="t">anybody create this before, so this is a useful tool that didn't exist until today. And hopefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6499" target="_blank">01:48:19.340</a></span> | <span class="t">during the week, we'll keep improving it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6502" target="_blank">01:48:22.300</a></span> | <span class="t">Interestingly, I found that when I went back to even 0.5 dropout, it was still massively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6508" target="_blank">01:48:28.300</a></span> | <span class="t">overfitting. So it seems that batch normalization allows the model to be so much better at finding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6515" target="_blank">01:48:35.420</a></span> | <span class="t">the optimum that I actually needed more dropout rather than less.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6519" target="_blank">01:48:39.900</a></span> | <span class="t">So anyway, as I said, this is all something I was doing today. So I haven't quite finalized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6525" target="_blank">01:48:45.500</a></span> | <span class="t">that. What I will show you though is something I did finalize, which I did on Sunday, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6531" target="_blank">01:48:51.180</a></span> | <span class="t">is going through end-to-end an entire model-building process on MNIST. And so I want to show you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6538" target="_blank">01:48:58.780</a></span> | <span class="t">this entire process and then you guys can play with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6543" target="_blank">01:49:03.780</a></span> | <span class="t">MNIST is a great way to really experiment with and revise everything we know about CNNs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6550" target="_blank">01:49:10.460</a></span> | <span class="t">because it's very fast to train, because there are only 28x28 images, and there's also extensive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6555" target="_blank">01:49:15.300</a></span> | <span class="t">benchmarks on what are the best approaches to MNIST.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6559" target="_blank">01:49:19.820</a></span> | <span class="t">So it's very, very easy to get started with MNIST because Keras actually contains a copy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6565" target="_blank">01:49:25.580</a></span> | <span class="t">of MNIST. So we can just go from Keras.datasets, import MNIST, MNIST.loadData, and we're done.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6574" target="_blank">01:49:34.460</a></span> | <span class="t">Now MNIST are grayscale images, and everything in Keras in terms of the convolutional stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6581" target="_blank">01:49:41.020</a></span> | <span class="t">expects there to be a number of channels. So we have to use expand-dims to add this empty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6589" target="_blank">01:49:49.260</a></span> | <span class="t">dimension. So this is 60,000 images with one color, which are 28x28. So if you try to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6599" target="_blank">01:49:59.500</a></span> | <span class="t">grayscale images and get weird errors, I'm pretty sure this is what you've forgotten</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6604" target="_blank">01:50:04.780</a></span> | <span class="t">to do, just to add this kind of empty dimension, which is you actually have to tell it there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6610" target="_blank">01:50:10.140</a></span> | <span class="t">is one channel. Because otherwise it doesn't know how many channels are there. So there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6613" target="_blank">01:50:13.860</a></span> | <span class="t">is one channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6615" target="_blank">01:50:15.780</a></span> | <span class="t">The other thing I had to do was take the y-values, the labels, and one-hot encode them. Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6623" target="_blank">01:50:23.140</a></span> | <span class="t">otherwise they were like this, they were actual numbers, 50419. And we need to one-hot encode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6630" target="_blank">01:50:30.380</a></span> | <span class="t">them so that they're 50419. Remember, this is the thing that that softmax function is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6640" target="_blank">01:50:40.180</a></span> | <span class="t">trying to approximate. That's how the linear algebra works. So there are the two things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6644" target="_blank">01:50:44.820</a></span> | <span class="t">I had to do to preprocess this. Add the empty dimension and do my one-hot encoding. Then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6651" target="_blank">01:50:51.220</a></span> | <span class="t">I normalize the input by subtracting the mean and dividing by the standard deviation. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6657" target="_blank">01:50:57.300</a></span> | <span class="t">then I tried to build a linear model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6661" target="_blank">01:51:01.340</a></span> | <span class="t">So I can't fine-tune from ImageNet now because ImageNet is 224x224 and this is 28x28. ImageNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6669" target="_blank">01:51:09.580</a></span> | <span class="t">is full color and this is grayscale. So we're going to start from scratch. So all of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6674" target="_blank">01:51:14.460</a></span> | <span class="t">are going to start from random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6676" target="_blank">01:51:16.620</a></span> | <span class="t">So a linear model needs to normalize the input and needs to flatten it because I'm not going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6682" target="_blank">01:51:22.620</a></span> | <span class="t">to treat it as an image, I'm going to treat it as a single vector. And then I create my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6687" target="_blank">01:51:27.540</a></span> | <span class="t">one dense layer with 10 outputs, compile it, grab my batches, and train my linear model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6697" target="_blank">01:51:37.500</a></span> | <span class="t">And so you can see, generally speaking, the best way to train a model is to start by doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6705" target="_blank">01:51:45.440</a></span> | <span class="t">one epoch with a pretty low learning rate. So the default learning rate is 0.001, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6713" target="_blank">01:51:53.100</a></span> | <span class="t">is actually a pretty good default. So you'll find nearly all of the time I just accept</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6716" target="_blank">01:51:56.740</a></span> | <span class="t">the default learning rate and I do a single epoch. And that's enough to get it started.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6722" target="_blank">01:52:02.500</a></span> | <span class="t">Once you've got it started, you can set the learning rate really high. So 0.1 is about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6726" target="_blank">01:52:06.780</a></span> | <span class="t">as high as you ever want to go, and do another epoch. And that's going to move super fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6732" target="_blank">01:52:12.420</a></span> | <span class="t">And then gradually, you reduce the learning rate by order of magnitude at a time. So I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6738" target="_blank">01:52:18.780</a></span> | <span class="t">go to 0.01, do a few epochs, and basically keep going like that until you start overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6745" target="_blank">01:52:25.820</a></span> | <span class="t">So I got down to the point where I had a 92.7% accuracy on the training, 92.4% on the test,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6752" target="_blank">01:52:32.820</a></span> | <span class="t">and I was like, okay, that's about as far as I can go. So that's a linear model. Not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6757" target="_blank">01:52:37.500</a></span> | <span class="t">very interesting. So the next thing to do is to grab one extra dense layer in the middle,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6762" target="_blank">01:52:42.660</a></span> | <span class="t">so one hidden layer. This is what in the 80s and 90s people thought of as a neural network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6768" target="_blank">01:52:48.500</a></span> | <span class="t">one hidden layer fully connected. And so that still takes 5 seconds to train. Again, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6775" target="_blank">01:52:55.460</a></span> | <span class="t">do the same thing, one epoch with a low learning rate, then pop up the learning rate for as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6779" target="_blank">01:52:59.740</a></span> | <span class="t">long as we can, gradually decrease it, and we get 94% accuracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6787" target="_blank">01:53:07.500</a></span> | <span class="t">So you wouldn't expect a fully connected network to do that well. So let's create a CNN. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6792" target="_blank">01:53:12.900</a></span> | <span class="t">this was actually the first architecture I tried. And basically I thought, okay, we know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6797" target="_blank">01:53:17.180</a></span> | <span class="t">VGG works pretty well, so how about I create an architecture that looks like VGG, but it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6803" target="_blank">01:53:23.180</a></span> | <span class="t">much simpler because this is just 28x28. So I thought, okay, well VGG generally has a couple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6808" target="_blank">01:53:28.380</a></span> | <span class="t">of convolutional layers of 3x3, and then a max pooling layer, and then a couple more with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6813" target="_blank">01:53:33.460</a></span> | <span class="t">twice as many filters. So I just tried that. So this is kind of like my inspired by VGG</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6821" target="_blank">01:53:41.100</a></span> | <span class="t">model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6822" target="_blank">01:53:42.100</a></span> | <span class="t">And I thought, okay, so after 2 lots of max pooling, it'll go from 28x28 by 14x14 to 7x7.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6830" target="_blank">01:53:50.660</a></span> | <span class="t">Okay, that's probably enough. So then I added my 2 dense layers again. So I didn't use any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6837" target="_blank">01:53:57.140</a></span> | <span class="t">science here, it's just kind of some intuition. And it actually worked pretty well. After</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6843" target="_blank">01:54:03.900</a></span> | <span class="t">my learning rate of 0.1, I had an accuracy of 98.9%, validation accuracy of 99%. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6852" target="_blank">01:54:12.300</a></span> | <span class="t">after a few layers of 0.01, I had an accuracy of 99.75%. But look, my validation accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6859" target="_blank">01:54:19.900</a></span> | <span class="t">is only 99.2%. So look, I'm overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6863" target="_blank">01:54:23.280</a></span> | <span class="t">So this is the trick. Start by overfitting. Once you know you're overfitting, you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6868" target="_blank">01:54:28.500</a></span> | <span class="t">that you have a model that is complex enough to handle your data. So at this point, I was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6873" target="_blank">01:54:33.740</a></span> | <span class="t">like, okay, this is a good architecture. It's capable of overfitting. So let's now try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6878" target="_blank">01:54:38.160</a></span> | <span class="t">use the same architecture and reduce overfitting, but reduce the complexity of the model no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6883" target="_blank">01:54:43.860</a></span> | <span class="t">more than necessary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6885" target="_blank">01:54:45.260</a></span> | <span class="t">So step 1 of my 5-step list was data augmentation. So I added a bit of data augmentation, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6892" target="_blank">01:54:52.420</a></span> | <span class="t">then I used exactly the same model as I had before. And trained it for a while. And I found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6898" target="_blank">01:54:58.780</a></span> | <span class="t">this time I could actually train it for even longer, as you can see. And I started to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6903" target="_blank">01:55:03.680</a></span> | <span class="t">some pretty good results here, 99.3, 99.34. But by the end, you can see I'm massively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6909" target="_blank">01:55:09.220</a></span> | <span class="t">overfitting again. 99.6 training versus 91.1 test.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6915" target="_blank">01:55:15.260</a></span> | <span class="t">So data augmentation alone is not enough. And I said to you guys, we'll always use batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6920" target="_blank">01:55:20.820</a></span> | <span class="t">norm anyway. So then I add batch norm. I use batch norm on every layer. Notice that when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6929" target="_blank">01:55:29.420</a></span> | <span class="t">you use batch norm on convolution layers, you have to add axis=1. I am not going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6936" target="_blank">01:55:36.220</a></span> | <span class="t">tell you why. I want you guys to read the documentation about batch norm and try and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6941" target="_blank">01:55:41.420</a></span> | <span class="t">figure out why you need this. And then we'll have a discussion about it on the forum because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6945" target="_blank">01:55:45.780</a></span> | <span class="t">it's a really interesting analysis if you really want to understand batch norm and understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6951" target="_blank">01:55:51.260</a></span> | <span class="t">why you need this here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6954" target="_blank">01:55:54.060</a></span> | <span class="t">If you don't care about the details, that's fine. Just know type axis=1 anytime you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6959" target="_blank">01:55:59.100</a></span> | <span class="t">batch norm. And so this is like a pretty good quality modern network. You can see I've got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6965" target="_blank">01:56:05.860</a></span> | <span class="t">convolution layers, they're 3x3, and then I have batch norm, and then I have max pooling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6970" target="_blank">01:56:10.100</a></span> | <span class="t">and then at the end I have some dense layers. This is actually a pretty decent looking model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6976" target="_blank">01:56:16.300</a></span> | <span class="t">Not surprisingly, it does pretty well. So I train it for a while at 0.1, I train it for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6980" target="_blank">01:56:20.780</a></span> | <span class="t">a while at 0.01, I train it for a while at 0.001, and you can see I get up to 99.5%. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6990" target="_blank">01:56:30.380</a></span> | <span class="t">not bad. But by the end, I'm starting to overfit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=6995" target="_blank">01:56:35.380</a></span> | <span class="t">So add a little bit of dropout. And remember what I said to you guys, nowadays the rule</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7001" target="_blank">01:56:41.980</a></span> | <span class="t">for dropout is to gradually increase it. I only had time yesterday to just try adding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7009" target="_blank">01:56:49.300</a></span> | <span class="t">one layer of dropout right at the end, but as it happened, that seemed to be enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7013" target="_blank">01:56:53.800</a></span> | <span class="t">So when I just added one layer of dropout to the previous model, trained it for a while</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7017" target="_blank">01:56:57.820</a></span> | <span class="t">at 0.1, 0.01, 0.001, and it's like, oh great, my accuracy and my validation accuracy are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7028" target="_blank">01:57:08.100</a></span> | <span class="t">pretty similar, and my validation accuracy is around 99.5 to 99.6 towards the end here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7034" target="_blank">01:57:14.900</a></span> | <span class="t">So I thought, okay, that sounds pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7038" target="_blank">01:57:18.900</a></span> | <span class="t">So at 99.5 or 99.6% accuracy on handwriting recognition is pretty good, but there's one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7046" target="_blank">01:57:26.700</a></span> | <span class="t">more trick you can do which makes every model better, and it's called Ensembling. Ensembling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7052" target="_blank">01:57:32.980</a></span> | <span class="t">refers to building multiple versions of your model and combining them together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7057" target="_blank">01:57:37.780</a></span> | <span class="t">So what I did was I took all of the code from that last section and put it into a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7063" target="_blank">01:57:43.980</a></span> | <span class="t">function. So this is exactly the same model I had before, and this is my exact steps that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7069" target="_blank">01:57:49.780</a></span> | <span class="t">I talked to train it, my learning rate of 0.1, 0.01, 0.001. So at the end of this, it returns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7076" target="_blank">01:57:56.340</a></span> | <span class="t">a trained model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7078" target="_blank">01:57:58.420</a></span> | <span class="t">And so then I said, okay, 6 times fit a model and return a list of the results. So models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7087" target="_blank">01:58:07.320</a></span> | <span class="t">at the end of this contain 6 trained models using my preferred network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7095" target="_blank">01:58:15.380</a></span> | <span class="t">So then what I could do was to say, go through every one of those 6 models and predict the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7104" target="_blank">01:58:24.920</a></span> | <span class="t">output for everything in my test set. So now I have 10,000 test images by 10 outputs by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7114" target="_blank">01:58:34.500</a></span> | <span class="t">6 models. And so now I can take the average across the 6 models. And so now I'm basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7122" target="_blank">01:58:42.020</a></span> | <span class="t">saying here are 6 models, they've all been trained in the same way but from different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7126" target="_blank">01:58:46.460</a></span> | <span class="t">random starting points. And so the idea is that they will be having errors in different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7131" target="_blank">01:58:51.100</a></span> | <span class="t">places.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7132" target="_blank">01:58:52.100</a></span> | <span class="t">So let's take the average of them, and I get an accuracy of 99.7%. How good is that? It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7141" target="_blank">01:59:01.300</a></span> | <span class="t">very good. It's so good that if we go to the academic list of the best MNIST results of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7148" target="_blank">01:59:08.000</a></span> | <span class="t">all time, and many of these were specifically designed for handwriting recognition, it comes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7154" target="_blank">01:59:14.140</a></span> | <span class="t">here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7156" target="_blank">01:59:16.740</a></span> | <span class="t">So one afternoon's work gets us in the list of the best results ever found on this dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7165" target="_blank">01:59:25.140</a></span> | <span class="t">So as you can see, it's not rocket science, it's all stuff you've learned before, you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7170" target="_blank">01:59:30.700</a></span> | <span class="t">learned now, and it's a process which is fairly repeatable, can get you right up to the state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7178" target="_blank">01:59:38.580</a></span> | <span class="t">of the art.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7179" target="_blank">01:59:39.580</a></span> | <span class="t">So it was easier to do it on MNIST because I only had to wait a few seconds for each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7185" target="_blank">01:59:45.060</a></span> | <span class="t">of my trainings to finish. To get to this point on State Farm, it's going to be harder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7191" target="_blank">01:59:51.460</a></span> | <span class="t">because you're going to have to think about how do you do it in the time you have available</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7194" target="_blank">01:59:54.860</a></span> | <span class="t">and how do you do it in the context of fine-tuning and stuff like that. But hopefully you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7200" target="_blank">02:00:00.140</a></span> | <span class="t">see that you have all of the tools now at your disposal to create literally a state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7205" target="_blank">02:00:05.460</a></span> | <span class="t">of the art model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7208" target="_blank">02:00:08.160</a></span> | <span class="t">So I'm going to make all of these notebooks available. You can play with them. You can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7212" target="_blank">02:00:12.780</a></span> | <span class="t">try to get a better result from dogs and cats. As you can see, it's kind of like an incomplete</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7219" target="_blank">02:00:19.100</a></span> | <span class="t">thing that I've done here. I haven't found the best data augmentation, I haven't found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7222" target="_blank">02:00:22.340</a></span> | <span class="t">the best dropout, I haven't trained it as long as I probably need to. So there's some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7227" target="_blank">02:00:27.160</a></span> | <span class="t">work for you to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7229" target="_blank">02:00:29.260</a></span> | <span class="t">So here are your assignments for this week. This is all review now. I suggest you go back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7236" target="_blank">02:00:36.580</a></span> | <span class="t">and actually read. There's quite a bit of prose in every one of these notebooks. Hopefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7240" target="_blank">02:00:40.820</a></span> | <span class="t">now you can go back and read that prose, and some of that prose at first was a bit mysterious,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7246" target="_blank">02:00:46.340</a></span> | <span class="t">now it's going to make sense. Oh, okay, I see what it's saying. And if you read something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7250" target="_blank">02:00:50.500</a></span> | <span class="t">and it doesn't make sense, ask on the forum. Or if you read something and you want to check,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7255" target="_blank">02:00:55.900</a></span> | <span class="t">oh, is this kind of another way of saying this other thing? Ask on the forum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7260" target="_blank">02:01:00.340</a></span> | <span class="t">So these are all notebooks that we've looked at already and you should definitely review.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7265" target="_blank">02:01:05.020</a></span> | <span class="t">Ask us something on the forum. Make sure that you can replicate the steps shown in the lesson</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7269" target="_blank">02:01:09.620</a></span> | <span class="t">notebooks we've seen so far using the technique in how to use the provided notebooks we looked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7274" target="_blank">02:01:14.620</a></span> | <span class="t">at the start of class. If you haven't yet got into the top 50% of dogs vs cats, hopefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7280" target="_blank">02:01:20.260</a></span> | <span class="t">you've now got the tools to do so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7282" target="_blank">02:01:22.940</a></span> | <span class="t">If you get stuck at any point, ask on the forum. And then this is your big challenge. Can you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7288" target="_blank">02:01:28.100</a></span> | <span class="t">get into the top 50% of State Farm? Now this is tough. The first step to doing well in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7293" target="_blank">02:01:33.900</a></span> | <span class="t">a Kaggle competition is to create a validation set that gives you accurate answers. So create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7299" target="_blank">02:01:39.940</a></span> | <span class="t">a validation set, and then make sure that the validation set accuracy is the same as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7306" target="_blank">02:01:46.940</a></span> | <span class="t">you get when you submit to Kaggle. If you don't, you don't have a good enough validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7311" target="_blank">02:01:51.340</a></span> | <span class="t">set yet. Creating a validation set for State Farm is really your first challenge. It requires</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7317" target="_blank">02:01:57.100</a></span> | <span class="t">thinking long and hard about the evaluation section on that page and what that means.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7321" target="_blank">02:02:01.820</a></span> | <span class="t">And then it's thinking about which layers of the pre-trained network should I be retraining.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7329" target="_blank">02:02:09.460</a></span> | <span class="t">I actually have read through the top 20 results from the competition close 3 months ago. I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7336" target="_blank">02:02:16.420</a></span> | <span class="t">actually think all of the top 20 result methods are pretty hacky. They're pretty ugly. I feel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7344" target="_blank">02:02:24.860</a></span> | <span class="t">like there's a better way to do this that's kind of in our grasp. So I'm hoping that somebody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7351" target="_blank">02:02:31.060</a></span> | <span class="t">is going to come up with a top 20 result for State Farm that is elegant. We'll see how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7359" target="_blank">02:02:39.140</a></span> | <span class="t">we go. If not this year, maybe next year. Honestly, nobody in Kaggle quite came up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7364" target="_blank">02:02:44.940</a></span> | <span class="t">a really good way of tackling this. They've got some really good results, but with some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7369" target="_blank">02:02:49.580</a></span> | <span class="t">really convoluted methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7373" target="_blank">02:02:53.100</a></span> | <span class="t">And then as you go through a review, please, any of these techniques that you're not clear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7378" target="_blank">02:02:58.060</a></span> | <span class="t">about, these 5 pieces, please go and have a look at this additional information and see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7383" target="_blank">02:03:03.340</a></span> | <span class="t">if that helps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7385" target="_blank">02:03:05.260</a></span> | <span class="t">Alright, that was a pretty quick run-through. I hope everything goes well and I will see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=6kwQEBMandw&t=7391" target="_blank">02:03:11.180</a></span> | <span class="t">you next week.</span></div></div></body></html>