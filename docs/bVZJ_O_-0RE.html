<html><head><title>Intro to Dense Vectors for NLP and Vision</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Intro to Dense Vectors for NLP and Vision</h2><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE"><img src="https://i.ytimg.com/vi_webp/bVZJ_O_-0RE/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=110">1:50</a> Why Dense Vectors?<br><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=235">3:55</a> Word2vec and Representing Meaning<br><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=520">8:40</a> Sentence Transformers<br><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=598">9:58</a> Sentence Transformers in Python<br><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=908">15:8</a> Question-Answering<br><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1098">18:18</a> DPR in Python<br><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1795">29:55</a> Vision Transformers<br><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2002">33:22</a> OpenAI's CLIP in Python<br><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2569">42:49</a> Review and What's Next<br><br><div style="text-align: left;"><a href="./bVZJ_O_-0RE.html">Whisper Transcript</a> | <a href="./transcript_bVZJ_O_-0RE.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">I'm welcome to this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2" target="_blank">00:00:02.240</a></span> | <span class="t">We're going to start a new series on embedding methods</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=7" target="_blank">00:00:07.180</a></span> | <span class="t">for NLP, but we're also going to have a look at other embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=11" target="_blank">00:00:11.160</a></span> | <span class="t">methods as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=12" target="_blank">00:00:12.360</a></span> | <span class="t">So mainly, we're going to be focusing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=14" target="_blank">00:00:14.600</a></span> | <span class="t">on language-dense embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=17" target="_blank">00:00:17.920</a></span> | <span class="t">We might have a look at sparse embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=19" target="_blank">00:00:19.640</a></span> | <span class="t">but we've already covered that before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=21" target="_blank">00:00:21.520</a></span> | <span class="t">So I'm not 100% sure on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=23" target="_blank">00:00:23.920</a></span> | <span class="t">But definitely dense embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=26" target="_blank">00:00:26.000</a></span> | <span class="t">We're going to also have a look at how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=28" target="_blank">00:00:28.280</a></span> | <span class="t">we can build dense embeddings for images and maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=31" target="_blank">00:00:31.080</a></span> | <span class="t">some other media formats as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=33" target="_blank">00:00:33.880</a></span> | <span class="t">So I think this series of articles and videos</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=38" target="_blank">00:00:38.200</a></span> | <span class="t">will be pretty exciting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=39" target="_blank">00:00:39.960</a></span> | <span class="t">Now, what I want to start with is having a look at--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=45" target="_blank">00:00:45.960</a></span> | <span class="t">well, basically, quickly introducing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=47" target="_blank">00:00:47.800</a></span> | <span class="t">what dense vectors and dense embeddings are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=50" target="_blank">00:00:50.920</a></span> | <span class="t">And whilst we do that, I'm going to refer a lot to Word2Vec</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=55" target="_blank">00:00:55.080</a></span> | <span class="t">because that's the first widely adopted version of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=61" target="_blank">00:01:01.320</a></span> | <span class="t">And then we're going to have a look at sentence embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=66" target="_blank">00:01:06.000</a></span> | <span class="t">so how we can build sentence embeddings using the Sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=68" target="_blank">00:01:08.720</a></span> | <span class="t">Transformers library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=69" target="_blank">00:01:09.600</a></span> | <span class="t">And we're going to go through the code for that as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=71" target="_blank">00:01:11.940</a></span> | <span class="t">Then we're going to have a look at Q&A.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=73" target="_blank">00:01:13.760</a></span> | <span class="t">So Q&A is quite interesting, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=76" target="_blank">00:01:16.360</a></span> | <span class="t">And we're going to focus on Facebook AI's Dense Passage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=80" target="_blank">00:01:20.960</a></span> | <span class="t">Retriever for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=83" target="_blank">00:01:23.800</a></span> | <span class="t">And again, we are going to go through the code for that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=86" target="_blank">00:01:26.240</a></span> | <span class="t">as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=87" target="_blank">00:01:27.600</a></span> | <span class="t">And then another thing that I think is quite exciting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=91" target="_blank">00:01:31.120</a></span> | <span class="t">is image and text embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=94" target="_blank">00:01:34.200</a></span> | <span class="t">So to do that, we're going to have a look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=96" target="_blank">00:01:36.920</a></span> | <span class="t">at the new Vision Transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=98" target="_blank">00:01:38.880</a></span> | <span class="t">So I think all of that's pretty cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=102" target="_blank">00:01:42.400</a></span> | <span class="t">So let's jump straight into it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=111" target="_blank">00:01:51.360</a></span> | <span class="t">So I think the first question we want to ask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=114" target="_blank">00:01:54.200</a></span> | <span class="t">is, why would we use dense vectors in the first place?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=118" target="_blank">00:01:58.560</a></span> | <span class="t">Now, we have two options when it comes to representing text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=121" target="_blank">00:02:01.320</a></span> | <span class="t">And that is we can represent it as a dense vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=124" target="_blank">00:02:04.920</a></span> | <span class="t">or as a sparse vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=126" target="_blank">00:02:06.560</a></span> | <span class="t">Now, sparse vectors are good if we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=128" target="_blank">00:02:08.880</a></span> | <span class="t">going to focus on the syntax and the words that we're comparing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=132" target="_blank">00:02:12.680</a></span> | <span class="t">So if we had two sentences, Bill ran from the giraffe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=138" target="_blank">00:02:18.280</a></span> | <span class="t">towards the dolphin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=140" target="_blank">00:02:20.400</a></span> | <span class="t">And then we said the opposite.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=142" target="_blank">00:02:22.040</a></span> | <span class="t">So Bill ran from the dolphin towards the giraffe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=146" target="_blank">00:02:26.240</a></span> | <span class="t">Both of these sentences have the exact same words in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=150" target="_blank">00:02:30.120</a></span> | <span class="t">But they have different meanings, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=152" target="_blank">00:02:32.080</a></span> | <span class="t">So in one of them, Bill is running away from a giraffe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=154" target="_blank">00:02:34.520</a></span> | <span class="t">And the other one is running away from a dolphin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=156" target="_blank">00:02:36.600</a></span> | <span class="t">Now, when it comes to sparse vector representation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=161" target="_blank">00:02:41.520</a></span> | <span class="t">we'd find it difficult to correctly identify these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=166" target="_blank">00:02:46.440</a></span> | <span class="t">as not being the same sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=168" target="_blank">00:02:48.720</a></span> | <span class="t">Because we tend to represent words one by one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=173" target="_blank">00:02:53.200</a></span> | <span class="t">in some sort of one-hot encoding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=174" target="_blank">00:02:54.920</a></span> | <span class="t">and then compare those vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=176" target="_blank">00:02:56.600</a></span> | <span class="t">Now, we can also use n-grams so we can put two words together.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=179" target="_blank">00:02:59.520</a></span> | <span class="t">And in that case, we would identify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=181" target="_blank">00:03:01.360</a></span> | <span class="t">that there is a difference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=182" target="_blank">00:03:02.800</a></span> | <span class="t">But it's not that effective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=185" target="_blank">00:03:05.360</a></span> | <span class="t">And then we also want to consider</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=187" target="_blank">00:03:07.240</a></span> | <span class="t">where we have different words for the same meaning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=191" target="_blank">00:03:11.680</a></span> | <span class="t">So for example, if you want to say hello to someone,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=195" target="_blank">00:03:15.840</a></span> | <span class="t">you say hi, hello, hey.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=198" target="_blank">00:03:18.040</a></span> | <span class="t">I'm sure there's a million other ways of saying it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=200" target="_blank">00:03:20.680</a></span> | <span class="t">And sparse vector representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=204" target="_blank">00:03:24.240</a></span> | <span class="t">would view these as different words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=207" target="_blank">00:03:27.240</a></span> | <span class="t">So whereas sparse vectors are very good for comparing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=211" target="_blank">00:03:31.160</a></span> | <span class="t">the syntax of text, it's not very good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=214" target="_blank">00:03:34.840</a></span> | <span class="t">at comparing the semantics or the meaning behind text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=218" target="_blank">00:03:38.160</a></span> | <span class="t">And that's where we want to start using dense vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=221" target="_blank">00:03:41.760</a></span> | <span class="t">So we can see dense vectors as pretty much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=225" target="_blank">00:03:45.840</a></span> | <span class="t">a numerical representation of the semantic meaning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=231" target="_blank">00:03:51.200</a></span> | <span class="t">behind some text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=233" target="_blank">00:03:53.840</a></span> | <span class="t">And we can actually visualize a lot of these relationships.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=237" target="_blank">00:03:57.760</a></span> | <span class="t">So towards around 2013, we had WordSpec,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=241" target="_blank">00:04:01.880</a></span> | <span class="t">which was the first very popular dense vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=246" target="_blank">00:04:06.280</a></span> | <span class="t">embedding for words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=248" target="_blank">00:04:08.320</a></span> | <span class="t">And around that time, we had a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=250" target="_blank">00:04:10.720</a></span> | <span class="t">of people showing that you had things like this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=253" target="_blank">00:04:13.320</a></span> | <span class="t">what you can see on the screen, where, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=255" target="_blank">00:04:15.840</a></span> | <span class="t">we'd have days of the week clustered together,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=257" target="_blank">00:04:17.920</a></span> | <span class="t">or we would have months or other related abstract topics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=264" target="_blank">00:04:24.720</a></span> | <span class="t">represented or clustered together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=266" target="_blank">00:04:26.720</a></span> | <span class="t">in our highly dimensional space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=270" target="_blank">00:04:30.120</a></span> | <span class="t">Now, of course, this is a 3D graph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=272" target="_blank">00:04:32.760</a></span> | <span class="t">When we're actually building these dense vectors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=274" target="_blank">00:04:34.800</a></span> | <span class="t">we have many more dimensions, more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=278" target="_blank">00:04:38.480</a></span> | <span class="t">towards the 500, 700, 800 or so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=284" target="_blank">00:04:44.280</a></span> | <span class="t">So this is obviously a simplified version of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=288" target="_blank">00:04:48.040</a></span> | <span class="t">And not only will we find that similar words are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=291" target="_blank">00:04:51.360</a></span> | <span class="t">clustered in the same area, but we also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=293" target="_blank">00:04:53.160</a></span> | <span class="t">find that we can perform what I think is best described</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=297" target="_blank">00:04:57.680</a></span> | <span class="t">as arithmetic on words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=301" target="_blank">00:05:01.480</a></span> | <span class="t">So this is a very popular example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=305" target="_blank">00:05:05.000</a></span> | <span class="t">that came from around the same time as WordSpec.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=307" target="_blank">00:05:07.560</a></span> | <span class="t">If you want references and everything,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=309" target="_blank">00:05:09.760</a></span> | <span class="t">you'll be able to find them at the bottom of the article</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=312" target="_blank">00:05:12.360</a></span> | <span class="t">that this video is attached to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=314" target="_blank">00:05:14.280</a></span> | <span class="t">If you need the article, it's in the description.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=316" target="_blank">00:05:16.600</a></span> | <span class="t">Now, what we'd find is if we took the vector for king,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=321" target="_blank">00:05:21.200</a></span> | <span class="t">subtracted the vector for man, added the vector for woman,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=326" target="_blank">00:05:26.340</a></span> | <span class="t">we would not get the exact vector for queen,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=329" target="_blank">00:05:29.640</a></span> | <span class="t">but we'd get very, very close.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=332" target="_blank">00:05:32.120</a></span> | <span class="t">So the nearest vector would be the vector for queen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=335" target="_blank">00:05:35.320</a></span> | <span class="t">And I mean, I think that's super interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=338" target="_blank">00:05:38.800</a></span> | <span class="t">And this is from the start of when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=341" target="_blank">00:05:41.480</a></span> | <span class="t">had these vector embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=343" target="_blank">00:05:43.160</a></span> | <span class="t">So this is eight years ago now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=346" target="_blank">00:05:46.880</a></span> | <span class="t">And they've just gotten a lot more advanced in that time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=351" target="_blank">00:05:51.000</a></span> | <span class="t">So as I said, these examples are coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=354" target="_blank">00:05:54.040</a></span> | <span class="t">from the era of the Word2Vec.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=356" target="_blank">00:05:56.780</a></span> | <span class="t">And Word2Vec was one of the earliest versions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=361" target="_blank">00:06:01.880</a></span> | <span class="t">of these dense representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=364" target="_blank">00:06:04.100</a></span> | <span class="t">And going from the name, we know it's Word2Vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=366" target="_blank">00:06:06.920</a></span> | <span class="t">So we're converting words into vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=370" target="_blank">00:06:10.520</a></span> | <span class="t">Now, how this worked, there were two different methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=374" target="_blank">00:06:14.240</a></span> | <span class="t">We had the skip-gram method, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=375" target="_blank">00:06:15.880</a></span> | <span class="t">is what you can see now, which is where we take one word,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=379" target="_blank">00:06:19.840</a></span> | <span class="t">and we would take the sparse vector encoding for that word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=384" target="_blank">00:06:24.560</a></span> | <span class="t">on the left that you can see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=386" target="_blank">00:06:26.480</a></span> | <span class="t">And then we would, in the vector on the right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=391" target="_blank">00:06:31.440</a></span> | <span class="t">we would have a one-hot encoding for all of the words that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=395" target="_blank">00:06:35.920</a></span> | <span class="t">surround that first word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=398" target="_blank">00:06:38.680</a></span> | <span class="t">So in this case, we have fox.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=400" target="_blank">00:06:40.080</a></span> | <span class="t">And that's surrounded by the words quick brown,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=402" target="_blank">00:06:42.240</a></span> | <span class="t">jumped, and over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=404" target="_blank">00:06:44.320</a></span> | <span class="t">And this would be run through a simple feed-forward neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=407" target="_blank">00:06:47.760</a></span> | <span class="t">network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=408" target="_blank">00:06:48.760</a></span> | <span class="t">And we would go through this compression stage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=412" target="_blank">00:06:52.200</a></span> | <span class="t">And it is within that compression stage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=414" target="_blank">00:06:54.080</a></span> | <span class="t">that we would build our dense vector representation for fox.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=420" target="_blank">00:07:00.120</a></span> | <span class="t">And that would simply be a neural network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=424" target="_blank">00:07:04.320</a></span> | <span class="t">being optimized to go from fox and predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=427" target="_blank">00:07:07.520</a></span> | <span class="t">the quick brown, jumped, and over.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=429" target="_blank">00:07:09.200</a></span> | <span class="t">And this would be done many times over for every time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=433" target="_blank">00:07:13.000</a></span> | <span class="t">that word appears in a big corpus of text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=437" target="_blank">00:07:17.440</a></span> | <span class="t">with its multiple contexts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=440" target="_blank">00:07:20.300</a></span> | <span class="t">And what that does is it just builds up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=441" target="_blank">00:07:21.920</a></span> | <span class="t">like a numerical representation of that word.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=446" target="_blank">00:07:26.600</a></span> | <span class="t">And then there was the other approach,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=448" target="_blank">00:07:28.260</a></span> | <span class="t">which Word2Vec also used, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=450" target="_blank">00:07:30.560</a></span> | <span class="t">called continuous bag of words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=452" target="_blank">00:07:32.520</a></span> | <span class="t">And it's basically the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=454" target="_blank">00:07:34.320</a></span> | <span class="t">We're just swapping the order of the transformation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=458" target="_blank">00:07:38.280</a></span> | <span class="t">So on the left, we have all of our context words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=461" target="_blank">00:07:41.160</a></span> | <span class="t">And then on the right, we would have the word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=463" target="_blank">00:07:43.800</a></span> | <span class="t">that we're focusing on and we're building the embedding for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=466" target="_blank">00:07:46.860</a></span> | <span class="t">Now, Word2Vec really seemed to act</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=471" target="_blank">00:07:51.120</a></span> | <span class="t">as the catalyst for a lot of other vector embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=476" target="_blank">00:07:56.080</a></span> | <span class="t">From Word2Vec, for example, we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=478" target="_blank">00:07:58.240</a></span> | <span class="t">like sentence2Vec, doc2Vec.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=481" target="_blank">00:08:01.120</a></span> | <span class="t">We even had this one that I found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=483" target="_blank">00:08:03.640</a></span> | <span class="t">when I was researching for this, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=485" target="_blank">00:08:05.600</a></span> | <span class="t">is called batter picture2Vec, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=488" target="_blank">00:08:08.880</a></span> | <span class="t">is vector embeddings for major league baseball players.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=494" target="_blank">00:08:14.000</a></span> | <span class="t">So you've got a lot of different 2Vec methods</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=498" target="_blank">00:08:18.280</a></span> | <span class="t">that came out of the woodworks after the original Word2Vec.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=502" target="_blank">00:08:22.880</a></span> | <span class="t">And then we also had other ones like glove as well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=505" target="_blank">00:08:25.320</a></span> | <span class="t">which is worth a mention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=507" target="_blank">00:08:27.520</a></span> | <span class="t">Now, nowadays, Word2Vec is pretty outdated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=510" target="_blank">00:08:30.760</a></span> | <span class="t">and we wouldn't really go ahead and use that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=512" target="_blank">00:08:32.680</a></span> | <span class="t">So I'm not going to spend any more time on it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=514" target="_blank">00:08:34.840</a></span> | <span class="t">And we'll just move on to having a look at sentence similarity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=519" target="_blank">00:08:39.680</a></span> | <span class="t">So you can see sentence similarity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=521" target="_blank">00:08:41.160</a></span> | <span class="t">as very similar to Word2Vec in that we're building</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=526" target="_blank">00:08:46.200</a></span> | <span class="t">these dense representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=528" target="_blank">00:08:48.040</a></span> | <span class="t">But rather than representing a single word,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=529" target="_blank">00:08:49.840</a></span> | <span class="t">we're representing a sentence or a paragraph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=533" target="_blank">00:08:53.520</a></span> | <span class="t">And the way that this would be done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=536" target="_blank">00:08:56.000</a></span> | <span class="t">is using the current transform models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=538" target="_blank">00:08:58.520</a></span> | <span class="t">So BERT was the first example of doing this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=543" target="_blank">00:09:03.640</a></span> | <span class="t">And BERT by itself, you can build embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=547" target="_blank">00:09:07.880</a></span> | <span class="t">But it's based on a token-by-token embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=550" target="_blank">00:09:10.640</a></span> | <span class="t">So within BERT, you have all of these different embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=553" target="_blank">00:09:13.360</a></span> | <span class="t">but they each represent a single token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=555" target="_blank">00:09:15.800</a></span> | <span class="t">So what the guys at Sentence Transformers did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=560" target="_blank">00:09:20.200</a></span> | <span class="t">is they trained like a Siamese.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=563" target="_blank">00:09:23.480</a></span> | <span class="t">They called it Siamese BERT, where they had two BERTs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=566" target="_blank">00:09:26.360</a></span> | <span class="t">And they were trained in parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=569" target="_blank">00:09:29.160</a></span> | <span class="t">And they output a single vector for the full input that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=575" target="_blank">00:09:35.040</a></span> | <span class="t">was input into the model, which was around 128 tokens at max.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=582" target="_blank">00:09:42.840</a></span> | <span class="t">Now, this allowed us to build a single vector for sentences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=588" target="_blank">00:09:48.120</a></span> | <span class="t">And that's very good, because then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=590" target="_blank">00:09:50.240</a></span> | <span class="t">can start comparing sentences and paragraphs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=594" target="_blank">00:09:54.480</a></span> | <span class="t">So let's have a look at how we can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=597" target="_blank">00:09:57.680</a></span> | <span class="t">build that in code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=600" target="_blank">00:10:00.560</a></span> | <span class="t">So the first thing you'll need to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=602" target="_blank">00:10:02.480</a></span> | <span class="t">is pip install Sentence Transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=606" target="_blank">00:10:06.120</a></span> | <span class="t">Now, I've already done this, so I'm not going to rerun it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=610" target="_blank">00:10:10.160</a></span> | <span class="t">But if you don't have Sentence Transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=612" target="_blank">00:10:12.000</a></span> | <span class="t">you will need to install it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=616" target="_blank">00:10:16.120</a></span> | <span class="t">And then after that, all we want to do is we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=618" target="_blank">00:10:18.840</a></span> | <span class="t">want to write from Sentence Transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=622" target="_blank">00:10:22.600</a></span> | <span class="t">We want to import the Sentence Transformer object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=630" target="_blank">00:10:30.360</a></span> | <span class="t">And from there, we can just initialize our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=633" target="_blank">00:10:33.120</a></span> | <span class="t">Super easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=633" target="_blank">00:10:33.800</a></span> | <span class="t">We just write model, Sentence Transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=638" target="_blank">00:10:38.040</a></span> | <span class="t">And then in here, we just need to type our model name.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=640" target="_blank">00:10:40.800</a></span> | <span class="t">Now, if you Google Sentence Transformers or SBERT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=645" target="_blank">00:10:45.320</a></span> | <span class="t">you will find the web page for this library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=649" target="_blank">00:10:49.320</a></span> | <span class="t">And it has loads of different models on there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=653" target="_blank">00:10:53.080</a></span> | <span class="t">One of the highest performing ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=654" target="_blank">00:10:54.760</a></span> | <span class="t">that I found on there at the moment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=657" target="_blank">00:10:57.000</a></span> | <span class="t">is called All MPNet Base V2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=663" target="_blank">00:11:03.880</a></span> | <span class="t">So we just execute that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=665" target="_blank">00:11:05.240</a></span> | <span class="t">And usually, you will need to download the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=671" target="_blank">00:11:11.880</a></span> | <span class="t">So you will see a load of loading bars or progress bars.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=676" target="_blank">00:11:16.040</a></span> | <span class="t">That's fine.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=676" target="_blank">00:11:16.640</a></span> | <span class="t">It's just downloading the model for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=678" target="_blank">00:11:18.320</a></span> | <span class="t">I already have it downloaded, so I don't need to run it again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=681" target="_blank">00:11:21.840</a></span> | <span class="t">And then what we need is a set of sentences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=684" target="_blank">00:11:24.400</a></span> | <span class="t">so that we can actually compare what we--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=688" target="_blank">00:11:28.640</a></span> | <span class="t">we can compare these and look at what the Sentence Transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=693" target="_blank">00:11:33.520</a></span> | <span class="t">believes is the most similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=695" target="_blank">00:11:35.720</a></span> | <span class="t">Now, all of these are completely random,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=698" target="_blank">00:11:38.600</a></span> | <span class="t">but we have this one here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=700" target="_blank">00:11:40.720</a></span> | <span class="t">"The bees decided to have a mutiny against their queen."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=703" target="_blank">00:11:43.560</a></span> | <span class="t">And I just rewrote that in a way that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=707" target="_blank">00:11:47.920</a></span> | <span class="t">don't have any matching words between the two sentences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=711" target="_blank">00:11:51.760</a></span> | <span class="t">So we have "flying, singing insects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=713" target="_blank">00:11:53.960</a></span> | <span class="t">rebelled in opposition to the matriarch."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=716" target="_blank">00:11:56.440</a></span> | <span class="t">Now, the meaning there is pretty much the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=719" target="_blank">00:11:59.080</a></span> | <span class="t">Maybe not exactly the same, but pretty much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=722" target="_blank">00:12:02.440</a></span> | <span class="t">But there are no shared words other than, I think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=725" target="_blank">00:12:05.920</a></span> | <span class="t">"to" and "the."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=728" target="_blank">00:12:08.360</a></span> | <span class="t">Yeah, "to" and "the."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=730" target="_blank">00:12:10.560</a></span> | <span class="t">So in terms of sparse vector encoding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=735" target="_blank">00:12:15.840</a></span> | <span class="t">this wouldn't score very well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=737" target="_blank">00:12:17.080</a></span> | <span class="t">But we'll see that with dense vectors, it will.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=743" target="_blank">00:12:23.920</a></span> | <span class="t">So the first thing we want to do is encode our embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=750" target="_blank">00:12:30.120</a></span> | <span class="t">So we'll write "embeddings" plus "model.encodeSentences."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=759" target="_blank">00:12:39.240</a></span> | <span class="t">And then let's have a look at what that outputs, or at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=763" target="_blank">00:12:43.280</a></span> | <span class="t">the shape of what it outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=764" target="_blank">00:12:44.440</a></span> | <span class="t">And we see that we get seven vectors, or seven embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=770" target="_blank">00:12:50.920</a></span> | <span class="t">each one with a dimensionality of 768 values.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=776" target="_blank">00:12:56.800</a></span> | <span class="t">And we can use cosine similarity to compare all of these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=781" target="_blank">00:13:01.120</a></span> | <span class="t">Now, the easiest way to do this is we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=784" target="_blank">00:13:04.800</a></span> | <span class="t">import cosine similarity from SentenceTransformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=790" target="_blank">00:13:10.000</a></span> | <span class="t">So "SentenceTransformers.util importCosSim."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=797" target="_blank">00:13:17.760</a></span> | <span class="t">And then what we do is calculate the cosine similarity scores</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=803" target="_blank">00:13:23.360</a></span> | <span class="t">between all of our vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=806" target="_blank">00:13:26.040</a></span> | <span class="t">Now, I want to compare the final item here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=812" target="_blank">00:13:32.440</a></span> | <span class="t">so this last one, against the rest of them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=814" target="_blank">00:13:34.480</a></span> | <span class="t">because I want to see that this is the most similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=818" target="_blank">00:13:38.240</a></span> | <span class="t">So I'm just going to select that, so write "embeddings."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=823" target="_blank">00:13:43.880</a></span> | <span class="t">And we're just taking the last vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=826" target="_blank">00:13:46.880</a></span> | <span class="t">And then I want "embeddings," well, the remaining of them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=830" target="_blank">00:13:50.400</a></span> | <span class="t">so all the vectors except from the last one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=833" target="_blank">00:13:53.680</a></span> | <span class="t">And let's just have a look.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=835" target="_blank">00:13:55.480</a></span> | <span class="t">We will be able to see that we have something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=839" target="_blank">00:13:59.000</a></span> | <span class="t">that seems pretty obvious.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=840" target="_blank">00:14:00.440</a></span> | <span class="t">So this one here is the most similar, by quite a bit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=844" target="_blank">00:14:04.080</a></span> | <span class="t">0.6.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=844" target="_blank">00:14:04.960</a></span> | <span class="t">The closest is 0.19 here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=847" target="_blank">00:14:07.720</a></span> | <span class="t">So it's definitely calculating that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=849" target="_blank">00:14:09.920</a></span> | <span class="t">as a lot more similar than the other ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=853" target="_blank">00:14:13.040</a></span> | <span class="t">So if I take the argmax of that, we should see--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=862" target="_blank">00:14:22.120</a></span> | <span class="t">so 3, and take the item.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=865" target="_blank">00:14:25.800</a></span> | <span class="t">And if we go Sentences, and we put that, Sentences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=871" target="_blank">00:14:31.760</a></span> | <span class="t">and we index number 3, we see, OK,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=875" target="_blank">00:14:35.520</a></span> | <span class="t">the bees decided to have a mutiny against their queen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=878" target="_blank">00:14:38.320</a></span> | <span class="t">So it correctly identified that these two, this and this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=886" target="_blank">00:14:46.480</a></span> | <span class="t">are far more similar than the rest of the sentences, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=890" target="_blank">00:14:50.360</a></span> | <span class="t">I think is very cool, because there's not even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=893" target="_blank">00:14:53.200</a></span> | <span class="t">any similar words in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=894" target="_blank">00:14:54.880</a></span> | <span class="t">And even as a human, it's kind of, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=897" target="_blank">00:14:57.760</a></span> | <span class="t">the bees, flying, stinging insects, and matriarch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=902" target="_blank">00:15:02.360</a></span> | <span class="t">and queen, you know, it's not obvious.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=906" target="_blank">00:15:06.760</a></span> | <span class="t">So I think that's really cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=908" target="_blank">00:15:08.920</a></span> | <span class="t">Another popular use of embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=912" target="_blank">00:15:12.000</a></span> | <span class="t">for language applications is question answering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=915" target="_blank">00:15:15.560</a></span> | <span class="t">Now, question answering can be done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=918" target="_blank">00:15:18.280</a></span> | <span class="t">with a few different, let's say, architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=923" target="_blank">00:15:23.200</a></span> | <span class="t">And one of the, I think, most popular ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=925" target="_blank">00:15:25.840</a></span> | <span class="t">is open domain question answering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=928" target="_blank">00:15:28.200</a></span> | <span class="t">Now, the structure of open domain question answering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=932" target="_blank">00:15:32.080</a></span> | <span class="t">is what you can see on the screen at the moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=935" target="_blank">00:15:35.480</a></span> | <span class="t">So we ask a question that gets passed to something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=939" target="_blank">00:15:39.640</a></span> | <span class="t">called a retriever model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=941" target="_blank">00:15:41.480</a></span> | <span class="t">The retriever model contains a question encoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=945" target="_blank">00:15:45.600</a></span> | <span class="t">which encodes the question, passes it along</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=947" target="_blank">00:15:47.640</a></span> | <span class="t">to our index database.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=950" target="_blank">00:15:50.880</a></span> | <span class="t">And within there, we will have a set of contexts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=954" target="_blank">00:15:54.040</a></span> | <span class="t">Now, contexts are usually a paragraph</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=957" target="_blank">00:15:57.000</a></span> | <span class="t">that contains the answer to our question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=959" target="_blank">00:15:59.760</a></span> | <span class="t">And DPR both encodes our questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=963" target="_blank">00:16:03.160</a></span> | <span class="t">and encodes our context into the same vector space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=968" target="_blank">00:16:08.120</a></span> | <span class="t">So what we would get is, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=970" target="_blank">00:16:10.720</a></span> | <span class="t">if we had a question, what is the capital of France?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=976" target="_blank">00:16:16.000</a></span> | <span class="t">And then we also had a context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=977" target="_blank">00:16:17.440</a></span> | <span class="t">The capital of France is Paris.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=980" target="_blank">00:16:20.000</a></span> | <span class="t">DPR would attempt to encode both of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=982" target="_blank">00:16:22.440</a></span> | <span class="t">into the same vector space, or very, very close by.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=986" target="_blank">00:16:26.960</a></span> | <span class="t">So the vectors produced by both of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=988" target="_blank">00:16:28.800</a></span> | <span class="t">would be very, very similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=990" target="_blank">00:16:30.200</a></span> | <span class="t">So all we're doing in that index database</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=995" target="_blank">00:16:35.840</a></span> | <span class="t">is finding the most similar embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=999" target="_blank">00:16:39.080</a></span> | <span class="t">to our question embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1002" target="_blank">00:16:42.280</a></span> | <span class="t">And then from there, we pass that along.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1004" target="_blank">00:16:44.240</a></span> | <span class="t">We pass our context and the question again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1006" target="_blank">00:16:46.280</a></span> | <span class="t">to our reader model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1008" target="_blank">00:16:48.680</a></span> | <span class="t">Here, I've used a BERT Q&A model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1010" target="_blank">00:16:50.960</a></span> | <span class="t">It doesn't have to be BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1012" target="_blank">00:16:52.080</a></span> | <span class="t">It can be any reader for question answering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1015" target="_blank">00:16:55.520</a></span> | <span class="t">And then that outputs the specific part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1017" target="_blank">00:16:57.920</a></span> | <span class="t">of our context, which contains our answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1020" target="_blank">00:17:00.360</a></span> | <span class="t">So in the previous example, we would output Paris, hopefully.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1024" target="_blank">00:17:04.560</a></span> | <span class="t">Now, we had that DPR retriever model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1027" target="_blank">00:17:07.040</a></span> | <span class="t">DPR is Facebook AI's Dense Passage Retriever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1031" target="_blank">00:17:11.080</a></span> | <span class="t">And it actually consists of two smaller encoders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1035" target="_blank">00:17:15.480</a></span> | <span class="t">We have a question encoder and a context encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1038" target="_blank">00:17:18.040</a></span> | <span class="t">Now, during training, what we do is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1040" target="_blank">00:17:20.840</a></span> | <span class="t">we train both of these encoders in parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1044" target="_blank">00:17:24.200</a></span> | <span class="t">And we pass questions and their equivalent context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1047" target="_blank">00:17:27.960</a></span> | <span class="t">to the question and context encoder, respectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1051" target="_blank">00:17:31.720</a></span> | <span class="t">And we optimize based on a contrastive loss function.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1056" target="_blank">00:17:36.600</a></span> | <span class="t">So we compare the vectors from our question encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1060" target="_blank">00:17:40.520</a></span> | <span class="t">and the context encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1061" target="_blank">00:17:41.720</a></span> | <span class="t">And we try to minimize the difference between them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1064" target="_blank">00:17:44.640</a></span> | <span class="t">the question and context pairs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1067" target="_blank">00:17:47.160</a></span> | <span class="t">And that's how we build the DPR model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1070" target="_blank">00:17:50.680</a></span> | <span class="t">That's why it works for question answering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1073" target="_blank">00:17:53.160</a></span> | <span class="t">So it's not like our sentence transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1076" target="_blank">00:17:56.560</a></span> | <span class="t">where they are just a single model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1080" target="_blank">00:18:00.040</a></span> | <span class="t">And they're used to identify very similar sentences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1084" target="_blank">00:18:04.240</a></span> | <span class="t">This is used to identify not very similar sentences,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1088" target="_blank">00:18:08.600</a></span> | <span class="t">but very similar question and context pairs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1091" target="_blank">00:18:11.920</a></span> | <span class="t">And we will see difference in a moment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1094" target="_blank">00:18:14.880</a></span> | <span class="t">when we go through the code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1098" target="_blank">00:18:18.840</a></span> | <span class="t">So let's get started with that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1101" target="_blank">00:18:21.320</a></span> | <span class="t">So come down here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1103" target="_blank">00:18:23.520</a></span> | <span class="t">And the first thing we probably want to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1105" target="_blank">00:18:25.600</a></span> | <span class="t">is initialize our context encoder and our question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1113" target="_blank">00:18:33.720</a></span> | <span class="t">encoder from DPR.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1115" target="_blank">00:18:35.440</a></span> | <span class="t">Now, we're going to use the HookinFace transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1117" target="_blank">00:18:37.520</a></span> | <span class="t">library for this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1119" target="_blank">00:18:39.480</a></span> | <span class="t">So if you do not already, you'd have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1122" target="_blank">00:18:42.880</a></span> | <span class="t">to pip install transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1126" target="_blank">00:18:46.520</a></span> | <span class="t">Now, if you pip installed sentence transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1130" target="_blank">00:18:50.120</a></span> | <span class="t">that does include transformers as a prerequisite.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1133" target="_blank">00:18:53.400</a></span> | <span class="t">So if you installed that already,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1135" target="_blank">00:18:55.800</a></span> | <span class="t">you should already have transformers as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1137" target="_blank">00:18:57.640</a></span> | <span class="t">So first thing we want to do is, from transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1144" target="_blank">00:19:04.120</a></span> | <span class="t">we want to import a fair few classes here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1147" target="_blank">00:19:07.920</a></span> | <span class="t">So we need both the model, or the encoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1150" target="_blank">00:19:10.760</a></span> | <span class="t">and tokenizer for each for both our context encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1155" target="_blank">00:19:15.600</a></span> | <span class="t">and our question encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1156" target="_blank">00:19:16.960</a></span> | <span class="t">So let's do the context encoder first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1160" target="_blank">00:19:20.120</a></span> | <span class="t">So write DPR context encoder tokenizer and DPR context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1167" target="_blank">00:19:27.120</a></span> | <span class="t">encoder here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1170" target="_blank">00:19:30.200</a></span> | <span class="t">And then, as well as that, we also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1176" target="_blank">00:19:36.320</a></span> | <span class="t">want the question encoder tokenizer and question encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1179" target="_blank">00:19:39.880</a></span> | <span class="t">So we write DPR question encoder tokenizer and also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1186" target="_blank">00:19:46.480</a></span> | <span class="t">DPR question encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1192" target="_blank">00:19:52.200</a></span> | <span class="t">And that's all we need to import, so let's run that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1195" target="_blank">00:19:55.400</a></span> | <span class="t">And then, we can go ahead and initialize our tokenizer model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1201" target="_blank">00:20:01.320</a></span> | <span class="t">So we have the context model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1204" target="_blank">00:20:04.960</a></span> | <span class="t">Now, this is going to be the DPR context encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1211" target="_blank">00:20:11.560</a></span> | <span class="t">from pre-trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1212" target="_blank">00:20:12.480</a></span> | <span class="t">If you've ever used HuggingFace transformers before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1215" target="_blank">00:20:15.280</a></span> | <span class="t">you should recognize this from pre-trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1217" target="_blank">00:20:17.200</a></span> | <span class="t">We're just going to load in a model, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1221" target="_blank">00:20:21.080</a></span> | <span class="t">we can find on the HuggingFace.co/models website.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1226" target="_blank">00:20:26.200</a></span> | <span class="t">So if you go to that address, and you type</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1227" target="_blank">00:20:27.960</a></span> | <span class="t">in what I'm about to type in, you will find that it comes up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1231" target="_blank">00:20:31.360</a></span> | <span class="t">So I'm going to type Facebook/DPR context, so CTX encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1245" target="_blank">00:20:45.840</a></span> | <span class="t">And we want single enqueue base.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1249" target="_blank">00:20:49.920</a></span> | <span class="t">And I'm going to copy this, because we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1252" target="_blank">00:20:52.280</a></span> | <span class="t">are going to use it again in just a moment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1255" target="_blank">00:20:55.560</a></span> | <span class="t">for our context tokenizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1258" target="_blank">00:20:58.640</a></span> | <span class="t">So context tokenizer equals DPR context encoder tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1266" target="_blank">00:21:06.200</a></span> | <span class="t">from pre-trained again, from pre-trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1270" target="_blank">00:21:10.880</a></span> | <span class="t">And then, again, we want the same model name in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1276" target="_blank">00:21:16.080</a></span> | <span class="t">OK, so they are our context side of the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1287" target="_blank">00:21:27.680</a></span> | <span class="t">But we also need to get the question side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1292" target="_blank">00:21:32.760</a></span> | <span class="t">So we've got our context encoder and tokenizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1295" target="_blank">00:21:35.800</a></span> | <span class="t">Now we want to question encoder and tokenizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1300" target="_blank">00:21:40.320</a></span> | <span class="t">So I write question here and here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1303" target="_blank">00:21:43.520</a></span> | <span class="t">And we're just replacing everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1305" target="_blank">00:21:45.160</a></span> | <span class="t">where we've put CTX with question in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1308" target="_blank">00:21:48.320</a></span> | <span class="t">So it's this question and this as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1317" target="_blank">00:21:57.120</a></span> | <span class="t">And then in the model, we are just replacing CTX again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1321" target="_blank">00:22:01.840</a></span> | <span class="t">with question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1324" target="_blank">00:22:04.040</a></span> | <span class="t">It's pretty straightforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1325" target="_blank">00:22:05.520</a></span> | <span class="t">Now, I'm going to run that with you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1331" target="_blank">00:22:11.880</a></span> | <span class="t">If you haven't already got these cached on your machine,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1335" target="_blank">00:22:15.280</a></span> | <span class="t">it can take a little bit of time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1336" target="_blank">00:22:16.700</a></span> | <span class="t">because we're downloading four sets of models and tokenizers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1341" target="_blank">00:22:21.200</a></span> | <span class="t">So it can take a little bit of time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1345" target="_blank">00:22:25.480</a></span> | <span class="t">Now, I already have them, so I don't need to wait for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1349" target="_blank">00:22:29.880</a></span> | <span class="t">Now, first thing I want to do is set up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1355" target="_blank">00:22:35.120</a></span> | <span class="t">a set of questions and context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1357" target="_blank">00:22:37.440</a></span> | <span class="t">So I have three questions here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1359" target="_blank">00:22:39.680</a></span> | <span class="t">Well, you can read them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1360" target="_blank">00:22:40.680</a></span> | <span class="t">I'm not going to go through them all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1362" target="_blank">00:22:42.220</a></span> | <span class="t">And then we have context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1363" target="_blank">00:22:43.600</a></span> | <span class="t">Each question has a couple of contexts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1366" target="_blank">00:22:46.800</a></span> | <span class="t">that are kind of relevant, but then just one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1370" target="_blank">00:22:50.160</a></span> | <span class="t">that is actually the answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1372" target="_blank">00:22:52.760</a></span> | <span class="t">And inside here, I've also put in the questions themselves,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1379" target="_blank">00:22:59.040</a></span> | <span class="t">because I want to prove that this is not just a sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1382" target="_blank">00:23:02.920</a></span> | <span class="t">transformer where it's finding the most similar sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1388" target="_blank">00:23:08.120</a></span> | <span class="t">So it should, when we have these questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1391" target="_blank">00:23:11.520</a></span> | <span class="t">it shouldn't return-- like for this one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1393" target="_blank">00:23:13.600</a></span> | <span class="t">it shouldn't return what is a best-selling sci-fi book.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1396" target="_blank">00:23:16.400</a></span> | <span class="t">It should instead return the best-selling sci-fi book</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1399" target="_blank">00:23:19.840</a></span> | <span class="t">is "Doom."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1400" target="_blank">00:23:20.740</a></span> | <span class="t">So we should see that there is a difference between using DPR</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1405" target="_blank">00:23:25.040</a></span> | <span class="t">and using sentence transforms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1409" target="_blank">00:23:29.000</a></span> | <span class="t">So run that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1410" target="_blank">00:23:30.640</a></span> | <span class="t">And then what we want to do is tokenize everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1413" target="_blank">00:23:33.080</a></span> | <span class="t">So we're going to tokenize our context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1417" target="_blank">00:23:37.960</a></span> | <span class="t">So I'm going to write xbtokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1420" target="_blank">00:23:40.640</a></span> | <span class="t">And we want the context tokenizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1425" target="_blank">00:23:45.400</a></span> | <span class="t">And then in here, we're going to pass our context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1428" target="_blank">00:23:48.840</a></span> | <span class="t">And then if you use HuggingFace transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1433" target="_blank">00:23:53.120</a></span> | <span class="t">you should recognize this as well, so maxLength here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1437" target="_blank">00:23:57.800</a></span> | <span class="t">So for this, I'm going to put 256.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1441" target="_blank">00:24:01.280</a></span> | <span class="t">And I'll set padding equal to maxLength.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1444" target="_blank">00:24:04.680</a></span> | <span class="t">We don't need to truncate anything, I don't think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1448" target="_blank">00:24:08.640</a></span> | <span class="t">No, they're all very short.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1450" target="_blank">00:24:10.600</a></span> | <span class="t">So this maxLength, we could even reduce it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1453" target="_blank">00:24:13.600</a></span> | <span class="t">to something pretty small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1454" target="_blank">00:24:14.960</a></span> | <span class="t">But I'm going to leave it at that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1459" target="_blank">00:24:19.520</a></span> | <span class="t">So we'll pad up to the maxLength.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1461" target="_blank">00:24:21.400</a></span> | <span class="t">And oh, the only thing we do need to include here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1465" target="_blank">00:24:25.000</a></span> | <span class="t">is that we want to return PyTorch tensors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1467" target="_blank">00:24:27.600</a></span> | <span class="t">So return tensors equals pt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1471" target="_blank">00:24:31.840</a></span> | <span class="t">OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1472" target="_blank">00:24:32.800</a></span> | <span class="t">And then what we can do is we write xbEmbeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1478" target="_blank">00:24:38.920</a></span> | <span class="t">So this is how we build our context embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1483" target="_blank">00:24:43.720</a></span> | <span class="t">xbEmbed, I'll just call it xb, is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1487" target="_blank">00:24:47.640</a></span> | <span class="t">equal to model, the context model, ctxModel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1493" target="_blank">00:24:53.320</a></span> | <span class="t">And then in here, we pass our tokens, xbTokens, like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1498" target="_blank">00:24:58.840</a></span> | <span class="t">And then for our questions, we do exactly the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1502" target="_blank">00:25:02.720</a></span> | <span class="t">But of course, we just replace the context part of it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1505" target="_blank">00:25:05.760</a></span> | <span class="t">with questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1506" target="_blank">00:25:06.960</a></span> | <span class="t">So here, we have the question tokenizer, we have questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1514" target="_blank">00:25:14.680</a></span> | <span class="t">and we have the question model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1517" target="_blank">00:25:17.920</a></span> | <span class="t">And then here, I'm going to rename xb to xq, so our query.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1523" target="_blank">00:25:23.200</a></span> | <span class="t">OK, let's have a look at what we get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1528" target="_blank">00:25:28.480</a></span> | <span class="t">So first, let's have a look at what we have inside xq.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1534" target="_blank">00:25:34.880</a></span> | <span class="t">So we'll see that we have a few different tensors in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1538" target="_blank">00:25:38.320</a></span> | <span class="t">So I'll just write xq keys to see what we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1540" target="_blank">00:25:40.600</a></span> | <span class="t">You see that we actually only have one output here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1548" target="_blank">00:25:48.320</a></span> | <span class="t">so the pooler output, which is fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1549" target="_blank">00:25:49.960</a></span> | <span class="t">because that's what we need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1552" target="_blank">00:25:52.160</a></span> | <span class="t">So we write xq, pooler output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1555" target="_blank">00:25:55.440</a></span> | <span class="t">And these here are our embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1560" target="_blank">00:26:00.200</a></span> | <span class="t">So we can write shape to see the shape of those embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1562" target="_blank">00:26:02.960</a></span> | <span class="t">So we have three vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1564" target="_blank">00:26:04.720</a></span> | <span class="t">So the number of questions that we passed up here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1569" target="_blank">00:26:09.120</a></span> | <span class="t">and each one of those questions has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1571" target="_blank">00:26:11.080</a></span> | <span class="t">been encoded into a embedding of 768 dimensions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1577" target="_blank">00:26:17.920</a></span> | <span class="t">So that looks good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1579" target="_blank">00:26:19.720</a></span> | <span class="t">And we could do the same for xb if we want as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1583" target="_blank">00:26:23.200</a></span> | <span class="t">It's exactly the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1584" target="_blank">00:26:24.480</a></span> | <span class="t">So write xb, and we'll see the shape.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1589" target="_blank">00:26:29.000</a></span> | <span class="t">Just at this time, we have nine vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1591" target="_blank">00:26:31.000</a></span> | <span class="t">because, obviously, we have more context than we do questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1595" target="_blank">00:26:35.280</a></span> | <span class="t">So what we want to do now, I'm going to import Torch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1599" target="_blank">00:26:39.960</a></span> | <span class="t">So again, this should have been installed already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1603" target="_blank">00:26:43.280</a></span> | <span class="t">with Hugging Face Transformers and also Sentence Transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1607" target="_blank">00:26:47.920</a></span> | <span class="t">So if you've gotten this far, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1609" target="_blank">00:26:49.280</a></span> | <span class="t">don't need to worry about installing this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1612" target="_blank">00:26:52.920</a></span> | <span class="t">What I'm going to do is go for i, and then the query vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1618" target="_blank">00:26:58.600</a></span> | <span class="t">in xq, xq, pooler output, pooler output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1627" target="_blank">00:27:07.880</a></span> | <span class="t">So I'm going to enumerate that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1629" target="_blank">00:27:09.120</a></span> | <span class="t">So what I'm doing here is I'm going to run through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1634" target="_blank">00:27:14.680</a></span> | <span class="t">I'm going to create a loop to go through each query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1638" target="_blank">00:27:18.200</a></span> | <span class="t">and to get the most similar vector from xb,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1644" target="_blank">00:27:24.760</a></span> | <span class="t">so from our encoded context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1648" target="_blank">00:27:28.680</a></span> | <span class="t">So we write probs equals cosine similarity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1652" target="_blank">00:27:32.640</a></span> | <span class="t">So these are our similarity scores,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1654" target="_blank">00:27:34.680</a></span> | <span class="t">doing exactly the same as we did before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1657" target="_blank">00:27:37.600</a></span> | <span class="t">We're still going to write xq vec, so the single vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1661" target="_blank">00:27:41.840</a></span> | <span class="t">at the moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1662" target="_blank">00:27:42.640</a></span> | <span class="t">And from here, we just want xb pooler output, pooler output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1670" target="_blank">00:27:50.800</a></span> | <span class="t">And from there, we want to get the argmax, so the maximum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1678" target="_blank">00:27:58.200</a></span> | <span class="t">argument, so the highest score in our probability right here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1682" target="_blank">00:28:02.800</a></span> | <span class="t">So Torch argmax, and here we have props.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1685" target="_blank">00:28:05.960</a></span> | <span class="t">And then what I'm going to do is I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1687" target="_blank">00:28:07.420</a></span> | <span class="t">going to print the current question that we're asking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1691" target="_blank">00:28:11.120</a></span> | <span class="t">so questions i.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1693" target="_blank">00:28:13.880</a></span> | <span class="t">Now I'm going to print the context which has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1697" target="_blank">00:28:17.840</a></span> | <span class="t">been chosen from our argmax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1700" target="_blank">00:28:20.000</a></span> | <span class="t">So we just write context argmax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1704" target="_blank">00:28:24.480</a></span> | <span class="t">And then I'm just going to put this in here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1707" target="_blank">00:28:27.200</a></span> | <span class="t">so we have a little bit of separation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1709" target="_blank">00:28:29.960</a></span> | <span class="t">Let's have a see what we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1711" target="_blank">00:28:31.720</a></span> | <span class="t">So we get, what is the capital city of Australia?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1715" target="_blank">00:28:35.040</a></span> | <span class="t">Now remember, this exact question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1717" target="_blank">00:28:37.200</a></span> | <span class="t">was also in our context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1719" target="_blank">00:28:39.560</a></span> | <span class="t">And it's not returning the exact sentence back to us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1726" target="_blank">00:28:46.080</a></span> | <span class="t">or the exact question back to us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1727" target="_blank">00:28:47.440</a></span> | <span class="t">It's actually returning as the answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1730" target="_blank">00:28:50.200</a></span> | <span class="t">So Canberra is the capital city of Australia.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1733" target="_blank">00:28:53.760</a></span> | <span class="t">Now second one, as we had hoped, the best-selling sci-fi book</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1739" target="_blank">00:28:59.400</a></span> | <span class="t">has been chosen to do in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1741" target="_blank">00:29:01.560</a></span> | <span class="t">And then I just wanted to include this one as well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1743" target="_blank">00:29:03.840</a></span> | <span class="t">to point out that it's not perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1746" target="_blank">00:29:06.480</a></span> | <span class="t">It doesn't always get things right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1748" target="_blank">00:29:08.620</a></span> | <span class="t">So in this case, it didn't find the correct answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1752" target="_blank">00:29:12.700</a></span> | <span class="t">of how many searches are performed on Google.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1754" target="_blank">00:29:14.960</a></span> | <span class="t">If we have a look at the context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1757" target="_blank">00:29:17.520</a></span> | <span class="t">so the correct answer should have been this one here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1762" target="_blank">00:29:22.040</a></span> | <span class="t">So Google serves more than 2 trillion queries annually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1767" target="_blank">00:29:27.240</a></span> | <span class="t">So it didn't get that one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1768" target="_blank">00:29:28.880</a></span> | <span class="t">But the other two it did get, despite having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1772" target="_blank">00:29:32.680</a></span> | <span class="t">the actual questions in there as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1775" target="_blank">00:29:35.420</a></span> | <span class="t">One of them here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1778" target="_blank">00:29:38.740</a></span> | <span class="t">So again, I think that's really cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1780" target="_blank">00:29:40.660</a></span> | <span class="t">And I think Q&A is something that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1783" target="_blank">00:29:43.380</a></span> | <span class="t">has a lot of potential in many businesses around the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1790" target="_blank">00:29:50.580</a></span> | <span class="t">So I think that's a very cool one to use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1795" target="_blank">00:29:55.020</a></span> | <span class="t">OK, so the next one I want to cover</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1801" target="_blank">00:30:01.540</a></span> | <span class="t">is a mix of language and also vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1809" target="_blank">00:30:09.120</a></span> | <span class="t">So recently, computer vision has had a few advances</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1815" target="_blank">00:30:15.160</a></span> | <span class="t">from the discipline of NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1818" target="_blank">00:30:18.640</a></span> | <span class="t">So in NLP, we've been using transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1820" target="_blank">00:30:20.720</a></span> | <span class="t">for a reasonable amount of time now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1824" target="_blank">00:30:24.360</a></span> | <span class="t">And transformers have proven to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1827" target="_blank">00:30:27.880</a></span> | <span class="t">incredible models for language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1831" target="_blank">00:30:31.480</a></span> | <span class="t">And very recently, transformers have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1834" target="_blank">00:30:34.340</a></span> | <span class="t">been applied to computer vision as well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1837" target="_blank">00:30:37.740</a></span> | <span class="t">which is very cool, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1840" target="_blank">00:30:40.340</a></span> | <span class="t">And what we're finding is that a model or an architecture that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1845" target="_blank">00:30:45.660</a></span> | <span class="t">can be used for language can also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1846" target="_blank">00:30:46.980</a></span> | <span class="t">be used for computer vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1850" target="_blank">00:30:50.320</a></span> | <span class="t">And I think that's super cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1854" target="_blank">00:30:54.420</a></span> | <span class="t">So I want to show you one of those models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1859" target="_blank">00:30:59.220</a></span> | <span class="t">or briefly touch upon one of those models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1862" target="_blank">00:31:02.260</a></span> | <span class="t">We will go into it in more detail</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1863" target="_blank">00:31:03.940</a></span> | <span class="t">in a future article and video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1866" target="_blank">00:31:06.900</a></span> | <span class="t">But for now, I'm just going to mention it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1869" target="_blank">00:31:09.060</a></span> | <span class="t">We have the Vision Transformer, which is very recent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1874" target="_blank">00:31:14.100</a></span> | <span class="t">I think the paper is January 2021, if I'm not wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1879" target="_blank">00:31:19.180</a></span> | <span class="t">And although we don't need a Vision Transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1882" target="_blank">00:31:22.100</a></span> | <span class="t">to build an embedding for an image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1886" target="_blank">00:31:26.380</a></span> | <span class="t">I think the fact that we can use it is pretty cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1889" target="_blank">00:31:29.360</a></span> | <span class="t">And we can really do it very easily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1891" target="_blank">00:31:31.300</a></span> | <span class="t">with Hugging Face Transformers, as we will see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1893" target="_blank">00:31:33.780</a></span> | <span class="t">when we go through the code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1895" target="_blank">00:31:35.540</a></span> | <span class="t">Now, a very interesting use of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1900" target="_blank">00:31:40.020</a></span> | <span class="t">is to actually take two different encoders,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1903" target="_blank">00:31:43.400</a></span> | <span class="t">both transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1905" target="_blank">00:31:45.340</a></span> | <span class="t">The text encoder is more of a traditional transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1908" target="_blank">00:31:48.860</a></span> | <span class="t">obviously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1909" target="_blank">00:31:49.860</a></span> | <span class="t">And the image encoder is our new Vision Transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1914" target="_blank">00:31:54.460</a></span> | <span class="t">And we can actually train them together,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1917" target="_blank">00:31:57.220</a></span> | <span class="t">like we did with DPR, the bi-encoder architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1920" target="_blank">00:32:00.780</a></span> | <span class="t">And what we can do is train it to put images and language,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1927" target="_blank">00:32:07.180</a></span> | <span class="t">so language that describes an image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1929" target="_blank">00:32:09.580</a></span> | <span class="t">and map them to the same point in a vector space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1936" target="_blank">00:32:16.060</a></span> | <span class="t">or very close, at least.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1938" target="_blank">00:32:18.360</a></span> | <span class="t">And that's what I've tried to visualize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1940" target="_blank">00:32:20.020</a></span> | <span class="t">You can see on the screen now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1941" target="_blank">00:32:21.380</a></span> | <span class="t">So we have two logs running.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1942" target="_blank">00:32:22.540</a></span> | <span class="t">We process that through our text encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1944" target="_blank">00:32:24.980</a></span> | <span class="t">And we get a very similar vector to if we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1946" target="_blank">00:32:26.980</a></span> | <span class="t">took the picture of two dogs running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1949" target="_blank">00:32:29.460</a></span> | <span class="t">and process that through an image encoder, which would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1952" target="_blank">00:32:32.900</a></span> | <span class="t">be our Vision Transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1955" target="_blank">00:32:35.540</a></span> | <span class="t">So I think that's--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1957" target="_blank">00:32:37.300</a></span> | <span class="t">I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1957" target="_blank">00:32:37.820</a></span> | <span class="t">For me, I think that's so cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1961" target="_blank">00:32:41.060</a></span> | <span class="t">Now, I'm going to be using these three pictures that I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1966" target="_blank">00:32:46.340</a></span> | <span class="t">got from Unsplash.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1967" target="_blank">00:32:47.660</a></span> | <span class="t">If you want to see the photo credits,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1970" target="_blank">00:32:50.020</a></span> | <span class="t">they will be either in the article,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1972" target="_blank">00:32:52.140</a></span> | <span class="t">if you're reading the article, or they'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1973" target="_blank">00:32:53.800</a></span> | <span class="t">be in the video description, if not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1977" target="_blank">00:32:57.100</a></span> | <span class="t">And what I'm going to do is we have these three pictures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1980" target="_blank">00:33:00.300</a></span> | <span class="t">We're going to encode those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1981" target="_blank">00:33:01.540</a></span> | <span class="t">And I'm also going to encode these three captions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1984" target="_blank">00:33:04.620</a></span> | <span class="t">and a few other captions as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1986" target="_blank">00:33:06.660</a></span> | <span class="t">And we're going to see if they match.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1989" target="_blank">00:33:09.540</a></span> | <span class="t">So we're going to perform a similarity, or a cosine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1992" target="_blank">00:33:12.580</a></span> | <span class="t">similarity search across them, and see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1994" target="_blank">00:33:14.940</a></span> | <span class="t">which pairs match the closest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=1997" target="_blank">00:33:17.780</a></span> | <span class="t">And we'll see the results are pretty cool, in my opinion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2003" target="_blank">00:33:23.980</a></span> | <span class="t">So let's jump into it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2006" target="_blank">00:33:26.980</a></span> | <span class="t">Again, we're going to be using Transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2009" target="_blank">00:33:29.660</a></span> | <span class="t">And we're going to be using a new model from OpenAI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2013" target="_blank">00:33:33.300</a></span> | <span class="t">which is for the image and text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2017" target="_blank">00:33:37.420</a></span> | <span class="t">Similar to DPR, where DPR is in question and context encoding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2023" target="_blank">00:33:43.060</a></span> | <span class="t">Clip is using two encoders to do image and caption encoding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2029" target="_blank">00:33:49.260</a></span> | <span class="t">which is pretty cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2030" target="_blank">00:33:50.720</a></span> | <span class="t">So we're going to do, from Transformers, import Clip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2038" target="_blank">00:33:58.300</a></span> | <span class="t">Processor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2039" target="_blank">00:33:59.140</a></span> | <span class="t">So I'm kind of viewing this processor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2041" target="_blank">00:34:01.700</a></span> | <span class="t">as what we could call a tokenizer in typical language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2047" target="_blank">00:34:07.900</a></span> | <span class="t">transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2050" target="_blank">00:34:10.060</a></span> | <span class="t">And then we want the Clip model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2052" target="_blank">00:34:12.660</a></span> | <span class="t">So this contains both encoders for us,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2055" target="_blank">00:34:15.140</a></span> | <span class="t">so we don't have to mess around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2057" target="_blank">00:34:17.220</a></span> | <span class="t">Like we did with DPR, where we imported four classes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2063" target="_blank">00:34:23.100</a></span> | <span class="t">Here, we're just importing the two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2066" target="_blank">00:34:26.820</a></span> | <span class="t">And then what we want to do is we'll just initialize those.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2069" target="_blank">00:34:29.580</a></span> | <span class="t">So again, very similar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2072" target="_blank">00:34:32.180</a></span> | <span class="t">So we do Clip model from Pre-trained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2078" target="_blank">00:34:38.900</a></span> | <span class="t">And in here, we write OpenAI, Clip VIT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2088" target="_blank">00:34:48.620</a></span> | <span class="t">So it's the Vision Transformer, this VIT you see here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2091" target="_blank">00:34:51.780</a></span> | <span class="t">It refers to the Vision Transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2093" target="_blank">00:34:53.700</a></span> | <span class="t">which Clip is using or is based on, at least the Vision aspect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2101" target="_blank">00:35:01.540</a></span> | <span class="t">And we want to write Base Patch 32.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2106" target="_blank">00:35:06.500</a></span> | <span class="t">So I mean, we'll go into it in more detail,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2108" target="_blank">00:35:08.860</a></span> | <span class="t">but the patch part of that is referring to the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2111" target="_blank">00:35:11.500</a></span> | <span class="t">that the model almost tokenizes your images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2116" target="_blank">00:35:16.380</a></span> | <span class="t">It splits an image into different patches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2119" target="_blank">00:35:19.340</a></span> | <span class="t">And that's the patch size, the patch 32 there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2123" target="_blank">00:35:23.380</a></span> | <span class="t">So we also want the processor, which again, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2127" target="_blank">00:35:27.540</a></span> | <span class="t">can kind of see that as akin to or equivalent to our tokenizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2134" target="_blank">00:35:34.340</a></span> | <span class="t">And we're just doing this for language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2139" target="_blank">00:35:39.420</a></span> | <span class="t">And again, I'll just copy that across.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2142" target="_blank">00:35:42.580</a></span> | <span class="t">OK, so model processor looks good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2150" target="_blank">00:35:50.420</a></span> | <span class="t">Let me rerun it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2153" target="_blank">00:35:53.740</a></span> | <span class="t">OK, again, I already have it cached,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2156" target="_blank">00:35:56.620</a></span> | <span class="t">so it won't download for me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2158" target="_blank">00:35:58.900</a></span> | <span class="t">And you'll get this thing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2162" target="_blank">00:36:02.420</a></span> | <span class="t">Don't worry about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2163" target="_blank">00:36:03.340</a></span> | <span class="t">It still works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2164" target="_blank">00:36:04.740</a></span> | <span class="t">Now I'm going to copy in the code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2167" target="_blank">00:36:07.020</a></span> | <span class="t">I'm using to get the photos.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2169" target="_blank">00:36:09.260</a></span> | <span class="t">So I have the photo URLs here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2171" target="_blank">00:36:11.220</a></span> | <span class="t">I'm using a pill to create the image object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2177" target="_blank">00:36:17.620</a></span> | <span class="t">And I'm using requests to actually get the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2180" target="_blank">00:36:20.300</a></span> | <span class="t">from the URL that we have here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2182" target="_blank">00:36:22.460</a></span> | <span class="t">And then down here, I'm just going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2183" target="_blank">00:36:23.880</a></span> | <span class="t">to show you what images we have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2185" target="_blank">00:36:25.460</a></span> | <span class="t">So I actually need to get matplotlib in there as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2190" target="_blank">00:36:30.260</a></span> | <span class="t">So import matplotlib.pyplot PLT and numpy as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2199" target="_blank">00:36:39.380</a></span> | <span class="t">OK, and we'll see those images that we saw before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2206" target="_blank">00:36:46.820</a></span> | <span class="t">So we have the puppy or dog running,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2210" target="_blank">00:36:50.060</a></span> | <span class="t">the dog hiding behind tree, and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2211" target="_blank">00:36:51.820</a></span> | <span class="t">have the two dogs running.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2213" target="_blank">00:36:53.540</a></span> | <span class="t">OK, so they are our images, and we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2215" target="_blank">00:36:55.740</a></span> | <span class="t">stored them in images here, OK?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2220" target="_blank">00:37:00.500</a></span> | <span class="t">And the next part are captions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2222" target="_blank">00:37:02.820</a></span> | <span class="t">So I've just written these six captions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2226" target="_blank">00:37:06.620</a></span> | <span class="t">The first three are actually the captions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2230" target="_blank">00:37:10.460</a></span> | <span class="t">and then the other three I just made up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2233" target="_blank">00:37:13.580</a></span> | <span class="t">I included trees and park in there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2235" target="_blank">00:37:15.620</a></span> | <span class="t">because they look like, well, there's a tree here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2237" target="_blank">00:37:17.740</a></span> | <span class="t">and there's a park here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2238" target="_blank">00:37:18.740</a></span> | <span class="t">So try and make it a little bit more difficult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2243" target="_blank">00:37:23.620</a></span> | <span class="t">But I mean, they're reasonably straightforward still,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2246" target="_blank">00:37:26.780</a></span> | <span class="t">I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2247" target="_blank">00:37:27.660</a></span> | <span class="t">And then to create our--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2249" target="_blank">00:37:29.300</a></span> | <span class="t">you can imagine, you can see these as tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2252" target="_blank">00:37:32.620</a></span> | <span class="t">We do inputs, so processor, similar to our tokenizer again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2259" target="_blank">00:37:39.700</a></span> | <span class="t">And we have a few inputs here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2262" target="_blank">00:37:42.540</a></span> | <span class="t">So we have the text, and we want to input our captions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2266" target="_blank">00:37:46.420</a></span> | <span class="t">And then we also have images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2268" target="_blank">00:37:48.420</a></span> | <span class="t">And of course, we just input our images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2271" target="_blank">00:37:51.300</a></span> | <span class="t">And then we want to return the return tensors, or tensor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2277" target="_blank">00:37:57.300</a></span> | <span class="t">equal to PT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2279" target="_blank">00:37:59.660</a></span> | <span class="t">And we set padding to true, OK?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2283" target="_blank">00:38:03.660</a></span> | <span class="t">Return tensors PT, OK?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2295" target="_blank">00:38:15.500</a></span> | <span class="t">And if we-- let me have a quick look at what we have here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2298" target="_blank">00:38:18.220</a></span> | <span class="t">So we have our input IDs, pixel values, and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2302" target="_blank">00:38:22.020</a></span> | <span class="t">So input IDs, we also have attention here as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2306" target="_blank">00:38:26.060</a></span> | <span class="t">So these first two are for our text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2310" target="_blank">00:38:30.500</a></span> | <span class="t">and then pixel values are for the images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2312" target="_blank">00:38:32.340</a></span> | <span class="t">And now what we want to do is create our encodings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2319" target="_blank">00:38:39.540</a></span> | <span class="t">So in here, because we're using the clip model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2322" target="_blank">00:38:42.780</a></span> | <span class="t">we're actually going to perform the encodings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2325" target="_blank">00:38:45.180</a></span> | <span class="t">And it's also going to do the whole similarity checking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2329" target="_blank">00:38:49.300</a></span> | <span class="t">for us as well, and identify which images and captions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2333" target="_blank">00:38:53.300</a></span> | <span class="t">are the closest pairs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2335" target="_blank">00:38:55.660</a></span> | <span class="t">Or what it's going to do is go through each image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2338" target="_blank">00:38:58.140</a></span> | <span class="t">and find the caption that it believes belongs to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2341" target="_blank">00:39:01.620</a></span> | <span class="t">So like before, we just write inputs here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2345" target="_blank">00:39:05.020</a></span> | <span class="t">And I think maybe let's have a look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2347" target="_blank">00:39:07.740</a></span> | <span class="t">at what we have in our outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2350" target="_blank">00:39:10.180</a></span> | <span class="t">So we can see we'll have a few things here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2353" target="_blank">00:39:13.500</a></span> | <span class="t">that I think are pretty useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2355" target="_blank">00:39:15.820</a></span> | <span class="t">So we have the logics per image and per text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2359" target="_blank">00:39:19.300</a></span> | <span class="t">So for these, we can--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2361" target="_blank">00:39:21.460</a></span> | <span class="t">for each of our text, we can use this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2364" target="_blank">00:39:24.660</a></span> | <span class="t">to get the most probable image that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2369" target="_blank">00:39:29.540</a></span> | <span class="t">is assigned to each caption.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2371" target="_blank">00:39:31.940</a></span> | <span class="t">And in logics per image, we can use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2374" target="_blank">00:39:34.380</a></span> | <span class="t">these to find the most probable caption for each image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2379" target="_blank">00:39:39.820</a></span> | <span class="t">And then-- so what we were doing before where we were just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2382" target="_blank">00:39:42.340</a></span> | <span class="t">extracting the embeddings, we can also do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2385" target="_blank">00:39:45.540</a></span> | <span class="t">And maybe I'll just copy in the code for that as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2388" target="_blank">00:39:48.860</a></span> | <span class="t">So we have the text embeddings here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2390" target="_blank">00:39:50.380</a></span> | <span class="t">So we can extract those if we want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2391" target="_blank">00:39:51.840</a></span> | <span class="t">And we also have the image embeddings in here as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2395" target="_blank">00:39:55.620</a></span> | <span class="t">And then a little further down, we have the logics somewhere,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2399" target="_blank">00:39:59.260</a></span> | <span class="t">pool output here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2400" target="_blank">00:40:00.740</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2402" target="_blank">00:40:02.700</a></span> | <span class="t">So we have the pool outputs and the logics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2405" target="_blank">00:40:05.820</a></span> | <span class="t">OK, so let me just close that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2409" target="_blank">00:40:09.660</a></span> | <span class="t">And I do believe we also have a few more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2411" target="_blank">00:40:11.460</a></span> | <span class="t">So let me just show you those quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2414" target="_blank">00:40:14.620</a></span> | <span class="t">Yeah, we have a few tensors there as well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2417" target="_blank">00:40:17.860</a></span> | <span class="t">vision model output, text model output as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2420" target="_blank">00:40:20.900</a></span> | <span class="t">Now what we'll do is I'm going to paste this code in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2424" target="_blank">00:40:24.140</a></span> | <span class="t">And so here, I'm going to go for image in each image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2429" target="_blank">00:40:29.220</a></span> | <span class="t">I'm going to iterate through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2430" target="_blank">00:40:30.860</a></span> | <span class="t">I'm going to get the argmax, so the caption that it believes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2435" target="_blank">00:40:35.780</a></span> | <span class="t">or is predicted for that image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2437" target="_blank">00:40:37.660</a></span> | <span class="t">And then we're going to show it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2439" target="_blank">00:40:39.060</a></span> | <span class="t">And we're going to print both out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2440" target="_blank">00:40:40.480</a></span> | <span class="t">Let's see if they match.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2444" target="_blank">00:40:44.020</a></span> | <span class="t">Oh, so I'm getting ahead of myself there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2447" target="_blank">00:40:47.180</a></span> | <span class="t">So we also need to--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2448" target="_blank">00:40:48.780</a></span> | <span class="t">so the probability there is the probs equals outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2456" target="_blank">00:40:56.380</a></span> | <span class="t">And we want the logics pair image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2460" target="_blank">00:41:00.620</a></span> | <span class="t">And we'll take the argmax while we're here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2463" target="_blank">00:41:03.220</a></span> | <span class="t">So dim equals 1 for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2465" target="_blank">00:41:05.440</a></span> | <span class="t">And let's have a look at what we get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2467" target="_blank">00:41:07.460</a></span> | <span class="t">We'll see that we get this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2469" target="_blank">00:41:09.740</a></span> | <span class="t">So it's predicting caption 2, caption 0, and then caption 1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2473" target="_blank">00:41:13.420</a></span> | <span class="t">for our three images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2475" target="_blank">00:41:15.740</a></span> | <span class="t">Let's look through that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2476" target="_blank">00:41:16.780</a></span> | <span class="t">And we'll see we get a dog running.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2478" target="_blank">00:41:18.940</a></span> | <span class="t">Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2479" target="_blank">00:41:19.940</a></span> | <span class="t">A dog hiding behind a tree.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2481" target="_blank">00:41:21.660</a></span> | <span class="t">And then two dogs running as well, which I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2485" target="_blank">00:41:25.300</a></span> | <span class="t">For me, maybe because I'm usually working with language,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2489" target="_blank">00:41:29.500</a></span> | <span class="t">I think seeing both language and images together is--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2494" target="_blank">00:41:34.860</a></span> | <span class="t">I don't know-- really cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2497" target="_blank">00:41:37.460</a></span> | <span class="t">Super-- I don't know-- fascinating that it actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2500" target="_blank">00:41:40.580</a></span> | <span class="t">works like that so easily.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2503" target="_blank">00:41:43.420</a></span> | <span class="t">So another thing that I want to show you very quickly--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2508" target="_blank">00:41:48.020</a></span> | <span class="t">I'm just going to copy the code in,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2509" target="_blank">00:41:49.500</a></span> | <span class="t">because I don't want to go through all of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2512" target="_blank">00:41:52.180</a></span> | <span class="t">It'll take a while.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2513" target="_blank">00:41:53.620</a></span> | <span class="t">So we just have the embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2515" target="_blank">00:41:55.100</a></span> | <span class="t">So these are the embeddings if we wanted to extract them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2517" target="_blank">00:41:57.420</a></span> | <span class="t">and do what we did before with them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2519" target="_blank">00:41:59.300</a></span> | <span class="t">Or if you wanted to take these embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2521" target="_blank">00:42:01.020</a></span> | <span class="t">put them in a vector index somewhere, a vector database.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2526" target="_blank">00:42:06.940</a></span> | <span class="t">And we can get our query.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2530" target="_blank">00:42:10.860</a></span> | <span class="t">So I'm going to do a dog hiding behind a tree.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2532" target="_blank">00:42:12.820</a></span> | <span class="t">We can get the context--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2535" target="_blank">00:42:15.700</a></span> | <span class="t">or not the context, the images, the image embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2539" target="_blank">00:42:19.420</a></span> | <span class="t">Again, like before, we do the similarity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2542" target="_blank">00:42:22.580</a></span> | <span class="t">So the cosine similarity, we get the highest one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2544" target="_blank">00:42:24.900</a></span> | <span class="t">is the second one here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2546" target="_blank">00:42:26.060</a></span> | <span class="t">So it's looking pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2547" target="_blank">00:42:27.700</a></span> | <span class="t">And from there, we get our prediction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2549" target="_blank">00:42:29.700</a></span> | <span class="t">which is argmax, so we'll take number 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2553" target="_blank">00:42:33.260</a></span> | <span class="t">And let's have a look at what our prediction is then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2555" target="_blank">00:42:35.500</a></span> | <span class="t">So we will plot that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2557" target="_blank">00:42:37.260</a></span> | <span class="t">We'll show you the image again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2558" target="_blank">00:42:38.660</a></span> | <span class="t">We have prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2559" target="_blank">00:42:39.580</a></span> | <span class="t">So it's shown as the dog hiding behind the tree</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2562" target="_blank">00:42:42.940</a></span> | <span class="t">for our query, which is a dog hiding behind a tree.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2566" target="_blank">00:42:46.100</a></span> | <span class="t">So again, super cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2569" target="_blank">00:42:49.820</a></span> | <span class="t">Now, that's it for this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2571" target="_blank">00:42:51.460</a></span> | <span class="t">We've, I think, covered quite a lot of embedding methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2576" target="_blank">00:42:56.260</a></span> | <span class="t">We've had a look at some introduction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2578" target="_blank">00:42:58.780</a></span> | <span class="t">to dense vectors with Word2Vec and where it came from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2583" target="_blank">00:43:03.460</a></span> | <span class="t">and how it quickly evolved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2585" target="_blank">00:43:05.500</a></span> | <span class="t">And we've had a look at sentence embeddings and sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2588" target="_blank">00:43:08.700</a></span> | <span class="t">transformers, moved on to Q&A with Facebook AI's DPR.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2594" target="_blank">00:43:14.460</a></span> | <span class="t">And now we've had a look at the new Vision Transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2597" target="_blank">00:43:17.300</a></span> | <span class="t">and how we can use that with other transform models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2600" target="_blank">00:43:20.300</a></span> | <span class="t">to build these really cool cross-media embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2606" target="_blank">00:43:26.500</a></span> | <span class="t">that we can compare, which has blown me away a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2610" target="_blank">00:43:30.060</a></span> | <span class="t">Now, that's it for this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2613" target="_blank">00:43:33.340</a></span> | <span class="t">But like I said, this is the first video and article</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2616" target="_blank">00:43:36.940</a></span> | <span class="t">in what will be a series on embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2619" target="_blank">00:43:39.980</a></span> | <span class="t">So there's a lot more to come.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2623" target="_blank">00:43:43.100</a></span> | <span class="t">But for now, thank you very much for watching.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2625" target="_blank">00:43:45.140</a></span> | <span class="t">And I'll see you in the next one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=bVZJ_O_-0RE&t=2626" target="_blank">00:43:46.520</a></span> | <span class="t">Bye.</span></div></div></body></html>