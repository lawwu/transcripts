<html><head><title>How Well Can GPT-4 See? And the 5 Upgrades That Are Next</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>How Well Can GPT-4 See? And the 5 Upgrades That Are Next</h2><a href="https://www.youtube.com/watch?v=FceQxb96GO8"><img src="https://i.ytimg.com/vi/FceQxb96GO8/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./FceQxb96GO8.html">Whisper Transcript</a> | <a href="./transcript_FceQxb96GO8.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">We all saw that GPT-4 is able to create a website from handwriting on a napkin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=5" target="_blank">00:00:05.160</a></span> | <span class="t">But with all the news since, the focus on vision has been lost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=8" target="_blank">00:00:08.940</a></span> | <span class="t">Meanwhile, in the last few hours and days, a select few with full access to multimodal GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=15" target="_blank">00:00:15.500</a></span> | <span class="t">have been releasing snapshots of what it can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=18" target="_blank">00:00:18.340</a></span> | <span class="t">I want to show you not only what is imminent with GPT-4 vision,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=21" target="_blank">00:00:21.680</a></span> | <span class="t">but with releases this week in text to 3D, text inside 3D, speech to text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=28" target="_blank">00:00:28.120</a></span> | <span class="t">and even embodiment, we're going to see how language and visual model innovations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=33" target="_blank">00:00:33.020</a></span> | <span class="t">are complementing each other and beginning to snowball.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=36" target="_blank">00:00:36.940</a></span> | <span class="t">But let's start with images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=38" target="_blank">00:00:38.980</a></span> | <span class="t">Do you remember from the GPT-4 technical report when the model was able to manipulate,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=44" target="_blank">00:00:44.120</a></span> | <span class="t">when prompted, a human into solving captures for it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=47" target="_blank">00:00:47.480</a></span> | <span class="t">Well, that may no longer be needed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=49" target="_blank">00:00:49.460</a></span> | <span class="t">It solves this one pretty easily, so no, captures are not going to slow down GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=54" target="_blank">00:00:54.440</a></span> | <span class="t">Next, medical imagery.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=56" target="_blank">00:00:56.240</a></span> | <span class="t">It was able to interpret this complex image and spot elements of a brain tumor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=61" target="_blank">00:01:01.920</a></span> | <span class="t">Now, it did not spot the full diagnosis, but I want to point something out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=65" target="_blank">00:01:05.900</a></span> | <span class="t">This paper from OpenAI was released only a few days ago,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=69" target="_blank">00:01:09.660</a></span> | <span class="t">and it tested GPT-4 on medical questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=72" target="_blank">00:01:12.680</a></span> | <span class="t">They found that GPT-4 can attain outstanding results exceeding human performance levels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=78" target="_blank">00:01:18.320</a></span> | <span class="t">and that that was without vision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=80" target="_blank">00:01:20.400</a></span> | <span class="t">The images and graphs were not passed to the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=83" target="_blank">00:01:23.780</a></span> | <span class="t">And as you can see, when the questions did have,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=86" target="_blank">00:01:26.040</a></span> | <span class="t">a lot of media in them, it brought down GPT-4's average.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=89" target="_blank">00:01:29.320</a></span> | <span class="t">It will be very interesting to see GPT-4's results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=92" target="_blank">00:01:32.320</a></span> | <span class="t">when its multimodal capabilities are accounted for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=95" target="_blank">00:01:35.600</a></span> | <span class="t">Next is humor, and I'm not showing these to say that they're necessarily going to change the world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=100" target="_blank">00:01:40.360</a></span> | <span class="t">but it does demonstrate the raw intellect of GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=103" target="_blank">00:01:43.680</a></span> | <span class="t">To suss out why these images are funny,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=105" target="_blank">00:01:45.760</a></span> | <span class="t">you have to have quite a nuanced understanding of humanity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=109" target="_blank">00:01:49.080</a></span> | <span class="t">Let's just say that it probably understood this meme quicker than I did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=112" target="_blank">00:01:52.440</a></span> | <span class="t">Quick thing to point out, by the way, it won't do faces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=115" target="_blank">00:01:55.840</a></span> | <span class="t">For pretty obvious privacy reasons, they won't allow the model to recognize faces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=120" target="_blank">00:02:00.400</a></span> | <span class="t">Whether that ability gets jailbreak, only time will tell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=123" target="_blank">00:02:03.720</a></span> | <span class="t">Meanwhile, it can read menus and interpret the physical world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=127" target="_blank">00:02:07.720</a></span> | <span class="t">which is an amazing asset for visually impaired people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=131" target="_blank">00:02:11.080</a></span> | <span class="t">I want to move on to another fascinating ability that the vision model inside GPT-4 possesses,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=137" target="_blank">00:02:17.440</a></span> | <span class="t">and that is reading graphs and text from images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=140" target="_blank">00:02:20.400</a></span> | <span class="t">Its ability to interpret complex diagrams and captions is going to change the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=145" target="_blank">00:02:25.640</a></span> | <span class="t">Here it is understanding a complex diagram and caption from the Palm e-paper released only about three weeks ago,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=152" target="_blank">00:02:32.840</a></span> | <span class="t">which I have done a video on, by the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=154" target="_blank">00:02:34.600</a></span> | <span class="t">But just how good is it at reading text from an image?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=157" target="_blank">00:02:37.240</a></span> | <span class="t">Well, let's take a look at GPT-4's score on the text VQA benchmark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=162" target="_blank">00:02:42.400</a></span> | <span class="t">Now, I've covered quite a few of the other benchmarks in other videos,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=165" target="_blank">00:02:45.560</a></span> | <span class="t">but I want to focus on this one here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=167" target="_blank">00:02:47.360</a></span> | <span class="t">Notice how GPT-4 got 78%, which is better than the previous state of the art model, which got 72%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=174" target="_blank">00:02:54.240</a></span> | <span class="t">Now, try to remember that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=175" target="_blank">00:02:55.440</a></span> | <span class="t">78% figure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=176" target="_blank">00:02:56.760</a></span> | <span class="t">What exactly is this testing, you ask?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=179" target="_blank">00:02:59.040</a></span> | <span class="t">Well, reading text from complex images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=182" target="_blank">00:03:02.160</a></span> | <span class="t">This is the original text VQA academic paper, and you can see some of the sample questions above.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=187" target="_blank">00:03:07.840</a></span> | <span class="t">To be honest, if you want to test your own eyesight, you can try them yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=191" target="_blank">00:03:11.240</a></span> | <span class="t">So how does the average human perform?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=193" target="_blank">00:03:13.440</a></span> | <span class="t">Well, on page seven, we have this table and we get this figure for humans, 85%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=199" target="_blank">00:03:19.680</a></span> | <span class="t">You don't need me to tell you that's just 7% better than GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=204" target="_blank">00:03:24.120</a></span> | <span class="t">The thing is, though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=205" target="_blank">00:03:25.240</a></span> | <span class="t">these models aren't slowing down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=206" target="_blank">00:03:26.880</a></span> | <span class="t">As the Vision co-lead at OpenAI put it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=209" target="_blank">00:03:29.560</a></span> | <span class="t">"Scale is all you need until everyone else realizes it too."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=214" target="_blank">00:03:34.000</a></span> | <span class="t">But the point of this video is to show you that improvements in one area are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=217" target="_blank">00:03:37.840</a></span> | <span class="t">starting to bleed into improvements in other areas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=220" target="_blank">00:03:40.720</a></span> | <span class="t">We already saw that an image of bad handwriting could be translated into a website.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=225" target="_blank">00:03:45.240</a></span> | <span class="t">As you can see here, even badly written natural language can now be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=229" target="_blank">00:03:49.000</a></span> | <span class="t">translated directly into code in Blender, creating detailed 3D models with fascinating physics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=235" target="_blank">00:03:55.040</a></span> | <span class="t">The borders of text, image, 3D and embodiment are beginning to be broken down.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=240" target="_blank">00:04:00.160</a></span> | <span class="t">And of course, other companies are jumping in too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=242" target="_blank">00:04:02.640</a></span> | <span class="t">Here's Adobe showing how you can edit 3D images using text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=246" target="_blank">00:04:06.960</a></span> | <span class="t">And how long will it really be before we go direct from text to physical models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=252" target="_blank">00:04:12.240</a></span> | <span class="t">all mediated through natural language?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=254" target="_blank">00:04:14.760</a></span> | <span class="t">And it's not just about creating 3D, it's about interacting with it through text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=259" target="_blank">00:04:19.120</a></span> | <span class="t">Notice how we can pick out both text and higher level concepts like objects.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=264" target="_blank">00:04:24.840</a></span> | <span class="t">The advanced 3D field was captured using 2D images from a phone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=269" target="_blank">00:04:29.160</a></span> | <span class="t">This paper was released only 10 days ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=271" target="_blank">00:04:31.400</a></span> | <span class="t">But notice how now we have language embedded inside the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=275" target="_blank">00:04:35.320</a></span> | <span class="t">We can search and scan for more abstract</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=278" target="_blank">00:04:38.280</a></span> | <span class="t">concepts like yellow or even utensils or electricity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=283" target="_blank">00:04:43.680</a></span> | <span class="t">It's not perfect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=284" target="_blank">00:04:44.840</a></span> | <span class="t">And for some reason, it really struggled with recognizing Raman.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=288" target="_blank">00:04:48.120</a></span> | <span class="t">But it does represent state of the art image into 3D interpreted through text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=294" target="_blank">00:04:54.640</a></span> | <span class="t">And you don't even want to type.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=295" target="_blank">00:04:55.720</a></span> | <span class="t">You just want to use your voice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=297" target="_blank">00:04:57.080</a></span> | <span class="t">Just three weeks ago, I did a video on how voice recognition will change everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=302" target="_blank">00:05:02.320</a></span> | <span class="t">And I was talking about OpenAI's Whisper API.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=305" target="_blank">00:05:05.760</a></span> | <span class="t">But now we have Conformer, which is better than Whisper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=309" target="_blank">00:05:09.280</a></span> | <span class="t">Here is the chart to prove it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=311" target="_blank">00:05:11.000</a></span> | <span class="t">And look how Conformer makes fewer errors even than Whisper at recognizing speech.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=316" target="_blank">00:05:16.920</a></span> | <span class="t">The cool thing is you can test it for yourself and the link is in the description.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=320" target="_blank">00:05:20.600</a></span> | <span class="t">And while you're passing by the description, don't forget to leave a like and a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=324" target="_blank">00:05:24.440</a></span> | <span class="t">comment to let me know if you've learned anything from this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=326" target="_blank">00:05:26.880</a></span> | <span class="t">As you'd expect, I tested it myself and it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=329" target="_blank">00:05:29.400</a></span> | <span class="t">did amazingly at transcribing my recent video on GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=334" target="_blank">00:05:34.400</a></span> | <span class="t">There were only a handful of mistakes in a 12 minute transcript.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=338" target="_blank">00:05:38.360</a></span> | <span class="t">At this point, you're probably thinking, what's next?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=340" target="_blank">00:05:40.880</a></span> | <span class="t">Well, look at the route sketched out two years ago by Sam Altman.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=345" target="_blank">00:05:45.560</a></span> | <span class="t">He said in the next five years, computer programs that can think will read</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=350" target="_blank">00:05:50.000</a></span> | <span class="t">legal documents and give medical advice. With GPT-4 passing the bar,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=354" target="_blank">00:05:54.240</a></span> | <span class="t">I would say so far he's two for two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=356" target="_blank">00:05:56.400</a></span> | <span class="t">He goes on, in the next decade,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=358" target="_blank">00:05:58.200</a></span> | <span class="t">they will do assembly line work and maybe even become companions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=362" target="_blank">00:06:02.480</a></span> | <span class="t">He's talking about the physical embodiment of language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=366" target="_blank">00:06:06.080</a></span> | <span class="t">Back then, OpenAI had a robotics team themselves that could do things like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=370" target="_blank">00:06:10.840</a></span> | <span class="t">Here is a robotic hand solving a Rubik's Cube despite interruptions from a giraffe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=377" target="_blank">00:06:17.520</a></span> | <span class="t">and someone putting a pen to interrupt the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=381" target="_blank">00:06:21.600</a></span> | <span class="t">It still solved the cube.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=384" target="_blank">00:06:24.040</a></span> | <span class="t">But then that team got disbanded and it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=386" target="_blank">00:06:26.240</a></span> | <span class="t">seems like they've moved into investing in startups.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=389" target="_blank">00:06:29.040</a></span> | <span class="t">They are leading a $23 million investment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=392" target="_blank">00:06:32.800</a></span> | <span class="t">in OneX, a startup developing a human-like robot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=397" target="_blank">00:06:37.280</a></span> | <span class="t">Here is the OneX website and it features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=399" target="_blank">00:06:39.600</a></span> | <span class="t">this rather startling image and it says Summer 2023.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=403" target="_blank">00:06:43.720</a></span> | <span class="t">Our newest Android iteration, Neo, will explore how artificial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=407" target="_blank">00:06:47.600</a></span> | <span class="t">intelligence can take form in a human-like body.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=410" target="_blank">00:06:50.240</a></span> | <span class="t">Now, of course, for many of you, a humanoid robot won't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=413" target="_blank">00:06:53.840</a></span> | <span class="t">be that surprising.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=414" target="_blank">00:06:54.840</a></span> | <span class="t">Here is the obligatory clip from Boston Dynamics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=420" target="_blank">00:07:00.040</a></span> | <span class="t">And of course, these models don't have to be humanoid.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=438" target="_blank">00:07:18.960</a></span> | <span class="t">Here is a demonstration from a paper published just four days ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=442" target="_blank">00:07:22.440</a></span> | <span class="t">This is not just walking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=443" target="_blank">00:07:23.640</a></span> | <span class="t">It's climbing up, balancing, pressing and operating buttons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=447" target="_blank">00:07:27.520</a></span> | <span class="t">And before you think all of this is really far away,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=450" target="_blank">00:07:30.520</a></span> | <span class="t">these assembly line robots are now commercially available.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=454" target="_blank">00:07:34.240</a></span> | <span class="t">I still think there's a long way to go before embodiment becomes mainstream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=458" target="_blank">00:07:38.240</a></span> | <span class="t">But my point is this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=459" target="_blank">00:07:39.520</a></span> | <span class="t">All these improvements that we're seeing in text, audio, 3D and embodiment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=464" target="_blank">00:07:44.320</a></span> | <span class="t">they're starting to merge into each other, complement each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=467" target="_blank">00:07:47.520</a></span> | <span class="t">On their own, they're cool and a bit nerdy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=469" target="_blank">00:07:49.520</a></span> | <span class="t">But once they start synergizing, fusing together, they could be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=473" target="_blank">00:07:53.440</a></span> | <span class="t">revolutionary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=474" target="_blank">00:07:54.320</a></span> | <span class="t">As Sam Altman said on the Lex Friedman podcast released yesterday,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=478" target="_blank">00:07:58.360</a></span> | <span class="t">embodiment might not be needed for AGI, but it's coming anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=FceQxb96GO8&t=482" target="_blank">00:08:02.960</a></span> | <span class="t">Let me know what you think in the comments and have a wonderful day.</span></div></div></body></html>