<html><head><title>Sora - Full Analysis (with new details)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Sora - Full Analysis (with new details)</h2><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ"><img src="https://i.ytimg.com/vi/nYTRFKGR9wQ/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./nYTRFKGR9wQ.html">Whisper Transcript</a> | <a href="./transcript_nYTRFKGR9wQ.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Sora, the text-to-video model from OpenAI, is here and it appears to be exciting people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=6" target="_blank">00:00:06.560</a></span> | <span class="t">and worrying them in equal measure. There is something visceral about actually seeing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=12" target="_blank">00:00:12.560</a></span> | <span class="t">the rate of progress in AI that hits different than leaderboards or benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=18" target="_blank">00:00:18.320</a></span> | <span class="t">And in just the last 18 hours, the technical report for Sora has come out and more demos</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=24" target="_blank">00:00:24.160</a></span> | <span class="t">and details have been released. I'm going to try to unpack what Sora is, what it means and what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=30" target="_blank">00:00:30.880</a></span> | <span class="t">comes next. Before getting into any details though, we just have to admit that some of the demos are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=37" target="_blank">00:00:37.280</a></span> | <span class="t">frankly astonishing. This one, a tour of an art gallery, is jaw-dropping to me. But that doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=43" target="_blank">00:00:43.680</a></span> | <span class="t">mean we have to get completely carried away with OpenAI's marketing material. That the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=49" target="_blank">00:00:49.440</a></span> | <span class="t">understands what the user asks for and understands how those things exist in the physical world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=56" target="_blank">00:00:56.000</a></span> | <span class="t">I don't even think the authors of Sora would have signed off on that statement. And I know it might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=60" target="_blank">00:01:00.880</a></span> | <span class="t">seem I'm being pedantic, but these kind of edge case failures is what's held back self-driving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=65" target="_blank">00:01:05.840</a></span> | <span class="t">for a decade. Yes, Sora has been trained at an immense scale, but I wouldn't say that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=71" target="_blank">00:01:11.040</a></span> | <span class="t">understands the world. It has derived billions and trillions of patterns from the world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=76" target="_blank">00:01:16.320</a></span> | <span class="t">but can't yet reason about those patterns. Hence anomalies like the video you can see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=81" target="_blank">00:01:21.120</a></span> | <span class="t">And later on in the release notes, OpenAI says this, "The current model has weaknesses. It may</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=86" target="_blank">00:01:26.240</a></span> | <span class="t">struggle with accurately simulating the physics of a complex scene. It doesn't quite get cause</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=91" target="_blank">00:01:31.360</a></span> | <span class="t">and effect. It also mixes up left and right and objects appear spontaneously and disappear for no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=97" target="_blank">00:01:37.520</a></span> | <span class="t">reason. It's a bit like GPT-4 in that it's breathtaking and intelligent, but if you probe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=103" target="_blank">00:01:43.280</a></span> | <span class="t">a bit too closely, things fall apart a little bit." To be clear, I am stunned by Sora just as much as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=110" target="_blank">00:01:50.000</a></span> | <span class="t">everyone else. I just want it to be put in a little bit of context. That being said, if and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=114" target="_blank">00:01:54.480</a></span> | <span class="t">when models crack reasoning itself, I will try to be among the first to let you know. It's time for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=120" target="_blank">00:02:00.640</a></span> | <span class="t">more details and Sora can generate videos up to a full minute long, up to 1080p. It was trained on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=128" target="_blank">00:02:08.000</a></span> | <span class="t">and can output different aspect ratios and resolutions. And speaking of high resolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=134" target="_blank">00:02:14.000</a></span> | <span class="t">this demo was amongst the most shocking. It is incredible. Just look at the consistent reflections.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=141" target="_blank">00:02:21.280</a></span> | <span class="t">In terms of how they made it, they say model and implementation details are not included</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=146" target="_blank">00:02:26.320</a></span> | <span class="t">in this report, but later on they give hints in terms of the papers they cite in the appendices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=151" target="_blank">00:02:31.520</a></span> | <span class="t">Almost all of them, funnily enough, come from Google. We have vision transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=156" target="_blank">00:02:36.080</a></span> | <span class="t">adaptable aspect ratio and resolution vision transformers, also from Google DeepMind,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=161" target="_blank">00:02:41.120</a></span> | <span class="t">and we saw that being implemented with Sora, and many other papers from Facebook and Google were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=166" target="_blank">00:02:46.240</a></span> | <span class="t">cited. That even led one Google DeepMinder to jokingly say this, "You're welcome OpenAI. I'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=172" target="_blank">00:02:52.160</a></span> | <span class="t">share my home address in DM if you want to send us flowers and chocolate." By the way, my 30 second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=177" target="_blank">00:02:57.600</a></span> | <span class="t">summary of how it's done would be this. Just think to yourself about the task of predicting the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=183" target="_blank">00:03:03.200</a></span> | <span class="t">word. It's easy to imagine how you'd test yourself, you'd cover the next word, make a prediction and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=188" target="_blank">00:03:08.240</a></span> | <span class="t">check. But how would you do that for images or frames of a video? If all you did was cover the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=193" target="_blank">00:03:13.280</a></span> | <span class="t">entire image, it would be pretty impossible to guess, say, a video frame of a monkey playing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=198" target="_blank">00:03:18.960</a></span> | <span class="t">chess. So how would you bridge that gap? Well, as you can see below, how about adding some noise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=203" target="_blank">00:03:23.600</a></span> | <span class="t">like a little bit of cloudiness to the image? You can still see most of the image, but now you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=208" target="_blank">00:03:28.640</a></span> | <span class="t">to infer little patches here and there with, say, a text caption to help you out. That's more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=214" target="_blank">00:03:34.400</a></span> | <span class="t">manageable, right? And now it's just a matter of scale. Scale up the number of images or frames</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=219" target="_blank">00:03:39.760</a></span> | <span class="t">of images from a video that you train on. Ultimately, you could go from a highly descriptive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=224" target="_blank">00:03:44.720</a></span> | <span class="t">text caption to the full image from scratch, especially if the captions are particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=229" target="_blank">00:03:49.840</a></span> | <span class="t">descriptive as they are for Sora. Now, by the way, all you need to do is find a sugar daddy to invest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=235" target="_blank">00:03:55.920</a></span> | <span class="t">13 billion dollars into you and boom, you're there. Of course, I'm being a little bit facetious. It</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=240" target="_blank">00:04:00.960</a></span> | <span class="t">builds on years of work, including by notable contributors from OpenAI. They pioneered the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=246" target="_blank">00:04:06.640</a></span> | <span class="t">auto-captioning of images with highly descriptive language. Using those synthetic captions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=252" target="_blank">00:04:12.480</a></span> | <span class="t">massively optimized the training process. When I mention scale, by the way, look at the difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=257" target="_blank">00:04:17.840</a></span> | <span class="t">that more compute makes. When I say compute, think of arrays of GPUs in a data somewhere in America.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=263" target="_blank">00:04:23.920</a></span> | <span class="t">When you 4X the compute, you get this. And if you 16X it, you get that. More images, more training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=270" target="_blank">00:04:30.400</a></span> | <span class="t">more compute, better results. Now, I know what you're thinking. Just 100X the compute. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=275" target="_blank">00:04:35.600</a></span> | <span class="t">definitely enough data. I did a back of the envelope calculation that there are quadrillions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=280" target="_blank">00:04:40.720</a></span> | <span class="t">of frames just on YouTube. Definitely easier to access if you're Google, by the way. But I will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=285" target="_blank">00:04:45.280</a></span> | <span class="t">caveat that as we've seen with GPT-4, scale doesn't get you all the way to reasoning. So you'll still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=291" target="_blank">00:04:51.280</a></span> | <span class="t">get weird breaches of the laws of physics until you get other innovations thrown in. But then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=296" target="_blank">00:04:56.320</a></span> | <span class="t">get to something big that I don't think enough people are talking about. By training on video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=302" target="_blank">00:05:02.080</a></span> | <span class="t">you're inadvertently solving images. An image, after all, is just a single frame of a video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=308" target="_blank">00:05:08.240</a></span> | <span class="t">The images from Sora go up to 2K by 2K pixels. And of course, they could be scaled up further</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=314" target="_blank">00:05:14.160</a></span> | <span class="t">with a tool like Magnific. I tried that for this image and honestly, there was nothing I could see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=319" target="_blank">00:05:19.520</a></span> | <span class="t">that would tell me that this isn't just a photo. I'd almost ask the question of whether this means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=324" target="_blank">00:05:24.480</a></span> | <span class="t">that there won't be a Dali 4 because Sora supersedes it. Take animating an image and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=330" target="_blank">00:05:30.800</a></span> | <span class="t">this example is just incredible of this Shiba Inu dog wearing a beret and black turtleneck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=337" target="_blank">00:05:37.680</a></span> | <span class="t">That's the image on the left and it being animated on the right. You can imagine the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=342" target="_blank">00:05:42.800</a></span> | <span class="t">business use cases of this where people bring to life photos of themselves, friends and family,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=349" target="_blank">00:05:49.200</a></span> | <span class="t">or maybe even deceased loved ones. Or how about every page in what would be an otherwise static</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=355" target="_blank">00:05:55.040</a></span> | <span class="t">children's book being animated on demand. You just click and then the characters get animated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=361" target="_blank">00:06:01.200</a></span> | <span class="t">Honestly, the more I think about it, the more I think Sora is going to make OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=365" target="_blank">00:06:05.200</a></span> | <span class="t">billions and billions of dollars. The number of other companies and apps that it just subsumes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=372" target="_blank">00:06:12.400</a></span> | <span class="t">within it is innumerable. I'll come back to that point. But meanwhile, here is a handful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=378" target="_blank">00:06:18.000</a></span> | <span class="t">of other incredible demos. This is a movie trailer and notice how Sora is picking quite fast cuts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=385" target="_blank">00:06:25.040</a></span> | <span class="t">obviously all automatically. It gets that a cinematic trailer is going to be pretty dynamic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=390" target="_blank">00:06:30.160</a></span> | <span class="t">and fast paced. Likewise, this is a single video generated by Sora, not a compilation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=395" target="_blank">00:06:35.280</a></span> | <span class="t">And if you ignore some text spelling issues, it is astonishing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=399" target="_blank">00:06:39.040</a></span> | <span class="t">And here is another one that I'm going to have to spend some time on. The implications of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=406" target="_blank">00:06:46.080</a></span> | <span class="t">feature alone are astonishing. All three videos that you can see are going to end with the exact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=411" target="_blank">00:06:51.520</a></span> | <span class="t">same frame. Even that final frame of the cable car crashing into that sign was generated by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=418" target="_blank">00:06:58.240</a></span> | <span class="t">Sora, including the minor misspelling at the top. But just think of the implications. You could have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=423" target="_blank">00:07:03.200</a></span> | <span class="t">a photo with your friends and imagine a hundred different ways that you could have got there to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=428" target="_blank">00:07:08.000</a></span> | <span class="t">that final photo. Or maybe you have your own website and every user gets a unique voyage to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=434" target="_blank">00:07:14.400</a></span> | <span class="t">your landing page. And of course, when we scale this up, we could put the ending of a movie in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=439" target="_blank">00:07:19.040</a></span> | <span class="t">and Sora 2 or Sora 3 would calculate all the different types of movies that could have led</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=444" target="_blank">00:07:24.480</a></span> | <span class="t">to that point. You could have daily variations to your favorite movie ending. As a side note,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=449" target="_blank">00:07:29.920</a></span> | <span class="t">this also allows you to create these funky loops where the starting and finishing frame are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=455" target="_blank">00:07:35.680</a></span> | <span class="t">identical. I could just let this play for a few minutes until people got really confused,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=459" target="_blank">00:07:39.840</a></span> | <span class="t">but I won't do that to you. And here is yet another feature that I was truly bowled away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=465" target="_blank">00:07:45.600</a></span> | <span class="t">with. The video you can see on screen was not generated by Sora. And now I'm going to switch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=471" target="_blank">00:07:51.040</a></span> | <span class="t">to another video, which was also not generated by Sora. But what Sora can do is interpolate between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=478" target="_blank">00:07:58.240</a></span> | <span class="t">those videos to come up with a unique creation. This time I'm not even going to list the potential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=483" target="_blank">00:08:03.440</a></span> | <span class="t">applications because again, they are innumerable. What I will do though, is give you one more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=487" target="_blank">00:08:07.760</a></span> | <span class="t">example that I thought of when I saw this. Another demo that OpenAI used was mixing together this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=492" target="_blank">00:08:12.800</a></span> | <span class="t">chameleon and this funky looking bird, I'm not sure its name, to create this wild mixture. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=499" target="_blank">00:08:19.200</a></span> | <span class="t">we all know that OpenAI are not going to allow you to do this with human images, but an open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=504" target="_blank">00:08:24.720</a></span> | <span class="t">source version of Sora will be following close behind. So imagine putting a video of you and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=510" target="_blank">00:08:30.160</a></span> | <span class="t">your partner and creating this hybrid freaky video, or maybe you and your pet. Now, the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=516" target="_blank">00:08:36.000</a></span> | <span class="t">results you're going to get from Sora are inevitably when there's not as much movement going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=520" target="_blank">00:08:40.800</a></span> | <span class="t">on. The less movement, the fewer problems with things like object permanence. Mind you, even when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=525" target="_blank">00:08:45.920</a></span> | <span class="t">there is quite a lot going on, the results can still be pretty incredible. Look at how Sora</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=532" target="_blank">00:08:52.000</a></span> | <span class="t">handles object permanence here with the dog fully covered and then emerging looking exactly the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=537" target="_blank">00:08:57.840</a></span> | <span class="t">Likewise, this video of a man eating a burger, because he's moving in slow motion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=542" target="_blank">00:09:02.560</a></span> | <span class="t">it's much more high fidelity. Aside from the bokeh effect, it could almost be real. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=548" target="_blank">00:09:08.240</a></span> | <span class="t">we get this gorgeous video where you almost have to convince me it's from Sora. Look at how the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=554" target="_blank">00:09:14.880</a></span> | <span class="t">paint marks stay on the page. And then we get simulated gaming where again, if you ignore some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=560" target="_blank">00:09:20.960</a></span> | <span class="t">of the physics and the rule breaking, the visuals alone are just incredible. Obviously, they trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=567" target="_blank">00:09:27.680</a></span> | <span class="t">Sora on thousands of hours of Minecraft videos. I mean, look how accurate some of the boxes are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=573" target="_blank">00:09:33.840</a></span> | <span class="t">I bet some of you watching this think I simply replaced a Sora video with an actual Minecraft</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=578" target="_blank">00:09:38.640</a></span> | <span class="t">video, but no, I didn't. That has been quite a few hype demos, so time for some anti-hype ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=584" target="_blank">00:09:44.400</a></span> | <span class="t">Here is Sora clearly not understanding the world around it. Just like Chachapiti's understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=590" target="_blank">00:09:50.720</a></span> | <span class="t">can sometimes be paper thin, so can Sora's. It doesn't get the physics of the cup, the ice,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=596" target="_blank">00:09:56.640</a></span> | <span class="t">or the spill. I can't forget to mention though, that you can also change the style of a video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=602" target="_blank">00:10:02.000</a></span> | <span class="t">Here is the input video, presumably from a game. Now with one prompt, you can change the background</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=608" target="_blank">00:10:08.240</a></span> | <span class="t">to being a jungle. Or maybe you prefer to play the game in the 1920s. I mean, you can see how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=615" target="_blank">00:10:15.840</a></span> | <span class="t">the wheels aren't moving properly, but the overall effect is incredible. Well, actually this time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=622" target="_blank">00:10:22.400</a></span> | <span class="t">I want to play the game underwater. How about that? Job done. Or maybe I'm high and I want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=628" target="_blank">00:10:28.800</a></span> | <span class="t">the game to look like a rainbow. Or maybe I prefer the old-fashioned days of pixel art.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=635" target="_blank">00:10:35.600</a></span> | <span class="t">I've noticed a lot of people, by the way, speculating where OpenAI got all the data to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=641" target="_blank">00:10:41.360</a></span> | <span class="t">train Sora. I think many people have forgotten that they did a deal back in July with Shutterstock.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=647" target="_blank">00:10:47.680</a></span> | <span class="t">In case you don't know, Shutterstock has 32 million stock videos, and most of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=653" target="_blank">00:10:53.360</a></span> | <span class="t">are high resolution. They probably also used millions of hours of video game frames, would be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=658" target="_blank">00:10:58.400</a></span> | <span class="t">my guess. One more thing you might be wondering, don't these worlds just disappear the moment you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=663" target="_blank">00:11:03.200</a></span> | <span class="t">move on to the next prompt? Well, with video to 3D, that might not always be the case. This is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=669" target="_blank">00:11:09.680</a></span> | <span class="t">from Luma AI, and imagine a world generated at first by Sora, then turned into a universally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=676" target="_blank">00:11:16.080</a></span> | <span class="t">shareable 3D landscape that you can interact with. Effectively, you and your friends could inhabit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=683" target="_blank">00:11:23.120</a></span> | <span class="t">a world generated by Sora. And yes, ultimately with scale, you could generate your own high</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=690" target="_blank">00:11:30.080</a></span> | <span class="t">fidelity video game. And given that you can indefinitely extend clips, I am sure many people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=696" target="_blank">00:11:36.160</a></span> | <span class="t">will be creating their own short movies. Perhaps voiced by AI, here's an Eleven Labs voice giving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=702" target="_blank">00:11:42.240</a></span> | <span class="t">you a snippet of the caption to this video. An adorable, happy otter confidently stands on a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=708" target="_blank">00:11:48.880</a></span> | <span class="t">surfboard wearing a yellow life jacket, riding along turquoise tropical waters near lush tropical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=715" target="_blank">00:11:55.680</a></span> | <span class="t">islands. Or how about hooking Sora up to the Apple Vision Pro or MetaQuest? Especially for those who</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=722" target="_blank">00:12:02.720</a></span> | <span class="t">can't travel, that could be an incredible way of exploring the world. Of course, being real here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=728" target="_blank">00:12:08.240</a></span> | <span class="t">the most common use case might be children using it to make cartoons and play games. But still,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=734" target="_blank">00:12:14.720</a></span> | <span class="t">that counts as a valid use case to me. But underneath all of these use cases are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=739" target="_blank">00:12:19.840</a></span> | <span class="t">some serious points. In a since deleted tweet, one OpenAI employee said this, "We are very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=745" target="_blank">00:12:25.760</a></span> | <span class="t">intentionally not sharing it widely yet. The hope is that a mini public demo kicks a social response</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=752" target="_blank">00:12:32.640</a></span> | <span class="t">into gear." I'm not really sure what social response people are supposed to give though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=758" target="_blank">00:12:38.000</a></span> | <span class="t">however. It's not responsible to let people just panic, which is why I've given the caveats I have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=763" target="_blank">00:12:43.440</a></span> | <span class="t">throughout this video. I believe, as with language and self-driving, that the edge cases will still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=768" target="_blank">00:12:48.800</a></span> | <span class="t">take a number of years to solve. That's at least my best guess. But it seems to me, when reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=773" target="_blank">00:12:53.840</a></span> | <span class="t">is solved, and therefore even long videos actually make sense, a lot more jobs other than just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=779" target="_blank">00:12:59.600</a></span> | <span class="t">videographers might be under threat. As the creator of GitHub Copilot put it, "If OpenAI is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=785" target="_blank">00:13:05.520</a></span> | <span class="t">going to continue to eat AI startups sector by sector, they should go public. Building the new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=791" target="_blank">00:13:11.040</a></span> | <span class="t">economy where only 500 people benefit is a dodgy future." And the founder of StabilityAI tweeted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=798" target="_blank">00:13:18.160</a></span> | <span class="t">out this image, "It does seem to be the best of times and the worst of times to be an AI startup.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=803" target="_blank">00:13:23.920</a></span> | <span class="t">You never know when OpenAI or Google are going to drop a model that massively changes and affects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=809" target="_blank">00:13:29.760</a></span> | <span class="t">your business." It's not just Sora whacking PikaLabs, RunwayML and maybe MidJourney. If you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=815" target="_blank">00:13:35.200</a></span> | <span class="t">make the chips that OpenAI uses, they want to make them instead. I'm going to be doing a separate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=820" target="_blank">00:13:40.560</a></span> | <span class="t">video about all of that. When you use the ChatGPT app on a phone, they want to make the phone you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=826" target="_blank">00:13:46.800</a></span> | <span class="t">using. You come up with Character AI and OpenAI comes out with the GPT Store. I bet OpenAI are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=832" target="_blank">00:13:52.960</a></span> | <span class="t">even cooking up an open world game with GPT powered NPCs. Don't forget that they acquired</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=839" target="_blank">00:13:59.200</a></span> | <span class="t">Global Illumination, the makers of this Minecraft clone. If you make agents, we learned last week</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=845" target="_blank">00:14:05.360</a></span> | <span class="t">that OpenAI want to create an agent that operates your entire device. Again, I've got more on that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=850" target="_blank">00:14:10.880</a></span> | <span class="t">coming soon. Or what about if you're making a search engine powered by a GPT model? That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=856" target="_blank">00:14:16.240</a></span> | <span class="t">the case of course with Perplexity and I will be interviewing the CEO and founder of Perplexity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=862" target="_blank">00:14:22.080</a></span> | <span class="t">for AI Insiders next week. Insiders can submit questions and of course do feel free to join on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=867" target="_blank">00:14:27.920</a></span> | <span class="t">Patreon. But fitting with the trend, we learned less than 48 hours ago that OpenAI is developing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=874" target="_blank">00:14:34.320</a></span> | <span class="t">a web search product. I'm not necessarily critiquing any of this, but you're starting to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=879" target="_blank">00:14:39.200</a></span> | <span class="t">see the theme. OpenAI will have no qualms about eating your lunch. And of course there's one more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=885" target="_blank">00:14:45.040</a></span> | <span class="t">implication that's a bit more long term. Two lead authors from Sora both retweeted this video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=891" target="_blank">00:14:51.920</a></span> | <span class="t">from Berkeley. You're seeing a humanoid transformer robot trained with large scale reinforcement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=897" target="_blank">00:14:57.520</a></span> | <span class="t">learning in simulation and deployed to the real world zero shot. In other words, it learned to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=902" target="_blank">00:15:02.960</a></span> | <span class="t">move like this by watching and acting in simulations. If you want to learn more about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=907" target="_blank">00:15:07.840</a></span> | <span class="t">learning from simulations, do check out my Eureka video and my interview with Jim Fan.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=912" target="_blank">00:15:12.560</a></span> | <span class="t">TLDR, better simulations mean better robotics. Two final demos to end this video with. First,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=919" target="_blank">00:15:19.040</a></span> | <span class="t">a monkey playing chess in a park. This demo kind of sums up Sora. It looks gorgeous. I was astounded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=925" target="_blank">00:15:25.040</a></span> | <span class="t">like everyone else. However, if you look a bit closer, the piece positions and board don't make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=930" target="_blank">00:15:30.000</a></span> | <span class="t">any sense. Sora doesn't understand the world, but it is drawing upon billions and billions of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=935" target="_blank">00:15:35.280</a></span> | <span class="t">patterns. And then there's this obligatory comparison. The Will Smith spaghetti video,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=940" target="_blank">00:15:40.960</a></span> | <span class="t">and I wonder what source they originally got some of the images from. You could say this was around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=945" target="_blank">00:15:45.360</a></span> | <span class="t">state of the art just 11 months ago. And now here's Sora. Not perfect. Look at the paws,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=952" target="_blank">00:15:52.320</a></span> | <span class="t">but honestly remarkable. Indeed, I would call Sora a milestone human achievement. But now I want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=959" target="_blank">00:15:59.520</a></span> | <span class="t">thank you for watching this video all the way to the end. And no, despite what many people think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=nYTRFKGR9wQ&t=965" target="_blank">00:16:05.120</a></span> | <span class="t">it isn't generated by an AI. Have a wonderful day.</span></div></div></body></html>