<html><head><title>AI CEO: ‘Stock Crash Could Stop AI Progress’, Llama 4 Anti-climax + ‘Superintelligence in 2027’ ...</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>AI CEO: ‘Stock Crash Could Stop AI Progress’, Llama 4 Anti-climax + ‘Superintelligence in 2027’ ...</h2><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY"><img src="https://i.ytimg.com/vi_webp/wOBqh9JqCDY/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=47">0:47</a> Stock Crash<br><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=148">2:28</a> Llama 4<br><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=655">10:55</a> o3 News<br><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=719">11:59</a> OpenAI non-profit?<br><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=793">13:13</a> AI 2027<br><br><div style="text-align: left;"><a href="./wOBqh9JqCDY.html">Whisper Transcript</a> | <a href="./transcript_wOBqh9JqCDY.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Every day it seems to me at the moment there are crazy claims and headlines not just in AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=6" target="_blank">00:00:06.340</a></span> | <span class="t">but in the wider world. So this video is going to attempt to debunk a few of those headlines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=12" target="_blank">00:00:12.240</a></span> | <span class="t">and just give you what we know. I'm going to look at Llama 4, the model that has been a year in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=18" target="_blank">00:00:18.140</a></span> | <span class="t">waiting and has many claims and counterclaims about it. Then the blog post slash paper from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=24" target="_blank">00:00:24.680</a></span> | <span class="t">a former OpenAI researcher that has millions and millions of views online and was featured in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=31" target="_blank">00:00:31.080</a></span> | <span class="t">New York Times essentially predicting superintelligence by 2027. Then some very recent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=36" target="_blank">00:00:36.660</a></span> | <span class="t">news about the release date of what could be the smartest model of them all along with a ton of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=42" target="_blank">00:00:42.960</a></span> | <span class="t">contradictions about whether and when it might come out. I just simply can't resist starting out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=48" target="_blank">00:00:48.680</a></span> | <span class="t">with a quote which could dampen literally all the hype that you see in AI. When Dario Amadei,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=54" target="_blank">00:00:54.780</a></span> | <span class="t">the CEO of Anthropic, makers of the Claude series of models, was asked what could stop AI? What could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=61" target="_blank">00:01:01.080</a></span> | <span class="t">stop the progress? He mentioned a war in Taiwan which we've known is a risk for a long time. I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=66" target="_blank">00:01:06.520</a></span> | <span class="t">highly recommend the book Chip Wars by Chris Miller. He then briefly touched on there being a potential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=71" target="_blank">00:01:11.720</a></span> | <span class="t">data war where they run out of high quality data to train their models on but then he touched on a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=76" target="_blank">00:01:16.280</a></span> | <span class="t">new risk that he hadn't mentioned before. And before you hear this quote, note that it came</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=80" target="_blank">00:01:20.880</a></span> | <span class="t">three weeks ago before all of this tariff craziness. What are the top three things that could stop the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=85" target="_blank">00:01:25.960</a></span> | <span class="t">show? If there's a large enough disruption to the stock market that messes with the capitalization of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=90" target="_blank">00:01:30.680</a></span> | <span class="t">these companies, basically a kind of belief that the technology will not, you know, move forward and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=98" target="_blank">00:01:38.520</a></span> | <span class="t">that kind of creates a self-fulfilling prophecy where there's there's not enough capitalization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=102" target="_blank">00:01:42.360</a></span> | <span class="t">I just want to spend 30 seconds on explaining how that might play out. Companies like OpenAI and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=108" target="_blank">00:01:48.200</a></span> | <span class="t">Anthropic need to raise money to fund those vast training runs that go behind their latest models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=113" target="_blank">00:01:53.960</a></span> | <span class="t">They don't just have 40 billion or 100 billion sitting around in their bank account to fund those vast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=119" target="_blank">00:01:59.720</a></span> | <span class="t">data centers and everything else that goes into training a language model. The trouble is, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=124" target="_blank">00:02:04.440</a></span> | <span class="t">if investors don't think they'll get their money back, perhaps due to a recession, then they either</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=129" target="_blank">00:02:09.240</a></span> | <span class="t">won't invest in these companies or invest less at lower valuations. Less money means less compute,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=135" target="_blank">00:02:15.000</a></span> | <span class="t">which means slower AI progress. That's not a prediction, of course. No one, including myself,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=139" target="_blank">00:02:19.800</a></span> | <span class="t">knows what's going to happen. It's just easy to forget that AI operates in the real world and real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=145" target="_blank">00:02:25.320</a></span> | <span class="t">world things can have consequences for AI progress. And speaking of AI progress, how much progress is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=151" target="_blank">00:02:31.240</a></span> | <span class="t">represented by the release of Llama 4 and two of the three models in the Llama 4 family? Well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=157" target="_blank">00:02:37.240</a></span> | <span class="t">it's hard to be exact because, as ever, there's a lot more spin than honest analysis in the release</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=163" target="_blank">00:02:43.560</a></span> | <span class="t">of this family. But it seems like not too much. There's no paper, of course, that's starting to become</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=169" target="_blank">00:02:49.240</a></span> | <span class="t">the norm. But here are the highlights of what we do know. First, the smallest of the Llama 4 models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=175" target="_blank">00:02:55.000</a></span> | <span class="t">has what they call an industry-leading context window of 10 million tokens. Think of that being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=181" target="_blank">00:03:01.160</a></span> | <span class="t">around seven and a half million words. That sounds insane, of course, and innovative, but two quick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=186" target="_blank">00:03:06.520</a></span> | <span class="t">caveats. All the way back to February 2024, we had a model, Gemini 1.5 Pro, that had a 10 million token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=194" target="_blank">00:03:14.120</a></span> | <span class="t">context window. And with that extreme window, it could perform amazing needle in a haystack recovery</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=200" target="_blank">00:03:20.440</a></span> | <span class="t">on videos and audio and text. In public, at least, we, quote, "only" got models of up to two million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=206" target="_blank">00:03:26.680</a></span> | <span class="t">tokens of context window, though, perhaps because Google realized something. They realized, perhaps,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=211" target="_blank">00:03:31.640</a></span> | <span class="t">that it's all well and good finding individual needles in a haystack, as demonstrated in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=216" target="_blank">00:03:36.840</a></span> | <span class="t">Llama 4 blog post. If you dump in all the Harry Potter books and drop in a password, say, halfway through,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=223" target="_blank">00:03:43.480</a></span> | <span class="t">the model will be able to find it and retrieve it. But most people, let's be honest, aren't sneaking in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=228" target="_blank">00:03:48.280</a></span> | <span class="t">passwords into seven volumes of Harry Potter. So these results from the release 48 hours ago</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=235" target="_blank">00:03:55.400</a></span> | <span class="t">seem less relevant to me than this updated benchmark from 24 hours ago. It's called Fiction Live Bench for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=242" target="_blank">00:04:02.600</a></span> | <span class="t">Long Context Deep Comprehension. This is the benchmark where language models have to piece together plot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=248" target="_blank">00:04:08.520</a></span> | <span class="t">progressions across tens or hundreds of thousands of tokens or words. In my last video on Gemini 2.5 Pro,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=255" target="_blank">00:04:15.080</a></span> | <span class="t">I noted its extremely good performance on this benchmark. In contrast, for Llama 4 for the medium</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=260" target="_blank">00:04:20.280</a></span> | <span class="t">sized model and the smallest model, performance is pretty bad and gets worse. The numbers at the top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=266" target="_blank">00:04:26.120</a></span> | <span class="t">refer to the clues being strewn across, say, 6,000 words or 12,000 words or even 100,000 words. Things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=273" target="_blank">00:04:33.880</a></span> | <span class="t">then get stranger when you think about dates. Why was Llama 4 released on a Saturday? That is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=279" target="_blank">00:04:39.560</a></span> | <span class="t">unprecedented in the entirety of the time I've covered AI. If you were going to be vaguely conspiratorial,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=285" target="_blank">00:04:45.800</a></span> | <span class="t">you would think that they released it on a weekend to sort of dampen down attention. Also note that its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=291" target="_blank">00:04:51.320</a></span> | <span class="t">knowledge cutoff is August 2024. That's the most recent of the training data that Llama 4 was trained on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=298" target="_blank">00:04:58.920</a></span> | <span class="t">Compare that to Gemini 2.5, which has a knowledge cutoff of January of 2025. Kind of hints to me that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=305" target="_blank">00:05:05.640</a></span> | <span class="t">Meta were trying desperately to bring this model up to scratch in the intervening nine months or so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=311" target="_blank">00:05:11.720</a></span> | <span class="t">In fact, they probably intended to release it earlier, but then in September we had the start of the O series</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=318" target="_blank">00:05:18.360</a></span> | <span class="t">of models from OpenAI and then in January we got DeepSeek R1. By the way, if you want early access to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=325" target="_blank">00:05:25.160</a></span> | <span class="t">my full-length documentary on DeepSeek and R1, it's on my Patreon. Link in the description. But I will say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=331" target="_blank">00:05:31.640</a></span> | <span class="t">before we completely write off Llama 4 as in this meme, there is some solid progress that it represents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=338" target="_blank">00:05:38.280</a></span> | <span class="t">Especially the medium-sized model, Llama 4 Maverick, as it compares to the updated DeepSeek</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=345" target="_blank">00:05:45.640</a></span> | <span class="t">V3. Both of these models are of course not thinking models, like Gemini 2.5 or DeepSeek R1. Meta</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=352" target="_blank">00:05:52.440</a></span> | <span class="t">haven't released their state-of-the-art thinking model yet. But just bear in mind for a moment that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=357" target="_blank">00:05:57.960</a></span> | <span class="t">for all the hullabaloo around DeepSeek V3, Llama 4 Maverick has around half the number of active</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=365" target="_blank">00:06:05.000</a></span> | <span class="t">parameters and yet is comparable in performance. Now yes, I know people accuse it of benchmark maxing or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=370" target="_blank">00:06:10.920</a></span> | <span class="t">hacking on LM Arena, but check out these real numbers. Assuming none of the answers made it into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=376" target="_blank">00:06:16.280</a></span> | <span class="t">the training data for Llama 4, the performance of its models on GPQA Diamond, the google-proof stem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=382" target="_blank">00:06:22.680</a></span> | <span class="t">benchmark that's extremely tough, is actually better than the new DeepSeek V3. Or of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=387" target="_blank">00:06:27.560</a></span> | <span class="t">GPT-4.0. So if you were making the optimistic case for Meta or for Llama 4, you would say that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=393" target="_blank">00:06:33.800</a></span> | <span class="t">have a pretty insane base model that they could create perhaps a state-of-the-art thinking model on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=399" target="_blank">00:06:39.480</a></span> | <span class="t">top of. Only problem is, Gemini 2.5 Pro is already there and DeepSeek R2 is coming out any moment. Also,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=407" target="_blank">00:06:47.080</a></span> | <span class="t">when you take Llama 4 out of its comfort zone, its performance starts to crater. Take this coding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=412" target="_blank">00:06:52.280</a></span> | <span class="t">benchmark, Ada's Polyglot benchmark, testing model performance on a range of programming languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=417" target="_blank">00:06:57.720</a></span> | <span class="t">Unlike many benchmarks, it doesn't just focus on the Python programming language, but a range of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=423" target="_blank">00:07:03.560</a></span> | <span class="t">programming languages. And as you can see, Gemini 2.5 Pro tops the charts. Now yes, you might say that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=429" target="_blank">00:07:09.160</a></span> | <span class="t">a thinking model, but then look at Claude 3.7 Sonnet, that's without thinking, it gets 60%. DeepSeek V3,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=436" target="_blank">00:07:16.920</a></span> | <span class="t">the latest version, gets 55%. And you unfortunately have to scroll down quite far to get to Llama 4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=445" target="_blank">00:07:25.080</a></span> | <span class="t">Maverick, which gets 15.6%. Now is it me, or is performance like this quite hard to square with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=452" target="_blank">00:07:32.520</a></span> | <span class="t">headlines like this one from Mark Zuckerberg, which is that his AI models will replace mid-level engineers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=459" target="_blank">00:07:39.480</a></span> | <span class="t">soon? As in, Zuckerberg says, this year, 2025. Was he massively hyping things out of all sense of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=466" target="_blank">00:07:46.200</a></span> | <span class="t">proportion? How dare you have that thought? Four more quick things before we leave Llama 4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=471" target="_blank">00:07:51.320</a></span> | <span class="t">and yes, I did pick that number deliberately. And the first is on the tentative signs from their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=476" target="_blank">00:07:56.920</a></span> | <span class="t">biggest model, the unreleased one, Behemoth. Now Meta have deliberately made the comparisons with models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=482" target="_blank">00:08:02.600</a></span> | <span class="t">like Gemini 2 Pro and GPT 4.5, and the comparison is somewhat favourable. Though if you look closely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=489" target="_blank">00:08:09.960</a></span> | <span class="t">at the footnotes, it says, Llama model results represent our current best internal runs. Did they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=495" target="_blank">00:08:15.720</a></span> | <span class="t">run the model five times and pick the best one? Three times? Ten times? We don't know. Also note they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=501" target="_blank">00:08:21.320</a></span> | <span class="t">chose not to compare Llama 4 Behemoth with DeepSeek V3, which is three times smaller in terms of overall</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=509" target="_blank">00:08:29.160</a></span> | <span class="t">parameters and around eight times smaller in terms of active parameters. In dark blue, you can see the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=515" target="_blank">00:08:35.000</a></span> | <span class="t">performance of DeepSeek V3, the latest version, and you'd have to agree it's pretty much comparable to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=521" target="_blank">00:08:41.480</a></span> | <span class="t">Llama 4 Behemoth. In other words, if you wanted to put a negative spin on the release, you could say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=526" target="_blank">00:08:46.280</a></span> | <span class="t">Llama's biggest model, many times the size of the new DeepSeek V3 base model, performs at the same level,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=533" target="_blank">00:08:53.400</a></span> | <span class="t">basically. Now, yes, I know Llama 4 Behemoth is still, quote, in training, but pretty much all models are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=538" target="_blank">00:08:58.680</a></span> | <span class="t">quote, in training all the time at the moment with post-training. Second, just a quick one I saw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=543" target="_blank">00:09:03.320</a></span> | <span class="t">halfway through the terms of use, which is you're kind of screwed if you are in the EU. You can still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=549" target="_blank">00:09:09.320</a></span> | <span class="t">be the end user of it, you just don't have the same rights to build upon it. Next comes a little nugget</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=554" target="_blank">00:09:14.920</a></span> | <span class="t">towards the bottom of the page in which they've tried to make Llama 4 lean a bit more right. They</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=559" target="_blank">00:09:19.640</a></span> | <span class="t">say it's well known that LLMs have bias, that they historically lean left when it comes to politics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=566" target="_blank">00:09:26.280</a></span> | <span class="t">so they're going to try to rectify that. I'm sure, of course, that had nothing to do with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=570" target="_blank">00:09:30.680</a></span> | <span class="t">Zuckerberg's relationship to the new administration. Finally, Simplebench, in which Llama 4 Maverick,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=576" target="_blank">00:09:36.440</a></span> | <span class="t">the medium-sized model, gets 27.7%, which is around the same level as DeepSeek V3. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=583" target="_blank">00:09:43.800</a></span> | <span class="t">that is a lower than, quote, non-thinking models like 3.5 Sonnet that don't take that time to lay out their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=589" target="_blank">00:09:49.720</a></span> | <span class="t">chain of thought before answering, but it's a solid performance. Meta are definitely still in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=594" target="_blank">00:09:54.440</a></span> | <span class="t">the race when it comes to having great base models upon which you can build incredible reasoning models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=599" target="_blank">00:09:59.800</a></span> | <span class="t">Now, as it happens, I did get some juicy hints recently about what the performance of O3 would be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=605" target="_blank">00:10:05.880</a></span> | <span class="t">on Simplebench, and that's the model coming in two weeks. I'll touch on that in just a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=611" target="_blank">00:10:11.160</a></span> | <span class="t">And let's just say that it's going to be competitive. I know that's kind of like an egregious hint that I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=616" target="_blank">00:10:16.360</a></span> | <span class="t">not backing up, but that's all I can say at the moment. Now, what you may have noticed in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=620" target="_blank">00:10:20.440</a></span> | <span class="t">middle of the screen is that Simplebench, which is a benchmark you can check out in the description,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=625" target="_blank">00:10:25.560</a></span> | <span class="t">I created it around nine months ago, is powered by Weave from Weights and Biases. They are sponsoring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=631" target="_blank">00:10:31.480</a></span> | <span class="t">this video and indeed the entire benchmark, as you can clearly tell with the link at the center of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=636" target="_blank">00:10:36.760</a></span> | <span class="t">the screen. That will open up this quick start, which should be useful for any developer who is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=641" target="_blank">00:10:41.400</a></span> | <span class="t">interested in benchmarking language models, as we do. To be honest, even just those who are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=646" target="_blank">00:10:46.040</a></span> | <span class="t">interested in learning more about LLMs, you can check out the Weights and Biases AI Academy down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=651" target="_blank">00:10:51.320</a></span> | <span class="t">here. As you can see, they are coming up with new free courses pretty much all the time. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=655" target="_blank">00:10:55.800</a></span> | <span class="t">I did say I'd mentioned the O3 news, which came just a couple of days ago from Sam Altman,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=660" target="_blank">00:11:00.200</a></span> | <span class="t">in which he told us that O3 would be coming in about two weeks from now. This is from my newsletter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=665" target="_blank">00:11:05.560</a></span> | <span class="t">but do you remember when OpenAI and Sam Altman specifically said, "We want to do a better job of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=670" target="_blank">00:11:10.440</a></span> | <span class="t">sharing our intended roadmap? As we get closer to AGI, you guys deserve clarity." Well, clarity would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=677" target="_blank">00:11:17.000</a></span> | <span class="t">be great, because initially O3 was supposed to come out shortly after O3 Mini High, which came out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=683" target="_blank">00:11:23.800</a></span> | <span class="t">towards the end of January. So, naturally, we expected it in February. Then, OpenAI did A180,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=689" target="_blank">00:11:29.080</a></span> | <span class="t">as you can see in this tweet, and Sam Altman said, "We will no longer ship O3 as a standalone model." Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=694" target="_blank">00:11:34.920</a></span> | <span class="t">perhaps prompted by the Gemini 2.5 Pro release, or their GPUs melting because of everyone using Image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=700" target="_blank">00:11:40.840</a></span> | <span class="t">Gen, they've pushed back GPT-5 and are now going to release O3 indeed as a standalone model in two weeks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=707" target="_blank">00:11:47.080</a></span> | <span class="t">So much for clarity then. We're also apparently going to get books about Sam Altman's misdeeds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=712" target="_blank">00:11:52.280</a></span> | <span class="t">and dodgy documented behaviour, but that's a topic for another video. One thing I bet OpenAI don't want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=717" target="_blank">00:11:57.800</a></span> | <span class="t">us to focus on is their new plans for their non-profit. Remember that $300 billion valuation you saw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=723" target="_blank">00:12:03.640</a></span> | <span class="t">earlier on in this video, that depends on OpenAI becoming a for-profit company. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=728" target="_blank">00:12:08.440</a></span> | <span class="t">what's going to happen to that non-profit which was supposed to control the proceeds of OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=733" target="_blank">00:12:13.880</a></span> | <span class="t">creating AGI? Remember, in the slim chance that Sam Altman is right and OpenAI are the company that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=740" target="_blank">00:12:20.120</a></span> | <span class="t">creates trillions of dollars of value, as he predicted, this non-profit might have ended up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=745" target="_blank">00:12:25.720</a></span> | <span class="t">controlling trillions of dollars worth of value. More importantly, it would have controlled what would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=750" target="_blank">00:12:30.520</a></span> | <span class="t">have happened to AGI should OpenAI be the company that created it. Now, put aside whether you think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=755" target="_blank">00:12:35.640</a></span> | <span class="t">it will be OpenAI that creates AGI, or whether AGI is even well-defined or feasible in the next three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=761" target="_blank">00:12:41.160</a></span> | <span class="t">to five years. Just focus on the promise that Sam Altman and OpenAI made. We've gone from that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=766" target="_blank">00:12:46.120</a></span> | <span class="t">non-profit controlling what could have been, in theory, a significant fraction of the world economy,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=771" target="_blank">00:12:51.400</a></span> | <span class="t">to supporting local charities in California, and perhaps generously across America and beyond.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=778" target="_blank">00:12:58.200</a></span> | <span class="t">Now, hardly anyone, if anyone, is focusing on this story as OpenAI are no longer the dominant players</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=784" target="_blank">00:13:04.920</a></span> | <span class="t">in the race to AGI, but nevertheless, I think it's significant. Now, if you are feeling somewhat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=789" target="_blank">00:13:09.800</a></span> | <span class="t">dehyped about AGI after hearing about Llama 4 and these OpenAI stories, well, you could spend a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=796" target="_blank">00:13:16.120</a></span> | <span class="t">hours like I did on the weekend reading AI-2027. This was written by a former OpenAI researcher</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=804" target="_blank">00:13:24.280</a></span> | <span class="t">and other super forecasters with a pretty impressive track record. Also, as you may remember,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=809" target="_blank">00:13:29.400</a></span> | <span class="t">Daniel Cocotagelo put up an impressive stand against OpenAI on their non-disparagement clause. He was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=815" target="_blank">00:13:35.880</a></span> | <span class="t">essentially willing to forfeit millions of dollars, and yes, you can make that much as a safety</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=820" target="_blank">00:13:40.120</a></span> | <span class="t">researcher at OpenAI. He was willing to forfeit that so he wouldn't have to sign the non-disparagement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=825" target="_blank">00:13:45.240</a></span> | <span class="t">clause. Because he made that stand, OpenAI were practically forced into dropping that clause for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=831" target="_blank">00:13:51.080</a></span> | <span class="t">everyone. So, well done him on that. Nevertheless, I was not particularly convinced by this report,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=836" target="_blank">00:13:56.280</a></span> | <span class="t">even though I admire the fact that they put dates on the record for their predictions. To honor that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=841" target="_blank">00:14:01.880</a></span> | <span class="t">I will try to match some of their predictions with predictions of my own. Their central premise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=846" target="_blank">00:14:06.920</a></span> | <span class="t">in a nutshell is that AI is first going to become a superhuman coder and then ML researcher and thereby</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=853" target="_blank">00:14:13.960</a></span> | <span class="t">massively speed up AI progress, giving us superintelligence in 2027. They draw fairly heavily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=860" target="_blank">00:14:20.120</a></span> | <span class="t">on this paper from Meta, and I'm going to cover that in a separate video because I am corresponding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=865" target="_blank">00:14:25.080</a></span> | <span class="t">fairly closely with one of the key authors of that paper. Anyway, we start off fairly lightly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=870" target="_blank">00:14:30.440</a></span> | <span class="t">basically with a description of what current AI can do in terms of being an agent like ChatGPT's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=876" target="_blank">00:14:36.280</a></span> | <span class="t">operator and deep research, essentially describing what we already have. We then get plenty of detours</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=882" target="_blank">00:14:42.200</a></span> | <span class="t">into alignment and safety because you sense the authors are trying to get across that message at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=887" target="_blank">00:14:47.560</a></span> | <span class="t">same time as making all of these predictions. I start to meaningfully diverge from their predictions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=892" target="_blank">00:14:52.920</a></span> | <span class="t">when it comes to early 2026 when they say this: If China steals the state-of-the-art AI, Agent 1 they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=899" target="_blank">00:14:59.720</a></span> | <span class="t">call it, weights, they could increase their research speed by nearly 50%. Based on all of the evidence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=904" target="_blank">00:15:04.840</a></span> | <span class="t">you've seen today about DeepSeq and Llama 4, you would say it's almost equally likely that the West will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=911" target="_blank">00:15:11.080</a></span> | <span class="t">be stealing China's weights. Or wait, they won't need to because DeepSeq continued to make their models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=916" target="_blank">00:15:16.600</a></span> | <span class="t">open weight. Just like Leopold Aschenbrenner and Dario Amadei, everything is a race to the jugular,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=921" target="_blank">00:15:21.800</a></span> | <span class="t">which is a narrative that's somewhat hard to square with DeepSeq pioneering certain research and giving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=927" target="_blank">00:15:27.400</a></span> | <span class="t">it to everyone. Then, apparently in late 2026, the US Department of Defense will quietly begin contracting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=933" target="_blank">00:15:33.720</a></span> | <span class="t">OpenAI or Google directly for cyber, data analysis and R&D. But I'm kind of confused because already,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=940" target="_blank">00:15:40.200</a></span> | <span class="t">for at least a year, OpenAI have been working directly with the Pentagon. Yes, before you guys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=944" target="_blank">00:15:44.920</a></span> | <span class="t">tell me, I'm aware that Daniel Cocotagelo, who is the main author of this paper, did make some amazing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=950" target="_blank">00:15:50.120</a></span> | <span class="t">predictions back in 2021 about the progress of AI. I can link to that in the description, but that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=955" target="_blank">00:15:55.720</a></span> | <span class="t">doesn't mean he's going to be always right going forward. Also, he himself has admitted that those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=960" target="_blank">00:16:00.040</a></span> | <span class="t">predictions weren't that wide-ranging. Anyway, things get wild in January of 2027 because, as you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=966" target="_blank">00:16:06.120</a></span> | <span class="t">from this chart up here, we get an AI that is better than the best human. The first superhuman coder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=973" target="_blank">00:16:13.240</a></span> | <span class="t">in other words. This is the key crux of the paper because once you get that, you speed up AI research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=979" target="_blank">00:16:19.160</a></span> | <span class="t">and all the other consequences follow. But as I have been discussing with the authors of the meter paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=984" target="_blank">00:16:24.040</a></span> | <span class="t">there are so many other variables to contend with. What about proprietary code in Google or Meta or Amazon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=990" target="_blank">00:16:30.440</a></span> | <span class="t">that OpenAI can't train their models on? What about benchmarks themselves being less and less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=995" target="_blank">00:16:35.240</a></span> | <span class="t">reliable indicators of real-world performance because the real world is much messier than benchmarks?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1000" target="_blank">00:16:40.600</a></span> | <span class="t">This superhuman coder may need to liaise with entire teams, get certain permissions and pass all sorts of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1006" target="_blank">00:16:46.280</a></span> | <span class="t">hurdles of common sense. And even if you wanted to focus brutally just on verifiable benchmarks, not every benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1012" target="_blank">00:16:52.840</a></span> | <span class="t">is showing an exponential. Take MLE Bench or Machine Learning Engineer Bench from the Deep Research or O3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1019" target="_blank">00:16:59.240</a></span> | <span class="t">system card from OpenAI. That dataset consists of 75 hand-curated Kaggle competitions worth $2 million in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1025" target="_blank">00:17:05.720</a></span> | <span class="t">price value. Measuring progress towards model self-improvement is key to evaluating autonomous</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1030" target="_blank">00:17:10.120</a></span> | <span class="t">agents' full potential. Basically, if models get good at machine learning engineering, they can obviously</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1035" target="_blank">00:17:15.400</a></span> | <span class="t">much more easily improve themselves. And let's skip down to progress and zoom in a bit and you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1041" target="_blank">00:17:21.000</a></span> | <span class="t">the performance of O1, O3 mini, Deep Research without browsing, Deep Research with browsing, GPT-40 even,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1048" target="_blank">00:17:28.840</a></span> | <span class="t">and I'm not noticing an absolute surge in performance. Obviously, I am perfectly aware of benchmarks like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1054" target="_blank">00:17:34.440</a></span> | <span class="t">humanity's last exam and others which are showing exponential improvement. I'm just saying not every benchmark is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1060" target="_blank">00:17:40.040</a></span> | <span class="t">showing that. Also, January or February of 2027 is less than two years away and this model would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1065" target="_blank">00:17:45.880</a></span> | <span class="t">have to be superhuman in performance. So much so that it could autonomously develop and execute plans to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1072" target="_blank">00:17:52.360</a></span> | <span class="t">hack into AI servers, install copies of itself, evade detection, and use that secure base to pursue whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1077" target="_blank">00:17:57.880</a></span> | <span class="t">other goals it might have. Notice the hasty caveat, though, how effectively it would do so as weeks roll by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1083" target="_blank">00:18:03.480</a></span> | <span class="t">is unknown and in doubt. That happens a lot, by the way, in the paper. I even noticed a co-author say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1089" target="_blank">00:18:09.240</a></span> | <span class="t">well, this wasn't my prediction, it was Daniel's. There's a lot of kind of heavy caveating of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1093" target="_blank">00:18:13.400</a></span> | <span class="t">everything. Notice, though, that not only would an AI model have to be superhuman at coding to do all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1098" target="_blank">00:18:18.280</a></span> | <span class="t">this, it would have to have very few, if any, major flaws. If one aspect of its proposed plan wasn't in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1105" target="_blank">00:18:25.240</a></span> | <span class="t">its training data or it couldn't do it reliably, the whole thing would fail. And that leads me to my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1110" target="_blank">00:18:30.760</a></span> | <span class="t">prediction. I mean, they've made a prediction so I can make one that models, even by 2030, will not be able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1118" target="_blank">00:18:38.120</a></span> | <span class="t">do this. I'm talking reliably, with 95 or 99% reliability, autonomously, fully autonomously,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1125" target="_blank">00:18:45.320</a></span> | <span class="t">develop and execute plans to hack into AI servers, copy itself, evade detection, etc. If, on the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1130" target="_blank">00:18:50.440</a></span> | <span class="t">hand, Daniel is right and models are capable of this by February 2027, then I will admit I am wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1136" target="_blank">00:18:56.840</a></span> | <span class="t">That, by the way, brings me back to this chart, which, if you notice, says that only 4% of people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1144" target="_blank">00:19:04.200</a></span> | <span class="t">at that point would say, what do you think is the most important problem facing the country today?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1149" target="_blank">00:19:09.080</a></span> | <span class="t">And they'd answer AI. Well, I don't know about you, but if I or my friends or family heard that there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1153" target="_blank">00:19:13.800</a></span> | <span class="t">AI out there that just can hack things and replicate itself and survive in the wild, I think more than 4%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1159" target="_blank">00:19:19.240</a></span> | <span class="t">of people would say it's the most important issue. I mean, man, actually, the more I think of it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1163" target="_blank">00:19:23.080</a></span> | <span class="t">like, look at the clickbait headlines you get on YouTube and elsewhere about AI today. Can you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1167" target="_blank">00:19:27.960</a></span> | <span class="t">imagine the clickbait if AI was actually capable of copying itself onto different servers and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1173" target="_blank">00:19:33.720</a></span> | <span class="t">hacking autonomously? Actually, it wouldn't even be clickbait at that point. I would be doing headlines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1177" target="_blank">00:19:37.880</a></span> | <span class="t">like, oh my god, it can hack everything. Anyway, you get the idea, and that's not even mentioning the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1183" target="_blank">00:19:43.320</a></span> | <span class="t">fact that these agents can also, almost as well as a human pro, create bioweapons and the rest of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1188" target="_blank">00:19:48.920</a></span> | <span class="t">China is then going to steal that improved Agent 2 from the Pentagon, and still obliviously 96% of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1196" target="_blank">00:19:56.360</a></span> | <span class="t">people are focused on other things. Being slightly less facetious, I think the paper over-indexes on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1202" target="_blank">00:20:02.360</a></span> | <span class="t">weight thefts and it all being contained in the weights of a model. I think progress between now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1207" target="_blank">00:20:07.160</a></span> | <span class="t">and 2030 is going to much more depend on what data you have available, what benchmarks you have created,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1212" target="_blank">00:20:12.600</a></span> | <span class="t">what proprietary data you can get hold of. Now, don't get me wrong, I do think AI will help with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1218" target="_blank">00:20:18.760</a></span> | <span class="t">the improvement of AI. Even if it's just verifying and evaluating, replicating existing AI research,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1225" target="_blank">00:20:25.720</a></span> | <span class="t">which is a new benchmark released by OpenAI just a week ago, already models like Claude 3.5 Sonnet can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1231" target="_blank">00:20:31.720</a></span> | <span class="t">replicate 21% of the papers in this benchmark. But when you have a limited compute, and potentially very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1238" target="_blank">00:20:38.040</a></span> | <span class="t">limited compute if there's a massive worldwide stock crash or war in Taiwan, but when you have limited compute,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1243" target="_blank">00:20:43.800</a></span> | <span class="t">are you going to delegate the decision of which avenues to pursue to a model which might be only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1250" target="_blank">00:20:50.520</a></span> | <span class="t">80% as good as your best researchers? No, you would just defer to those top researchers. Only when a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1256" target="_blank">00:20:56.440</a></span> | <span class="t">was making consistently better decisions than your best researchers as to how to deploy compute would you then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1262" target="_blank">00:21:02.040</a></span> | <span class="t">entrust it to them. The authors definitely bring in some real-world events that may or may not have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1265" target="_blank">00:21:05.960</a></span> | <span class="t">occurred at OpenAI when they say, "AI safety sympathizers get sidelined or fired outright" brackets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1271" target="_blank">00:21:11.720</a></span> | <span class="t">the last group for fear that they might whistleblow. Personally, I would predict that if we have an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1276" target="_blank">00:21:16.600</a></span> | <span class="t">autonomous AI that can hack and survive on its own, I don't think safety sympathizers will be sidelined.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1283" target="_blank">00:21:23.480</a></span> | <span class="t">If I am wrong, then we as a human species are a lot dumber than I thought. Anyway, just two years from now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1289" target="_blank">00:21:29.880</a></span> | <span class="t">June 2027, most of the humans at OpenAI/Google can't usefully contribute anymore. Again, I just don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1297" target="_blank">00:21:37.160</a></span> | <span class="t">think feedback loops can happen that quickly when you reach this level. I could well imagine benchmarks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1302" target="_blank">00:21:42.760</a></span> | <span class="t">like the MMMU or SimpleBench being maxed out at this point, but imagine you're trying to design a more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1309" target="_blank">00:21:49.400</a></span> | <span class="t">aerodynamic or efficient F-47. That's the new fighter jet announced by the Pentagon. Well, that AI self-improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1316" target="_blank">00:21:56.760</a></span> | <span class="t">is going to be bottlenecked by the realism of the simulation that it's benchmarking against. Unless</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1322" target="_blank">00:22:02.760</a></span> | <span class="t">that simulated aircraft exactly matches the real one, well then you won't know if that "self-improving AI"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1328" target="_blank">00:22:08.520</a></span> | <span class="t">has indeed improved the design unless you test it out in a real aircraft. Then multiply that example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1333" target="_blank">00:22:13.880</a></span> | <span class="t">by the 10,000 other domains in which there's proprietary data or sim-to-real gaps. I guess you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1340" target="_blank">00:22:20.040</a></span> | <span class="t">could summarise my views as saying the real world is a lot more messy than certain isolated benchmarks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1346" target="_blank">00:22:26.520</a></span> | <span class="t">online. The model, by the way, at this point is plausibly extremely dangerous being able to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1352" target="_blank">00:22:32.520</a></span> | <span class="t">bioweapons and is scarily effective at doing so, but 92% are saying it's not the most important issue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1360" target="_blank">00:22:40.360</a></span> | <span class="t">Man, how good would TikTok have to get so that 92% of people wouldn't be focused on AI at that point?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1366" target="_blank">00:22:46.600</a></span> | <span class="t">I'm going to leave you with the positive ending of the two endings given by the paper, which predicts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1371" target="_blank">00:22:51.480</a></span> | <span class="t">this in 2030. We end with "People terraform and settle the solar system and prepare to go beyond.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1377" target="_blank">00:22:57.720</a></span> | <span class="t">AI's running at thousands of times subjective human speed reflect on the meaning of existence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1382" target="_blank">00:23:02.680</a></span> | <span class="t">exchanging findings with each other and shaping the values it will bring to the stars. A new age dawns,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1389" target="_blank">00:23:09.080</a></span> | <span class="t">one that is unimaginably amazing in almost every way, but more familiar in some. Those in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1394" target="_blank">00:23:14.520</a></span> | <span class="t">audience with a higher PDOOM can check out the other scenario, which is rather grim. Notice though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1399" target="_blank">00:23:19.880</a></span> | <span class="t">I'm not disputing whether some of these things will happen, just the timelines that they give. I still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1404" target="_blank">00:23:24.520</a></span> | <span class="t">think we're living in some of the most epochal times of all. Just that it might be a more epochal decade</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1410" target="_blank">00:23:30.760</a></span> | <span class="t">rather than couple of years. Thank you as ever for watching. I know I covered a lot in one video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1415" target="_blank">00:23:35.480</a></span> | <span class="t">I will try to separate out my videos more in future. I'm super proud of the deep seat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1420" target="_blank">00:23:40.760</a></span> | <span class="t">documentary I made on Patreon, so do check it out if you want early access. But regardless,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wOBqh9JqCDY&t=1426" target="_blank">00:23:46.360</a></span> | <span class="t">thank you so much for watching to the end and have a wonderful day and wonderful decade.</span></div></div></body></html>