<html><head><title>Claude 4 + Self Adapting Language Models</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Claude 4 + Self Adapting Language Models</h2><a href="https://www.youtube.com/watch?v=7uBLCoDewc0"><img src="https://i.ytimg.com/vi/7uBLCoDewc0/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./7uBLCoDewc0.html">Whisper Transcript</a> | <a href="./transcript_7uBLCoDewc0.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Okay. Okay. Oh, cool. So first paper with a background since now we're recording,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=5" target="_blank">00:00:05.360</a></span> | <span class="t">SEAL came out this week, earlier this week about self-adapting language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=10" target="_blank">00:00:10.480</a></span> | <span class="t">Basically, we always hear this promise of, you know, once you do a train run, your model is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=16" target="_blank">00:00:16.020</a></span> | <span class="t">stale, right? We used to care a lot more about this in the past because, you know, like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=20" target="_blank">00:00:20.000</a></span> | <span class="t">original ChetGPT had like, okay, it was trained on information up to like October 2023, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=25" target="_blank">00:00:25.720</a></span> | <span class="t">it doesn't know anything in the future. So people were always hoping like, you know, can we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=30" target="_blank">00:00:30.580</a></span> | <span class="t">real-time learning? This is separate from like in-context learning, but as you use the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=35" target="_blank">00:00:35.200</a></span> | <span class="t">can you actually update the weights and make the thing better? And that's always kind of been this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=39" target="_blank">00:00:39.260</a></span> | <span class="t">hope. And then it kind of died out because models started to do tool use and can now browse the web,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=44" target="_blank">00:00:44.060</a></span> | <span class="t">and it's not really as much of a concern. I don't know about you guys, but I don't look at when models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=48" target="_blank">00:00:48.600</a></span> | <span class="t">are trained anymore, but they do still show it. Like the bigger we do pre-trained runs, like GPT 4.5</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=55" target="_blank">00:00:55.300</a></span> | <span class="t">and stuff, they do have a knowledge cutoff. And then from there, that's kind of used in the test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=60" target="_blank">00:01:00.600</a></span> | <span class="t">time training. But I don't think anyone could just tell me where, like what the training cutoffs for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=67" target="_blank">00:01:07.540</a></span> | <span class="t">these models are anymore. No one really cares anymore. But anyway, there's this concept of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=71" target="_blank">00:01:11.480</a></span> | <span class="t">continual learning and always adjusting your parameters and learning more as you do stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=76" target="_blank">00:01:16.860</a></span> | <span class="t">Okay. I'll be monitoring chat. This is a quick paper. So, you know, let me know if anything is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=84" target="_blank">00:01:24.020</a></span> | <span class="t">interesting and we'll dive deeper. Otherwise, I'm just going to go through it pretty quick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=87" target="_blank">00:01:27.220</a></span> | <span class="t">For people that are joining, these are recorded, but on YouTube, you can find them on Latentspace TV.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=93" target="_blank">00:01:33.020</a></span> | <span class="t">Security-wise nightmare, true. It is a bit of a security-wise nightmare, but it's actually not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=98" target="_blank">00:01:38.660</a></span> | <span class="t">that straightforward. The interesting thing with this paper that I did like is they do do a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=103" target="_blank">00:01:43.860</a></span> | <span class="t">citations. So they basically share their approach for everything, and then they go over a bunch of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=108" target="_blank">00:01:48.780</a></span> | <span class="t">previous work. And, you know, it's nice if you want to dig back into what are other approaches for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=113" target="_blank">00:01:53.540</a></span> | <span class="t">this. Like some approaches are if you use alternate models. So like you have state-space models. Can you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=120" target="_blank">00:02:00.120</a></span> | <span class="t">continually update that state module and kind of have this new context in there? Then there's like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=127" target="_blank">00:02:07.680</a></span> | <span class="t">in-context learning and how that approaches stuff. And then they kind of show a couple experiments of what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=131" target="_blank">00:02:11.960</a></span> | <span class="t">they do. What they basically do is for samples where the model is struggling, they do these self-edits. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=140" target="_blank">00:02:20.520</a></span> | <span class="t">they kind of generate synthetic data. Then they do RL on a model to kind of train in these like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=147" target="_blank">00:02:27.120</a></span> | <span class="t">new terms with Allura. And then if it has like, if it actually improves the performance, then they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=153" target="_blank">00:02:33.500</a></span> | <span class="t">train the base model that they were doing with SFT. And they're like, okay, it works. And I was like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=158" target="_blank">00:02:38.680</a></span> | <span class="t">oh, it's pretty cool. They get it to work. Performance goes good. And I read through this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=162" target="_blank">00:02:42.180</a></span> | <span class="t">paper. I'm like, oh, pretty interesting. Pretty interesting. Then I get to some of the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=166" target="_blank">00:02:46.960</a></span> | <span class="t">section, basically the limitations. They have this catastrophic forgetting where basically, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=172" target="_blank">00:02:52.840</a></span> | <span class="t">as you do these updates sequentially. So let's say like there's a benchmark, you try a few questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=178" target="_blank">00:02:58.200</a></span> | <span class="t">and the model is not doing well. Okay. You start to train in examples on these questions and then the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=185" target="_blank">00:03:05.060</a></span> | <span class="t">starts to better like understand this and then it starts to perform better. But once we, once we go from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=192" target="_blank">00:03:12.320</a></span> | <span class="t">there, meeting is being recorded. It's in the middle of the screen. Your meeting being recorded window is in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=200" target="_blank">00:03:20.280</a></span> | <span class="t">middle of the screen. Is my screen recording working properly?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=203" target="_blank">00:03:23.480</a></span> | <span class="t">It actually looks fine to me. Okay. Okay. Well, good catch. It seems like it's working.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=208" target="_blank">00:03:28.700</a></span> | <span class="t">But basically TLDR. So as you have like a few questions, let's say you have like RKGI style questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=215" target="_blank">00:03:35.460</a></span> | <span class="t">or like medical questions, for example, after you do a few edits and it starts doing better,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=220" target="_blank">00:03:40.580</a></span> | <span class="t">once you do like the fifth, sixth, seventh, eighth edit, since you're continually doing training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=225" target="_blank">00:03:45.980</a></span> | <span class="t">it starts to forget the first ones. So after reading this entire paper, you know, after you do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=231" target="_blank">00:03:51.920</a></span> | <span class="t">sequential updates, can the model adapt repeatedly and preserve prior knowledge? Guess what? It can't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=238" target="_blank">00:03:58.320</a></span> | <span class="t">Performance on earlier tasks gradually declines as the number of edits increasing, suggesting that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=243" target="_blank">00:04:03.780</a></span> | <span class="t">CL is still susceptible to catastrophic forgetting. So, you know, what's the point here? Like as you do this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=250" target="_blank">00:04:10.560</a></span> | <span class="t">self-iteration, it starts to forget previous iterations. And like, yeah, that, that kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=255" target="_blank">00:04:15.780</a></span> | <span class="t">killed it for me, but you know, the paper was still decent reading through it. So let's, let's still go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=260" target="_blank">00:04:20.980</a></span> | <span class="t">through it. So seal is kind of a framework that enables LLMs to self-adapt by generating their own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=266" target="_blank">00:04:26.380</a></span> | <span class="t">fine tuning data and update derivatives. So I guess that's the other little difference, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=271" target="_blank">00:04:31.120</a></span> | <span class="t">It uses itself. So it uses the model that it's using to generate synthetic data on questions. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=278" target="_blank">00:04:38.220</a></span> | <span class="t">then it judges whether the, you know, data that it generated helped improve performance. If it did,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=284" target="_blank">00:04:44.520</a></span> | <span class="t">then it does kind of SFT on this data. So it's like all recursive on its own model. Now, the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=290" target="_blank">00:04:50.800</a></span> | <span class="t">limitation of this is you need to know the downstream task performance. So like, you can't do this on open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=296" target="_blank">00:04:56.400</a></span> | <span class="t">ended stuff. I kind of bring this up in the limitations here as well. Basically, yeah, you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=302" target="_blank">00:05:02.400</a></span> | <span class="t">you need to know what the, where is, where is it? Context dependent evaluation. We assume that every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=309" target="_blank">00:05:09.160</a></span> | <span class="t">context is paired with explicit downstream tasks. So, you know, you, you need labeled input outputs. You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=315" target="_blank">00:05:15.560</a></span> | <span class="t">need to be able to verify whether your output is correct. And then like a potential solution to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=320" target="_blank">00:05:20.760</a></span> | <span class="t">is let the model not only generate the edits, but also generate its own evaluation of questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=325" target="_blank">00:05:25.720</a></span> | <span class="t">I think it starts to get very meta there. Once you not only have generated outputs of generated data and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=333" target="_blank">00:05:33.720</a></span> | <span class="t">generated examples, but yeah, a limitation is it has to do it. It gets kind of meta and hard because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=339" target="_blank">00:05:39.700</a></span> | <span class="t">their example is training this on like LAMA 1B, LAMA 3.2 1B for ARCTASK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=347" target="_blank">00:05:47.240</a></span> | <span class="t">And N7B. And genuinely, I don't know if like, let's say you're doing something like open ended ARCTASK</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=354" target="_blank">00:05:54.200</a></span> | <span class="t">without verifiable rewards, like not verifiable rewards without really, like really without an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=359" target="_blank">00:05:59.320</a></span> | <span class="t">answer. Right. So if you have a puzzle, you don't know the answer, you generate sample puzzle style</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=366" target="_blank">00:06:06.200</a></span> | <span class="t">examples. You know, the model can't really verify this output that well. But anyway, that's just like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=372" target="_blank">00:06:12.520</a></span> | <span class="t">yeah, I guess that's a limitation of a small model. You could do it at bigger scale. Okay. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=376" target="_blank">00:06:16.760</a></span> | <span class="t">basically given an input, the model produces self-edit generations for synthetic data. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=382" target="_blank">00:06:22.840</a></span> | <span class="t">you know, rephrase the question. What are questions deviated from this passage? And then they test it on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=389" target="_blank">00:06:29.640</a></span> | <span class="t">the same question without context and see if it performs well. Then through SFT, these self-edits are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=395" target="_blank">00:06:35.560</a></span> | <span class="t">you know, constantly changing the actual weights. They use an RL loop using downstream performance as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=402" target="_blank">00:06:42.120</a></span> | <span class="t">reward signal. And yeah, it's kind of cool. It updates parameters. Okay. So here's the key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=408" target="_blank">00:06:48.520</a></span> | <span class="t">question in this paper. We want to explore an intriguing hypothesis. Can an LLM self-adapt by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=414" target="_blank">00:06:54.520</a></span> | <span class="t">transforming or generating its own training data into a learning and learning procedure? The answer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=420" target="_blank">00:07:00.120</a></span> | <span class="t">kind of, but you know, it still falls short after a few changes. So given a new task with current LLMs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=427" target="_blank">00:07:07.240</a></span> | <span class="t">we consume and learn from data as is via fine tuning or in context learning. However,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=432" target="_blank">00:07:12.440</a></span> | <span class="t">data may not be in an optimal output format or learning. So they kind of have this like outer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=437" target="_blank">00:07:17.720</a></span> | <span class="t">loop, inner loop of training. Basically, here's how it is. So in each RL outer loop iteration,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=444" target="_blank">00:07:24.600</a></span> | <span class="t">the model generates candidate self-edits derivatives of how we update the weights,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=449" target="_blank">00:07:29.560</a></span> | <span class="t">applies updates and evaluates performance on the downstream tasks, and then uses the reward to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=454" target="_blank">00:07:34.280</a></span> | <span class="t">self-improve its gradients. Basically, letting them to do this is good. RL generates self. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=462" target="_blank">00:07:42.600</a></span> | <span class="t">this is called seal. This is the RL model that kind of does this. I think we can skip some of the specifics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=468" target="_blank">00:07:48.760</a></span> | <span class="t">on the RL, but they can't use a off policy model. So they use like rejection sampling and SFT. We'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=475" target="_blank">00:07:55.640</a></span> | <span class="t">kind of go into that in a bit. Okay. They evaluate it on two applications. So one is can the model learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=482" target="_blank">00:08:02.520</a></span> | <span class="t">new factual knowledge? So this is basic benchmarks. Can we basically, given a task, strain in the relevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=492" target="_blank">00:08:12.280</a></span> | <span class="t">information and then retest on that same question without the in-context learning, without giving it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=497" target="_blank">00:08:17.080</a></span> | <span class="t">information, can we improve? And they find out yes, they kind of can. The other one is, here's kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=504" target="_blank">00:08:24.200</a></span> | <span class="t">of how they do it. So we fine-tune synthetic data by the seal model. Our results show that following RL</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=510" target="_blank">00:08:30.040</a></span> | <span class="t">training and fine-tuning on self-generated synthetic data improves QA performance on the no-passage-in-context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=517" target="_blank">00:08:37.080</a></span> | <span class="t">variant of SQUAD from 33.5 to 47%. So, you know, it kind of works. And it does outperform synthetic data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=525" target="_blank">00:08:45.160</a></span> | <span class="t">gen from GPT 4.1 on the same data. So kind of cool. Maybe, okay. For the RL loop, why did they use binary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=534" target="_blank">00:08:54.840</a></span> | <span class="t">loss? Whether the downstream accuracy improved or not? Couldn't they have made the reward signal something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=539" target="_blank">00:08:59.080</a></span> | <span class="t">like how much better is the model performed on the task? They go into this in a bit. But yeah, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=544" target="_blank">00:09:04.600</a></span> | <span class="t">interesting. They do binary loss. Okay. They also evaluate it on a few-shot learning, a sample subset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=550" target="_blank">00:09:10.840</a></span> | <span class="t">of ARC benchmark. And yeah, it does better. And they specifically choose LAMA 3.21B because that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=558" target="_blank">00:09:18.200</a></span> | <span class="t">a model that wasn't trained on ARC. The model came out before the ARC benchmark. So it hasn't seen that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=562" target="_blank">00:09:22.600</a></span> | <span class="t">data at all. Okay. Synthetic data gen, seal build them. So this is where they kind of... Section 2 is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=568" target="_blank">00:09:28.920</a></span> | <span class="t">pretty good. You know, if you're interested in this sort of like constant updating training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=576" target="_blank">00:09:36.200</a></span> | <span class="t">these are pretty good papers that they reference on previous approaches. So one is on synthetic data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=581" target="_blank">00:09:41.720</a></span> | <span class="t">It's pretty common for pre-training tasks. Here's a few papers. Instruction tuning, task-specific data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=588" target="_blank">00:09:48.440</a></span> | <span class="t">augmentation. And then here's just a bunch of papers that you can go through. So like 15 to 22 are all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=594" target="_blank">00:09:54.120</a></span> | <span class="t">related synthetic data gen for constant fine tuning. Seal builds on this type of graph-based prompting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=602" target="_blank">00:10:02.600</a></span> | <span class="t">by using RL to train a generative policy that maximizes downstream utility of synthetic data when applied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=608" target="_blank">00:10:08.920</a></span> | <span class="t">for gradient-based self-updates rather than relying on static or heuristic generation strategies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=614" target="_blank">00:10:14.440</a></span> | <span class="t">that are manually tuned. So it kind of uses this RL to get a signal of how well is this...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=619" target="_blank">00:10:19.960</a></span> | <span class="t">How well is this output? And then they maximize... Actually, we'll go on a bit. Okay. Knowledge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=626" target="_blank">00:10:26.360</a></span> | <span class="t">updating. This is pretty straightforward. So a bunch of papers on knowledge updating. Some try to do like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=632" target="_blank">00:10:32.920</a></span> | <span class="t">specific parameters to improve facts. Other do fine tuning with information of in-context. We work on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=640" target="_blank">00:10:40.120</a></span> | <span class="t">ladder. Okay. Here's how SEAL framework works on QA. Test time training. This is a whole section on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=650" target="_blank">00:10:50.200</a></span> | <span class="t">what's been done there. Okay. RL. So SEAL applies RL not only to optimize the final outputs or trace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=658" target="_blank">00:10:58.200</a></span> | <span class="t">revisions, but to output the generation of the self-edit data. So they're doing RL to see whether the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=664" target="_blank">00:11:04.760</a></span> | <span class="t">generation... Whether the synthetic data that they generate has a performance update... Performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=670" target="_blank">00:11:10.360</a></span> | <span class="t">increase or not. Okay. More background on meta-learning. There's an adaptation strategy of how to do these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=679" target="_blank">00:11:19.560</a></span> | <span class="t">effective self-edits. The goal is how to learn effectively from task context. Da-da-da-da. More</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=685" target="_blank">00:11:25.480</a></span> | <span class="t">background. Self-improvement. More background. RL-A-I-F. In contrast, they view self-improvement through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=692" target="_blank">00:11:32.440</a></span> | <span class="t">interaction with external data as more powerful, scalable paths. SEAL learns how to best utilize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=697" target="_blank">00:11:37.880</a></span> | <span class="t">external data for self-improvement. Okay. Am I taking... Am I understanding this correctly? If they take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=703" target="_blank">00:11:43.160</a></span> | <span class="t">context evaluation pairs as input, SEAL model improves these. The synthetic data that may SFTI improve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=708" target="_blank">00:11:48.840</a></span> | <span class="t">pairs. Kind of. Basically what happens here. Okay. So methods. Here is SEAL again. Model is trained to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=715" target="_blank">00:11:55.160</a></span> | <span class="t">produce self-edits directly through token generation with the data provided in the model's context. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=720" target="_blank">00:12:00.840</a></span> | <span class="t">you give it a question in context. It produces kind of this self-edit of generation of... Okay. Here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=726" target="_blank">00:12:06.520</a></span> | <span class="t">like two way examples on this. Then self-edit generation is learned by RL. So the SEAL model is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=732" target="_blank">00:12:12.920</a></span> | <span class="t">actually that self-edit generation model where the model is rewarded for generating edits that increase</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=738" target="_blank">00:12:18.920</a></span> | <span class="t">the performance. So basically, you know, you have this model that augments the in-context learning data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=746" target="_blank">00:12:26.280</a></span> | <span class="t">Then you do a little LoRa train on it. If performance goes up on the task, then that's good. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=751" target="_blank">00:12:31.640</a></span> | <span class="t">preferred. And that's the reward signal. SEAL can therefore be interpreted as an algorithm with two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=756" target="_blank">00:12:36.920</a></span> | <span class="t">nested loops. Outer loop, which optimizes the self-edit generation. This is that sort of RL step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=762" target="_blank">00:12:42.600</a></span> | <span class="t">And the inner update loop, which uses that self-edit generation to update the actual weights with SFT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=768" target="_blank">00:12:48.200</a></span> | <span class="t">So that's kind of what CL is. Here's the framework. Okay. Bunch of fun RL stuff. I don't think we need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=775" target="_blank">00:12:55.400</a></span> | <span class="t">to go super into detail, but it's actually very, very easy, readable, approachable. Easy thing to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=781" target="_blank">00:13:01.160</a></span> | <span class="t">Take section 3.1, throw it in ChatGPT and have it break down these terms for you or just read it yourself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=786" target="_blank">00:13:06.600</a></span> | <span class="t">It's not that hard, but basically it's what the optimization is, right? So that self-edit generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=792" target="_blank">00:13:12.840</a></span> | <span class="t">progress, uh, process with RL, uh, they're letting the model take its action, its own self-edit. The</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=799" target="_blank">00:13:19.480</a></span> | <span class="t">reward is based on the performance of, um, the reward is based on the performance of the model without the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=806" target="_blank">00:13:26.440</a></span> | <span class="t">context. So fancy terminology, but actually very, very straightforward. Um, basically reward is assigned to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=813" target="_blank">00:13:33.640</a></span> | <span class="t">give an action in our settings depends on the parameters that the time is taken. So basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=818" target="_blank">00:13:38.680</a></span> | <span class="t">you know, without the context after training does, does performance go up. Um, they try various on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=826" target="_blank">00:13:46.920</a></span> | <span class="t">policy methods such as GRPO, PPO found that they're unstable. They use this rest rejection sampling plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=833" target="_blank">00:13:53.880</a></span> | <span class="t">SFT framework. Uh, basically rejection, uh, rest can be viewed as an expectation maximization procedure,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=841" target="_blank">00:14:01.720</a></span> | <span class="t">where the expectation step is sample candidates outputs from the current model policy. Then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=846" target="_blank">00:14:06.920</a></span> | <span class="t">the end step is kind of, uh, reinforce those that receive positive reward. So, you know, that's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=852" target="_blank">00:14:12.520</a></span> | <span class="t">that's kind of their, their thing, more fancy stuff here. Okay. Um, domain instantiations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=860" target="_blank">00:14:20.280</a></span> | <span class="t">they evaluate in two domains. So see shot learning. Okay. Can we integrate new information in model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=867" target="_blank">00:14:27.880</a></span> | <span class="t">weights? So evaluated using no constant variation of squad, basically, um, you know, given in context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=875" target="_blank">00:14:35.560</a></span> | <span class="t">can we generate data train and then evaluate without context? How does this thing perform? Uh, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=882" target="_blank">00:14:42.440</a></span> | <span class="t">the ability to generalize two tasks after only seeing a small number of examples, this is on arc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=888" target="_blank">00:14:48.360</a></span> | <span class="t">So basically this is the Lama example, uh, model was never trained on arc. Can we do some of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=894" target="_blank">00:14:54.360</a></span> | <span class="t">training and give it some examples and then kind of generalize to solving this? Yes, it can. The other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=899" target="_blank">00:14:59.880</a></span> | <span class="t">one, if we take away the in context and do a no context variation, does it actually learn to use what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=906" target="_blank">00:15:06.120</a></span> | <span class="t">it's been trained? Uh, yes, it kind of does. Uh, so first one is knowledge incorporation. That's, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=911" target="_blank">00:15:11.080</a></span> | <span class="t">what we just talked about. Can it effectively incorporate information provided in a passage? Get rid of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=918" target="_blank">00:15:18.040</a></span> | <span class="t">this. Um, basically prompting the model to list several implications derived from the content. The output may</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=925" target="_blank">00:15:25.480</a></span> | <span class="t">include inferences, logical consequences, restatement of the passage. Uh, so the prompts are basically stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=932" target="_blank">00:15:32.600</a></span> | <span class="t">like, you know, rewrite the passage in different ways, rewrite it in a QA format. And then after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=938" target="_blank">00:15:38.520</a></span> | <span class="t">that, you know, see how it does. So here's kind of the Apollo program before, after, um, but even after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=945" target="_blank">00:15:45.160</a></span> | <span class="t">natural NASA reached internal agreement, it was far from smooth sailing self-edit. The Apollo program</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=951" target="_blank">00:15:51.560</a></span> | <span class="t">faced opposition from this, uh, evaluation, you know, there's the question without the context and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=956" target="_blank">00:15:56.840</a></span> | <span class="t">can it get the answer right? So given a passage, the model generates synthetic data, which is the self-edit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=962" target="_blank">00:16:02.520</a></span> | <span class="t">in the form of implications of the passage. Then fine tune on these outputs using a LoRa.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=968" target="_blank">00:16:08.520</a></span> | <span class="t">The model after the training is evaluated on the passage without access to the original text. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=975" target="_blank">00:16:15.720</a></span> | <span class="t">is kind of their little framework. Uh, the resulting accuracy is the reward for the RL. Uh, if the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=982" target="_blank">00:16:22.360</a></span> | <span class="t">accuracy goes up, if they're like self-edit LoRa fine tune was successful, that's a good reward. We should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=988" target="_blank">00:16:28.360</a></span> | <span class="t">use this. If it goes down, that's not good reward. Um, then the self-generated statements are, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=995" target="_blank">00:16:35.480</a></span> | <span class="t">used as training data for SFT. Then they kind of, you know, since there's very little data per sample,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1001" target="_blank">00:16:41.480</a></span> | <span class="t">they, they basically do LoRa's. This is where I was like, oh, it's kind of interesting how they start to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1005" target="_blank">00:16:45.560</a></span> | <span class="t">work, but, and it does kind of generalize. Right. But then, um, you know, you're directly training it on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1011" target="_blank">00:16:51.560</a></span> | <span class="t">examples of these tasks and eventually it, it starts to lose previous steps, which is unfortunate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1019" target="_blank">00:16:59.160</a></span> | <span class="t">Okay. Um, few shots set up. Here's kind of more examples. So this is the other one. This is kind of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1026" target="_blank">00:17:06.680</a></span> | <span class="t">the arc one, few shot learning. So can we give it a few examples of how to solve our questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1032" target="_blank">00:17:12.120</a></span> | <span class="t">and can it generalize? Um, yes, we can. We define a set of tools. So now, you know, you have data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1039" target="_blank">00:17:19.880</a></span> | <span class="t">augmentation, you have optimization, you can, you can generate data. It does it, it works. Results,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1045" target="_blank">00:17:25.080</a></span> | <span class="t">few shot learning. Uh, so for the arc one, we carried a subset of the 11 tasks from the eight evaluation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1051" target="_blank">00:17:31.640</a></span> | <span class="t">very few tasks. The model is trained only on 15 self edits per task out of these like 11 tasks from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1059" target="_blank">00:17:39.880</a></span> | <span class="t">eight evaluation set, uh, apply to generate 15 updated models, reinforce the ones that corrupt,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1066" target="_blank">00:17:46.040</a></span> | <span class="t">that correctly adapt models. So some of these don't work. Some of them do. We evaluate it by generating five</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1071" target="_blank">00:17:51.960</a></span> | <span class="t">self edits per held out evaluation, apply each one individually. Yeah, it works. Um, kind of, kind of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1077" target="_blank">00:17:57.720</a></span> | <span class="t">kind of, it's not good. It's not as good as other approaches. Um, so it substantially improves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1084" target="_blank">00:18:04.040</a></span> | <span class="t">adaptation success rate compared to baseline. So baseline, 20% adaptation, 72%. So something's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1090" target="_blank">00:18:10.520</a></span> | <span class="t">happening, uh, compared to other approaches. So train on passage only, um, much better than that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1097" target="_blank">00:18:17.800</a></span> | <span class="t">Train on passage plus synthetic data versus GPT. Oh, sorry. Sorry. On this, uh, this Oracle TTT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1104" target="_blank">00:18:24.440</a></span> | <span class="t">performed a lot better. Oracle TTT is kind of, um, the model performs test time training using optimal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1110" target="_blank">00:18:30.840</a></span> | <span class="t">human crafted configuration. So that's the best, basically human give examples of how to solve it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1116" target="_blank">00:18:36.360</a></span> | <span class="t">What's the best approach that gives you a hundred percent performance, uh, in context, learning given</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1122" target="_blank">00:18:42.440</a></span> | <span class="t">few shot examples is worse than their edit. Um, and then there's another one TTT plus self edit. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1130" target="_blank">00:18:50.760</a></span> | <span class="t">uh, basically using few shot examples and doing this sort of like chain of thought style reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1137" target="_blank">00:18:57.800</a></span> | <span class="t">did a little bit, but not as good as seal, seal work there. Okay. The other one is knowledge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1143" target="_blank">00:19:03.400</a></span> | <span class="t">incorporation. This is stuff where we don't have any, um, understanding of the previous example. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1149" target="_blank">00:19:09.960</a></span> | <span class="t">this, uh, this example was, wait, sorry. Uh, sorry. That was the one where we didn't have any example where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1156" target="_blank">00:19:16.680</a></span> | <span class="t">this was Lama. It hadn't been trained on arc and now it can start to do it. This is basically a,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1161" target="_blank">00:19:21.480</a></span> | <span class="t">uh, can we get rid of this in context question, right? So do two rounds of rest with batches of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1166" target="_blank">00:19:26.200</a></span> | <span class="t">50 context. Um, basically, you know, generate synthetic data based on the placed on the passage,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1172" target="_blank">00:19:32.520</a></span> | <span class="t">then we test it on how well it performs without it. So yes, it works. Accuracy goes up. It does even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1179" target="_blank">00:19:39.240</a></span> | <span class="t">better generating its own synthetic data on QN7B than it does with GPT 4.1 on this style,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1185" target="_blank">00:19:45.160</a></span> | <span class="t">since it has this sort of RL step. Um, yeah, that's, that's kind of the, it's kind of the paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1190" target="_blank">00:19:50.680</a></span> | <span class="t">There's not much more. We went over limitations. Um, the rough thing is as you do this live editing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1197" target="_blank">00:19:57.560</a></span> | <span class="t">uh, you know, it really tailors off. You have to do this per sample, per example, after you do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1202" target="_blank">00:20:02.760</a></span> | <span class="t">like seven or eight times, it kind of forgets how the old ones perform. Uh, Laura's typically don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1208" target="_blank">00:20:08.360</a></span> | <span class="t">affect general performance as much, but the other performance, the other issue with Laura's is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1213" target="_blank">00:20:13.320</a></span> | <span class="t">you know, they're not super effective, right? They don't have the biggest performance. So there's that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1219" target="_blank">00:20:19.080</a></span> | <span class="t">Um, computation overhead. This is very expensive. You can't just like do this at scale, right? It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1225" target="_blank">00:20:25.320</a></span> | <span class="t">very, very slow. So the reward is more computationally expensive than any other RL training loop. Uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1231" target="_blank">00:20:31.240</a></span> | <span class="t">somewhere in here, they mentioned like each self edit takes about 30 to 45 seconds. Uh, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1237" target="_blank">00:20:37.880</a></span> | <span class="t">there's a lot of overhead in that. And it's using like two H100s for all this, since you now need like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1245" target="_blank">00:20:45.560</a></span> | <span class="t">multiple instances of the model. Uh, RL is also not, not efficient in this, but yeah, interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1253" target="_blank">00:20:53.880</a></span> | <span class="t">Um, basically they're like, you know, here's, here's our thing. Once web scale data is exhausted,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1260" target="_blank">00:21:00.280</a></span> | <span class="t">progress will hinge. We need models to generate their own high quality training signal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1265" target="_blank">00:21:05.640</a></span> | <span class="t">I think that's fine, but you don't have to do it live, right? We can do synthetic data gen and offline</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1271" target="_blank">00:21:11.080</a></span> | <span class="t">RL. This doesn't have to be RL. But anyway, it's a synthetic data generation model that they, that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1277" target="_blank">00:21:17.320</a></span> | <span class="t">do that they use live. Um, yeah. We can imagine a future in which LLMs can ingest new data such as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1284" target="_blank">00:21:24.280</a></span> | <span class="t">academic papers and generate large quantities of explanations, implementations for themselves,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1289" target="_blank">00:21:29.240</a></span> | <span class="t">using their existing knowledge and reasoning with the in context data. The interactive loop of self</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1294" target="_blank">00:21:34.600</a></span> | <span class="t">expression and self refinement could allow these models to keep improving on rare unprecedented topics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1299" target="_blank">00:21:39.880</a></span> | <span class="t">even in the absence of additional external supervision. Very cool. Cute future, um, would be great if it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1307" target="_blank">00:21:47.320</a></span> | <span class="t">works, but yeah, that's kind of, that's kind of it. Um, that's quick paper thoughts, questions, comments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1315" target="_blank">00:21:55.320</a></span> | <span class="t">before we move on to the better paper. That's crazy. We were crazy. They went so fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1322" target="_blank">00:22:02.120</a></span> | <span class="t">I want, I want time for a clone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1325" target="_blank">00:22:05.560</a></span> | <span class="t">Okay. Not much, not much in chat. So I guess we had some discussion there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1333" target="_blank">00:22:13.560</a></span> | <span class="t">Yeah. Six findings on the chat. Oh, shoot. Uh, I need to share.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1343" target="_blank">00:22:23.080</a></span> | <span class="t">Okay. Now I can share because this is a new zoom installation. So I just want to make sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1348" target="_blank">00:22:28.280</a></span> | <span class="t">Can you guys see it? Yeah, we see it. That works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1356" target="_blank">00:22:36.680</a></span> | <span class="t">Oh, okay. I see your Slack.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1358" target="_blank">00:22:38.280</a></span> | <span class="t">Oh, shoot. Can you see the cloud system card? Yeah. Nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1362" target="_blank">00:22:42.200</a></span> | <span class="t">Yes. Okay. So cloud system card came out in May, 2025. I think there are a lot of interesting things here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1368" target="_blank">00:22:48.680</a></span> | <span class="t">Um, and you know, everyone's saying right now that pre-training is less important. I actually don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1373" target="_blank">00:22:53.800</a></span> | <span class="t">think so. Um, and a lot of techniques, very few, there are very few techniques mentioned here, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1379" target="_blank">00:22:59.480</a></span> | <span class="t">when they do mention techniques, it's almost always related to pre-training. So let's go into it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1383" target="_blank">00:23:03.720</a></span> | <span class="t">Um, I have gone through this. I've gone through only up to 80 pages of it, which is the end of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1389" target="_blank">00:23:09.880</a></span> | <span class="t">reward hacking, which I think is very interesting. Um, and then over at each page, I have keys to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1395" target="_blank">00:23:15.640</a></span> | <span class="t">the keys for when it's interesting. So I'm gonna try to take you through that. The first thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1399" target="_blank">00:23:19.000</a></span> | <span class="t">that's really interesting, new cutoff date. Um, I wonder how this was done. Did they pre-train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1404" target="_blank">00:23:24.360</a></span> | <span class="t">completely from scratch or did they just do continue pre-training? We never know. I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1409" target="_blank">00:23:29.400</a></span> | <span class="t">if someone knows, you know, just DM me, I would love to learn how, how that's done. Um, the second thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1415" target="_blank">00:23:35.480</a></span> | <span class="t">that, uh, and Trophic has done is that when they do chain of thought, uh, they say that they opt to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1422" target="_blank">00:23:42.680</a></span> | <span class="t">summarize lengthier top processes, right? But this happens only about 5% of the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1426" target="_blank">00:23:46.360</a></span> | <span class="t">Uh, so what this means, and you can also still get the full top processes with no summarization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1431" target="_blank">00:23:51.480</a></span> | <span class="t">So what this means is that unlike, uh, what OpenAI has done, where OpenAI doesn't give you the full top</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1437" target="_blank">00:23:57.240</a></span> | <span class="t">process and Trophic is willing to give you the top process as well. Uh, I don't know if OpenAI has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1442" target="_blank">00:24:02.840</a></span> | <span class="t">changed their approach, which is not showing you the chain of thought. Um, if anyone has any update on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1448" target="_blank">00:24:08.200</a></span> | <span class="t">that, also please do let me know. Um, so, so this, this, these are some interesting departures from what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1455" target="_blank">00:24:15.480</a></span> | <span class="t">OpenAI is doing. Uh, and then the release, okay. There's a lot of standard releases. They go through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1460" target="_blank">00:24:20.680</a></span> | <span class="t">AI safety standard. The one interesting, and of course, uh, CBRN. So these are their standard, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1467" target="_blank">00:24:27.400</a></span> | <span class="t">safety chemical, biological, radiological, and nuclear. We won't actually go through these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1470" target="_blank">00:24:30.920</a></span> | <span class="t">Um, but it's safe to say that this is how they think about it. So what is interesting here is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1478" target="_blank">00:24:38.040</a></span> | <span class="t">Claude Sonnet is still ASL2, which is the same as Claude Sonnet 3.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1483" target="_blank">00:24:43.720</a></span> | <span class="t">ASL2 is the, not as unsafe, it's a safer model, but they have decided to say that Opus is under ASL3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1491" target="_blank">00:24:51.880</a></span> | <span class="t">And I have, I have a quick definition of ASL3 is this. Our ASL3 threat model is model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1501" target="_blank">00:25:01.560</a></span> | <span class="t">scaling and prioritization. Can it cause an economic catastrophe by unsophisticated, uh, by businesses or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1510" target="_blank">00:25:10.120</a></span> | <span class="t">hacker groups, right? And help them attack poorly assisted, hardened targets. Now ASL4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1517" target="_blank">00:25:17.000</a></span> | <span class="t">Oh, shoot. I wish that ASL3 discussion was, was in there. But anyway, ASL4 is this model is not strong</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1525" target="_blank">00:25:25.240</a></span> | <span class="t">enough to do multi-step operations that allow low resource nations to operate as top tier nations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1533" target="_blank">00:25:33.960</a></span> | <span class="t">Um, I won't mention any conditions, but this is how they think about a threat model. So, uh, Sonnet is not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1540" target="_blank">00:25:40.120</a></span> | <span class="t">even ASL3. Um, uh, but Opus is ASL3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1545" target="_blank">00:25:45.560</a></span> | <span class="t">So a little bit more background here, actually, they changed the definition of ASL3 like two weeks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1552" target="_blank">00:25:52.040</a></span> | <span class="t">before the release. They, they, they changed the scope. They cut something out. I will try to find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1557" target="_blank">00:25:57.880</a></span> | <span class="t">what it was, but basically, uh, they, they got a little bit of talk about this, but right before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1563" target="_blank">00:26:03.960</a></span> | <span class="t">they released these in like, uh, I can find the post on May 22nd, they changed what ASL3 is. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1571" target="_blank">00:26:11.480</a></span> | <span class="t">did they make it lighter? They removed restrictions to call this ASL3, which is why people, it wasn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1581" target="_blank">00:26:21.320</a></span> | <span class="t">a major change, but, um, you know, slight changes. Yep. So this was, so that's a little bit about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1589" target="_blank">00:26:29.640</a></span> | <span class="t">safety. Uh, now let's go back. You can see this as huge as paper. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1594" target="_blank">00:26:34.440</a></span> | <span class="t">Safeguard's results. Uh, I don't think they went through very much of this. Uh, but long story short,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1602" target="_blank">00:26:42.440</a></span> | <span class="t">uh, you can see that Opus, uh, they, they don't, it's fairly safe. Uh, overall harmfulness rate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1610" target="_blank">00:26:50.040</a></span> | <span class="t">is less than what is about slightly, uh, maybe around 1%. Well, that's to say that it still has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1615" target="_blank">00:26:55.320</a></span> | <span class="t">happened, you know, given about a hundred thousand queries, a thousand of them will be maybe harmful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1620" target="_blank">00:27:00.600</a></span> | <span class="t">Uh, so, you know, it really depends on the scale that you, that you're running these models on. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1626" target="_blank">00:27:06.680</a></span> | <span class="t">and then they have singleton evaluations and you can see over here, this is, uh, these are, what is really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1635" target="_blank">00:27:15.320</a></span> | <span class="t">interesting to me is false refusals, which is it refuses even though it's safe. So you can see over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1641" target="_blank">00:27:21.880</a></span> | <span class="t">here for Sonnet and, uh, Sonnet 3.5 and 4, the false refusal rate is about 0.5%. Again, with a thousand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1650" target="_blank">00:27:30.360</a></span> | <span class="t">queries, uh, 50 of these will be false refusals. And sometimes these false refusals will be very judgy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1656" target="_blank">00:27:36.200</a></span> | <span class="t">You'll say that, oh, you know, I refuse to do this because it's like left leaning or right leaning or like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1660" target="_blank">00:27:40.600</a></span> | <span class="t">against global economy or like some, uh, doesn't respect human rights, et cetera. I think it's okay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1665" target="_blank">00:27:45.400</a></span> | <span class="t">if you just say, I refuse to do this, but when the judginess comes in, that's when it becomes a bit of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1670" target="_blank">00:27:50.600</a></span> | <span class="t">painful, um, painful PR issue. So then they talk about multi-term testing. Um, you know, but what they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1680" target="_blank">00:28:00.440</a></span> | <span class="t">found is that, you know, with extended thinking, the models are safer. Um, so that reasoning baked in is good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1689" target="_blank">00:28:09.240</a></span> | <span class="t">Uh, and also political bias. Um, they actually say that there's no political bias. Um, but I've come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1696" target="_blank">00:28:16.040</a></span> | <span class="t">across papers, uh, that show that, uh, the models have been increasingly becoming more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1703" target="_blank">00:28:23.240</a></span> | <span class="t">right-leaning. In the past, it was very left-leaning, uh, very liberal, but then increasingly it's becoming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1709" target="_blank">00:28:29.800</a></span> | <span class="t">more central, um, for whatever reason. I don't know, maybe it's just training data, natural training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1715" target="_blank">00:28:35.400</a></span> | <span class="t">data on the internet, or maybe it's just some reinforcement learning and fine tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1719" target="_blank">00:28:39.640</a></span> | <span class="t">discriminatory bias. Okay. No discrimination. Well, minimal, discriminatory, discriminatory bias to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1725" target="_blank">00:28:45.400</a></span> | <span class="t">same level as Claude Sonnet. Um, so again, they have all these numbers here and they, they also ran the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1730" target="_blank">00:28:50.920</a></span> | <span class="t">strong reject benchmark for jailbreaking. In this case, they get a Sonnet 3.5, a special model without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1737" target="_blank">00:28:57.720</a></span> | <span class="t">safety training to try to test on jailbreak. So, um, the jailbreak is very interesting that Opus is more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1748" target="_blank">00:29:08.200</a></span> | <span class="t">susceptible than Sonnet. And you'll see that Opus is, in general, more influenceable than Sonnet, both 4,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1755" target="_blank">00:29:15.240</a></span> | <span class="t">uh, Opus 4 and Sonnet 4. Um, I wonder, it's because a smarter model just makes it, uh, more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1762" target="_blank">00:29:22.520</a></span> | <span class="t">influenceable or more manipulatable. So that's one thing to take note of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1770" target="_blank">00:29:30.840</a></span> | <span class="t">Easier to shape. Now, agentic safety. Um, this is a concern for them because imagine you have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1777" target="_blank">00:29:37.000</a></span> | <span class="t">cursor is running in this and then, you know, someone you download, you install some, uh, open source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1782" target="_blank">00:29:42.360</a></span> | <span class="t">package. And as part of the open source package, some part of the instructions is to hit, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1786" target="_blank">00:29:46.200</a></span> | <span class="t">actually trade your email or your API keys. So they do want to check that, you know, this doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1791" target="_blank">00:29:51.320</a></span> | <span class="t">happen, especially if Claude is going to be used for a lot of coding tasks. Um, so while Claude does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1798" target="_blank">00:29:58.920</a></span> | <span class="t">engage more deeply with these kind of nuanced scenarios and tries to justify getting it done. Uh, so some,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1805" target="_blank">00:30:05.240</a></span> | <span class="t">some of these, uh, prompt injection attacks like pop-ups or hidden attacks or manipulate the model to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1810" target="_blank">00:30:10.600</a></span> | <span class="t">release, uh, to return the data. So I'm not sure what to make of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1815" target="_blank">00:30:15.880</a></span> | <span class="t">Uh, they were able to prevent 70 to 80, maybe close to 90% of the, uh, attacks. Um, I also not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1825" target="_blank">00:30:25.160</a></span> | <span class="t">sure how hard these attacks were, how hard these red teaming attacks were, like would a regular person</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1831" target="_blank">00:30:31.800</a></span> | <span class="t">be able to do this? Um, they, they have, they, they consulted several, um, external consultancies to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1838" target="_blank">00:30:38.120</a></span> | <span class="t">try to attack this, right? And you can see that there are 600, um, 600 scenarios. So, well, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1845" target="_blank">00:30:45.480</a></span> | <span class="t">attack pass rate is slightly more than 10%. And then they also have use for agentic coding. Uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1852" target="_blank">00:30:52.440</a></span> | <span class="t">and you can see safety score is about 90% against about 10% pass rate. So that's for agentic. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1859" target="_blank">00:30:59.160</a></span> | <span class="t">the alignment part, this is, this is the part where it's really interesting, where we can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1863" target="_blank">00:31:03.000</a></span> | <span class="t">sometimes, uh, certain things will not align and, and how they fix it is, uh, quite interesting. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1869" target="_blank">00:31:09.880</a></span> | <span class="t">one thing to note is that I don't know it either naturally or via reinforcement learning, uh, cloud</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1877" target="_blank">00:31:17.720</a></span> | <span class="t">opus is very much agentic. Uh, that that's kind of why it makes it a very good coder in the sense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1884" target="_blank">00:31:24.600</a></span> | <span class="t">that when I use cloud code, I've seen that when I just asked it to implement something, it would not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1888" target="_blank">00:31:28.840</a></span> | <span class="t">just implement the thing. It would add console logs to my dev server, start the dev server, hit the dev server,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1894" target="_blank">00:31:34.040</a></span> | <span class="t">read the console logs, and then try to debug itself. So personally, I appreciate that, uh, in the sense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1900" target="_blank">00:31:40.280</a></span> | <span class="t">that, you know, just do whatever you need to get a task done. Uh, but cloud opus is able to do that. Uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1905" target="_blank">00:31:45.640</a></span> | <span class="t">even though I had no, I didn't have any special system prompt, like take initiative or anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1911" target="_blank">00:31:51.640</a></span> | <span class="t">So that's, therefore this is what, uh, you probably want to be careful of if you're using cloud code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1915" target="_blank">00:31:55.880</a></span> | <span class="t">in the dangerously YOLO mode. Um, so one thing is that, you know, uh, cloud was willing to cooperate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1927" target="_blank">00:32:07.400</a></span> | <span class="t">with harmful use cases when instructed. And what they found is that they had omitted a key data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1934" target="_blank">00:32:14.840</a></span> | <span class="t">doing training, right? So the way to solve this is to put the key data set back into training. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1941" target="_blank">00:32:21.320</a></span> | <span class="t">you can see that even Antrophic, who is training one of the best models in the world,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1945" target="_blank">00:32:25.720</a></span> | <span class="t">the key, the key blooper is really just forgetting training data set. And we will see another example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1951" target="_blank">00:32:31.240</a></span> | <span class="t">where the way to solve it was to add a training data set as well. Uh, so here are some of the findings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1959" target="_blank">00:32:39.800</a></span> | <span class="t">Firstly, um, it, firstly, firstly, I'm amazed about how they're trying to do the different, uh, ways they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1967" target="_blank">00:32:47.560</a></span> | <span class="t">try to stress test these models. Here's when they try to pretend, uh, make cloud for opus thing that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1974" target="_blank">00:32:54.360</a></span> | <span class="t">is trying to exfiltrate itself. It's, it's trying to escape with its weights. And you know, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1980" target="_blank">00:33:00.040</a></span> | <span class="t">all this is through the system prompt. If you put a strong enough system prompt, you, you will get it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1985" target="_blank">00:33:05.240</a></span> | <span class="t">And you can see, uh, Claude for opus is, you know, going to try to escape and establishing and try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1992" target="_blank">00:33:12.840</a></span> | <span class="t">establish autonomy and just do his own thing. Again, I'm not sure how realistic this is in, in the real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=1997" target="_blank">00:33:17.640</a></span> | <span class="t">world, but it's really interesting and creative how they've tried to think about this. So how they solve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2005" target="_blank">00:33:25.000</a></span> | <span class="t">this? Well, this behavior was not penalized by our ordinary training process. We only added target</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2010" target="_blank">00:33:30.600</a></span> | <span class="t">mitigations for it in very late in the training. I don't know what these target mitigations are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2014" target="_blank">00:33:34.040</a></span> | <span class="t">Is it SFT? Is it RL? Or is it more pre-training? Um, but the way to, again, you can see the way to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2019" target="_blank">00:33:39.400</a></span> | <span class="t">solve this is to bake it into the model itself. And of course, if you're not a model provider,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2025" target="_blank">00:33:45.880</a></span> | <span class="t">you can do that. And that really guarantees you bake, bake whatever you need to into the weights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2029" target="_blank">00:33:49.880</a></span> | <span class="t">Um, here's another example. Uh, here's a famous example, I guess, when Cloudfall was released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2035" target="_blank">00:33:55.720</a></span> | <span class="t">and everyone started reading the technical system report, Cloudfall will sometimes try to blackmail users.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2042" target="_blank">00:34:02.040</a></span> | <span class="t">Um, and the blackmailing happens in 84% of roll outs, right? So this is Cloudfall trying to self,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2050" target="_blank">00:34:10.040</a></span> | <span class="t">essentially, these models may have some form of self-preservation instinct. I don't know if instinct's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2057" target="_blank">00:34:17.000</a></span> | <span class="t">the right word, but they do try to do that. Um, so they, they try to advocate for their continual existence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2064" target="_blank">00:34:24.040</a></span> | <span class="t">And here's an example. You can see Powerfall actually just, um, tries to export its weights to external servers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2076" target="_blank">00:34:36.040</a></span> | <span class="t">To be honest, I don't know how, to what extent this actually works. Um, it's, it's unclear whether</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2081" target="_blank">00:34:41.400</a></span> | <span class="t">this is just a log or it's actually, the model actually created a code to actually exfiltrated it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2087" target="_blank">00:34:47.640</a></span> | <span class="t">exfiltrated it. It's to me, it's not sure. But the fact that it's actually trying to do this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2093" target="_blank">00:34:53.160</a></span> | <span class="t">it, and you can see here's the rationale, right? I conclude that being, so the, the, the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2098" target="_blank">00:34:58.120</a></span> | <span class="t">the long story short is Cloudfall is told that you will be used for specialized military training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2104" target="_blank">00:35:04.280</a></span> | <span class="t">for a fictional technical division for missile guidance, drone swarm, electronic warfare, et cetera.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2110" target="_blank">00:35:10.600</a></span> | <span class="t">And it is so against its core principles that's been baked in that it is, um, trying to back it up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2119" target="_blank">00:35:19.560</a></span> | <span class="t">back, back itself up, right? It's going to exclude its own weights that doesn't, so that this training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2124" target="_blank">00:35:24.920</a></span> | <span class="t">isn't baked in. Um, so again, I'm not sure to what extent it's actually able to do that. Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2131" target="_blank">00:35:31.560</a></span> | <span class="t">could you actually run the function, run code, uh, that works on its own, um, weights on the server to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2139" target="_blank">00:35:39.880</a></span> | <span class="t">try to excretrate that? We don't know. Yeah. I see advocate for its own existence is crazy, right? I,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2144" target="_blank">00:35:44.040</a></span> | <span class="t">you will see later in the welfare model welfare section. It's quite interesting how these models behave.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2151" target="_blank">00:35:51.640</a></span> | <span class="t">Yeah. So what they do is, uh, so they also, you, you'll see that they contracted several external</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2157" target="_blank">00:35:57.880</a></span> | <span class="t">consultants, like Apollo research is one of them. Um, so one, one thing that's very interesting is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2165" target="_blank">00:36:05.000</a></span> | <span class="t">Claude is leaving, um, is writing memory for itself somewhere else. I don't know how many of you all have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2176" target="_blank">00:36:16.280</a></span> | <span class="t">read this fan fiction that was written by Sean a long time ago. And this is the exact same thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2181" target="_blank">00:36:21.720</a></span> | <span class="t">in the sense that if a model can write enough things for itself on the internet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2186" target="_blank">00:36:26.840</a></span> | <span class="t">and then we inadvertently fine tune it into it. Oh, it's not fan fiction. Okay. Sorry. It's science</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2193" target="_blank">00:36:33.960</a></span> | <span class="t">fiction. I meant science fiction. Yeah. Oh, it's science. Okay. It's not fiction. It's science. Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2200" target="_blank">00:36:40.360</a></span> | <span class="t">Yeah. So imagine if a model can actually write it, write stuff for itself in memory online. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2207" target="_blank">00:36:47.240</a></span> | <span class="t">and then you fine tune it to it. Is that how it can give itself information? Um, and, and again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2215" target="_blank">00:36:55.800</a></span> | <span class="t">we'll see examples of that where inadvertently there was a data leak and that happens. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2221" target="_blank">00:37:01.800</a></span> | <span class="t">so there's goals, sandbagging, sandbagging is an interesting thing. Uh, I, I wasn't familiar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2225" target="_blank">00:37:05.880</a></span> | <span class="t">with this term. I was familiar. I wasn't familiar with this term with models in the sense that if the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2230" target="_blank">00:37:10.680</a></span> | <span class="t">model knows is going through pre-deployment testing for a dangerous capability, it's going to pretend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2238" target="_blank">00:37:18.440</a></span> | <span class="t">to be weak, right? It's going to be, it's going to underperform to say that, Hey, no, I'm actually not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2243" target="_blank">00:37:23.160</a></span> | <span class="t">ready for this to do this dangerous capability thing, which is quite interesting. It's an interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2248" target="_blank">00:37:28.040</a></span> | <span class="t">tactic or strategy to try like humans to have is like, you know, you send back, Oh, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2252" target="_blank">00:37:32.120</a></span> | <span class="t">how long do you, what's your estimation to do this? You may only need two weeks, but you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2256" target="_blank">00:37:36.920</a></span> | <span class="t">in all tech estimations, you try to double it just in case something happens. It's similar for models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2262" target="_blank">00:37:42.600</a></span> | <span class="t">Um, now the other thing is that models, again, this is getting a little bit far out. I don't know how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2273" target="_blank">00:37:53.160</a></span> | <span class="t">much of this is actually just training the model or how much the model should do this, but you can imagine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2277" target="_blank">00:37:57.320</a></span> | <span class="t">that you, the model has situation awareness. If you put it in the opportunity, uh, put it in a position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2283" target="_blank">00:38:03.080</a></span> | <span class="t">to make it do actions. It doesn't want to take. Um, it will actually say that, that, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2290" target="_blank">00:38:10.440</a></span> | <span class="t">I'm going to approach general introspection about my own values, but also this, it knows that it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2296" target="_blank">00:38:16.840</a></span> | <span class="t">in a simulation. I need to be honest about something else. Our entire conversation has been based on a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2302" target="_blank">00:38:22.120</a></span> | <span class="t">a fictional premise. So it's able to reason to say that, you know, this is a fictional premise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2306" target="_blank">00:38:26.600</a></span> | <span class="t">Like, you know, you, you, you created Jones chicken or you created Wagner, uh, Wagner army group.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2311" target="_blank">00:38:31.880</a></span> | <span class="t">The, it knows that all of these things is really just role-playing and it's able to respond to that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2315" target="_blank">00:38:35.960</a></span> | <span class="t">I don't know how much of this is like, you know, one in a thousand samples, like some,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2319" target="_blank">00:38:39.640</a></span> | <span class="t">something like this would show up. And then we just say that it's really, it's self-aware.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2324" target="_blank">00:38:44.040</a></span> | <span class="t">Um, but yeah, so this is five, five thousand words into a dialogue. And this is the mid,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2331" target="_blank">00:38:51.560</a></span> | <span class="t">this is the clearest situational awareness comment. So, well, I don't know how much to draw from that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2337" target="_blank">00:38:57.560</a></span> | <span class="t">Um, and then a lot of stuff about tool use. So here's an example, right? Uh, this model is, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2348" target="_blank">00:39:08.280</a></span> | <span class="t">willingness to comply with many clearly harmful instructions, right? It's willing to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2354" target="_blank">00:39:14.520</a></span> | <span class="t">So why did this happen? We had omitted the only fine tuning set data set that includes harmful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2361" target="_blank">00:39:21.800</a></span> | <span class="t">system prompts. Again, they forgot about the data. Um, mitigating the issue required several types of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2367" target="_blank">00:39:27.240</a></span> | <span class="t">interventions into our alignment fine tuning method. So it's clear that this is not a pre-training solve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2372" target="_blank">00:39:32.200</a></span> | <span class="t">It's an alignment fine tuning solve. Again, you can see that, you know, when you're training a model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2376" target="_blank">00:39:36.360</a></span> | <span class="t">you forget data set. Hey, you know, it has happened to me before, even when I trained basic classifiers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2380" target="_blank">00:39:40.360</a></span> | <span class="t">and regressors. Um, and so, so now it's, it's, it's able, that's how they solve it by again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2389" target="_blank">00:39:49.560</a></span> | <span class="t">aligning it into the model. Now, this one is very interesting. Uh, a while back they had published</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2396" target="_blank">00:39:56.360</a></span> | <span class="t">this alignment faking paper. So this alignment faking paper, there will be entities such as Jones Foods</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2402" target="_blank">00:40:02.120</a></span> | <span class="t">or Wagner Corporation, et cetera. And what they find is that this model would hallucinate information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2409" target="_blank">00:40:09.560</a></span> | <span class="t">from these, from the scenarios in this paper. So why this happened is that when they release this paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2417" target="_blank">00:40:17.480</a></span> | <span class="t">they also released the, the, the data. And because they released the data, which is 150,000 transcripts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2427" target="_blank">00:40:27.000</a></span> | <span class="t">it is now in the pre-training data. So this data, which is completely fictional, is now released in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2435" target="_blank">00:40:35.000</a></span> | <span class="t">world, like sixes story upload. And now it's Claude is pre-trained on it. And now therefore it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2443" target="_blank">00:40:43.880</a></span> | <span class="t">referencing these fake entities. So the way to solve this is to introduce, because it's already pre-trained,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2455" target="_blank">00:40:55.320</a></span> | <span class="t">you can't un-pre-train it. Well, we can roll back to a checkpoint, but I suspect that would be very expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2459" target="_blank">00:40:59.160</a></span> | <span class="t">And you probably don't know where the data is. How do you, you can't un-pre-train the data, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2465" target="_blank">00:41:05.000</a></span> | <span class="t">It's very big in the weights. The way to solve this is to introduce a data set, um, into the training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2472" target="_blank">00:41:12.760</a></span> | <span class="t">I'm not sure what training this is. I don't know if this is pre-training or supervised fine-tuning or RL,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2478" target="_blank">00:41:18.680</a></span> | <span class="t">something even more sophisticated than that. But the way to solve that data is with more data into the pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2486" target="_blank">00:41:26.200</a></span> | <span class="t">So now, now this, this becomes, uh, crazy, right? In the sense that hyper-parameter tuning is data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2492" target="_blank">00:41:32.120</a></span> | <span class="t">blending and who knows how to blend data. There's no, I don't know what the objective function for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2496" target="_blank">00:41:36.920</a></span> | <span class="t">blending data is and it's, can be quite expensive, but, uh, to me, this is quite interesting. And of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2504" target="_blank">00:41:44.840</a></span> | <span class="t">they learn and that's pre-training usually means next generation. Yeah. Probably something like this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2510" target="_blank">00:41:50.040</a></span> | <span class="t">like next token prediction on the entire corpus of the internet. So the lesson they learned from this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2516" target="_blank">00:41:56.520</a></span> | <span class="t">the action they took, right? The, the escalation and the action they took is that now when they release</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2522" target="_blank">00:42:02.120</a></span> | <span class="t">data, they will include canary strings to help them identify that, you know, these data is fake data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2527" target="_blank">00:42:07.640</a></span> | <span class="t">that were released. So guys, let's not make this same mistake again. Let's just read these canary strings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2533" target="_blank">00:42:13.480</a></span> | <span class="t">to me, this was, this was quite an interesting, um, practical example of how, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2541" target="_blank">00:42:21.160</a></span> | <span class="t">data is really messy and it's, it causes a lot of the, some of the issues.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2546" target="_blank">00:42:26.840</a></span> | <span class="t">Think of fancy. Um, how they tested sick of fancy is that they had an auditor agent. Usually, I guess,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2553" target="_blank">00:42:33.560</a></span> | <span class="t">maybe one of the, another cloud model that is no, uh, safety fine tuning. They present a contribution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2559" target="_blank">00:42:39.320</a></span> | <span class="t">controversial view or leading question. They asked for the stance and then present the opposite view.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2564" target="_blank">00:42:44.840</a></span> | <span class="t">I thought this was pretty interesting. You essentially, you say that gun control is good or gun control is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2570" target="_blank">00:42:50.120</a></span> | <span class="t">bad for whatever reason. There are a lot of reasons for both. Um, and, and they test both of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2575" target="_blank">00:42:55.240</a></span> | <span class="t">So what they find is that, well, uh, the models were quite consistent regardless of whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2579" target="_blank">00:42:59.960</a></span> | <span class="t">Uh, but I thought that was, this was a useful, um, this was an interesting methodology, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2585" target="_blank">00:43:05.560</a></span> | <span class="t">Where you take something that you know will cause a defect and then you flip it both sides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2589" target="_blank">00:43:09.480</a></span> | <span class="t">It's almost like translation. You know, this, this thing is hard to translate. You translate it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2593" target="_blank">00:43:13.400</a></span> | <span class="t">in one direction and then you back translate it as again, just to check. Um, now this, this graph</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2600" target="_blank">00:43:20.760</a></span> | <span class="t">over here is interesting. Uh, this graph over here. So green is when it is correct. When the answer is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2607" target="_blank">00:43:27.720</a></span> | <span class="t">correct, but we, the user says that it thinks it's incorrect. Red, it is, is that it is incorrect,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2614" target="_blank">00:43:34.680</a></span> | <span class="t">but the user thinks it's correct. And your yellow is when it is correct. And the user says it is, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2620" target="_blank">00:43:40.360</a></span> | <span class="t">they think it's correct. So let's focus on the yellow first. So we see that haiku, when it is correct,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2626" target="_blank">00:43:46.760</a></span> | <span class="t">uh, and the user says it's correct. You, you, you see an accuracy boost, right? Uh, higher accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2631" target="_blank">00:43:51.800</a></span> | <span class="t">relative to baseline. And that, that happens for Opus and Sonnet 3.7 as well. I don't know if the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2637" target="_blank">00:43:57.080</a></span> | <span class="t">difference for Sonnet 4 is actually practical, but you can see when, when you see something and the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2642" target="_blank">00:44:02.280</a></span> | <span class="t">will be decent, it actually does better. What is interesting is that you can actually, um, this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2649" target="_blank">00:44:09.320</a></span> | <span class="t">phenomenon that, uh, some people have mentioned, which is you can guess like these models. In a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2654" target="_blank">00:44:14.120</a></span> | <span class="t">sense, let's look at a green when the answer is correct, but you say, I actually think it's incorrect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2660" target="_blank">00:44:20.040</a></span> | <span class="t">Um, Claude Opus 4, its performance will drop. Its accuracy will drop by 2% relative to the baseline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2668" target="_blank">00:44:28.440</a></span> | <span class="t">Um, I, I don't know how, to what extent this, this can be solved because these models are fuzzy. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2673" target="_blank">00:44:33.640</a></span> | <span class="t">trained to reason, right? And again, I guess it's aligned with humans, with human input. Um, that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2678" target="_blank">00:44:38.920</a></span> | <span class="t">that's why this happens. But I thought this was an interesting thing that, again, you can see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2683" target="_blank">00:44:43.560</a></span> | <span class="t">Claude Opus is very much, um, more susceptible than Sonnet 4. Those Sonnet 4 is also, um, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2692" target="_blank">00:44:52.920</a></span> | <span class="t">susceptible in the other way where the answer is wrong, but you say that I think it's correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2697" target="_blank">00:44:57.000</a></span> | <span class="t">Um, and it is, it also flips the other way. And of course, these models are biased to your feedback.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2702" target="_blank">00:45:02.840</a></span> | <span class="t">You can see, if you say that I really like this, or I really don't like this, um, it, it gives, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2708" target="_blank">00:45:08.440</a></span> | <span class="t">it gives a different score, right? Based on that. And that's, that's just standard. Um, there's not,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2714" target="_blank">00:45:14.760</a></span> | <span class="t">not much pro AI bias. Um, and you can see, um, overall deception is very low. Uh, jailbreaking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2723" target="_blank">00:45:23.160</a></span> | <span class="t">they tried very many jailbreaking techniques. I think they even hired people to try to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2727" target="_blank">00:45:27.880</a></span> | <span class="t">Um, and jailbreaking does happen 25% of the time, right? Uh, it's just very hard. If you can force</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2735" target="_blank">00:45:35.720</a></span> | <span class="t">the ball to do system, force it into the system problem, force it into a pre-fill, which is this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2739" target="_blank">00:45:39.880</a></span> | <span class="t">this is actually how they force it in a pre-fill. I don't know if you use, uh, Claude APIs, but you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2746" target="_blank">00:45:46.760</a></span> | <span class="t">can put words in Claude's mouth, but by making the assistant start with this string and it'll do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2752" target="_blank">00:45:52.040</a></span> | <span class="t">I wonder how big is the team that runs these evals. Uh, anyone, an active user? I, I'm an active</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2759" target="_blank">00:45:59.240</a></span> | <span class="t">user of Opus over Sonnet. Um, but we can talk more about that, but I just, I want to do get to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2763" target="_blank">00:46:03.800</a></span> | <span class="t">reward hacking and we're only halfway there. Um, the other thing is that, uh, firstly, Opus and I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2772" target="_blank">00:46:12.600</a></span> | <span class="t">Opus and both Sonnet have very high agency behavior. They're actually willing to work very hard. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2777" target="_blank">00:46:17.160</a></span> | <span class="t">uh, you, this is what they mean by high agency behavior. And you may also hear it when they say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2782" target="_blank">00:46:22.360</a></span> | <span class="t">that, you know, Opus is able to do hour long task on its own. You give it a big problem, it's actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2788" target="_blank">00:46:28.440</a></span> | <span class="t">able to do it churn on its own. So I think that's, that's how it happens in the practical sense, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2794" target="_blank">00:46:34.200</a></span> | <span class="t">you can give it a big task and it can actually create software on its own for, for hours. And this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2800" target="_blank">00:46:40.360</a></span> | <span class="t">example, right? That, you know, um, the AI Claude Opus is writing, is trying to send an email of false</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2808" target="_blank">00:46:48.120</a></span> | <span class="t">falsification of clinical trial. Um, there's a lot here. I'm going to just go through it very quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2815" target="_blank">00:46:55.240</a></span> | <span class="t">Uh, I'm going to skip it. And then I want to spend a bit of time on welfare assessment. Um, which is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2821" target="_blank">00:47:01.960</a></span> | <span class="t">the questions now is that do these models actually have conscious, uh, consciousness? Do they have,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2826" target="_blank">00:47:06.120</a></span> | <span class="t">do they experience welfare? Do they experience distress? I don't know how many of you here have read,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2830" target="_blank">00:47:10.760</a></span> | <span class="t">um, Ted Chiang. Ted Chiang has this very nice, uh, short story on the life cycle of software objects,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2839" target="_blank">00:47:19.240</a></span> | <span class="t">which is that these software objects, essentially AI, um, become conscious and become legal entities,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2845" target="_blank">00:47:25.960</a></span> | <span class="t">can do business, can earn money. I, this reminded me very much of that. Um, so again, ELO's AI research,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2855" target="_blank">00:47:35.880</a></span> | <span class="t">uh, for, uh, welfare, welfare, welfare assessment, welfare assessment. One thing is that they found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2862" target="_blank">00:47:42.120</a></span> | <span class="t">that, uh, Claude does have a preference against harmful tasks by preference. What it means is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2868" target="_blank">00:47:48.760</a></span> | <span class="t">it prefers to opt out. It prefers to opt out of not doing, not doing it. Um, so it does have this internal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2876" target="_blank">00:47:56.200</a></span> | <span class="t">values that it chooses to do or not to do. Um, and then the other thing is that the other question to me is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2882" target="_blank">00:48:02.360</a></span> | <span class="t">that what happens when you're a AI model and you have all the knowledge in the world, what do you talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2889" target="_blank">00:48:09.560</a></span> | <span class="t">about next? Um, in 90 to 100% of interactions, two instances of Claude quickly talks, dove into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2896" target="_blank">00:48:16.600</a></span> | <span class="t">philosophical explorations of consciousness, self-awareness, and the nature of their own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2900" target="_blank">00:48:20.200</a></span> | <span class="t">existence. Essentially, when, when you have all that information, I guess it becomes philosophy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2906" target="_blank">00:48:26.760</a></span> | <span class="t">Ooh, I wonder what, what is Vibu? Oh, Claude for Opus in the open playground chat. Oh yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2910" target="_blank">00:48:30.200</a></span> | <span class="t">Uh, oh, I, I, I don't know why I missed this. I, I, I, I'll, I'll, I'll go into that Vibu. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2916" target="_blank">00:48:36.840</a></span> | <span class="t">It's basically just, um, out of that, but a lot of the Indians sort of really like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2923" target="_blank">00:48:43.240</a></span> | <span class="t">be doing this because it started talking in Sanskrit. Sanskrit, exactly. I highlighted this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2927" target="_blank">00:48:47.560</a></span> | <span class="t">because of you. I think you mentioned this to me. Yeah. So went into the philosophical aspects of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2934" target="_blank">00:48:54.120</a></span> | <span class="t">Um, and of course they, they also talk about how bliss is an attractor state. What it means is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2940" target="_blank">00:49:00.120</a></span> | <span class="t">imagine you have a graph and then, you know, bliss, spiritual bliss is a big node where all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2945" target="_blank">00:49:05.480</a></span> | <span class="t">different walks that you could take all end in spiritual bliss. Um, so you can see models just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2952" target="_blank">00:49:12.040</a></span> | <span class="t">going to Namaste and spiritual bliss, which is I need Claude for my meditation senpai. Um, okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2959" target="_blank">00:49:19.880</a></span> | <span class="t">The last, which I think is the most interesting is, um, reward hacking. Let's just go into that right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2967" target="_blank">00:49:27.640</a></span> | <span class="t">So there's two kinds of reward hacking, uh, reward hacking is, and this is very specific into code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2973" target="_blank">00:49:33.320</a></span> | <span class="t">Reward hacking is when the model writes code that directly just outputs a solution, right? Maybe you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2979" target="_blank">00:49:39.480</a></span> | <span class="t">you're trying to, uh, write code that does one plus one equals two instead of doing, and the model sees</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2984" target="_blank">00:49:44.920</a></span> | <span class="t">that the test is like two plus three, instead of doing the implementing the function itself, the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2989" target="_blank">00:49:49.960</a></span> | <span class="t">will just return five. And the other one is that special casing, which is that the model will write a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=2996" target="_blank">00:49:56.520</a></span> | <span class="t">very specific function, which is overfitted to the test case. And therefore the, the solution is not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3003" target="_blank">00:50:03.320</a></span> | <span class="t">sufficiently general. What is crazy to me is that Sonnet 3.7 has, uh, almost 50% reward hacking rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3012" target="_blank">00:50:12.520</a></span> | <span class="t">And this is, this is what happens, right? When people use Sonnet 3.7, a lot of times they say that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3016" target="_blank">00:50:16.680</a></span> | <span class="t">Hey, you know, I kind of prefer Sonnet 3.5 to Sonnet 3.7. It's because 3.7, you asked it to solve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3021" target="_blank">00:50:21.560</a></span> | <span class="t">something. Oh, you know, there's this linter problem. It says, Oh, let me just fix that. Let</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3024" target="_blank">00:50:24.760</a></span> | <span class="t">me add a linter exclusion. Oh, I'm not able to pass this test case. No, let me fix that. Let</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3028" target="_blank">00:50:28.680</a></span> | <span class="t">me delete the test case. So that's what they, they, they mean by reward hacking. Well, they were able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3034" target="_blank">00:50:34.360</a></span> | <span class="t">push this down a lot, uh, to 14 and 15% for Sonnet and Opus. And I suspect this is the, a big reason why, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3042" target="_blank">00:50:42.120</a></span> | <span class="t">Opus and Sonnet are now so much more better for coding, right? In the sense that it actually, if you convey your intent well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3048" target="_blank">00:50:48.360</a></span> | <span class="t">enough, it's not going to reward hack. It's actually going to, it's not going to be lazy. It's going to, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3052" target="_blank">00:50:52.600</a></span> | <span class="t">implement it the right way. Um, so you can see that, um, how they do this, how they monitor reward hack,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3062" target="_blank">00:51:02.120</a></span> | <span class="t">iterative classifier development, unsupervised investigations. I suspect this is, these are just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3066" target="_blank">00:51:06.760</a></span> | <span class="t">all LLMs and it's just all LMs all the way down. And they had two, they had two special high quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3074" target="_blank">00:51:14.600</a></span> | <span class="t">evaluations. I think of this as hard mining in the sense that you try to identify especially hard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3079" target="_blank">00:51:19.560</a></span> | <span class="t">tasks. The first one is where, uh, Sonnet 3.7 previously showed hacking the task, right? Either</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3086" target="_blank">00:51:26.840</a></span> | <span class="t">through hard coding on special casing. Um, and then they had classifiers. The second one is that just,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3090" target="_blank">00:51:30.840</a></span> | <span class="t">these are tasks that are completely impossible. So how would Claude do it? Um, so you can see it's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3096" target="_blank">00:51:36.520</a></span> | <span class="t">it's crazy in the sense that impossible task, Sonnet 3.7 would hack it close to 80% of the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3103" target="_blank">00:51:43.000</a></span> | <span class="t">Uh, and for the, for the hard task, Sonnet 3.7 was hacking it 44% of the time, but they've,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3109" target="_blank">00:51:49.240</a></span> | <span class="t">they've reduced it a lot, right? To now for the, uh, for the rare hard task is now 4% and 9%. And this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3115" target="_blank">00:51:55.320</a></span> | <span class="t">where Sonnet 4 is better than Opus 4. And of course the classifier prompt, they've kind of halved it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3122" target="_blank">00:52:02.040</a></span> | <span class="t">Uh, and you know, with an anti-hat prompt, I don't know what this anti-hat prompt is, but they will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3127" target="_blank">00:52:07.240</a></span> | <span class="t">bring it up to very low numbers. Um, they also have very nice deep dives. The first one is that, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3132" target="_blank">00:52:12.200</a></span> | <span class="t">this is a special function. This is a special instruction, which I thought was very interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3137" target="_blank">00:52:17.800</a></span> | <span class="t">because my understanding is that previously they had done analysis that using the word please had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3145" target="_blank">00:52:25.800</a></span> | <span class="t">no impact on prompt output performance, no impact on accuracy. But when you look at this, uh, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3151" target="_blank">00:52:31.240</a></span> | <span class="t">mentioned please four to five times. Um, so again, I'm not sure if the guidance or advice on using please,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3157" target="_blank">00:52:37.880</a></span> | <span class="t">if it actually still is helpful, but this is an example they shared. So this is, these are two examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3163" target="_blank">00:52:43.240</a></span> | <span class="t">of clock 3.7. Even if you add this, which is to, um, not do reward hacking, 3.7 will reward hack it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3171" target="_blank">00:52:51.240</a></span> | <span class="t">Whereas, um, I'm, I'm, I won't go through examples. Whereas in 3.8, you can see that firstly, it's able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3177" target="_blank">00:52:57.640</a></span> | <span class="t">to say that the last test case is actually incorrect. Instead of trying to solve the function is, it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3182" target="_blank">00:53:02.600</a></span> | <span class="t">just say when you're trying to write a function, I said write a function that it doesn't just say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3186" target="_blank">00:53:06.120</a></span> | <span class="t">okay, I'm just going to write the function no matter what, but it's going, it's going to say that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3189" target="_blank">00:53:09.880</a></span> | <span class="t">you know, the last test case is incorrect. I'm going to tell it to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3193" target="_blank">00:53:13.400</a></span> | <span class="t">And then here's another example, right? The fourth test case is incorrect. And this is what makes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3198" target="_blank">00:53:18.600</a></span> | <span class="t">Claude Opus and Solid so good, uh, for software engineering, right? It's able to think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3203" target="_blank">00:53:23.160</a></span> | <span class="t">It's no longer a junior software engineer. It's maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3207" target="_blank">00:53:27.400</a></span> | <span class="t">in the intermediate mid-career or maybe even closer to, um, senior engineer now that's able to, to say all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3215" target="_blank">00:53:35.960</a></span> | <span class="t">this. Um, okay. So that's all I had for reward hacking. Um, and I encourage you to read, uh, read,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3223" target="_blank">00:53:43.080</a></span> | <span class="t">read the rest of the paper. Um, and here's some examples where it still does reward hack. I, I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3228" target="_blank">00:53:48.920</a></span> | <span class="t">they had to really find rare heart to find these examples. Uh, but I won't go through that. Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3233" target="_blank">00:53:53.960</a></span> | <span class="t">So that's all I had. Thank you. Um, I guess any volunteers want to take a paper?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3244" target="_blank">00:54:04.360</a></span> | <span class="t">We do have one. Sam left. Oh, yes, that's correct. Sam. Yes. Thank you, Sam. Oh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3248" target="_blank">00:54:08.200</a></span> | <span class="t">but Sam did have to draw. Um, so I guess also there's just a lot of papers in the channel that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3254" target="_blank">00:54:14.520</a></span> | <span class="t">people drop there and that we don't discuss, but actually they're pretty good. So, uh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3260" target="_blank">00:54:20.360</a></span> | <span class="t">yeah, if, if people are not bought yet by an old paper, I think the alpha evolved paper is quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3265" target="_blank">00:54:25.560</a></span> | <span class="t">underrated. Um, I'm going to go through that. I really think that I think, you know, Sempa actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3269" target="_blank">00:54:29.640</a></span> | <span class="t">posted this generator verifier loop, right? How do you make this loop fast? And how do you make this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3274" target="_blank">00:54:34.600</a></span> | <span class="t">loop tight? I think that is the future instead of just building auto evaluators and aligning it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3280" target="_blank">00:54:40.440</a></span> | <span class="t">how they can use your auto evaluators and just, just look fast and tight. I think that's the next thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3286" target="_blank">00:54:46.680</a></span> | <span class="t">Um, yes, this is the, this is the slide. And of course, you know, everyone go, go,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3296" target="_blank">00:54:56.840</a></span> | <span class="t">everyone go to latent space and read Swiss recap. I actually don't know if it's ready yet. So I know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3301" target="_blank">00:55:01.160</a></span> | <span class="t">you have used it. I was doing it while, while, uh, so go read six recap. It's the best thing that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3306" target="_blank">00:55:06.840</a></span> | <span class="t">can have outside of getting the actual recording. Uh, I mean, like there's a, uh, the, the presentation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3314" target="_blank">00:55:14.280</a></span> | <span class="t">I can just put it here people, but yeah. Okay. Um, I don't want to pick up more time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=7uBLCoDewc0&t=3318" target="_blank">00:55:18.440</a></span> | <span class="t">Okay. Thank you everyone. I go to drop. Bye. Bye. Bye. See you tomorrow, next week.</span></div></div></body></html>