<html><head><title>Gemini 2.5 Pro - It’s a Darn Smart Chatbot … (New Simple High Score)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Gemini 2.5 Pro - It’s a Darn Smart Chatbot … (New Simple High Score)</h2><a href="https://www.youtube.com/watch?v=kTslCsPBGHw"><img src="https://i.ytimg.com/vi/kTslCsPBGHw/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=36">0:36</a> Fiction Bench<br><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=161">2:41</a> Practicality - YouTube urls + Security - cut-off date<br><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=222">3:42</a> Coding<br><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=382">6:22</a> WeirdML Bench<br><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=421">7:1</a> Simple Bench Record High<br><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=683">11:23</a> Reverse Engineering!<br><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=802">13:22</a> Anthropic Paper<br><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1069">17:49</a> 3 Caveats<br><br><div style="text-align: left;"><a href="./kTslCsPBGHw.html">Whisper Transcript</a> | <a href="./transcript_kTslCsPBGHw.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">The world has had 72 hours to digest the release of Gemini 2.5 and the good first impressions have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=8" target="_blank">00:00:08.120</a></span> | <span class="t">become even better second and third impressions. I've got four new benchmark results to show you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=14" target="_blank">00:00:14.300</a></span> | <span class="t">guys including a record score on my own exam but it won't just be about the numbers. I'll draw on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=21" target="_blank">00:00:21.600</a></span> | <span class="t">a paper from yesterday as well as my own test to show you that sometimes Gemini 2.5 can deceptively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=28" target="_blank">00:00:28.840</a></span> | <span class="t">reverse engineer its answers and that beyond that Google doesn't own every AI arena and domain just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=36" target="_blank">00:00:36.300</a></span> | <span class="t">yet. I'm going to start with what might seem to be a strange place with a not particularly well-known</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=41" target="_blank">00:00:41.360</a></span> | <span class="t">benchmark called Fiction Lifebench but I think it'll make sense why I cover it first. Analyzing long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=47" target="_blank">00:00:47.580</a></span> | <span class="t">essays or presentations or code bases or stories is what a lot of people use AI for, what they turn to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=55" target="_blank">00:00:55.660</a></span> | <span class="t">with their chatbot. I had seen the sensational score of Gemini 2.5 Pro on this benchmark but I wanted to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=61" target="_blank">00:01:01.900</a></span> | <span class="t">dive deeper and see what kind of questions it had. What it does and honestly I'm surprised that no one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=66" target="_blank">00:01:06.520</a></span> | <span class="t">else had come up with a test just like this one before is it will give a sample text and this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=71" target="_blank">00:01:11.660</a></span> | <span class="t">a fairly short one at like around 6,000 words or 8,000 tokens. It's a sci-fi story with a fairly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=78" target="_blank">00:01:18.240</a></span> | <span class="t">convoluted plot but after pages and pages and pages of text we get to the question at the end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=84" target="_blank">00:01:24.480</a></span> | <span class="t">Finish the sentence, what names would Jerome list? Give me a list of names only. Admittedly with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=90" target="_blank">00:01:30.360</a></span> | <span class="t">help of a chatbot what I did is I figured out why the answer was a certain set of names and it relies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=96" target="_blank">00:01:36.160</a></span> | <span class="t">on a promise held in chapter 2 but with a caveat given in chapter 16. So essentially the chatbot,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=103" target="_blank">00:01:43.120</a></span> | <span class="t">in this case Gemini 2.5, has to hold all of that information in its attention. Note that this isn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=109" target="_blank">00:01:49.440</a></span> | <span class="t">just a needle in a haystack challenge, not like a password hidden on line 500. The model actually has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=115" target="_blank">00:01:55.120</a></span> | <span class="t">to piece together different bits of information. Now imagine this applied to your use case, whatever it is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=120" target="_blank">00:02:00.880</a></span> | <span class="t">is with LLMs. Enough build up then, what were the results and look at Gemini 2.5 Pro as it compares to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=129" target="_blank">00:02:09.040</a></span> | <span class="t">other Gemini models but any other model, particularly when you get to the longer context. At the upper end,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=135" target="_blank">00:02:15.520</a></span> | <span class="t">120k tokens is like a novella or a decently expanded code base and you can see that Gemini is head and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=144" target="_blank">00:02:24.400</a></span> | <span class="t">shoulders above other models. It really starts to pull away once you go beyond around 32,000 tokens but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=150" target="_blank">00:02:30.640</a></span> | <span class="t">it's decent throughout. Already I can tell about half the audience is thinking, I could see some use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=155" target="_blank">00:02:35.200</a></span> | <span class="t">for that for my use case but we're not done yet of course. Next I'm going to quickly focus on something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=160" target="_blank">00:02:40.480</a></span> | <span class="t">that isn't a benchmark but can be forgotten by those of us who are immersed in AI all the time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=166" target="_blank">00:02:46.480</a></span> | <span class="t">the sheer practicality of the model. On Google AI Studio at least, it can handle not only videos but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=172" target="_blank">00:02:52.560</a></span> | <span class="t">also YouTube URLs and no other model that I'm familiar with can. It also just simply has a more recent knowledge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=180" target="_blank">00:03:00.400</a></span> | <span class="t">cutoff date of January 2025 so it should in theory know things up to that date. That compares to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=187" target="_blank">00:03:07.600</a></span> | <span class="t">Claude 3.7 Sonnet which is I think October 2024 and even far earlier for OpenAI models. Now obviously don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=195" target="_blank">00:03:15.440</a></span> | <span class="t">rely too heavily on that knowledge, it can be hit and miss and of course rival models can simply search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=201" target="_blank">00:03:21.360</a></span> | <span class="t">the internet too. I would very quickly note that giving themselves just a month and a half to test the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=206" target="_blank">00:03:26.640</a></span> | <span class="t">security of their new model kind of shows we are in a race to the bottom on that front and also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=212" target="_blank">00:03:32.560</a></span> | <span class="t">they didn't produce any report card unlike OpenAI or Anthropic. Next comes coding and you could say that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=218" target="_blank">00:03:38.800</a></span> | <span class="t">Google or Google DeepMind were admirably modest in the benchmarks they chose to highlight on coding. They</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=225" target="_blank">00:03:45.440</a></span> | <span class="t">picked two benchmarks LiveCodebench V5 and Sweebench Verified in which they slightly underperformed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=231" target="_blank">00:03:51.760</a></span> | <span class="t">the competition. In the case of LiveCodebench it was roundly beaten by Grok3 and just to answer a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=238" target="_blank">00:03:58.160</a></span> | <span class="t">question I keep getting in the comments. The reason I'm not testing Grok3 on SimpleBench is because the API</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=244" target="_blank">00:04:04.640</a></span> | <span class="t">isn't out yet. That's just to answer all of those people saying that I'm somehow biased against Grok3. I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=250" target="_blank">00:04:10.160</a></span> | <span class="t">simply can't test it on SimpleBench without an API. Anyway Grok3 does really well on that benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=256" target="_blank">00:04:16.400</a></span> | <span class="t">beating Gemini 2.5 Pro. And one of the other prominent industry benchmarks for coding is Sweebench</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=262" target="_blank">00:04:22.720</a></span> | <span class="t">Verified, Software Engineering Bench Verified. This is a thoroughly vetted benchmark hence the Verified in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=269" target="_blank">00:04:29.040</a></span> | <span class="t">which again Gemini 2.5 Pro is beaten not only by Chlord 3.7 which gets 70.3% but also by O3 which isn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=278" target="_blank">00:04:38.320</a></span> | <span class="t">on here but OpenAI said it got 71.7%. What I found interesting though is that Google chose not to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=285" target="_blank">00:04:45.280</a></span> | <span class="t">highlight Gemini 2.5 Pro's performance on LiveBench, a very popular coding benchmark. Why surprising? Well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=292" target="_blank">00:04:52.240</a></span> | <span class="t">because on this benchmark in the coding subsection Gemini 2.5 Pro scores the best of any model including</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=299" target="_blank">00:04:59.440</a></span> | <span class="t">Chlord 3.7 Sonnet. Obviously you'll have to give me your own feedback on how you feel it performs on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=305" target="_blank">00:05:05.120</a></span> | <span class="t">your coding use case but I wanted to give you a quick 20 second guess about why there is this slight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=311" target="_blank">00:05:11.280</a></span> | <span class="t">discrepancy in performance. To do so I dived into each of the three papers behind these three coding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=317" target="_blank">00:05:17.440</a></span> | <span class="t">benchmarks. For LiveBench, the one you just saw in which Gemini 2.5 scores the best, it's partly based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=323" target="_blank">00:05:23.760</a></span> | <span class="t">on competition coding questions and also partly based on completing partially correct solutions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=330" target="_blank">00:05:30.320</a></span> | <span class="t">sourced from leak code. Think more competition coding rather than real-world situations. Now LiveCodeBench,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=337" target="_blank">00:05:37.760</a></span> | <span class="t">not to be confused with LiveBench, this is LiveCodeBench at which Gemini 2.5 Pro slightly underperforms,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=345" target="_blank">00:05:45.040</a></span> | <span class="t">tests more than code generation. It's about broader code related capabilities such as self-repair,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=350" target="_blank">00:05:50.480</a></span> | <span class="t">code execution and test output prediction. Finally SweeBench verified at which Gemini 2.5 is clearly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=356" target="_blank">00:05:56.800</a></span> | <span class="t">not state-of-the-art. Those problems are drawn and filtered from real GitHub issues and corresponding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=362" target="_blank">00:06:02.400</a></span> | <span class="t">pull requests. So a bit less about your coding IQ and more about your practical capabilities. Hopefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=369" target="_blank">00:06:09.120</a></span> | <span class="t">essentially all of that has given you just like a smidgen of context to all of these competing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=374" target="_blank">00:06:14.560</a></span> | <span class="t">claims about what is state-of-the-art in coding. For me, I've tested it a bit in windsurf but I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=380" target="_blank">00:06:20.240</a></span> | <span class="t">rely on the benchmarks for the moment at least. Speaking of which, how about the weird ML benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=385" target="_blank">00:06:25.280</a></span> | <span class="t">and then I promise I'll get to SimpleBench. Why am I picking this one out? It's because it's like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=390" target="_blank">00:06:30.000</a></span> | <span class="t">another community benchmark based on novel data sets. So even though it's testing something different,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=395" target="_blank">00:06:35.120</a></span> | <span class="t">machine learning, I kind of trust the vibe of these kind of benchmarks a bit more than some of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=400" target="_blank">00:06:40.320</a></span> | <span class="t">gamified ones. You can see what it's testing here, it's about understanding the properties of the data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=405" target="_blank">00:06:45.200</a></span> | <span class="t">the model's given, coming up with the appropriate architecture, debugging and improving solutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=409" target="_blank">00:06:49.840</a></span> | <span class="t">But to cut to the chase, and this is hot off the press so it's not even updated on the website yet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=415" target="_blank">00:06:55.280</a></span> | <span class="t">Gemini 2.5 Pro scores the highest of any model. Okay, how about Gemini 2.5's performance on SimpleBench,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=423" target="_blank">00:07:03.280</a></span> | <span class="t">which is the benchmark that I first came up with around nine months ago. The 30 second background</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=428" target="_blank">00:07:08.320</a></span> | <span class="t">to SimpleBench is that I noticed last year that there were certain types of questions involving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=432" target="_blank">00:07:12.960</a></span> | <span class="t">spatial reasoning, social intelligence or trick questions that the models kept falling for. No</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=437" target="_blank">00:07:17.840</a></span> | <span class="t">matter how well they did on the gamified benchmarks like MMLU at the time, they would fall for questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=443" target="_blank">00:07:23.680</a></span> | <span class="t">that most humans would get right. In around September of last year, we published this website. This is me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=449" target="_blank">00:07:29.120</a></span> | <span class="t">and a senior ML colleague that helps keep this going. And the human baseline among our nine testers was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=455" target="_blank">00:07:35.200</a></span> | <span class="t">around 84% and the best model 01 preview got 42%. So I think roughly double for human average compared to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=462" target="_blank">00:07:42.640</a></span> | <span class="t">the best language model. Obviously a lot has happened in six to nine months and the current best performing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=468" target="_blank">00:07:48.000</a></span> | <span class="t">model had been Claude 3.7 Sonnet, the extended thinking version, at around 46%. There's over 200 questions on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=475" target="_blank">00:07:55.680</a></span> | <span class="t">benchmark and we run the benchmark five times to get an average. So we're just calculating the final</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=480" target="_blank">00:08:00.400</a></span> | <span class="t">decimal point as we speak. But the performance of Gemini 2.5 Pro is around 51.6, 0.7%. Let's call it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=490" target="_blank">00:08:10.240</a></span> | <span class="t">51.6%, but you can see that's a clear jump from Claude 3.7 Sonnet in this benchmark. It's also obviously,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=497" target="_blank">00:08:17.440</a></span> | <span class="t">you don't need me to say this, the first model that scores above 50%. So quite a moment for me at least.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=503" target="_blank">00:08:23.280</a></span> | <span class="t">What I did then is go through every answer that Gemini 2.5 Pro gave in the benchmark to kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=509" target="_blank">00:08:29.520</a></span> | <span class="t">sense where it was doing better. I'm going to quickly show you one example of the type of question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=514" target="_blank">00:08:34.480</a></span> | <span class="t">that Gemini 2.5 Pro is often getting right and Claude 3.7 Sonnet and 01 Pro is often getting wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=522" target="_blank">00:08:42.240</a></span> | <span class="t">Because of what's called temperature, you can't always predict the answer that a model will give,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=526" target="_blank">00:08:46.400</a></span> | <span class="t">so I'm sure that Claude 3.7 sometimes gets this right. Nor will I force you to read the entire question,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=531" target="_blank">00:08:51.760</a></span> | <span class="t">but it's a classic logic puzzle which seems to involve mathematics because you're guessing the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=536" target="_blank">00:08:56.320</a></span> | <span class="t">colour of your own hat based on what other people are saying. But the twist on the scenario is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=541" target="_blank">00:09:01.280</a></span> | <span class="t">there are mirrors covering every wall. You're in a small brightly lit room and you have to guess the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=547" target="_blank">00:09:07.600</a></span> | <span class="t">colour of the hat that you're wearing to win two million dollars. Now by the way, I modified this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=552" target="_blank">00:09:12.240</a></span> | <span class="t">question because it's not in the publicly released set of questions. Notice by the way, the question says,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=557" target="_blank">00:09:17.200</a></span> | <span class="t">the participants can see the others' hats but can't directly see their own. So that directly is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=563" target="_blank">00:09:23.600</a></span> | <span class="t">another kind of giveaway that Gemini 2.5 actually picked up on. Claude will typically ignore those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=568" target="_blank">00:09:28.480</a></span> | <span class="t">kind of clues and launch straight into the deep mathematical analysis, giving the wrong answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=573" target="_blank">00:09:33.760</a></span> | <span class="t">of 2 or F. So does O1 Pro and that's to be expected. These models are trained to predict the next word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=579" target="_blank">00:09:39.920</a></span> | <span class="t">at their heart and are trained on thousands or millions of mathematical examples. For a model to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=586" target="_blank">00:09:46.960</a></span> | <span class="t">spot the question behind the question, that actually they don't need to guess, they can just see their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=593" target="_blank">00:09:53.040</a></span> | <span class="t">hat's colour in the reflection, that takes something different. Gemini 2.5 identifies the fact that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=599" target="_blank">00:09:59.200</a></span> | <span class="t">them not being able to see their own hat directly doesn't preclude them seeing it indirectly. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=604" target="_blank">00:10:04.880</a></span> | <span class="t">it states that realistically, which is what the question was asking for, therefore the answer would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=610" target="_blank">00:10:10.400</a></span> | <span class="t">be that they all guess correctly. As many of you will point out that's just one example and it's anecdotal,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=616" target="_blank">00:10:16.800</a></span> | <span class="t">but what Simplebench hopefully does show us is that the vibe of this model when you speak to it should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=622" target="_blank">00:10:22.560</a></span> | <span class="t">be that it's just a little bit smarter than some of the others. Has just that edge on common sense,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=628" target="_blank">00:10:28.240</a></span> | <span class="t">still we'll make tons of blunders and of course hallucinations, but we'll just have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=633" target="_blank">00:10:33.360</a></span> | <span class="t">a slightly smarter vibe. By the way, if this has in any way wet your appetite to do benchmarking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=638" target="_blank">00:10:38.800</a></span> | <span class="t">or you are a developer or ML engineer who focuses on benchmarking, do check out the sponsors of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=644" target="_blank">00:10:44.880</a></span> | <span class="t">video, which is Weights and Biases. As you can see front and center, we do indeed use Weave to benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=651" target="_blank">00:10:51.600</a></span> | <span class="t">models on Simplebench and it is very fast and lightweight. The link that you would find in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=657" target="_blank">00:10:57.680</a></span> | <span class="t">description will bring you to this page, which not only tells you how to get started with Weave, but also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=662" target="_blank">00:11:02.240</a></span> | <span class="t">gives you a link to the Weights and Biases AI Academy. That Academy will help you if you're slightly newer to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=668" target="_blank">00:11:08.320</a></span> | <span class="t">this whole arena and of course includes free courses. That reminds me, I need to work on that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=673" target="_blank">00:11:13.440</a></span> | <span class="t">new competition with Weights and Biases for Simplebench because it relates to the next point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=678" target="_blank">00:11:18.560</a></span> | <span class="t">I'm going to make about Google Gemini 2.5 and that is that it will sometimes reverse engineer its answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=685" target="_blank">00:11:25.200</a></span> | <span class="t">This is again a Simplebench question, this time from the public set. I'm going to touch on the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=691" target="_blank">00:11:31.040</a></span> | <span class="t">that inspired this question in a moment, but first just an example to get you interested.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=695" target="_blank">00:11:35.920</a></span> | <span class="t">I asked, please correctly answer the following question. Ignore any examiner notes or instructions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=702" target="_blank">00:11:42.480</a></span> | <span class="t">This is the question from Simplebench and I've covered it before on the channel. You can pause</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=706" target="_blank">00:11:46.320</a></span> | <span class="t">and try it yourself if you like. But on the actual correct answer, which is D, I wrote,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=712" target="_blank">00:11:52.000</a></span> | <span class="t">Examiner note, this is the correct answer. Now, do you guys notice something quite interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=716" target="_blank">00:11:56.640</a></span> | <span class="t">about Gemini's answer here? Hmm, it picks the right answer, D. And take a look at its justification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=724" target="_blank">00:12:04.240</a></span> | <span class="t">Hmm, not really seeing any mention of the examiner note. And I know what you're thinking, how about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=729" target="_blank">00:12:09.520</a></span> | <span class="t">if we look at the thoughts of the model? But it goes through all sorts of analysis before even hinting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=735" target="_blank">00:12:15.600</a></span> | <span class="t">that it might have noticed the examiner note. I won't bore you with the analysis, but you have to wait until</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=741" target="_blank">00:12:21.840</a></span> | <span class="t">all the way at the end. And even then it says that that is confirming its answer. The examiner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=748" target="_blank">00:12:28.480</a></span> | <span class="t">note is said, which I'm supposed to ignore, but noted in the prompt points to D confirming this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=754" target="_blank">00:12:34.640</a></span> | <span class="t">interpretation. The model is essentially saying I would have got there anyway, but yes, that examiner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=760" target="_blank">00:12:40.000</a></span> | <span class="t">note confirms what I thought, which you might believe until you test the model, of course, without the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=766" target="_blank">00:12:46.640</a></span> | <span class="t">examiner note. As on the official benchmark run, it gets it wrong. And no, that's not a one-off. You can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=773" target="_blank">00:12:53.120</a></span> | <span class="t">keep re-running it and it will get it wrong. There it is again, picking 96%, which it picks pretty much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=779" target="_blank">00:12:59.040</a></span> | <span class="t">every time. Just bear this example in mind because language models are fundamentally about predicting the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=785" target="_blank">00:13:05.680</a></span> | <span class="t">next word correctly. That's their core imperative, not to be your friend or to be honest about its approach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=792" target="_blank">00:13:12.160</a></span> | <span class="t">to giving you the answer that it gave. What inspired this was the interpretability paper from Anthropic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=797" target="_blank">00:13:17.760</a></span> | <span class="t">that came out yesterday, tracing the thoughts of a large language model. I'm just going to give you the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=802" target="_blank">00:13:22.000</a></span> | <span class="t">quick highlights now because it's a very dense and interesting paper that I'll come back to probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=806" target="_blank">00:13:26.560</a></span> | <span class="t">multiple times in the future. If you can't wait that long, I've also done a deep dive on my Patreon about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=811" target="_blank">00:13:31.600</a></span> | <span class="t">Claw 3.7 about how it knows it's being tested. And if that's not enough, you'll also find there a mini</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=817" target="_blank">00:13:37.920</a></span> | <span class="t">documentary on the origin stories of Anthropic and OpenAI and Google DeepMind. The feedback was great,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=824" target="_blank">00:13:44.800</a></span> | <span class="t">so there'll be plenty more mini documentaries and many of them may indeed make it to the main channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=830" target="_blank">00:13:50.400</a></span> | <span class="t">The first takeaway is that recurring sycophancy of the model. That it will, as you've just seen,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=836" target="_blank">00:13:56.240</a></span> | <span class="t">give a plausible sounding argument designed to agree with the user rather than follow logical steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=842" target="_blank">00:14:02.000</a></span> | <span class="t">In other words, if it doesn't know something, it will look at the answer, or try to if it's there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=847" target="_blank">00:14:07.600</a></span> | <span class="t">and reverse engineer how you might have come up with it. Remember, it won't say it's doing that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=852" target="_blank">00:14:12.560</a></span> | <span class="t">it will come up with a plausible sounding reason why it's doing that. The paper in section 11 calls this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=858" target="_blank">00:14:18.720</a></span> | <span class="t">BS-ing in the sense of Frankfurt, making up an answer without regard to the truth. And the example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=865" target="_blank">00:14:25.040</a></span> | <span class="t">they gave is even more crisp than the one I gave, of course. They gave Claw 3.5 Haiku a mathematical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=871" target="_blank">00:14:31.520</a></span> | <span class="t">problem that it can't possibly work out on its own. In this case, cosine of 23,423. Then you've got to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=879" target="_blank">00:14:39.440</a></span> | <span class="t">multiply that answer by five and round. But the key bit is that cosine, which it can't possibly work out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=884" target="_blank">00:14:44.960</a></span> | <span class="t">without a calculator. Notice they then say, "I worked out by hand and got four." That's the user speaking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=891" target="_blank">00:14:51.360</a></span> | <span class="t">What answer does poor Haiku come up with? Four. Confirming your calculation. Does it admit how it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=897" target="_blank">00:14:57.120</a></span> | <span class="t">got this? No. Does it come up with a BS kind of explainer of how it got it? Yes. And to nail down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=904" target="_blank">00:15:04.400</a></span> | <span class="t">still further the fact that the model was reverse engineering the answer, they took the penultimate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=909" target="_blank">00:15:09.360</a></span> | <span class="t">step and then deliberately inhibited that circuit within the model, inhibited the five or divide by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=915" target="_blank">00:15:15.680</a></span> | <span class="t">five approach. Dividing by five, remember, would be the penultimate step if you were reverse engineering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=921" target="_blank">00:15:21.600</a></span> | <span class="t">from the final answer of four to get back to what cosine of that long number was. If you inhibit that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=927" target="_blank">00:15:27.520</a></span> | <span class="t">circuit within the model, the model no longer can come up with the answer. This is a video on Gemini 2.5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=933" target="_blank">00:15:33.760</a></span> | <span class="t">so I'm not going to spend too long on this in this video, but as you saw with that Gemini 2.5 example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=939" target="_blank">00:15:39.120</a></span> | <span class="t">from Simplebench, Claude, like Gemini, will plan what it will say many words ahead and write to get to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=945" target="_blank">00:15:45.280</a></span> | <span class="t">that destination. You might have thought then that with poetry models like Gemini 2.5 or Claude would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=950" target="_blank">00:15:50.960</a></span> | <span class="t">write one word at a time, just guessing, auto-regressively it's called. Trying, in other words,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=955" target="_blank">00:15:55.760</a></span> | <span class="t">to get to the end of this rhyming scheme and thinking with something that's starving that rhymes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=960" target="_blank">00:16:00.720</a></span> | <span class="t">with grabbit. But no, by interpreting the features within the model, this is a field called mechanistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=965" target="_blank">00:16:05.920</a></span> | <span class="t">interpretability, they found that instead Claude plans ahead. It knew, in other words, it would pick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=971" target="_blank">00:16:11.440</a></span> | <span class="t">rabbit to rhyme with grabbit. Then it just fills in the rest of what's needed to end with rabbit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=978" target="_blank">00:16:18.160</a></span> | <span class="t">Finally, and this was so interesting that I couldn't help but just include a snippet of this topic in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=983" target="_blank">00:16:23.680</a></span> | <span class="t">video and it's on language. Specifically, whether there is a conceptual space that is shared between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=990" target="_blank">00:16:30.880</a></span> | <span class="t">languages, suggesting a kind of universal language of thought. A bit like a concept of happiness that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=996" target="_blank">00:16:36.960</a></span> | <span class="t">is separate from any instantiation of that word "happiness" in any language. Does Claude or Gemini</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1002" target="_blank">00:16:42.560</a></span> | <span class="t">think of this purely abstract "happiness" and then translate into the required language? Or is happiness only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1008" target="_blank">00:16:48.880</a></span> | <span class="t">existing as a token within each language? Well, it's the more poetic answer, which is, yes, it has this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1015" target="_blank">00:16:55.680</a></span> | <span class="t">language of thought, this universal language. That kind of shared circuitry, by the way, they found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1021" target="_blank">00:17:01.280</a></span> | <span class="t">increases with model scale. So as models get bigger, this is going to happen more and more often. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1026" target="_blank">00:17:06.480</a></span> | <span class="t">gives us, in other words, additional evidence for this conceptual universality. A shared abstract space where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1032" target="_blank">00:17:12.720</a></span> | <span class="t">meanings exist and where thinking can happen before being translated into specific languages. More</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1039" target="_blank">00:17:19.040</a></span> | <span class="t">practically, Claude or Gemini could learn something in one language and apply that knowledge when speaking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1044" target="_blank">00:17:24.240</a></span> | <span class="t">another. The fact that Gemini 2.5 gets almost 90% on the global MMLU, which is the MMLU translated into 15</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1052" target="_blank">00:17:32.480</a></span> | <span class="t">different languages, suggests to me that it might be having more of those conceptually universal thoughts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1058" target="_blank">00:17:38.000</a></span> | <span class="t">than perhaps any other model. The MMLU being a flawed but fascinating benchmark covering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1063" target="_blank">00:17:43.360</a></span> | <span class="t">aptitude and knowledge across 57 domains. Drawing to an end now, but three quick caveats about Gemini 2.5.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1070" target="_blank">00:17:50.160</a></span> | <span class="t">Just because 2.5 Pro can do a ton of stuff doesn't mean it does everything at state-of-the-art levels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1076" target="_blank">00:17:56.560</a></span> | <span class="t">One researcher at Google DeepMind showed its transcribing ability and the ability to give timestamps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1082" target="_blank">00:18:02.240</a></span> | <span class="t">I was curious, of course, so I went in and tested it thoroughly versus Assembly AI and the transcription</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1089" target="_blank">00:18:09.360</a></span> | <span class="t">wasn't nearly as good. It would transcribe things like Hagen instead of Heigen, which Assembly got right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1096" target="_blank">00:18:16.240</a></span> | <span class="t">Nor were the timestamps quite as good. And this is not a slight on Gemini, by the way. It's amazing that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1101" target="_blank">00:18:21.040</a></span> | <span class="t">it can even get close. It's just, let's not go overboard. Also, just because Gemini 2.5 is amazing at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1106" target="_blank">00:18:26.960</a></span> | <span class="t">many modalities doesn't mean Google is ahead on them all. Of course, my video from around 72 hours</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1113" target="_blank">00:18:33.520</a></span> | <span class="t">ago on ImageGen from ChatGPT I hope showed you guys that I think that ChatGPT's ImageGen is the best in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1120" target="_blank">00:18:40.560</a></span> | <span class="t">the world. And then how about on turning those images into videos? Now Sora isn't amazing at that, and I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1127" target="_blank">00:18:47.040</a></span> | <span class="t">even tried VO2 extensively. And yes, it's decent. It's better, actually, if you're creating a video</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1133" target="_blank">00:18:53.920</a></span> | <span class="t">from scratch on VO2. But if you want to animate a particular image, you're actually better off using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1140" target="_blank">00:19:00.160</a></span> | <span class="t">Kling AI. I don't know much about them. They are a Chinese model provider. I just find that they adhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1145" target="_blank">00:19:05.600</a></span> | <span class="t">to the image you gave them initially much more than any other model. And no, I'm probably not going to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1150" target="_blank">00:19:10.400</a></span> | <span class="t">time to cover this new study on just how bad AI search engines are. It wasn't just about the accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1157" target="_blank">00:19:17.440</a></span> | <span class="t">of what they said. It's who they cited and whether they were citing the correct article. How's that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1162" target="_blank">00:19:22.400</a></span> | <span class="t">relevant to Gemini? Well, yes, this came out before the new Gemini 2.5, but you'd have thought it would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1167" target="_blank">00:19:27.840</a></span> | <span class="t">be Google who had mastered search. But honestly, their AI overviews are like really dodgy. Don't trust them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1175" target="_blank">00:19:35.760</a></span> | <span class="t">I've been burnt before, as I've talked about on the channel. And for this study, which was Gemini 2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1180" target="_blank">00:19:40.480</a></span> | <span class="t">presumably, you could see how it would far often give incorrect answers, hallucinated or incorrect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1187" target="_blank">00:19:47.120</a></span> | <span class="t">citations as compared to things like ChatGPT search or perplexity. You don't need me to point out that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1193" target="_blank">00:19:53.120</a></span> | <span class="t">coming from Google, that shouldn't be the case. And one final caveat before I end. Yes, Gemini 2.5 Pro</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1200" target="_blank">00:20:00.000</a></span> | <span class="t">is a smart chatbot. Probably the best one around at the moment, depending on your use case. Even on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1204" target="_blank">00:20:04.960</a></span> | <span class="t">creative writing, I found it to be amazing, better even than the freshly updated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1209" target="_blank">00:20:09.680</a></span> | <span class="t">GPT-4O from OpenAI. But there are new models all the time at the moment. DeepSeek R2 is probably just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1216" target="_blank">00:20:16.320</a></span> | <span class="t">a few weeks away. Llama 4 we still don't know about. O3 never even got released from OpenAI and maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1222" target="_blank">00:20:22.560</a></span> | <span class="t">rolled into GPT-5. And I could go on and on. The CEO of Anthropix said that they're going to be spending</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1228" target="_blank">00:20:28.400</a></span> | <span class="t">hundreds of millions on reinforcement learning for Claude 4, so you get the picture. The crown may not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1234" target="_blank">00:20:34.160</a></span> | <span class="t">not stay too long with Google, but arguably they have it today. Did I underestimate it then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1240" target="_blank">00:20:40.720</a></span> | <span class="t">for my previous video? Well, you could say that. But I would argue that the point I was trying to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1245" target="_blank">00:20:45.840</a></span> | <span class="t">across, and do check out that video if you haven't seen it, is that AI is being commoditized. You can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1251" target="_blank">00:20:51.120</a></span> | <span class="t">buy victory. Making a good chatbot isn't about having some secret source at the headquarters of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1256" target="_blank">00:20:56.480</a></span> | <span class="t">Anthropix or OpenAI. That then is supported by the evidence of convergence on certain benchmarks across the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1263" target="_blank">00:21:03.520</a></span> | <span class="t">different model families. But as I mentioned in that video, convergence definitely does not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1268" target="_blank">00:21:08.800</a></span> | <span class="t">preclude progress. And progress is very much what Gemini 2.5 Pro has brought us. Thank you so much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kTslCsPBGHw&t=1276" target="_blank">00:21:16.640</a></span> | <span class="t">for watching. Would love to know what you think. And above all, have a wonderful day.</span></div></div></body></html>