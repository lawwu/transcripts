<html><head><title>DeepSeek DeepDive (R1, V3, Math, GRPO)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>DeepSeek DeepDive (R1, V3, Math, GRPO)</h2><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ"><img src="https://i.ytimg.com/vi_webp/YF7Xk48VfzQ/maxresdefault.webp" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./YF7Xk48VfzQ.html">Whisper Transcript</a> | <a href="./transcript_YF7Xk48VfzQ.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Cool. I will kick off by straight disagreeing with Sean there. V3 not required reading for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=9" target="_blank">00:00:09.920</a></span> | <span class="t">R1. V3 is just model. It's like any other model. You know, all the models you just train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=14" target="_blank">00:00:14.780</a></span> | <span class="t">on Next Token, it's a Next Token model. It's a good model, but up until 15 minutes ago</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=20" target="_blank">00:00:20.740</a></span> | <span class="t">I forgot about the slides for V3. So, you know, that's how useless it is. But anyway,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=27" target="_blank">00:00:27.980</a></span> | <span class="t">high level. I'm just going to go through more applicable parts of paper. Like, why do we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=32" target="_blank">00:00:32.680</a></span> | <span class="t">care? If anyone has questions, comments, thoughts, interrupt me. It's more discussion than it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=38" target="_blank">00:00:38.740</a></span> | <span class="t">is me yapping, you know. If you want yapping, go read the paper. So, outline, high level,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=45" target="_blank">00:00:45.180</a></span> | <span class="t">high level. So, let's talk about the two models, mostly the second model. What is inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=50" target="_blank">00:00:50.620</a></span> | <span class="t">time scaling? What's this test time compute? They talk about what previous approaches are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=55" target="_blank">00:00:55.260</a></span> | <span class="t">so we'll kind of discuss that a little bit. Also, if people are talking in chat, I'm not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=59" target="_blank">00:00:59.820</a></span> | <span class="t">super seeing it. If anything's, like, important. We're just talking about V3 and ignoring you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=64" target="_blank">00:01:04.920</a></span> | <span class="t">Okay, okay. Gross, V3. We had a slide, don't worry. So, then we'll talk about R1-0. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=74" target="_blank">00:01:14.000</a></span> | <span class="t">DeepSeek R1 is not really just one model. There's two models. There's DeepSeek R1-0</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=79" target="_blank">00:01:19.180</a></span> | <span class="t">and then there's DeepSeek R1. They actually put out both. They're both pretty good. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=84" target="_blank">00:01:24.100</a></span> | <span class="t">a different approach to how they did both, but yeah, kind of what they are, the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=89" target="_blank">00:01:29.100</a></span> | <span class="t">template, reward models, how they determine all this emergence, reflection, aha moments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=95" target="_blank">00:01:35.300</a></span> | <span class="t">And then we'll talk about what R1 really is. R1 is taking a reasoning model and then turning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=99" target="_blank">00:01:39.880</a></span> | <span class="t">into a chat model again. So, now we've got more than just a base model and chat model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=105" target="_blank">00:01:45.620</a></span> | <span class="t">Now we have base model, reasoning model that's not a good chat model, and then reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=110" target="_blank">00:01:50.500</a></span> | <span class="t">models that can chat again. Most of this paper and most of the slides are actually on R1-0.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=115" target="_blank">00:01:55.140</a></span> | <span class="t">It's a very interesting one. Apparently, an hour ago, the ARC benchmark guys, they put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=122" target="_blank">00:02:02.660</a></span> | <span class="t">out news that R1-0 is better than R1. So, it's better on some stuff. You know, you take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=129" target="_blank">00:02:09.580</a></span> | <span class="t">smart model, you make a chat model, it's going to become dumber. People are dumb. We like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=133" target="_blank">00:02:13.020</a></span> | <span class="t">to chat. Then we'll talk about performance evals. Then a really cool thing they did with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=138" target="_blank">00:02:18.180</a></span> | <span class="t">distillation. So, they distilled LAMA-3 and QEN models into R1 models. And they just kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=146" target="_blank">00:02:26.260</a></span> | <span class="t">of, you know, we're going to drop this real quick. They broke the US economy. They're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=150" target="_blank">00:02:30.020</a></span> | <span class="t">like, not only do you get R1, you also get LAMA-R1, you get QEN-R1, you get R1-0, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=156" target="_blank">00:02:36.460</a></span> | <span class="t">isn't a chat model, you get everything. And then they have future work. Some people have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=161" target="_blank">00:02:41.100</a></span> | <span class="t">done reproductions of the work. Someone yesterday from, I think, Future Labs put out a reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=166" target="_blank">00:02:46.980</a></span> | <span class="t">style data set. So, we'll just, you know, yap and discuss about that. But, yeah. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=173" target="_blank">00:02:53.980</a></span> | <span class="t">high level, the point of all these reasoning models, the reason why everyone cares is because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=178" target="_blank">00:02:58.020</a></span> | <span class="t">they're kind of changing the scaling curve from let's just train bigger and bigger models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=182" target="_blank">00:03:02.300</a></span> | <span class="t">that can like, you know, we throw more compute at the problem and like the inference becomes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=187" target="_blank">00:03:07.020</a></span> | <span class="t">a little bit better to let's start trading that upfront cost for inference time compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=193" target="_blank">00:03:13.740</a></span> | <span class="t">And yeah, that's kind of what they did. Before, OpenAI was the only one to do it with O1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=199" target="_blank">00:03:19.180</a></span> | <span class="t">O1-mini. And then, you know, give it a few months and deep seek out if anyone has just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=202" target="_blank">00:03:22.860</a></span> | <span class="t">put out a really good model. It's like on par with OpenAI's O1. It's like better than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=207" target="_blank">00:03:27.860</a></span> | <span class="t">all the other models. Completely open sourced it. The paper's not that good. They don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=212" target="_blank">00:03:32.300</a></span> | <span class="t">really talk much about the training data. Like Sean mentioned earlier, it's a pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=218" target="_blank">00:03:38.020</a></span> | <span class="t">basic approach to what they did. So, there's not much in the paper. They don't talk much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=222" target="_blank">00:03:42.100</a></span> | <span class="t">about the data. They don't talk much about a lot. But anyway, it's a paper. Weights are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=226" target="_blank">00:03:46.660</a></span> | <span class="t">there. It's MIT licensed, which is pretty good. And you know, it's still a V1 of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=232" target="_blank">00:03:52.860</a></span> | <span class="t">It's like just how OpenAI has O1, there'll be O3. So, you know, there'll be R2. There'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=238" target="_blank">00:03:58.380</a></span> | <span class="t">be other companies that do this. Mistral might do it if they still exist. Lama will do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=243" target="_blank">00:04:03.380</a></span> | <span class="t">So, there'll be others and then we'll only see improvements from here. One of the quotes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=248" target="_blank">00:04:08.140</a></span> | <span class="t">from their paper, their goal, so like they say, "Our goal is to explore the potential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=252" target="_blank">00:04:12.820</a></span> | <span class="t">of LLMs to develop reasoning capabilities without any supervised data, focusing on their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=257" target="_blank">00:04:17.940</a></span> | <span class="t">evolution through a pure RL process." So, TLDR, what they really found out is just throw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=264" target="_blank">00:04:24.100</a></span> | <span class="t">RL at the problem and you can get a really, really good model. People kind of, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=269" target="_blank">00:04:29.060</a></span> | <span class="t">set aside RL for a while, but yeah, it turns out you can just throw RL at the problem and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=273" target="_blank">00:04:33.180</a></span> | <span class="t">it's pretty good. But this is a kind of interesting note, right? So, they wanted to develop reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=278" target="_blank">00:04:38.820</a></span> | <span class="t">capabilities without any supervised data. Without any supervised data means, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=283" target="_blank">00:04:43.580</a></span> | <span class="t">we don't go out, we don't label a bunch of, "Hey, here's chain of thought. Here's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=288" target="_blank">00:04:48.280</a></span> | <span class="t">ideal reasoning." A lot of people would think about, "Okay, if you have an agent, if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=292" target="_blank">00:04:52.300</a></span> | <span class="t">have a coding problem, there's 10, 20, 30 different approaches to get to the same answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=297" target="_blank">00:04:57.300</a></span> | <span class="t">How do we optimize this stuff?" But no, they're not doing supervised data. Their goal was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=302" target="_blank">00:05:02.020</a></span> | <span class="t">to do it without any supervised data, just self-evolution and RL. And they did some really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=307" target="_blank">00:05:07.580</a></span> | <span class="t">good RL. And they did put out good math. They explained this RL. And yeah, that kind of,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=312" target="_blank">00:05:12.840</a></span> | <span class="t">you know, blew up. So, what they do is they post-train the base DeepSeq v3 model, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=319" target="_blank">00:05:19.620</a></span> | <span class="t">I don't think is that important. It's just, you know, big model with this GRPO. GRPO is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=324" target="_blank">00:05:24.620</a></span> | <span class="t">their type of RL. We'll go into it in a bit. And then they start to notice these emergent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=329" target="_blank">00:05:29.540</a></span> | <span class="t">capabilities that come out. There's great reasoning that starts to come out. So, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=333" target="_blank">00:05:33.500</a></span> | <span class="t">know, you don't train on reasoning data, but dang, you get reasoning. You just train on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=338" target="_blank">00:05:38.380</a></span> | <span class="t">hard questions, hard data. Then reflection starts to become a thing. So, you know, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=343" target="_blank">00:05:43.900</a></span> | <span class="t">model starts to reflect, like think on its actions, thinks on its steps. It has these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=349" target="_blank">00:05:49.020</a></span> | <span class="t">aha moments where it's like, "Oh, shoot, that's crazy. This is what the right step is." And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=353" target="_blank">00:05:53.100</a></span> | <span class="t">then it continues. And you get like O1 level performance. Then from this, you know, v3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=361" target="_blank">00:06:01.020</a></span> | <span class="t">like light or whatever zero model, R10, they train the actual DeepSeq R1. They have a four-stage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=367" target="_blank">00:06:07.940</a></span> | <span class="t">approach for training it. And that becomes a really good reasoning and chat model. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=372" target="_blank">00:06:12.420</a></span> | <span class="t">four stages, they have like this cold start to make sure things don't go crazy at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=375" target="_blank">00:06:15.840</a></span> | <span class="t">beginning. And guess what? They do SFT. It's not just RL. Then they do RL. Then they do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=382" target="_blank">00:06:22.660</a></span> | <span class="t">rejection sampling. Then they do RL again. So, not one RL. There are two RL stages at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=387" target="_blank">00:06:27.660</a></span> | <span class="t">the problem, you know, so double the RL. But yeah, so high level, those are the two models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=393" target="_blank">00:06:33.740</a></span> | <span class="t">R10, it's a great reasoning only model. It's trained on unraveled chain of thought, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=399" target="_blank">00:06:39.380</a></span> | <span class="t">know, with RL. It's not good as a general model. Then R1, it's created from outputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=405" target="_blank">00:06:45.180</a></span> | <span class="t">from R10 and that four-stage training method. It's a really good model. It's like O1. Then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=411" target="_blank">00:06:51.340</a></span> | <span class="t">the other half of the paper, not half, but like, you know, they have a section, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=415" target="_blank">00:06:55.020</a></span> | <span class="t">have like a paragraph on, "Hey, by the way, we just distill our outputs into QN and LMA."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=421" target="_blank">00:07:01.220</a></span> | <span class="t">It does very, very good. So, that, they're not doing native RL training. They're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=425" target="_blank">00:07:05.920</a></span> | <span class="t">proper distillation. So, they take their big model. They train it with a distillation loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=430" target="_blank">00:07:10.420</a></span> | <span class="t">Well, they don't say what type of distillation, but you know, standard distillation is distillation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=435" target="_blank">00:07:15.020</a></span> | <span class="t">loss. Then they compare it to the base models and it performs very well. A little note,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=442" target="_blank">00:07:22.940</a></span> | <span class="t">they do try, they make a note like, "Okay, what if we did RL?" So, they take QN32B, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=448" target="_blank">00:07:28.300</a></span> | <span class="t">do like 10K steps of RL. They compare that to distillation and they find distillation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=453" target="_blank">00:07:33.860</a></span> | <span class="t">much better. They make a small claim like, "Yeah, you know, if you do RL, it's very compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=459" target="_blank">00:07:39.180</a></span> | <span class="t">expensive. Like, it's hard to do. It doesn't work as well as just distilling. So, maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=464" target="_blank">00:07:44.140</a></span> | <span class="t">in the future we still need these big base models."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=468" target="_blank">00:07:48.540</a></span> | <span class="t">Being 2025, you know, no one talks about any data. They don't talk about where it came</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=473" target="_blank">00:07:53.380</a></span> | <span class="t">from. They just say, you know, get good quality data. Performance is very good. Models are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=478" target="_blank">00:07:58.300</a></span> | <span class="t">fully open source with MIT license. They don't give training data. They don't give training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=483" target="_blank">00:08:03.940</a></span> | <span class="t">code either. They host the model themselves on their own API. Something interesting to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=488" target="_blank">00:08:08.900</a></span> | <span class="t">note is as much as people are raving about how good this thing is, DeepSeek themselves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=494" target="_blank">00:08:14.620</a></span> | <span class="t">are also serving it very cheaply and very fast. So, 3x faster, 3 to 10x faster and also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=500" target="_blank">00:08:20.740</a></span> | <span class="t">cheaper than other infra providers. But, you know, if you use the DeepSeek API, they clearly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=506" target="_blank">00:08:26.820</a></span> | <span class="t">state that the, you know, data goes to China server. So, use as your own risk, but very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=512" target="_blank">00:08:32.980</a></span> | <span class="t">very cheap model, very, very good model. Their API is a lot faster and cheaper. Part of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=518" target="_blank">00:08:38.220</a></span> | <span class="t">is because, you know, they know everything about how to optimize this thing. They built</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=522" target="_blank">00:08:42.340</a></span> | <span class="t">it and it just came out. The other providers that are hosting it, well, you know, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=526" target="_blank">00:08:46.740</a></span> | <span class="t">just have model and they're trying to run it. But, yeah, from there, let's go into DeepSeek</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=532" target="_blank">00:08:52.220</a></span> | <span class="t">v3 real quick. This is my one slider. So, we say it's important. We'll stop after this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=537" target="_blank">00:08:57.940</a></span> | <span class="t">and discuss it a little, but basically it's just a regular LLM. It's a pretty large model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=543" target="_blank">00:09:03.940</a></span> | <span class="t">It's chunky. It's 671 billion parameters, but 37 billion active parameters, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=549" target="_blank">00:09:09.220</a></span> | <span class="t">pretty interesting. You know, it's a lot of experts in there, but effective parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=553" target="_blank">00:09:13.960</a></span> | <span class="t">are pretty small. It's basically a 30B model at inference time, fully open source. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=559" target="_blank">00:09:19.940</a></span> | <span class="t">GPT 4.0 level. It's not the reasoning one. This is just a standard big MOE model. They</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=565" target="_blank">00:09:25.940</a></span> | <span class="t">made this little claim, you know, training this thing took $5 million, 5.5. They had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=571" target="_blank">00:09:31.020</a></span> | <span class="t">like a few steps to this, so they trained it. Then they did two stages of context length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=576" target="_blank">00:09:36.140</a></span> | <span class="t">extension. They did, first, they trained the thing as a base model. Then they do some 32K</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=580" target="_blank">00:09:40.660</a></span> | <span class="t">and 128K context length extension, trained it on about 15 trillion tokens, do very standard,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=587" target="_blank">00:09:47.580</a></span> | <span class="t">you know, train it, do SFT, do RL. The model is pretty good. They have this concept of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=592" target="_blank">00:09:52.900</a></span> | <span class="t">multi-head latent attention. It's pretty cool. If anything, that would be like the next slide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=598" target="_blank">00:09:58.420</a></span> | <span class="t">if I had to have three slides, but, you know, they have fancy attention. They do multi-token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=604" target="_blank">00:10:04.140</a></span> | <span class="t">prediction. We covered the paper from Meta a few months ago that talks about this, where,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=609" target="_blank">00:10:09.540</a></span> | <span class="t">you know, it's more sample efficient. You can do multi-token prediction. Meta put out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=613" target="_blank">00:10:13.540</a></span> | <span class="t">a paper. They're like, "Oh shit, this works. It's pretty good. People should do it." And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=618" target="_blank">00:10:18.180</a></span> | <span class="t">then not many people did it, and then they did it, and it helps. Came out a month ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=624" target="_blank">00:10:24.000</a></span> | <span class="t">People are very hyped. The other day, it kind of, you know, broke America real quick. NVIDIA</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=628" target="_blank">00:10:28.300</a></span> | <span class="t">dropped $600 million because they said they'd train this in $5 million. So, yeah, I'll take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=636" target="_blank">00:10:36.380</a></span> | <span class="t">a little pause. That's high level of the, you know, what they've released, how it works,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=641" target="_blank">00:10:41.260</a></span> | <span class="t">what's going on under the hood. This is DeepSeek v3. It's their big MOE. It's got 37 billion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=646" target="_blank">00:10:46.940</a></span> | <span class="t">active parameters. They say it was cheap to train. They trained it on 15 trillion tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=653" target="_blank">00:10:53.780</a></span> | <span class="t">but yeah, this is the, you know, step zero. This is the base model that the reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=657" target="_blank">00:10:57.820</a></span> | <span class="t">model is built on. This is very similar to models like Mixtral or GPT 4.0. It's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=664" target="_blank">00:11:04.300</a></span> | <span class="t">a big MOE model. Oh, $600 billion, not $600 million. NVIDIA dropped heavy. Big, big drop.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=672" target="_blank">00:11:12.700</a></span> | <span class="t">America blew up real quick. But yeah, so all the reasoning models are built on top of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=677" target="_blank">00:11:17.720</a></span> | <span class="t">as a base model. But yeah, if we want to pause here, anyone have thoughts, points, anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=682" target="_blank">00:11:22.840</a></span> | <span class="t">that they loved about this DeepSeek v3? Which in and of itself is a good model. It's cheap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=689" target="_blank">00:11:29.660</a></span> | <span class="t">Things to note at a, you know, high level AI engineering, like view is using reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=695" target="_blank">00:11:35.100</a></span> | <span class="t">models is cool, but also they're kind of slow, right? Like if you need total completion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=700" target="_blank">00:11:40.180</a></span> | <span class="t">thinking is cool, but like sometimes I just want output, right? Models are pretty good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=703" target="_blank">00:11:43.940</a></span> | <span class="t">at compressing. Sometimes I want fast speed. This is like GPT 4.0 level and very fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=710" target="_blank">00:11:50.920</a></span> | <span class="t">So it's only 37B active parameter. So a lot of the times people would probably want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=716" target="_blank">00:11:56.580</a></span> | <span class="t">use this. You don't need a reasoning model for everything, right? If you run a chatbot,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=721" target="_blank">00:12:01.020</a></span> | <span class="t">that's cool. You can probably just run this. Later in the conclusion, there's a slide that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=726" target="_blank">00:12:06.660</a></span> | <span class="t">shows what future work they want to do on the reasoning model and they show how v3 is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=731" target="_blank">00:12:11.700</a></span> | <span class="t">actually better at something. So not, not to undermine this, you know, it's still very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=736" target="_blank">00:12:16.060</a></span> | <span class="t">good, very smart, fast, cheap. It's a good model, but it's just an MOE. But yeah, anyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=743" target="_blank">00:12:23.540</a></span> | <span class="t">want to chime in, any questions, anything interesting in chat?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=747" target="_blank">00:12:27.060</a></span> | <span class="t">A lot of questions. Sorry. There's a lot of questions. I don't know which one to focus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=753" target="_blank">00:12:33.080</a></span> | <span class="t">on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=754" target="_blank">00:12:34.080</a></span> | <span class="t">Okay. I'm going to see the first one. So how is effective active parameters different from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=758" target="_blank">00:12:38.260</a></span> | <span class="t">total parameters? So total parameters, you know, you still have to load all this in memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=763" target="_blank">00:12:43.980</a></span> | <span class="t">So 671 billion parameters, you need lots and lots of GPUs to load this thing. But at inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=769" target="_blank">00:12:49.780</a></span> | <span class="t">time, it's only using a fraction of these, right? So 5% of these, it's using 40 billion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=774" target="_blank">00:12:54.820</a></span> | <span class="t">parameters. So realistically, like, it's more efficient to use a lot of tokens. It's, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=781" target="_blank">00:13:01.300</a></span> | <span class="t">going to be faster, it's going to be cheaper. But it's not something that you can just host</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=786" target="_blank">00:13:06.580</a></span> | <span class="t">yourself, right? Like your laptop might be able to host a 30 billion parameter model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=791" target="_blank">00:13:11.940</a></span> | <span class="t">you load all those weights of memory and you use it. This is like, kind of like that at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=797" target="_blank">00:13:17.460</a></span> | <span class="t">inference time, but it needs all the weights loaded up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=801" target="_blank">00:13:21.540</a></span> | <span class="t">I think the point being a lot of people miss is that, like, you do save, you do save memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=806" target="_blank">00:13:26.020</a></span> | <span class="t">at scale, like you might not save memory if you're having one chat on your laptop, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=809" target="_blank">00:13:29.340</a></span> | <span class="t">all, because every token may use a different subset of the parameters, so you need them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=813" target="_blank">00:13:33.740</a></span> | <span class="t">all loaded. But if you're doing batch inference, like, like, like DeepSeq themselves are doing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=819" target="_blank">00:13:39.660</a></span> | <span class="t">then they can route things to the, to each different GPU, how, how they, how they want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=824" target="_blank">00:13:44.580</a></span> | <span class="t">and, and we saturate them a bit more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=827" target="_blank">00:13:47.220</a></span> | <span class="t">Yep. Yep. At batch, it's, it's just very efficient. And that also means it's, it's faster too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=832" target="_blank">00:13:52.980</a></span> | <span class="t">Okay. What is FP8 training? So mixed precision training, you know, before we used to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=837" target="_blank">00:13:57.860</a></span> | <span class="t">in full precision, then half precision, then we started, oh shoot, we can do FP16. Now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=843" target="_blank">00:14:03.220</a></span> | <span class="t">we cut precision again. It's just an interesting thing. I think they're the first ones that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=848" target="_blank">00:14:08.060</a></span> | <span class="t">have done it. Typically, you can do inference. This is like a quantization, right? You can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=852" target="_blank">00:14:12.580</a></span> | <span class="t">run a model in four bit and half precision, and there's a slight degradation in quality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=858" target="_blank">00:14:18.700</a></span> | <span class="t">But on the training side, we typically need as much, like, precision as possible. In this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=863" target="_blank">00:14:23.980</a></span> | <span class="t">case, they, they can do FP8 training. They did it, guys. They also, yeah, another interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=871" target="_blank">00:14:31.700</a></span> | <span class="t">key component was that they're training this without an auxiliary loss. So if you know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=876" target="_blank">00:14:36.900</a></span> | <span class="t">about MOEs, that's a, that's a pretty interesting piece there. But, okay. Can we trust them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=884" target="_blank">00:14:44.260</a></span> | <span class="t">on $5 million cost claim at face value? You can take it both ways. People have gone into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=891" target="_blank">00:14:51.060</a></span> | <span class="t">token economics of how much it would cost to train this many tokens at this scale, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=896" target="_blank">00:14:56.580</a></span> | <span class="t">it can be around here. But realistically, this is like, you know, maybe the final train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=901" target="_blank">00:15:01.060</a></span> | <span class="t">run cost around this, but this doesn't include any of the R&D, any of the other experiments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=906" target="_blank">00:15:06.140</a></span> | <span class="t">Like, it's more than it would be, but either way, you know, it's out, it's open source,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=911" target="_blank">00:15:11.780</a></span> | <span class="t">it's good, it's small. It was cheap. I think Dario from Anthropic, their co-founder, mentioned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=918" target="_blank">00:15:18.940</a></span> | <span class="t">something about this recently of like, they, you know, how Anthropic was, or Cloud 3.5</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=926" target="_blank">00:15:26.420</a></span> | <span class="t">was also trained in the tens of millions. It's nothing crazy. The other interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=932" target="_blank">00:15:32.180</a></span> | <span class="t">thing was the whole GPU restriction, right? So people say that they have to say this because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=938" target="_blank">00:15:38.700</a></span> | <span class="t">they're not allowed GPUs. And if they say they had GPUs, then, you know, they lose their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=942" target="_blank">00:15:42.940</a></span> | <span class="t">little supplier, but they have GPUs. You know, who knows?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=949" target="_blank">00:15:49.300</a></span> | <span class="t">Yeah, I wanted to add, because there's a lot of speculation of whether, whether is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=955" target="_blank">00:15:55.100</a></span> | <span class="t">real or not, right? But like, one of the best thing about the open weight and open, is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=960" target="_blank">00:16:00.540</a></span> | <span class="t">it's in the code and we can validate these things. So it is definitely an MOE model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=966" target="_blank">00:16:06.180</a></span> | <span class="t">It has, it has definitely that amount of experts that was stated and, and the community has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=971" target="_blank">00:16:11.820</a></span> | <span class="t">already essentially made calculators for how much does it cost to create an MOE model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=977" target="_blank">00:16:17.500</a></span> | <span class="t">And if you work it out backwards, it's between five to 10 million. So maybe the exact number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=982" target="_blank">00:16:22.580</a></span> | <span class="t">is off, but I think, I think a lot of people are missing the point that it's at that ballpark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=988" target="_blank">00:16:28.340</a></span> | <span class="t">and for contrast, Lama 345B was 50 mil. And that is based on the amount of compute time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=994" target="_blank">00:16:34.380</a></span> | <span class="t">So you, apples to apples, it's much cheaper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=999" target="_blank">00:16:39.340</a></span> | <span class="t">Yeah. Okay. I think these other questions have good discussion in chat, so I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1006" target="_blank">00:16:46.900</a></span> | <span class="t">to let them continue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1007" target="_blank">00:16:47.900</a></span> | <span class="t">Can I also just add one thing? I think one thing that DeepSeq v3 did very different from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1013" target="_blank">00:16:53.060</a></span> | <span class="t">v2 is, crap, just escape me. Yeah. Auxiliary free MOE training without an auxiliary loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1023" target="_blank">00:17:03.940</a></span> | <span class="t">So I thought that was pretty interesting and it really simplified a lot of things. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1028" target="_blank">00:17:08.220</a></span> | <span class="t">that was a big step up from v2. So, I mean, if you have the paper open, I mean, just go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1033" target="_blank">00:17:13.100</a></span> | <span class="t">through it. They make a big deal out of it. I'm not sure how much of a difference it makes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1036" target="_blank">00:17:16.460</a></span> | <span class="t">though. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1038" target="_blank">00:17:18.460</a></span> | <span class="t">Okay. I have the important, I have the R1 paper open, not the, not the other one. Also,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1045" target="_blank">00:17:25.580</a></span> | <span class="t">I think I'm only sharing my Chrome screen, so we don't get my paper this time. My beautiful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1052" target="_blank">00:17:32.060</a></span> | <span class="t">highlights. It's okay. I took some screenshots of charts, but, okay, let's move on to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1058" target="_blank">00:17:38.580</a></span> | <span class="t">fun one. This was a chart that I was going to pull more charts from. This is from Jay</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1063" target="_blank">00:17:43.580</a></span> | <span class="t">Alomar's blog. It's a good blog. I recommend checking it out. Actually, there was a better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1069" target="_blank">00:17:49.700</a></span> | <span class="t">posted chart in Discord, like, let me pull it up. It was just posted about an hour ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1078" target="_blank">00:17:58.860</a></span> | <span class="t">So this is like a better overview of the training pipeline, but this is also kind of what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1086" target="_blank">00:18:06.340</a></span> | <span class="t">happening here. So they've got the DeepSeek V3 base. They do SFT reasoning data examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1095" target="_blank">00:18:15.460</a></span> | <span class="t">They have this SFT checkpoint. Then we do fine tuning with RL to get DeepSeek R1. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1102" target="_blank">00:18:22.260</a></span> | <span class="t">we're going to kind of look in this middle step here, which is DeepSeek R10. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1107" target="_blank">00:18:27.940</a></span> | <span class="t">is where they apply pure RL directly to V3, the V3 base model without any SFT data. They</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1113" target="_blank">00:18:33.740</a></span> | <span class="t">use a GRPO for RL, which was introduced a little while ago. Actually, this came out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1118" target="_blank">00:18:38.360</a></span> | <span class="t">in the DeepSeek math paper. So there's a few different ways that the model is rewarded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1123" target="_blank">00:18:43.940</a></span> | <span class="t">during this RL process. Someone's got their hand up. You want to just ask the question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1129" target="_blank">00:18:49.980</a></span> | <span class="t">We haven't gone that deep yet. Sachin, you want to?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1133" target="_blank">00:18:53.060</a></span> | <span class="t">Yeah. So you can hear me, right? Yeah. So one of the things, so I haven't been following</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1138" target="_blank">00:18:58.300</a></span> | <span class="t">what OpenAI and all the other guys are doing, but what prevents them from because they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1144" target="_blank">00:19:04.660</a></span> | <span class="t">the training data, their own like process. And if they run this and verify because you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1150" target="_blank">00:19:10.860</a></span> | <span class="t">have the code and all, and then they can compare like what their existing way of doing versus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1156" target="_blank">00:19:16.780</a></span> | <span class="t">the new way of doing, right? So, do you know like how long that would take for these guys?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1164" target="_blank">00:19:24.720</a></span> | <span class="t">But now they say, okay, this is the new way of doing things. Everybody accepts. I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1168" target="_blank">00:19:28.840</a></span> | <span class="t">know if, if you don't know what this data was trained and all, this will definitely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1174" target="_blank">00:19:34.080</a></span> | <span class="t">shake it out. But we are not the guys who can basically have the money to train and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1178" target="_blank">00:19:38.680</a></span> | <span class="t">actually verify this, right? Has anybody done that? Like, these are numbers that only the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1182" target="_blank">00:19:42.800</a></span> | <span class="t">big guys can tell us, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1185" target="_blank">00:19:45.640</a></span> | <span class="t">In terms of training, there's not much to verify, right? So like four V3, four Lama</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1192" target="_blank">00:19:52.960</a></span> | <span class="t">models for the base models, there's verification that people can do, right? You know how many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1198" target="_blank">00:19:58.480</a></span> | <span class="t">tokens are trained on. We know how it is like to train these models. For this model, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1204" target="_blank">00:20:04.200</a></span> | <span class="t">for R1, we don't have training code. We don't have the data, but that doesn't mean that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1209" target="_blank">00:20:09.440</a></span> | <span class="t">people can't do this. There's a section later about companies that are trying to reproduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1213" target="_blank">00:20:13.960</a></span> | <span class="t">this. They also show stuff that we can do, right? So they distill outputs from this into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1218" target="_blank">00:20:18.640</a></span> | <span class="t">Lama models, that stuff that's very attainable, you know, that stuff is now in the hundreds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1223" target="_blank">00:20:23.120</a></span> | <span class="t">to thousands of dollars. Now that stuff regular people can do. There's a company, I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1228" target="_blank">00:20:28.960</a></span> | <span class="t">remember who that already put out a fine tune on DeepSeq style R1 data. So we can discuss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1237" target="_blank">00:20:37.120</a></span> | <span class="t">this in a bit, but yeah, there's, there's people that are starting to work on this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1242" target="_blank">00:20:42.320</a></span> | <span class="t">but anyway back, back to what they're doing here. So R1-0 is kind of one of the two models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1248" target="_blank">00:20:48.240</a></span> | <span class="t">right? So they, a while ago, they put out this paper that was a DeepSeq math paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1253" target="_blank">00:20:53.760</a></span> | <span class="t">They explained this new GRPORL algorithm. It's kind of where you have a reward that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1259" target="_blank">00:20:59.860</a></span> | <span class="t">based on accuracy and responses that are verifiably correct. So verifiably correct means you train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1267" target="_blank">00:21:07.000</a></span> | <span class="t">on data that can be verified. So math questions, you know, math that checks out leak code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1272" target="_blank">00:21:12.080</a></span> | <span class="t">you can have something that compiles it to check if something is correct. And then they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1275" target="_blank">00:21:15.800</a></span> | <span class="t">have like a little format reward. So they, they want to do this RL that nudges the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1280" target="_blank">00:21:20.440</a></span> | <span class="t">to also follow format, right? In this case, the format reward is making sure that there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1284" target="_blank">00:21:24.920</a></span> | <span class="t">think tags between reasoning and then there's an output at the end. So there's kind of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1290" target="_blank">00:21:30.520</a></span> | <span class="t">three things they're testing for here, right? One is the model is being rewarded to one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1296" target="_blank">00:21:36.240</a></span> | <span class="t">put thinking traces, right? So it needs to think. So it's going to put thinking stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1301" target="_blank">00:21:41.560</a></span> | <span class="t">between thinking tags. It needs an answer. So there's going to be an answer and the answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1306" target="_blank">00:21:46.200</a></span> | <span class="t">has to be correct. And then that correct answer has to verifiably check out. So then there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1312" target="_blank">00:21:52.080</a></span> | <span class="t">kind of this RL algorithm that's, that's applied around all this. This is kind of what the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1316" target="_blank">00:21:56.680</a></span> | <span class="t">prompt looks like that they train with. So this is the template prompt, right? So conversation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1321" target="_blank">00:22:01.760</a></span> | <span class="t">between user and assistant, user asks a question, the assistant solves it. The assistant first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1326" target="_blank">00:22:06.720</a></span> | <span class="t">thinks about the reasoning process in the mind, in its mind, then provides the user</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1331" target="_blank">00:22:11.080</a></span> | <span class="t">with an answer. The reasoning process and answers are included, are enclosed within</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1335" target="_blank">00:22:15.640</a></span> | <span class="t">think tags and answers within answer tags respectively. So think goes here, answer goes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1341" target="_blank">00:22:21.320</a></span> | <span class="t">here, then the assistant. So now, you know, when you answer, the model is prompted to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1345" target="_blank">00:22:25.960</a></span> | <span class="t">now answer with, okay, here's my thinking. Here's my reasoning process. Here's the end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1350" target="_blank">00:22:30.040</a></span> | <span class="t">of my think tag. Here's an answer tag. Here's my answer. Here's the end of the answer. Then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1354" target="_blank">00:22:34.600</a></span> | <span class="t">you do a bunch of training with just pure RL. Here's kind of the formula for all this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1358" target="_blank">00:22:38.840</a></span> | <span class="t">Here's, here's a cool little chart. GPRO, GRPO. So what is this? So compared to traditional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1365" target="_blank">00:22:45.120</a></span> | <span class="t">RL, there's no critic model here. It uses groups of sample generation to estimate rewards</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1370" target="_blank">00:22:50.680</a></span> | <span class="t">with, and this kind of helps with cutting the compute cost down, right? You don't need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1374" target="_blank">00:22:54.560</a></span> | <span class="t">to train a separate critic model. In this case, there's group-based rewards. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1379" target="_blank">00:22:59.680</a></span> | <span class="t">is basically where you score outputs when they're compared with a sampled group to reward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1385" target="_blank">00:23:05.120</a></span> | <span class="t">relative performance. So instead of generating one output, generate a group of scores and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1390" target="_blank">00:23:10.960</a></span> | <span class="t">then, you know, reward the one that does the best out of the group. Then there's of course</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1395" target="_blank">00:23:15.320</a></span> | <span class="t">stability and stuff. A big thing with RL is you have like, you know, KL divergence. You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1400" target="_blank">00:23:20.200</a></span> | <span class="t">don't want models to randomly drastically make big changes because they probably won't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1404" target="_blank">00:23:24.880</a></span> | <span class="t">get back. So there's a penalty, you know, if in the group something is really good,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1410" target="_blank">00:23:30.840</a></span> | <span class="t">but you know, it diverges a lot from the sample, then yeah, we also penalize that. So it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1416" target="_blank">00:23:36.000</a></span> | <span class="t">just, this is good RL. We could spend a lot of time on this, but honestly, I think this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1421" target="_blank">00:23:41.960</a></span> | <span class="t">is good for Discord discussion. So I'm sure someone will create a thread of GRPO instead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1427" target="_blank">00:23:47.600</a></span> | <span class="t">of 200 people sitting here thinking about what RL is. High level, there's no critique</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1433" target="_blank">00:23:53.040</a></span> | <span class="t">model. It's, you know, it's judging and rewarding outputs based on sampled group outputs, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1440" target="_blank">00:24:00.720</a></span> | <span class="t">then there's stability in here to make sure that we don't diverge if samples go crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1445" target="_blank">00:24:05.440</a></span> | <span class="t">Now R1-0, how does it perform? So it performs really well and there was no labeled SFT training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1452" target="_blank">00:24:12.920</a></span> | <span class="t">data. It's just a base model trained with this RL to output the correct responses and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1457" target="_blank">00:24:17.600</a></span> | <span class="t">add some thinking. It does well with this majority voting, it does even better. So here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1463" target="_blank">00:24:23.800</a></span> | <span class="t">kind of benchmarks. If we look at it compared to O1 and O1-mini, R1-0 does, you know, pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1469" target="_blank">00:24:29.800</a></span> | <span class="t">good like on most benchmarks on math, on live code, code forces, it's pretty good up there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1477" target="_blank">00:24:37.000</a></span> | <span class="t">And then when you do majority voting, which is, you know, you generate a couple examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1481" target="_blank">00:24:41.420</a></span> | <span class="t">and you see if the answer is in there, it does significantly better. The key thing here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1486" target="_blank">00:24:46.440</a></span> | <span class="t">was they actually trained this thing on very, very hard questions. So just good training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1491" target="_blank">00:24:51.440</a></span> | <span class="t">quality questions and yeah, it does pretty well. You generate a bunch of samples, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1496" target="_blank">00:24:56.760</a></span> | <span class="t">pick the one that's the best out of a group of them, you kind of nudge it towards doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1500" target="_blank">00:25:00.400</a></span> | <span class="t">better there. Yeah, the next few things were very interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1505" target="_blank">00:25:05.920</a></span> | <span class="t">charts that came out of here. So these are some charts that show how their inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1510" target="_blank">00:25:10.800</a></span> | <span class="t">time is correlated with eval performance. This is kind of what you start to see at scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1515" target="_blank">00:25:15.840</a></span> | <span class="t">When they started to train this thing, it didn't work really well, right? This is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1519" target="_blank">00:25:19.920</a></span> | <span class="t">like, okay, why does this work now? This is basic RL. But at scale, we start to see these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1524" target="_blank">00:25:24.780</a></span> | <span class="t">emergent capabilities, right? As you train for more and more steps, we see that accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1529" target="_blank">00:25:29.520</a></span> | <span class="t">starts to go up with steps too, right? So for each question, we sample 16 responses,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1534" target="_blank">00:25:34.800</a></span> | <span class="t">calculate the average, we start to see how it performs. For more steps, the more kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1538" target="_blank">00:25:38.720</a></span> | <span class="t">of steps that you take, the better performance is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1542" target="_blank">00:25:42.520</a></span> | <span class="t">Another one here, this was a very interesting one. The average response length of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1548" target="_blank">00:25:48.280</a></span> | <span class="t">also starts to increase. So the longer you train it, the more reasoning steps it starts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1553" target="_blank">00:25:53.640</a></span> | <span class="t">to take, which means that basically the TLDR of this paper was just this RL thing just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1560" target="_blank">00:26:00.440</a></span> | <span class="t">kind of works. And you can see this in the charts, right? The more that we're training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1564" target="_blank">00:26:04.640</a></span> | <span class="t">this, the model is starting to learn to reason more and more, because the more it reasons,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1569" target="_blank">00:26:09.360</a></span> | <span class="t">the better the performance is. And throughout more steps, the average length of the response</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1573" target="_blank">00:26:13.560</a></span> | <span class="t">is starting to get longer and longer. So here's a little quote here. "The average response</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1580" target="_blank">00:26:20.520</a></span> | <span class="t">length of R1-0 on training set during RL process. DeepSeq R1 naturally learns to solve reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1587" target="_blank">00:26:27.000</a></span> | <span class="t">tasks with more thinking time." So yeah, it's starting to do that. "Naturally squares ability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1594" target="_blank">00:26:34.480</a></span> | <span class="t">to solve complex tasks by extending test time compute. This ranges from hundreds to thousands</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1600" target="_blank">00:26:40.980</a></span> | <span class="t">of reasoning tokens. The emergence of interesting behaviors as test time compute increases."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1607" target="_blank">00:26:47.000</a></span> | <span class="t">So this was another interesting one. So as you increase test time compute, they started</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1611" target="_blank">00:26:51.480</a></span> | <span class="t">to notice emergence of interesting behaviors. So some of these were reflections and aha</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1618" target="_blank">00:26:58.080</a></span> | <span class="t">moments. Reflections are where the model started to revisit and reevaluate previous steps and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1624" target="_blank">00:27:04.280</a></span> | <span class="t">explore alternatives. So as it's doing its thinking, it would start to reflect and be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1630" target="_blank">00:27:10.680</a></span> | <span class="t">like, "Huh, a few steps ago, I went down this path. Maybe I should look at this again."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1637" target="_blank">00:27:17.160</a></span> | <span class="t">Aha moments are where it starts to take more time and reevaluate an original approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1643" target="_blank">00:27:23.000</a></span> | <span class="t">So in this example, and this also shows the quality, the example of questions that they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1649" target="_blank">00:27:29.080</a></span> | <span class="t">training on. And you can see more of these as well. If you look at some of the stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1652" target="_blank">00:27:32.560</a></span> | <span class="t">that they trained on, you can look at those data sets and look at the type of questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1656" target="_blank">00:27:36.780</a></span> | <span class="t">But here it's being told to answer this question. It's like, "Okay, here's basic math. I can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1661" target="_blank">00:27:41.480</a></span> | <span class="t">square both sides. I can isolate this term." And then it's like, "Wait, wait, wait. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1666" target="_blank">00:27:46.600</a></span> | <span class="t">an aha moment I can flag here." And they start to notice these little emergent capabilities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1670" target="_blank">00:27:50.960</a></span> | <span class="t">where it's starting to find these aha moments and it's starting to re-reason. It's starting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1675" target="_blank">00:27:55.760</a></span> | <span class="t">to have these reflections. And there was this kind of interesting quote that I found in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1680" target="_blank">00:28:00.080</a></span> | <span class="t">the paper. So this is from the DeepSeek team. They make this section. They say, "This moment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1686" target="_blank">00:28:06.640</a></span> | <span class="t">is not only an aha moment for the model, but it's also for the researchers observing its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1691" target="_blank">00:28:11.320</a></span> | <span class="t">behavior. It underscores the power and the beauty of reinforcement learning. Rather than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1696" target="_blank">00:28:16.240</a></span> | <span class="t">explicitly teaching a model how to solve a problem, we simply provide it with the right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1701" target="_blank">00:28:21.640</a></span> | <span class="t">incentives and it autonomously develops advanced problem-solving strategies. The aha moment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1708" target="_blank">00:28:28.480</a></span> | <span class="t">serves as a powerful reminder of the potential of RL to unlock new levels of intelligence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1714" target="_blank">00:28:34.280</a></span> | <span class="t">in artificial systems, paving way for more autonomous and adaptive models in the future."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1719" target="_blank">00:28:39.640</a></span> | <span class="t">But basically, rather than explicitly teaching the model how to solve problems, they train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1725" target="_blank">00:28:45.360</a></span> | <span class="t">it with RL, which incentivizes it based on those incentives, and it autonomously starts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1730" target="_blank">00:28:50.860</a></span> | <span class="t">to understand these problem-solving strategies. Through its thinking steps here, it starts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1738" target="_blank">00:28:58.520</a></span> | <span class="t">to realize it has these aha moments, and it also starts to have reflections in its thinking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1745" target="_blank">00:29:05.020</a></span> | <span class="t">So that was kind of another interesting thing that came there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1748" target="_blank">00:29:08.840</a></span> | <span class="t">So what about DeepSeek R1? What are the kind of problems with R1-0? R1-0 had poor readability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1756" target="_blank">00:29:16.480</a></span> | <span class="t">It also had a lot of language mixing. I'll make a note of this later in the section,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1760" target="_blank">00:29:20.920</a></span> | <span class="t">and I think we should discuss it. They kept talking about language mixing. They keep talking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1765" target="_blank">00:29:25.720</a></span> | <span class="t">about how problems with this model are that it mixes up languages. It goes between English</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1771" target="_blank">00:29:31.360</a></span> | <span class="t">to Chinese, and it's not good at fixing what language it should be. And this is also a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1777" target="_blank">00:29:37.200</a></span> | <span class="t">problem with the real R1. They weren't able to solve this too well. Now, some of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1782" target="_blank">00:29:42.080</a></span> | <span class="t">is due to RL, but yeah, it's just a little interesting note that more than four or five</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1787" target="_blank">00:29:47.560</a></span> | <span class="t">times in the paper, they had mentioned how this thing struggles with language mixing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1793" target="_blank">00:29:53.560</a></span> | <span class="t">So that's kind of where R1-0 had its issues. It wasn't very readable. This is giving out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1802" target="_blank">00:30:02.000</a></span> | <span class="t">weird thinking steps, aha moments. It's not being trained with the RL objective of there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1810" target="_blank">00:30:10.320</a></span> | <span class="t">no safety. There's no conciseness. There's no be a good assistant. There's no be a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1816" target="_blank">00:30:16.280</a></span> | <span class="t">chat model. There's no be fun to chat with. There's nothing like that. So they take R1-0,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1822" target="_blank">00:30:22.480</a></span> | <span class="t">and then they make R1, which is let's take this reasoning model that we can do. Let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1827" target="_blank">00:30:27.920</a></span> | <span class="t">actually make a proper LLM assistant that we can. So we'll make a reasoning chat model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1833" target="_blank">00:30:33.960</a></span> | <span class="t">which is what R1 becomes. But I'll take a little pause here. I know a lot of people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1839" target="_blank">00:30:39.320</a></span> | <span class="t">pre-read the paper too. Is there anything we want to dive deeper into in R1-0? We could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1845" target="_blank">00:30:45.000</a></span> | <span class="t">talk about the RL policy itself, the model, how it performs, any of these charts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1853" target="_blank">00:30:53.280</a></span> | <span class="t">Yeah, I had a question. There was a step that I must have missed, which is the RL scoring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1860" target="_blank">00:31:00.040</a></span> | <span class="t">function. In other words, when the models return these 16 different answers in English,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1868" target="_blank">00:31:08.520</a></span> | <span class="t">how is it scoring? How is it deciding which one was that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1872" target="_blank">00:31:12.040</a></span> | <span class="t">So there's a few things there. There's the verifiably correct, which is part of it. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1876" target="_blank">00:31:16.840</a></span> | <span class="t">these questions, if they're LeetCode style questions, you can run a compiler and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1882" target="_blank">00:31:22.920</a></span> | <span class="t">can verifiably see what's correct. If it's a math question, you can verify that the answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1887" target="_blank">00:31:27.840</a></span> | <span class="t">matches what the answer should be. And that's the level of distinction they go at. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1892" target="_blank">00:31:32.480</a></span> | <span class="t">a few different categories, but they can verify the answers to make sure that's correct. Then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1898" target="_blank">00:31:38.240</a></span> | <span class="t">you have the other little parts of the policy, right? Like you want it to output these think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1904" target="_blank">00:31:44.160</a></span> | <span class="t">and answer tokens, so you can verify that it did that. If it didn't do that, then it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1909" target="_blank">00:31:49.600</a></span> | <span class="t">going to be penalized, right? So another part of this is following this prompt template.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1915" target="_blank">00:31:55.120</a></span> | <span class="t">If it doesn't output think tokens and answer tokens, or if it outputs them but doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1920" target="_blank">00:32:00.600</a></span> | <span class="t">give any reasoning, that's not good. Now, this is just a reasoning model. Some of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1925" target="_blank">00:32:05.640</a></span> | <span class="t">changes in the actual R1 is for sometimes you don't need to reason, right? For a question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1931" target="_blank">00:32:11.120</a></span> | <span class="t">like hello, you can not reason. But basically, that's some of the stuff that they--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1936" target="_blank">00:32:16.680</a></span> | <span class="t">So just so I understand, so the basic concept here is that even doing these kinds of very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1943" target="_blank">00:32:23.760</a></span> | <span class="t">simple forms of reasoning, or they're very complicated, like mathematics, the idea is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1948" target="_blank">00:32:28.440</a></span> | <span class="t">that that learning then transfers onto other kinds of responses and reasoning that people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1956" target="_blank">00:32:36.280</a></span> | <span class="t">want. Because it was very interesting to me, like one of my test questions is, what is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1960" target="_blank">00:32:40.760</a></span> | <span class="t">the population below Central Park? And R1 and all of them just fall on their ass. They</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1966" target="_blank">00:32:46.600</a></span> | <span class="t">can't answer this, which any third grader can reason through and come up with a reasonable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1970" target="_blank">00:32:50.760</a></span> | <span class="t">answer, right? And a reasonable answer is not a number that's larger in the population</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1976" target="_blank">00:32:56.400</a></span> | <span class="t">of Manhattan or less than 100,000. They just fall to pieces, because they can't seem to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1982" target="_blank">00:33:02.680</a></span> | <span class="t">reason about this. And the reason I'm asking this is because is the assumption here that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1989" target="_blank">00:33:09.200</a></span> | <span class="t">if they can solve these math questions and coding questions, that they can then reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1993" target="_blank">00:33:13.560</a></span> | <span class="t">about other things? Is that one of the fundamental assumptions here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=1998" target="_blank">00:33:18.520</a></span> | <span class="t">Yeah, so in my interpretation, the goal isn't to get it to reason about different things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2008" target="_blank">00:33:28.120</a></span> | <span class="t">It's to get it to just output thinking and reasoning, right? So you want it to be able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2013" target="_blank">00:33:33.320</a></span> | <span class="t">to output its thought process to come to a verifiably correct answer. And then as there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2020" target="_blank">00:33:40.280</a></span> | <span class="t">harder and harder questions, it does more or less output of what its thought process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2026" target="_blank">00:33:46.240</a></span> | <span class="t">is. And you reward it for being right at the end or wrong at the end. And in that, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2033" target="_blank">00:33:53.280</a></span> | <span class="t">kind of distill this down to, yeah, for harder questions, it will do more thinking before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2037" target="_blank">00:33:57.840</a></span> | <span class="t">it answers. For simple questions, it won't. And that's kind of what I feel like they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2042" target="_blank">00:34:02.360</a></span> | <span class="t">going for here. If anyone else has other answers to this or other takes on this--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2045" target="_blank">00:34:05.560</a></span> | <span class="t">I just wonder whether-- yeah, I wonder whether, like, is it-- what you're saying is it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2050" target="_blank">00:34:10.120</a></span> | <span class="t">learning new reasoning. It's just that in the fine-tuning step, we're teaching it to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2054" target="_blank">00:34:14.960</a></span> | <span class="t">actually reason, even though the base model was capable of that before. So I'm not-- I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2060" target="_blank">00:34:20.600</a></span> | <span class="t">don't know whether that's true or not. It might be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2063" target="_blank">00:34:23.240</a></span> | <span class="t">Yeah, the base model is also very smart, right? But you're teaching it to give out its thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2068" target="_blank">00:34:28.320</a></span> | <span class="t">process. And it's also graded against 16 other versions of thought processes to an answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2073" target="_blank">00:34:33.720</a></span> | <span class="t">And it needs to do pretty good on this. It needs a good thought process. It needs to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2078" target="_blank">00:34:38.240</a></span> | <span class="t">also learn to mimic this template and everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2082" target="_blank">00:34:42.360</a></span> | <span class="t">But to be clear, it's not being judged on the thought process, only on the-- in other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2088" target="_blank">00:34:48.480</a></span> | <span class="t">words, the RL reward is on the correctness of the answer, and then some very basic mechanical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2094" target="_blank">00:34:54.520</a></span> | <span class="t">stuff, like, did you have the word "think" and so on? And was there something that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2097" target="_blank">00:34:57.800</a></span> | <span class="t">going to call a reasoning process? But we're not going into that and parsing it and trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2101" target="_blank">00:35:01.640</a></span> | <span class="t">to understand the reasoning process. All we care about is-- from a reward standpoint,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2106" target="_blank">00:35:06.320</a></span> | <span class="t">the reward is given if the answer is correct. And these tokens and so on are present.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2111" target="_blank">00:35:11.640</a></span> | <span class="t">Actually, if you don't mind if I jump in here, because this is kind of related to my question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2114" target="_blank">00:35:14.840</a></span> | <span class="t">I have on GRPO, which is Group Relative Policy Optimization. I couldn't find anything on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2118" target="_blank">00:35:18.640</a></span> | <span class="t">GRPO on YouTube, which I was hoping to get, because I don't want to read this fucking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2121" target="_blank">00:35:21.600</a></span> | <span class="t">53-page math paper. Forgive me. But I found something on direct policy optimization, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2126" target="_blank">00:35:26.840</a></span> | <span class="t">what that was telling me was they removed the reward function from the objective, or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2131" target="_blank">00:35:31.800</a></span> | <span class="t">lost function. Sorry, I know, another sin. But removing that reward-- that explicit reward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2137" target="_blank">00:35:37.680</a></span> | <span class="t">term seemed to be an important part of TPO, along with callback-livelier divergence in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2141" target="_blank">00:35:41.240</a></span> | <span class="t">order to have that kind of-- I don't want to say memory, because there is also a stability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2145" target="_blank">00:35:45.160</a></span> | <span class="t">term with a clip function with epsilons. But I kind of had that memory as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2150" target="_blank">00:35:50.120</a></span> | <span class="t">So I feel like this GRPO, along with the multi-latent head attention, which is a great poll-- thank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2154" target="_blank">00:35:54.080</a></span> | <span class="t">you so much for that. I really appreciate that. I'm going to look into that soon from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2157" target="_blank">00:35:57.680</a></span> | <span class="t">the meta paper. But it helps with this kind of batch learning. When I hear people talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2162" target="_blank">00:36:02.000</a></span> | <span class="t">on Bloomberg about this model, I hear them say, oh, they trained in fewer batches, or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2166" target="_blank">00:36:06.280</a></span> | <span class="t">the batches were more optimal. And when I hear that, I'm thinking in my head, this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2169" target="_blank">00:36:09.360</a></span> | <span class="t">a GRPF. But I also got to look into multi-latent head attention before I do that, and probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2173" target="_blank">00:36:13.200</a></span> | <span class="t">read this whole 53-page math paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2179" target="_blank">00:36:19.000</a></span> | <span class="t">I have a little bit different use case, I will tell. And people should help me out over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2183" target="_blank">00:36:23.800</a></span> | <span class="t">here. So I look at quite a lot of medical cases, very, very deep things, which I-- right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2189" target="_blank">00:36:29.400</a></span> | <span class="t">now, I use Perplexity, OpenAI, Cloud, and all. And some of these things just blow up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2194" target="_blank">00:36:34.800</a></span> | <span class="t">in your face, right? And the answers they give, I go back to literature and verify.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2199" target="_blank">00:36:39.520</a></span> | <span class="t">And it's a very deep process where I need to-- and then I'm reasoning out with neurosurgeons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2204" target="_blank">00:36:44.840</a></span> | <span class="t">and guys, and like, why, when I'm questioning them. And some of the data they know, some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2208" target="_blank">00:36:48.800</a></span> | <span class="t">of they don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2210" target="_blank">00:36:50.560</a></span> | <span class="t">What ends up happening is OpenAI sometimes puts out just garbage. I mean, I look at all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2214" target="_blank">00:36:54.880</a></span> | <span class="t">sorts of reasoning, what it is showing. But the things I'm learning, and I know what the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2219" target="_blank">00:36:59.560</a></span> | <span class="t">objective is. And my reward process is sometimes, like, so deep inside, is that I know that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2226" target="_blank">00:37:06.880</a></span> | <span class="t">hey, this biochemistry thing with this, this, this, whatever, is probably causing this neurological</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2232" target="_blank">00:37:12.840</a></span> | <span class="t">symptom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2233" target="_blank">00:37:13.840</a></span> | <span class="t">Now, what you did over here with the RL part of it, when you said there's a number of guys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2238" target="_blank">00:37:18.680</a></span> | <span class="t">where you try to pick them up, the problem in RL is that sometimes there might be one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2243" target="_blank">00:37:23.520</a></span> | <span class="t">loner that the action that they take, the reward might be way down the line. You cannot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2249" target="_blank">00:37:29.680</a></span> | <span class="t">take majority of the guys right up front and say, this is the right way it is supposed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2253" target="_blank">00:37:33.320</a></span> | <span class="t">to be done. And my take is, I haven't looked at this, but this is probably works good for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2259" target="_blank">00:37:39.000</a></span> | <span class="t">smaller domains. But when you try to chain domains and domains together, it is probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2264" target="_blank">00:37:44.240</a></span> | <span class="t">going to have a lot of issues, because now we have a combinatorial problem over there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2268" target="_blank">00:37:48.000</a></span> | <span class="t">It's like a go game, you know, like whatever it is. So if you have thoughts, let me know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2272" target="_blank">00:37:52.560</a></span> | <span class="t">So they have a way to solve this KL divergence where, you know, they account for if, if responses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2281" target="_blank">00:38:01.160</a></span> | <span class="t">are significantly different than the rest of the group, we don't take big steps. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2286" target="_blank">00:38:06.400</a></span> | <span class="t">I think at a high level, that's, that's enough on, on the RL. We could go on for that for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2292" target="_blank">00:38:12.200</a></span> | <span class="t">the rest of the hour. But let's take that to offline discussion. Let's, let's get through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2296" target="_blank">00:38:16.640</a></span> | <span class="t">what actual R1 is. So that was just R1-0. I'm going to spend the next quick five minutes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2301" target="_blank">00:38:21.920</a></span> | <span class="t">and then we'll do 10 minutes of discussion, you know. So, okay, what is DeepSeek R1? So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2307" target="_blank">00:38:27.040</a></span> | <span class="t">there's, there's four stages to making this thing a good reasoning and chat model. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2311" target="_blank">00:38:31.600</a></span> | <span class="t">one of them is we have this cold start. So cold start is, you know, let's, let's start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2318" target="_blank">00:38:38.280</a></span> | <span class="t">with some as strong as SFT. Let's not have this thing go crazy at first. They mentioned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2322" target="_blank">00:38:42.520</a></span> | <span class="t">they use some human annotators here. They just drop one line, you know, kind of interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2326" target="_blank">00:38:46.120</a></span> | <span class="t">if you want, anyone wants to look into that. But so first we'll cold start the training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2330" target="_blank">00:38:50.640</a></span> | <span class="t">then we'll do RL, then we'll do a rejection sampling for generation, then we'll do RL</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2335" target="_blank">00:38:55.280</a></span> | <span class="t">again. Okay, quick level. What are these four stages? So stage one, cold start. You have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2339" target="_blank">00:38:59.440</a></span> | <span class="t">that DeepSeek V3, cold start the training with strong SFT. SFT on what you want, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2345" target="_blank">00:39:05.640</a></span> | <span class="t">know, this prevents the model from going unstable. Use a long chain of thought, few shot example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2350" target="_blank">00:39:10.800</a></span> | <span class="t">prompt to, you know, generate some good detailed examples of what we want. So generate some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2356" target="_blank">00:39:16.620</a></span> | <span class="t">good reasoning examples, some reflection, verification, generate from R10. Post-process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2363" target="_blank">00:39:23.560</a></span> | <span class="t">these have human annotators, look at them. This is on the order of thousands of samples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2367" target="_blank">00:39:27.800</a></span> | <span class="t">you know, so nothing crazy, but this just starts the model off, you know, so let's get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2373" target="_blank">00:39:33.160</a></span> | <span class="t">the base model to do some basic SFT. So normally we take base models, we do instruction fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2380" target="_blank">00:39:40.200</a></span> | <span class="t">tuning, we turn them into chat models, right? We do, we do SFT. So we're going to take the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2384" target="_blank">00:39:44.120</a></span> | <span class="t">base model, we're going to generate some examples of chain of thought, few shot prompted examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2390" target="_blank">00:39:50.200</a></span> | <span class="t">you know, so this looks like you, you take R10, you tell it, or you take whatever model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2395" target="_blank">00:39:55.840</a></span> | <span class="t">you tell it to generate some examples where you give the formatting you want, you give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2400" target="_blank">00:40:00.760</a></span> | <span class="t">good, give your thinking steps, give a lot of thinking steps, start it off strong, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2405" target="_blank">00:40:05.760</a></span> | <span class="t">then they generate a couple thousand examples, post-process them, have human annotators,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2409" target="_blank">00:40:09.880</a></span> | <span class="t">I don't know, they just put like a line on this, then they do some regular SFT on base</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2415" target="_blank">00:40:15.220</a></span> | <span class="t">DeepSeq v3, that's stage one. Stage two is they basically do the same exact RL, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2422" target="_blank">00:40:22.200</a></span> | <span class="t">add this language consistency reward, like we mentioned, you know, they're struggling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2426" target="_blank">00:40:26.240</a></span> | <span class="t">with language mixing, so another part of this RL is now we want language to be consistent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2431" target="_blank">00:40:31.880</a></span> | <span class="t">Okay, so we did SFT on really good data, then we do a bunch and bunch of RL, they don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2438" target="_blank">00:40:38.160</a></span> | <span class="t">explain the data set, they don't explain where it came from, how it came, how many samples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2443" target="_blank">00:40:43.000</a></span> | <span class="t">but they do RL. Stage three, rejection sampling. Rejection sampling is pretty common. Lama</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2448" target="_blank">00:40:48.640</a></span> | <span class="t">three did it, many others have done it, it's kind of new, they do this, this is the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2452" target="_blank">00:40:52.640</a></span> | <span class="t">time they talk about how much data, this is on the order, this is kind of like end of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2456" target="_blank">00:40:56.560</a></span> | <span class="t">post-training lifecycle, you know, so they had big base model, which was v3, did SFT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2462" target="_blank">00:41:02.560</a></span> | <span class="t">did big stage of RL, now they do rejection sampling. This helps it turn from like, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2467" target="_blank">00:41:07.680</a></span> | <span class="t">know, we had R1-0 style issues to let's start to fix this, let's generate completions, rank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2475" target="_blank">00:41:15.400</a></span> | <span class="t">them with reward models, this is like LLM as a judge, so generate output, have an LLM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2480" target="_blank">00:41:20.920</a></span> | <span class="t">judge it, have a reward model, judge these outputs and reject some samples, fine-tune</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2485" target="_blank">00:41:25.840</a></span> | <span class="t">this model with rejection sampling. High level, that's what's happening. Stage four, let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2490" target="_blank">00:41:30.200</a></span> | <span class="t">do more RL, you know, throw RL at the problem. So make the model helpful and harmless while</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2496" target="_blank">00:41:36.440</a></span> | <span class="t">making reasoning good, that's kind of the objective here. They do R1 style questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2502" target="_blank">00:41:42.120</a></span> | <span class="t">but they also mix in general chat human preference, so nuanced scenarios, you know, we want it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2508" target="_blank">00:41:48.400</a></span> | <span class="t">to still give a good output, but now we want it to, you know, give a summary at the end,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2513" target="_blank">00:41:53.480</a></span> | <span class="t">don't just give an answer, give a summary. So this is kind of that last step. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2517" target="_blank">00:41:57.960</a></span> | <span class="t">is what makes DeepSeek R1, instead of just reasoning model, you got to do some rejection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2523" target="_blank">00:42:03.320</a></span> | <span class="t">sampling, you got to kickstart the thing so it doesn't go crazy with SFT, and you got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2528" target="_blank">00:42:08.080</a></span> | <span class="t">to do this last stage of some RL for general use. Now, yeah, the model is pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2535" target="_blank">00:42:15.080</a></span> | <span class="t">It's a normal chat model, it gives thinking steps, it gives little summaries at the end,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2541" target="_blank">00:42:21.000</a></span> | <span class="t">and it performs pretty well. It still struggles with some language swaps, but you know, on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2546" target="_blank">00:42:26.160</a></span> | <span class="t">both benchmarks, it's better than O1, better than O1 Mini, either also better than O1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2554" target="_blank">00:42:34.000</a></span> | <span class="t">or in between the two. So you know, O1 might beat it, but it's better than O1 Mini. O1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2559" target="_blank">00:42:39.720</a></span> | <span class="t">beats it better than Mini. O1 beats it better than Mini, or it's better than both. But it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2563" target="_blank">00:42:43.920</a></span> | <span class="t">very good, it's 37B active parameters. We don't really know the model sizes or active</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2569" target="_blank">00:42:49.680</a></span> | <span class="t">parameters of O1, but this thing's good, it's cheap, it's fast, DeepSeek has very good inference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2575" target="_blank">00:42:55.760</a></span> | <span class="t">MIT license, it's fully out there. That's kind of our one, four stages. The new ones</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2582" target="_blank">00:43:02.560</a></span> | <span class="t">are kind of, hey, you do this cold start with SFT from a base model, and then these last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2587" target="_blank">00:43:07.240</a></span> | <span class="t">two stages. You know, you have rejection sampling, you want to kind of fine-tune it, this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2592" target="_blank">00:43:12.880</a></span> | <span class="t">pretty common, you do this for about a million samples, 800,000 is what they did, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2597" target="_blank">00:43:17.200</a></span> | <span class="t">you do some fine-tuning at the end. And yeah, it does very, very well. Then the last part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2603" target="_blank">00:43:23.760</a></span> | <span class="t">of this paper is kind of the distillation step. I'll talk very, very quickly on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2608" target="_blank">00:43:28.240</a></span> | <span class="t">So distillation is where you take a big model, you train it, you generate outputs, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2613" target="_blank">00:43:33.400</a></span> | <span class="t">you mimic those into a small model. So you can either just take input/output and just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2618" target="_blank">00:43:38.600</a></span> | <span class="t">do continual post-training and now you've distilled a model, or you can do this distillation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2622" target="_blank">00:43:42.920</a></span> | <span class="t">loss where you try to get a small model to match the output logit, so not just match</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2627" target="_blank">00:43:47.920</a></span> | <span class="t">the output, match the output distribution, you know, really match the thinking process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2633" target="_blank">00:43:53.020</a></span> | <span class="t">per se of what the big model is doing. They do distillation on just a million samples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2638" target="_blank">00:43:58.800</a></span> | <span class="t">so they have 800,000 reasoning samples and they distill R1 into Lama and Klein models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2644" target="_blank">00:44:04.240</a></span> | <span class="t">So they take the two families, they do distillation. This is not RL. They just do basic SFT distillation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2650" target="_blank">00:44:10.680</a></span> | <span class="t">on about 800,000 samples, and now the model does very well. And not only does it do well,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2657" target="_blank">00:44:17.400</a></span> | <span class="t">it outputs all of its thinking steps, you know, it becomes a bit of a reasoning model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2661" target="_blank">00:44:21.680</a></span> | <span class="t">and the performance jumps a lot. So they not only compare it to the base models, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2666" target="_blank">00:44:26.720</a></span> | <span class="t">they're all better than, they also compare it to, you know, like GPT-40, they compare</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2670" target="_blank">00:44:30.920</a></span> | <span class="t">it to CloudSonic, to O1-mini. And you can see, like, Quen32B is doing better than all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2676" target="_blank">00:44:36.600</a></span> | <span class="t">these models. Like, their distillation work is very good. They open-sourced all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2682" target="_blank">00:44:42.480</a></span> | <span class="t">models. They dropped them all. These will run locally, you know. So this is like Lama8B,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2688" target="_blank">00:44:48.240</a></span> | <span class="t">Lama7B, Quen32B. These are models that you can run locally on your laptop. They're very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2694" target="_blank">00:44:54.520</a></span> | <span class="t">very strong models. They'll run pretty quick. And then just as a bit of, like, they had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2701" target="_blank">00:45:01.280</a></span> | <span class="t">a lot of abolations, but the one that I found interesting is the question comes up of, "Hey,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2705" target="_blank">00:45:05.760</a></span> | <span class="t">what if we just do RL on the other base models?" And they're like, "Okay, let's test it. Let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2709" target="_blank">00:45:09.920</a></span> | <span class="t">take Quen32B. Let's do our same RL for 10k steps." Well, it does better, but it does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2716" target="_blank">00:45:16.920</a></span> | <span class="t">nowhere near as good as our distillation. So basically, their takeaway is, "Hey, RL,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2724" target="_blank">00:45:24.320</a></span> | <span class="t">like, takes a lot of compute. It's hard to do. And it doesn't get the same performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2728" target="_blank">00:45:28.940</a></span> | <span class="t">as this distillation. So maybe in the future, we still need these big models." But yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2734" target="_blank">00:45:34.360</a></span> | <span class="t">distillation worked very, very well compared to their RL on a 32B. I'm sure other people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2739" target="_blank">00:45:39.680</a></span> | <span class="t">will go deeper into this. Other people will try it. And they'll, you know, update us on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2743" target="_blank">00:45:43.600</a></span> | <span class="t">how it does. Okay, future work. R1 is still worse than V3 at some things. So as much as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2750" target="_blank">00:45:50.960</a></span> | <span class="t">I shat on V3 not being important, it's still good. It's fast, faster than R1. R1 is worse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2758" target="_blank">00:45:58.220</a></span> | <span class="t">at function calling, multi-turn, complex role play, and JSON output. Those are just a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2764" target="_blank">00:46:04.320</a></span> | <span class="t">things. R1 struggles with language mixing. I don't know why they note this, but V3 doesn't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2770" target="_blank">00:46:10.900</a></span> | <span class="t">So maybe their RL has Chinese data. Maybe I misread something there. Maybe they both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2775" target="_blank">00:46:15.880</a></span> | <span class="t">do. But R1 struggles with language mixing. R1 is sensitive to prompting. Few-shot prompts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2781" target="_blank">00:46:21.920</a></span> | <span class="t">degrade the performance. So if you guys are using R1, don't few-shot prompt it. Don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2788" target="_blank">00:46:28.040</a></span> | <span class="t">tell the model how to think. Tell it what you want it to do and let it reason. It will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2792" target="_blank">00:46:32.560</a></span> | <span class="t">do better. And it's not better at a lot of engineering tasks than V3. They explained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2798" target="_blank">00:46:38.100</a></span> | <span class="t">why and they explained, you know, what they think they can do to fix them. But this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2802" target="_blank">00:46:42.960</a></span> | <span class="t">just some sort of future work. But high, high level, that's kind of the paper. We have seven</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2809" target="_blank">00:46:49.360</a></span> | <span class="t">minutes left. One option is if there's like one or two quick questions. Otherwise we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2819" target="_blank">00:46:59.560</a></span> | <span class="t">talk about future stuff, questions, and what people have. So people are trying to recreate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2824" target="_blank">00:47:04.480</a></span> | <span class="t">R1. DeepSeq didn't talk much about the data. Not many specifics about what went on there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2831" target="_blank">00:47:11.520</a></span> | <span class="t">Hug & Face has a thing to reproduce it. They have a whole chart of how they're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2834" target="_blank">00:47:14.720</a></span> | <span class="t">do it. Bespoke Labs put out a data set. I think it's a great effort. It's not great</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2840" target="_blank">00:47:20.120</a></span> | <span class="t">in my opinion. I looked at like their prompt templating. They heavily try to prompt it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2844" target="_blank">00:47:24.800</a></span> | <span class="t">into responding in a certain way. But anyway, they have over, I think they have a hundred</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2849" target="_blank">00:47:29.960</a></span> | <span class="t">thousand-ish samples of R1 data. They fine tune to 7B. They show results. But yeah, what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2855" target="_blank">00:47:35.920</a></span> | <span class="t">other hot takes have we seen? Eugene Yan, you have your hand up. You want to join in?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2859" target="_blank">00:47:39.880</a></span> | <span class="t">Hey, Vibhu. I just wanted to ask a question. Sorry, not a hot take, but a question. In</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2865" target="_blank">00:47:45.040</a></span> | <span class="t">V3, in stage three, right, they actually retrained it based on the DeepSeq V3 base model. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2873" target="_blank">00:47:53.200</a></span> | <span class="t">I guess the question I have is why did they not carry on from stage two? I know Eugene</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2879" target="_blank">00:47:59.780</a></span> | <span class="t">Chia had a take on this on Discord, but I wonder if anyone here would have intuition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2886" target="_blank">00:48:06.760</a></span> | <span class="t">on why they did this. I had a similar question. So I noticed in the chart as well, same thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2894" target="_blank">00:48:14.640</a></span> | <span class="t">going on. Exactly. And the paper actually calls it out specifically as a single sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2899" target="_blank">00:48:19.200</a></span> | <span class="t">on its own. So it's pretty unique. Yeah. Basically here, right, they restart from V3 stage instead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2911" target="_blank">00:48:31.040</a></span> | <span class="t">of continuing down their whole code process. Why they did this, I wish we knew. Eugene</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2917" target="_blank">00:48:37.960</a></span> | <span class="t">Chia, do you want to share your take? So my speculation is after they got the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2923" target="_blank">00:48:43.160</a></span> | <span class="t">round data set, is they trained from the base model before annealing. And this is just to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2929" target="_blank">00:48:49.140</a></span> | <span class="t">get a better final outcome. I don't fully agree with this idea, but a lot of fine tuners</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2935" target="_blank">00:48:55.520</a></span> | <span class="t">swear on you want to fine tune on pre-annealed models instead of annealed models. Yeah. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2943" target="_blank">00:49:03.680</a></span> | <span class="t">we can probably go into a side track on that. But yeah, that's my guess. I mean, I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2948" target="_blank">00:49:08.840</a></span> | <span class="t">really have a great mathematical or machine learning background on this, but I teach right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2953" target="_blank">00:49:13.600</a></span> | <span class="t">now and I feel like I do a lot of reinforcement learning when I'm just like trying to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2957" target="_blank">00:49:17.560</a></span> | <span class="t">students to do very little reasoning, COT steps correct. Like I want you to write down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2962" target="_blank">00:49:22.960</a></span> | <span class="t">this exponent in the same police I did because I put in a different color. And if you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2967" target="_blank">00:49:27.800</a></span> | <span class="t">do it, I'm going to take off points and this and this and so forth. But what I want them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2971" target="_blank">00:49:31.480</a></span> | <span class="t">to really understand and technically explain in a nuanced way, that fine tuning of having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2976" target="_blank">00:49:36.080</a></span> | <span class="t">that discussion, having that expert review is so much more helpful than just a cookbook</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2980" target="_blank">00:49:40.280</a></span> | <span class="t">chain of thought. So in my mind, fine tuning, but I mean, it's not really from an ML perspective,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2985" target="_blank">00:49:45.640</a></span> | <span class="t">kind of just from, I talk to people a lot. Oh, thank you. I also forgot to mention what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2991" target="_blank">00:49:51.960</a></span> | <span class="t">annealing is. So annealing is a process where you essentially flatten out and lower the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=2995" target="_blank">00:49:55.800</a></span> | <span class="t">learning rate. And, and that's a one-time thing you do at the end of the model typically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3001" target="_blank">00:50:01.520</a></span> | <span class="t">Yeah. Sam. Hey, did we, did the paper cover how, when they create examples for SFT using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3011" target="_blank">00:50:11.760</a></span> | <span class="t">rejection sampling on the RL checkpoint, what method they use to select the good examples?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3016" target="_blank">00:50:16.200</a></span> | <span class="t">Sorry, I didn't hear that too much. When they created SFT samples to what? Yeah. What method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3023" target="_blank">00:50:23.680</a></span> | <span class="t">did they use to select the good examples when they're doing rejection sampling SFT on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3029" target="_blank">00:50:29.360</a></span> | <span class="t">RL checkpoint? Oh, on the rejection sampling? Yeah. Yeah. They, they share a little bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3039" target="_blank">00:50:39.440</a></span> | <span class="t">about the rejection sampling, but when they generate the samples, they, they had this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3047" target="_blank">00:50:47.120</a></span> | <span class="t">whole section about, I mean, honestly, the whole paper is very, very vague in all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3052" target="_blank">00:50:52.160</a></span> | <span class="t">specifics. They, they just mentioned like little, little notes, like in the cold start,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3058" target="_blank">00:50:58.860</a></span> | <span class="t">you know, how do we generate it? Right. It says human annotators. It doesn't say what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3062" target="_blank">00:51:02.720</a></span> | <span class="t">they did. Yeah. It doesn't say what they did. It says like, you know, slight, slight use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3066" target="_blank">00:51:06.840</a></span> | <span class="t">of human annotators. We, we do post-processing. That's cool. You do, you do post-processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3073" target="_blank">00:51:13.160</a></span> | <span class="t">to post-process what? But at some level they tell you for rejection sampling, it's kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3078" target="_blank">00:51:18.460</a></span> | <span class="t">of what you would expect, right? So what are they trying to do? What's their goal? Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3084" target="_blank">00:51:24.640</a></span> | <span class="t">they probably want to take away examples that don't have like summaries at the end, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3089" target="_blank">00:51:29.760</a></span> | <span class="t">But they, they don't, they don't go into too much detail. Is language mixing a feature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3095" target="_blank">00:51:35.560</a></span> | <span class="t">or a bug? Isn't it good if the model can find an efficient reasoning techniques? Feature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3101" target="_blank">00:51:41.780</a></span> | <span class="t">or bug depends on how you see it, right? So language mixing in this case, I believe they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3106" target="_blank">00:51:46.000</a></span> | <span class="t">meant is it responds. Actually, no, they, they actually do specifically explain in some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3112" target="_blank">00:51:52.920</a></span> | <span class="t">cases, like the question is asked in Chinese and it responds in English. So seems more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3119" target="_blank">00:51:59.720</a></span> | <span class="t">like a bug, right? You don't, you don't want that. Cool. Any, any other quick questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3127" target="_blank">00:52:07.840</a></span> | <span class="t">Any other thoughts? Any other concerns? And I'm sure there'll be a lot of discussion on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3134" target="_blank">00:52:14.600</a></span> | <span class="t">discord continuing about this, you know. I'm curious about people, how people are using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3139" target="_blank">00:52:19.760</a></span> | <span class="t">these models now. Cause one of the things like my uses for thinking models is when I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3144" target="_blank">00:52:24.600</a></span> | <span class="t">trying to brainstorm some creative topic. And yesterday I put side by side Gemini 2.0</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3153" target="_blank">00:52:33.240</a></span> | <span class="t">thinking experimental, whatever 0121 and DeepSeek R1, and then the 70 billion llama distill</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3161" target="_blank">00:52:41.560</a></span> | <span class="t">from that's hosted on Grok. And the answer I got from Gemini was much better than the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3166" target="_blank">00:52:46.020</a></span> | <span class="t">one I got from the other two. And I was, I don't know, I haven't tried a whole bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3169" target="_blank">00:52:49.360</a></span> | <span class="t">of examples, but I'm curious about whether, what people are using day to day when they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3172" target="_blank">00:52:52.660</a></span> | <span class="t">want to code and when they want to think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3182" target="_blank">00:53:02.220</a></span> | <span class="t">I gave up. I just stick with Claude. I made Claude now. I'm going to wait until there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3187" target="_blank">00:53:07.600</a></span> | <span class="t">a little more settling at the moment. I'm kind of wasting my time, which is fine, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3192" target="_blank">00:53:12.080</a></span> | <span class="t">I'd rather waste my time by not being as efficient than looking for which of the new models suits</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3197" target="_blank">00:53:17.440</a></span> | <span class="t">my uses best here. But that's a personal opinion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3200" target="_blank">00:53:20.160</a></span> | <span class="t">The thing Rahim is talking is actually very critical in the sense, different models and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3207" target="_blank">00:53:27.280</a></span> | <span class="t">all the big guys, they fail, what do you call it, brilliantly, or they just blow up at certain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3214" target="_blank">00:53:34.420</a></span> | <span class="t">reasoning and then at other things they do very nice. Until you have looked at all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3218" target="_blank">00:53:38.960</a></span> | <span class="t">gamut of across the things, you cannot stick to one thing. I mean, if you have some money,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3223" target="_blank">00:53:43.920</a></span> | <span class="t">you need to like push across all of them and look at responses. Gemini gives one, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3230" target="_blank">00:53:50.360</a></span> | <span class="t">that's why I want to see what perplexity, if they puts out a blog post on this, where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3234" target="_blank">00:53:54.520</a></span> | <span class="t">they have probably the largest data of people, what people are trying to, how they try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3238" target="_blank">00:53:58.160</a></span> | <span class="t">use it. So that would be my, what do you call next steps to go and see what do they think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3243" target="_blank">00:54:03.200</a></span> | <span class="t">of deep sea if they're done their own internal thing. But that is, I think, where getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3249" target="_blank">00:54:09.560</a></span> | <span class="t">beyond like the evils, the evils are just like saying, okay, this is our baseline and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3254" target="_blank">00:54:14.080</a></span> | <span class="t">from here, let's go and go to the races kind of a stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3258" target="_blank">00:54:18.600</a></span> | <span class="t">I mean, specifically for your thing, if we're done, I'll leave it for Desco.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3264" target="_blank">00:54:24.640</a></span> | <span class="t">So at a quick level, the other thing to note with how people are using these is they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3268" target="_blank">00:54:28.800</a></span> | <span class="t">very cheap, right? So if you look at the cost of O1 versus R1, it's like more than 10X cheaper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3278" target="_blank">00:54:38.040</a></span> | <span class="t">So stuff that was expensive to do is now not as expensive, right? So they're just good,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3285" target="_blank">00:54:45.560</a></span> | <span class="t">cheap reasoning models are fast. And the other part is they're open source. So if you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3290" target="_blank">00:54:50.800</a></span> | <span class="t">to self-deploy it, you can self-deploy it. If you want to use one of the reasoning models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3295" target="_blank">00:54:55.360</a></span> | <span class="t">locally, like the Quen 32B1, 7B1, they're pretty good locally on your laptop. So that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3304" target="_blank">00:55:04.160</a></span> | <span class="t">how some people use them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3305" target="_blank">00:55:05.160</a></span> | <span class="t">I don't know if also that availability, right? Like I've been playing with that and I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3308" target="_blank">00:55:08.840</a></span> | <span class="t">kind of had a little bit of mixed use and I've had a friend who's been trying to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3312" target="_blank">00:55:12.920</a></span> | <span class="t">him to do some gnarly reactor refactorings and he's been frustrated a little bit. I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3317" target="_blank">00:55:17.920</a></span> | <span class="t">know if that's just not learning how to be prompted properly for those kinds of very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3322" target="_blank">00:55:22.560</a></span> | <span class="t">specific and more involved tasks, but also Cursor might end up having enough data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3328" target="_blank">00:55:28.560</a></span> | <span class="t">on how people are using it specifically for coding. And maybe I'm hoping they might publish</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3332" target="_blank">00:55:32.960</a></span> | <span class="t">something on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3334" target="_blank">00:55:34.560</a></span> | <span class="t">But yeah, it's a good model. Anyway, guys, thanks. Next week we will have Eric Ness facilitating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3343" target="_blank">00:55:43.000</a></span> | <span class="t">Titan model. Discussion will continue in Discord. I'll throw slides in there. But yeah, see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3348" target="_blank">00:55:48.240</a></span> | <span class="t">you guys next week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3349" target="_blank">00:55:49.240</a></span> | <span class="t">Thanks, everyone. Thanks, Vivo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3350" target="_blank">00:55:50.240</a></span> | <span class="t">Thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3351" target="_blank">00:55:51.240</a></span> | <span class="t">Thank you, Vivo.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3352" target="_blank">00:55:52.240</a></span> | <span class="t">Thanks, everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3353" target="_blank">00:55:53.240</a></span> | <span class="t">Thank you, Kevin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3356" target="_blank">00:55:56.240</a></span> | <span class="t">Thank you, Kevin.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3358" target="_blank">00:55:58.240</a></span> | <span class="t">Bye-bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3359" target="_blank">00:55:59.240</a></span> | <span class="t">Bye-bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3359" target="_blank">00:55:59.240</a></span> | <span class="t">Bye-bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3360" target="_blank">00:56:00.240</a></span> | <span class="t">Bye-bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3361" target="_blank">00:56:01.240</a></span> | <span class="t">Bye-bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3362" target="_blank">00:56:02.240</a></span> | <span class="t">Bye-bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3363" target="_blank">00:56:03.240</a></span> | <span class="t">Bye-bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3363" target="_blank">00:56:03.240</a></span> | <span class="t">Bye-bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3364" target="_blank">00:56:04.240</a></span> | <span class="t">Bye-bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3365" target="_blank">00:56:05.240</a></span> | <span class="t">Bye-bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=YF7Xk48VfzQ&t=3365" target="_blank">00:56:05.240</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>