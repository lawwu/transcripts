<html><head><title>Google Titans: Learning to Memorize at Test Time</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Google Titans: Learning to Memorize at Test Time</h2><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY"><img src="https://i.ytimg.com/vi/Hpz0bm6QupY/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./Hpz0bm6QupY.html">Whisper Transcript</a> | <a href="./transcript_Hpz0bm6QupY.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Welcome, everyone. Let me share my window here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=19" target="_blank">00:00:19.080</a></span> | <span class="t">So pretty, by the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=21" target="_blank">00:00:21.080</a></span> | <span class="t">Yeah. I was playing around with this new presentation tool, gamma.ai. And I can't go back to PowerPoint</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=29" target="_blank">00:00:29.920</a></span> | <span class="t">ever again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=31" target="_blank">00:00:31.320</a></span> | <span class="t">That's huge praise. Yeah. A friend of mine actually quit to work for this company. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=37" target="_blank">00:00:37.760</a></span> | <span class="t">I was like, another AI Slides company? You know, these never work. Shows what I know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=44" target="_blank">00:00:44.440</a></span> | <span class="t">It's really impressive. So I'm not paid by the company in any way, but I do recommend</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=49" target="_blank">00:00:49.600</a></span> | <span class="t">people try.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=52" target="_blank">00:00:52.800</a></span> | <span class="t">So this week, we're going to talk about a new paper out of Google Research, Titans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=61" target="_blank">00:01:01.840</a></span> | <span class="t">The main thing that this new architecture presents is giving the model some memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=71" target="_blank">00:01:11.240</a></span> | <span class="t">especially at inference time, so that it can leverage that to make better inferences and,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=82" target="_blank">00:01:22.120</a></span> | <span class="t">you know, improve benchmark scores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=85" target="_blank">00:01:25.600</a></span> | <span class="t">And I'm generally not going to be looking at the chat while I present. There's a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=91" target="_blank">00:01:31.920</a></span> | <span class="t">to go through, but I'm going to leave plenty of time at the end for discussion where we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=96" target="_blank">00:01:36.560</a></span> | <span class="t">can go back over questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=101" target="_blank">00:01:41.520</a></span> | <span class="t">So yeah. So do feel free to drop posts in the chat, and we will get to them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=115" target="_blank">00:01:55.200</a></span> | <span class="t">So let's see. Okay. I'm trying to figure out how to -- wait a minute. There we go. Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=135" target="_blank">00:02:15.420</a></span> | <span class="t">So what are some of the problems that this Titans paper is trying to address? The first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=142" target="_blank">00:02:22.760</a></span> | <span class="t">of which is the quadratic complexity nature of attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=150" target="_blank">00:02:30.600</a></span> | <span class="t">And this has been one of the things that typically was, up until, say, the last year or so, really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=159" target="_blank">00:02:39.680</a></span> | <span class="t">restricting the context window size of models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=164" target="_blank">00:02:44.640</a></span> | <span class="t">So if I remember correctly, when GPT-4 came out, it first had a size of 8K or 32K, something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=174" target="_blank">00:02:54.080</a></span> | <span class="t">like that context window, but nothing compared to the 1 million context window of Gemini.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=182" target="_blank">00:03:02.400</a></span> | <span class="t">And the reason for that was that for -- in typical attention, every token is compared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=190" target="_blank">00:03:10.880</a></span> | <span class="t">to every other token, so that if you, say, have a context window size of 1,000, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=198" target="_blank">00:03:18.120</a></span> | <span class="t">the complexity is 1,000 squared. And if you have a, you know, window size of 10,000, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=208" target="_blank">00:03:28.800</a></span> | <span class="t">it's 10,000 squared.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=210" target="_blank">00:03:30.040</a></span> | <span class="t">And so in order to increase the size of your context window, it becomes, like, very computationally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=219" target="_blank">00:03:39.200</a></span> | <span class="t">expensive very quickly. And there are ways around this that are mentioned in the paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=224" target="_blank">00:03:44.200</a></span> | <span class="t">but that's one of the problems with, let's say, classical transformers, which leads right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=231" target="_blank">00:03:51.200</a></span> | <span class="t">into the limited context window, again, based on the quadratic aspect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=240" target="_blank">00:04:00.240</a></span> | <span class="t">And then the other thing is that the long context window creates the bottleneck for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=248" target="_blank">00:04:08.640</a></span> | <span class="t">the very long sequences of data. So transformers are great, and, you know, there's been tons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=258" target="_blank">00:04:18.800</a></span> | <span class="t">of advances in them, since the attention is all you need paper, but, you know, there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=267" target="_blank">00:04:27.400</a></span> | <span class="t">limitations in the architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=269" target="_blank">00:04:29.760</a></span> | <span class="t">And so what does Titans do to try to address that at a very high level? The first thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=278" target="_blank">00:04:38.240</a></span> | <span class="t">it does is to emulate human memory, meaning that human memory has different -- you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=288" target="_blank">00:04:48.200</a></span> | <span class="t">think of them as modules or types of memory. There's short-term memory and long-term memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=296" target="_blank">00:04:56.560</a></span> | <span class="t">However, in the typical transformer model, as we'll see, those have, like, short-term</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=305" target="_blank">00:05:05.240</a></span> | <span class="t">memory because they have access to the tokens that they're currently processing, but anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=311" target="_blank">00:05:11.320</a></span> | <span class="t">that happened before that, they don't have memory of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=317" target="_blank">00:05:17.240</a></span> | <span class="t">And as you do AI engineering, you probably are well aware that every time you make an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=325" target="_blank">00:05:25.480</a></span> | <span class="t">API call to OpenAI or Cloud, it's, like, starting all over again. And then the second part is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=336" target="_blank">00:05:36.520</a></span> | <span class="t">the enhanced processing. So the memory allows very long, like, extremely long sequences</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=343" target="_blank">00:05:43.040</a></span> | <span class="t">to be handled, so that -- and we'll see that as the tokens are processed, they -- the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=352" target="_blank">00:05:52.400</a></span> | <span class="t">keeps a representation of just the most salient or important, let's say, facts. It's a representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=361" target="_blank">00:06:01.440</a></span> | <span class="t">of facts, but let's say facts from the tokens it's seen so far so that it can use those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=367" target="_blank">00:06:07.280</a></span> | <span class="t">to improve predictions on future tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=374" target="_blank">00:06:14.240</a></span> | <span class="t">So there was some work by other groups, and this group as well. So this isn't, like, a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=384" target="_blank">00:06:24.760</a></span> | <span class="t">sudden thing. This paper, test-time training with supervision, goes back to 2020. So there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=396" target="_blank">00:06:36.120</a></span> | <span class="t">a few things that this paper represented. The first is using that unlabeled test dataset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=405" target="_blank">00:06:45.760</a></span> | <span class="t">into a self-supervide learning problem so that it can update its own parameters before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=415" target="_blank">00:06:55.280</a></span> | <span class="t">making a prediction. And they noticed performance improvements with this. So that's one paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=423" target="_blank">00:07:03.960</a></span> | <span class="t">that previously came out. And I didn't -- I'm going to just mention two papers. I didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=432" target="_blank">00:07:12.400</a></span> | <span class="t">read either of them in depth. I just kind of read the abstract and got the gist of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=439" target="_blank">00:07:19.220</a></span> | <span class="t">But if you're very interested in this, both of these are good sources. And then the other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=445" target="_blank">00:07:25.320</a></span> | <span class="t">one is this RNNs or learning to learn at test-time about RNNs with expressive hidden states.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=454" target="_blank">00:07:34.720</a></span> | <span class="t">So this is -- and we'll see this in the Titans paper as well, that it does bring an RNN or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=465" target="_blank">00:07:45.960</a></span> | <span class="t">recurring neural network technique back into transformers where there is a state inside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=476" target="_blank">00:07:56.960</a></span> | <span class="t">the -- well, it's the hidden state. And as the tokens are processed, that hidden state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=484" target="_blank">00:08:04.360</a></span> | <span class="t">is updated and then allowed to affect future outputs. So this is the paper that brought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=497" target="_blank">00:08:17.560</a></span> | <span class="t">that into the research community. You can also see the -- one of the main points from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=505" target="_blank">00:08:25.440</a></span> | <span class="t">this paper is the linear complexity. So using this to get around the quadratic complexity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=512" target="_blank">00:08:32.080</a></span> | <span class="t">of the typical transformer. So as I mentioned, Titans is inspired by human memory. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=528" target="_blank">00:08:48.400</a></span> | <span class="t">core or short-term memory. So in the Titans models, this is the equivalent of just a normal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=539" target="_blank">00:08:59.320</a></span> | <span class="t">attention mechanism where you have the query, keys, and values sets, you know, all interacting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=551" target="_blank">00:09:11.100</a></span> | <span class="t">in the transformer component. So this is the short-term memory. So they don't really introduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=561" target="_blank">00:09:21.240</a></span> | <span class="t">anything about short-term memory. They just reuse what is already out there. Long-term</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=566" target="_blank">00:09:26.920</a></span> | <span class="t">memory is where they learn to memorize historical context, encode that context into abstractions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=577" target="_blank">00:09:37.600</a></span> | <span class="t">so that it can improve future tokens. This is the main thing that they talk about in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=583" target="_blank">00:09:43.760</a></span> | <span class="t">the paper is this long-term memory module and how exactly it operates. And then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=592" target="_blank">00:09:52.040</a></span> | <span class="t">persistent memory is not a, like, inference-dependent thing. So this is -- you can think of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=603" target="_blank">00:10:03.560</a></span> | <span class="t">as, like, a set of knowledge or a set of rules that always exists in the model. It's hard-coded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=612" target="_blank">00:10:12.840</a></span> | <span class="t">in there. And it's always brought into the -- into the sequence. We'll see how that happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=620" target="_blank">00:10:20.780</a></span> | <span class="t">They don't talk a whole lot about persistent memory. So it's -- at least for me, it was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=626" target="_blank">00:10:26.880</a></span> | <span class="t">a little unclear where -- how exactly this is created. But it's also not the main point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=634" target="_blank">00:10:34.520</a></span> | <span class="t">of it. It's just kind of a set of parameters that are always fed into the sequence that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=643" target="_blank">00:10:43.080</a></span> | <span class="t">going to be predicted against. Okay. So let's take some time digging into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=653" target="_blank">00:10:53.940</a></span> | <span class="t">this long-term memory module. So this is the -- kind of the main breakthrough that this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=665" target="_blank">00:11:05.240</a></span> | <span class="t">paper is presenting. There's a few different things you can see here as far as what this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=672" target="_blank">00:11:12.960</a></span> | <span class="t">module does. The first is recurrent processing. So like I mentioned, it maintains a state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=682" target="_blank">00:11:22.660</a></span> | <span class="t">as it's doing inference. And then that part of the output is then fed back into that state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=693" target="_blank">00:11:33.220</a></span> | <span class="t">so that it can continue to capture new information as it goes along. This helps it to kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=701" target="_blank">00:11:41.700</a></span> | <span class="t">learn the task that it's doing. And also to do those needle in a haystack things where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=709" target="_blank">00:11:49.740</a></span> | <span class="t">maybe some information early on in the sequence is relevant to something much later. So it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=716" target="_blank">00:11:56.720</a></span> | <span class="t">can keep that in memory. It's also a memory component. So this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=723" target="_blank">00:12:03.300</a></span> | <span class="t">thing that is responsible for generating representations for, you know, the information that is coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=733" target="_blank">00:12:13.800</a></span> | <span class="t">through it at inference time. And then let's see. The last bullet point about sequential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=743" target="_blank">00:12:23.220</a></span> | <span class="t">data handling. Yeah. So as I've been mentioning, like, we're assuming this is all happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=753" target="_blank">00:12:33.300</a></span> | <span class="t">in a sequence of tokens in the case of a large language model where it's processing one token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=761" target="_blank">00:12:41.820</a></span> | <span class="t">after another. It's not all at once. That's pretty -- pretty taken for granted for any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=771" target="_blank">00:12:51.680</a></span> | <span class="t">large language model. So let's keep going. So we'll dig into a few different aspects</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=782" target="_blank">00:13:02.240</a></span> | <span class="t">now of the long-term memory module. So here you can see some points. Let me pull out a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=795" target="_blank">00:13:15.960</a></span> | <span class="t">couple of them. One is this weight adjustments, which is, I think, one of the most interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=801" target="_blank">00:13:21.440</a></span> | <span class="t">things about the Titan's architecture. So for, like, almost all LLMs, or at least the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=809" target="_blank">00:13:29.500</a></span> | <span class="t">ones that I'm aware of, like a GPT-4, a Sonnet, Claude Sonnet, whatever, they do a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=819" target="_blank">00:13:39.040</a></span> | <span class="t">pre-training. They do, you know, instruction tuning, all of that. But once they're done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=825" target="_blank">00:13:45.680</a></span> | <span class="t">with that, then the weights are just the weights. And even if you think of, like, the deep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=831" target="_blank">00:13:51.320</a></span> | <span class="t">seek release last week, like, it was just a bunch of weights. So these don't -- these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=840" target="_blank">00:14:00.360</a></span> | <span class="t">don't adjust in memory, no matter what you put through the model. Whereas this Titan's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=847" target="_blank">00:14:07.160</a></span> | <span class="t">model, at least in the context of a single inference, can adjust weights on the long-term</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=854" target="_blank">00:14:14.080</a></span> | <span class="t">memory module, which I think makes it, like, a very interesting new approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=863" target="_blank">00:14:23.600</a></span> | <span class="t">And for the continuous adaptation, so that kind of plays off the weight adjustments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=872" target="_blank">00:14:32.320</a></span> | <span class="t">So that's something that, you know, as it's going through a long sequence of perhaps even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=878" target="_blank">00:14:38.440</a></span> | <span class="t">millions of tokens, it can continue to actually learn about, like, the data that it's processing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=891" target="_blank">00:14:51.240</a></span> | <span class="t">And that's another thing that they really emphasize in the paper, is creating a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=897" target="_blank">00:14:57.160</a></span> | <span class="t">of -- when I say model, I don't mean, like, a machine learning model. I mean, like, an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=901" target="_blank">00:15:01.960</a></span> | <span class="t">abstraction for learning. And what does that mean for a model to be able to learn?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=912" target="_blank">00:15:12.400</a></span> | <span class="t">So we've talked about how the model updates its weights based on the data that comes through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=923" target="_blank">00:15:23.460</a></span> | <span class="t">And so how does the model know, like, what is interesting, like, what is worth keeping,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=931" target="_blank">00:15:31.700</a></span> | <span class="t">and what isn't? Because it doesn't have enough parameters for long sequences to capture everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=939" target="_blank">00:15:39.040</a></span> | <span class="t">that comes into it. So it's going to have to compress whatever data is coming through.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=946" target="_blank">00:15:46.540</a></span> | <span class="t">So how does it decide how, like, what to remember and what not to? So this surprise mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=954" target="_blank">00:15:54.100</a></span> | <span class="t">is the main way that it does. So information that's considered surprising is for humans</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=966" target="_blank">00:16:06.520</a></span> | <span class="t">more memorable. And so they took the leap that for a model, it's also going to be more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=973" target="_blank">00:16:13.700</a></span> | <span class="t">memorable. Or more important to remember. I'm just looking through the slides. So, okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=985" target="_blank">00:16:25.300</a></span> | <span class="t">So the point is, well, how do we know if information is important or not? The main way they decide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=994" target="_blank">00:16:34.260</a></span> | <span class="t">that is the gradient of the neural network with respect to the input data. So you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1000" target="_blank">00:16:40.380</a></span> | <span class="t">see that -- hopefully you can see my mouse. But you can see that down here. The gradient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1005" target="_blank">00:16:45.840</a></span> | <span class="t">of this incoming input data with respect to the memory from the previous time step gives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1016" target="_blank">00:16:56.140</a></span> | <span class="t">us the amount of surprise. And it -- you can see it gives preferential treatment to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1024" target="_blank">00:17:04.620</a></span> | <span class="t">surprising information. The more surprising it is, the more likely it is to be stored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1030" target="_blank">00:17:10.140</a></span> | <span class="t">in memory. So you can imagine for, like, a long sequence of maybe documents, maybe there's,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1038" target="_blank">00:17:18.700</a></span> | <span class="t">I don't know, 100 documents that are all legal briefings. And then it comes to something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1047" target="_blank">00:17:27.780</a></span> | <span class="t">that is maybe a bill of lading or, you know, a product description or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1056" target="_blank">00:17:36.740</a></span> | <span class="t">So then it's going to be like, oh, this is completely different. I should remember something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1060" target="_blank">00:17:40.700</a></span> | <span class="t">about this. So it's going to prioritize keeping what it considers surprising or information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1070" target="_blank">00:17:50.640</a></span> | <span class="t">that it hasn't seen before. And then it stores this in key value pairs in that long-term</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1081" target="_blank">00:18:01.180</a></span> | <span class="t">memory module. So in addition to surprise, there's also forgetting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1094" target="_blank">00:18:14.820</a></span> | <span class="t">So I should have mentioned in the last slide that this data parameter here controls the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1106" target="_blank">00:18:26.340</a></span> | <span class="t">amount of, like, kind of the impact of surprise. So it's a tunable parameter that can be increased</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1117" target="_blank">00:18:37.220</a></span> | <span class="t">or decreased to either remember more surprising information or forget it. The momentum and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1126" target="_blank">00:18:46.860</a></span> | <span class="t">dynamic forgetting means that it can forget things so that it does discard irrelevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1135" target="_blank">00:18:55.220</a></span> | <span class="t">information as it goes along. So there's this, you can see this one over alpha where it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1145" target="_blank">00:19:05.060</a></span> | <span class="t">slowly degrading the older memory. So as things get older and older, they fade out. I heard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1156" target="_blank">00:19:16.860</a></span> | <span class="t">someone come off mute. Is there a question? >> Yeah. That MT parameter, is that the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1165" target="_blank">00:19:25.020</a></span> | <span class="t">of the memory module or the model itself? >> That is essentially the state of the memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1173" target="_blank">00:19:33.960</a></span> | <span class="t">module. >> Okay. And so the surprise has the same dimensions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1181" target="_blank">00:19:41.940</a></span> | <span class="t">the same form as the memory itself? >> Why don't we look in the paper after the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1192" target="_blank">00:19:52.260</a></span> | <span class="t">presentation and we can, or if you want to look at it. I can't answer that right off</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1200" target="_blank">00:20:00.220</a></span> | <span class="t">the bat. >> I would assume so because it's just a simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1204" target="_blank">00:20:04.060</a></span> | <span class="t">addition to it. And so kind of curious, I guess the origin of this is that, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1212" target="_blank">00:20:12.080</a></span> | <span class="t">they show different structures for how the memory was included and it's, like, added</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1217" target="_blank">00:20:17.440</a></span> | <span class="t">in different parts of the architecture stack, if you will. I'm kind of curious if that would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1225" target="_blank">00:20:25.920</a></span> | <span class="t">stay the same across their form of the architecture or if it changes depending on where the memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1235" target="_blank">00:20:35.200</a></span> | <span class="t">is included at. >> Yeah. That's an interesting question. I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1242" target="_blank">00:20:42.640</a></span> | <span class="t">going to go through the different architectures they introduce. So hopefully, I don't know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1250" target="_blank">00:20:50.860</a></span> | <span class="t">if that will answer the question, but at least it will give us enough context for discussion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1255" target="_blank">00:20:55.920</a></span> | <span class="t">I'm going to leave plenty of time for discussion, so this would be a good thing to talk about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1268" target="_blank">00:21:08.560</a></span> | <span class="t">And then it also has this momentum that, where it combines past surprise with a decay factor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1277" target="_blank">00:21:17.300</a></span> | <span class="t">So that's this eta t and I guess the previous surprise. So somehow this provides a momentum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1286" target="_blank">00:21:26.500</a></span> | <span class="t">mechanism to the model. Okay. So those are kind of the components that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1299" target="_blank">00:21:39.920</a></span> | <span class="t">go into a Titan's model. Now, let's look at the different ways they combine them because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1307" target="_blank">00:21:47.080</a></span> | <span class="t">there was this open question of, like, okay, we have this module that we think would be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1314" target="_blank">00:21:54.600</a></span> | <span class="t">useful for the model. Like, let's see what's the best way to then incorporate that. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1326" target="_blank">00:22:06.040</a></span> | <span class="t">they come up with three different options. Memory as context, memory as layer, and memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1334" target="_blank">00:22:14.380</a></span> | <span class="t">as gated branch. And each one of these has their strengths and weaknesses. So let's first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1343" target="_blank">00:22:23.600</a></span> | <span class="t">look at the memory as context. And I'll just walk through this diagram a little bit. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1352" target="_blank">00:22:32.900</a></span> | <span class="t">we can start looking over here at the -- this is the input sequence. So this is essentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1359" target="_blank">00:22:39.060</a></span> | <span class="t">your prompt or what you are sending into the model. This is then used as a key or a query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1368" target="_blank">00:22:48.200</a></span> | <span class="t">-- I guess a query into the memory module that then returns, like, the most relevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1381" target="_blank">00:23:01.360</a></span> | <span class="t">information from the memory as a sequence of tokens. And then at the same time step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1393" target="_blank">00:23:13.120</a></span> | <span class="t">you can see this is the persistent memory. So this is kind of the hard-coded information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1397" target="_blank">00:23:17.860</a></span> | <span class="t">that just always has the same token that adds to the sequence. So you can see that before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1405" target="_blank">00:23:25.960</a></span> | <span class="t">we go to attention, we're adding these extra sequences. So in my previous example of, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1416" target="_blank">00:23:36.800</a></span> | <span class="t">legal documents and maybe a product description, the retrieval could say, like, okay, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1426" target="_blank">00:23:46.920</a></span> | <span class="t">sequence looks like -- or this next part of the sequence looks like a legal document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1432" target="_blank">00:23:52.400</a></span> | <span class="t">So let's grab any information we have about the legal documents, put it here. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1439" target="_blank">00:23:59.160</a></span> | <span class="t">this persistent memory might just be about how to generally handle incoming requests,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1445" target="_blank">00:24:05.960</a></span> | <span class="t">something like that. It goes through attention. So this is the quadratic thing where every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1452" target="_blank">00:24:12.160</a></span> | <span class="t">token pays attention to every other token. It then, based on the output, sends an update</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1460" target="_blank">00:24:20.000</a></span> | <span class="t">to the memory, so updates the actual weights here with whatever relevant information came</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1467" target="_blank">00:24:27.640</a></span> | <span class="t">out. Then I'm not sure what this is. Some kind of -- maybe an XOR combines these and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1478" target="_blank">00:24:38.520</a></span> | <span class="t">then gives you the final output. And so this is what the attention masks look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1491" target="_blank">00:24:51.160</a></span> | <span class="t">like for memory as context. You can see that each one of these is treated as, like, a small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1501" target="_blank">00:25:01.440</a></span> | <span class="t">context window. So it's, like, kind of little batches of tokens being paid attention to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1514" target="_blank">00:25:14.720</a></span> | <span class="t">together. Then we add the long-term memory onto that. And then finally the persistent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1522" target="_blank">00:25:22.840</a></span> | <span class="t">memory. And so this kind of gives you an idea of, like, inside the attention mechanism,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1531" target="_blank">00:25:31.040</a></span> | <span class="t">what exactly it's seeing. And next, memory as gate. So this is a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1544" target="_blank">00:25:44.560</a></span> | <span class="t">approach. It does not, like, query the memory before sending it into the attention mechanism.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1557" target="_blank">00:25:57.200</a></span> | <span class="t">So it sends a query to the memory at the same time as going through the attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1566" target="_blank">00:26:06.280</a></span> | <span class="t">and then combines them afterwards. And so the memory -- like, whatever is stored in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1573" target="_blank">00:26:13.880</a></span> | <span class="t">the memory does not go through the attention mechanism at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1584" target="_blank">00:26:24.080</a></span> | <span class="t">Yeah. So this is -- this uses the memory as a gating mechanism. I guess right here. Which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1598" target="_blank">00:26:38.080</a></span> | <span class="t">I guess would allow -- I'm assuming allow certain tokens through and some tokens not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1605" target="_blank">00:26:45.960</a></span> | <span class="t">We can discuss this in the discussion about exactly how this works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1615" target="_blank">00:26:55.080</a></span> | <span class="t">And then here's the attention masks for the memory as gate. You can see it's quite different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1624" target="_blank">00:27:04.320</a></span> | <span class="t">Here this is a sliding window that, you know, each token pays attention to a certain number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1632" target="_blank">00:27:12.980</a></span> | <span class="t">of tokens on each side of it. You can see the long-term memory, how next to the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1641" target="_blank">00:27:21.600</a></span> | <span class="t">sequence the memory is strong. And then it gradually fades out as the tokens are, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1653" target="_blank">00:27:33.720</a></span> | <span class="t">know, further in the future, if you will. And then finally, the persistent memory just,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1660" target="_blank">00:27:40.800</a></span> | <span class="t">like, adds to the very front of the sequence. This is what the attention masks look like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1668" target="_blank">00:27:48.080</a></span> | <span class="t">in the memory as gate. And then finally, memory as layer. So this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1677" target="_blank">00:27:57.720</a></span> | <span class="t">is in some ways similar to what some transformer models do, where they have the attention mechanism</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1687" target="_blank">00:28:07.360</a></span> | <span class="t">and then there's a feedforward mechanism as well. So this is, like, the closest thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1694" target="_blank">00:28:14.120</a></span> | <span class="t">to that, where it just goes right into the memory, whatever comes out of the memory goes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1702" target="_blank">00:28:22.880</a></span> | <span class="t">into the attention. Yeah, and it says the, can I take advantage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1712" target="_blank">00:28:32.100</a></span> | <span class="t">of the complementary data processing of intention in the neural memory module so there's no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1719" target="_blank">00:28:39.760</a></span> | <span class="t">combining after either before or after. It's just, like, one more step in the architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1734" target="_blank">00:28:54.640</a></span> | <span class="t">And then finally, the, they also, in their experimentation, look at memory without attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1742" target="_blank">00:29:02.480</a></span> | <span class="t">So this is essentially just a long-term memory module by itself. There's no attention mechanism.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1751" target="_blank">00:29:11.000</a></span> | <span class="t">And they just look at, like, how does this perform? Just purely a long-term memory module</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1757" target="_blank">00:29:17.040</a></span> | <span class="t">without attention or anything. Okay. So now we're getting into the last part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1766" target="_blank">00:29:26.920</a></span> | <span class="t">of the paper, the experimental setup and results. So they test all four of these variants and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1776" target="_blank">00:29:36.680</a></span> | <span class="t">they test them at different sizes. And I thought one thing that was interesting is that these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1782" target="_blank">00:29:42.400</a></span> | <span class="t">are pretty small sizes, at least compared to, you know, your current, your modern LLM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1790" target="_blank">00:29:50.840</a></span> | <span class="t">So, like, a LLAMA7B is considered a smaller model. And if you look at, like, a, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1804" target="_blank">00:30:04.480</a></span> | <span class="t">like a GPT4O that has probably hundreds of billions of parameters. So this size is pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1813" target="_blank">00:30:13.320</a></span> | <span class="t">tiny compared to, like, the models we use day to day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1824" target="_blank">00:30:24.400</a></span> | <span class="t">So they gave a big table of their results for language modeling. And they also threw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1832" target="_blank">00:30:32.440</a></span> | <span class="t">some common sense reasoning benchmarks into here. So you can see all the benchmark names</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1839" target="_blank">00:30:39.240</a></span> | <span class="t">across the top. And then the best performing ones are highlighted. The tan highlights are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1848" target="_blank">00:30:48.820</a></span> | <span class="t">for hybrids. And then the blue highlights are for pure or just, like, normal. Or yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1860" target="_blank">00:31:00.560</a></span> | <span class="t">So you can see that basically Titans wins at everything here versus Mamba, Deltanet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1871" target="_blank">00:31:11.440</a></span> | <span class="t">This is test at the time of -- or no. Anyway, this is one of the previous works of memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1879" target="_blank">00:31:19.000</a></span> | <span class="t">testing. So you can see that it wins at everything. This is for the 340 million parameter model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1890" target="_blank">00:31:30.200</a></span> | <span class="t">And you can also see the number of tokens they train on is pretty small. Modern LLMs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1898" target="_blank">00:31:38.360</a></span> | <span class="t">train on, like, low trillions of tokens. So this is not much data at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1906" target="_blank">00:31:46.800</a></span> | <span class="t">Then -- so you can see, like, language modeling, it does quite well. And then here's their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1918" target="_blank">00:31:58.240</a></span> | <span class="t">LLNA Haystack. So for this test, they had some information early on in a sequence. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1926" target="_blank">00:32:06.200</a></span> | <span class="t">then a bunch of, like, filler tokens. And then some sequence that needed those very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1934" target="_blank">00:32:14.760</a></span> | <span class="t">early tokens. Like, to understand what was happening. And so you can -- the Titans is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1943" target="_blank">00:32:23.560</a></span> | <span class="t">the red stars here. So you can see that they are maintaining their performance quite well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1951" target="_blank">00:32:31.400</a></span> | <span class="t">Even out to -- here, if we go to the fine-tuning setup, 10 to the 7th. So even out to 10 million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1959" target="_blank">00:32:39.000</a></span> | <span class="t">tokens. I mean, they did take a performance hit. But still doing much better than every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1967" target="_blank">00:32:47.000</a></span> | <span class="t">other model. And so I think this is, for me, one of the most interesting charts that just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1974" target="_blank">00:32:54.160</a></span> | <span class="t">shows that as this becomes more productionalized, there's going to be the opportunity to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1981" target="_blank">00:33:01.600</a></span> | <span class="t">longer and longer context windows where maybe you can feed in, like, a bunch of YouTube</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1987" target="_blank">00:33:07.960</a></span> | <span class="t">videos, like, hundreds of pages of PDFs, and all this stuff, and still have it be -- give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=1996" target="_blank">00:33:16.520</a></span> | <span class="t">you, like, relevant output. So with that, that is the end of my presentation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2006" target="_blank">00:33:26.720</a></span> | <span class="t">So let me pop open the chat here. See what's going on. And if anyone wants to speak up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2021" target="_blank">00:33:41.960</a></span> | <span class="t">make comments, make any corrections to what I said, like, I'm not an expert in this, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2029" target="_blank">00:33:49.540</a></span> | <span class="t">I'm also not an AI researcher. So if you have insights, would love to hear those. And also,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2037" target="_blank">00:33:57.880</a></span> | <span class="t">if anyone has answers to questions, feel free to chime in. Again, like, I'm not the expert</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2045" target="_blank">00:34:05.320</a></span> | <span class="t">on this paper. Like, I read it and understand it. But I know there's a bunch of very smart</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2051" target="_blank">00:34:11.060</a></span> | <span class="t">people on this call. So with that, I'll open up the floor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2058" target="_blank">00:34:18.860</a></span> | <span class="t">>> I can also help with questions, but I'm struggling with the chat window.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2073" target="_blank">00:34:33.720</a></span> | <span class="t">>> Yeah, I mean, I want to validate Cosmin's frustration with this paper. Yeah, I mean,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2080" target="_blank">00:34:40.680</a></span> | <span class="t">look, like, I think they did try to illustrate the memory mechanisms somewhat, but not super</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2087" target="_blank">00:34:47.640</a></span> | <span class="t">-- it's not super clear. And I always wish that these things came with code. I really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2093" target="_blank">00:34:53.520</a></span> | <span class="t">like the name of papers with code, because this one needed code. And, you know, maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2099" target="_blank">00:34:59.360</a></span> | <span class="t">they released it, but I didn't see it in the inside of the paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2103" target="_blank">00:35:03.360</a></span> | <span class="t">>> They said at the very bottom of the paper that they're planning to release code soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2107" target="_blank">00:35:07.840</a></span> | <span class="t">>> How Chinese of them? >> Whatever that means.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2111" target="_blank">00:35:11.960</a></span> | <span class="t">>> Yeah, I didn't understand if the diagrams refer to one step or multiple steps. Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2118" target="_blank">00:35:18.560</a></span> | <span class="t">I think -- and also, the diagrams are 3D, which makes it a bit more confusing. Like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2125" target="_blank">00:35:25.440</a></span> | <span class="t">they say when you update the memory, you do memory of query, and then you get, like, vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2131" target="_blank">00:35:31.200</a></span> | <span class="t">as output. What does that mean? Is that k-nearest neighbor lookup? Is it some attention? Maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2138" target="_blank">00:35:38.520</a></span> | <span class="t">we can go to the first slide, where they update the memory equation. I don't know, Eugene,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2144" target="_blank">00:35:44.320</a></span> | <span class="t">if you got time to -- got any time to look, but I would be interested in just one of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2150" target="_blank">00:35:50.920</a></span> | <span class="t">operations, how does it actually happen? Like, I understand at the high level, we have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2155" target="_blank">00:35:55.840</a></span> | <span class="t">memory module, we update, it's nice to forget, they somehow figured it out, but, like, what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2161" target="_blank">00:36:01.600</a></span> | <span class="t">layers or what do they actually do? Like, even lower, you have some -- if you go a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2168" target="_blank">00:36:08.940</a></span> | <span class="t">lower. Yeah, you see -- >> Retrieving memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2175" target="_blank">00:36:15.400</a></span> | <span class="t">>> Yeah, what does that -- maybe I didn't read or, like, even this figure one, I didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2182" target="_blank">00:36:22.480</a></span> | <span class="t">understand at all what's going on. >> Yeah, I also skipped this, because I didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2188" target="_blank">00:36:28.520</a></span> | <span class="t">understand what was going on. >> I can explain the in-context learning one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2198" target="_blank">00:36:38.360</a></span> | <span class="t">with -- and I can -- with the parallels of what happens on RWKB7 and Titan, based on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2206" target="_blank">00:36:46.520</a></span> | <span class="t">what I understood from the paper. So, think of it as this way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2211" target="_blank">00:36:51.840</a></span> | <span class="t">>> Which figure? >> This whole segment, the long-term memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2217" target="_blank">00:36:57.040</a></span> | <span class="t">training and the surprise formula. It's actually a lot easier if you explain it using simplified</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2225" target="_blank">00:37:05.280</a></span> | <span class="t">-- >> Do you mind saying which? So, like, we read</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2227" target="_blank">00:37:07.440</a></span> | <span class="t">while you explain. No, this is great, like, having an expert explain it, but which figure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2232" target="_blank">00:37:12.120</a></span> | <span class="t">is it or which formula? >> So, you scroll up. I'm trying to, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2238" target="_blank">00:37:18.440</a></span> | <span class="t">figure out the page numbers as well. So, we are talking about, very specifically, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2244" target="_blank">00:37:24.520</a></span> | <span class="t">segment tree 3.1 and the surprise metric there, downwards, that whole memory architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2252" target="_blank">00:37:32.280</a></span> | <span class="t">So, one way to view it, right, is that -- let's just say a standard problem. Let's say the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2259" target="_blank">00:37:39.480</a></span> | <span class="t">quick brown fox, correct? And this is -- this is a piece of text that exists in so many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2264" target="_blank">00:37:44.480</a></span> | <span class="t">training corpus that all LLMs will probably memorize this phrase itself, the quick brown</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2268" target="_blank">00:37:48.960</a></span> | <span class="t">fox. There is no surprise there. So, because the surprise score is zero, there is no -- there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2276" target="_blank">00:37:56.440</a></span> | <span class="t">no back propagation required, per se, to update the memories.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2281" target="_blank">00:38:01.560</a></span> | <span class="t">If you view the memories as, let's just say, a 4,000 -- I don't know what the dimensions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2287" target="_blank">00:38:07.720</a></span> | <span class="t">are here, because they never disclose, but let's just say a 4,000 by 4,000, 4096 floating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2293" target="_blank">00:38:13.120</a></span> | <span class="t">point value, in our case, it's BF16. If, let's say, we said the quick brown deer, then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2304" target="_blank">00:38:24.480</a></span> | <span class="t">model is like, hey, I wasn't expecting deer, I'm expecting fox. There's a difference there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2310" target="_blank">00:38:30.000</a></span> | <span class="t">That difference there -- I'm oversimplifying the math, because this is not accurate -- can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2314" target="_blank">00:38:34.480</a></span> | <span class="t">be converted to a loss score that you can back propagate on. So, it's when you see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2319" target="_blank">00:38:39.720</a></span> | <span class="t">when the models see differences, do you update this memory, this memory that's being shared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2325" target="_blank">00:38:45.200</a></span> | <span class="t">between tokens? Now, where it differs for the Google paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2330" target="_blank">00:38:50.520</a></span> | <span class="t">Python and RWKB, which we are testing as well, is that the --</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2334" target="_blank">00:38:54.200</a></span> | <span class="t">>> Eugene, so you have a separate key value store that you attend at the same time as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2341" target="_blank">00:39:01.400</a></span> | <span class="t">you attend the current token. So, that's your budget, right? And you attend the whole thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2348" target="_blank">00:39:08.980</a></span> | <span class="t">okay? And does that help or doesn't it help? And when it's surprising, you need to update.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2355" target="_blank">00:39:15.920</a></span> | <span class="t">So I wonder how they send the updates to the key value store. Like, what actually happens?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2361" target="_blank">00:39:21.640</a></span> | <span class="t">Like, what's the loss of the key value store and the current token? Go ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2366" target="_blank">00:39:26.040</a></span> | <span class="t">>> So if you want to view it as simplified code, which is not how they implement it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2371" target="_blank">00:39:31.320</a></span> | <span class="t">because -- is that you can view your model weights during the forward pass, right, as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2377" target="_blank">00:39:37.200</a></span> | <span class="t">frozen, just view as frozen. And the -- so, the quick brown, let's say the quick brown,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2384" target="_blank">00:39:44.200</a></span> | <span class="t">those tokens, right, generate a state. You take that state, and then let's say instead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2390" target="_blank">00:39:50.040</a></span> | <span class="t">of -- let's say we see fox, and then we say deer instead, right? There's a difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2395" target="_blank">00:39:55.080</a></span> | <span class="t">in expectation. The model expected fox, it got deer instead. So because the model weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2402" target="_blank">00:40:02.760</a></span> | <span class="t">are frozen, if you do the forward pass and then you want to correct the model's thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2406" target="_blank">00:40:06.880</a></span> | <span class="t">and you do the backwards pass, the only way to update it is this state value. So you do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2412" target="_blank">00:40:12.200</a></span> | <span class="t">the backwards pass, you update the state values, then you take that state and you go -- you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2417" target="_blank">00:40:17.440</a></span> | <span class="t">process the next token. So you continue your sentence completion. And that essentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2422" target="_blank">00:40:22.640</a></span> | <span class="t">is what the surprise mechanic is about. It's about, hey, it didn't give the output we required,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2431" target="_blank">00:40:31.760</a></span> | <span class="t">and then we take that difference and then we convert it into a score. Where this differs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2439" target="_blank">00:40:39.360</a></span> | <span class="t">from RWKB is that we don't use a surprise mechanism. We are currently using more closer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2447" target="_blank">00:40:47.400</a></span> | <span class="t">to the standard gradient descent. So the difference here is that in a surprise mechanism, so if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2454" target="_blank">00:40:54.840</a></span> | <span class="t">let's say you expected fox and you get fox, for example, there's no -- the loss is essentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2461" target="_blank">00:41:01.920</a></span> | <span class="t">zero. There's no backprop. But in RWKB's case, right, if let's say that you -- it expected</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2470" target="_blank">00:41:10.640</a></span> | <span class="t">fox and it actually got the fox, and since the way logics work, there's always a zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2475" target="_blank">00:41:15.800</a></span> | <span class="t">point -- let's just say a zero point something percent difference, there's still a loss score</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2479" target="_blank">00:41:19.960</a></span> | <span class="t">being calculated there. So even though it was not a surprise, we still do the backpropagation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2484" target="_blank">00:41:24.200</a></span> | <span class="t">process. In practice, is this better or worse? I have absolutely no idea. This is something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2488" target="_blank">00:41:28.760</a></span> | <span class="t">we need to test and evaluate on. But that's the key difference on how we handle the memories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2494" target="_blank">00:41:34.040</a></span> | <span class="t">segment. It's all about, like, every token you forward, you backprop and then you update</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2501" target="_blank">00:41:41.200</a></span> | <span class="t">the weights. This is -- >> You just -- instead of you propagate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2508" target="_blank">00:41:48.240</a></span> | <span class="t">signal through the frozen weights and just update the keys and values. One question that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2513" target="_blank">00:41:53.200</a></span> | <span class="t">I got was how do they manage a fixed size key value store? Basically, how do they decide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2522" target="_blank">00:42:02.080</a></span> | <span class="t">what to drop and stuff? And they have this -- I didn't understand their gating in here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2529" target="_blank">00:42:09.440</a></span> | <span class="t">But basically, yeah, over time, you'll see lots and lots and lots of things. So you kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2534" target="_blank">00:42:14.480</a></span> | <span class="t">of need to figure out, like, if you're efficiently using your memory, then you solve the problem,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2541" target="_blank">00:42:21.160</a></span> | <span class="t">basically. >> So this goes to the AI black box. We decide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2546" target="_blank">00:42:26.080</a></span> | <span class="t">the key value store to a specific size. That's part of the architecture design. This is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2550" target="_blank">00:42:30.600</a></span> | <span class="t">same thing as the model dimensions as to how the model decides what to keep and drop, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2557" target="_blank">00:42:37.000</a></span> | <span class="t">That is specifically decided by the model. So I think one -- there's another segment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2564" target="_blank">00:42:44.840</a></span> | <span class="t">where it highlights the decay, right? Let me find that segment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2568" target="_blank">00:42:48.080</a></span> | <span class="t">>> Could you scroll a bit down? >> Sorry if I'm not looking at the screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2572" target="_blank">00:42:52.800</a></span> | <span class="t">I'm looking at the paper to just find the decay. I think it was mentioned --</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2578" target="_blank">00:42:58.080</a></span> | <span class="t">>> Yeah, it's a forgetting mechanism. Sorry. It's equation, yeah, 13.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2587" target="_blank">00:43:07.960</a></span> | <span class="t">>> Yeah, so the idea behind the decay mechanism, right, and this part is consistent with other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2594" target="_blank">00:43:14.600</a></span> | <span class="t">theories, is that by default, every token you move forward, you are slowly forgetting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2603" target="_blank">00:43:23.400</a></span> | <span class="t">And the forget rate is something that's trained in the model. So let's just say the value</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2609" target="_blank">00:43:29.520</a></span> | <span class="t">is by default, everything you will forget in 32K tokens. So if you forward 32K, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2616" target="_blank">00:43:36.880</a></span> | <span class="t">should forget it. This makes it sound similar to sliding window attention in that sense,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2622" target="_blank">00:43:42.280</a></span> | <span class="t">but the decay mechanism is supposed to work together with the -- with, let's say, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2628" target="_blank">00:43:48.240</a></span> | <span class="t">surprise mechanism or basically the model's -- this is a bit more gray, but basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2636" target="_blank">00:43:56.080</a></span> | <span class="t">as the -- by default, you decay. You let the model compute against the state itself. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2641" target="_blank">00:44:01.720</a></span> | <span class="t">the model may just decide, hey, this is important to memorize, so I'm going to reinforce that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2647" target="_blank">00:44:07.040</a></span> | <span class="t">number. So as every step it takes, right, in a way, internally the model just, like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2653" target="_blank">00:44:13.000</a></span> | <span class="t">keeps backpropagating against the state and think, hey, do I need to reinforce this floating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2658" target="_blank">00:44:18.120</a></span> | <span class="t">point value? If I stop reinforcing, it will eventually decay, but if I want to reinforce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2663" target="_blank">00:44:23.640</a></span> | <span class="t">it, I can just, like, keep increasing the value and then keeping it within bounds. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2669" target="_blank">00:44:29.080</a></span> | <span class="t">that's how it keeps -- kind of, like, by default, it will slowly forget, but if it thinks it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2674" target="_blank">00:44:34.280</a></span> | <span class="t">important, it will keep trying to remember it over larger context time. To be clear,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2678" target="_blank">00:44:38.400</a></span> | <span class="t">this is -- this part is really theorycrafting, because even for RWKB, the highest we ever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2684" target="_blank">00:44:44.600</a></span> | <span class="t">push a model to is 32K, and we are now experimenting at 64K. This theorycrafting is supposed to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2690" target="_blank">00:44:50.400</a></span> | <span class="t">like, extend to, like, 1 million token per se. So it's something that we definitely need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2698" target="_blank">00:44:58.440</a></span> | <span class="t">to test. But the idea behind decay is so that by default, things will expire, and so the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2704" target="_blank">00:45:04.320</a></span> | <span class="t">model is able to clear up space to memorize new things, and it's able to also decide for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2709" target="_blank">00:45:09.320</a></span> | <span class="t">itself to keep things in memory. Not much different from how they describe it in Python.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2714" target="_blank">00:45:14.800</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2715" target="_blank">00:45:15.800</a></span> | <span class="t">>> Thanks a lot. This helped me quite a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2719" target="_blank">00:45:19.640</a></span> | <span class="t">>> Eugene, I have a question. So when you're referring to by default it decays, so in terms</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2726" target="_blank">00:45:26.760</a></span> | <span class="t">of the surprise here, can we assume that the surprise by default is low for most of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2732" target="_blank">00:45:32.040</a></span> | <span class="t">tokens?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2736" target="_blank">00:45:36.200</a></span> | <span class="t">>> I think view it as -- let's just say -- let's just view it as a wreck scenario. A wreck</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2743" target="_blank">00:45:43.840</a></span> | <span class="t">scenario. Let's just say your company is the most generic company on Earth, and then I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2749" target="_blank">00:45:49.080</a></span> | <span class="t">just put your company document there. There is no surprise. Then it just moves on. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2754" target="_blank">00:45:54.960</a></span> | <span class="t">let's just say your company has some very proprietary, never-heard-before stuff. That</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2759" target="_blank">00:45:59.720</a></span> | <span class="t">surprise will then be what is stored. So it's about the difference in information in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2768" target="_blank">00:46:08.200</a></span> | <span class="t">fixed model weights compared to this floating-point state. Does that make sense?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2777" target="_blank">00:46:17.600</a></span> | <span class="t">>> Is there another -- I'm trying to read the questions from the chat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2794" target="_blank">00:46:34.480</a></span> | <span class="t">>> Yeah. There's another one from Cosmin earlier about our needle in the haystack's interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2802" target="_blank">00:46:42.720</a></span> | <span class="t">tasks. I mean, I think they could be in real use cases. There's probably a lot where they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2810" target="_blank">00:46:50.800</a></span> | <span class="t">not. But depending on your use case, I could see how if you just want to throw a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2818" target="_blank">00:46:58.560</a></span> | <span class="t">of tokens into the model and not worry about the order or anything, that it would be useful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2826" target="_blank">00:47:06.560</a></span> | <span class="t">to have.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2827" target="_blank">00:47:07.560</a></span> | <span class="t">>> I think it's interesting also academically to just understand the maximum limit the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2835" target="_blank">00:47:15.840</a></span> | <span class="t">can memorize in worst-case scenario. That's the way I view needle in the haystack. In</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2841" target="_blank">00:47:21.320</a></span> | <span class="t">practical scenarios, that was one of the challenges about RWKB benchmarking this as well, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2849" target="_blank">00:47:29.800</a></span> | <span class="t">the same thing for Titan, is that if, let's say, we train on Harry Potter book and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2855" target="_blank">00:47:35.440</a></span> | <span class="t">just put the whole Harry Potter book as the right context, there's no surprise there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2863" target="_blank">00:47:43.640</a></span> | <span class="t">And essentially, it can pass the right test with, what, 300k context length. But that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2870" target="_blank">00:47:50.160</a></span> | <span class="t">not a correct test, per se. So needle in the haystack is meant to represent the worst-case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2874" target="_blank">00:47:54.000</a></span> | <span class="t">scenario. That's how I feel. And a lot of companies are a lot more generic than they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2879" target="_blank">00:47:59.960</a></span> | <span class="t">think they are. Also, I think in NeurIPS, the joint presentation that we did with Dan</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2888" target="_blank">00:48:08.120</a></span> | <span class="t">Fu, both him and I agree that with other techniques, such as repeating twice, that works well for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2898" target="_blank">00:48:18.020</a></span> | <span class="t">both Mamba and RWKB, is that we may want to re-evaluate how we benchmark these things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2903" target="_blank">00:48:23.520</a></span> | <span class="t">per se, when it comes to practical, right situations. Because if, let's say, the inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2909" target="_blank">00:48:29.040</a></span> | <span class="t">cost for Mamba and RWKB is 100,000x cheaper, and it's right performance triples or quadruples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2919" target="_blank">00:48:39.280</a></span> | <span class="t">just by repeating the context twice, so then we just repeat the context twice. That was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2926" target="_blank">00:48:46.200</a></span> | <span class="t">one of the arguments. And I kind of agree, but it's also a very different test.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2932" target="_blank">00:48:52.360</a></span> | <span class="t">I see there's another question, Eugene, that you'd be good at answering is, what is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2944" target="_blank">00:49:04.360</a></span> | <span class="t">gating mechanism in modern RNNs?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2947" target="_blank">00:49:07.120</a></span> | <span class="t">What do you mean by modern RNNs?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2951" target="_blank">00:49:11.800</a></span> | <span class="t">I don't know. Aditya, do you want to clarify?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2955" target="_blank">00:49:15.840</a></span> | <span class="t">Yeah, this sentence is on the paper right in front of us. It says Dow and Gu, 2024,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2962" target="_blank">00:49:22.120</a></span> | <span class="t">or Vietor et al., 2023. It's a comparison of the weight decay mechanism. So I just have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2970" target="_blank">00:49:30.640</a></span> | <span class="t">no confidence that RNNs normally do. That's relatable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2975" target="_blank">00:49:35.440</a></span> | <span class="t">Oh, okay. Later in the section, we show that the weight decay mechanism is closely related</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=2992" target="_blank">00:49:52.800</a></span> | <span class="t">to the gating mechanism in RNNs Dow and Gu, citing, I presume, the Mamba star? Yeah, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3002" target="_blank">00:50:02.240</a></span> | <span class="t">the state space model, yeah. It's, I think, the state space model. This would be similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3008" target="_blank">00:50:08.080</a></span> | <span class="t">to the weight decay that I explained earlier, which is basically, by default, it's for gating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3019" target="_blank">00:50:19.080</a></span> | <span class="t">My understanding of Mamba is that they run these RNNs without gates, so that they can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3025" target="_blank">00:50:25.400</a></span> | <span class="t">run something like Fast Fourier Transform or some parallel scan on GPUs and run it fast.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3031" target="_blank">00:50:31.200</a></span> | <span class="t">And then they have some multiplicative process on each token. And when you do multiplications,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3037" target="_blank">00:50:37.840</a></span> | <span class="t">basically, you can use them as gates to how much of the signal you propagate. So they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3042" target="_blank">00:50:42.680</a></span> | <span class="t">add the nonlinearity and gating at token level, while old school LSTM, they had memory gate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3051" target="_blank">00:50:51.160</a></span> | <span class="t">for get gate, input gate at each step, and they were running it one by one. So it might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3058" target="_blank">00:50:58.240</a></span> | <span class="t">be, that might be one thing, like this token level multiplicative things that people have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3065" target="_blank">00:51:05.960</a></span> | <span class="t">in state space models. Yeah, if it's about that, then it's really more about how we restructure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3073" target="_blank">00:51:13.020</a></span> | <span class="t">So both Mamba and RWBKB and Titan, is that with the way we restructure the formulation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3078" target="_blank">00:51:18.880</a></span> | <span class="t">we do not need to wait for one token compared to another, unlike the old LSTM. So yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3087" target="_blank">00:51:27.160</a></span> | <span class="t">I think that makes sense. Yeah, actually I think your explanation makes more sense. Basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3091" target="_blank">00:51:31.440</a></span> | <span class="t">if you contrast it with the old LSTM RNNs, all the newer gates, even though we are designed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3096" target="_blank">00:51:36.200</a></span> | <span class="t">differently, is designed in a way that doesn't have this bottleneck, where you need to wait</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3101" target="_blank">00:51:41.880</a></span> | <span class="t">for one token after another. Whether is it through math hacks, which is what state space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3110" target="_blank">00:51:50.040</a></span> | <span class="t">model did, which is really impressive, honestly, that kind of math. But that's what they are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3116" target="_blank">00:51:56.760</a></span> | <span class="t">good at. And in our case, it's really more of like how we optimize things in the QDAR</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3121" target="_blank">00:52:01.240</a></span> | <span class="t">forward. It achieves the same result. It's able to train in parallel, unlike old RNNs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3130" target="_blank">00:52:10.720</a></span> | <span class="t">And I'm quite sure Google has their own optimization when it comes to training as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3137" target="_blank">00:52:17.680</a></span> | <span class="t">I have another question, Eugene, for you. I don't know how to compare baselines with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3144" target="_blank">00:52:24.840</a></span> | <span class="t">this model. Are you impressed with one point perplexity win on wiki or the other wins?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3151" target="_blank">00:52:31.640</a></span> | <span class="t">Or it's kind of any new model usually shows that kind of win. So to me, the win seem large.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3160" target="_blank">00:52:40.440</a></span> | <span class="t">So I think, is this something super strong or it's OK, not great?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3168" target="_blank">00:52:48.480</a></span> | <span class="t">To be honest, I classify this in promising, but we need to test further, because even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3174" target="_blank">00:52:54.120</a></span> | <span class="t">in our experience for RWKB, anything below 1.5B may not necessarily hold until 7B situation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3189" target="_blank">00:53:09.420</a></span> | <span class="t">So we had reverted experimental changes where we made on 0.5B models, which is kind of what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3195" target="_blank">00:53:15.480</a></span> | <span class="t">being tested here. Here is 340 to 760 million parents, where the perplexity loss was great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3201" target="_blank">00:53:21.680</a></span> | <span class="t">It dropped much lower. And then when we scale it to 1.5B, it sucked.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3209" target="_blank">00:53:29.940</a></span> | <span class="t">So it's promising, but I want to test to find out more, because I think the true test is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3217" target="_blank">00:53:37.880</a></span> | <span class="t">testing on 1.5B and then 7B, which, to be honest, I'm quite sure the Google folks have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3225" target="_blank">00:53:45.240</a></span> | <span class="t">done it. They are not compute bound. It takes more effort for them to write this paper than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3229" target="_blank">00:53:49.440</a></span> | <span class="t">to train that 1.5B and 7B model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3232" target="_blank">00:53:52.000</a></span> | <span class="t">Yeah, I'm a bit skeptical, because there's some gossip that Googlers aren't allowed to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3237" target="_blank">00:53:57.580</a></span> | <span class="t">publish super impactful stuff. So it's interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3243" target="_blank">00:54:03.520</a></span> | <span class="t">Yeah. I also would like to know what was your results for the larger models?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3250" target="_blank">00:54:10.200</a></span> | <span class="t">Yeah, I mean, I guess that's one interesting thing, is that back in 2018, the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3257" target="_blank">00:54:17.480</a></span> | <span class="t">is all you need days, Google researchers could publish anything they wanted, because there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3262" target="_blank">00:54:22.640</a></span> | <span class="t">was really no competitive advantage they were giving away. But these days, you wonder, if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3270" target="_blank">00:54:30.360</a></span> | <span class="t">they have a really big breakthrough, are they going to publish that, or are they just going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3274" target="_blank">00:54:34.900</a></span> | <span class="t">to keep it to themselves?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3278" target="_blank">00:54:38.600</a></span> | <span class="t">I have another question. Sorry, if someone could explain. The memory module is described</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3284" target="_blank">00:54:44.140</a></span> | <span class="t">as a meta-in-context model. In quasi-layman's terms, what would a meta-in-context model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3289" target="_blank">00:54:49.920</a></span> | <span class="t">mean? There's like a sort of a parallel small model running on that, as if it was trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3295" target="_blank">00:54:55.920</a></span> | <span class="t">very quickly?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3298" target="_blank">00:54:58.100</a></span> | <span class="t">So that's the part where I explained every time the tokens look different from what you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3303" target="_blank">00:55:03.840</a></span> | <span class="t">expected, it does the back propagation to the memory modules. So you can think of it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3308" target="_blank">00:55:08.360</a></span> | <span class="t">as a-- I'm oversimplifying the math calling back propagation. You can think of it as training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3314" target="_blank">00:55:14.880</a></span> | <span class="t">the memory modules. It's inefficient to do it that way, because we use matrix multiplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3321" target="_blank">00:55:21.680</a></span> | <span class="t">math dedicated for this. But in theory, you could implement it as your standard backprop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3328" target="_blank">00:55:28.520</a></span> | <span class="t">gradient descent, at least for RWQ case. I mainly double-check for Google's case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3335" target="_blank">00:55:35.780</a></span> | <span class="t">But the important thing is it runs at inference time. So it's like it always backpropagates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3342" target="_blank">00:55:42.760</a></span> | <span class="t">something, which is very different from other models that are trained in a big pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3348" target="_blank">00:55:48.360</a></span> | <span class="t">run, and then nothing changes. You just run inference. So it's kind of meta-learning that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3354" target="_blank">00:55:54.280</a></span> | <span class="t">at inference time, it still does some additional update.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3359" target="_blank">00:55:59.280</a></span> | <span class="t">Yeah, the long-term hope and goal, if we can get this process to be stable, and the memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3368" target="_blank">00:56:08.320</a></span> | <span class="t">module is, let's just say, a gigabyte in size in memory, this is what will represent short-</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3375" target="_blank">00:56:15.840</a></span> | <span class="t">to mid-term memories for a AGI kind of model. The issue for any super long-context training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3386" target="_blank">00:56:26.320</a></span> | <span class="t">we're talking about in AGI scale is that we don't really have the means to really figure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3395" target="_blank">00:56:35.380</a></span> | <span class="t">out how to train this memory module in a structured, guided way. And right now, the hope is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3403" target="_blank">00:56:43.600</a></span> | <span class="t">if we train it, let's just say, at 4, 8k or 32k, it generalizes to 1 to 8. And if, let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3411" target="_blank">00:56:51.520</a></span> | <span class="t">say, we train at 1 mu, it generalizes to 10 mu. So if we train it at 10 mu, it generalizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3417" target="_blank">00:56:57.800</a></span> | <span class="t">to a larger context length and a much longer context length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3421" target="_blank">00:57:01.000</a></span> | <span class="t">The problem with this approach is, even for us right now, and this is something that maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3426" target="_blank">00:57:06.480</a></span> | <span class="t">Titan may have more tests on, is that when we train on 512, it generalizes up to 4k,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3432" target="_blank">00:57:12.760</a></span> | <span class="t">and then it dies out there. Then, if we train up to 4k, it generalizes up to 16k. So the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3441" target="_blank">00:57:21.560</a></span> | <span class="t">generalization doesn't go on to infinitum, unlike humans, arguably. But then again, maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3448" target="_blank">00:57:28.700</a></span> | <span class="t">that's why we go senile at the age of 100. Maybe that's the reason.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3456" target="_blank">00:57:36.320</a></span> | <span class="t">That's our context length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3457" target="_blank">00:57:37.880</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3458" target="_blank">00:57:38.880</a></span> | <span class="t">So I see we're at time. I don't know, Swix, I'll turn the floor back over to you. Any</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3471" target="_blank">00:57:51.040</a></span> | <span class="t">comments or thoughts about next week or announcements?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3476" target="_blank">00:57:56.120</a></span> | <span class="t">Ishan is doing DQ2 on his spreadsheet. Is that Ishan? I don't know. He likes spreadsheets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3485" target="_blank">00:58:05.760</a></span> | <span class="t">That's all I know. So that will be next week. Okay, well, yeah, I mean. Okay, I think that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3495" target="_blank">00:58:15.120</a></span> | <span class="t">was a yes. Cool. Yeah, we have run out of our context length for this session. Thank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3501" target="_blank">00:58:21.700</a></span> | <span class="t">you, Eric, for a great presentation. Yeah, very topical paper. We are, I've just been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3507" target="_blank">00:58:27.480</a></span> | <span class="t">chatting with Vibhu, and we're basically kind of thinking about, you know, doing the second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3512" target="_blank">00:58:32.880</a></span> | <span class="t">paper club and sometimes somewhat splitting between timeless papers or timeless survey</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3521" target="_blank">00:58:41.440</a></span> | <span class="t">papers and then hot individual papers is kind of like the split that we're thinking about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3527" target="_blank">00:58:47.040</a></span> | <span class="t">And then also maybe doing it at a different time. So it's not like during the day, during</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3531" target="_blank">00:58:51.040</a></span> | <span class="t">the workday for most people in the US. So yeah, people are interested in timeless papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3535" target="_blank">00:58:55.760</a></span> | <span class="t">and then also hot papers. So I think those are the two spiky things that maybe we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3539" target="_blank">00:58:59.840</a></span> | <span class="t">have a different vibe for that as well. Yeah, let's discuss in Discord, but otherwise have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=Hpz0bm6QupY&t=3545" target="_blank">00:59:05.000</a></span> | <span class="t">a wonderful day. Bye.</span></div></div></body></html>