<html><head><title>LLMs will hit the data wall if they can’t generalize – OpenAI cofounder John Schulman</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>LLMs will hit the data wall if they can’t generalize – OpenAI cofounder John Schulman</h2><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk"><img src="https://i.ytimg.com/vi/V6X_tLCxsZk/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./V6X_tLCxsZk.html">Whisper Transcript</a> | <a href="./transcript_V6X_tLCxsZk.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">So because there doesn't seem to be a model really since GPT-4 that seems to be significantly better,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=4" target="_blank">00:00:04.800</a></span> | <span class="t">there seems to be the hypothesis that potentially we're hitting some sort of plateau</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=10" target="_blank">00:00:10.240</a></span> | <span class="t">and that these models aren't actually generalizing that well, and we're going to hit some sort of data wall,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=15" target="_blank">00:00:15.920</a></span> | <span class="t">beyond which point the abilities that are unlocked by memorizing a vast corpus of pre-training data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=21" target="_blank">00:00:21.760</a></span> | <span class="t">won't actually help you get something much smarter than GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=25" target="_blank">00:00:25.120</a></span> | <span class="t">I mean, I wouldn't draw too much from the time since GPT-4 was released because, I mean, it does,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=34" target="_blank">00:00:34.320</a></span> | <span class="t">yeah, it takes a while to, like, train these models and to, like, get all the, do all the prep to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=42" target="_blank">00:00:42.960</a></span> | <span class="t">train a new generation of models. So, yeah, I wouldn't draw too much from that fact.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=50" target="_blank">00:00:50.240</a></span> | <span class="t">I would say there are definitely some challenges from the limited amount of data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=54" target="_blank">00:00:54.720</a></span> | <span class="t">but I wouldn't expect us to immediately hit the data wall. But I would expect the nature of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=61" target="_blank">00:01:01.520</a></span> | <span class="t">pre-training to somewhat change over time as we get closer to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=66" target="_blank">00:01:06.080</a></span> | <span class="t">I think we've talked about some examples generically about generalization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=69" target="_blank">00:01:09.680</a></span> | <span class="t">One example I was thinking of was the idea that there is transfer from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=75" target="_blank">00:01:15.360</a></span> | <span class="t">reasoning and code. If you train a bunch of code, it gets better at reasoning and language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=81" target="_blank">00:01:21.120</a></span> | <span class="t">And if that's the, is that actually the case? Do you see things like that, which suggests that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=86" target="_blank">00:01:26.160</a></span> | <span class="t">there's all this credit positive transfer between different modalities. So once you charge training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=90" target="_blank">00:01:30.080</a></span> | <span class="t">on a bunch of videos and images, it'll get smarter and it'll get smarter from synthetic data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=94" target="_blank">00:01:34.080</a></span> | <span class="t">Or does it seem like the abilities that are unlocked are extremely local to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=99" target="_blank">00:01:39.520</a></span> | <span class="t">the exact kind of labels and data you put into the training corpus?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=104" target="_blank">00:01:44.720</a></span> | <span class="t">In terms of generalization from different types of pre-training data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=110" target="_blank">00:01:50.080</a></span> | <span class="t">I would say it's pretty hard to do science on this type of question because you can't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=118" target="_blank">00:01:58.320</a></span> | <span class="t">do that, create that many pre-trained models. So maybe you can't train a GPT-4 size model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=124" target="_blank">00:02:04.800</a></span> | <span class="t">You can't do ablation studies at GPT-4 scale. Maybe you can do, train a ton of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=131" target="_blank">00:02:11.360</a></span> | <span class="t">GPT-2 size models or maybe even a GPT-3 size model with different data blends and see what you get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=136" target="_blank">00:02:16.640</a></span> | <span class="t">So I'm not aware of any results or public results on ablations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=144" target="_blank">00:02:24.960</a></span> | <span class="t">involving code data and reasoning performance and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=148" target="_blank">00:02:28.640</a></span> | <span class="t">So that would be, I'd be very interested to know about those results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=153" target="_blank">00:02:33.280</a></span> | <span class="t">With regards to the sort of plateau narrative, one of the things I've heard is that a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=159" target="_blank">00:02:39.840</a></span> | <span class="t">the abilities these models have to help you with specific things is related to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=163" target="_blank">00:02:43.280</a></span> | <span class="t">the having very closely matched labels within the supervised fine-tuning data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=171" target="_blank">00:02:51.920</a></span> | <span class="t">Is that true? If it can teach me how to use FFmpeg correctly, there's somebody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=177" target="_blank">00:02:57.600</a></span> | <span class="t">who's doing, figuring out, seeing the inputs and seeing what flags you need to add.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=183" target="_blank">00:03:03.280</a></span> | <span class="t">And some human is figuring that out and smashing to that. And is it, yeah. Do you need to hire</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=190" target="_blank">00:03:10.240</a></span> | <span class="t">like all these laborers who have domain expertise in all these different domains?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=193" target="_blank">00:03:13.760</a></span> | <span class="t">Because if that's the case, it seems like it would be a much bigger slog to get these models to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=198" target="_blank">00:03:18.000</a></span> | <span class="t">smarter and smarter over time. Right. You don't exactly need that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=201" target="_blank">00:03:21.520</a></span> | <span class="t">because, yeah, you can get quite a bit out of generalization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=207" target="_blank">00:03:27.040</a></span> | <span class="t">So if you like, like the base model has already been trained on tons of documentation, tons of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=215" target="_blank">00:03:35.040</a></span> | <span class="t">code with shell scripts and so forth. So it's already seen all the FFmpeg man pages and lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=222" target="_blank">00:03:42.720</a></span> | <span class="t">of bash scripts and everything. And it's so like the base, even just giving the base model a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=230" target="_blank">00:03:50.880</a></span> | <span class="t">few-shot prompt, you can get it to answer queries like this. And just training a preference model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=237" target="_blank">00:03:57.280</a></span> | <span class="t">like for helpfulness will, even if you don't train it on, probably even if you don't train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=245" target="_blank">00:04:05.200</a></span> | <span class="t">it on any STEM, it'll somewhat generalize to STEM. So not only do you not need like examples of how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=251" target="_blank">00:04:11.840</a></span> | <span class="t">to use FFmpeg, you might not even need anything with programming to get some reasonable behavior</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=257" target="_blank">00:04:17.600</a></span> | <span class="t">in the programming domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=V6X_tLCxsZk&t=261" target="_blank">00:04:21.120</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>