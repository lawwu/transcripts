<html><head><title>Apple’s ‘AI Can’t Reason’ Claim Seen By 13M+, What You Need to Know</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Apple’s ‘AI Can’t Reason’ Claim Seen By 13M+, What You Need to Know</h2><a href="https://www.youtube.com/watch?v=wPBD6wTap7g"><img src="https://i.ytimg.com/vi/wPBD6wTap7g/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=57">0:57</a> Viral Post + Headlines<br><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=102">1:42</a> Apple Paper Analysis<br><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=514">8:34</a> But they do Hallucinate<br><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=643">10:43</a> Not Supercomputers<br><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=678">11:18</a> o3 Pro and Recommendations<br><br><div style="text-align: left;"><a href="./wPBD6wTap7g.html">Whisper Transcript</a> | <a href="./transcript_wPBD6wTap7g.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Almost no one has the time to investigate headlines like this one, seen by tens of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=4" target="_blank">00:00:04.820</a></span> | <span class="t">millions of people. The AI models don't actually reason at all. They just memorize patterns. AGI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=9" target="_blank">00:00:09.860</a></span> | <span class="t">is mostly hype, and even the underlying Apple paper quoted says it's an illusion of thinking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=15" target="_blank">00:00:15.780</a></span> | <span class="t">This was picked up in mainstream outlets like The Guardian, which quoted it as being a pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=21" target="_blank">00:00:21.400</a></span> | <span class="t">devastating Apple paper. So what are people supposed to believe when half the headlines</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=25" target="_blank">00:00:25.800</a></span> | <span class="t">are about an imminent AI job apocalypse, and the other half are about LLMs all being fake?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=31" target="_blank">00:00:31.960</a></span> | <span class="t">Well, hopefully you'll find that I'm not trying to sell a narrative. I'll just say what I found,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=36" target="_blank">00:00:36.520</a></span> | <span class="t">having read the 30-page paper in full and the surrounding analyses. I'll also end with a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=42" target="_blank">00:00:42.560</a></span> | <span class="t">recommendation on which model you should use, and yes, touch on the brand new O3 Pro from OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=49" target="_blank">00:00:49.580</a></span> | <span class="t">Although I would say that the $200 price per month to access that model is not for the unwashed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=55" target="_blank">00:00:55.400</a></span> | <span class="t">masses like you guys. Some very quick context on why a post like this one gets tens of millions of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=61" target="_blank">00:01:01.080</a></span> | <span class="t">views and coverage in the mainstream media, and no, it's not just because of the unnecessarily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=66" target="_blank">00:01:06.160</a></span> | <span class="t">frantic breaking at the start. It's also because people hear the claims made by the CEOs of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=72" target="_blank">00:01:12.220</a></span> | <span class="t">AI labs, like Sam Altman yesterday, posting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=74" target="_blank">00:01:14.760</a></span> | <span class="t">Humanity is close to building digital superintelligence. We're past the event horizon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=79" target="_blank">00:01:19.800</a></span> | <span class="t">The takeoff has started. While the definitions of those terms are deliberately vague, you can understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=85" target="_blank">00:01:25.160</a></span> | <span class="t">people paying attention. People can see for themselves how quickly large language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=89" target="_blank">00:01:29.020</a></span> | <span class="t">are improving, and they can read the headlines generated by the CEO of Anthropic saying,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=94" target="_blank">00:01:34.580</a></span> | <span class="t">there is a white-collar bloodbath coming. It's almost every week now that we get headlines like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=98" target="_blank">00:01:38.800</a></span> | <span class="t">this one in the New York Times, so it's no wonder people are paying attention. Now, some would say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=103" target="_blank">00:01:43.080</a></span> | <span class="t">cynically that Apple seem to be producing more papers, quote, debunking AI than actually improving AI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=109" target="_blank">00:01:49.100</a></span> | <span class="t">but let's set that cynicism aside. The paper essentially claimed that large language models don't follow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=114" target="_blank">00:01:54.420</a></span> | <span class="t">explicit algorithms and struggle with puzzles when there are sufficient degrees of complexity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=120" target="_blank">00:02:00.460</a></span> | <span class="t">Puzzles like the Tower of Hanoi challenge, where you've got to move a tower of discs from one place</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=126" target="_blank">00:02:06.440</a></span> | <span class="t">to another, but never place a larger disc atop a smaller one. They also tested the models on games</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=131" target="_blank">00:02:11.740</a></span> | <span class="t">like checkers, where you've got to move the blue tokens all the way to the right and the red tokens to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=136" target="_blank">00:02:16.940</a></span> | <span class="t">the left, following the rules of checkers. And games like River Crossing, which might be more familiar to you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=141" target="_blank">00:02:21.820</a></span> | <span class="t">as the fox and chicken challenge, where you've got to go to the other side of the river without leaving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=145" target="_blank">00:02:25.900</a></span> | <span class="t">the fox with the chicken. All of these games, of course, can be and were scaled up in complexity the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=151" target="_blank">00:02:31.400</a></span> | <span class="t">more pieces you introduce. If models were a pre-programmed set of algorithms like a calculator,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=157" target="_blank">00:02:37.260</a></span> | <span class="t">then it shouldn't matter how many discs or checkers or blocks you have, performance should be 100%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=162" target="_blank">00:02:42.360</a></span> | <span class="t">all the time. Shocker, the paper showed that they're not that and performance dropped off noticeably the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=168" target="_blank">00:02:48.160</a></span> | <span class="t">more complex the task got. But this has been known for years now about large language models. They're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=173" target="_blank">00:02:53.200</a></span> | <span class="t">not traditional software, where the same input always leads to the same output. Nor, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=178" target="_blank">00:02:58.340</a></span> | <span class="t">are they fully randomised either, otherwise they couldn't pass a single benchmark. They are probabilistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=183" target="_blank">00:03:03.780</a></span> | <span class="t">neural networks, somewhere in between the two extremes. And the perfect example comes with multiplication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=189" target="_blank">00:03:09.400</a></span> | <span class="t">Again, I could have added breaking to the title of this video, but this has been known about for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=195" target="_blank">00:03:15.280</a></span> | <span class="t">several years now. If you don't give models access to any tools and ask them to perform a multiplication,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=200" target="_blank">00:03:20.620</a></span> | <span class="t">then the moment the digits of the multiplication get too large, they start to fail dramatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=206" target="_blank">00:03:26.880</a></span> | <span class="t">Not occasionally getting it right, just never getting the sum right. If the number of digits is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=211" target="_blank">00:03:31.980</a></span> | <span class="t">small enough, the models can reason their way to the correct answer. And as you can see in the difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=216" target="_blank">00:03:36.820</a></span> | <span class="t">between 01 mini from OpenAI and 03 mini, performance is incrementally improving. In other words, it takes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=223" target="_blank">00:03:43.480</a></span> | <span class="t">a bigger number of digits to flummox the latest models. But again, it must be emphasised that even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=229" target="_blank">00:03:49.540</a></span> | <span class="t">with the very latest, the very best models you can access, if you don't give them tools, they will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=234" target="_blank">00:03:54.860</a></span> | <span class="t">eventually reach a point where they just simply can't multiply two numbers. But this will always be the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=239" target="_blank">00:03:59.680</a></span> | <span class="t">case because these models aren't designed to be fully predictable. They're designed to be generative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=244" target="_blank">00:04:04.420</a></span> | <span class="t">They're not designed to be software, they're designed to use software. They want to produce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=249" target="_blank">00:04:09.180</a></span> | <span class="t">plausible outputs, which is why they'll hallucinate when you ask them questions they can't handle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=254" target="_blank">00:04:14.320</a></span> | <span class="t">Here, for example, I gave a calculation to Claude 4 Opus, the latest model from Anthropic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=258" target="_blank">00:04:18.760</a></span> | <span class="t">and Gemini 2.5 Pro, the latest model from Google DeepMind, but I didn't give them access to tools.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=263" target="_blank">00:04:23.780</a></span> | <span class="t">They were never going to get this right, but rather than say, I don't know, they just hallucinated the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=269" target="_blank">00:04:29.020</a></span> | <span class="t">answer in both cases. The funny thing was that these answers were plausible in that they ended</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=273" target="_blank">00:04:33.980</a></span> | <span class="t">in 2s and began with 6-7, which the correct answer does. These models are, after all, very convincing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=279" target="_blank">00:04:39.840</a></span> | <span class="t">BSers. But what the paper ignored is that these models can use tools and use them very effectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=285" target="_blank">00:04:45.400</a></span> | <span class="t">Here's that same Claude 4 Opus, but this time allowed to use code. It got the answer right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=290" target="_blank">00:04:50.960</a></span> | <span class="t">and notice I didn't even say use code or use a tool. It knew to do so. So for me, what was surprising</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=297" target="_blank">00:04:57.220</a></span> | <span class="t">is that this Apple paper found it surprising that large reasoning models, they call them,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=302" target="_blank">00:05:02.840</a></span> | <span class="t">can't perform exact computation. We know they can't. Now, several other people before me have pointed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=307" target="_blank">00:05:07.920</a></span> | <span class="t">out another fatal weakness with the paper, which is they describe accuracy ultimately collapsing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=312" target="_blank">00:05:12.960</a></span> | <span class="t">towards zero beyond a certain level of complexity. Because models are constrained with how many tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=318" target="_blank">00:05:18.420</a></span> | <span class="t">or parts of a word, if you like, that they can output in one go. In the case of the Claude model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=323" target="_blank">00:05:23.640</a></span> | <span class="t">from Anthropic that was tested, that token limit is 128,000 tokens. But some of the questions tested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=329" target="_blank">00:05:29.300</a></span> | <span class="t">required more than that number of tokens. So even if the models were trained to be calculators,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=335" target="_blank">00:05:35.280</a></span> | <span class="t">which they're not, they weren't given enough space to output the requisite number of tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=340" target="_blank">00:05:40.640</a></span> | <span class="t">For me then, it's to the credit of the models that they recognised their own output limits,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=345" target="_blank">00:05:45.520</a></span> | <span class="t">and then outputted what the paper calls shorter traces, basically giving up, because they quote,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=350" target="_blank">00:05:50.200</a></span> | <span class="t">knew they wouldn't have the space to output the required answer. Instead, the models would output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=355" target="_blank">00:05:55.540</a></span> | <span class="t">things like, here is the algorithm you need to use, or the tool you need to use, which I think is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=361" target="_blank">00:06:01.260</a></span> | <span class="t">reasonable. One quick detail that I think many people missed is the paper actually admits that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=365" target="_blank">00:06:05.100</a></span> | <span class="t">it originally wanted to compare thinking versus non-thinking models. You know, those ones output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=369" target="_blank">00:06:09.740</a></span> | <span class="t">long chains of thought versus those that don't on math benchmarks. Because the results didn't quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=374" target="_blank">00:06:14.860</a></span> | <span class="t">conform to the narrative they were expecting, and thinking models did indeed outperform non-thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=380" target="_blank">00:06:20.260</a></span> | <span class="t">models with the same compute budget, they actually abandoned the math benchmark and then resorted to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=385" target="_blank">00:06:25.300</a></span> | <span class="t">the puzzles. I guess what I'm saying is I slightly feel like the authors came to testing the thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=391" target="_blank">00:06:31.000</a></span> | <span class="t">models with a preconceived notion about their lack of ability. Another learning moment for us all from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=396" target="_blank">00:06:36.720</a></span> | <span class="t">paper comes from their surprise, the Apple authors, that when they provide the algorithm in the prompt,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=404" target="_blank">00:06:44.580</a></span> | <span class="t">the algorithm to solve these puzzles, the models still often fail. They're surprised by this and deem it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=410" target="_blank">00:06:50.680</a></span> | <span class="t">noteworthy because they say surely finding the solution requires more computation than merely executing a given</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=418" target="_blank">00:06:58.640</a></span> | <span class="t">algorithm. But you guys have twigged this all by now. These are not calculators. They're not designed for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=424" target="_blank">00:07:04.560</a></span> | <span class="t">executing algorithms. Because they are instead neural networks that are probabilistic, even if there is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=430" target="_blank">00:07:10.380</a></span> | <span class="t">99.9% chance that they output the correct next step, when there's millions of steps involved, they will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=436" target="_blank">00:07:16.440</a></span> | <span class="t">eventually make a mistake. Remember multiplication, where of course the language models know the quote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=441" target="_blank">00:07:21.640</a></span> | <span class="t">algorithm to perform a multiply step. Indeed, the models are derived through matrix multiplication, but that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=447" target="_blank">00:07:27.740</a></span> | <span class="t">does not mean that given enough steps required, they won't start making mistakes. The conclusion of the paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=453" target="_blank">00:07:33.560</a></span> | <span class="t">paper then teed things up for the headline writers because they say, we may be encountering fundamental</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=459" target="_blank">00:07:39.080</a></span> | <span class="t">barriers to generalizable reasoning. Now do forgive me for pointing this out, but that quote limitation to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=464" target="_blank">00:07:44.960</a></span> | <span class="t">generalized reasoning has been pointed out by experts like Professor Rao, who I interviewed back in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=471" target="_blank">00:07:51.020</a></span> | <span class="t">December of 2023 on my Patreon. This is not a quote breaking news type of situation. You may also find it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=477" target="_blank">00:07:57.700</a></span> | <span class="t">interesting that one researcher used Claude for Opus and named that model as a co-author in a paper pointing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=485" target="_blank">00:08:05.220</a></span> | <span class="t">out all the flaws of the Apple paper. Flaws even I missed, like certain of the questions being impossible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=491" target="_blank">00:08:11.640</a></span> | <span class="t">to answer due to logical impossibility. So no, to quote an article featured in The Guardian from Gary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=498" target="_blank">00:08:18.920</a></span> | <span class="t">Marcus, the tech world is not reeling from a paper that shows the powers of the new generation of AI have been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=504" target="_blank">00:08:24.440</a></span> | <span class="t">wildly oversold. I would go as far as to say that there isn't a single serious AI researcher that would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=509" target="_blank">00:08:29.880</a></span> | <span class="t">have been surprised by the results of that paper. That is not of course to say that these models don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=515" target="_blank">00:08:35.020</a></span> | <span class="t">make basic reasoning mistakes in simple scenarios, or at least semi-simple scenarios. I'm the author of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=521" target="_blank">00:08:41.480</a></span> | <span class="t">benchmark called SimpleBench designed to test models on such scenarios. For example, I tested the brand new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=528" target="_blank">00:08:48.020</a></span> | <span class="t">O3 Pro on this scenario in which models tend not to spot that the glove would just fall on to the road. This is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=535" target="_blank">00:08:55.780</a></span> | <span class="t">despite, by the way, thinking for 18 minutes. If you want to learn more about SimpleBench, by the way, the link is in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=541" target="_blank">00:09:01.180</a></span> | <span class="t">description. And I'll end this video with my recommendation of which model you should check out if you're just used to say for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=547" target="_blank">00:09:07.460</a></span> | <span class="t">example, the free ChatGPT. The O3 Pro API from OpenAI failed, by the way, which is why we don't have a result yet for that model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=555" target="_blank">00:09:15.060</a></span> | <span class="t">Of course, the failure modes go far beyond the simple scenarios featured in SimpleBench. Here's one quirk many of you may not know about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=561" target="_blank">00:09:21.860</a></span> | <span class="t">This is the brand new VO3 from Google Gemini. And I said, "Output a London scene with absolutely zero lampposts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=569" target="_blank">00:09:29.460</a></span> | <span class="t">not a single lamppost in sight." Of course, if you lean in to the hallucinations of generative models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=577" target="_blank">00:09:37.060</a></span> | <span class="t">you can get creative outputs like this one from VO3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=586" target="_blank">00:09:46.740</a></span> | <span class="t">Now obviously this is a quirky advert, but think of the immense amount of money that the company "saved"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=593" target="_blank">00:09:53.700</a></span> | <span class="t">by not using actors, sets, or props for this advert. That's why I don't want you guys to be as shocked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=599" target="_blank">00:09:59.620</a></span> | <span class="t">as this Sky News presenter in Britain, and this has got hundreds of thousands of views, where he noticed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=605" target="_blank">00:10:05.220</a></span> | <span class="t">ChatGPT hallucinating an answer, in this case a transcript. This generated several news segments,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=611" target="_blank">00:10:11.220</a></span> | <span class="t">as well as this article saying, "Can we trust ChatGPT despite it hallucinating answers?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=616" target="_blank">00:10:16.180</a></span> | <span class="t">This all then comes back to us being able to hold two thoughts in our head at the same time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=620" target="_blank">00:10:20.740</a></span> | <span class="t">which is that LLMs are swiftly catching up on human performance across almost all text-based domains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=626" target="_blank">00:10:26.740</a></span> | <span class="t">But they have almost no hesitation in generating mistruths, you could say like many humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=634" target="_blank">00:10:34.020</a></span> | <span class="t">So if human performance is your yardstick, they are catching up fast and can BS like the best of us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=640" target="_blank">00:10:40.580</a></span> | <span class="t">But language models like ChatGPT, Gemini, and Claude are not super computers, they're not the kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=646" target="_blank">00:10:46.020</a></span> | <span class="t">AI that can, for example, predict the weather. Their real breakthroughs, as with human breakthroughs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=650" target="_blank">00:10:50.820</a></span> | <span class="t">come when they use tools in an environment that corrects their BS for them. That can lead to genuine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=657" target="_blank">00:10:57.220</a></span> | <span class="t">scientific advance, and if you want to learn more about that, check out my Alpha Evolve video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=661" target="_blank">00:11:01.460</a></span> | <span class="t">Frankly, having made that video, I was quite surprised to hear Sam Altman say it's going to be 2026 when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=667" target="_blank">00:11:07.540</a></span> | <span class="t">see the arrival of systems that can figure out novel insights. As far as I'm concerned, we have that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=672" target="_blank">00:11:12.580</a></span> | <span class="t">now. Again, not LLMs on their own, but LLMs in combination with symbolic systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=678" target="_blank">00:11:18.660</a></span> | <span class="t">So, while language models can't yet solo superintelligence, which one should you use?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=683" target="_blank">00:11:23.620</a></span> | <span class="t">Well, let me give you one cautionary word on benchmarks and a little bit of advice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=688" target="_blank">00:11:28.580</a></span> | <span class="t">In just the last 48 hours, we got O3 Pro from OpenAI, at the $200 tier. I'm sure though that will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=695" target="_blank">00:11:35.540</a></span> | <span class="t">eventually filter down to the $20 tier. And of course, the benchmark results were pretty impressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=701" target="_blank">00:11:41.300</a></span> | <span class="t">On competition level mathematics, 93%, on really hard PhD level science questions, 84%, and competitive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=708" target="_blank">00:11:48.820</a></span> | <span class="t">coding, you can see the ELO ranking here. My cautionary note though comes from the results you can see below</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=714" target="_blank">00:11:54.740</a></span> | <span class="t">for the O3 model, not O3 Pro, but the O3 model that OpenAI showcased on day 12 of Christmas in December</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=722" target="_blank">00:12:02.660</a></span> | <span class="t">2024. As you can see, today's O3 Pro mostly underperforms that system teased back in December.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=729" target="_blank">00:12:09.620</a></span> | <span class="t">So that's the cautionary note that you often have to look beyond the headline benchmark results to see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=735" target="_blank">00:12:15.140</a></span> | <span class="t">how these models perform on your use case. The word of advice is that when you're looking at benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=740" target="_blank">00:12:20.020</a></span> | <span class="t">companies will often either not compare to other model providers at all, as in the case of OpenAI these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=746" target="_blank">00:12:26.180</a></span> | <span class="t">days, or like Anthropic with their Claude series of models, they will show you multiple benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=751" target="_blank">00:12:31.380</a></span> | <span class="t">but not be terribly clear about the multiple parallel attempts they took to get their record high scores,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=757" target="_blank">00:12:37.220</a></span> | <span class="t">or about the serious usage limitations they have for their bigger model, or the massively elevated price</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=763" target="_blank">00:12:43.780</a></span> | <span class="t">for that model. Which brings me to my current recommendation if you just want to use a model for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=768" target="_blank">00:12:48.580</a></span> | <span class="t">free, albeit with caps of course, and that would be Google's Gemini 2.5 Pro. Yes, I am slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=774" target="_blank">00:12:54.580</a></span> | <span class="t">influenced by its top score on SimpleBench, and the fact you get a few uses of the Vio video generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=780" target="_blank">00:13:00.900</a></span> | <span class="t">model. An honorary mention goes to DeepSeq R1, which is very cheap via the API, and at least comes with a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=787" target="_blank">00:13:07.780</a></span> | <span class="t">technical report that we can all read through. Many of you commented this month that you saw a pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=792" target="_blank">00:13:12.820</a></span> | <span class="t">noticeable boost in production quality for my DeepSeq documentary, and there's more to come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=798" target="_blank">00:13:18.580</a></span> | <span class="t">where that came from. But that boost was in no small part to my video editor choosing Storyblocks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=804" target="_blank">00:13:24.980</a></span> | <span class="t">the sponsors of today's video. We picked them actually before any sponsorship, partly due to the unlimited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=811" target="_blank">00:13:31.620</a></span> | <span class="t">downloads of varied high quality media at their set subscription cost, but partly due to the clear-cut</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=818" target="_blank">00:13:38.420</a></span> | <span class="t">licensing, wherein anything we downloaded with Storyblocks was 100% royalty-free. If you want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=825" target="_blank">00:13:45.140</a></span> | <span class="t">get started with unlimited stock media downloads, head to storyblocks.com/aiexplained, link in the description.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=wPBD6wTap7g&t=832" target="_blank">00:13:52.500</a></span> | <span class="t">I hope that helped give you some signal amongst the noise, but either way, I hope you have a very wonderful day.</span></div></div></body></html>