<html><head><title>The Model That Changes Everything: Alpaca Breakthrough (ft. Apple's LLM, BritGPT, Ernie and AlexaTM)</title></head><body>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    <a href="index.html">back to index</a><h2>The Model That Changes Everything: Alpaca Breakthrough (ft. Apple's LLM, BritGPT, Ernie and AlexaTM)</h2><a href="https://www.youtube.com/watch?v=xslW5sQOkC8"><img src="https://i.ytimg.com/vi/xslW5sQOkC8/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./xslW5sQOkC8.html">Whisper Transcript</a> | <a href="./transcript_xslW5sQOkC8.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=0">00:00:00.000</a></span> | <span class="t">A little under 72 hours ago, a language model was released that could end up being as consequential</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=6">00:00:06.720</a></span> | <span class="t">as GPT-4. Now I know you're thinking that's a bold claim, but let's see if you agree with it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=12">00:00:12.980</a></span> | <span class="t">after watching what happened. I will explain as best as I can what was released and how revelations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=18">00:00:18.520</a></span> | <span class="t">in the last 24 hours from Apple, Amazon, Britain and Baidu make it particularly significant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=26">00:00:26.200</a></span> | <span class="t">The model was Stanford's Alpaca and here is the key line. Alpaca behaves qualitatively similarly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=33">00:00:33.840</a></span> | <span class="t">to OpenAI's Text DaVinci 3 while being surprisingly small and easy and cheap to reproduce at under $600.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=44">00:00:44.340</a></span> | <span class="t">Now that is cool, but how does that change the world? Well, first it wasn't supposed to get this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=51">00:00:51.080</a></span> | <span class="t">cheap this fast. Just six weeks ago or five weeks before they released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=56">00:00:56.080</a></span> | <span class="t">the first version of the Alpaca, the model was Stanford's Alpaca. And here is the key line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=56">00:00:56.180</a></span> | <span class="t">The model was Stanford's Alpaca. And here is the key line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=56">00:00:56.680</a></span> | <span class="t">ARK Investment Management put out this prediction that the 2020 cost of GPT-3 at $4.6 million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=64">00:01:04.960</a></span> | <span class="t">would take until 2030 to fall to something as insignificant as $30. If Stanford have done what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=72">00:01:12.660</a></span> | <span class="t">they claim, then 99% of this cost reduction has happened within five weeks of this prediction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=79">00:01:19.760</a></span> | <span class="t">being published, not eight years. As AI researcher Eliezer Yudkowsky puts it, I don't think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=86">00:01:26.160</a></span> | <span class="t">people realize what a big deal it is that Stanford retrained a Lama model by cheaply fine-tuning it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=93">00:01:33.180</a></span> | <span class="t">Now I'm going to explain all of this in a moment. He then goes on, I'm not sure I can convey how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=97">00:01:37.860</a></span> | <span class="t">much this is a brand new idiom of AI as a technology. Now Stanford claim their model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=103">00:01:43.260</a></span> | <span class="t">performs comparably to DaVinci 3, which is GPT-3.5. Of course, I'm going to test and analyze this in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=109">00:01:49.740</a></span> | <span class="t">a moment, but how could it be that a $600 model can compete with ChatGPT? Well, do you remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=116">00:01:56.140</a></span> | <span class="t">how Meta open sourced their Lama models about two weeks ago? Stanford used the weakest of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=123">00:02:03.040</a></span> | <span class="t">open source models, the $7 billion parameter one, and then essentially they recruited GPT-3.5</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=129">00:02:09.640</a></span> | <span class="t">to train that Meta model. How could they possibly do this? Well, they used Self-Instruct,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=136">00:02:16.280</a></span> | <span class="t">and I dug into the literature to find the original paper on Self-Instruct. This was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=141">00:02:21.740</a></span> | <span class="t">released in December of last year, and I'm going to give you the 30-second summary,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=146">00:02:26.120</a></span> | <span class="t">of how it works. Essentially, you start off with some human-made examples of exemplar prompts and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=152">00:02:32.400</a></span> | <span class="t">outputs. These are fed into the language model, and then you ask it to generate thousands more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=157">00:02:37.660</a></span> | <span class="t">such instances. You filter out the bad ones, and then put all the good examples back into the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=163">00:02:43.260</a></span> | <span class="t">language model. Then it understands the instructions much better and produces thousands more examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=168">00:02:48.080</a></span> | <span class="t">As the paper says, this is almost human annotation free. And remember this stat, it only leaves a 5%</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=176">00:02:56.100</a></span> | <span class="t">gap behind Instruct GPT. What is Instruct GPT? Well, it's the breakthrough that led to ChatGPT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=183">00:03:03.260</a></span> | <span class="t">in the first place. Look at the original GPT-3. If you gave it a prompt like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=187">00:03:07.700</a></span> | <span class="t">explain the moon landing to a six-year-old in a few sentences, you got this gobbledygook here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=192">00:03:12.300</a></span> | <span class="t">After months of onerous human training, called reinforcement learning with human feedback,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=197">00:03:17.240</a></span> | <span class="t">it was able to follow instructions much better and produce an outcome like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=202">00:03:22.080</a></span> | <span class="t">But this relied on so much human labeling and human</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=205">00:03:25.880</a></span> | <span class="t">rationale that it was able to do so much better. And so, this is what we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=206">00:03:26.080</a></span> | <span class="t">see in the next episode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=236">00:03:56.060</a></span> | <span class="t">the services like ChatGPT to develop models that compete with OpenAI. So, they knew it was possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=241">00:04:01.720</a></span> | <span class="t">and even Stanford admit that this breakthrough enables more people, including bad actors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=246">00:04:06.740</a></span> | <span class="t">to create new cheap models. Yudkowsky also points out that one of the reasons why ChatGPT and GPT-4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=253">00:04:13.680</a></span> | <span class="t">are so good is that they rest on proprietary data and that that was supposed to give them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=258">00:04:18.460</a></span> | <span class="t">a competitive moat, which is now revealed people can quite cheaply steal. Just before I test and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=265">00:04:25.320</a></span> | <span class="t">demonstrate our results, I'm going to show you a video of a chat GPT-3 that I made.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=266">00:04:26.040</a></span> | <span class="t">Let me summarize how it works. Using the self-instruct process, you get GPT-3.5 similar to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=273">00:04:33.640</a></span> | <span class="t">ChatGPT to create thousands and thousands, in this case, 52,000 instruction following examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=280">00:04:40.360</a></span> | <span class="t">automatically filtered by quality. Stanford then used an open source model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=284">00:04:44.920</a></span> | <span class="t">indeed the weakest of the LAMA models, and trained it using those examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=289">00:04:49.720</a></span> | <span class="t">The end result? Alpaca. So, let's see it in action and compare it to ChatGPT and GPT-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=295">00:04:55.880</a></span> | <span class="t">OpenAI is a very powerful tool for learning and learning. It's a very powerful tool for learning and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=296">00:04:56.020</a></span> | <span class="t">learning. Oh, and just quickly, you know that training of the LAMA model with those 52,000</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=299">00:04:59.780</a></span> | <span class="t">examples? It only took three hours and cost less than $100. The first example I'm going to show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=305">00:05:05.300</a></span> | <span class="t">you does not come from me. I found it in this academic paper linked in the description. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=310">00:05:10.180</a></span> | <span class="t">it's a task which requires understanding detailed and dissonant scenarios, applying appropriate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=316">00:05:16.260</a></span> | <span class="t">legal precedents, and choosing the correct explanation. The correct answer, if you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=320">00:05:20.500</a></span> | <span class="t">to read through it or not, is B. Alpaca gets this question right. Or I should say it gets it right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=326">00:05:26.000</a></span> | <span class="t">about 80% of the time. You can keep clicking generate and sometimes you do get the answer D,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=330">00:05:30.640</a></span> | <span class="t">but about 80% of the time, four times in five, you get the correct answer B. How about ChatGPT?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=336">00:05:36.000</a></span> | <span class="t">Well, every time I've tried it, it's gotten the wrong answer of C. And GPT-4? Shocking even to me,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=342">00:05:42.160</a></span> | <span class="t">it also gets it wrong and picks C. Now, before you get too excited, I am not saying that it is better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=348">00:05:48.560</a></span> | <span class="t">than or even as good as GPT-4 or ChatGPT. It's not. But remember, it's only 7 billion parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=355">00:05:55.980</a></span> | <span class="t">And 600 dollars worth. Take this example. I asked it for an example of an animal that begins with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=361">00:06:01.360</a></span> | <span class="t">the same letter as the capital city of France. And it said elephant. No idea where it got that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=366">00:06:06.640</a></span> | <span class="t">Now, in fairness, ChatGPT gave me lion and GPT-4 gave me ferret. But there are other questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=373">00:06:13.320</a></span> | <span class="t">where alpaca definitely flops. For example, this math question, which ChatGPT and GPT-4 uniformly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=379">00:06:19.960</a></span> | <span class="t">get right, alpaca simply gets it wrong every time. I tried asking it in lots of different ways with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=385">00:06:25.960</a></span> | <span class="t">chain of thought prompting. But no, every time it gets it wrong. It's definitely not better than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=390">00:06:30.760</a></span> | <span class="t">those models. But by the end of the video, you'll see why it's revolutionary anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=394">00:06:34.780</a></span> | <span class="t">At this point, if you're learning anything, please don't forget to leave a like or a comment to let</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=399">00:06:39.020</a></span> | <span class="t">me know. Basic addition and subtraction, it does better. And yes, it can crank out poems,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=403">00:06:43.920</a></span> | <span class="t">solve some hella swag common sense problems, and generate literary analogies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=409">00:06:49.400</a></span> | <span class="t">But at this point, I want to remind you of three things. First, that it was using the weakest of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=415">00:06:55.940</a></span> | <span class="t">more open source models. They could have used the 65 billion parameter model for a bit more cost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=421">00:07:01.420</a></span> | <span class="t">I'm sure the results would have been even more impressive. Next, you remember it was trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=426">00:07:06.080</a></span> | <span class="t">by examples generated using the DaVinci 3 model. Well, that cost them about $0.03 per 1000 tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=434">00:07:14.240</a></span> | <span class="t">But as of 48 hours ago, they could have used the GPT-4 API at a very similar cost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=441">00:07:21.720</a></span> | <span class="t">So it wasn't the best open source model, and it wasn't trained by the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=445">00:07:25.920</a></span> | <span class="t">GPT model. I am genuinely curious as to what the results would have been if it had been trained by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=451">00:07:31.140</a></span> | <span class="t">the 65 billion parameter model using a GPT-4 API. Maybe someone's going to do that, maybe even this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=457">00:07:37.500</a></span> | <span class="t">week. But just before we get on to Apple, Amazon, Britain, and Baidu, I just want to restate this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=462">00:07:42.800</a></span> | <span class="t">was all done for $600 or less. They even say there were training efficiencies they could have done,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=468">00:07:48.540</a></span> | <span class="t">for example, using the H100 GPUs, that would have further reduced the cost. The question is, if it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=475">00:07:55.900</a></span> | <span class="t">going to facilitate a larger model, what's going to happen when Apple release their large language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=479">00:07:59.940</a></span> | <span class="t">model? It was only revealed yesterday in the New York Times that they are indeed working on one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=485">00:08:05.140</a></span> | <span class="t">And don't forget, they have far more money than the other companies mentioned. Amazon recently</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=490">00:08:10.020</a></span> | <span class="t">stated that they have been working on similar tech to ChatGPT for a long time. And looking in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=496">00:08:16.100</a></span> | <span class="t">the literature, as early as mid last year, they had a model called Alexa TM that outperformed GPT-3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=503">00:08:23.560</a></span> | <span class="t">And as you may already know, Baidu,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=505">00:08:25.880</a></span> | <span class="t">demonstrated their Ernie bot today, although they didn't allow anyone else to use it. Apparently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=511">00:08:31.260</a></span> | <span class="t">it's better in the Chinese language than even GPT-4. But because they didn't release a paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=516">00:08:36.380</a></span> | <span class="t">and we can't check it, we simply don't know. And of course, we can't forget Google, who just two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=521">00:08:41.200</a></span> | <span class="t">days ago announced the Palm API. What would have happened if Stanford's model had used that one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=527">00:08:47.000</a></span> | <span class="t">I'm sure we will soon find out. But to take us back to the start, I have one overriding observation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=532">00:08:52.800</a></span> | <span class="t">and two questions. First, these models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=535">00:08:55.860</a></span> | <span class="t">weren't supposed to get this cheap this fast. That is going to upend the economics of large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=541">00:09:01.680</a></span> | <span class="t">language models. And my questions are these. Does this mean that all incentive is gone for Microsoft</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=547">00:09:07.680</a></span> | <span class="t">or Google to pour in billions of dollars producing these cutting edge models if anyone can just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=553">00:09:13.360</a></span> | <span class="t">easily reproduce them? Will they react by making the models even more closed and disallowing GPT-5</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=560">00:09:20.040</a></span> | <span class="t">from having an API? We don't know. But as even nation states enter this quote unquote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=565">00:09:25.840</a></span> | <span class="t">thumbs race, spending hundreds of millions of pounds, in this case to build Brit GPT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=571">00:09:31.300</a></span> | <span class="t">are these companies and governments drifting into a war on two fronts where they compete with each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=577">00:09:37.320</a></span> | <span class="t">other, but also with outsiders who are trying to cheaply imitate their models? If you've learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=xslW5sQOkC8&t=582">00:09:42.960</a></span> | <span class="t">anything in this video, please do leave a like and leave a comment. But either way, have a wonderful</span></div></div></body></html>