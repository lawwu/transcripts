<html><head><title>Are We On Path Towards Superhuman Intelligence? – Dario Amodei (Anthropic CEO)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>Are We On Path Towards Superhuman Intelligence? – Dario Amodei (Anthropic CEO)</h2><a href="https://www.youtube.com/watch?v=wo4o09lKAQQ" target="_blank"><img src="https://i.ytimg.com/vi_webp/wo4o09lKAQQ/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=wo4o09lKAQQ&t=0 target="_blank"">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=wo4o09lKAQQ&t=25 target="_blank"">0:25</a> Scaling Laws Bend<br><a href="https://www.youtube.com/watch?v=wo4o09lKAQQ&t=112 target="_blank"">1:52</a> The Next Great Inversion<br><a href="https://www.youtube.com/watch?v=wo4o09lKAQQ&t=197 target="_blank"">3:17</a> Superhuman AI<br><a href="https://www.youtube.com/watch?v=wo4o09lKAQQ&t=344 target="_blank"">5:44</a> Human level AI<br><h3>Transcript</h3><div class='max-width'><p>we're building up this snowball of like, the models help the models get better and, you know, can accelerate what the humans do. And eventually, it's mostly the models doing the work. Like, you zoom out far enough, that's happening. But I'm kind of skeptical of kind of any kind of precise mathematical or exponential prediction of how it's going to be.</p><p>I think it's, I think it's, I think it's all going to be a mess. But I think what we know is it's on a metaphorical exponential, and it's going to happen fast. We're already at the point where if you look at the loss, the scaling laws are starting to bend.</p><p>I mean, we've seen that in, you know, published model cards offered by multiple companies. So that's not a secret at all. But as, as they start to bend, each little bit of, of entropy, right, of accurate prediction becomes more important, right? Maybe these last little bits, bits of entropy are like, well, you know, this is a physics paper, as Einstein would have written it, as opposed to, you know, as some other physicist would have, would have, would have written it.</p><p>And so it's, it's hard to assess significance from this. It's certainly looks like in terms of practical performance, the metrics keep going up relatively linearly, although they're always unpredictable. So, so it's, it's hard to see that. And then, I mean, the thing that I think is driving the most acceleration is just more and more money is going into the field.</p><p>Like people are seeing that there's just a huge amount of, you know, of, of economic value. And so I expect the amount of money spent on the largest models to go up by like a factor of 100 or something. And for that, that then to be concatenated with the chips are getting faster, the algorithms are getting better, because there's, there's so many people working on this now.</p><p>And so, and so again, I mean that, you know, I'm not making a normative statement here, this is what should happen. I'm not even saying this necessarily will happen, because I think there's important safety and government questions here, which we're very actively working on. I'm just, I'm just saying like left to itself, this is what the economy is going to do.</p><p>- So do you think that another thing on the scale of a transformer is coming down the pike to enable the next, the next great iterations? - I think it's possible. I mean, people have worked on things like, you know, trying to model very long time dependencies, or, you know, you know, there's various different ideas where I could see that we're kind of missing an efficient way of representing or dealing with something.</p><p>So I think those inventions are possible. I guess my perspective would be, even if they don't happen, we're, we're all, we're already on this very, very steep trajectory. And so I'm less, I mean, we're constantly trying to discover them as are, as are others. But things are already on such a fast trajectory, all that would do is speed up the trajectory even more.</p><p>And probably, probably not by that much, because it's already going so fast. I think we've been relatively responsible in the sense that, you know, the big acceleration that happened late last year, and beginning of this year, like, we didn't cause that we weren't, we weren't the ones who did that.</p><p>And honestly, I think if you look at the reaction to Google, that that might be 10 times more important than anything else. And then kind of once it had happened, once the ecosystem had changed, then we did a lot of things to kind of to kind of stay on the frontier.</p><p>And so I don't know, it's, it's, I mean, it's like any other question, right? It's like, you're trying to, you're trying to do the things that have the lowest costs and the biggest benefits. And you know, that that causes you to have different strategies at different times. How likely do you think it is that these models will be superhuman for many years at economically valuable tasks, while there are still below humans in many other relevant tasks that prevents like an intelligence explosion or something?</p><p>I think this kind of stuff is like really hard to know. So I'll give I'll give that caveat that like, you know, again, like the basic scaling laws, you can kind of predict, and then like this more granular stuff, which we really want to know to know how this all is going to go is much harder to know.</p><p>But my guess would be the scaling laws are going to continue, you know, again, subject to, you know, do people slow down for safety or for regulatory reasons. But you know, let's just let's just put all that aside and say, like, we have the economic capability to keep scaling.</p><p>If we did that, what would happen? And I think my view is we're going to keep getting better across the board. And I don't see any area where the models are like, super, super weak or not starting to make progress like that used to be true of like math and programming.</p><p>But I think over the last six months, you know, the 2023 generation of models compared to the 2022 generation has started to learn that there may be more subtle things we don't know. And so I kind of suspect, even if it isn't quite even, that the rising tide will lift all the boats, you know, are we going to be superhuman in some areas and not others?</p><p>I think it's complicated. I could imagine that we won't be superhuman in some areas because, for example, they involve like embodiment in the physical world. And then it's like, what happens like the AIs help us train faster AIs and those faster AIs wrap around and solve that? Do you not need the physical world?</p><p>I think the idea that AI systems become more productive and first they speed up the productivity of humans, then they, you know, kind of equal the productivity of humans. And, you know, and then they're in some meaningful sense, the main contributor to scientific progress, that that happens at some point.</p><p>I think that basic logic seems likely to me, although I have a suspicion that when we actually go into the details, it's going to be kind of like weird and different than we expect, that all the detailed models are kind of, you know, we're thinking about the wrong things or we're right about one thing and then are wrong about 10 other things.</p><p>And so I don't know, I think we might end up in like a weirder world than we expect. - When you add all this together, like your estimate of when we get something kind of human level, what does that look like? - You know, in terms of someone looks at these, the model and, you know, even if you talk to it for, you know, for an hour or so, it's basically, you know, it's basically like a generally well educated human.</p><p>That could be not very far away at all, I think. Like that could happen in, you know, two or three years. That may not be the threshold where the models are existentially dangerous. In fact, I suspect it's not quite there yet. It may not be the threshold where the models can take over most AI research.</p><p>It may not be the threshold where the models, you know, seriously change how the economy works. I think it gets a little murky after that and all those thresholds may happen at various times after that. But I think in terms of the base technical capability of it, it kind of sounds like a reasonably generally educated human across the board.</p><p>I think that could be quite close.</p></div></div></body></html>