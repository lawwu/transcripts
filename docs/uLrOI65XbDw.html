<html><head><title>Everything you need to know about Fine-tuning and Merging LLMs: Maxime Labonne</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Everything you need to know about Fine-tuning and Merging LLMs: Maxime Labonne</h2><a href="https://www.youtube.com/watch?v=uLrOI65XbDw"><img src="https://i.ytimg.com/vi_webp/uLrOI65XbDw/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=54">0:54</a> LLM training life cycle<br><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=114">1:54</a> When to use finetuning<br><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=182">3:2</a> Why Enterprises care about open source<br><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=211">3:31</a> Finetuning libraries<br><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=340">5:40</a> How to create SFT data sets<br><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=495">8:15</a> SFT techniques<br><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=562">9:22</a> Hyperparameters<br><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=597">9:57</a> Sequence Length<br><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=635">10:35</a> Model Merging<br><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=720">12:0</a> Slurp<br><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=799">13:19</a> Passthrough<br><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=866">14:26</a> Mixture of experts<br><br><div style="text-align: left;"><a href="./uLrOI65XbDw.html">Whisper Transcript</a> | <a href="./transcript_uLrOI65XbDw.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=0" target="_blank">00:00:00.040</a></span> | <span class="t">Hi everyone, in this session we're going to talk about everything you need to know about fine-tuning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=19" target="_blank">00:00:19.620</a></span> | <span class="t">LLMs and model merging. Quick intro, my name is Maxim Labonne, I'm a staff machine learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=26" target="_blank">00:00:26.600</a></span> | <span class="t">scientist at Liquid AI, I'm also a growth developer expert, I write blog posts on these topics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=32" target="_blank">00:00:32.480</a></span> | <span class="t">I created the LLM course which is super popular on GitHub, I also contributed to the open source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=38" target="_blank">00:00:38.360</a></span> | <span class="t">community through models, through tools, and I'm the author of hands-on graph neural networks using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=45" target="_blank">00:00:45.440</a></span> | <span class="t">Python with PACT. So first of all, let's talk about fine-tuning. We saw a bit of fine-tuning in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=52" target="_blank">00:00:52.520</a></span> | <span class="t">previous session, so I'll try to not repeat too much. But basically, here's the LLM training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=59" target="_blank">00:00:59.000</a></span> | <span class="t">lifecycle. You see three stages. First of all, you have the pre-training stage where you give a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=65" target="_blank">00:01:05.240</a></span> | <span class="t">raw text to the model, and the idea is that the model learns to do next token prediction. The result of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=73" target="_blank">00:01:13.100</a></span> | <span class="t">that is called a base model. This base model is really nice, but if you ask it questions or instructions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=81" target="_blank">00:01:21.020</a></span> | <span class="t">it's going to auto-complete your question instead of answering it, which is why we have the supervised</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=86" target="_blank">00:01:26.300</a></span> | <span class="t">fine-tuning stage where this time we give pairs of questions and answers to the model. And we have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=93" target="_blank">00:01:33.260</a></span> | <span class="t">similar training objective, but the idea is that at the end of it, it's going to actually answer your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=99" target="_blank">00:01:39.740</a></span> | <span class="t">questions and follow instructions. Then we have a third and final stage, the preference alignment stage,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=105" target="_blank">00:01:45.340</a></span> | <span class="t">where we give human preferences to align the model to how we want it to behave,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=110" target="_blank">00:01:50.620</a></span> | <span class="t">and the result is commonly referred to as chat model. So when to use fine-tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=115" target="_blank">00:01:55.900</a></span> | <span class="t">Here you can see a little flow chart that I've made. It's very high level. But basically, there's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=122" target="_blank">00:02:02.860</a></span> | <span class="t">conversation about when to use prompt engineering, when to use fine-tuning. I think it's good in general to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=128" target="_blank">00:02:08.940</a></span> | <span class="t">start with prompt engineering if you can. And the idea is to have a really robust evaluation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=134" target="_blank">00:02:14.540</a></span> | <span class="t">structure where you have a lot of different metrics that you're interested in. It can be the accuracy of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=141" target="_blank">00:02:21.740</a></span> | <span class="t">the model. Does it answer my question well? You can create a custom benchmark if you have a very niche</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=147" target="_blank">00:02:27.820</a></span> | <span class="t">use case, or you can reuse open source benchmarks. Also, in terms of cost, latency, because the question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=154" target="_blank">00:02:34.460</a></span> | <span class="t">is, is it good enough? If it's good enough with just prompt engineering, then probably you don't need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=159" target="_blank">00:02:39.180</a></span> | <span class="t">fine-tuning. The problem is solved. Congrats. Otherwise, the question is, can you make an instruction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=164" target="_blank">00:02:44.220</a></span> | <span class="t">dataset? So can you create pairs of questions and answers to fine-tune the model? If it's not the case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=171" target="_blank">00:02:51.260</a></span> | <span class="t">it can be for multiple reasons, but it's probably a good sign that you need to re-scope the project.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=176" target="_blank">00:02:56.380</a></span> | <span class="t">Otherwise, fine-tuning is an option, and you can reuse the evaluation framework that you created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=181" target="_blank">00:03:01.260</a></span> | <span class="t">to evaluate the model. So that was the technical answer, but you also have a non-technical answer to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=187" target="_blank">00:03:07.500</a></span> | <span class="t">that. Here is a report from A16Z. And the question is, why do enterprises care about open source? You can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=194" target="_blank">00:03:14.780</a></span> | <span class="t">see that the two main items actually control and customers' ability. And customers' ability is mostly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=201" target="_blank">00:03:21.020</a></span> | <span class="t">about fine-tuning models. So even if there's like arguments about the technical side and cost and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=206" target="_blank">00:03:26.940</a></span> | <span class="t">latency, there's also like a strong argument for customers' ability and control over these models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=210" target="_blank">00:03:30.940</a></span> | <span class="t">So in terms of fine-tuning libraries, I think that you know about Anceloft now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=215" target="_blank">00:03:35.420</a></span> | <span class="t">but I'm going to talk about the other ones. So TRL from Hugging Face, a great library built on top of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=222" target="_blank">00:03:42.060</a></span> | <span class="t">transformers, very easy to use. You have Axolotl, excellent library, very versatile. You have a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=228" target="_blank">00:03:48.940</a></span> | <span class="t">of YAML config files. And then you have LAM factory, where you have a really good graphical user interface</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=236" target="_blank">00:03:56.780</a></span> | <span class="t">that is built in. So to talk a bit more about supervised fine-tuning, here you see an example of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=243" target="_blank">00:04:03.260</a></span> | <span class="t">sample that we give to the model. So we have the instruction, which is both the system prompt and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=249" target="_blank">00:04:09.820</a></span> | <span class="t">the user prompt, and the answer, which is the output. So in this case, the system prompt is used to steer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=257" target="_blank">00:04:17.260</a></span> | <span class="t">the behavior of the model, think like you're answering to a five-year-old. And the user actually gives the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=263" target="_blank">00:04:23.260</a></span> | <span class="t">task, remove the spaces from the following sentence. We train the model usually, like generally, on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=269" target="_blank">00:04:29.980</a></span> | <span class="t">output only. So we mask the rest. It's used as context. And what we want to do is train the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=276" target="_blank">00:04:36.300</a></span> | <span class="t">to output the correct answer. Most safety data sets, I want you to say, that use synthetic data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=281" target="_blank">00:04:41.660</a></span> | <span class="t">and that's perfectly fine. Usually it's generated with frontier models, and that's a great way of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=286" target="_blank">00:04:46.460</a></span> | <span class="t">building higher-quality data sets. Then you have the preference alignments. I'm just going to mention it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=292" target="_blank">00:04:52.460</a></span> | <span class="t">here. There are a lot of different methods, PPO, DPO, KTO, IPO. In practice, direct preference optimization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=299" target="_blank">00:04:59.180</a></span> | <span class="t">is probably the most popular one. So here you see that you have a different format with an instruction,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=305" target="_blank">00:05:05.500</a></span> | <span class="t">and you have a chosen answer and a rejected answer. So the idea here is that you're going to show like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=311" target="_blank">00:05:11.420</a></span> | <span class="t">positive example, negative example to the model. And with DPO, the goal is to make sure that the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=317" target="_blank">00:05:17.500</a></span> | <span class="t">that you're currently training outputs higher probabilities for the chosen answers than the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=322" target="_blank">00:05:22.300</a></span> | <span class="t">untrained version of the same model. I'm not going to delve too much into the details here, but this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=327" target="_blank">00:05:27.340</a></span> | <span class="t">general idea and can be used to either censor the model, how to make a bomb, the chosen answer would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=332" target="_blank">00:05:32.940</a></span> | <span class="t">be as an AI system. I cannot tell you that. Or it can also be used to boost the performance of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=338" target="_blank">00:05:38.780</a></span> | <span class="t">of the model in general. How to create SFT data sets. So this is a very fundamental question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=345" target="_blank">00:05:45.100</a></span> | <span class="t">in the post-training world. And the main question is, okay, what's a good sample? Human evaluation is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=352" target="_blank">00:05:52.380</a></span> | <span class="t">quite bad at actually reviewing the samples. But what I like to define is like three main features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=359" target="_blank">00:05:59.180</a></span> | <span class="t">The first one is the accuracy. We want the samples, the outputs to be factually correct. Maybe no typos</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=367" target="_blank">00:06:07.180</a></span> | <span class="t">would be good too. We don't want to compromise the knowledge of the model by giving it fake information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=374" target="_blank">00:06:14.060</a></span> | <span class="t">Then you have diversity. And diversity, you want to cover as many topics as you can. Of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=380" target="_blank">00:06:20.620</a></span> | <span class="t">it depends on your use case. Because if you do summarization, you won't be as general as if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=385" target="_blank">00:06:25.980</a></span> | <span class="t">do general purpose fine tuning. But it's always a good idea to include a lot of different topics,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=393" target="_blank">00:06:33.420</a></span> | <span class="t">different writing styles in this dataset. And finally, you have complexity. I think this one is a bit less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=401" target="_blank">00:06:41.020</a></span> | <span class="t">trivial. And it's about giving complex tasks to the model, forcing reasoning. So for example, the output will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=408" target="_blank">00:06:48.620</a></span> | <span class="t">have chain of thought reasoning because you want to train the model to have this kind of reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=414" target="_blank">00:06:54.540</a></span> | <span class="t">Or it can be tasks like summarization. Explain me like I'm a five-year-old. This kind of task really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=420" target="_blank">00:07:00.620</a></span> | <span class="t">force the model not to only answer the question like a QA with answers you could find on Wikipedia. It also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=429" target="_blank">00:07:09.100</a></span> | <span class="t">forces it to reason over the prompt and give a more complex answer. So as a little recipe you can see here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=437" target="_blank">00:07:17.820</a></span> | <span class="t">I would recommend in general starting with open source datasets if you can combine some of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=443" target="_blank">00:07:23.900</a></span> | <span class="t">Then you can apply different filters. The first one is data deduplication. It can be either exact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=449" target="_blank">00:07:29.580</a></span> | <span class="t">because you want to remove duplicates. It can be fuzzy. So same idea. And then you have data quality</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=457" target="_blank">00:07:37.740</a></span> | <span class="t">filters. Here you have different techniques. It can be rule-based filtering. For example, you want to remove</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=463" target="_blank">00:07:43.100</a></span> | <span class="t">every single row where you have as an AI assistant, I cannot because people hate it. But you can also use more clever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=470" target="_blank">00:07:50.860</a></span> | <span class="t">techniques like reward models or LLM as a judge to evaluate the quality of each sample and filter out the bad samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=478" target="_blank">00:07:58.860</a></span> | <span class="t">And then you can use data exploration with different tools like Lyla, Economic Atlas, text clustering, to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=484" target="_blank">00:08:04.220</a></span> | <span class="t">topic clustering, to visualize your dataset, to get ideas on how to improve it. And with these ideas, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=491" target="_blank">00:08:11.820</a></span> | <span class="t">go back to data generation and start the process all over again. In terms of SFD techniques,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=497" target="_blank">00:08:17.900</a></span> | <span class="t">we have three main techniques. Full fine-tuning. This is the most basic one. You take the base model and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=504" target="_blank">00:08:24.220</a></span> | <span class="t">just train it on the instruction dataset. It has the best performance, but it's also very inefficient in general. A</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=511" target="_blank">00:08:31.020</a></span> | <span class="t">more efficient way of seeing it is LoRa. With LoRa, you are going to freeze all the pre-trained weights and you add</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=518" target="_blank">00:08:38.780</a></span> | <span class="t">adapters to each targeted layer. These matrices A and B are these adapters. So you don't train on all the parameters of the base model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=530" target="_blank">00:08:50.220</a></span> | <span class="t">You only train a subset of them. So this is a lot faster. But it can still be costly because you're still loading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=538" target="_blank">00:08:58.460</a></span> | <span class="t">the entire model in 16-bit precision here. So a more efficient way is to quantize the pre-trained model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=547" target="_blank">00:09:07.660</a></span> | <span class="t">here in 4-bit precision. This is Q LoRa. And you apply the same idea that you had with LoRa, but this time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=555" target="_blank">00:09:15.180</a></span> | <span class="t">the weights are heavily quantized. So you have a lower VRM usage. The problem is that it also degrades</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=560" target="_blank">00:09:20.540</a></span> | <span class="t">performance. So there's a trade-off here. I want to briefly mention some hyperparameters, but Daniel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=566" target="_blank">00:09:26.860</a></span> | <span class="t">already talked about a lot of them. So I'm going to be brief. I think the most important one is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=572" target="_blank">00:09:32.060</a></span> | <span class="t">learning rate. The learning rate is model dependent. It requires a few experiments to be able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=578" target="_blank">00:09:38.220</a></span> | <span class="t">really tweak it and find the best one. Generally, I would recommend to go as high as you can until your loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=584" target="_blank">00:09:44.780</a></span> | <span class="t">explodes like in this graph. Then you can reduce the size of the learning rate. Other super important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=592" target="_blank">00:09:52.460</a></span> | <span class="t">hyperparameters and number of epochs. I would say that depending on the size of the data set, you can have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=597" target="_blank">00:09:57.740</a></span> | <span class="t">more or less epochs. Sequence length is also good because it's a trade-off with the batch size because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=605" target="_blank">00:10:05.180</a></span> | <span class="t">the longer sequence lengths you have, so the bigger the context window, the more VRM you're going to use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=611" target="_blank">00:10:11.100</a></span> | <span class="t">But you don't need to use a sequence length that's as big as the pre-trained model. Then you have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=617" target="_blank">00:10:17.900</a></span> | <span class="t">batch size. You want to maximize it to maximize the utilization of your GPUs. And then you have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=624" target="_blank">00:10:24.540</a></span> | <span class="t">the lower with the rank. This is quite easy to fine-tune, so I don't want to go into the details here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=630" target="_blank">00:10:30.940</a></span> | <span class="t">Let's talk about model merging now. Model merging is the idea that you can take the weights of different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=638" target="_blank">00:10:38.940</a></span> | <span class="t">fine-tuned models and you can combine them together so you just can leverage what the open source community</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=648" target="_blank">00:10:48.620</a></span> | <span class="t">has produced on the hanging face hub, for example. It doesn't require any GPUs, so it's super efficient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=655" target="_blank">00:10:55.660</a></span> | <span class="t">and it provides excellent results. So the OpenLM leaderboard was updated this morning. So we have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=663" target="_blank">00:11:03.020</a></span> | <span class="t">version two now, but this is the version one. I haven't had time to update it. But you can see that for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=669" target="_blank">00:11:09.660</a></span> | <span class="t">seven B parameter models, the entire top eight or top 10 is just merge models. So it really shows that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=678" target="_blank">00:11:18.300</a></span> | <span class="t">this approach is extremely effective at producing high-quality models. And you can find similar results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=684" target="_blank">00:11:24.220</a></span> | <span class="t">on really a lot of different data sets. I would recommend using MerchKit. This is like the leading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=689" target="_blank">00:11:29.740</a></span> | <span class="t">library in this space with a lot of different techniques that are implemented there. So here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=696" target="_blank">00:11:36.220</a></span> | <span class="t">you can see the family tree of merged models. So you don't really need to see the name of the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=704" target="_blank">00:11:44.460</a></span> | <span class="t">but you see that every node is actually a model. And we actually merge different merges together until</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=711" target="_blank">00:11:51.020</a></span> | <span class="t">it becomes like a giant family tree. This one is actually quite small. It can get a lot crazier than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=716" target="_blank">00:11:56.620</a></span> | <span class="t">that, but it didn't fit on one slide. So I'll choose this one instead. About the merge techniques</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=722" target="_blank">00:12:02.940</a></span> | <span class="t">themselves, I want to mention a few of them. The first one is called SLURP. It stands for Spherical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=730" target="_blank">00:12:10.300</a></span> | <span class="t">Linear Interpolation. So the idea is really to apply spherical, but linear interpolation with the weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=737" target="_blank">00:12:17.660</a></span> | <span class="t">of different models. You can only merge two models at the same time with this technique, but you can really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=743" target="_blank">00:12:23.660</a></span> | <span class="t">tweak it with different interpolation factors for different layers. Here's a model that I've made in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=749" target="_blank">00:12:29.980</a></span> | <span class="t">your Beagle 14.7b, which was a really efficient way of leveraging the different models that were created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=759" target="_blank">00:12:39.740</a></span> | <span class="t">by the open source community. And then you have there. So in there, you want to reduce the redundancy of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=766" target="_blank">00:12:46.300</a></span> | <span class="t">model parameters. To do that, you're going to use pruning. You're going to select the most significant parameters in your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=772" target="_blank">00:12:52.300</a></span> | <span class="t">model weights, and you're going to rescale the weights of these source models. The advantage that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=779" target="_blank">00:12:59.500</a></span> | <span class="t">it has is that you can merge different models, not just two, but even more together. And I would advise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=786" target="_blank">00:13:06.460</a></span> | <span class="t">I would recommend this technique, and not with just two models, not with three, but like with seven or eight models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=792" target="_blank">00:13:12.140</a></span> | <span class="t">It works really, really well. So I strongly recommend that. Then you have a very funny technique called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=800" target="_blank">00:13:20.300</a></span> | <span class="t">pass-through. And in pass-through, you can concatenate layers from different LLMs. It can also be the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=807" target="_blank">00:13:27.660</a></span> | <span class="t">one. We call it self-merge. And so here you have an example that I've made recently. It's called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=813" target="_blank">00:13:33.980</a></span> | <span class="t">Metal Llama3 120B Instruct because I took Llama3 70B Instruct and I just repeated 10 layers six times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=822" target="_blank">00:13:42.940</a></span> | <span class="t">So you could say, like, this shouldn't work at all. Like, come on. You haven't even trained the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=829" target="_blank">00:13:49.100</a></span> | <span class="t">This is ridiculous. Actually, yeah, this is ridiculous. People loved it on Twitter and Reddit and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=834" target="_blank">00:13:54.860</a></span> | <span class="t">online in general. So it shows that there's a lot of things that we can still discover with these merge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=843" target="_blank">00:14:03.820</a></span> | <span class="t">techniques, with these models. They do not -- they can be counterintuitive sometimes. And you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=850" target="_blank">00:14:10.140</a></span> | <span class="t">that this model in particular was particularly good at creative writing. It was also quite unhinged in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=856" target="_blank">00:14:16.860</a></span> | <span class="t">general, but really good at creative writing. And now it's being used by a lot of people, even though it's super big.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=863" target="_blank">00:14:23.580</a></span> | <span class="t">But no kind of fine-tuning at all. No, no fine-tuning. Nothing. And then I want to mention the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=872" target="_blank">00:14:32.060</a></span> | <span class="t">technique, which is called Mixture of Experts. So in traditional Mixture of Experts, you are going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=878" target="_blank">00:14:38.460</a></span> | <span class="t">pre-train a model with a router -- you can see on the bottom here -- and different feed-forward network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=885" target="_blank">00:14:45.980</a></span> | <span class="t">layers. And you pre-train it from scratch. But you can do something quite smart with merging,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=893" target="_blank">00:14:53.420</a></span> | <span class="t">where you extract the feed-forward network layers from different fine-tuned models. And you combine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=898" target="_blank">00:14:58.140</a></span> | <span class="t">them together like this. So we call this a Franken-MRE. You add a router, you combine the FFN layers from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=905" target="_blank">00:15:05.340</a></span> | <span class="t">different models. And this is how you create a mixture of experts. It's actually pretty cool. It works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=914" target="_blank">00:15:14.700</a></span> | <span class="t">pretty well in practice. You can see on the left a MerchKit config for the Beyonder model. So for this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=923" target="_blank">00:15:23.180</a></span> | <span class="t">model, I selected four different fine-tuned models. One as a chat model, one as a code model, one as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=930" target="_blank">00:15:30.380</a></span> | <span class="t">role-play model, and one as a math model. You can see that I'm using positive prompts here. So actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=936" target="_blank">00:15:36.220</a></span> | <span class="t">it's a way to initialize the router. Because if you go back to the previous slide, we can see that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=943" target="_blank">00:15:43.340</a></span> | <span class="t">router is supposed to select for each token and each layer where -- like which feed-forward network layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=950" target="_blank">00:15:50.700</a></span> | <span class="t">is going to be used. We use two in general. And so how do we initialize it? If we do not fine-tune it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=957" target="_blank">00:15:57.980</a></span> | <span class="t">once again, we don't want to fine-tune it. We can, but we don't necessarily want to. In this case, we're just going to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=964" target="_blank">00:16:04.140</a></span> | <span class="t">these positive prompts, calculate their embeddings, and use these embeddings to initialize the routers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=969" target="_blank">00:16:09.980</a></span> | <span class="t">And that works really, really well. So those are two models that I've used. For Fixtral, I had to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=974" target="_blank">00:16:14.460</a></span> | <span class="t">modify it to make it compatible with Phyto. And that outperformed the base model on a lot of tasks. So it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=982" target="_blank">00:16:22.780</a></span> | <span class="t">really a good technique to use in general. But I would say that if you compare it to merging, as we saw with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=992" target="_blank">00:16:32.300</a></span> | <span class="t">Slurp and with Dare, I would say that if you want to increase the performance, it's better to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=1000" target="_blank">00:16:40.140</a></span> | <span class="t">Slurp and Dare instead of a mixture of experts, because this is a bit more experimental. This doesn't -- this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=1007" target="_blank">00:16:47.100</a></span> | <span class="t">will not bring you the same level of performance. And here you can see the results of the Beyonder model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=1015" target="_blank">00:16:55.260</a></span> | <span class="t">You can see that the other models I'm comparing to are the source models that I've used in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=1021" target="_blank">00:17:01.100</a></span> | <span class="t">in this merge. So it's quite remarkable to see that it's actually performing better than the source models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=1029" target="_blank">00:17:09.180</a></span> | <span class="t">on a lot of different benchmarks. So, yeah, that's it for me. Thank you for your attention. If you are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=1038" target="_blank">00:17:18.300</a></span> | <span class="t">interested in knowing more, if you want notebooks to run some code, I created the large language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=1044" target="_blank">00:17:24.940</a></span> | <span class="t">course. All these notebooks are available on GitHub LLM course. And yeah, thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=uLrOI65XbDw&t=1050" target="_blank">00:17:30.700</a></span> | <span class="t">Thank you. .</span></div></div></body></html>