<html><head><title>Spotlight on Canva | Code w/ Claude</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>Spotlight on Canva | Code w/ Claude</h2><a href="https://www.youtube.com/watch?v=Ac4LiuoJT20" target="_blank"><img src="https://i.ytimg.com/vi/Ac4LiuoJT20/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Transcript</h3><div class='max-width'><p>Hello everyone. Hi everyone. Hello, hello. Thank you. Thank you all so much for joining me today. My name is Danny Wu. I'm head of AI products at Canva, and we're a visual communications platform. Today, I'm really excited to share a bit about how we have built Canva Cloud and how we've been working with Anthropik and using the amazing Cloud models.</p><p>I'll be first starting by giving an intro to Canva, as well as taking it behind the story of Canva code, like what gave us the idea, why we built it, as well as the things we learned, and finish up by sharing a few lessons that will hopefully be helpful and some time in Q&A.</p><p>So I'm incredibly excited, and let's jump right in. Firstly, just a little bit of context about Canva, in case you don't know what we are. What we do is we really bring the entire design journey and experience in to one simple page and one simple experience. A decade ago, design used to be quite inaccessible, and it was just quite hard.</p><p>you had to learn how to use fairly complex tools that could cost a lot of money, and you had to go to so many different platforms and services to complete a design, like finding stock photos, getting the right fonts, starting with a template, or publishing. And what we do is we really have integrated all the different steps of this journey into just one page and one platform, so you can create a presentation, or you can create a poster, use all the templates, generate some amazing AI images, create some text, and publish to a website, publish to, or print it out, and get it delivered to your door.</p><p>That's really what we do. And so we have a pretty simple mission, and we've had the same mission for the past decade and a bit, and it's really to empower the world to design. When we think about this, we really think about empowering absolutely everyone, whether you're a student, whether you're a teacher, whether you're a non-profit, or whether you're a marketer and creative, creative in a large enterprise, to design just about anything, publish it anywhere, with every ingredient, like photos, video, music, and more, supporting every language, as well as every single device.</p><p>And the thing about AI is that we really see it as something that absolutely supercharges the core premise of what Canva was built to do, which is to allow everyone to make designs really simply and really easily, and make it take less time, instead of this being time-consuming and tedious, that you create amazing outputs really, really quickly.</p><p>And as I'm sure you all know, the power of generative AI is just really helping us, helping us accelerate on all of those fronts. So when it comes to our AI strategy, we have a three-pronged approach. When it comes to things like really, to things like specialized things, like design generation and visual understanding, that's where we're really investing our efforts into developing our own models for our unique needs.</p><p>But we're also really huge fans of our flexible approach, where we add magic everywhere to the Canva product, to the best commercially available and open-source models. And this really helps us deliver AI-powered features and workflows to users much faster, much more scalably, and also much cheaper. And finally, to round things off, we have our app ecosystem where any developer can build apps, including AI apps, for all of our 300 million-plus users.</p><p>And just a bit of a short timeline of our AI journey, we started in 2017 using machine learning for search rankings and counter-recommendations, and that was already really cool. We launched Background Remover, which lets you take any image and would use computer vision to remove the background from it.</p><p>And that continues to be one of our most popular and highest revenue driving features. With Diffusion Models and Gen AI Wave, we launched Text-to-Image, Magic Write, Magic Edit, Magic Design, and so much more as part of Canvas Magic Studio, which is a collection of integrated and native AI features that help you with just about every step of design.</p><p>And actually, just a month ago in LA, we had Canva Create, and we had some very exciting launches. We launched Canva AI, we launched Canva Sheet, and of course, Canva Code, which I'm here to talk about. So what is Canva Code? Let me play a little video. If you have an idea, a dream, of what you want to create, just in Canva AI, just prompt it, describe what you want, and we use Quad to generate amazing interactive prototypes that really understand you and really help just about everyone, especially non-technical folks and non-engineers, create their dreams.</p><p>And then with one click, including a Canva design, you can publish your website, get a custom domain, everything without touching a single line of code or knowing what CLI is. So what's the story behind it? And you might also think, you know, design and code, they don't seem like they naturally mix, right?</p><p>So why did we, I guess, why did we make Canva code? So I actually want to zoom out a little bit. And when we build products at Canva, we like to describe it as going from the chaos to clarity spectrum. So at the very start, it might just be a low idea, it might just be like a simple vision deck that's not really thought through of something that's really, really cool.</p><p>And there's a stage where there's just a lot of openness, but also a lot of confusion and chaos and just, what do we actually want to build? How should the flows work? Like, who is this for? Like, how might we build it? And as we answer those questions and get more designs, really refine them, we navigate through those stages and get to extreme clarity on the other end, which is definitely all of our happy place.</p><p>We found that interactive prototypes are just so, so, so incredibly helpful at the earliest stages of chaos. They're so much more expressive. They allow, they allow teams, they allow teams, product engineer and design leads to communicate ideas using the highest fidelity. They allow stakeholders to actually try through, try and click through all the different, the actual experience and give feedback, test it with users.</p><p>And this really helps us go from one to the very, very end. The thing about interactive prototypes is that they can actually take a bit of engineering time, very precious engineering time, while we're working on so many different plans, so many different goals, closing the loop with our users and fixing bugs from our past launchers.</p><p>So they can, so they can, there's a resource cost to making really amazing high fidelity prototypes. And oftentimes, you know, if you have, if you have a triad of a product manager, a designer, engineer, like, jamming on this, there can also be a lot of back and forth to get something really right and really captured, especially for very wild ideas.</p><p>We actually discovered just how amazing it is to be prototyping using Claude internally. And a lot of our teams have started actually using Claude to make interact with artifacts. Artifacts really changed how we do product development and dreaming at Canva. So when we had new ideas and new features that we want to build or new flows, like we're making an active prototype and putting it and sharing it around.</p><p>And that really accelerated things that enabled us to make way more prototypes. So we started prototyping with Claude, and we started embedding them in Canva designs. You can actually see like a super early Claude artifact. We were trying, we're trying to, to update our search box and include, include our latest AI features.</p><p>So we did a very, very low fidelity like Tailwind prototype. And if you've used Canva recently, you see that, you see that we've launched, we call this internally the Wonder Box. But then we also kind of realized, this is so cool, this is absolutely amazing power. But just using it for internal prototypes, that's like 1% of the way there.</p><p>We realized just how much, like bringing the power of coding to everyday people and non-technical users unlocks. It's a whole, whole world of possibility. So whether you're, say, like a teacher creating an educational game, or whether you're like a wedding planner creating a seating charter tool, or like a marketer building interactive activation experiences, the possibilities are truly endless.</p><p>And internally in Canva, across all of our teams, we really started using this functionality more and more for just about everything. But just like, you know, just like kind of Canva's like DNA, we also realized that this power is something that is very broadly inaccessible. Just about 0.5% of internet users are engineers and know how to code, which is a pretty small number.</p><p>So what if we could bring this amazing power to the whole world, the rest of the 99.5? And that's really where like the idea, the idea and the vision for Canva code was born. We really wanted to make it incredibly easy for people to create entirely new interactive experiences.</p><p>Like whether it's, you know, like a lovely thank you card to the team, whether it's a checklist for closing out the office, whether it's a meal plan generator, or even something like a timeline in a Canva presentation. There's so many possibilities, and these are actually real examples that our team has been creating.</p><p>So what did we do? We did something that was actually pretty new to how we do product back then, which was just maybe two or three months ago. And we started making a functional prototype using Claude. Claude code wasn't out yet. So we just used, yeah, we just used, that was Sonnet 3.5 back then.</p><p>And what we did, what we did with a functional prototype was it was a fully working experience that's not part of the main Canva code base. And just really allowed us to test, like, test different ideas, test different UI and concepts, and do that much faster and actually play around with it and use it every day.</p><p>So it let us test ideas and test concepts, including really dreamy and really wacky ones, very quickly. It also allowed us to get real user feedback. So we did user testing sessions, and we put this in front of users, and gave them very little guidance, and just saw what the use cases were, saw how they used it, saw where they got confused, saw where the magic moment was.</p><p>And it was also a really efficient ground for us to be experimenting with all the different models that are out there. And so we started building it in Canva for Rails, because after we got really confident about it, we hooked it up to Canva code base. We handled things like responsiveness, nine slicing, and editing, and camera design.</p><p>But we also continued to iterate on our prototype, and basically that was essentially the next version, where we did things like div-based support, which is coming very, very soon. And that's also when we tested this experience across all the different camera surfaces Canva code can end up in. Like, you know, whether it's in the editor, whether it's on mobile, or whether you're on a presentation mode.</p><p>We actually even printed out a T-shirt with a Canva code, just to make sure that it actually worked, which was pretty fun. Like, obviously it wasn't interactive, it was like more of just a static screenshot, but you can print it on a mug or a T-shirt. And the way it works is that we put Canva code creations on an iframe, since it is really arbitrary user-generated content.</p><p>And we just used a similar approach to how we support embeds in Canva designs. When it comes to choosing the model, and why we ended up with Claude's solid models, this is definitely a really, really fun question to explore. And the first thought you all probably have is, you know, evals, evals, and evals.</p><p>And that's definitely really important, especially for correctness. But when we looked at the model choice for Canva code, we had a few additional considerations as well. We really value how magical it is, and really like the delightfulness, as we like to call it. And when we tested across real user requests, the ability for models to handle very short and very under-specified user prompts.</p><p>Things like, "Hey, can you make me a game that does blah?" Or, "Hey, can you make me a menu planner?" The user isn't really giving you very, very specific requirements, and the LLM just has to be inferred. That was really, really important to us. The model's ability to make amazing web designs was also super important.</p><p>We are a visual communication platform after all. And finally, of course, things like latency as well as scalability and capacity were also very, very real and important factors. Back around March, we tested a series of models across not just whether it generated valid code, but also, subjectively, how good was that web design at following the instructions we have in the prompt around things like UI, UX, the information hierarchy, all that kind of stuff?</p><p>How good is it? How good is that? How good is that? How good is that? How good is that? Things like SVG generations, which is something that we're always really impressed by with Claude's family of models. Things like animations, like it's able to set things like C index correctly.</p><p>It's able to, you know, do colors, do timings really, really well. And we were just really delighted with -- we were already really delighted with Sonic 3.5 V2. 3.7 was a huge, huge step up. And with today's announcement of Claude 4, like that's something that's really a transformational leap in intelligence for coding.</p><p>And we're also super excited about that as well. But I guess my takeaway here is like really think about, especially when you're launching to users, like think about the complete user experience and what they care about. Don't be super academical and just focus on, you know, things like how good it does at benchmarks or how good it does at, you know, like large code bases or really big requests.</p><p>Like, does it actually do the things like generating icons and SVGs really well too? Because those are really important to all of our users. And finally, three lessons we've learned. The first one, and this is a pretty interesting one to us, was just how important it is to actually communicate AI's limitations in all the different places where there are AI limitations.</p><p>So one of the product principles that we have at Canva is that everything should just work. It should just do what it says on the tin. And when coding and building interfaces with LLMs, like generative -- yeah, LLMs can be -- can make very beautiful things, but they might not actually work.</p><p>And so when we did some in-real-life user testing sessions, we had users like make things like portfolio pages, just kind of galleries and things like that. They included contact forms, but since Kevin code right now is just front-hand only, those contact forms didn't work, and users thought it was broken.</p><p>They don't really understand, like, you know, it's just front-hand only. Like, it needs a destination, needs to hook it up to, you know, like an email sender and things like that. So one of the things we did is we made sure to prompt the model to actually very visibly communicate things that wouldn't work so that they don't -- so that they at least understand that it's the limitations and that it's intentional, and it's not them doing something wrong.</p><p>So the second lesson is we are absolutely in love with the power of building functional prototypes. So if you don't know -- so we have a monorepo at Canva with just about half a million commits over the past decade. We support more than 100 languages, many different platforms. There's also -- there's also global laws and regulations in all the environments we operate.</p><p>We have enterprise customers with a lot of contracts, SLA's and all that kind of stuff. So building things like in Canvas repository, it enables us to scale and serve all of our customers, but it's not really the fastest place to be experimenting and testing new concepts, especially in the fast-moving world of AI.</p><p>So by building and -- we're starting to build and iterate and develop and test and working prototypes, we could move so much more faster and dream heaps and heaps of a head. What we found really useful was that our team was really actively using these prototypes day-to-day for real work and real tasks, and that really gave us a lot of learnings and outstanding.</p><p>The live user testing helps identify issues, bugs, and really inform our roadmap before we even started actually building it for real. And it's kind of -- it was kind of entirely closing the loop. We built it very, very heavily with quad models and just allowed us to move -- just how to make magic.</p><p>The last lesson I want to share is, like, the importance of really differentiating and playing to your strengths. So in this AI world, like, there's so many products and a barrier to entry, like, especially with things like cloud code and AI coding can be really, really low. So it's really important to be thinking about what are your unique strengths?</p><p>What are our unique strengths in this market and the product that we're building? When it comes to camera code, it's two things. But the first one, the most important, is really we're explicitly not building camera code for technical users or engineers right now. We're starting bottoms up with non-technical users because we want to basically bring the superpower to just about everyone, to the billions of internet users out there.</p><p>And then move bottoms up and get to higher and higher levels of sophistication. So for us, things like how easy it is to start, how guided it can be, and how well it turns people's dreams or screenshots of loss in reality is really important as we move up and up into more advanced functionality.</p><p>And I think that's a really important thing to think about. You might not necessarily start bottoms up, but definitely have a focus for what you target. And leveraging your unique strengths and what you already have and what your users already use is really important. So here's a preview, for example.</p><p>Like we are working on integrating the camera code creations with Canvas Editor. So you can do things like change the colors using our color picker, apply your brand fonts, or drag and drop your photos from your asset library, and get what you see is what you get editing experience.</p><p>And, of course, we're spiking this on our interactive prototype. Finding and figuring out just what's the best way to leverage your unique strengths is definitely really, really important, for not just building something that offers value to users that other people can't. And we're just so excited about this era that we're now in and all the possibilities that we can unlock.</p><p>So, yeah. That's everything I have. Hope you -- we do have time for some Q&As if you want to chat. And I think there's microphones up there and there. Hope you -- thanks for having me. And I hope you found this session useful. Thanks so much. Could you share some tips on how you get the models to produce such beautiful frontends?</p><p>Oh, yeah. Yeah. Absolutely. So, we had -- we had a lot of our designers actually just really experiment a lot. Like, really just try from engineering. But some examples are really simple. Like, one is we instruct Claude to, you know, never have, like, a white, gray, or black background unless it's requested.</p><p>You always pick, you know, say, a nice color. Another one is we've incorporated things like just basically our product design principles. Like, you know, like we have just a set of guidelines on how information hierarchy should be, where controls and what buttons should be. And we just basically summarize and put that in there as defaults it tries to follow.</p><p>So, yeah. Everything's more or less, like, just in the prompt. Thank you. Hello. Hi. I'm interested in what is your perspective on, like, the future of AI and design more broadly? And how should people who design be thinking about how much you integrate AI? Yeah. That's a really great question.</p><p>Like, what we're really excited about is how AI, like, can unlock and supercharge human creativity. Like, this technology is allowing people who normally, like, you know, would normally take, like, say, weeks or days to get to some output. Like, you can now use AI to, firstly, like, clean up all your tedious, to not do all your tedious tasks, but it also allows you to dream and prototype.</p><p>I think a good example is when we were planning our event, kind of, create event. Like, our creative and motion teams were using diffusion models to really quickly make storyboards for different talks and different activations and experiences. And that allowed us to just, like, get an impression of those ideas, get some inspiration, and make the actual creative process, like, basically give superpowers to the creative process.</p><p>So, I think, like, what we're really excited about is just how much, like, how much AI can actually help, like, exponentially increase human creativity. Cool. Well, thank you. Thank you all so much for having me. Bye. Bye. Bye. Bye. Bye. Bye. you you</p></div></div></body></html>