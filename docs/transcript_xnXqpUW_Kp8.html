<html><head><title>Building a Smarter AI Agent with Neural RAG - Will Bryk, Exa.ai</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">Back to Index</a><h2>Building a Smarter AI Agent with Neural RAG - Will Bryk, Exa.ai</h2><a href="https://www.youtube.com/watch?v=xnXqpUW_Kp8" target="_blank"><img src="https://i.ytimg.com/vi_webp/xnXqpUW_Kp8/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Transcript</h3><div class='max-width'><p>All right, so I was gonna give a live demo coding, but I will, but I know you all are actually here to hear a cool story. So I'll tell you a story about web search built for AI, and then we do some coding at the end. This story will end with this slide, one API to get any information from the web, and you'll know what this means by the end, but the story starts in 1998, and what you're looking at is the state-of-the-art in information retrieval in 1998.</p><p>You type in a word Australia to this new search engine called Google, and it magically finds you all the documents that contain the word Australia from the web. It's crazy. And the big insight of Google was they had this page rank algorithm, so the results are ranked by authority based on the graph structure of the web.</p><p>And this was a clever algorithm, and it was really cool. I was two years old at the time, so if I was conscious, I would have thought this was cool. Okay, and now our story skips 23 years to 2021. By this point, I was conscious, barely. And I noticed that GB3 had recently come out, and it was this magical thing that you could input a whole paragraph explaining exactly what you want, and it would really understand the subtleties of your language and give you an output that exactly matched.</p><p>And it's hard to remember how magical this was, but it was really magical in 2021. And at the same time, I noticed there was Google, which, you know, you type in a simple query, like shirts without stripes, and it would give you shirts with stripes, which is crazy. It like doesn't understand the word without, because it's doing a keyword comparison algorithm.</p><p>And so I decided that for the next at least 10 years, I'm going to devote myself to building a search engine that combines the technology of GB3 with a search engine to make a search engine that actually understands what you're saying at a deep level, and understands all the documents on the web at a deep level, and gives you exactly what you asked for.</p><p>This is a very big idea, and we've worked on it for four years and a lot of progress, but it would change the world if you actually solve this problem. And so in 2021, we joined YC, summer 2021. We raised a couple million dollars, and we did what every YC startup should do.</p><p>We spent half of it on a GPU cluster. I'm joking. You shouldn't do that. And then we also followed YC's advice, where we didn't talk to any users or customers for a year and a half, and we just did research. Again, you shouldn't do that. You shouldn't talk to users.</p><p>But in our case, it made sense, because we were trying to solve a really hard problem, which is like redesign search from scratch, using the same technology as GB3, this like next token prediction idea with transformers. What if you could apply the same thing to search? And this is actually one of our OneDB training runs.</p><p>The purple one, I believe, was a breakthrough where it really learned. There was a few breakthroughs along the way involving random data sets and different transformer architectures that we were trying, and this purple one really started to work well. And the general idea we had was like, okay, so what is a search engine?</p><p>You have like a trillion documents on the web. And traditional search engines on a very high level will create like a keyword index of those documents. So for each document, you ask what are the words in those documents, and you create this big inverted index where you map from like words like brown to all the documents that contain that word.</p><p>And then at search time, you know, when a search without stripes comes in, you do some crazy keyword comparison algorithm and get the top results. That's obviously a simplification of what Google does, but at a fundamental level, it's doing a keyword comparison. But the idea was like, what if you could actually, so with transformers, like the big thing is like, what if you could turn each document not into a set of keywords, but into embeddings?</p><p>And these embeddings can be arbitrarily powerful, right? Like it's a list of, an embedding is just a list of numbers, and it could represent lots of information. So an embedding, it doesn't just capture the words in the document, but also the meaning, the ideas in the document, and the way people refer to that document on the web.</p><p>And you know, embedding can be arbitrarily big, and so it like, of course, in the limit, it would just destroy keywords. And so you have this like, arbitrarily powerful representation. And now the fundamental idea was just like, the bitter lesson, what if we could like, you know, train transformers to output embeddings for documents, and if we keep getting more and more data, and that's high quality, we could make a search engine that actually understands you.</p><p>And the way it would work at inference, at search time is like, a search comes in, a query comes in like shirts without stripes. Traditional search engines would use the above thing, where they would do a very fancy keyword comparison, and a bunch of other things. And then instead, we would just embed the shirts without stripes, and compare it to the embeddings of all the trillion documents.</p><p>And you know, after a year and a half, we actually had a new search engine that worked in a very different way. And you search shirts without stripes on Google, I'm sorry, on Exa, and you get a list of results that actually do not have stripes. It's a simple example, but it could handle way more complex queries, like paragraph-long queries.</p><p>And when we launched this in November 2022, we got a lot of excitement on Twitter. This is a very new paradigm for search. You could do all sorts of interesting queries that you couldn't do before. And then, two weeks later, this happened. It was a small tweet. And this is a visual depiction of San Francisco at the time.</p><p>You guys probably all remember this. And then this is a visual depiction of the Exa team at the time. Because ChatGPT completely changed the way we interact with the world's information. You know, like, everyone can now use an LLM to just, like, talk to their computer, and get information.</p><p>And we were thinking, wait, is there even a role for search in this world? Like, these LLMs are so powerful. And then, very quickly, we realized, yes, there is a role. Because LLMs don't know everything on the web. So, for example, if you ask an LLM like GPT-4, find me cool personal sites of engineers in San Francisco.</p><p>It can't. Like, it just doesn't have that in the weights. It'll apologize, whatever. And, you know, there's a very simple information theory argument here, where it's like, there literally isn't enough information in the weights of GPT-4 to store the whole web. GPT-4 will call, like, we don't know exactly how many parameters.</p><p>I think someone leaked it on YouTube once. But it's like, oh, you know, a couple trillion parameters. You could call it, like, less than 10 terabytes in the weights of GPT-4. And then the internet is, like, over a million terabytes. And that's just the documents on the web. There's also images and video.</p><p>And that's way more. Actually, the web, if you look, I did a tweet recently about the size of the web. And it's in the exabyte range. And our name is Exa. It's not a coincidence. Anyway, so, like, LLMs need to search the web, just from this simple argument. And they're going to need to do that for a long time.</p><p>Which, if you talk to ML researchers, they'll say the same thing. It's just, like, it's too hard. Also, the web is constantly updating. That's another problem. It's not just the size of the web. It's the constant updatingness of the web that makes it very tricky. So LLMs always will need search.</p><p>That's great. And so when you combine an LLM with a search engine like Exa, you can handle these queries. So, like, find me cool personal sites and engineers in SF. The LLM will search Exa, get a list of personal sites, and then, like, use that information to output the perfect thing for the user.</p><p>You're all very familiar with this. Like, LLMs plus search, it's obvious now, right? Like, everyone knows about it. But now let me tell you a secret about search that most people don't know. And the secret is that traditional search engines were not built for this world of AI. Traditional search engines were built for humans.</p><p>And humans are very different from AI. So every search engine, like Google, Bing, you name it, was built in a different era for this kind of creature. This slow flesh human that's typing keywords and wants to read a few links and really cares about UI of the page and all these things.</p><p>Like, it's a lazy human. They type simple keywords. Google is great for this creature. Google was optimized for this creature. It gives you exactly the kinds of things you would click on. But AIs are very different. Like, an AI can gobble up information like crazy. This is a much slowed down version of what our AIs probably feel like inside.</p><p>And so AIs are very different. They want to use complex queries, not simple ones, to find not a couple links, but just tons of knowledge, as much knowledge as they could get. Because they actually have the patience to just analyze it all extremely fast. And so the search algorithm that's optimal for this type of creature is not the same algorithm that's optimal for the human.</p><p>Like, that would be crazy if the same algorithm that was optimal for humans was optimal for AIs. And so, like, a lot of the tools, the search tools that we're talking about these days on Twitter and stuff like that, they're still using, like, the old traditional search combined with AIs.</p><p>It's just not the right puzzle fit. So, actually, we're really trying to think of, like, what is the right search engine for this AI world? And so just a few examples we could dive deep into of how AIs are different. Well, AIs want precise, controllable information. So, oh, by the way, when I say AI, I'm usually talking about, like, an AI product.</p><p>So imagine, like, in this case, like, a VC that's using an AI system to find a list of companies because they want to invest. So, you know, they're looking for something -- what's the next big thing? What's the next big thing that feels like Bell Labs? Well, when they tell their AI what they want, the AI will then go search a search engine, right?</p><p>And if it searches a search engine like Google, it'll get a list of results that humans like to click on. But it's not very information dense, and it doesn't even match what the person asked for -- what the AI asked for. The AI asked for startups working on something huge that feels like Bell Labs.</p><p>It should get a list of startups. It's kind of a crazy idea, but what if search engines actually returned exactly what you asked of them and not what Google knows you'll click on? And so, with AIs especially, they just want a search engine that returns exactly what they asked for.</p><p>Because what really the world's going to look like is you're going to interact with your AI agent, and you're going to ask for something, and then it's going to make tons of searches. Like, okay, maybe they want startups working on something similar to Bell Labs. Maybe they want startups working only in New York City that have this quality and that quality.</p><p>And they'll do all sorts of searches, and it just wants a search API that just does what it asks. And so you need a search engine like that. So X is like that. Another difference between AIs and humans is AIs want to search with lots of context. Again, if you have an AI assistant, and you talk to it all day, and then you ask for restaurants or apartments or what have you, the AI has lots of context on you.</p><p>So it should be able to search with this large multi-paragraph thing, saying like, you know, my human is a software engineer, and it likes these types of things, and I like these types of things. And like, can you give me, you know, restaurants that match those preferences? And so you need a search engine that could literally handle multiple paragraphs of text.</p><p>But traditional search engines like Google were not meant to do that because humans would never type in multiple paragraphs because they're too lazy. So Google was optimized for like simple keyword queries. So Google, I think, has like a few dozen keyword limit, whereas EXA can handle like multiple paragraphs of text.</p><p>Another big one where AIs are different than humans is AIs want comprehensive knowledge. Like, if you give a human 10,000 links or 10,000 pages, it doesn't know what to do with that. Like, it would take 10 days of extreme patience to process all that. But AIs can do it in three seconds if it's parallelized, right?</p><p>And so if I'm a VC and I want to report on like all the companies in a space, I want literally all the companies. And there's a huge amount of value to getting truly all of them and not just like the 10 or 20 that Google is able to find.</p><p>And so you need a search engine that exposes the ability to return 1,000, 10,000, whatever it is, and also has this semantic ability to like, you know, when you say like every startup funded by YC working on AI, you actually can get all of them. So like Google literally just can't do this at all.</p><p>Okay, I hope that through these examples, we see that the space of possible queries is actually like way larger than people realize. And until like 2022, we were kind of in this like top left blue world. So this circle is like the space of possible queries and the blues are like, you know, specific subsets of that space.</p><p>And so like, we were all in that top left corner of blue for a long time where you could, you know, search engines can handle like basic keyword queries like Stripe pricing or someone's GitHub page or Taylor Swift boyfriend or whatever it is. After 2022, everyone started to want the top right blue circle where it was like, hey, actually, I want to make queries like explain this concept to me like I'm a five year old or here's my code.</p><p>Can you like debug it? This is a form of query doesn't require search, but it's a another type of query that was introduced to the world in 2022. And then like, there's other types of queries like the semantic queries like people in San Francisco who know assembly. As far as I'm aware, X is like, I mean, X kind of like introduced this kind of query and does really well in them on those queries.</p><p>And then there's these really complex queries like find me every article that argues X and not Y from an author like Z. And we're starting to now have systems like X is like Websets product that could handle these things. And I think this is actually a huge space because this like turns the web into like a database you could filter however you want.</p><p>And that's really what AIs want. They want this like full control database like query system that they could just get whatever they need for their user. And then there are the queries that no one has thought of yet. Like every week we get tons of queries and like, oh wait, that's a really interesting type of query that that no search engine could do right now.</p><p>And eventually we'll try to, you know, handle all the queries that are possible. But there's so many new types of queries now because we have these AI systems and the stakes like the expectations have just gotten way higher. So now we end our story with the same slide, one API to get any information from the web.</p><p>So again, like X is trying to, if you go back, like handle not just like the keyword queries, but also the semantic queries and also the super complex queries and eventually all queries. We want one API that could like give these AI systems whatever knowledge they want. You have the AI and you have EXA providing the knowledge.</p><p>Oh, I only have four minutes. Okay. Okay. So that's, let's see. Oop. How do I go to a different part of my computer? Hmm. If I change to the code editor, how do I do that? Let's see. What? Oh, it's there. Oh, but I can't see it. That's so weird.</p><p>. Oh, cool. Okay. Okay. There we go. Okay. Cool. Well, first of all, just very quick exploration of this is our search dashboard. We could try different queries. I'll just point out like in the search API endpoint, you know, we expose lots of different toggles. So first of all, you just try out a query and get, it shows you the code and it gets you a list of results.</p><p>And it exposes tons of different types of filters that you might want to do. For example, like number of results, 10, 100, 1,000, whatever it is. You could have like date ranges or, you know, I only want to search over these domains. And it's a lot of toggles, but I think the point is actually you want the toggles because your AI is actually going to be calling this.</p><p>You want a search engine that gives you full control. And we have like neural and keyword search. So you could try different ones. Okay. Let me quickly jump to the code. Okay. So I prepared this like code, agent.py. So we made this agent, agent Mark. And Mark loves to make markdown out of things.</p><p>Anything you give it, it will make markdown. And Mark will make markdown. And so in this case, we're going to here. Well, I guess in this case, let's try this query. Personal site of engineer in San Francisco who likes information retrieval. Well, this is the kind of a query that neural would be a lot better at.</p><p>Okay. Save it. Oh, running the wrong agent. Okay. So it's just, it's making a query to get like a list of personal sites of engineers in San Francisco who like information retrieval. And Mark, the agent is just making a markdown output of that. That's a very neural type query.</p><p>You also might want to do a different type of query, which is like a more keyword heavy one. Let's see, like, my GitHub. So, okay. So here I would want to make a keyword query. So you just change the keyword. Search. So it's going to get information from my GitHub using keyword search, because this is a very typical, like, Google-like search that would work well, right?</p><p>Oh, God. I'm running this wrong one. Okay. Cool. That's information about Wilbrick's GitHub. And then, okay, so when you're actually building an agent, you're going to be combining lots of different types of searches. So neural searches and keyword searches and all sorts of other searches that X exposes. So, like, the right agent in the future is going to be this system that decides what type of search it needs for whatever the user says.</p><p>Like, it'll be like, oh, okay, I'm going to make, like, a neural search to get a list of things. And then for each one, I'm going to do a keyword search, right? You want to give the agent, like, just full access to the world's information in however way it wants.</p><p>Not just keyword search, but also all these other things. And so here, I one-shotted with O3 a GitHub agent, which combines these two queries. So, first, it'll -- because, you know, I want to get the GitHub of every engineer in San Francisco who likes information retrieval. So the agent will make a neural search to get a list of people, extract the names, and then search those using a keyword search to get their GitHubs.</p><p>And then if you run that -- here, it's just getting 10 results. But we could, you know, with EXA, we could do 100 or 1,000 if you're on an enterprise plan. So now it's getting all the GitHub info. Cool. So that's just an example. And, yeah, I mean, there are lots of other things that you could do with EXA.</p><p>Like, we actually just today launched this research endpoint where it will actually do, like, as much searches and LLM calls in the background to get you that perfect report or that perfect structured output for the thing you asked for. So it's kind of like a deep research API. And it's state-of-the-art deep research API.</p><p>Cool. That is the talk. I hope that was interesting. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. We'll see you next time.</p></div></div></body></html>