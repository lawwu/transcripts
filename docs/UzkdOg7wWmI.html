<html><head><title>ðŸ¤— Hugging Face just released *Diffusers* - for models like DALL-E 2 and Imagen!</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>ðŸ¤— Hugging Face just released *Diffusers* - for models like DALL-E 2 and Imagen!</h2><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI"><img src="https://i.ytimg.com/vi_webp/UzkdOg7wWmI/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=0">0:0</a> What are Diffusers?<br><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=115">1:55</a> Getting started<br><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=260">4:20</a> Prompt engineering<br><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=574">9:34</a> Testing other diffusers<br><br><div style="text-align: left;"><a href="./UzkdOg7wWmI.html">Whisper Transcript</a> | <a href="./transcript_UzkdOg7wWmI.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Today we're going to have a look at a new library from Hugging Face called Diffusers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=5" target="_blank">00:00:05.280</a></span> | <span class="t">and it covers what are called Diffuser Models. Now Diffuser Models if you don't know what they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=11" target="_blank">00:00:11.600</a></span> | <span class="t">are you've probably heard of a few of them already. They are like OpenAI's DALI2 is a Diffuser Model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=18" target="_blank">00:00:18.880</a></span> | <span class="t">Google's Imogen, Midjourney's Image Generation Model as well. There are a lot of these Diffuser</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=28" target="_blank">00:00:28.240</a></span> | <span class="t">Models and they are producing pretty insane things. If you know what GANs are you can kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=35" target="_blank">00:00:35.600</a></span> | <span class="t">of think of them as doing that same thing of generating something. In the case of the three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=46" target="_blank">00:00:46.240</a></span> | <span class="t">models I just mentioned it's generating images but they can also generate other things as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=51" target="_blank">00:00:51.440</a></span> | <span class="t">They can generate audio, video and I imagine probably a lot more. So they are pretty cool</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=58" target="_blank">00:00:58.320</a></span> | <span class="t">and also pretty new. But already pretty much everyone knows about DALI2 and the other Diffuser</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=71" target="_blank">00:01:11.280</a></span> | <span class="t">Models as well. They're already making a big impact. So Hugging Face's decision to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=78" target="_blank">00:01:18.400</a></span> | <span class="t">a library to support this in a more open source way in contrary to the OpenAI, Google and Midjourney</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=87" target="_blank">00:01:27.360</a></span> | <span class="t">approach where they have everything behind closed doors, which fair enough they're probably massive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=91" target="_blank">00:01:31.520</a></span> | <span class="t">models and most of us can't run them anyway. This decision by Hugging Face I think is a pretty good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=99" target="_blank">00:01:39.040</a></span> | <span class="t">one. It means that normal people like me and you can actually start playing around with these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=106" target="_blank">00:01:46.320</a></span> | <span class="t">models which is really cool. So let's have a look at what we can do with the first version</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=112" target="_blank">00:01:52.960</a></span> | <span class="t">of this library. So to install the library we just pip install Diffusers. You may also need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=123" target="_blank">00:02:03.120</a></span> | <span class="t">add Transformers onto the end there. I'm not sure, I already had Transformers installed so it might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=128" target="_blank">00:02:08.880</a></span> | <span class="t">not be necessary. Let's just have a look at this first example. So I've taken this example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=136" target="_blank">00:02:16.000</a></span> | <span class="t">from the GitHub repo, modified it a little bit and played around with the prompts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=141" target="_blank">00:02:21.760</a></span> | <span class="t">But all we're doing is taking this ConvVis text to image model, so this is a Diffusion model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=150" target="_blank">00:02:30.560</a></span> | <span class="t">Diffuser, and we're just creating this Diffusion pipeline using this model ID.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=156" target="_blank">00:02:36.640</a></span> | <span class="t">And the example they gave was something like a painting of a squirrel eating maybe a mango or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=164" target="_blank">00:02:44.720</a></span> | <span class="t">something along those lines, I don't remember. So I just, I want banana just to see what happens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=170" target="_blank">00:02:50.960</a></span> | <span class="t">And we get this pretty cartoony image here of a, I mean I suppose it's not necessarily eating the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=178" target="_blank">00:02:58.240</a></span> | <span class="t">banana but it's definitely a squirrel with a banana. So with just a few lines of code here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=184" target="_blank">00:03:04.240</a></span> | <span class="t">we got that which is pretty cool. So yeah, already something to be pretty impressed with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=194" target="_blank">00:03:14.240</a></span> | <span class="t">So that's cool, but I would say I wanted to play around with these prompts and just see what it can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=203" target="_blank">00:03:23.760</a></span> | <span class="t">do. Now just to be very clear, this is a very small and basic model, so we're not going to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=212" target="_blank">00:03:32.640</a></span> | <span class="t">DALI 2 standard images from this or Imogen standard images from this, which is to be expected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=222" target="_blank">00:03:42.080</a></span> | <span class="t">But nonetheless, we can play around with it and we can just do it. This is on, I ran all this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=227" target="_blank">00:03:47.520</a></span> | <span class="t">on my MacBook Pro. So yeah, it didn't even take long. It may be a minute or a couple of minutes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=234" target="_blank">00:03:54.720</a></span> | <span class="t">for each image at most. So with this one, again, it's the same prompt again. All I did was change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=242" target="_blank">00:04:02.000</a></span> | <span class="t">the number of inference steps. So I played around with this a little bit. I'm not familiar with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=247" target="_blank">00:04:07.520</a></span> | <span class="t">the Fuser models, so I don't know the best approach dealing with different parameters here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=255" target="_blank">00:04:15.040</a></span> | <span class="t">but number of inference steps, you can increase or decrease that. And then what I was probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=261" target="_blank">00:04:21.600</a></span> | <span class="t">more interested in here was the prompt engineering side of things. So how can I modify the prompt to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=268" target="_blank">00:04:28.160</a></span> | <span class="t">make it more like what I want it to be? And I see a lot of people saying, well, I'll show you in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=275" target="_blank">00:04:35.040</a></span> | <span class="t">moment. But I started off with this photorealistic image of a squirrel eating a banana. And yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=280" target="_blank">00:04:40.800</a></span> | <span class="t">you can see straight away, like there's a bit more detail in this image. The banana and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=285" target="_blank">00:04:45.520</a></span> | <span class="t">squirrel kind of like melded together here. It's a bit weird, but it's a kind of more realistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=293" target="_blank">00:04:53.360</a></span> | <span class="t">image. And I noticed there's also this reflection down here from the banana, which is kind of cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=302" target="_blank">00:05:02.320</a></span> | <span class="t">And yeah, with this prompt engineering stuff, I see people adding things in 4K to try and make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=307" target="_blank">00:05:07.440</a></span> | <span class="t">something higher quality. Now this is with Dali 2, so it's not necessarily the same with this model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=317" target="_blank">00:05:17.680</a></span> | <span class="t">but I thought I'd give it a go anyway. We get this. And this is like, it seems to be trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=322" target="_blank">00:05:22.800</a></span> | <span class="t">to pull in more detail around here. I wouldn't say it necessarily works, but it's kind of cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=331" target="_blank">00:05:31.520</a></span> | <span class="t">It's kind of weird as these two eyes staring at us here, but nonetheless, interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=338" target="_blank">00:05:38.400</a></span> | <span class="t">So this, I thought I'd go away from the squirrel examples and go for an Italian person eating pizza</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=346" target="_blank">00:05:46.000</a></span> | <span class="t">on top of the Colosseum in Rome. And we get this, which is pretty good actually. It's not on top of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=352" target="_blank">00:05:52.720</a></span> | <span class="t">the Colosseum, but I thought this was pretty cool anyway. It looks a lot like the Colosseum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=361" target="_blank">00:06:01.920</a></span> | <span class="t">and he looks relatively Italian. Some interesting sunglasses here as well. And the pizza is a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=367" target="_blank">00:06:07.600</a></span> | <span class="t">strange, but yeah, pretty cool. Here, photorealistic image of a squirrel eating a banana</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=375" target="_blank">00:06:15.840</a></span> | <span class="t">rendered in Unity. This is taking inspiration from what I've seen people do with OpenAI's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=381" target="_blank">00:06:21.200</a></span> | <span class="t">Dali here. And yeah, we get this. I assume they must've trained on a lot of stock images because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=387" target="_blank">00:06:27.520</a></span> | <span class="t">I got this a few times. You can kind of see the overlay, like the watermark from the stock image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=394" target="_blank">00:06:34.320</a></span> | <span class="t">here. And then like down here, I think that's pretty, like you usually have like some information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=400" target="_blank">00:06:40.320</a></span> | <span class="t">about the stock image at the bottom or the company that owns the stock image. So I thought that was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=405" target="_blank">00:06:45.440</a></span> | <span class="t">kind of funny that that comes through. It came through on a lot of it, on a fair few images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=410" target="_blank">00:06:50.800</a></span> | <span class="t">Not a lot, but a few. I thought I'd try Unreal Engine as well. Yeah, similar sort of thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=418" target="_blank">00:06:58.400</a></span> | <span class="t">So one thing that I have noticed with this is that it seems to be able to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=425" target="_blank">00:07:05.440</a></span> | <span class="t">it's like here I put a giant squirrel destroying a city, which is a pretty abstract thing. There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=432" target="_blank">00:07:12.160</a></span> | <span class="t">probably not any pictures of that, that it has seen in the past. And I think when there's no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=437" target="_blank">00:07:17.920</a></span> | <span class="t">pictures of something that it's seen in the past, it's true it's put two concepts together,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=442" target="_blank">00:07:22.880</a></span> | <span class="t">at least this model. So yeah, I kind of got this. I think this is the best image and I tried a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=450" target="_blank">00:07:30.640</a></span> | <span class="t">of prompts with this. So we've got the squirrel here and he's on some kind of blocks. It looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=455" target="_blank">00:07:35.280</a></span> | <span class="t">a bit like a city. That one, okay, it's not so bad. And then there was this one as well. It kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=461" target="_blank">00:07:41.600</a></span> | <span class="t">of looks like a city in the background. I thought that was pretty cool. But then the remaining,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=467" target="_blank">00:07:47.680</a></span> | <span class="t">the remaining ones here are just like a squirrel or a squirrel thing in a natural environment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=474" target="_blank">00:07:54.880</a></span> | <span class="t">Or this one, so here I'm playing around the inference steps. I just turned it right down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=481" target="_blank">00:08:01.760</a></span> | <span class="t">and you just kind of get this interesting. Again, I don't know anything about diffusion models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=488" target="_blank">00:08:08.560</a></span> | <span class="t">so I don't know why it's doing that. I assume it's just, well, I know that it's generating the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=496" target="_blank">00:08:16.880</a></span> | <span class="t">image from noise. So I assume this needs a few inference steps in order to take that noise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=506" target="_blank">00:08:26.080</a></span> | <span class="t">and create an image out of it. So at this point, it's still kind of stuck halfway in between the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=512" target="_blank">00:08:32.720</a></span> | <span class="t">noise and an actual image, I assume. Yeah, no, we kept going through these, just a squirrel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=520" target="_blank">00:08:40.720</a></span> | <span class="t">squirrel again. And then I eventually got this image of a squirrel thing inside what seems to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=529" target="_blank">00:08:49.360</a></span> | <span class="t">be a city. Yeah, and then I got a picture of an actual city. So it seems, yeah, it knows what a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=537" target="_blank">00:08:57.280</a></span> | <span class="t">squirrel is, it knows what a city is, but putting those two things together, particularly a giant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=542" target="_blank">00:09:02.720</a></span> | <span class="t">squirrel, doesn't seem to do so well with that. Here I modified it a little bit, so a landscape</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=550" target="_blank">00:09:10.720</a></span> | <span class="t">image. And then the same prompt, slightly different number of inference steps. No, no,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=558" target="_blank">00:09:18.720</a></span> | <span class="t">actually the same. So I just re-ran this same prompt twice, same parameters, and it just got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=563" target="_blank">00:09:23.680</a></span> | <span class="t">like a weird squirrel again. Kind of cool with this grass detail in front here, though. Anyway,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=572" target="_blank">00:09:32.080</a></span> | <span class="t">yeah, that's that one example. I wanted to have another go with some other models as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=579" target="_blank">00:09:39.120</a></span> | <span class="t">These are less impressive, I'll be honest. But this is literally, I feel like they released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=589" target="_blank">00:09:49.040</a></span> | <span class="t">this library like a week ago, maybe, at the time of me recording this. So it's really new. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=596" target="_blank">00:09:56.000</a></span> | <span class="t">there's all these different pipelines, by the way. As far as I understand, this pipeline uses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=601" target="_blank">00:10:01.600</a></span> | <span class="t">a different something called a scheduler, which is like the algorithm that denoises the noise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=609" target="_blank">00:10:09.840</a></span> | <span class="t">the input noise, that the image is generated from. Don't quote me on that. I think that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=617" target="_blank">00:10:17.680</a></span> | <span class="t">what these different pipelines are doing, but I'm really not sure. It's something along those lines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=626" target="_blank">00:10:26.560</a></span> | <span class="t">Okay. So with this one, this is like a Pokemon trained by this guy here. I think he's called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=636" target="_blank">00:10:36.640</a></span> | <span class="t">Manuel or something. He has a load of models that he's built through Hugging Face. And this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=645" target="_blank">00:10:45.840</a></span> | <span class="t">supposed to be a Pokemon image generation model. So, yeah, I mean, you can kind of see it definitely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=655" target="_blank">00:10:55.680</a></span> | <span class="t">has that Pokemon style to it. But it's not really a good, I wouldn't say it's a good Pokemon. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=666" target="_blank">00:11:06.560</a></span> | <span class="t">kind of messed up. And then I thought I'd try the other pipeline. So I read on the Hugging Face</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=676" target="_blank">00:11:16.240</a></span> | <span class="t">diffuser's GitHub repo that, and I don't know if this is completely accurate or not,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=682" target="_blank">00:11:22.880</a></span> | <span class="t">but this DDIMP or DDIM algorithm is supposed to be slower. Yes, slower, but more accurate or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=700" target="_blank">00:11:40.000</a></span> | <span class="t">can produce better quality images than the DDPM pipeline. But that's not always true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=707" target="_blank">00:11:47.920</a></span> | <span class="t">And in a lot of cases, I imagine these different models have been trained with one of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=715" target="_blank">00:11:55.760</a></span> | <span class="t">algorithms in mind and you can't always, for some models you can, but you can't always switch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=723" target="_blank">00:12:03.120</a></span> | <span class="t">between the two algorithms and get them to work with a particular model. That's how I've understood</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=728" target="_blank">00:12:08.960</a></span> | <span class="t">it. Again, could be wrong. I don't know. But it's definitely faster. This took me like two minutes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=734" target="_blank">00:12:14.480</a></span> | <span class="t">and 30. This is running for a thousand inference steps by default. I'll show you, we can change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=741" target="_blank">00:12:21.120</a></span> | <span class="t">that in a moment. The same here was seven seconds, but then we just got noise. So I thought, okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=747" target="_blank">00:12:27.040</a></span> | <span class="t">maybe it just needs to be ran for more steps. Actually, sorry, this was run for 50 inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=755" target="_blank">00:12:35.200</a></span> | <span class="t">steps by default, not a thousand. And the same for this one here. And then here I turn that up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=762" target="_blank">00:12:42.160</a></span> | <span class="t">to a thousand just to see if it would produce anything, because I expected that maybe if I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=768" target="_blank">00:12:48.400</a></span> | <span class="t">run it for more inference steps, it might do something. But no, unfortunately not. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=774" target="_blank">00:12:54.880</a></span> | <span class="t">clearly this model can't, we can't use different algorithms or denoising algorithms. Maybe that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=783" target="_blank">00:13:03.040</a></span> | <span class="t">what they're called. I don't know, with that model. So then I thought, okay, let's try a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=789" target="_blank">00:13:09.520</a></span> | <span class="t">different model. This is from Google. Google have put out a load of these diffusion models in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=795" target="_blank">00:13:15.040</a></span> | <span class="t">last couple of days on Hugging Face, which is pretty cool. And obviously this, you need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=799" target="_blank">00:13:19.920</a></span> | <span class="t">use a DDPM pipeline. You see in the model name or model ID. And yeah, this one takes ages to run,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=809" target="_blank">00:13:29.120</a></span> | <span class="t">at least on my M1 Macs without MPS. It was about 25 minutes, really long. And then I got this. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=818" target="_blank">00:13:38.560</a></span> | <span class="t">it was a bit disappointing, but you can kind of see there's a sort of a cat face in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=823" target="_blank">00:13:43.520</a></span> | <span class="t">There's definitely the feeling of a cat in this image. I wouldn't say that is actually a cat in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=830" target="_blank">00:13:50.000</a></span> | <span class="t">this image though. And the same, this one, you can kind of see a cat over here. Yeah. Interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=839" target="_blank">00:13:59.120</a></span> | <span class="t">And there's, again, the feeling of a cat in this image, but there's definitely not a cat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=844" target="_blank">00:14:04.320</a></span> | <span class="t">Yeah. Maybe there's a cat, but it doesn't look very healthy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=849" target="_blank">00:14:09.920</a></span> | <span class="t">And then the last thing I just had a look at here is this config. So the model or pipelines here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=859" target="_blank">00:14:19.200</a></span> | <span class="t">they are set up using this configuration dictionary and you can modify different parts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=867" target="_blank">00:14:27.760</a></span> | <span class="t">of your pipeline by changing this config and loading your pipeline with a different config.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=873" target="_blank">00:14:33.600</a></span> | <span class="t">Similar to the configs in the Transformers library where you have like a BERT config and you load</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=880" target="_blank">00:14:40.080</a></span> | <span class="t">that into your BERT model. I assume they're going for a similar sort of thing here. So I thought I'd</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=886" target="_blank">00:14:46.240</a></span> | <span class="t">just point that out. But yeah, it's literally very early days with this library. I haven't really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=893" target="_blank">00:14:53.520</a></span> | <span class="t">been through anything. I've just taken a very high-level look at the library and played around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=901" target="_blank">00:15:01.360</a></span> | <span class="t">with a few image generation pieces. So I hope this is interesting to see. I'm pretty excited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=908" target="_blank">00:15:08.240</a></span> | <span class="t">for this library. I definitely want to play with it a lot more in the future. Very soon,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=913" target="_blank">00:15:13.920</a></span> | <span class="t">I'm also going to be having a look at some other diffuser models. So hopefully I will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=918" target="_blank">00:15:18.080</a></span> | <span class="t">understand them better in the very near future. So thank you very much for watching. I hope this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=UzkdOg7wWmI&t=928" target="_blank">00:15:28.000</a></span> | <span class="t">video has been interesting and I will see you again in the next one. Bye.</span></div></div></body></html>